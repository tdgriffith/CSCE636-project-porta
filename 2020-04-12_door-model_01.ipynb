{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.281647Z",
     "start_time": "2020-05-01T02:24:25.274699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.463030Z",
     "start_time": "2020-05-01T02:24:25.282888Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.686381Z",
     "start_time": "2020-05-01T02:24:25.464230Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.695139Z",
     "start_time": "2020-05-01T02:24:25.687539Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.706926Z",
     "start_time": "2020-05-01T02:24:25.696176Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.716623Z",
     "start_time": "2020-05-01T02:24:25.707836Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.727287Z",
     "start_time": "2020-05-01T02:24:25.718111Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:25.736207Z",
     "start_time": "2020-05-01T02:24:25.728524Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:26.867745Z",
     "start_time": "2020-05-01T02:24:25.737156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/191]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:26.877448Z",
     "start_time": "2020-05-01T02:24:26.868803Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:26.887496Z",
     "start_time": "2020-05-01T02:24:26.878374Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/val')\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:27.182833Z",
     "start_time": "2020-05-01T02:24:26.888566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/56]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:27.192525Z",
     "start_time": "2020-05-01T02:24:27.183931Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:27.731185Z",
     "start_time": "2020-05-01T02:24:27.193452Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.144734Z",
     "start_time": "2020-05-01T02:24:27.732374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.154709Z",
     "start_time": "2020-05-01T02:24:30.145577Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.179414Z",
     "start_time": "2020-05-01T02:24:30.155903Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 1200), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1200,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.196150Z",
     "start_time": "2020-05-01T02:24:30.180514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1200, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.208157Z",
     "start_time": "2020-05-01T02:24:30.197941Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-3,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:24:30.218779Z",
     "start_time": "2020-05-01T02:24:30.209268Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:17.530864Z",
     "start_time": "2020-05-01T02:24:30.219739Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/12]\tTime 0.741 (0.741)\tData 0.399 (0.399)\tLoss 1.1038 (1.1038)\tAcc 0.250 (0.250)\n",
      "Epoch: [1][2/12]\tTime 0.031 (0.386)\tData 0.003 (0.201)\tLoss 1.0988 (1.1013)\tAcc 0.250 (0.250)\n",
      "Epoch: [1][3/12]\tTime 0.112 (0.295)\tData 0.083 (0.162)\tLoss 1.0926 (1.0984)\tAcc 0.562 (0.354)\n",
      "Epoch: [1][4/12]\tTime 0.088 (0.243)\tData 0.062 (0.137)\tLoss 1.0789 (1.0935)\tAcc 0.750 (0.453)\n",
      "Epoch: [1][5/12]\tTime 0.083 (0.211)\tData 0.057 (0.121)\tLoss 1.0592 (1.0866)\tAcc 0.688 (0.500)\n",
      "Epoch: [1][6/12]\tTime 0.081 (0.189)\tData 0.056 (0.110)\tLoss 1.0434 (1.0794)\tAcc 0.688 (0.531)\n",
      "Epoch: [1][7/12]\tTime 0.083 (0.174)\tData 0.058 (0.103)\tLoss 1.0623 (1.0770)\tAcc 0.562 (0.536)\n",
      "Epoch: [1][8/12]\tTime 0.079 (0.162)\tData 0.054 (0.096)\tLoss 1.0185 (1.0697)\tAcc 0.688 (0.555)\n",
      "Epoch: [1][9/12]\tTime 0.083 (0.153)\tData 0.056 (0.092)\tLoss 0.9702 (1.0586)\tAcc 0.812 (0.583)\n",
      "Epoch: [1][10/12]\tTime 0.085 (0.147)\tData 0.059 (0.089)\tLoss 0.9787 (1.0506)\tAcc 0.688 (0.594)\n",
      "Epoch: [1][11/12]\tTime 0.083 (0.141)\tData 0.058 (0.086)\tLoss 1.0221 (1.0480)\tAcc 0.562 (0.591)\n",
      "Epoch: [1][12/12]\tTime 0.086 (0.136)\tData 0.061 (0.084)\tLoss 0.9939 (1.0438)\tAcc 0.600 (0.592)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/18]\tTime 0.306 (0.306)\tData 0.283 (0.283)\tLoss 0.9235 (0.9235)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/18]\tTime 0.074 (0.190)\tData 0.054 (0.168)\tLoss 1.0850 (1.0043)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/18]\tTime 0.077 (0.152)\tData 0.055 (0.130)\tLoss 1.0055 (1.0047)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/18]\tTime 0.075 (0.133)\tData 0.054 (0.111)\tLoss 1.0075 (1.0054)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/18]\tTime 0.080 (0.122)\tData 0.057 (0.101)\tLoss 1.0076 (1.0058)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/18]\tTime 0.077 (0.115)\tData 0.057 (0.093)\tLoss 0.9135 (0.9904)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/18]\tTime 0.076 (0.109)\tData 0.056 (0.088)\tLoss 0.9328 (0.9822)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/18]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 1.0635 (0.9924)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/18]\tTime 0.076 (0.102)\tData 0.055 (0.081)\tLoss 0.9126 (0.9835)\tAcc 1.000 (0.757)\n",
      "Epoch: [1][10/18]\tTime 0.076 (0.099)\tData 0.055 (0.078)\tLoss 1.1153 (0.9967)\tAcc 0.375 (0.719)\n",
      "Epoch: [1][11/18]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 1.0983 (1.0059)\tAcc 0.375 (0.688)\n",
      "Epoch: [1][12/18]\tTime 0.076 (0.095)\tData 0.056 (0.074)\tLoss 1.0539 (1.0099)\tAcc 0.562 (0.677)\n",
      "Epoch: [1][13/18]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 1.1189 (1.0183)\tAcc 0.312 (0.649)\n",
      "Epoch: [1][14/18]\tTime 0.078 (0.092)\tData 0.057 (0.072)\tLoss 1.0265 (1.0189)\tAcc 0.625 (0.647)\n",
      "Epoch: [1][15/18]\tTime 0.077 (0.091)\tData 0.057 (0.071)\tLoss 1.0287 (1.0195)\tAcc 0.625 (0.646)\n",
      "Epoch: [1][16/18]\tTime 0.075 (0.090)\tData 0.055 (0.070)\tLoss 1.0297 (1.0202)\tAcc 0.625 (0.645)\n",
      "Epoch: [1][17/18]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 1.0263 (1.0205)\tAcc 0.625 (0.643)\n",
      "Epoch: [1][18/18]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 1.0261 (1.0207)\tAcc 0.625 (0.643)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/12]\tTime 0.533 (0.533)\tData 0.503 (0.503)\tLoss 0.9630 (0.9630)\tAcc 0.625 (0.625)\n",
      "Epoch: [2][2/12]\tTime 0.079 (0.306)\tData 0.052 (0.277)\tLoss 0.8832 (0.9231)\tAcc 0.750 (0.688)\n",
      "Epoch: [2][3/12]\tTime 0.082 (0.231)\tData 0.056 (0.203)\tLoss 0.9281 (0.9248)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/12]\tTime 0.083 (0.194)\tData 0.058 (0.167)\tLoss 0.9983 (0.9431)\tAcc 0.562 (0.656)\n",
      "Epoch: [2][5/12]\tTime 0.084 (0.172)\tData 0.059 (0.145)\tLoss 0.9287 (0.9403)\tAcc 0.625 (0.650)\n",
      "Epoch: [2][6/12]\tTime 0.084 (0.157)\tData 0.059 (0.131)\tLoss 1.0174 (0.9531)\tAcc 0.562 (0.635)\n",
      "Epoch: [2][7/12]\tTime 0.085 (0.147)\tData 0.060 (0.121)\tLoss 0.8216 (0.9343)\tAcc 0.750 (0.652)\n",
      "Epoch: [2][8/12]\tTime 0.084 (0.139)\tData 0.058 (0.113)\tLoss 0.6805 (0.9026)\tAcc 0.875 (0.680)\n",
      "Epoch: [2][9/12]\tTime 0.083 (0.133)\tData 0.058 (0.107)\tLoss 0.9117 (0.9036)\tAcc 0.625 (0.674)\n",
      "Epoch: [2][10/12]\tTime 0.082 (0.128)\tData 0.057 (0.102)\tLoss 0.7575 (0.8890)\tAcc 0.750 (0.681)\n",
      "Epoch: [2][11/12]\tTime 0.083 (0.124)\tData 0.058 (0.098)\tLoss 0.8425 (0.8848)\tAcc 0.688 (0.682)\n",
      "Epoch: [2][12/12]\tTime 0.084 (0.120)\tData 0.059 (0.095)\tLoss 0.7627 (0.8752)\tAcc 0.733 (0.686)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/18]\tTime 0.231 (0.231)\tData 0.196 (0.196)\tLoss 0.7520 (0.7520)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/18]\tTime 0.067 (0.149)\tData 0.046 (0.121)\tLoss 1.1480 (0.9500)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/18]\tTime 0.080 (0.126)\tData 0.059 (0.100)\tLoss 0.9480 (0.9493)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/18]\tTime 0.078 (0.114)\tData 0.057 (0.089)\tLoss 0.9384 (0.9466)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/18]\tTime 0.074 (0.106)\tData 0.054 (0.082)\tLoss 0.9204 (0.9414)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/18]\tTime 0.073 (0.101)\tData 0.053 (0.077)\tLoss 0.6887 (0.8993)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/18]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.7550 (0.8786)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/18]\tTime 0.075 (0.094)\tData 0.054 (0.072)\tLoss 1.0665 (0.9021)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.6669 (0.8760)\tAcc 1.000 (0.757)\n",
      "Epoch: [2][10/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.1791 (0.9063)\tAcc 0.375 (0.719)\n",
      "Epoch: [2][11/18]\tTime 0.073 (0.089)\tData 0.053 (0.067)\tLoss 1.1612 (0.9295)\tAcc 0.375 (0.688)\n",
      "Epoch: [2][12/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.0186 (0.9369)\tAcc 0.562 (0.677)\n",
      "Epoch: [2][13/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.2039 (0.9574)\tAcc 0.312 (0.649)\n",
      "Epoch: [2][14/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.9537 (0.9572)\tAcc 0.625 (0.647)\n",
      "Epoch: [2][15/18]\tTime 0.076 (0.085)\tData 0.056 (0.063)\tLoss 0.9659 (0.9577)\tAcc 0.625 (0.646)\n",
      "Epoch: [2][16/18]\tTime 0.079 (0.084)\tData 0.059 (0.063)\tLoss 0.9683 (0.9584)\tAcc 0.625 (0.645)\n",
      "Epoch: [2][17/18]\tTime 0.078 (0.084)\tData 0.058 (0.063)\tLoss 0.9699 (0.9591)\tAcc 0.625 (0.643)\n",
      "Epoch: [2][18/18]\tTime 0.077 (0.084)\tData 0.058 (0.063)\tLoss 0.9590 (0.9591)\tAcc 0.625 (0.643)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/12]\tTime 0.492 (0.492)\tData 0.462 (0.462)\tLoss 0.7602 (0.7602)\tAcc 0.750 (0.750)\n",
      "Epoch: [3][2/12]\tTime 0.079 (0.286)\tData 0.054 (0.258)\tLoss 0.8331 (0.7966)\tAcc 0.688 (0.719)\n",
      "Epoch: [3][3/12]\tTime 0.084 (0.219)\tData 0.059 (0.192)\tLoss 1.2391 (0.9441)\tAcc 0.438 (0.625)\n",
      "Epoch: [3][4/12]\tTime 0.085 (0.185)\tData 0.058 (0.158)\tLoss 0.8448 (0.9193)\tAcc 0.688 (0.641)\n",
      "Epoch: [3][5/12]\tTime 0.128 (0.174)\tData 0.103 (0.147)\tLoss 0.6427 (0.8640)\tAcc 0.812 (0.675)\n",
      "Epoch: [3][6/12]\tTime 0.079 (0.158)\tData 0.054 (0.132)\tLoss 1.1802 (0.9167)\tAcc 0.500 (0.646)\n",
      "Epoch: [3][7/12]\tTime 0.079 (0.147)\tData 0.054 (0.120)\tLoss 1.0151 (0.9307)\tAcc 0.625 (0.643)\n",
      "Epoch: [3][8/12]\tTime 0.078 (0.138)\tData 0.052 (0.112)\tLoss 0.5893 (0.8881)\tAcc 0.812 (0.664)\n",
      "Epoch: [3][9/12]\tTime 0.089 (0.132)\tData 0.064 (0.107)\tLoss 0.8433 (0.8831)\tAcc 0.688 (0.667)\n",
      "Epoch: [3][10/12]\tTime 0.079 (0.127)\tData 0.055 (0.101)\tLoss 0.6683 (0.8616)\tAcc 0.812 (0.681)\n",
      "Epoch: [3][11/12]\tTime 0.079 (0.123)\tData 0.055 (0.097)\tLoss 0.5328 (0.8317)\tAcc 0.875 (0.699)\n",
      "Epoch: [3][12/12]\tTime 0.079 (0.119)\tData 0.055 (0.094)\tLoss 1.0683 (0.8503)\tAcc 0.533 (0.686)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/18]\tTime 0.224 (0.224)\tData 0.196 (0.196)\tLoss 0.6312 (0.6312)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/18]\tTime 0.075 (0.149)\tData 0.048 (0.122)\tLoss 1.1849 (0.9081)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/18]\tTime 0.069 (0.123)\tData 0.048 (0.097)\tLoss 0.9260 (0.9140)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.086)\tLoss 0.9396 (0.9204)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/18]\tTime 0.074 (0.103)\tData 0.054 (0.080)\tLoss 0.8913 (0.9146)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/18]\tTime 0.073 (0.098)\tData 0.053 (0.075)\tLoss 0.5833 (0.8594)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/18]\tTime 0.077 (0.095)\tData 0.057 (0.073)\tLoss 0.6962 (0.8361)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/18]\tTime 0.073 (0.092)\tData 0.053 (0.070)\tLoss 1.1017 (0.8693)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/18]\tTime 0.075 (0.090)\tData 0.054 (0.068)\tLoss 0.5480 (0.8336)\tAcc 1.000 (0.757)\n",
      "Epoch: [3][10/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 1.2468 (0.8749)\tAcc 0.375 (0.719)\n",
      "Epoch: [3][11/18]\tTime 0.073 (0.087)\tData 0.053 (0.066)\tLoss 1.2138 (0.9057)\tAcc 0.375 (0.688)\n",
      "Epoch: [3][12/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 1.0531 (0.9180)\tAcc 0.562 (0.677)\n",
      "Epoch: [3][13/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 1.2872 (0.9464)\tAcc 0.312 (0.649)\n",
      "Epoch: [3][14/18]\tTime 0.073 (0.085)\tData 0.053 (0.063)\tLoss 0.9497 (0.9466)\tAcc 0.625 (0.647)\n",
      "Epoch: [3][15/18]\tTime 0.075 (0.084)\tData 0.056 (0.063)\tLoss 0.9432 (0.9464)\tAcc 0.625 (0.646)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][16/18]\tTime 0.073 (0.083)\tData 0.053 (0.062)\tLoss 0.9290 (0.9453)\tAcc 0.625 (0.645)\n",
      "Epoch: [3][17/18]\tTime 0.075 (0.083)\tData 0.054 (0.062)\tLoss 0.9592 (0.9461)\tAcc 0.625 (0.643)\n",
      "Epoch: [3][18/18]\tTime 0.075 (0.082)\tData 0.055 (0.061)\tLoss 0.9582 (0.9465)\tAcc 0.625 (0.643)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/12]\tTime 0.374 (0.374)\tData 0.347 (0.347)\tLoss 0.7274 (0.7274)\tAcc 0.750 (0.750)\n",
      "Epoch: [4][2/12]\tTime 0.079 (0.227)\tData 0.051 (0.199)\tLoss 0.7665 (0.7469)\tAcc 0.750 (0.750)\n",
      "Epoch: [4][3/12]\tTime 0.077 (0.177)\tData 0.052 (0.150)\tLoss 0.7898 (0.7612)\tAcc 0.688 (0.729)\n",
      "Epoch: [4][4/12]\tTime 0.078 (0.152)\tData 0.053 (0.126)\tLoss 0.8210 (0.7762)\tAcc 0.688 (0.719)\n",
      "Epoch: [4][5/12]\tTime 0.081 (0.138)\tData 0.056 (0.112)\tLoss 0.6308 (0.7471)\tAcc 0.812 (0.738)\n",
      "Epoch: [4][6/12]\tTime 0.078 (0.128)\tData 0.053 (0.102)\tLoss 0.5405 (0.7127)\tAcc 0.875 (0.760)\n",
      "Epoch: [4][7/12]\tTime 0.079 (0.121)\tData 0.054 (0.095)\tLoss 0.9918 (0.7525)\tAcc 0.562 (0.732)\n",
      "Epoch: [4][8/12]\tTime 0.079 (0.116)\tData 0.054 (0.090)\tLoss 0.8048 (0.7591)\tAcc 0.688 (0.727)\n",
      "Epoch: [4][9/12]\tTime 0.084 (0.112)\tData 0.056 (0.086)\tLoss 0.9962 (0.7854)\tAcc 0.562 (0.708)\n",
      "Epoch: [4][10/12]\tTime 0.077 (0.109)\tData 0.051 (0.083)\tLoss 0.8252 (0.7894)\tAcc 0.688 (0.706)\n",
      "Epoch: [4][11/12]\tTime 0.077 (0.106)\tData 0.052 (0.080)\tLoss 1.0344 (0.8117)\tAcc 0.562 (0.693)\n",
      "Epoch: [4][12/12]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 0.9739 (0.8244)\tAcc 0.600 (0.686)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/18]\tTime 0.215 (0.215)\tData 0.185 (0.185)\tLoss 0.5800 (0.5800)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/18]\tTime 0.068 (0.141)\tData 0.046 (0.116)\tLoss 1.1803 (0.8801)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/18]\tTime 0.077 (0.120)\tData 0.056 (0.096)\tLoss 0.8871 (0.8825)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/18]\tTime 0.079 (0.110)\tData 0.058 (0.086)\tLoss 0.8973 (0.8862)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/18]\tTime 0.079 (0.104)\tData 0.057 (0.080)\tLoss 0.8815 (0.8852)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/18]\tTime 0.078 (0.099)\tData 0.057 (0.077)\tLoss 0.5065 (0.8221)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/18]\tTime 0.079 (0.097)\tData 0.058 (0.074)\tLoss 0.6326 (0.7950)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/18]\tTime 0.080 (0.094)\tData 0.059 (0.072)\tLoss 1.1109 (0.8345)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/18]\tTime 0.078 (0.093)\tData 0.057 (0.070)\tLoss 0.5164 (0.7992)\tAcc 1.000 (0.757)\n",
      "Epoch: [4][10/18]\tTime 0.079 (0.091)\tData 0.058 (0.069)\tLoss 1.2215 (0.8414)\tAcc 0.375 (0.719)\n",
      "Epoch: [4][11/18]\tTime 0.078 (0.090)\tData 0.058 (0.068)\tLoss 1.2209 (0.8759)\tAcc 0.375 (0.688)\n",
      "Epoch: [4][12/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 0.9815 (0.8847)\tAcc 0.562 (0.677)\n",
      "Epoch: [4][13/18]\tTime 0.078 (0.088)\tData 0.057 (0.066)\tLoss 1.2849 (0.9155)\tAcc 0.312 (0.649)\n",
      "Epoch: [4][14/18]\tTime 0.079 (0.088)\tData 0.058 (0.066)\tLoss 0.9331 (0.9167)\tAcc 0.625 (0.647)\n",
      "Epoch: [4][15/18]\tTime 0.078 (0.087)\tData 0.058 (0.065)\tLoss 0.9395 (0.9183)\tAcc 0.625 (0.646)\n",
      "Epoch: [4][16/18]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 0.9194 (0.9183)\tAcc 0.625 (0.645)\n",
      "Epoch: [4][17/18]\tTime 0.075 (0.086)\tData 0.056 (0.064)\tLoss 0.9152 (0.9182)\tAcc 0.625 (0.643)\n",
      "Epoch: [4][18/18]\tTime 0.080 (0.085)\tData 0.060 (0.064)\tLoss 0.8957 (0.9175)\tAcc 0.625 (0.643)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/12]\tTime 0.412 (0.412)\tData 0.384 (0.384)\tLoss 1.0853 (1.0853)\tAcc 0.500 (0.500)\n",
      "Epoch: [5][2/12]\tTime 0.083 (0.248)\tData 0.056 (0.220)\tLoss 0.8760 (0.9806)\tAcc 0.625 (0.562)\n",
      "Epoch: [5][3/12]\tTime 0.082 (0.193)\tData 0.057 (0.166)\tLoss 0.6988 (0.8867)\tAcc 0.750 (0.625)\n",
      "Epoch: [5][4/12]\tTime 0.086 (0.166)\tData 0.058 (0.139)\tLoss 0.8513 (0.8779)\tAcc 0.625 (0.625)\n",
      "Epoch: [5][5/12]\tTime 0.084 (0.149)\tData 0.059 (0.123)\tLoss 0.9301 (0.8883)\tAcc 0.562 (0.613)\n",
      "Epoch: [5][6/12]\tTime 0.085 (0.139)\tData 0.060 (0.112)\tLoss 0.9203 (0.8936)\tAcc 0.562 (0.604)\n",
      "Epoch: [5][7/12]\tTime 0.081 (0.130)\tData 0.057 (0.105)\tLoss 0.5926 (0.8506)\tAcc 0.875 (0.643)\n",
      "Epoch: [5][8/12]\tTime 0.079 (0.124)\tData 0.054 (0.098)\tLoss 0.7707 (0.8407)\tAcc 0.750 (0.656)\n",
      "Epoch: [5][9/12]\tTime 0.081 (0.119)\tData 0.056 (0.094)\tLoss 0.6637 (0.8210)\tAcc 0.812 (0.674)\n",
      "Epoch: [5][10/12]\tTime 0.079 (0.115)\tData 0.054 (0.090)\tLoss 0.9539 (0.8343)\tAcc 0.562 (0.663)\n",
      "Epoch: [5][11/12]\tTime 0.080 (0.112)\tData 0.055 (0.087)\tLoss 0.6885 (0.8210)\tAcc 0.750 (0.670)\n",
      "Epoch: [5][12/12]\tTime 0.080 (0.109)\tData 0.055 (0.084)\tLoss 0.5965 (0.8034)\tAcc 0.867 (0.686)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/18]\tTime 0.227 (0.227)\tData 0.200 (0.200)\tLoss 0.6034 (0.6034)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/18]\tTime 0.077 (0.152)\tData 0.048 (0.124)\tLoss 1.1157 (0.8596)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/18]\tTime 0.068 (0.124)\tData 0.047 (0.098)\tLoss 0.8811 (0.8667)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/18]\tTime 0.073 (0.111)\tData 0.053 (0.087)\tLoss 0.8535 (0.8634)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/18]\tTime 0.079 (0.105)\tData 0.058 (0.081)\tLoss 0.8485 (0.8604)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/18]\tTime 0.078 (0.100)\tData 0.058 (0.077)\tLoss 0.5466 (0.8081)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/18]\tTime 0.078 (0.097)\tData 0.058 (0.074)\tLoss 0.6579 (0.7867)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 1.0630 (0.8212)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/18]\tTime 0.079 (0.093)\tData 0.058 (0.071)\tLoss 0.4986 (0.7854)\tAcc 1.000 (0.757)\n",
      "Epoch: [5][10/18]\tTime 0.078 (0.092)\tData 0.058 (0.070)\tLoss 1.1789 (0.8247)\tAcc 0.375 (0.719)\n",
      "Epoch: [5][11/18]\tTime 0.079 (0.091)\tData 0.059 (0.069)\tLoss 1.1509 (0.8544)\tAcc 0.375 (0.688)\n",
      "Epoch: [5][12/18]\tTime 0.079 (0.090)\tData 0.059 (0.068)\tLoss 0.9710 (0.8641)\tAcc 0.562 (0.677)\n",
      "Epoch: [5][13/18]\tTime 0.079 (0.089)\tData 0.059 (0.067)\tLoss 1.2456 (0.8934)\tAcc 0.312 (0.649)\n",
      "Epoch: [5][14/18]\tTime 0.079 (0.088)\tData 0.059 (0.067)\tLoss 0.9394 (0.8967)\tAcc 0.625 (0.647)\n",
      "Epoch: [5][15/18]\tTime 0.079 (0.087)\tData 0.059 (0.066)\tLoss 0.9075 (0.8974)\tAcc 0.625 (0.646)\n",
      "Epoch: [5][16/18]\tTime 0.079 (0.087)\tData 0.059 (0.066)\tLoss 0.9314 (0.8996)\tAcc 0.625 (0.645)\n",
      "Epoch: [5][17/18]\tTime 0.078 (0.086)\tData 0.058 (0.065)\tLoss 0.9254 (0.9011)\tAcc 0.625 (0.643)\n",
      "Epoch: [5][18/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 0.8876 (0.9007)\tAcc 0.625 (0.643)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/12]\tTime 0.388 (0.388)\tData 0.359 (0.359)\tLoss 1.0220 (1.0220)\tAcc 0.562 (0.562)\n",
      "Epoch: [6][2/12]\tTime 0.076 (0.232)\tData 0.052 (0.205)\tLoss 0.6778 (0.8499)\tAcc 0.812 (0.688)\n",
      "Epoch: [6][3/12]\tTime 0.079 (0.181)\tData 0.055 (0.155)\tLoss 0.5859 (0.7619)\tAcc 0.875 (0.750)\n",
      "Epoch: [6][4/12]\tTime 0.080 (0.156)\tData 0.054 (0.130)\tLoss 0.6539 (0.7349)\tAcc 0.750 (0.750)\n",
      "Epoch: [6][5/12]\tTime 0.078 (0.140)\tData 0.053 (0.114)\tLoss 0.7529 (0.7385)\tAcc 0.688 (0.738)\n",
      "Epoch: [6][6/12]\tTime 0.088 (0.132)\tData 0.064 (0.106)\tLoss 0.9494 (0.7736)\tAcc 0.562 (0.708)\n",
      "Epoch: [6][7/12]\tTime 0.082 (0.125)\tData 0.056 (0.099)\tLoss 0.8782 (0.7886)\tAcc 0.562 (0.688)\n",
      "Epoch: [6][8/12]\tTime 0.077 (0.119)\tData 0.052 (0.093)\tLoss 0.6399 (0.7700)\tAcc 0.812 (0.703)\n",
      "Epoch: [6][9/12]\tTime 0.080 (0.114)\tData 0.056 (0.089)\tLoss 0.7153 (0.7639)\tAcc 0.688 (0.701)\n",
      "Epoch: [6][10/12]\tTime 0.079 (0.111)\tData 0.056 (0.086)\tLoss 1.1141 (0.7989)\tAcc 0.438 (0.675)\n",
      "Epoch: [6][11/12]\tTime 0.078 (0.108)\tData 0.055 (0.083)\tLoss 0.6249 (0.7831)\tAcc 0.750 (0.682)\n",
      "Epoch: [6][12/12]\tTime 0.079 (0.105)\tData 0.056 (0.081)\tLoss 0.7366 (0.7795)\tAcc 0.733 (0.686)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/18]\tTime 0.220 (0.220)\tData 0.186 (0.186)\tLoss 0.4532 (0.4532)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/18]\tTime 0.063 (0.141)\tData 0.042 (0.114)\tLoss 1.1482 (0.8007)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/18]\tTime 0.073 (0.119)\tData 0.052 (0.093)\tLoss 0.8368 (0.8127)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/18]\tTime 0.074 (0.107)\tData 0.054 (0.084)\tLoss 0.7837 (0.8055)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/18]\tTime 0.074 (0.101)\tData 0.053 (0.078)\tLoss 0.8051 (0.8054)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 0.3500 (0.7295)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 0.5517 (0.7041)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 1.0908 (0.7524)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/18]\tTime 0.075 (0.089)\tData 0.054 (0.067)\tLoss 0.3051 (0.7027)\tAcc 1.000 (0.757)\n",
      "Epoch: [6][10/18]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 1.2679 (0.7593)\tAcc 0.375 (0.719)\n",
      "Epoch: [6][11/18]\tTime 0.073 (0.086)\tData 0.053 (0.065)\tLoss 1.2447 (0.8034)\tAcc 0.375 (0.688)\n",
      "Epoch: [6][12/18]\tTime 0.081 (0.086)\tData 0.061 (0.064)\tLoss 0.9819 (0.8183)\tAcc 0.562 (0.677)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][13/18]\tTime 0.076 (0.085)\tData 0.056 (0.064)\tLoss 1.3302 (0.8576)\tAcc 0.312 (0.649)\n",
      "Epoch: [6][14/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.9263 (0.8626)\tAcc 0.625 (0.647)\n",
      "Epoch: [6][15/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.9360 (0.8675)\tAcc 0.625 (0.646)\n",
      "Epoch: [6][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.9145 (0.8704)\tAcc 0.625 (0.645)\n",
      "Epoch: [6][17/18]\tTime 0.076 (0.083)\tData 0.056 (0.062)\tLoss 0.9417 (0.8746)\tAcc 0.625 (0.643)\n",
      "Epoch: [6][18/18]\tTime 0.075 (0.082)\tData 0.055 (0.061)\tLoss 0.9656 (0.8772)\tAcc 0.625 (0.643)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/12]\tTime 0.391 (0.391)\tData 0.362 (0.362)\tLoss 1.0331 (1.0331)\tAcc 0.500 (0.500)\n",
      "Epoch: [7][2/12]\tTime 0.076 (0.234)\tData 0.052 (0.207)\tLoss 1.0645 (1.0488)\tAcc 0.500 (0.500)\n",
      "Epoch: [7][3/12]\tTime 0.079 (0.182)\tData 0.055 (0.156)\tLoss 0.7363 (0.9446)\tAcc 0.688 (0.562)\n",
      "Epoch: [7][4/12]\tTime 0.082 (0.157)\tData 0.055 (0.131)\tLoss 0.7260 (0.8899)\tAcc 0.688 (0.594)\n",
      "Epoch: [7][5/12]\tTime 0.086 (0.143)\tData 0.061 (0.117)\tLoss 0.5299 (0.8179)\tAcc 0.875 (0.650)\n",
      "Epoch: [7][6/12]\tTime 0.080 (0.132)\tData 0.055 (0.107)\tLoss 0.5554 (0.7742)\tAcc 0.812 (0.677)\n",
      "Epoch: [7][7/12]\tTime 0.082 (0.125)\tData 0.055 (0.099)\tLoss 0.7288 (0.7677)\tAcc 0.750 (0.688)\n",
      "Epoch: [7][8/12]\tTime 0.078 (0.119)\tData 0.052 (0.093)\tLoss 0.7529 (0.7658)\tAcc 0.750 (0.695)\n",
      "Epoch: [7][9/12]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.7660 (0.7659)\tAcc 0.688 (0.694)\n",
      "Epoch: [7][10/12]\tTime 0.080 (0.111)\tData 0.055 (0.086)\tLoss 1.1841 (0.8077)\tAcc 0.438 (0.669)\n",
      "Epoch: [7][11/12]\tTime 0.080 (0.108)\tData 0.055 (0.083)\tLoss 0.6142 (0.7901)\tAcc 0.812 (0.682)\n",
      "Epoch: [7][12/12]\tTime 0.079 (0.106)\tData 0.055 (0.080)\tLoss 0.6800 (0.7814)\tAcc 0.733 (0.686)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/18]\tTime 0.226 (0.226)\tData 0.201 (0.201)\tLoss 0.4101 (0.4101)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/18]\tTime 0.081 (0.153)\tData 0.052 (0.126)\tLoss 1.0753 (0.7427)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/18]\tTime 0.069 (0.125)\tData 0.047 (0.100)\tLoss 0.6509 (0.7121)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/18]\tTime 0.074 (0.112)\tData 0.054 (0.088)\tLoss 0.6807 (0.7042)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/18]\tTime 0.075 (0.105)\tData 0.054 (0.082)\tLoss 0.7933 (0.7220)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/18]\tTime 0.076 (0.100)\tData 0.055 (0.077)\tLoss 0.3585 (0.6615)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/18]\tTime 0.075 (0.097)\tData 0.054 (0.074)\tLoss 0.6054 (0.6534)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/18]\tTime 0.076 (0.094)\tData 0.056 (0.072)\tLoss 1.0569 (0.7039)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/18]\tTime 0.075 (0.092)\tData 0.054 (0.070)\tLoss 0.2293 (0.6511)\tAcc 1.000 (0.757)\n",
      "Epoch: [7][10/18]\tTime 0.075 (0.090)\tData 0.055 (0.068)\tLoss 1.2410 (0.7101)\tAcc 0.375 (0.719)\n",
      "Epoch: [7][11/18]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 1.2666 (0.7607)\tAcc 0.375 (0.688)\n",
      "Epoch: [7][12/18]\tTime 0.076 (0.088)\tData 0.056 (0.066)\tLoss 0.9483 (0.7763)\tAcc 0.562 (0.677)\n",
      "Epoch: [7][13/18]\tTime 0.074 (0.087)\tData 0.055 (0.065)\tLoss 1.2610 (0.8136)\tAcc 0.312 (0.649)\n",
      "Epoch: [7][14/18]\tTime 0.075 (0.086)\tData 0.056 (0.065)\tLoss 0.8415 (0.8156)\tAcc 0.625 (0.647)\n",
      "Epoch: [7][15/18]\tTime 0.075 (0.085)\tData 0.056 (0.064)\tLoss 0.9114 (0.8220)\tAcc 0.625 (0.646)\n",
      "Epoch: [7][16/18]\tTime 0.075 (0.085)\tData 0.056 (0.063)\tLoss 0.8758 (0.8254)\tAcc 0.625 (0.645)\n",
      "Epoch: [7][17/18]\tTime 0.075 (0.084)\tData 0.056 (0.063)\tLoss 0.8981 (0.8296)\tAcc 0.625 (0.643)\n",
      "Epoch: [7][18/18]\tTime 0.075 (0.084)\tData 0.056 (0.063)\tLoss 0.8918 (0.8314)\tAcc 0.625 (0.643)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/12]\tTime 0.528 (0.528)\tData 0.497 (0.497)\tLoss 0.6285 (0.6285)\tAcc 0.812 (0.812)\n",
      "Epoch: [8][2/12]\tTime 0.075 (0.302)\tData 0.050 (0.274)\tLoss 0.6437 (0.6361)\tAcc 0.688 (0.750)\n",
      "Epoch: [8][3/12]\tTime 0.079 (0.227)\tData 0.055 (0.201)\tLoss 0.8077 (0.6933)\tAcc 0.688 (0.729)\n",
      "Epoch: [8][4/12]\tTime 0.083 (0.191)\tData 0.056 (0.164)\tLoss 0.8664 (0.7366)\tAcc 0.688 (0.719)\n",
      "Epoch: [8][5/12]\tTime 0.147 (0.182)\tData 0.118 (0.155)\tLoss 1.1693 (0.8231)\tAcc 0.438 (0.663)\n",
      "Epoch: [8][6/12]\tTime 0.077 (0.165)\tData 0.052 (0.138)\tLoss 0.7065 (0.8037)\tAcc 0.812 (0.688)\n",
      "Epoch: [8][7/12]\tTime 0.081 (0.153)\tData 0.056 (0.126)\tLoss 0.7142 (0.7909)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][8/12]\tTime 0.080 (0.144)\tData 0.055 (0.117)\tLoss 0.9726 (0.8136)\tAcc 0.562 (0.672)\n",
      "Epoch: [8][9/12]\tTime 0.080 (0.137)\tData 0.055 (0.110)\tLoss 0.5746 (0.7871)\tAcc 0.750 (0.681)\n",
      "Epoch: [8][10/12]\tTime 0.079 (0.131)\tData 0.055 (0.105)\tLoss 0.8182 (0.7902)\tAcc 0.625 (0.675)\n",
      "Epoch: [8][11/12]\tTime 0.080 (0.126)\tData 0.055 (0.100)\tLoss 0.4525 (0.7595)\tAcc 0.875 (0.693)\n",
      "Epoch: [8][12/12]\tTime 0.079 (0.122)\tData 0.055 (0.097)\tLoss 0.8509 (0.7667)\tAcc 0.600 (0.686)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/18]\tTime 0.221 (0.221)\tData 0.192 (0.192)\tLoss 0.3989 (0.3989)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/18]\tTime 0.070 (0.145)\tData 0.047 (0.119)\tLoss 1.0026 (0.7008)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/18]\tTime 0.075 (0.122)\tData 0.053 (0.097)\tLoss 0.7219 (0.7078)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/18]\tTime 0.075 (0.110)\tData 0.055 (0.087)\tLoss 0.6866 (0.7025)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/18]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 0.8624 (0.7345)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/18]\tTime 0.076 (0.099)\tData 0.055 (0.076)\tLoss 0.3599 (0.6720)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/18]\tTime 0.076 (0.095)\tData 0.055 (0.073)\tLoss 0.6181 (0.6643)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 1.0049 (0.7069)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/18]\tTime 0.074 (0.091)\tData 0.053 (0.069)\tLoss 0.1782 (0.6482)\tAcc 1.000 (0.757)\n",
      "Epoch: [8][10/18]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 1.2144 (0.7048)\tAcc 0.375 (0.719)\n",
      "Epoch: [8][11/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 1.2118 (0.7509)\tAcc 0.375 (0.688)\n",
      "Epoch: [8][12/18]\tTime 0.075 (0.087)\tData 0.055 (0.065)\tLoss 0.9307 (0.7659)\tAcc 0.562 (0.677)\n",
      "Epoch: [8][13/18]\tTime 0.074 (0.086)\tData 0.055 (0.064)\tLoss 1.2880 (0.8060)\tAcc 0.312 (0.649)\n",
      "Epoch: [8][14/18]\tTime 0.076 (0.085)\tData 0.056 (0.064)\tLoss 0.8594 (0.8098)\tAcc 0.625 (0.647)\n",
      "Epoch: [8][15/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.8783 (0.8144)\tAcc 0.625 (0.646)\n",
      "Epoch: [8][16/18]\tTime 0.077 (0.084)\tData 0.056 (0.063)\tLoss 0.8449 (0.8163)\tAcc 0.625 (0.645)\n",
      "Epoch: [8][17/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.8961 (0.8210)\tAcc 0.625 (0.643)\n",
      "Epoch: [8][18/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.7397 (0.8187)\tAcc 0.625 (0.643)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/12]\tTime 0.446 (0.446)\tData 0.416 (0.416)\tLoss 0.6387 (0.6387)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][2/12]\tTime 0.080 (0.263)\tData 0.054 (0.235)\tLoss 0.9581 (0.7984)\tAcc 0.562 (0.625)\n",
      "Epoch: [9][3/12]\tTime 0.080 (0.202)\tData 0.054 (0.175)\tLoss 0.4369 (0.6779)\tAcc 0.875 (0.708)\n",
      "Epoch: [9][4/12]\tTime 0.084 (0.172)\tData 0.055 (0.145)\tLoss 0.9925 (0.7565)\tAcc 0.562 (0.672)\n",
      "Epoch: [9][5/12]\tTime 0.082 (0.154)\tData 0.057 (0.127)\tLoss 0.5532 (0.7159)\tAcc 0.750 (0.688)\n",
      "Epoch: [9][6/12]\tTime 0.079 (0.142)\tData 0.055 (0.115)\tLoss 0.6431 (0.7037)\tAcc 0.750 (0.698)\n",
      "Epoch: [9][7/12]\tTime 0.080 (0.133)\tData 0.055 (0.107)\tLoss 0.7769 (0.7142)\tAcc 0.625 (0.688)\n",
      "Epoch: [9][8/12]\tTime 0.081 (0.127)\tData 0.054 (0.100)\tLoss 0.7409 (0.7175)\tAcc 0.812 (0.703)\n",
      "Epoch: [9][9/12]\tTime 0.077 (0.121)\tData 0.053 (0.095)\tLoss 0.6453 (0.7095)\tAcc 0.750 (0.708)\n",
      "Epoch: [9][10/12]\tTime 0.080 (0.117)\tData 0.056 (0.091)\tLoss 0.8369 (0.7223)\tAcc 0.562 (0.694)\n",
      "Epoch: [9][11/12]\tTime 0.079 (0.114)\tData 0.055 (0.088)\tLoss 0.6870 (0.7190)\tAcc 0.750 (0.699)\n",
      "Epoch: [9][12/12]\tTime 0.080 (0.111)\tData 0.055 (0.085)\tLoss 0.8613 (0.7302)\tAcc 0.533 (0.686)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/18]\tTime 0.222 (0.222)\tData 0.194 (0.194)\tLoss 0.3567 (0.3567)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/18]\tTime 0.073 (0.148)\tData 0.048 (0.121)\tLoss 1.0319 (0.6943)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/18]\tTime 0.070 (0.122)\tData 0.049 (0.097)\tLoss 0.6861 (0.6916)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/18]\tTime 0.075 (0.110)\tData 0.055 (0.086)\tLoss 0.7137 (0.6971)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/18]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 0.8244 (0.7226)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/18]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.3662 (0.6632)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/18]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.6922 (0.6673)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/18]\tTime 0.077 (0.093)\tData 0.056 (0.071)\tLoss 1.0777 (0.7186)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/18]\tTime 0.075 (0.091)\tData 0.054 (0.069)\tLoss 0.1369 (0.6540)\tAcc 1.000 (0.757)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][10/18]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 1.2583 (0.7144)\tAcc 0.375 (0.719)\n",
      "Epoch: [9][11/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 1.3406 (0.7713)\tAcc 0.375 (0.688)\n",
      "Epoch: [9][12/18]\tTime 0.075 (0.087)\tData 0.056 (0.065)\tLoss 1.0246 (0.7925)\tAcc 0.562 (0.677)\n",
      "Epoch: [9][13/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 1.1876 (0.8229)\tAcc 0.312 (0.649)\n",
      "Epoch: [9][14/18]\tTime 0.074 (0.085)\tData 0.055 (0.064)\tLoss 0.8683 (0.8261)\tAcc 0.625 (0.647)\n",
      "Epoch: [9][15/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.9782 (0.8362)\tAcc 0.625 (0.646)\n",
      "Epoch: [9][16/18]\tTime 0.076 (0.084)\tData 0.056 (0.063)\tLoss 0.9663 (0.8444)\tAcc 0.625 (0.645)\n",
      "Epoch: [9][17/18]\tTime 0.075 (0.083)\tData 0.055 (0.062)\tLoss 0.8191 (0.8429)\tAcc 0.625 (0.643)\n",
      "Epoch: [9][18/18]\tTime 0.076 (0.083)\tData 0.056 (0.062)\tLoss 0.8086 (0.8419)\tAcc 0.625 (0.643)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/12]\tTime 0.296 (0.296)\tData 0.265 (0.265)\tLoss 0.7322 (0.7322)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][2/12]\tTime 0.081 (0.189)\tData 0.055 (0.160)\tLoss 0.8709 (0.8016)\tAcc 0.562 (0.625)\n",
      "Epoch: [10][3/12]\tTime 0.079 (0.152)\tData 0.054 (0.125)\tLoss 0.5743 (0.7258)\tAcc 0.812 (0.688)\n",
      "Epoch: [10][4/12]\tTime 0.080 (0.134)\tData 0.054 (0.107)\tLoss 0.8313 (0.7522)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/12]\tTime 0.080 (0.123)\tData 0.053 (0.096)\tLoss 0.5807 (0.7179)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/12]\tTime 0.078 (0.116)\tData 0.053 (0.089)\tLoss 1.0854 (0.7791)\tAcc 0.500 (0.656)\n",
      "Epoch: [10][7/12]\tTime 0.080 (0.111)\tData 0.055 (0.084)\tLoss 0.5484 (0.7462)\tAcc 0.812 (0.679)\n",
      "Epoch: [10][8/12]\tTime 0.081 (0.107)\tData 0.054 (0.080)\tLoss 0.5925 (0.7270)\tAcc 0.812 (0.695)\n",
      "Epoch: [10][9/12]\tTime 0.080 (0.104)\tData 0.053 (0.077)\tLoss 0.4662 (0.6980)\tAcc 0.875 (0.715)\n",
      "Epoch: [10][10/12]\tTime 0.078 (0.101)\tData 0.053 (0.075)\tLoss 0.7922 (0.7074)\tAcc 0.562 (0.700)\n",
      "Epoch: [10][11/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.8932 (0.7243)\tAcc 0.500 (0.682)\n",
      "Epoch: [10][12/12]\tTime 0.081 (0.098)\tData 0.057 (0.072)\tLoss 0.6149 (0.7157)\tAcc 0.867 (0.696)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/18]\tTime 0.228 (0.228)\tData 0.201 (0.201)\tLoss 0.4412 (0.4412)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/18]\tTime 0.073 (0.151)\tData 0.049 (0.125)\tLoss 0.9731 (0.7072)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/18]\tTime 0.073 (0.125)\tData 0.052 (0.101)\tLoss 0.6378 (0.6840)\tAcc 0.750 (0.708)\n",
      "Epoch: [10][4/18]\tTime 0.074 (0.112)\tData 0.055 (0.089)\tLoss 0.6955 (0.6869)\tAcc 0.688 (0.703)\n",
      "Epoch: [10][5/18]\tTime 0.076 (0.105)\tData 0.056 (0.083)\tLoss 0.7528 (0.7001)\tAcc 0.688 (0.700)\n",
      "Epoch: [10][6/18]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.4095 (0.6517)\tAcc 1.000 (0.750)\n",
      "Epoch: [10][7/18]\tTime 0.076 (0.097)\tData 0.056 (0.075)\tLoss 0.6826 (0.6561)\tAcc 0.750 (0.750)\n",
      "Epoch: [10][8/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.9894 (0.6977)\tAcc 0.562 (0.727)\n",
      "Epoch: [10][9/18]\tTime 0.076 (0.092)\tData 0.056 (0.070)\tLoss 0.1502 (0.6369)\tAcc 1.000 (0.757)\n",
      "Epoch: [10][10/18]\tTime 0.075 (0.090)\tData 0.055 (0.069)\tLoss 1.2184 (0.6950)\tAcc 0.375 (0.719)\n",
      "Epoch: [10][11/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 1.1551 (0.7369)\tAcc 0.375 (0.688)\n",
      "Epoch: [10][12/18]\tTime 0.075 (0.088)\tData 0.055 (0.067)\tLoss 1.0065 (0.7593)\tAcc 0.562 (0.677)\n",
      "Epoch: [10][13/18]\tTime 0.075 (0.087)\tData 0.056 (0.066)\tLoss 1.1922 (0.7926)\tAcc 0.375 (0.654)\n",
      "Epoch: [10][14/18]\tTime 0.075 (0.086)\tData 0.056 (0.065)\tLoss 0.7909 (0.7925)\tAcc 0.625 (0.652)\n",
      "Epoch: [10][15/18]\tTime 0.076 (0.085)\tData 0.057 (0.065)\tLoss 0.9195 (0.8010)\tAcc 0.750 (0.658)\n",
      "Epoch: [10][16/18]\tTime 0.075 (0.085)\tData 0.056 (0.064)\tLoss 0.9043 (0.8074)\tAcc 0.625 (0.656)\n",
      "Epoch: [10][17/18]\tTime 0.075 (0.084)\tData 0.055 (0.064)\tLoss 0.9654 (0.8167)\tAcc 0.625 (0.654)\n",
      "Epoch: [10][18/18]\tTime 0.076 (0.083)\tData 0.057 (0.063)\tLoss 0.8086 (0.8165)\tAcc 0.750 (0.657)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/12]\tTime 0.400 (0.400)\tData 0.367 (0.367)\tLoss 0.8526 (0.8526)\tAcc 0.562 (0.562)\n",
      "Epoch: [11][2/12]\tTime 0.073 (0.236)\tData 0.048 (0.207)\tLoss 0.8753 (0.8639)\tAcc 0.625 (0.594)\n",
      "Epoch: [11][3/12]\tTime 0.079 (0.184)\tData 0.054 (0.156)\tLoss 0.6413 (0.7897)\tAcc 0.750 (0.646)\n",
      "Epoch: [11][4/12]\tTime 0.082 (0.159)\tData 0.056 (0.131)\tLoss 0.7822 (0.7878)\tAcc 0.688 (0.656)\n",
      "Epoch: [11][5/12]\tTime 0.086 (0.144)\tData 0.058 (0.117)\tLoss 0.7952 (0.7893)\tAcc 0.750 (0.675)\n",
      "Epoch: [11][6/12]\tTime 0.093 (0.135)\tData 0.068 (0.109)\tLoss 0.9151 (0.8103)\tAcc 0.688 (0.677)\n",
      "Epoch: [11][7/12]\tTime 0.086 (0.128)\tData 0.060 (0.102)\tLoss 0.6444 (0.7866)\tAcc 0.750 (0.688)\n",
      "Epoch: [11][8/12]\tTime 0.084 (0.123)\tData 0.059 (0.096)\tLoss 0.5436 (0.7562)\tAcc 0.875 (0.711)\n",
      "Epoch: [11][9/12]\tTime 0.084 (0.118)\tData 0.060 (0.092)\tLoss 0.5896 (0.7377)\tAcc 0.812 (0.722)\n",
      "Epoch: [11][10/12]\tTime 0.084 (0.115)\tData 0.060 (0.089)\tLoss 0.7968 (0.7436)\tAcc 0.562 (0.706)\n",
      "Epoch: [11][11/12]\tTime 0.084 (0.112)\tData 0.060 (0.086)\tLoss 1.2164 (0.7866)\tAcc 0.562 (0.693)\n",
      "Epoch: [11][12/12]\tTime 0.084 (0.110)\tData 0.060 (0.084)\tLoss 0.5460 (0.7677)\tAcc 0.867 (0.707)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/18]\tTime 0.228 (0.228)\tData 0.189 (0.189)\tLoss 0.3850 (0.3850)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/18]\tTime 0.064 (0.146)\tData 0.039 (0.114)\tLoss 0.9250 (0.6550)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/18]\tTime 0.073 (0.121)\tData 0.052 (0.094)\tLoss 0.6733 (0.6611)\tAcc 0.812 (0.729)\n",
      "Epoch: [11][4/18]\tTime 0.076 (0.110)\tData 0.055 (0.084)\tLoss 0.6792 (0.6656)\tAcc 0.688 (0.719)\n",
      "Epoch: [11][5/18]\tTime 0.074 (0.103)\tData 0.053 (0.078)\tLoss 0.7773 (0.6880)\tAcc 0.750 (0.725)\n",
      "Epoch: [11][6/18]\tTime 0.076 (0.098)\tData 0.056 (0.074)\tLoss 0.3609 (0.6335)\tAcc 1.000 (0.771)\n",
      "Epoch: [11][7/18]\tTime 0.074 (0.095)\tData 0.054 (0.071)\tLoss 0.7237 (0.6463)\tAcc 0.812 (0.777)\n",
      "Epoch: [11][8/18]\tTime 0.077 (0.093)\tData 0.057 (0.069)\tLoss 1.0751 (0.6999)\tAcc 0.438 (0.734)\n",
      "Epoch: [11][9/18]\tTime 0.075 (0.091)\tData 0.055 (0.068)\tLoss 0.1599 (0.6399)\tAcc 1.000 (0.764)\n",
      "Epoch: [11][10/18]\tTime 0.076 (0.089)\tData 0.056 (0.067)\tLoss 1.2040 (0.6963)\tAcc 0.375 (0.725)\n",
      "Epoch: [11][11/18]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 1.3832 (0.7588)\tAcc 0.375 (0.693)\n",
      "Epoch: [11][12/18]\tTime 0.076 (0.087)\tData 0.056 (0.065)\tLoss 0.8981 (0.7704)\tAcc 0.562 (0.682)\n",
      "Epoch: [11][13/18]\tTime 0.075 (0.086)\tData 0.055 (0.064)\tLoss 1.2164 (0.8047)\tAcc 0.312 (0.654)\n",
      "Epoch: [11][14/18]\tTime 0.076 (0.085)\tData 0.056 (0.063)\tLoss 0.7919 (0.8038)\tAcc 0.625 (0.652)\n",
      "Epoch: [11][15/18]\tTime 0.076 (0.085)\tData 0.056 (0.063)\tLoss 0.8631 (0.8077)\tAcc 0.688 (0.654)\n",
      "Epoch: [11][16/18]\tTime 0.079 (0.084)\tData 0.059 (0.063)\tLoss 0.8180 (0.8084)\tAcc 0.625 (0.652)\n",
      "Epoch: [11][17/18]\tTime 0.081 (0.084)\tData 0.060 (0.063)\tLoss 0.8257 (0.8094)\tAcc 0.625 (0.651)\n",
      "Epoch: [11][18/18]\tTime 0.079 (0.084)\tData 0.059 (0.062)\tLoss 0.7462 (0.8076)\tAcc 0.750 (0.654)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/12]\tTime 0.311 (0.311)\tData 0.281 (0.281)\tLoss 0.5673 (0.5673)\tAcc 0.750 (0.750)\n",
      "Epoch: [12][2/12]\tTime 0.096 (0.203)\tData 0.068 (0.174)\tLoss 0.8408 (0.7040)\tAcc 0.625 (0.688)\n",
      "Epoch: [12][3/12]\tTime 0.081 (0.162)\tData 0.056 (0.135)\tLoss 0.9362 (0.7814)\tAcc 0.562 (0.646)\n",
      "Epoch: [12][4/12]\tTime 0.086 (0.143)\tData 0.059 (0.116)\tLoss 0.4310 (0.6938)\tAcc 0.812 (0.688)\n",
      "Epoch: [12][5/12]\tTime 0.084 (0.131)\tData 0.057 (0.104)\tLoss 0.7001 (0.6951)\tAcc 0.812 (0.713)\n",
      "Epoch: [12][6/12]\tTime 0.079 (0.123)\tData 0.054 (0.096)\tLoss 0.9737 (0.7415)\tAcc 0.500 (0.677)\n",
      "Epoch: [12][7/12]\tTime 0.081 (0.117)\tData 0.055 (0.090)\tLoss 0.8391 (0.7554)\tAcc 0.562 (0.661)\n",
      "Epoch: [12][8/12]\tTime 0.081 (0.112)\tData 0.055 (0.086)\tLoss 0.6706 (0.7448)\tAcc 0.812 (0.680)\n",
      "Epoch: [12][9/12]\tTime 0.084 (0.109)\tData 0.059 (0.083)\tLoss 0.6277 (0.7318)\tAcc 0.812 (0.694)\n",
      "Epoch: [12][10/12]\tTime 0.084 (0.107)\tData 0.060 (0.080)\tLoss 1.1795 (0.7766)\tAcc 0.500 (0.675)\n",
      "Epoch: [12][11/12]\tTime 0.084 (0.105)\tData 0.060 (0.078)\tLoss 0.6614 (0.7661)\tAcc 0.688 (0.676)\n",
      "Epoch: [12][12/12]\tTime 0.084 (0.103)\tData 0.060 (0.077)\tLoss 0.5999 (0.7531)\tAcc 0.733 (0.681)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/18]\tTime 0.218 (0.218)\tData 0.191 (0.191)\tLoss 0.4048 (0.4048)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/18]\tTime 0.079 (0.149)\tData 0.053 (0.122)\tLoss 0.9651 (0.6849)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/18]\tTime 0.074 (0.124)\tData 0.053 (0.099)\tLoss 0.6453 (0.6717)\tAcc 0.812 (0.729)\n",
      "Epoch: [12][4/18]\tTime 0.079 (0.113)\tData 0.059 (0.089)\tLoss 0.6375 (0.6632)\tAcc 0.625 (0.703)\n",
      "Epoch: [12][5/18]\tTime 0.080 (0.106)\tData 0.060 (0.083)\tLoss 0.8217 (0.6949)\tAcc 0.688 (0.700)\n",
      "Epoch: [12][6/18]\tTime 0.079 (0.102)\tData 0.058 (0.079)\tLoss 0.4202 (0.6491)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][7/18]\tTime 0.077 (0.098)\tData 0.056 (0.076)\tLoss 0.7297 (0.6606)\tAcc 0.875 (0.768)\n",
      "Epoch: [12][8/18]\tTime 0.079 (0.096)\tData 0.058 (0.073)\tLoss 1.0744 (0.7123)\tAcc 0.562 (0.742)\n",
      "Epoch: [12][9/18]\tTime 0.076 (0.094)\tData 0.055 (0.071)\tLoss 0.1978 (0.6552)\tAcc 1.000 (0.771)\n",
      "Epoch: [12][10/18]\tTime 0.076 (0.092)\tData 0.055 (0.070)\tLoss 1.0666 (0.6963)\tAcc 0.500 (0.744)\n",
      "Epoch: [12][11/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 1.2148 (0.7434)\tAcc 0.375 (0.710)\n",
      "Epoch: [12][12/18]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 0.8845 (0.7552)\tAcc 0.750 (0.714)\n",
      "Epoch: [12][13/18]\tTime 0.077 (0.088)\tData 0.057 (0.066)\tLoss 1.1070 (0.7823)\tAcc 0.375 (0.688)\n",
      "Epoch: [12][14/18]\tTime 0.078 (0.087)\tData 0.058 (0.066)\tLoss 0.7811 (0.7822)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][15/18]\tTime 0.076 (0.087)\tData 0.056 (0.065)\tLoss 0.9447 (0.7930)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][16/18]\tTime 0.076 (0.086)\tData 0.056 (0.065)\tLoss 0.7974 (0.7933)\tAcc 0.562 (0.680)\n",
      "Epoch: [12][17/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.9251 (0.8010)\tAcc 0.625 (0.676)\n",
      "Epoch: [12][18/18]\tTime 0.076 (0.085)\tData 0.056 (0.064)\tLoss 0.8428 (0.8022)\tAcc 0.875 (0.682)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/12]\tTime 0.299 (0.299)\tData 0.266 (0.266)\tLoss 0.5957 (0.5957)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][2/12]\tTime 0.074 (0.186)\tData 0.049 (0.158)\tLoss 0.7520 (0.6739)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][3/12]\tTime 0.080 (0.151)\tData 0.055 (0.124)\tLoss 0.5291 (0.6256)\tAcc 0.812 (0.729)\n",
      "Epoch: [13][4/12]\tTime 0.084 (0.134)\tData 0.056 (0.107)\tLoss 0.5508 (0.6069)\tAcc 0.812 (0.750)\n",
      "Epoch: [13][5/12]\tTime 0.076 (0.123)\tData 0.051 (0.096)\tLoss 0.6310 (0.6117)\tAcc 0.688 (0.738)\n",
      "Epoch: [13][6/12]\tTime 0.080 (0.116)\tData 0.055 (0.089)\tLoss 0.7065 (0.6275)\tAcc 0.750 (0.740)\n",
      "Epoch: [13][7/12]\tTime 0.085 (0.111)\tData 0.057 (0.084)\tLoss 1.2522 (0.7168)\tAcc 0.375 (0.688)\n",
      "Epoch: [13][8/12]\tTime 0.079 (0.107)\tData 0.053 (0.080)\tLoss 0.7187 (0.7170)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][9/12]\tTime 0.086 (0.105)\tData 0.061 (0.078)\tLoss 0.5380 (0.6971)\tAcc 0.812 (0.701)\n",
      "Epoch: [13][10/12]\tTime 0.084 (0.103)\tData 0.059 (0.076)\tLoss 0.6359 (0.6910)\tAcc 0.812 (0.713)\n",
      "Epoch: [13][11/12]\tTime 0.085 (0.101)\tData 0.060 (0.075)\tLoss 0.5527 (0.6784)\tAcc 0.812 (0.722)\n",
      "Epoch: [13][12/12]\tTime 0.084 (0.100)\tData 0.059 (0.074)\tLoss 0.9154 (0.6970)\tAcc 0.467 (0.702)\n",
      "validation at epoch 13\n",
      "Epoch: [13][1/18]\tTime 0.232 (0.232)\tData 0.194 (0.194)\tLoss 0.3922 (0.3922)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/18]\tTime 0.065 (0.149)\tData 0.042 (0.118)\tLoss 0.9419 (0.6671)\tAcc 0.500 (0.719)\n",
      "Epoch: [13][3/18]\tTime 0.078 (0.125)\tData 0.058 (0.098)\tLoss 0.6697 (0.6679)\tAcc 0.688 (0.708)\n",
      "Epoch: [13][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.088)\tLoss 0.6963 (0.6750)\tAcc 0.625 (0.688)\n",
      "Epoch: [13][5/18]\tTime 0.079 (0.107)\tData 0.059 (0.082)\tLoss 0.8492 (0.7099)\tAcc 0.625 (0.675)\n",
      "Epoch: [13][6/18]\tTime 0.081 (0.103)\tData 0.061 (0.079)\tLoss 0.3617 (0.6518)\tAcc 1.000 (0.729)\n",
      "Epoch: [13][7/18]\tTime 0.075 (0.099)\tData 0.055 (0.075)\tLoss 0.6376 (0.6498)\tAcc 0.812 (0.741)\n",
      "Epoch: [13][8/18]\tTime 0.075 (0.096)\tData 0.055 (0.073)\tLoss 1.0456 (0.6993)\tAcc 0.625 (0.727)\n",
      "Epoch: [13][9/18]\tTime 0.076 (0.094)\tData 0.056 (0.071)\tLoss 0.1709 (0.6406)\tAcc 1.000 (0.757)\n",
      "Epoch: [13][10/18]\tTime 0.075 (0.092)\tData 0.055 (0.069)\tLoss 1.1093 (0.6874)\tAcc 0.562 (0.738)\n",
      "Epoch: [13][11/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 1.3935 (0.7516)\tAcc 0.375 (0.705)\n",
      "Epoch: [13][12/18]\tTime 0.076 (0.089)\tData 0.056 (0.067)\tLoss 0.9219 (0.7658)\tAcc 0.625 (0.698)\n",
      "Epoch: [13][13/18]\tTime 0.077 (0.088)\tData 0.057 (0.066)\tLoss 1.0935 (0.7910)\tAcc 0.562 (0.688)\n",
      "Epoch: [13][14/18]\tTime 0.075 (0.087)\tData 0.056 (0.066)\tLoss 0.8258 (0.7935)\tAcc 0.562 (0.679)\n",
      "Epoch: [13][15/18]\tTime 0.076 (0.086)\tData 0.057 (0.065)\tLoss 0.9766 (0.8057)\tAcc 0.625 (0.675)\n",
      "Epoch: [13][16/18]\tTime 0.075 (0.086)\tData 0.056 (0.065)\tLoss 0.8410 (0.8079)\tAcc 0.750 (0.680)\n",
      "Epoch: [13][17/18]\tTime 0.076 (0.085)\tData 0.056 (0.064)\tLoss 0.7928 (0.8070)\tAcc 0.625 (0.676)\n",
      "Epoch: [13][18/18]\tTime 0.075 (0.085)\tData 0.056 (0.064)\tLoss 0.9013 (0.8097)\tAcc 0.625 (0.675)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/12]\tTime 0.341 (0.341)\tData 0.310 (0.310)\tLoss 0.7214 (0.7214)\tAcc 0.750 (0.750)\n",
      "Epoch: [14][2/12]\tTime 0.079 (0.210)\tData 0.054 (0.182)\tLoss 0.7293 (0.7254)\tAcc 0.812 (0.781)\n",
      "Epoch: [14][3/12]\tTime 0.084 (0.168)\tData 0.060 (0.141)\tLoss 0.7209 (0.7239)\tAcc 0.750 (0.771)\n",
      "Epoch: [14][4/12]\tTime 0.086 (0.148)\tData 0.060 (0.121)\tLoss 0.5354 (0.6768)\tAcc 0.750 (0.766)\n",
      "Epoch: [14][5/12]\tTime 0.131 (0.144)\tData 0.107 (0.118)\tLoss 0.8944 (0.7203)\tAcc 0.562 (0.725)\n",
      "Epoch: [14][6/12]\tTime 0.085 (0.135)\tData 0.060 (0.109)\tLoss 0.8957 (0.7495)\tAcc 0.500 (0.688)\n",
      "Epoch: [14][7/12]\tTime 0.084 (0.127)\tData 0.060 (0.102)\tLoss 0.6815 (0.7398)\tAcc 0.812 (0.705)\n",
      "Epoch: [14][8/12]\tTime 0.084 (0.122)\tData 0.060 (0.096)\tLoss 0.6064 (0.7231)\tAcc 0.750 (0.711)\n",
      "Epoch: [14][9/12]\tTime 0.084 (0.118)\tData 0.060 (0.092)\tLoss 0.6480 (0.7148)\tAcc 0.750 (0.715)\n",
      "Epoch: [14][10/12]\tTime 0.086 (0.115)\tData 0.062 (0.089)\tLoss 0.6216 (0.7054)\tAcc 0.812 (0.725)\n",
      "Epoch: [14][11/12]\tTime 0.091 (0.112)\tData 0.067 (0.087)\tLoss 0.5782 (0.6939)\tAcc 0.750 (0.727)\n",
      "Epoch: [14][12/12]\tTime 0.090 (0.111)\tData 0.065 (0.085)\tLoss 0.5163 (0.6799)\tAcc 0.800 (0.733)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/18]\tTime 0.217 (0.217)\tData 0.190 (0.190)\tLoss 0.3594 (0.3594)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/18]\tTime 0.070 (0.143)\tData 0.048 (0.119)\tLoss 0.8318 (0.5956)\tAcc 0.500 (0.719)\n",
      "Epoch: [14][3/18]\tTime 0.074 (0.120)\tData 0.053 (0.097)\tLoss 0.6364 (0.6092)\tAcc 0.812 (0.750)\n",
      "Epoch: [14][4/18]\tTime 0.074 (0.109)\tData 0.054 (0.086)\tLoss 0.6208 (0.6121)\tAcc 0.688 (0.734)\n",
      "Epoch: [14][5/18]\tTime 0.076 (0.102)\tData 0.056 (0.080)\tLoss 0.8571 (0.6611)\tAcc 0.688 (0.725)\n",
      "Epoch: [14][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.3844 (0.6150)\tAcc 1.000 (0.771)\n",
      "Epoch: [14][7/18]\tTime 0.075 (0.094)\tData 0.055 (0.073)\tLoss 0.7146 (0.6292)\tAcc 0.688 (0.759)\n",
      "Epoch: [14][8/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 0.9825 (0.6734)\tAcc 0.688 (0.750)\n",
      "Epoch: [14][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.068)\tLoss 0.1746 (0.6179)\tAcc 1.000 (0.778)\n",
      "Epoch: [14][10/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 1.1505 (0.6712)\tAcc 0.625 (0.762)\n",
      "Epoch: [14][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.2561 (0.7244)\tAcc 0.375 (0.727)\n",
      "Epoch: [14][12/18]\tTime 0.076 (0.086)\tData 0.056 (0.065)\tLoss 0.9207 (0.7407)\tAcc 0.688 (0.724)\n",
      "Epoch: [14][13/18]\tTime 0.084 (0.086)\tData 0.061 (0.065)\tLoss 1.1021 (0.7685)\tAcc 0.500 (0.707)\n",
      "Epoch: [14][14/18]\tTime 0.076 (0.085)\tData 0.056 (0.064)\tLoss 0.8965 (0.7777)\tAcc 0.562 (0.696)\n",
      "Epoch: [14][15/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.8574 (0.7830)\tAcc 0.750 (0.700)\n",
      "Epoch: [14][16/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.8804 (0.7891)\tAcc 0.688 (0.699)\n",
      "Epoch: [14][17/18]\tTime 0.073 (0.083)\tData 0.053 (0.063)\tLoss 0.8260 (0.7912)\tAcc 0.625 (0.695)\n",
      "Epoch: [14][18/18]\tTime 0.073 (0.083)\tData 0.053 (0.062)\tLoss 0.8554 (0.7931)\tAcc 0.750 (0.696)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/12]\tTime 0.367 (0.367)\tData 0.337 (0.337)\tLoss 0.6182 (0.6182)\tAcc 0.812 (0.812)\n",
      "Epoch: [15][2/12]\tTime 0.082 (0.225)\tData 0.055 (0.196)\tLoss 0.3770 (0.4976)\tAcc 1.000 (0.906)\n",
      "Epoch: [15][3/12]\tTime 0.082 (0.177)\tData 0.057 (0.149)\tLoss 0.8285 (0.6079)\tAcc 0.562 (0.792)\n",
      "Epoch: [15][4/12]\tTime 0.083 (0.154)\tData 0.058 (0.127)\tLoss 0.5107 (0.5836)\tAcc 0.812 (0.797)\n",
      "Epoch: [15][5/12]\tTime 0.084 (0.140)\tData 0.059 (0.113)\tLoss 0.8715 (0.6412)\tAcc 0.562 (0.750)\n",
      "Epoch: [15][6/12]\tTime 0.084 (0.130)\tData 0.059 (0.104)\tLoss 1.3126 (0.7531)\tAcc 0.438 (0.698)\n",
      "Epoch: [15][7/12]\tTime 0.083 (0.124)\tData 0.059 (0.098)\tLoss 0.7272 (0.7494)\tAcc 0.688 (0.696)\n",
      "Epoch: [15][8/12]\tTime 0.084 (0.119)\tData 0.059 (0.093)\tLoss 1.0318 (0.7847)\tAcc 0.688 (0.695)\n",
      "Epoch: [15][9/12]\tTime 0.078 (0.114)\tData 0.055 (0.089)\tLoss 0.6075 (0.7650)\tAcc 0.750 (0.701)\n",
      "Epoch: [15][10/12]\tTime 0.081 (0.111)\tData 0.056 (0.085)\tLoss 0.5228 (0.7408)\tAcc 0.750 (0.706)\n",
      "Epoch: [15][11/12]\tTime 0.081 (0.108)\tData 0.057 (0.083)\tLoss 0.7451 (0.7412)\tAcc 0.688 (0.705)\n",
      "Epoch: [15][12/12]\tTime 0.080 (0.106)\tData 0.056 (0.081)\tLoss 0.6459 (0.7337)\tAcc 0.800 (0.712)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/18]\tTime 0.230 (0.230)\tData 0.191 (0.191)\tLoss 0.3683 (0.3683)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/18]\tTime 0.060 (0.145)\tData 0.038 (0.115)\tLoss 1.0009 (0.6846)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/18]\tTime 0.076 (0.122)\tData 0.055 (0.095)\tLoss 0.6057 (0.6583)\tAcc 0.875 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][4/18]\tTime 0.074 (0.110)\tData 0.053 (0.084)\tLoss 0.6763 (0.6628)\tAcc 0.625 (0.719)\n",
      "Epoch: [15][5/18]\tTime 0.074 (0.103)\tData 0.053 (0.078)\tLoss 0.8029 (0.6908)\tAcc 0.688 (0.713)\n",
      "Epoch: [15][6/18]\tTime 0.074 (0.098)\tData 0.053 (0.074)\tLoss 0.3437 (0.6330)\tAcc 1.000 (0.760)\n",
      "Epoch: [15][7/18]\tTime 0.076 (0.095)\tData 0.055 (0.071)\tLoss 0.7224 (0.6457)\tAcc 0.688 (0.750)\n",
      "Epoch: [15][8/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.9239 (0.6805)\tAcc 0.562 (0.727)\n",
      "Epoch: [15][9/18]\tTime 0.078 (0.091)\tData 0.057 (0.068)\tLoss 0.1235 (0.6186)\tAcc 1.000 (0.757)\n",
      "Epoch: [15][10/18]\tTime 0.079 (0.090)\tData 0.059 (0.067)\tLoss 1.1098 (0.6677)\tAcc 0.438 (0.725)\n",
      "Epoch: [15][11/18]\tTime 0.078 (0.089)\tData 0.059 (0.067)\tLoss 1.2641 (0.7220)\tAcc 0.375 (0.693)\n",
      "Epoch: [15][12/18]\tTime 0.078 (0.088)\tData 0.058 (0.066)\tLoss 0.7392 (0.7234)\tAcc 0.625 (0.688)\n",
      "Epoch: [15][13/18]\tTime 0.079 (0.087)\tData 0.060 (0.065)\tLoss 1.0124 (0.7456)\tAcc 0.625 (0.683)\n",
      "Epoch: [15][14/18]\tTime 0.079 (0.087)\tData 0.059 (0.065)\tLoss 0.9319 (0.7589)\tAcc 0.562 (0.674)\n",
      "Epoch: [15][15/18]\tTime 0.079 (0.086)\tData 0.059 (0.065)\tLoss 0.8671 (0.7661)\tAcc 0.688 (0.675)\n",
      "Epoch: [15][16/18]\tTime 0.080 (0.086)\tData 0.060 (0.064)\tLoss 0.8022 (0.7684)\tAcc 0.625 (0.672)\n",
      "Epoch: [15][17/18]\tTime 0.079 (0.085)\tData 0.059 (0.064)\tLoss 0.8097 (0.7708)\tAcc 0.625 (0.669)\n",
      "Epoch: [15][18/18]\tTime 0.078 (0.085)\tData 0.059 (0.064)\tLoss 0.7592 (0.7705)\tAcc 0.625 (0.668)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/12]\tTime 0.380 (0.380)\tData 0.348 (0.348)\tLoss 0.6265 (0.6265)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][2/12]\tTime 0.073 (0.227)\tData 0.048 (0.198)\tLoss 0.8152 (0.7208)\tAcc 0.750 (0.719)\n",
      "Epoch: [16][3/12]\tTime 0.078 (0.177)\tData 0.053 (0.150)\tLoss 0.7978 (0.7465)\tAcc 0.625 (0.688)\n",
      "Epoch: [16][4/12]\tTime 0.078 (0.152)\tData 0.054 (0.126)\tLoss 0.5096 (0.6873)\tAcc 0.750 (0.703)\n",
      "Epoch: [16][5/12]\tTime 0.136 (0.149)\tData 0.111 (0.123)\tLoss 0.6555 (0.6809)\tAcc 0.750 (0.713)\n",
      "Epoch: [16][6/12]\tTime 0.079 (0.137)\tData 0.054 (0.111)\tLoss 0.8452 (0.7083)\tAcc 0.625 (0.698)\n",
      "Epoch: [16][7/12]\tTime 0.078 (0.129)\tData 0.052 (0.103)\tLoss 0.6528 (0.7004)\tAcc 0.875 (0.723)\n",
      "Epoch: [16][8/12]\tTime 0.077 (0.122)\tData 0.053 (0.096)\tLoss 0.7772 (0.7100)\tAcc 0.750 (0.727)\n",
      "Epoch: [16][9/12]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 0.3988 (0.6754)\tAcc 0.875 (0.743)\n",
      "Epoch: [16][10/12]\tTime 0.083 (0.114)\tData 0.059 (0.088)\tLoss 0.5106 (0.6589)\tAcc 0.812 (0.750)\n",
      "Epoch: [16][11/12]\tTime 0.084 (0.111)\tData 0.060 (0.086)\tLoss 0.9430 (0.6847)\tAcc 0.562 (0.733)\n",
      "Epoch: [16][12/12]\tTime 0.084 (0.109)\tData 0.060 (0.084)\tLoss 0.5585 (0.6748)\tAcc 0.667 (0.728)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/18]\tTime 0.230 (0.230)\tData 0.204 (0.204)\tLoss 0.2681 (0.2681)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/18]\tTime 0.081 (0.155)\tData 0.054 (0.129)\tLoss 0.9718 (0.6199)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/18]\tTime 0.073 (0.128)\tData 0.052 (0.104)\tLoss 0.5442 (0.5947)\tAcc 0.875 (0.750)\n",
      "Epoch: [16][4/18]\tTime 0.079 (0.116)\tData 0.059 (0.092)\tLoss 0.5813 (0.5914)\tAcc 0.625 (0.719)\n",
      "Epoch: [16][5/18]\tTime 0.080 (0.109)\tData 0.059 (0.086)\tLoss 0.7691 (0.6269)\tAcc 0.750 (0.725)\n",
      "Epoch: [16][6/18]\tTime 0.077 (0.103)\tData 0.056 (0.081)\tLoss 0.3632 (0.5830)\tAcc 0.938 (0.760)\n",
      "Epoch: [16][7/18]\tTime 0.082 (0.100)\tData 0.058 (0.077)\tLoss 0.6602 (0.5940)\tAcc 0.625 (0.741)\n",
      "Epoch: [16][8/18]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.9736 (0.6414)\tAcc 0.625 (0.727)\n",
      "Epoch: [16][9/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 0.1452 (0.5863)\tAcc 1.000 (0.757)\n",
      "Epoch: [16][10/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.2937 (0.6570)\tAcc 0.500 (0.731)\n",
      "Epoch: [16][11/18]\tTime 0.076 (0.091)\tData 0.057 (0.069)\tLoss 1.3957 (0.7242)\tAcc 0.375 (0.699)\n",
      "Epoch: [16][12/18]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 1.0160 (0.7485)\tAcc 0.688 (0.698)\n",
      "Epoch: [16][13/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1103 (0.7764)\tAcc 0.375 (0.673)\n",
      "Epoch: [16][14/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.9274 (0.7871)\tAcc 0.562 (0.665)\n",
      "Epoch: [16][15/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8565 (0.7918)\tAcc 0.750 (0.671)\n",
      "Epoch: [16][16/18]\tTime 0.074 (0.085)\tData 0.055 (0.065)\tLoss 0.8394 (0.7947)\tAcc 0.688 (0.672)\n",
      "Epoch: [16][17/18]\tTime 0.074 (0.085)\tData 0.055 (0.064)\tLoss 0.8227 (0.7964)\tAcc 0.625 (0.669)\n",
      "Epoch: [16][18/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.8798 (0.7988)\tAcc 0.750 (0.671)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/12]\tTime 0.433 (0.433)\tData 0.404 (0.404)\tLoss 0.6826 (0.6826)\tAcc 0.625 (0.625)\n",
      "Epoch: [17][2/12]\tTime 0.076 (0.254)\tData 0.050 (0.227)\tLoss 0.6746 (0.6786)\tAcc 0.750 (0.688)\n",
      "Epoch: [17][3/12]\tTime 0.080 (0.196)\tData 0.053 (0.169)\tLoss 0.3793 (0.5788)\tAcc 0.938 (0.771)\n",
      "Epoch: [17][4/12]\tTime 0.082 (0.167)\tData 0.057 (0.141)\tLoss 0.5453 (0.5704)\tAcc 0.812 (0.781)\n",
      "Epoch: [17][5/12]\tTime 0.085 (0.151)\tData 0.060 (0.125)\tLoss 0.6557 (0.5875)\tAcc 0.688 (0.762)\n",
      "Epoch: [17][6/12]\tTime 0.091 (0.141)\tData 0.062 (0.114)\tLoss 0.7873 (0.6208)\tAcc 0.750 (0.760)\n",
      "Epoch: [17][7/12]\tTime 0.081 (0.132)\tData 0.056 (0.106)\tLoss 0.6132 (0.6197)\tAcc 0.750 (0.759)\n",
      "Epoch: [17][8/12]\tTime 0.084 (0.126)\tData 0.059 (0.100)\tLoss 1.0826 (0.6776)\tAcc 0.625 (0.742)\n",
      "Epoch: [17][9/12]\tTime 0.082 (0.121)\tData 0.058 (0.095)\tLoss 0.7975 (0.6909)\tAcc 0.688 (0.736)\n",
      "Epoch: [17][10/12]\tTime 0.083 (0.118)\tData 0.058 (0.092)\tLoss 0.8266 (0.7045)\tAcc 0.688 (0.731)\n",
      "Epoch: [17][11/12]\tTime 0.082 (0.114)\tData 0.058 (0.089)\tLoss 0.7866 (0.7119)\tAcc 0.688 (0.727)\n",
      "Epoch: [17][12/12]\tTime 0.084 (0.112)\tData 0.059 (0.086)\tLoss 0.6600 (0.7078)\tAcc 0.800 (0.733)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/18]\tTime 0.221 (0.221)\tData 0.193 (0.193)\tLoss 0.3010 (0.3010)\tAcc 0.875 (0.875)\n",
      "Epoch: [17][2/18]\tTime 0.077 (0.149)\tData 0.053 (0.123)\tLoss 0.8894 (0.5952)\tAcc 0.562 (0.719)\n",
      "Epoch: [17][3/18]\tTime 0.075 (0.124)\tData 0.055 (0.100)\tLoss 0.5710 (0.5871)\tAcc 0.875 (0.771)\n",
      "Epoch: [17][4/18]\tTime 0.078 (0.113)\tData 0.058 (0.090)\tLoss 0.6070 (0.5921)\tAcc 0.625 (0.734)\n",
      "Epoch: [17][5/18]\tTime 0.079 (0.106)\tData 0.058 (0.083)\tLoss 0.7705 (0.6278)\tAcc 0.688 (0.725)\n",
      "Epoch: [17][6/18]\tTime 0.074 (0.101)\tData 0.054 (0.078)\tLoss 0.3600 (0.5832)\tAcc 0.938 (0.760)\n",
      "Epoch: [17][7/18]\tTime 0.074 (0.097)\tData 0.053 (0.075)\tLoss 0.7325 (0.6045)\tAcc 0.750 (0.759)\n",
      "Epoch: [17][8/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.9963 (0.6535)\tAcc 0.625 (0.742)\n",
      "Epoch: [17][9/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 0.1592 (0.5985)\tAcc 1.000 (0.771)\n",
      "Epoch: [17][10/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.1869 (0.6574)\tAcc 0.625 (0.756)\n",
      "Epoch: [17][11/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 1.2532 (0.7116)\tAcc 0.375 (0.722)\n",
      "Epoch: [17][12/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.9343 (0.7301)\tAcc 0.750 (0.724)\n",
      "Epoch: [17][13/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 1.1148 (0.7597)\tAcc 0.562 (0.712)\n",
      "Epoch: [17][14/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.8716 (0.7677)\tAcc 0.625 (0.705)\n",
      "Epoch: [17][15/18]\tTime 0.078 (0.085)\tData 0.059 (0.064)\tLoss 0.8514 (0.7733)\tAcc 0.750 (0.708)\n",
      "Epoch: [17][16/18]\tTime 0.076 (0.084)\tData 0.056 (0.063)\tLoss 0.8543 (0.7783)\tAcc 0.688 (0.707)\n",
      "Epoch: [17][17/18]\tTime 0.077 (0.084)\tData 0.058 (0.063)\tLoss 0.7976 (0.7795)\tAcc 0.625 (0.702)\n",
      "Epoch: [17][18/18]\tTime 0.074 (0.083)\tData 0.054 (0.063)\tLoss 1.1033 (0.7887)\tAcc 0.625 (0.700)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/12]\tTime 0.332 (0.332)\tData 0.303 (0.303)\tLoss 0.8294 (0.8294)\tAcc 0.750 (0.750)\n",
      "Epoch: [18][2/12]\tTime 0.080 (0.206)\tData 0.055 (0.179)\tLoss 0.8721 (0.8508)\tAcc 0.562 (0.656)\n",
      "Epoch: [18][3/12]\tTime 0.084 (0.166)\tData 0.059 (0.139)\tLoss 0.5657 (0.7558)\tAcc 0.812 (0.708)\n",
      "Epoch: [18][4/12]\tTime 0.084 (0.145)\tData 0.059 (0.119)\tLoss 0.6840 (0.7378)\tAcc 0.750 (0.719)\n",
      "Epoch: [18][5/12]\tTime 0.089 (0.134)\tData 0.065 (0.108)\tLoss 0.5537 (0.7010)\tAcc 0.812 (0.738)\n",
      "Epoch: [18][6/12]\tTime 0.092 (0.127)\tData 0.067 (0.101)\tLoss 0.7855 (0.7151)\tAcc 0.750 (0.740)\n",
      "Epoch: [18][7/12]\tTime 0.089 (0.122)\tData 0.062 (0.096)\tLoss 0.5820 (0.6961)\tAcc 0.688 (0.732)\n",
      "Epoch: [18][8/12]\tTime 0.080 (0.116)\tData 0.056 (0.091)\tLoss 0.4315 (0.6630)\tAcc 0.812 (0.742)\n",
      "Epoch: [18][9/12]\tTime 0.083 (0.113)\tData 0.059 (0.087)\tLoss 0.6336 (0.6597)\tAcc 0.812 (0.750)\n",
      "Epoch: [18][10/12]\tTime 0.082 (0.110)\tData 0.059 (0.084)\tLoss 0.7125 (0.6650)\tAcc 0.688 (0.744)\n",
      "Epoch: [18][11/12]\tTime 0.079 (0.107)\tData 0.055 (0.082)\tLoss 0.6636 (0.6649)\tAcc 0.625 (0.733)\n",
      "Epoch: [18][12/12]\tTime 0.077 (0.104)\tData 0.054 (0.079)\tLoss 0.7877 (0.6745)\tAcc 0.667 (0.728)\n",
      "validation at epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][1/18]\tTime 0.221 (0.221)\tData 0.196 (0.196)\tLoss 0.3449 (0.3449)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/18]\tTime 0.077 (0.149)\tData 0.050 (0.123)\tLoss 0.9080 (0.6265)\tAcc 0.500 (0.719)\n",
      "Epoch: [18][3/18]\tTime 0.069 (0.122)\tData 0.049 (0.099)\tLoss 0.6052 (0.6194)\tAcc 0.812 (0.750)\n",
      "Epoch: [18][4/18]\tTime 0.075 (0.110)\tData 0.055 (0.088)\tLoss 0.5915 (0.6124)\tAcc 0.625 (0.719)\n",
      "Epoch: [18][5/18]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 0.8342 (0.6568)\tAcc 0.688 (0.713)\n",
      "Epoch: [18][6/18]\tTime 0.081 (0.100)\tData 0.059 (0.077)\tLoss 0.3669 (0.6084)\tAcc 1.000 (0.760)\n",
      "Epoch: [18][7/18]\tTime 0.079 (0.097)\tData 0.057 (0.074)\tLoss 0.7168 (0.6239)\tAcc 0.688 (0.750)\n",
      "Epoch: [18][8/18]\tTime 0.079 (0.094)\tData 0.057 (0.072)\tLoss 0.9537 (0.6652)\tAcc 0.688 (0.742)\n",
      "Epoch: [18][9/18]\tTime 0.085 (0.093)\tData 0.057 (0.070)\tLoss 0.0899 (0.6012)\tAcc 1.000 (0.771)\n",
      "Epoch: [18][10/18]\tTime 0.076 (0.092)\tData 0.056 (0.069)\tLoss 1.0398 (0.6451)\tAcc 0.562 (0.750)\n",
      "Epoch: [18][11/18]\tTime 0.079 (0.090)\tData 0.059 (0.068)\tLoss 1.2593 (0.7009)\tAcc 0.375 (0.716)\n",
      "Epoch: [18][12/18]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 0.8205 (0.7109)\tAcc 0.812 (0.724)\n",
      "Epoch: [18][13/18]\tTime 0.077 (0.088)\tData 0.058 (0.066)\tLoss 1.2081 (0.7491)\tAcc 0.562 (0.712)\n",
      "Epoch: [18][14/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.9149 (0.7610)\tAcc 0.625 (0.705)\n",
      "Epoch: [18][15/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.9228 (0.7718)\tAcc 0.688 (0.704)\n",
      "Epoch: [18][16/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.9666 (0.7839)\tAcc 0.562 (0.695)\n",
      "Epoch: [18][17/18]\tTime 0.074 (0.085)\tData 0.055 (0.063)\tLoss 0.8037 (0.7851)\tAcc 0.625 (0.691)\n",
      "Epoch: [18][18/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.8191 (0.7861)\tAcc 0.875 (0.696)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/12]\tTime 0.409 (0.409)\tData 0.374 (0.374)\tLoss 0.5604 (0.5604)\tAcc 0.875 (0.875)\n",
      "Epoch: [19][2/12]\tTime 0.070 (0.240)\tData 0.044 (0.209)\tLoss 0.5363 (0.5484)\tAcc 0.750 (0.812)\n",
      "Epoch: [19][3/12]\tTime 0.079 (0.186)\tData 0.053 (0.157)\tLoss 0.6632 (0.5866)\tAcc 0.688 (0.771)\n",
      "Epoch: [19][4/12]\tTime 0.081 (0.160)\tData 0.055 (0.132)\tLoss 0.5631 (0.5807)\tAcc 0.812 (0.781)\n",
      "Epoch: [19][5/12]\tTime 0.084 (0.145)\tData 0.058 (0.117)\tLoss 0.7625 (0.6171)\tAcc 0.625 (0.750)\n",
      "Epoch: [19][6/12]\tTime 0.083 (0.134)\tData 0.057 (0.107)\tLoss 0.6344 (0.6200)\tAcc 0.750 (0.750)\n",
      "Epoch: [19][7/12]\tTime 0.080 (0.127)\tData 0.054 (0.099)\tLoss 0.9341 (0.6649)\tAcc 0.625 (0.732)\n",
      "Epoch: [19][8/12]\tTime 0.079 (0.121)\tData 0.055 (0.094)\tLoss 0.7259 (0.6725)\tAcc 0.750 (0.734)\n",
      "Epoch: [19][9/12]\tTime 0.083 (0.116)\tData 0.058 (0.090)\tLoss 0.5696 (0.6611)\tAcc 0.688 (0.729)\n",
      "Epoch: [19][10/12]\tTime 0.085 (0.113)\tData 0.059 (0.087)\tLoss 0.6037 (0.6553)\tAcc 0.688 (0.725)\n",
      "Epoch: [19][11/12]\tTime 0.085 (0.111)\tData 0.058 (0.084)\tLoss 1.3991 (0.7229)\tAcc 0.562 (0.710)\n",
      "Epoch: [19][12/12]\tTime 0.082 (0.108)\tData 0.057 (0.082)\tLoss 0.4118 (0.6985)\tAcc 0.867 (0.723)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/18]\tTime 0.332 (0.332)\tData 0.297 (0.297)\tLoss 0.2816 (0.2816)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/18]\tTime 0.067 (0.199)\tData 0.042 (0.169)\tLoss 0.9373 (0.6095)\tAcc 0.500 (0.719)\n",
      "Epoch: [19][3/18]\tTime 0.071 (0.157)\tData 0.050 (0.130)\tLoss 0.6079 (0.6089)\tAcc 0.750 (0.729)\n",
      "Epoch: [19][4/18]\tTime 0.075 (0.136)\tData 0.055 (0.111)\tLoss 0.5861 (0.6032)\tAcc 0.688 (0.719)\n",
      "Epoch: [19][5/18]\tTime 0.075 (0.124)\tData 0.054 (0.100)\tLoss 0.6759 (0.6178)\tAcc 0.750 (0.725)\n",
      "Epoch: [19][6/18]\tTime 0.075 (0.116)\tData 0.055 (0.092)\tLoss 0.3115 (0.5667)\tAcc 1.000 (0.771)\n",
      "Epoch: [19][7/18]\tTime 0.074 (0.110)\tData 0.054 (0.087)\tLoss 0.5909 (0.5702)\tAcc 0.750 (0.768)\n",
      "Epoch: [19][8/18]\tTime 0.075 (0.105)\tData 0.054 (0.083)\tLoss 0.9701 (0.6202)\tAcc 0.562 (0.742)\n",
      "Epoch: [19][9/18]\tTime 0.076 (0.102)\tData 0.056 (0.080)\tLoss 0.1253 (0.5652)\tAcc 1.000 (0.771)\n",
      "Epoch: [19][10/18]\tTime 0.076 (0.100)\tData 0.056 (0.077)\tLoss 1.2221 (0.6309)\tAcc 0.562 (0.750)\n",
      "Epoch: [19][11/18]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 1.2046 (0.6830)\tAcc 0.375 (0.716)\n",
      "Epoch: [19][12/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.8631 (0.6980)\tAcc 0.750 (0.719)\n",
      "Epoch: [19][13/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 1.2127 (0.7376)\tAcc 0.562 (0.707)\n",
      "Epoch: [19][14/18]\tTime 0.079 (0.093)\tData 0.060 (0.071)\tLoss 0.8583 (0.7463)\tAcc 0.562 (0.696)\n",
      "Epoch: [19][15/18]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.8495 (0.7531)\tAcc 0.750 (0.700)\n",
      "Epoch: [19][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.8127 (0.7569)\tAcc 0.688 (0.699)\n",
      "Epoch: [19][17/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.7949 (0.7591)\tAcc 0.688 (0.699)\n",
      "Epoch: [19][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.7897 (0.7600)\tAcc 0.875 (0.704)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/12]\tTime 0.316 (0.316)\tData 0.284 (0.284)\tLoss 0.5158 (0.5158)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][2/12]\tTime 0.074 (0.195)\tData 0.049 (0.167)\tLoss 0.9470 (0.7314)\tAcc 0.688 (0.781)\n",
      "Epoch: [20][3/12]\tTime 0.086 (0.159)\tData 0.057 (0.130)\tLoss 0.7006 (0.7211)\tAcc 0.750 (0.771)\n",
      "Epoch: [20][4/12]\tTime 0.096 (0.143)\tData 0.057 (0.112)\tLoss 1.1193 (0.8207)\tAcc 0.562 (0.719)\n",
      "Epoch: [20][5/12]\tTime 0.075 (0.129)\tData 0.044 (0.098)\tLoss 0.6390 (0.7843)\tAcc 0.688 (0.713)\n",
      "Epoch: [20][6/12]\tTime 0.081 (0.121)\tData 0.050 (0.090)\tLoss 0.4676 (0.7316)\tAcc 0.875 (0.740)\n",
      "Epoch: [20][7/12]\tTime 0.075 (0.115)\tData 0.051 (0.084)\tLoss 0.6368 (0.7180)\tAcc 0.688 (0.732)\n",
      "Epoch: [20][8/12]\tTime 0.078 (0.110)\tData 0.054 (0.081)\tLoss 0.5661 (0.6990)\tAcc 0.750 (0.734)\n",
      "Epoch: [20][9/12]\tTime 0.080 (0.107)\tData 0.056 (0.078)\tLoss 0.6357 (0.6920)\tAcc 0.812 (0.743)\n",
      "Epoch: [20][10/12]\tTime 0.083 (0.104)\tData 0.059 (0.076)\tLoss 0.5759 (0.6804)\tAcc 0.812 (0.750)\n",
      "Epoch: [20][11/12]\tTime 0.083 (0.103)\tData 0.059 (0.074)\tLoss 0.5871 (0.6719)\tAcc 0.750 (0.750)\n",
      "Epoch: [20][12/12]\tTime 0.080 (0.101)\tData 0.056 (0.073)\tLoss 0.5958 (0.6659)\tAcc 0.733 (0.749)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/18]\tTime 0.233 (0.233)\tData 0.199 (0.199)\tLoss 0.2955 (0.2955)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/18]\tTime 0.069 (0.151)\tData 0.041 (0.120)\tLoss 0.9219 (0.6087)\tAcc 0.500 (0.719)\n",
      "Epoch: [20][3/18]\tTime 0.067 (0.123)\tData 0.046 (0.096)\tLoss 0.6383 (0.6186)\tAcc 0.750 (0.729)\n",
      "Epoch: [20][4/18]\tTime 0.075 (0.111)\tData 0.053 (0.085)\tLoss 0.5507 (0.6016)\tAcc 0.750 (0.734)\n",
      "Epoch: [20][5/18]\tTime 0.073 (0.103)\tData 0.052 (0.078)\tLoss 0.8309 (0.6475)\tAcc 0.688 (0.725)\n",
      "Epoch: [20][6/18]\tTime 0.074 (0.098)\tData 0.054 (0.074)\tLoss 0.3208 (0.5930)\tAcc 1.000 (0.771)\n",
      "Epoch: [20][7/18]\tTime 0.074 (0.095)\tData 0.053 (0.071)\tLoss 0.7271 (0.6122)\tAcc 0.562 (0.741)\n",
      "Epoch: [20][8/18]\tTime 0.075 (0.092)\tData 0.054 (0.069)\tLoss 0.9198 (0.6506)\tAcc 0.750 (0.742)\n",
      "Epoch: [20][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.067)\tLoss 0.1327 (0.5931)\tAcc 1.000 (0.771)\n",
      "Epoch: [20][10/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 1.1044 (0.6442)\tAcc 0.750 (0.769)\n",
      "Epoch: [20][11/18]\tTime 0.078 (0.088)\tData 0.058 (0.066)\tLoss 1.2058 (0.6953)\tAcc 0.375 (0.733)\n",
      "Epoch: [20][12/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 0.9475 (0.7163)\tAcc 0.812 (0.740)\n",
      "Epoch: [20][13/18]\tTime 0.077 (0.086)\tData 0.057 (0.064)\tLoss 1.2262 (0.7555)\tAcc 0.438 (0.716)\n",
      "Epoch: [20][14/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.8236 (0.7604)\tAcc 0.625 (0.710)\n",
      "Epoch: [20][15/18]\tTime 0.073 (0.085)\tData 0.054 (0.063)\tLoss 0.8955 (0.7694)\tAcc 0.688 (0.708)\n",
      "Epoch: [20][16/18]\tTime 0.075 (0.084)\tData 0.055 (0.062)\tLoss 0.8126 (0.7721)\tAcc 0.625 (0.703)\n",
      "Epoch: [20][17/18]\tTime 0.077 (0.084)\tData 0.057 (0.062)\tLoss 0.8665 (0.7776)\tAcc 0.625 (0.699)\n",
      "Epoch: [20][18/18]\tTime 0.075 (0.083)\tData 0.056 (0.062)\tLoss 0.8362 (0.7793)\tAcc 0.750 (0.700)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/12]\tTime 0.336 (0.336)\tData 0.307 (0.307)\tLoss 0.7971 (0.7971)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][2/12]\tTime 0.083 (0.209)\tData 0.057 (0.182)\tLoss 0.5004 (0.6488)\tAcc 0.812 (0.781)\n",
      "Epoch: [21][3/12]\tTime 0.084 (0.168)\tData 0.058 (0.141)\tLoss 0.5128 (0.6035)\tAcc 0.875 (0.812)\n",
      "Epoch: [21][4/12]\tTime 0.085 (0.147)\tData 0.059 (0.120)\tLoss 0.5577 (0.5920)\tAcc 0.875 (0.828)\n",
      "Epoch: [21][5/12]\tTime 0.093 (0.136)\tData 0.058 (0.108)\tLoss 0.4721 (0.5680)\tAcc 0.750 (0.812)\n",
      "Epoch: [21][6/12]\tTime 0.085 (0.128)\tData 0.054 (0.099)\tLoss 0.6141 (0.5757)\tAcc 0.750 (0.802)\n",
      "Epoch: [21][7/12]\tTime 0.084 (0.122)\tData 0.054 (0.092)\tLoss 1.1048 (0.6513)\tAcc 0.562 (0.768)\n",
      "Epoch: [21][8/12]\tTime 0.083 (0.117)\tData 0.054 (0.087)\tLoss 0.6303 (0.6487)\tAcc 0.688 (0.758)\n",
      "Epoch: [21][9/12]\tTime 0.082 (0.113)\tData 0.053 (0.084)\tLoss 1.2426 (0.7147)\tAcc 0.562 (0.736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21][10/12]\tTime 0.081 (0.110)\tData 0.051 (0.080)\tLoss 0.8659 (0.7298)\tAcc 0.625 (0.725)\n",
      "Epoch: [21][11/12]\tTime 0.080 (0.107)\tData 0.049 (0.078)\tLoss 0.5427 (0.7128)\tAcc 0.812 (0.733)\n",
      "Epoch: [21][12/12]\tTime 0.077 (0.105)\tData 0.049 (0.075)\tLoss 0.6451 (0.7075)\tAcc 0.800 (0.738)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/18]\tTime 0.267 (0.267)\tData 0.238 (0.238)\tLoss 0.3748 (0.3748)\tAcc 0.875 (0.875)\n",
      "Epoch: [21][2/18]\tTime 0.104 (0.186)\tData 0.046 (0.142)\tLoss 0.9301 (0.6525)\tAcc 0.562 (0.719)\n",
      "Epoch: [21][3/18]\tTime 0.039 (0.137)\tData 0.016 (0.100)\tLoss 0.5724 (0.6258)\tAcc 0.875 (0.771)\n",
      "Epoch: [21][4/18]\tTime 0.072 (0.121)\tData 0.051 (0.088)\tLoss 0.5865 (0.6160)\tAcc 0.812 (0.781)\n",
      "Epoch: [21][5/18]\tTime 0.076 (0.112)\tData 0.055 (0.081)\tLoss 0.7545 (0.6437)\tAcc 0.688 (0.762)\n",
      "Epoch: [21][6/18]\tTime 0.086 (0.108)\tData 0.063 (0.078)\tLoss 0.3842 (0.6004)\tAcc 0.938 (0.792)\n",
      "Epoch: [21][7/18]\tTime 0.079 (0.103)\tData 0.057 (0.075)\tLoss 0.6731 (0.6108)\tAcc 0.750 (0.786)\n",
      "Epoch: [21][8/18]\tTime 0.079 (0.100)\tData 0.057 (0.073)\tLoss 0.9193 (0.6494)\tAcc 0.562 (0.758)\n",
      "Epoch: [21][9/18]\tTime 0.079 (0.098)\tData 0.058 (0.071)\tLoss 0.1464 (0.5935)\tAcc 1.000 (0.785)\n",
      "Epoch: [21][10/18]\tTime 0.079 (0.096)\tData 0.057 (0.070)\tLoss 1.1322 (0.6474)\tAcc 0.750 (0.781)\n",
      "Epoch: [21][11/18]\tTime 0.077 (0.094)\tData 0.057 (0.068)\tLoss 1.1967 (0.6973)\tAcc 0.375 (0.744)\n",
      "Epoch: [21][12/18]\tTime 0.078 (0.093)\tData 0.059 (0.068)\tLoss 0.9565 (0.7189)\tAcc 0.812 (0.750)\n",
      "Epoch: [21][13/18]\tTime 0.079 (0.092)\tData 0.059 (0.067)\tLoss 1.1325 (0.7507)\tAcc 0.438 (0.726)\n",
      "Epoch: [21][14/18]\tTime 0.078 (0.091)\tData 0.058 (0.066)\tLoss 0.7683 (0.7520)\tAcc 0.688 (0.723)\n",
      "Epoch: [21][15/18]\tTime 0.080 (0.090)\tData 0.059 (0.066)\tLoss 0.8294 (0.7571)\tAcc 0.750 (0.725)\n",
      "Epoch: [21][16/18]\tTime 0.079 (0.090)\tData 0.059 (0.065)\tLoss 0.8479 (0.7628)\tAcc 0.625 (0.719)\n",
      "Epoch: [21][17/18]\tTime 0.088 (0.089)\tData 0.068 (0.066)\tLoss 0.7715 (0.7633)\tAcc 0.625 (0.713)\n",
      "Epoch: [21][18/18]\tTime 0.077 (0.089)\tData 0.058 (0.065)\tLoss 0.7497 (0.7629)\tAcc 0.750 (0.714)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/12]\tTime 1.206 (1.206)\tData 1.172 (1.172)\tLoss 0.5598 (0.5598)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][2/12]\tTime 0.075 (0.640)\tData 0.048 (0.610)\tLoss 0.7775 (0.6686)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][3/12]\tTime 0.106 (0.462)\tData 0.061 (0.427)\tLoss 0.6624 (0.6666)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][4/12]\tTime 0.071 (0.365)\tData 0.044 (0.331)\tLoss 0.7410 (0.6852)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][5/12]\tTime 0.086 (0.309)\tData 0.061 (0.277)\tLoss 0.4855 (0.6452)\tAcc 0.875 (0.725)\n",
      "Epoch: [22][6/12]\tTime 0.087 (0.272)\tData 0.061 (0.241)\tLoss 0.6335 (0.6433)\tAcc 0.688 (0.719)\n",
      "Epoch: [22][7/12]\tTime 0.085 (0.245)\tData 0.061 (0.215)\tLoss 0.4580 (0.6168)\tAcc 0.812 (0.732)\n",
      "Epoch: [22][8/12]\tTime 0.085 (0.225)\tData 0.061 (0.196)\tLoss 0.7065 (0.6280)\tAcc 0.688 (0.727)\n",
      "Epoch: [22][9/12]\tTime 0.085 (0.210)\tData 0.061 (0.181)\tLoss 0.8499 (0.6527)\tAcc 0.625 (0.715)\n",
      "Epoch: [22][10/12]\tTime 0.086 (0.197)\tData 0.061 (0.169)\tLoss 0.6561 (0.6530)\tAcc 0.750 (0.719)\n",
      "Epoch: [22][11/12]\tTime 0.087 (0.187)\tData 0.062 (0.159)\tLoss 0.7303 (0.6600)\tAcc 0.688 (0.716)\n",
      "Epoch: [22][12/12]\tTime 0.086 (0.179)\tData 0.062 (0.151)\tLoss 0.7468 (0.6668)\tAcc 0.733 (0.717)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/18]\tTime 0.219 (0.219)\tData 0.193 (0.193)\tLoss 0.4670 (0.4670)\tAcc 0.875 (0.875)\n",
      "Epoch: [22][2/18]\tTime 0.074 (0.146)\tData 0.050 (0.121)\tLoss 0.8575 (0.6622)\tAcc 0.625 (0.750)\n",
      "Epoch: [22][3/18]\tTime 0.078 (0.124)\tData 0.054 (0.099)\tLoss 0.5867 (0.6371)\tAcc 0.688 (0.729)\n",
      "Epoch: [22][4/18]\tTime 0.076 (0.112)\tData 0.055 (0.088)\tLoss 0.6114 (0.6306)\tAcc 0.875 (0.766)\n",
      "Epoch: [22][5/18]\tTime 0.074 (0.104)\tData 0.054 (0.081)\tLoss 0.8076 (0.6660)\tAcc 0.625 (0.738)\n",
      "Epoch: [22][6/18]\tTime 0.073 (0.099)\tData 0.053 (0.077)\tLoss 0.3252 (0.6092)\tAcc 1.000 (0.781)\n",
      "Epoch: [22][7/18]\tTime 0.074 (0.095)\tData 0.053 (0.073)\tLoss 0.8094 (0.6378)\tAcc 0.562 (0.750)\n",
      "Epoch: [22][8/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 0.9997 (0.6831)\tAcc 0.500 (0.719)\n",
      "Epoch: [22][9/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.1476 (0.6236)\tAcc 1.000 (0.750)\n",
      "Epoch: [22][10/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 1.0954 (0.6708)\tAcc 0.500 (0.725)\n",
      "Epoch: [22][11/18]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 1.1506 (0.7144)\tAcc 0.375 (0.693)\n",
      "Epoch: [22][12/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 0.9283 (0.7322)\tAcc 0.812 (0.703)\n",
      "Epoch: [22][13/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 1.0246 (0.7547)\tAcc 0.562 (0.692)\n",
      "Epoch: [22][14/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.7947 (0.7576)\tAcc 0.562 (0.683)\n",
      "Epoch: [22][15/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.8943 (0.7667)\tAcc 0.625 (0.679)\n",
      "Epoch: [22][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.8262 (0.7704)\tAcc 0.625 (0.676)\n",
      "Epoch: [22][17/18]\tTime 0.075 (0.083)\tData 0.055 (0.062)\tLoss 0.7427 (0.7688)\tAcc 0.688 (0.676)\n",
      "Epoch: [22][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.7159 (0.7672)\tAcc 0.875 (0.682)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/12]\tTime 0.355 (0.355)\tData 0.327 (0.327)\tLoss 0.5642 (0.5642)\tAcc 0.812 (0.812)\n",
      "Epoch: [23][2/12]\tTime 0.076 (0.216)\tData 0.051 (0.189)\tLoss 0.7700 (0.6671)\tAcc 0.688 (0.750)\n",
      "Epoch: [23][3/12]\tTime 0.082 (0.171)\tData 0.053 (0.144)\tLoss 0.5808 (0.6384)\tAcc 0.875 (0.792)\n",
      "Epoch: [23][4/12]\tTime 0.075 (0.147)\tData 0.050 (0.120)\tLoss 0.6132 (0.6321)\tAcc 0.688 (0.766)\n",
      "Epoch: [23][5/12]\tTime 0.079 (0.133)\tData 0.054 (0.107)\tLoss 0.9487 (0.6954)\tAcc 0.688 (0.750)\n",
      "Epoch: [23][6/12]\tTime 0.079 (0.124)\tData 0.053 (0.098)\tLoss 0.6595 (0.6894)\tAcc 0.812 (0.760)\n",
      "Epoch: [23][7/12]\tTime 0.076 (0.117)\tData 0.052 (0.091)\tLoss 0.6401 (0.6824)\tAcc 0.812 (0.768)\n",
      "Epoch: [23][8/12]\tTime 0.080 (0.113)\tData 0.056 (0.087)\tLoss 0.5523 (0.6661)\tAcc 0.750 (0.766)\n",
      "Epoch: [23][9/12]\tTime 0.077 (0.109)\tData 0.054 (0.083)\tLoss 0.5677 (0.6552)\tAcc 0.812 (0.771)\n",
      "Epoch: [23][10/12]\tTime 0.078 (0.106)\tData 0.055 (0.080)\tLoss 0.5514 (0.6448)\tAcc 0.750 (0.769)\n",
      "Epoch: [23][11/12]\tTime 0.080 (0.103)\tData 0.056 (0.078)\tLoss 0.5314 (0.6345)\tAcc 0.750 (0.767)\n",
      "Epoch: [23][12/12]\tTime 0.081 (0.101)\tData 0.055 (0.076)\tLoss 0.6777 (0.6379)\tAcc 0.733 (0.764)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/18]\tTime 0.229 (0.229)\tData 0.201 (0.201)\tLoss 0.3026 (0.3026)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/18]\tTime 0.079 (0.154)\tData 0.046 (0.124)\tLoss 0.9380 (0.6203)\tAcc 0.688 (0.812)\n",
      "Epoch: [23][3/18]\tTime 0.063 (0.124)\tData 0.042 (0.096)\tLoss 0.6033 (0.6146)\tAcc 0.750 (0.792)\n",
      "Epoch: [23][4/18]\tTime 0.077 (0.112)\tData 0.056 (0.086)\tLoss 0.5923 (0.6091)\tAcc 0.750 (0.781)\n",
      "Epoch: [23][5/18]\tTime 0.078 (0.105)\tData 0.058 (0.081)\tLoss 0.7637 (0.6400)\tAcc 0.750 (0.775)\n",
      "Epoch: [23][6/18]\tTime 0.078 (0.101)\tData 0.058 (0.077)\tLoss 0.2999 (0.5833)\tAcc 1.000 (0.812)\n",
      "Epoch: [23][7/18]\tTime 0.080 (0.098)\tData 0.059 (0.074)\tLoss 0.5703 (0.5814)\tAcc 0.875 (0.821)\n",
      "Epoch: [23][8/18]\tTime 0.079 (0.096)\tData 0.058 (0.072)\tLoss 0.9866 (0.6321)\tAcc 0.625 (0.797)\n",
      "Epoch: [23][9/18]\tTime 0.074 (0.093)\tData 0.054 (0.070)\tLoss 0.0969 (0.5726)\tAcc 1.000 (0.819)\n",
      "Epoch: [23][10/18]\tTime 0.075 (0.091)\tData 0.054 (0.069)\tLoss 1.1695 (0.6323)\tAcc 0.688 (0.806)\n",
      "Epoch: [23][11/18]\tTime 0.074 (0.090)\tData 0.054 (0.067)\tLoss 1.2766 (0.6909)\tAcc 0.375 (0.767)\n",
      "Epoch: [23][12/18]\tTime 0.075 (0.089)\tData 0.054 (0.066)\tLoss 1.0514 (0.7209)\tAcc 0.812 (0.771)\n",
      "Epoch: [23][13/18]\tTime 0.078 (0.088)\tData 0.057 (0.066)\tLoss 0.9822 (0.7410)\tAcc 0.688 (0.764)\n",
      "Epoch: [23][14/18]\tTime 0.076 (0.087)\tData 0.057 (0.065)\tLoss 0.8222 (0.7468)\tAcc 0.500 (0.746)\n",
      "Epoch: [23][15/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 0.9538 (0.7606)\tAcc 0.750 (0.746)\n",
      "Epoch: [23][16/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.8342 (0.7652)\tAcc 0.750 (0.746)\n",
      "Epoch: [23][17/18]\tTime 0.074 (0.085)\tData 0.055 (0.063)\tLoss 0.8145 (0.7681)\tAcc 0.625 (0.739)\n",
      "Epoch: [23][18/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.5927 (0.7631)\tAcc 0.875 (0.743)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/12]\tTime 0.330 (0.330)\tData 0.292 (0.292)\tLoss 0.6194 (0.6194)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][2/12]\tTime 0.076 (0.203)\tData 0.050 (0.171)\tLoss 0.5298 (0.5746)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][3/12]\tTime 0.080 (0.162)\tData 0.054 (0.132)\tLoss 0.7975 (0.6489)\tAcc 0.688 (0.729)\n",
      "Epoch: [24][4/12]\tTime 0.085 (0.143)\tData 0.057 (0.113)\tLoss 0.4612 (0.6020)\tAcc 0.812 (0.750)\n",
      "Epoch: [24][5/12]\tTime 0.079 (0.130)\tData 0.054 (0.101)\tLoss 0.4328 (0.5681)\tAcc 0.875 (0.775)\n",
      "Epoch: [24][6/12]\tTime 0.085 (0.122)\tData 0.056 (0.094)\tLoss 0.9881 (0.6381)\tAcc 0.625 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24][7/12]\tTime 0.073 (0.115)\tData 0.049 (0.087)\tLoss 0.8445 (0.6676)\tAcc 0.625 (0.732)\n",
      "Epoch: [24][8/12]\tTime 0.080 (0.111)\tData 0.055 (0.083)\tLoss 0.8793 (0.6941)\tAcc 0.562 (0.711)\n",
      "Epoch: [24][9/12]\tTime 0.084 (0.108)\tData 0.060 (0.081)\tLoss 0.4578 (0.6678)\tAcc 0.812 (0.722)\n",
      "Epoch: [24][10/12]\tTime 0.086 (0.106)\tData 0.062 (0.079)\tLoss 0.6558 (0.6666)\tAcc 0.750 (0.725)\n",
      "Epoch: [24][11/12]\tTime 0.087 (0.104)\tData 0.062 (0.077)\tLoss 0.5109 (0.6525)\tAcc 0.812 (0.733)\n",
      "Epoch: [24][12/12]\tTime 0.087 (0.103)\tData 0.062 (0.076)\tLoss 0.5665 (0.6457)\tAcc 0.867 (0.743)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/18]\tTime 0.230 (0.230)\tData 0.203 (0.203)\tLoss 0.2311 (0.2311)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/18]\tTime 0.078 (0.154)\tData 0.050 (0.126)\tLoss 0.8895 (0.5603)\tAcc 0.750 (0.844)\n",
      "Epoch: [24][3/18]\tTime 0.068 (0.125)\tData 0.047 (0.100)\tLoss 0.5956 (0.5721)\tAcc 0.812 (0.833)\n",
      "Epoch: [24][4/18]\tTime 0.075 (0.113)\tData 0.054 (0.088)\tLoss 0.5950 (0.5778)\tAcc 0.812 (0.828)\n",
      "Epoch: [24][5/18]\tTime 0.080 (0.106)\tData 0.058 (0.082)\tLoss 0.7590 (0.6140)\tAcc 0.688 (0.800)\n",
      "Epoch: [24][6/18]\tTime 0.080 (0.102)\tData 0.059 (0.079)\tLoss 0.2868 (0.5595)\tAcc 0.938 (0.823)\n",
      "Epoch: [24][7/18]\tTime 0.081 (0.099)\tData 0.060 (0.076)\tLoss 0.8212 (0.5969)\tAcc 0.562 (0.786)\n",
      "Epoch: [24][8/18]\tTime 0.080 (0.096)\tData 0.059 (0.074)\tLoss 0.8595 (0.6297)\tAcc 0.812 (0.789)\n",
      "Epoch: [24][9/18]\tTime 0.075 (0.094)\tData 0.055 (0.072)\tLoss 0.1295 (0.5741)\tAcc 1.000 (0.812)\n",
      "Epoch: [24][10/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 1.0579 (0.6225)\tAcc 0.812 (0.812)\n",
      "Epoch: [24][11/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 1.1658 (0.6719)\tAcc 0.375 (0.773)\n",
      "Epoch: [24][12/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.9205 (0.6926)\tAcc 0.812 (0.776)\n",
      "Epoch: [24][13/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.9835 (0.7150)\tAcc 0.750 (0.774)\n",
      "Epoch: [24][14/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.7853 (0.7200)\tAcc 0.625 (0.763)\n",
      "Epoch: [24][15/18]\tTime 0.076 (0.086)\tData 0.056 (0.065)\tLoss 0.7910 (0.7247)\tAcc 0.750 (0.763)\n",
      "Epoch: [24][16/18]\tTime 0.081 (0.086)\tData 0.061 (0.064)\tLoss 0.8151 (0.7304)\tAcc 0.625 (0.754)\n",
      "Epoch: [24][17/18]\tTime 0.080 (0.085)\tData 0.060 (0.064)\tLoss 0.7454 (0.7313)\tAcc 0.625 (0.746)\n",
      "Epoch: [24][18/18]\tTime 0.079 (0.085)\tData 0.060 (0.064)\tLoss 0.7663 (0.7323)\tAcc 0.750 (0.746)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/12]\tTime 0.267 (0.267)\tData 0.238 (0.238)\tLoss 0.3706 (0.3706)\tAcc 0.875 (0.875)\n",
      "Epoch: [25][2/12]\tTime 0.077 (0.172)\tData 0.053 (0.145)\tLoss 0.7421 (0.5563)\tAcc 0.750 (0.812)\n",
      "Epoch: [25][3/12]\tTime 0.081 (0.142)\tData 0.054 (0.115)\tLoss 0.8155 (0.6427)\tAcc 0.562 (0.729)\n",
      "Epoch: [25][4/12]\tTime 0.077 (0.126)\tData 0.052 (0.099)\tLoss 0.7933 (0.6803)\tAcc 0.625 (0.703)\n",
      "Epoch: [25][5/12]\tTime 0.078 (0.116)\tData 0.053 (0.090)\tLoss 0.8835 (0.7210)\tAcc 0.625 (0.688)\n",
      "Epoch: [25][6/12]\tTime 0.078 (0.110)\tData 0.054 (0.084)\tLoss 0.8641 (0.7448)\tAcc 0.625 (0.677)\n",
      "Epoch: [25][7/12]\tTime 0.080 (0.105)\tData 0.054 (0.080)\tLoss 0.6293 (0.7283)\tAcc 0.625 (0.670)\n",
      "Epoch: [25][8/12]\tTime 0.075 (0.102)\tData 0.052 (0.076)\tLoss 0.8826 (0.7476)\tAcc 0.688 (0.672)\n",
      "Epoch: [25][9/12]\tTime 0.078 (0.099)\tData 0.055 (0.074)\tLoss 0.4148 (0.7106)\tAcc 0.875 (0.694)\n",
      "Epoch: [25][10/12]\tTime 0.079 (0.097)\tData 0.056 (0.072)\tLoss 0.6949 (0.7091)\tAcc 0.688 (0.694)\n",
      "Epoch: [25][11/12]\tTime 0.078 (0.095)\tData 0.055 (0.071)\tLoss 0.5549 (0.6950)\tAcc 0.750 (0.699)\n",
      "Epoch: [25][12/12]\tTime 0.078 (0.094)\tData 0.055 (0.069)\tLoss 0.7675 (0.7007)\tAcc 0.733 (0.702)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/18]\tTime 0.224 (0.224)\tData 0.197 (0.197)\tLoss 0.3873 (0.3873)\tAcc 0.875 (0.875)\n",
      "Epoch: [25][2/18]\tTime 0.074 (0.149)\tData 0.049 (0.123)\tLoss 0.9301 (0.6587)\tAcc 0.562 (0.719)\n",
      "Epoch: [25][3/18]\tTime 0.073 (0.124)\tData 0.051 (0.099)\tLoss 0.5703 (0.6292)\tAcc 0.875 (0.771)\n",
      "Epoch: [25][4/18]\tTime 0.073 (0.111)\tData 0.053 (0.088)\tLoss 0.6421 (0.6324)\tAcc 0.688 (0.750)\n",
      "Epoch: [25][5/18]\tTime 0.074 (0.104)\tData 0.053 (0.081)\tLoss 0.8621 (0.6784)\tAcc 0.688 (0.738)\n",
      "Epoch: [25][6/18]\tTime 0.074 (0.099)\tData 0.054 (0.076)\tLoss 0.3422 (0.6224)\tAcc 0.938 (0.771)\n",
      "Epoch: [25][7/18]\tTime 0.074 (0.095)\tData 0.053 (0.073)\tLoss 0.8434 (0.6539)\tAcc 0.500 (0.732)\n",
      "Epoch: [25][8/18]\tTime 0.076 (0.093)\tData 0.056 (0.071)\tLoss 1.0324 (0.7012)\tAcc 0.688 (0.727)\n",
      "Epoch: [25][9/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.1073 (0.6352)\tAcc 1.000 (0.757)\n",
      "Epoch: [25][10/18]\tTime 0.075 (0.089)\tData 0.054 (0.068)\tLoss 0.9368 (0.6654)\tAcc 0.812 (0.762)\n",
      "Epoch: [25][11/18]\tTime 0.078 (0.088)\tData 0.058 (0.067)\tLoss 1.3982 (0.7320)\tAcc 0.375 (0.727)\n",
      "Epoch: [25][12/18]\tTime 0.080 (0.087)\tData 0.060 (0.066)\tLoss 0.8967 (0.7457)\tAcc 0.812 (0.734)\n",
      "Epoch: [25][13/18]\tTime 0.080 (0.087)\tData 0.060 (0.066)\tLoss 1.0417 (0.7685)\tAcc 0.625 (0.726)\n",
      "Epoch: [25][14/18]\tTime 0.080 (0.086)\tData 0.060 (0.065)\tLoss 0.8252 (0.7726)\tAcc 0.562 (0.714)\n",
      "Epoch: [25][15/18]\tTime 0.078 (0.086)\tData 0.059 (0.065)\tLoss 0.9554 (0.7847)\tAcc 0.688 (0.713)\n",
      "Epoch: [25][16/18]\tTime 0.078 (0.085)\tData 0.058 (0.064)\tLoss 0.7372 (0.7818)\tAcc 0.750 (0.715)\n",
      "Epoch: [25][17/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.7092 (0.7775)\tAcc 0.625 (0.710)\n",
      "Epoch: [25][18/18]\tTime 0.077 (0.084)\tData 0.057 (0.063)\tLoss 0.8125 (0.7785)\tAcc 0.750 (0.711)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/12]\tTime 0.320 (0.320)\tData 0.288 (0.288)\tLoss 0.4149 (0.4149)\tAcc 1.000 (1.000)\n",
      "Epoch: [26][2/12]\tTime 0.075 (0.198)\tData 0.048 (0.168)\tLoss 0.4878 (0.4513)\tAcc 0.875 (0.938)\n",
      "Epoch: [26][3/12]\tTime 0.079 (0.158)\tData 0.054 (0.130)\tLoss 0.4721 (0.4582)\tAcc 0.812 (0.896)\n",
      "Epoch: [26][4/12]\tTime 0.085 (0.140)\tData 0.060 (0.113)\tLoss 0.8516 (0.5566)\tAcc 0.688 (0.844)\n",
      "Epoch: [26][5/12]\tTime 0.081 (0.128)\tData 0.056 (0.101)\tLoss 0.9439 (0.6340)\tAcc 0.625 (0.800)\n",
      "Epoch: [26][6/12]\tTime 0.082 (0.120)\tData 0.054 (0.093)\tLoss 0.5262 (0.6161)\tAcc 0.750 (0.792)\n",
      "Epoch: [26][7/12]\tTime 0.075 (0.114)\tData 0.051 (0.087)\tLoss 0.6391 (0.6194)\tAcc 0.750 (0.786)\n",
      "Epoch: [26][8/12]\tTime 0.080 (0.110)\tData 0.056 (0.083)\tLoss 0.9035 (0.6549)\tAcc 0.688 (0.773)\n",
      "Epoch: [26][9/12]\tTime 0.079 (0.106)\tData 0.056 (0.080)\tLoss 0.7278 (0.6630)\tAcc 0.688 (0.764)\n",
      "Epoch: [26][10/12]\tTime 0.079 (0.103)\tData 0.055 (0.078)\tLoss 0.6473 (0.6614)\tAcc 0.812 (0.769)\n",
      "Epoch: [26][11/12]\tTime 0.082 (0.102)\tData 0.058 (0.076)\tLoss 0.7127 (0.6661)\tAcc 0.688 (0.761)\n",
      "Epoch: [26][12/12]\tTime 0.083 (0.100)\tData 0.059 (0.075)\tLoss 0.9708 (0.6900)\tAcc 0.467 (0.738)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/18]\tTime 0.220 (0.220)\tData 0.190 (0.190)\tLoss 0.3348 (0.3348)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/18]\tTime 0.067 (0.144)\tData 0.045 (0.117)\tLoss 0.8367 (0.5858)\tAcc 0.750 (0.844)\n",
      "Epoch: [26][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.5628 (0.5781)\tAcc 0.750 (0.812)\n",
      "Epoch: [26][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.5371 (0.5679)\tAcc 0.750 (0.797)\n",
      "Epoch: [26][5/18]\tTime 0.074 (0.102)\tData 0.053 (0.079)\tLoss 0.8411 (0.6225)\tAcc 0.625 (0.762)\n",
      "Epoch: [26][6/18]\tTime 0.073 (0.097)\tData 0.053 (0.074)\tLoss 0.3719 (0.5808)\tAcc 0.938 (0.792)\n",
      "Epoch: [26][7/18]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.6581 (0.5918)\tAcc 0.750 (0.786)\n",
      "Epoch: [26][8/18]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.8363 (0.6224)\tAcc 0.750 (0.781)\n",
      "Epoch: [26][9/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.1165 (0.5662)\tAcc 1.000 (0.806)\n",
      "Epoch: [26][10/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 1.0889 (0.6184)\tAcc 0.688 (0.794)\n",
      "Epoch: [26][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.3279 (0.6829)\tAcc 0.375 (0.756)\n",
      "Epoch: [26][12/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.9667 (0.7066)\tAcc 0.688 (0.750)\n",
      "Epoch: [26][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 1.1061 (0.7373)\tAcc 0.500 (0.731)\n",
      "Epoch: [26][14/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.8140 (0.7428)\tAcc 0.688 (0.728)\n",
      "Epoch: [26][15/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.6682 (0.7378)\tAcc 0.750 (0.729)\n",
      "Epoch: [26][16/18]\tTime 0.074 (0.082)\tData 0.054 (0.061)\tLoss 0.8042 (0.7420)\tAcc 0.625 (0.723)\n",
      "Epoch: [26][17/18]\tTime 0.074 (0.082)\tData 0.054 (0.061)\tLoss 0.6919 (0.7390)\tAcc 0.625 (0.717)\n",
      "Epoch: [26][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.7546 (0.7395)\tAcc 0.625 (0.714)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/12]\tTime 0.365 (0.365)\tData 0.332 (0.332)\tLoss 0.7485 (0.7485)\tAcc 0.750 (0.750)\n",
      "Epoch: [27][2/12]\tTime 0.074 (0.219)\tData 0.049 (0.191)\tLoss 0.5849 (0.6667)\tAcc 0.750 (0.750)\n",
      "Epoch: [27][3/12]\tTime 0.079 (0.172)\tData 0.053 (0.145)\tLoss 0.5862 (0.6399)\tAcc 0.750 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][4/12]\tTime 0.080 (0.149)\tData 0.053 (0.122)\tLoss 0.6596 (0.6448)\tAcc 0.688 (0.734)\n",
      "Epoch: [27][5/12]\tTime 0.077 (0.135)\tData 0.052 (0.108)\tLoss 0.6088 (0.6376)\tAcc 0.750 (0.738)\n",
      "Epoch: [27][6/12]\tTime 0.078 (0.125)\tData 0.053 (0.099)\tLoss 0.9141 (0.6837)\tAcc 0.562 (0.708)\n",
      "Epoch: [27][7/12]\tTime 0.080 (0.119)\tData 0.054 (0.092)\tLoss 0.5056 (0.6582)\tAcc 0.812 (0.723)\n",
      "Epoch: [27][8/12]\tTime 0.077 (0.114)\tData 0.053 (0.087)\tLoss 0.6258 (0.6542)\tAcc 0.688 (0.719)\n",
      "Epoch: [27][9/12]\tTime 0.078 (0.110)\tData 0.054 (0.084)\tLoss 0.8197 (0.6726)\tAcc 0.688 (0.715)\n",
      "Epoch: [27][10/12]\tTime 0.077 (0.106)\tData 0.054 (0.081)\tLoss 0.4959 (0.6549)\tAcc 0.688 (0.713)\n",
      "Epoch: [27][11/12]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 0.7219 (0.6610)\tAcc 0.688 (0.710)\n",
      "Epoch: [27][12/12]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.5851 (0.6550)\tAcc 0.733 (0.712)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/18]\tTime 0.239 (0.239)\tData 0.205 (0.205)\tLoss 0.3760 (0.3760)\tAcc 0.938 (0.938)\n",
      "Epoch: [27][2/18]\tTime 0.071 (0.155)\tData 0.043 (0.124)\tLoss 0.8427 (0.6094)\tAcc 0.625 (0.781)\n",
      "Epoch: [27][3/18]\tTime 0.070 (0.126)\tData 0.048 (0.099)\tLoss 0.6180 (0.6122)\tAcc 0.812 (0.792)\n",
      "Epoch: [27][4/18]\tTime 0.077 (0.114)\tData 0.055 (0.088)\tLoss 0.7074 (0.6360)\tAcc 0.688 (0.766)\n",
      "Epoch: [27][5/18]\tTime 0.072 (0.106)\tData 0.052 (0.081)\tLoss 0.8242 (0.6737)\tAcc 0.750 (0.762)\n",
      "Epoch: [27][6/18]\tTime 0.075 (0.100)\tData 0.054 (0.076)\tLoss 0.4308 (0.6332)\tAcc 0.938 (0.792)\n",
      "Epoch: [27][7/18]\tTime 0.073 (0.097)\tData 0.053 (0.073)\tLoss 0.9119 (0.6730)\tAcc 0.562 (0.759)\n",
      "Epoch: [27][8/18]\tTime 0.077 (0.094)\tData 0.057 (0.071)\tLoss 1.1022 (0.7266)\tAcc 0.625 (0.742)\n",
      "Epoch: [27][9/18]\tTime 0.080 (0.093)\tData 0.057 (0.070)\tLoss 0.1494 (0.6625)\tAcc 1.000 (0.771)\n",
      "Epoch: [27][10/18]\tTime 0.078 (0.091)\tData 0.057 (0.068)\tLoss 1.0560 (0.7018)\tAcc 0.750 (0.769)\n",
      "Epoch: [27][11/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 1.4018 (0.7655)\tAcc 0.375 (0.733)\n",
      "Epoch: [27][12/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.8410 (0.7718)\tAcc 0.812 (0.740)\n",
      "Epoch: [27][13/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.9886 (0.7885)\tAcc 0.688 (0.736)\n",
      "Epoch: [27][14/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7396 (0.7850)\tAcc 0.562 (0.723)\n",
      "Epoch: [27][15/18]\tTime 0.082 (0.088)\tData 0.062 (0.066)\tLoss 0.7356 (0.7817)\tAcc 0.750 (0.725)\n",
      "Epoch: [27][16/18]\tTime 0.078 (0.087)\tData 0.058 (0.065)\tLoss 0.7992 (0.7828)\tAcc 0.750 (0.727)\n",
      "Epoch: [27][17/18]\tTime 0.077 (0.086)\tData 0.058 (0.065)\tLoss 0.8290 (0.7855)\tAcc 0.625 (0.721)\n",
      "Epoch: [27][18/18]\tTime 0.075 (0.086)\tData 0.056 (0.064)\tLoss 0.8353 (0.7869)\tAcc 0.875 (0.725)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/12]\tTime 0.304 (0.304)\tData 0.275 (0.275)\tLoss 0.5792 (0.5792)\tAcc 0.812 (0.812)\n",
      "Epoch: [28][2/12]\tTime 0.085 (0.194)\tData 0.060 (0.168)\tLoss 0.6507 (0.6150)\tAcc 0.688 (0.750)\n",
      "Epoch: [28][3/12]\tTime 0.084 (0.158)\tData 0.059 (0.131)\tLoss 0.6904 (0.6401)\tAcc 0.750 (0.750)\n",
      "Epoch: [28][4/12]\tTime 0.084 (0.139)\tData 0.059 (0.113)\tLoss 0.6853 (0.6514)\tAcc 0.750 (0.750)\n",
      "Epoch: [28][5/12]\tTime 0.084 (0.128)\tData 0.059 (0.102)\tLoss 0.5271 (0.6265)\tAcc 0.750 (0.750)\n",
      "Epoch: [28][6/12]\tTime 0.086 (0.121)\tData 0.059 (0.095)\tLoss 0.8200 (0.6588)\tAcc 0.625 (0.729)\n",
      "Epoch: [28][7/12]\tTime 0.081 (0.116)\tData 0.056 (0.090)\tLoss 0.7226 (0.6679)\tAcc 0.625 (0.714)\n",
      "Epoch: [28][8/12]\tTime 0.083 (0.111)\tData 0.058 (0.086)\tLoss 0.9899 (0.7081)\tAcc 0.625 (0.703)\n",
      "Epoch: [28][9/12]\tTime 0.081 (0.108)\tData 0.057 (0.082)\tLoss 0.6435 (0.7010)\tAcc 0.875 (0.722)\n",
      "Epoch: [28][10/12]\tTime 0.078 (0.105)\tData 0.055 (0.080)\tLoss 0.6355 (0.6944)\tAcc 0.812 (0.731)\n",
      "Epoch: [28][11/12]\tTime 0.078 (0.103)\tData 0.055 (0.077)\tLoss 0.5152 (0.6781)\tAcc 0.812 (0.739)\n",
      "Epoch: [28][12/12]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.9973 (0.7032)\tAcc 0.733 (0.738)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/18]\tTime 0.217 (0.217)\tData 0.189 (0.189)\tLoss 0.3587 (0.3587)\tAcc 0.875 (0.875)\n",
      "Epoch: [28][2/18]\tTime 0.069 (0.143)\tData 0.047 (0.118)\tLoss 0.8751 (0.6169)\tAcc 0.688 (0.781)\n",
      "Epoch: [28][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.5598 (0.5979)\tAcc 0.688 (0.750)\n",
      "Epoch: [28][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.6141 (0.6019)\tAcc 0.625 (0.719)\n",
      "Epoch: [28][5/18]\tTime 0.074 (0.101)\tData 0.053 (0.079)\tLoss 0.8630 (0.6541)\tAcc 0.688 (0.713)\n",
      "Epoch: [28][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.1931 (0.5773)\tAcc 1.000 (0.760)\n",
      "Epoch: [28][7/18]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.6099 (0.5820)\tAcc 0.750 (0.759)\n",
      "Epoch: [28][8/18]\tTime 0.078 (0.091)\tData 0.057 (0.070)\tLoss 1.0028 (0.6346)\tAcc 0.562 (0.734)\n",
      "Epoch: [28][9/18]\tTime 0.078 (0.090)\tData 0.057 (0.068)\tLoss 0.0747 (0.5724)\tAcc 1.000 (0.764)\n",
      "Epoch: [28][10/18]\tTime 0.080 (0.089)\tData 0.059 (0.068)\tLoss 1.2328 (0.6384)\tAcc 0.562 (0.744)\n",
      "Epoch: [28][11/18]\tTime 0.078 (0.088)\tData 0.058 (0.067)\tLoss 1.5466 (0.7210)\tAcc 0.375 (0.710)\n",
      "Epoch: [28][12/18]\tTime 0.079 (0.087)\tData 0.059 (0.066)\tLoss 0.9824 (0.7427)\tAcc 0.750 (0.714)\n",
      "Epoch: [28][13/18]\tTime 0.079 (0.086)\tData 0.059 (0.065)\tLoss 1.2174 (0.7793)\tAcc 0.625 (0.707)\n",
      "Epoch: [28][14/18]\tTime 0.079 (0.086)\tData 0.059 (0.065)\tLoss 0.9067 (0.7884)\tAcc 0.562 (0.696)\n",
      "Epoch: [28][15/18]\tTime 0.077 (0.085)\tData 0.058 (0.064)\tLoss 0.9874 (0.8016)\tAcc 0.625 (0.692)\n",
      "Epoch: [28][16/18]\tTime 0.078 (0.085)\tData 0.059 (0.064)\tLoss 0.7653 (0.7994)\tAcc 0.688 (0.691)\n",
      "Epoch: [28][17/18]\tTime 0.079 (0.085)\tData 0.059 (0.064)\tLoss 0.7758 (0.7980)\tAcc 0.625 (0.688)\n",
      "Epoch: [28][18/18]\tTime 0.078 (0.084)\tData 0.058 (0.063)\tLoss 0.6803 (0.7946)\tAcc 0.750 (0.689)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/12]\tTime 0.270 (0.270)\tData 0.238 (0.238)\tLoss 1.3978 (1.3978)\tAcc 0.500 (0.500)\n",
      "Epoch: [29][2/12]\tTime 0.072 (0.171)\tData 0.048 (0.143)\tLoss 0.4561 (0.9270)\tAcc 0.938 (0.719)\n",
      "Epoch: [29][3/12]\tTime 0.078 (0.140)\tData 0.054 (0.113)\tLoss 0.5990 (0.8177)\tAcc 0.875 (0.771)\n",
      "Epoch: [29][4/12]\tTime 0.081 (0.125)\tData 0.056 (0.099)\tLoss 0.9402 (0.8483)\tAcc 0.500 (0.703)\n",
      "Epoch: [29][5/12]\tTime 0.078 (0.116)\tData 0.053 (0.090)\tLoss 0.6656 (0.8118)\tAcc 0.750 (0.713)\n",
      "Epoch: [29][6/12]\tTime 0.080 (0.110)\tData 0.054 (0.084)\tLoss 0.9011 (0.8266)\tAcc 0.562 (0.688)\n",
      "Epoch: [29][7/12]\tTime 0.076 (0.105)\tData 0.052 (0.079)\tLoss 0.5625 (0.7889)\tAcc 0.750 (0.696)\n",
      "Epoch: [29][8/12]\tTime 0.078 (0.102)\tData 0.055 (0.076)\tLoss 0.4464 (0.7461)\tAcc 0.875 (0.719)\n",
      "Epoch: [29][9/12]\tTime 0.078 (0.099)\tData 0.055 (0.074)\tLoss 0.5096 (0.7198)\tAcc 0.688 (0.715)\n",
      "Epoch: [29][10/12]\tTime 0.078 (0.097)\tData 0.055 (0.072)\tLoss 0.7536 (0.7232)\tAcc 0.688 (0.713)\n",
      "Epoch: [29][11/12]\tTime 0.078 (0.095)\tData 0.055 (0.070)\tLoss 0.5803 (0.7102)\tAcc 0.812 (0.722)\n",
      "Epoch: [29][12/12]\tTime 0.078 (0.094)\tData 0.055 (0.069)\tLoss 0.6926 (0.7088)\tAcc 0.667 (0.717)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/18]\tTime 0.215 (0.215)\tData 0.186 (0.186)\tLoss 0.3434 (0.3434)\tAcc 0.875 (0.875)\n",
      "Epoch: [29][2/18]\tTime 0.068 (0.141)\tData 0.045 (0.116)\tLoss 0.8948 (0.6191)\tAcc 0.562 (0.719)\n",
      "Epoch: [29][3/18]\tTime 0.072 (0.118)\tData 0.052 (0.094)\tLoss 0.6107 (0.6163)\tAcc 0.625 (0.688)\n",
      "Epoch: [29][4/18]\tTime 0.073 (0.107)\tData 0.053 (0.084)\tLoss 0.5747 (0.6059)\tAcc 0.875 (0.734)\n",
      "Epoch: [29][5/18]\tTime 0.074 (0.100)\tData 0.054 (0.078)\tLoss 0.8215 (0.6490)\tAcc 0.750 (0.738)\n",
      "Epoch: [29][6/18]\tTime 0.074 (0.096)\tData 0.053 (0.074)\tLoss 0.3241 (0.5949)\tAcc 0.938 (0.771)\n",
      "Epoch: [29][7/18]\tTime 0.074 (0.093)\tData 0.053 (0.071)\tLoss 0.6332 (0.6004)\tAcc 0.812 (0.777)\n",
      "Epoch: [29][8/18]\tTime 0.073 (0.090)\tData 0.053 (0.069)\tLoss 1.0085 (0.6514)\tAcc 0.562 (0.750)\n",
      "Epoch: [29][9/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.1480 (0.5955)\tAcc 1.000 (0.778)\n",
      "Epoch: [29][10/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 0.9888 (0.6348)\tAcc 0.688 (0.769)\n",
      "Epoch: [29][11/18]\tTime 0.072 (0.086)\tData 0.053 (0.064)\tLoss 1.1104 (0.6780)\tAcc 0.375 (0.733)\n",
      "Epoch: [29][12/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.8014 (0.6883)\tAcc 0.750 (0.734)\n",
      "Epoch: [29][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 1.1777 (0.7260)\tAcc 0.562 (0.721)\n",
      "Epoch: [29][14/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.7889 (0.7305)\tAcc 0.562 (0.710)\n",
      "Epoch: [29][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.6806 (0.7271)\tAcc 0.750 (0.713)\n",
      "Epoch: [29][16/18]\tTime 0.074 (0.082)\tData 0.055 (0.061)\tLoss 0.7727 (0.7300)\tAcc 0.625 (0.707)\n",
      "Epoch: [29][17/18]\tTime 0.074 (0.082)\tData 0.055 (0.061)\tLoss 0.8862 (0.7392)\tAcc 0.562 (0.699)\n",
      "Epoch: [29][18/18]\tTime 0.074 (0.081)\tData 0.054 (0.061)\tLoss 0.8435 (0.7422)\tAcc 0.625 (0.696)\n",
      "train at epoch 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][1/12]\tTime 0.336 (0.336)\tData 0.307 (0.307)\tLoss 0.7384 (0.7384)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][2/12]\tTime 0.076 (0.206)\tData 0.050 (0.178)\tLoss 0.7625 (0.7504)\tAcc 0.625 (0.656)\n",
      "Epoch: [30][3/12]\tTime 0.077 (0.163)\tData 0.053 (0.136)\tLoss 0.6292 (0.7100)\tAcc 0.812 (0.708)\n",
      "Epoch: [30][4/12]\tTime 0.078 (0.142)\tData 0.054 (0.116)\tLoss 0.7986 (0.7322)\tAcc 0.688 (0.703)\n",
      "Epoch: [30][5/12]\tTime 0.079 (0.129)\tData 0.053 (0.103)\tLoss 0.4893 (0.6836)\tAcc 0.812 (0.725)\n",
      "Epoch: [30][6/12]\tTime 0.079 (0.121)\tData 0.053 (0.095)\tLoss 0.5871 (0.6675)\tAcc 0.625 (0.708)\n",
      "Epoch: [30][7/12]\tTime 0.077 (0.114)\tData 0.053 (0.089)\tLoss 0.5342 (0.6485)\tAcc 0.750 (0.714)\n",
      "Epoch: [30][8/12]\tTime 0.078 (0.110)\tData 0.054 (0.085)\tLoss 0.5465 (0.6357)\tAcc 0.812 (0.727)\n",
      "Epoch: [30][9/12]\tTime 0.078 (0.106)\tData 0.054 (0.081)\tLoss 1.0691 (0.6839)\tAcc 0.625 (0.715)\n",
      "Epoch: [30][10/12]\tTime 0.079 (0.104)\tData 0.054 (0.078)\tLoss 0.4576 (0.6613)\tAcc 0.750 (0.719)\n",
      "Epoch: [30][11/12]\tTime 0.079 (0.101)\tData 0.056 (0.076)\tLoss 0.5677 (0.6528)\tAcc 0.812 (0.727)\n",
      "Epoch: [30][12/12]\tTime 0.078 (0.099)\tData 0.055 (0.075)\tLoss 0.7219 (0.6582)\tAcc 0.667 (0.723)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/18]\tTime 0.227 (0.227)\tData 0.198 (0.198)\tLoss 0.2192 (0.2192)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/18]\tTime 0.069 (0.148)\tData 0.046 (0.122)\tLoss 0.9085 (0.5638)\tAcc 0.562 (0.750)\n",
      "Epoch: [30][3/18]\tTime 0.071 (0.123)\tData 0.051 (0.098)\tLoss 0.6353 (0.5876)\tAcc 0.750 (0.750)\n",
      "Epoch: [30][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.5823 (0.5863)\tAcc 0.812 (0.766)\n",
      "Epoch: [30][5/18]\tTime 0.074 (0.103)\tData 0.053 (0.080)\tLoss 0.8693 (0.6429)\tAcc 0.625 (0.738)\n",
      "Epoch: [30][6/18]\tTime 0.074 (0.098)\tData 0.053 (0.076)\tLoss 0.2499 (0.5774)\tAcc 0.938 (0.771)\n",
      "Epoch: [30][7/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.5639 (0.5755)\tAcc 0.812 (0.777)\n",
      "Epoch: [30][8/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 1.0381 (0.6333)\tAcc 0.562 (0.750)\n",
      "Epoch: [30][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.068)\tLoss 0.1725 (0.5821)\tAcc 1.000 (0.778)\n",
      "Epoch: [30][10/18]\tTime 0.073 (0.088)\tData 0.053 (0.067)\tLoss 1.0024 (0.6241)\tAcc 0.625 (0.762)\n",
      "Epoch: [30][11/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 1.2596 (0.6819)\tAcc 0.375 (0.727)\n",
      "Epoch: [30][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.9913 (0.7077)\tAcc 0.750 (0.729)\n",
      "Epoch: [30][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1470 (0.7415)\tAcc 0.438 (0.707)\n",
      "Epoch: [30][14/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.9217 (0.7543)\tAcc 0.688 (0.705)\n",
      "Epoch: [30][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.9128 (0.7649)\tAcc 0.688 (0.704)\n",
      "Epoch: [30][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.7518 (0.7641)\tAcc 0.625 (0.699)\n",
      "Epoch: [30][17/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.8033 (0.7664)\tAcc 0.625 (0.695)\n",
      "Epoch: [30][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.7915 (0.7671)\tAcc 0.625 (0.693)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/12]\tTime 0.375 (0.375)\tData 0.346 (0.346)\tLoss 0.3744 (0.3744)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/12]\tTime 0.076 (0.225)\tData 0.050 (0.198)\tLoss 0.3005 (0.3374)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][3/12]\tTime 0.079 (0.176)\tData 0.053 (0.150)\tLoss 0.9058 (0.5269)\tAcc 0.625 (0.833)\n",
      "Epoch: [31][4/12]\tTime 0.079 (0.152)\tData 0.052 (0.126)\tLoss 0.5084 (0.5223)\tAcc 0.750 (0.812)\n",
      "Epoch: [31][5/12]\tTime 0.080 (0.138)\tData 0.054 (0.111)\tLoss 0.6113 (0.5401)\tAcc 0.812 (0.812)\n",
      "Epoch: [31][6/12]\tTime 0.078 (0.128)\tData 0.054 (0.102)\tLoss 0.8281 (0.5881)\tAcc 0.688 (0.792)\n",
      "Epoch: [31][7/12]\tTime 0.078 (0.121)\tData 0.054 (0.095)\tLoss 0.5286 (0.5796)\tAcc 0.750 (0.786)\n",
      "Epoch: [31][8/12]\tTime 0.078 (0.115)\tData 0.054 (0.090)\tLoss 0.5716 (0.5786)\tAcc 0.812 (0.789)\n",
      "Epoch: [31][9/12]\tTime 0.078 (0.111)\tData 0.054 (0.086)\tLoss 1.1292 (0.6398)\tAcc 0.625 (0.771)\n",
      "Epoch: [31][10/12]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 1.4122 (0.7170)\tAcc 0.375 (0.731)\n",
      "Epoch: [31][11/12]\tTime 0.078 (0.105)\tData 0.054 (0.080)\tLoss 0.3341 (0.6822)\tAcc 0.938 (0.750)\n",
      "Epoch: [31][12/12]\tTime 0.078 (0.103)\tData 0.054 (0.078)\tLoss 1.1050 (0.7154)\tAcc 0.600 (0.738)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/18]\tTime 0.215 (0.215)\tData 0.185 (0.185)\tLoss 0.2989 (0.2989)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/18]\tTime 0.066 (0.140)\tData 0.045 (0.115)\tLoss 0.8250 (0.5619)\tAcc 0.688 (0.812)\n",
      "Epoch: [31][3/18]\tTime 0.074 (0.118)\tData 0.053 (0.094)\tLoss 0.6136 (0.5791)\tAcc 0.562 (0.729)\n",
      "Epoch: [31][4/18]\tTime 0.073 (0.107)\tData 0.053 (0.084)\tLoss 0.5474 (0.5712)\tAcc 0.875 (0.766)\n",
      "Epoch: [31][5/18]\tTime 0.074 (0.100)\tData 0.053 (0.078)\tLoss 0.7773 (0.6124)\tAcc 0.625 (0.738)\n",
      "Epoch: [31][6/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.2964 (0.5598)\tAcc 0.938 (0.771)\n",
      "Epoch: [31][7/18]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.6667 (0.5750)\tAcc 0.688 (0.759)\n",
      "Epoch: [31][8/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 1.0657 (0.6364)\tAcc 0.438 (0.719)\n",
      "Epoch: [31][9/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.1094 (0.5778)\tAcc 1.000 (0.750)\n",
      "Epoch: [31][10/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.1322 (0.6333)\tAcc 0.562 (0.731)\n",
      "Epoch: [31][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.4475 (0.7073)\tAcc 0.500 (0.710)\n",
      "Epoch: [31][12/18]\tTime 0.073 (0.085)\tData 0.055 (0.064)\tLoss 0.9650 (0.7288)\tAcc 0.688 (0.708)\n",
      "Epoch: [31][13/18]\tTime 0.073 (0.084)\tData 0.055 (0.063)\tLoss 1.1653 (0.7623)\tAcc 0.438 (0.688)\n",
      "Epoch: [31][14/18]\tTime 0.074 (0.083)\tData 0.055 (0.063)\tLoss 0.7009 (0.7580)\tAcc 0.625 (0.683)\n",
      "Epoch: [31][15/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.8366 (0.7632)\tAcc 0.625 (0.679)\n",
      "Epoch: [31][16/18]\tTime 0.073 (0.082)\tData 0.055 (0.062)\tLoss 0.8399 (0.7680)\tAcc 0.625 (0.676)\n",
      "Epoch: [31][17/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.7782 (0.7686)\tAcc 0.750 (0.680)\n",
      "Epoch: [31][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.8031 (0.7696)\tAcc 0.625 (0.679)\n",
      "train at epoch 32\n",
      "Epoch: [32][1/12]\tTime 0.300 (0.300)\tData 0.268 (0.268)\tLoss 0.8770 (0.8770)\tAcc 0.625 (0.625)\n",
      "Epoch: [32][2/12]\tTime 0.073 (0.186)\tData 0.048 (0.158)\tLoss 0.4344 (0.6557)\tAcc 0.812 (0.719)\n",
      "Epoch: [32][3/12]\tTime 0.078 (0.150)\tData 0.053 (0.123)\tLoss 0.7730 (0.6948)\tAcc 0.750 (0.729)\n",
      "Epoch: [32][4/12]\tTime 0.079 (0.133)\tData 0.053 (0.105)\tLoss 0.6364 (0.6802)\tAcc 0.750 (0.734)\n",
      "Epoch: [32][5/12]\tTime 0.078 (0.122)\tData 0.052 (0.095)\tLoss 0.6672 (0.6776)\tAcc 0.750 (0.738)\n",
      "Epoch: [32][6/12]\tTime 0.079 (0.114)\tData 0.054 (0.088)\tLoss 0.7014 (0.6816)\tAcc 0.625 (0.719)\n",
      "Epoch: [32][7/12]\tTime 0.077 (0.109)\tData 0.053 (0.083)\tLoss 0.6107 (0.6715)\tAcc 0.812 (0.732)\n",
      "Epoch: [32][8/12]\tTime 0.077 (0.105)\tData 0.054 (0.079)\tLoss 0.4756 (0.6470)\tAcc 0.750 (0.734)\n",
      "Epoch: [32][9/12]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.7086 (0.6538)\tAcc 0.750 (0.736)\n",
      "Epoch: [32][10/12]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 1.2149 (0.7099)\tAcc 0.625 (0.725)\n",
      "Epoch: [32][11/12]\tTime 0.078 (0.098)\tData 0.055 (0.073)\tLoss 0.6274 (0.7024)\tAcc 0.875 (0.739)\n",
      "Epoch: [32][12/12]\tTime 0.077 (0.096)\tData 0.054 (0.071)\tLoss 0.6144 (0.6955)\tAcc 0.733 (0.738)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/18]\tTime 0.219 (0.219)\tData 0.193 (0.193)\tLoss 0.2902 (0.2902)\tAcc 1.000 (1.000)\n",
      "Epoch: [32][2/18]\tTime 0.073 (0.146)\tData 0.049 (0.121)\tLoss 0.8256 (0.5579)\tAcc 0.812 (0.906)\n",
      "Epoch: [32][3/18]\tTime 0.070 (0.121)\tData 0.049 (0.097)\tLoss 0.6136 (0.5765)\tAcc 0.688 (0.833)\n",
      "Epoch: [32][4/18]\tTime 0.073 (0.109)\tData 0.053 (0.086)\tLoss 0.5775 (0.5767)\tAcc 0.812 (0.828)\n",
      "Epoch: [32][5/18]\tTime 0.074 (0.102)\tData 0.054 (0.080)\tLoss 0.8066 (0.6227)\tAcc 0.625 (0.788)\n",
      "Epoch: [32][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.3889 (0.5837)\tAcc 0.938 (0.812)\n",
      "Epoch: [32][7/18]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.6421 (0.5921)\tAcc 0.875 (0.821)\n",
      "Epoch: [32][8/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.9777 (0.6403)\tAcc 0.688 (0.805)\n",
      "Epoch: [32][9/18]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.1425 (0.5850)\tAcc 1.000 (0.826)\n",
      "Epoch: [32][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1032 (0.6368)\tAcc 0.688 (0.812)\n",
      "Epoch: [32][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.066)\tLoss 1.2662 (0.6940)\tAcc 0.375 (0.773)\n",
      "Epoch: [32][12/18]\tTime 0.073 (0.085)\tData 0.055 (0.065)\tLoss 0.9136 (0.7123)\tAcc 0.812 (0.776)\n",
      "Epoch: [32][13/18]\tTime 0.073 (0.084)\tData 0.055 (0.064)\tLoss 1.1734 (0.7478)\tAcc 0.562 (0.760)\n",
      "Epoch: [32][14/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.8258 (0.7533)\tAcc 0.500 (0.741)\n",
      "Epoch: [32][15/18]\tTime 0.074 (0.083)\tData 0.054 (0.063)\tLoss 0.9142 (0.7641)\tAcc 0.688 (0.738)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][16/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.7951 (0.7660)\tAcc 0.625 (0.730)\n",
      "Epoch: [32][17/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.8029 (0.7682)\tAcc 0.688 (0.728)\n",
      "Epoch: [32][18/18]\tTime 0.073 (0.081)\tData 0.055 (0.061)\tLoss 0.6379 (0.7644)\tAcc 1.000 (0.736)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/12]\tTime 0.285 (0.285)\tData 0.257 (0.257)\tLoss 0.8244 (0.8244)\tAcc 0.625 (0.625)\n",
      "Epoch: [33][2/12]\tTime 0.075 (0.180)\tData 0.051 (0.154)\tLoss 0.6873 (0.7559)\tAcc 0.625 (0.625)\n",
      "Epoch: [33][3/12]\tTime 0.079 (0.147)\tData 0.054 (0.120)\tLoss 0.7962 (0.7693)\tAcc 0.750 (0.667)\n",
      "Epoch: [33][4/12]\tTime 0.080 (0.130)\tData 0.052 (0.103)\tLoss 0.7619 (0.7675)\tAcc 0.625 (0.656)\n",
      "Epoch: [33][5/12]\tTime 0.077 (0.119)\tData 0.050 (0.093)\tLoss 0.6382 (0.7416)\tAcc 0.750 (0.675)\n",
      "Epoch: [33][6/12]\tTime 0.078 (0.112)\tData 0.052 (0.086)\tLoss 0.3692 (0.6795)\tAcc 0.875 (0.708)\n",
      "Epoch: [33][7/12]\tTime 0.076 (0.107)\tData 0.052 (0.081)\tLoss 0.9195 (0.7138)\tAcc 0.625 (0.696)\n",
      "Epoch: [33][8/12]\tTime 0.078 (0.104)\tData 0.054 (0.078)\tLoss 0.3771 (0.6717)\tAcc 0.938 (0.727)\n",
      "Epoch: [33][9/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.6553 (0.6699)\tAcc 0.812 (0.736)\n",
      "Epoch: [33][10/12]\tTime 0.078 (0.098)\tData 0.055 (0.073)\tLoss 0.7447 (0.6774)\tAcc 0.812 (0.744)\n",
      "Epoch: [33][11/12]\tTime 0.078 (0.097)\tData 0.055 (0.071)\tLoss 0.7878 (0.6874)\tAcc 0.812 (0.750)\n",
      "Epoch: [33][12/12]\tTime 0.078 (0.095)\tData 0.055 (0.070)\tLoss 0.7600 (0.6931)\tAcc 0.667 (0.743)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/18]\tTime 0.218 (0.218)\tData 0.192 (0.192)\tLoss 0.2081 (0.2081)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/18]\tTime 0.072 (0.145)\tData 0.048 (0.120)\tLoss 1.0496 (0.6288)\tAcc 0.500 (0.719)\n",
      "Epoch: [33][3/18]\tTime 0.071 (0.120)\tData 0.050 (0.097)\tLoss 0.6388 (0.6321)\tAcc 0.688 (0.708)\n",
      "Epoch: [33][4/18]\tTime 0.073 (0.109)\tData 0.053 (0.086)\tLoss 0.5828 (0.6198)\tAcc 0.750 (0.719)\n",
      "Epoch: [33][5/18]\tTime 0.074 (0.102)\tData 0.053 (0.079)\tLoss 0.7340 (0.6426)\tAcc 0.688 (0.713)\n",
      "Epoch: [33][6/18]\tTime 0.073 (0.097)\tData 0.053 (0.075)\tLoss 0.2087 (0.5703)\tAcc 1.000 (0.760)\n",
      "Epoch: [33][7/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 0.5734 (0.5708)\tAcc 0.750 (0.759)\n",
      "Epoch: [33][8/18]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 1.0215 (0.6271)\tAcc 0.625 (0.742)\n",
      "Epoch: [33][9/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.0632 (0.5644)\tAcc 1.000 (0.771)\n",
      "Epoch: [33][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 1.2502 (0.6330)\tAcc 0.562 (0.750)\n",
      "Epoch: [33][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.2777 (0.6916)\tAcc 0.375 (0.716)\n",
      "Epoch: [33][12/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1381 (0.7288)\tAcc 0.750 (0.719)\n",
      "Epoch: [33][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.064)\tLoss 1.4470 (0.7841)\tAcc 0.375 (0.692)\n",
      "Epoch: [33][14/18]\tTime 0.074 (0.083)\tData 0.054 (0.063)\tLoss 0.8658 (0.7899)\tAcc 0.562 (0.683)\n",
      "Epoch: [33][15/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.9325 (0.7994)\tAcc 0.688 (0.683)\n",
      "Epoch: [33][16/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.8747 (0.8041)\tAcc 0.625 (0.680)\n",
      "Epoch: [33][17/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.8249 (0.8053)\tAcc 0.625 (0.676)\n",
      "Epoch: [33][18/18]\tTime 0.073 (0.081)\tData 0.055 (0.061)\tLoss 0.7832 (0.8047)\tAcc 0.625 (0.675)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/12]\tTime 0.503 (0.503)\tData 0.458 (0.458)\tLoss 0.6084 (0.6084)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][2/12]\tTime 0.060 (0.281)\tData 0.034 (0.246)\tLoss 0.3506 (0.4795)\tAcc 0.875 (0.812)\n",
      "Epoch: [34][3/12]\tTime 0.079 (0.214)\tData 0.054 (0.182)\tLoss 0.5507 (0.5032)\tAcc 0.875 (0.833)\n",
      "Epoch: [34][4/12]\tTime 0.079 (0.180)\tData 0.054 (0.150)\tLoss 0.5380 (0.5119)\tAcc 0.750 (0.812)\n",
      "Epoch: [34][5/12]\tTime 0.080 (0.160)\tData 0.054 (0.131)\tLoss 0.6286 (0.5353)\tAcc 0.812 (0.812)\n",
      "Epoch: [34][6/12]\tTime 0.076 (0.146)\tData 0.052 (0.118)\tLoss 1.2707 (0.6579)\tAcc 0.375 (0.740)\n",
      "Epoch: [34][7/12]\tTime 0.078 (0.136)\tData 0.054 (0.108)\tLoss 0.5319 (0.6399)\tAcc 0.812 (0.750)\n",
      "Epoch: [34][8/12]\tTime 0.078 (0.129)\tData 0.054 (0.102)\tLoss 0.5375 (0.6271)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][9/12]\tTime 0.078 (0.123)\tData 0.054 (0.096)\tLoss 0.5107 (0.6141)\tAcc 0.812 (0.757)\n",
      "Epoch: [34][10/12]\tTime 0.078 (0.119)\tData 0.054 (0.092)\tLoss 0.5389 (0.6066)\tAcc 0.875 (0.769)\n",
      "Epoch: [34][11/12]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.6943 (0.6146)\tAcc 0.625 (0.756)\n",
      "Epoch: [34][12/12]\tTime 0.078 (0.112)\tData 0.054 (0.086)\tLoss 0.6129 (0.6144)\tAcc 0.667 (0.749)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/18]\tTime 0.214 (0.214)\tData 0.185 (0.185)\tLoss 0.2938 (0.2938)\tAcc 0.938 (0.938)\n",
      "Epoch: [34][2/18]\tTime 0.067 (0.140)\tData 0.046 (0.115)\tLoss 0.8851 (0.5894)\tAcc 0.562 (0.750)\n",
      "Epoch: [34][3/18]\tTime 0.073 (0.118)\tData 0.053 (0.094)\tLoss 0.6637 (0.6142)\tAcc 0.812 (0.771)\n",
      "Epoch: [34][4/18]\tTime 0.073 (0.107)\tData 0.053 (0.084)\tLoss 0.6098 (0.6131)\tAcc 0.688 (0.750)\n",
      "Epoch: [34][5/18]\tTime 0.074 (0.100)\tData 0.053 (0.078)\tLoss 0.7360 (0.6377)\tAcc 0.688 (0.738)\n",
      "Epoch: [34][6/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.3548 (0.5905)\tAcc 1.000 (0.781)\n",
      "Epoch: [34][7/18]\tTime 0.073 (0.093)\tData 0.053 (0.071)\tLoss 0.7605 (0.6148)\tAcc 0.688 (0.768)\n",
      "Epoch: [34][8/18]\tTime 0.073 (0.090)\tData 0.053 (0.069)\tLoss 1.0691 (0.6716)\tAcc 0.562 (0.742)\n",
      "Epoch: [34][9/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.1534 (0.6140)\tAcc 1.000 (0.771)\n",
      "Epoch: [34][10/18]\tTime 0.074 (0.087)\tData 0.053 (0.066)\tLoss 0.9992 (0.6525)\tAcc 0.625 (0.756)\n",
      "Epoch: [34][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.1821 (0.7007)\tAcc 0.375 (0.722)\n",
      "Epoch: [34][12/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.7895 (0.7081)\tAcc 0.812 (0.729)\n",
      "Epoch: [34][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.9258 (0.7248)\tAcc 0.812 (0.736)\n",
      "Epoch: [34][14/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.7827 (0.7290)\tAcc 0.625 (0.728)\n",
      "Epoch: [34][15/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.8168 (0.7348)\tAcc 0.750 (0.729)\n",
      "Epoch: [34][16/18]\tTime 0.074 (0.082)\tData 0.054 (0.061)\tLoss 0.8185 (0.7400)\tAcc 0.750 (0.730)\n",
      "Epoch: [34][17/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.7526 (0.7408)\tAcc 0.625 (0.724)\n",
      "Epoch: [34][18/18]\tTime 0.073 (0.081)\tData 0.055 (0.061)\tLoss 0.9270 (0.7461)\tAcc 0.750 (0.725)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/12]\tTime 0.256 (0.256)\tData 0.219 (0.219)\tLoss 0.4903 (0.4903)\tAcc 0.812 (0.812)\n",
      "Epoch: [35][2/12]\tTime 0.068 (0.162)\tData 0.042 (0.130)\tLoss 0.8182 (0.6543)\tAcc 0.750 (0.781)\n",
      "Epoch: [35][3/12]\tTime 0.080 (0.134)\tData 0.053 (0.105)\tLoss 0.4980 (0.6022)\tAcc 0.875 (0.812)\n",
      "Epoch: [35][4/12]\tTime 0.077 (0.120)\tData 0.052 (0.091)\tLoss 0.9865 (0.6983)\tAcc 0.562 (0.750)\n",
      "Epoch: [35][5/12]\tTime 0.078 (0.112)\tData 0.053 (0.084)\tLoss 0.6855 (0.6957)\tAcc 0.625 (0.725)\n",
      "Epoch: [35][6/12]\tTime 0.077 (0.106)\tData 0.053 (0.079)\tLoss 0.5119 (0.6651)\tAcc 0.875 (0.750)\n",
      "Epoch: [35][7/12]\tTime 0.078 (0.102)\tData 0.054 (0.075)\tLoss 0.7133 (0.6720)\tAcc 0.812 (0.759)\n",
      "Epoch: [35][8/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.8222 (0.6907)\tAcc 0.625 (0.742)\n",
      "Epoch: [35][9/12]\tTime 0.078 (0.097)\tData 0.054 (0.070)\tLoss 0.6934 (0.6910)\tAcc 0.688 (0.736)\n",
      "Epoch: [35][10/12]\tTime 0.083 (0.095)\tData 0.058 (0.069)\tLoss 0.3676 (0.6587)\tAcc 0.875 (0.750)\n",
      "Epoch: [35][11/12]\tTime 0.084 (0.094)\tData 0.059 (0.068)\tLoss 0.6694 (0.6597)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][12/12]\tTime 0.083 (0.093)\tData 0.058 (0.067)\tLoss 0.5530 (0.6513)\tAcc 0.800 (0.754)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/18]\tTime 0.270 (0.270)\tData 0.231 (0.231)\tLoss 0.2569 (0.2569)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/18]\tTime 0.064 (0.167)\tData 0.043 (0.137)\tLoss 0.8855 (0.5712)\tAcc 0.500 (0.719)\n",
      "Epoch: [35][3/18]\tTime 0.081 (0.138)\tData 0.059 (0.111)\tLoss 0.6758 (0.6060)\tAcc 0.625 (0.688)\n",
      "Epoch: [35][4/18]\tTime 0.077 (0.123)\tData 0.057 (0.097)\tLoss 0.6398 (0.6145)\tAcc 0.688 (0.688)\n",
      "Epoch: [35][5/18]\tTime 0.081 (0.115)\tData 0.061 (0.090)\tLoss 0.8899 (0.6696)\tAcc 0.688 (0.688)\n",
      "Epoch: [35][6/18]\tTime 0.079 (0.109)\tData 0.059 (0.085)\tLoss 0.2862 (0.6057)\tAcc 1.000 (0.740)\n",
      "Epoch: [35][7/18]\tTime 0.078 (0.104)\tData 0.057 (0.081)\tLoss 0.6830 (0.6167)\tAcc 0.688 (0.732)\n",
      "Epoch: [35][8/18]\tTime 0.075 (0.101)\tData 0.054 (0.078)\tLoss 0.9608 (0.6597)\tAcc 0.688 (0.727)\n",
      "Epoch: [35][9/18]\tTime 0.078 (0.098)\tData 0.058 (0.075)\tLoss 0.0847 (0.5958)\tAcc 1.000 (0.757)\n",
      "Epoch: [35][10/18]\tTime 0.080 (0.096)\tData 0.057 (0.074)\tLoss 1.2478 (0.6610)\tAcc 0.625 (0.744)\n",
      "Epoch: [35][11/18]\tTime 0.084 (0.095)\tData 0.064 (0.073)\tLoss 1.3115 (0.7202)\tAcc 0.375 (0.710)\n",
      "Epoch: [35][12/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.8519 (0.7311)\tAcc 0.812 (0.719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.0051 (0.7522)\tAcc 0.562 (0.707)\n",
      "Epoch: [35][14/18]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 0.8577 (0.7597)\tAcc 0.625 (0.701)\n",
      "Epoch: [35][15/18]\tTime 0.079 (0.090)\tData 0.060 (0.069)\tLoss 0.8039 (0.7627)\tAcc 0.750 (0.704)\n",
      "Epoch: [35][16/18]\tTime 0.076 (0.090)\tData 0.056 (0.068)\tLoss 0.7360 (0.7610)\tAcc 0.688 (0.703)\n",
      "Epoch: [35][17/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 0.7743 (0.7618)\tAcc 0.688 (0.702)\n",
      "Epoch: [35][18/18]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 0.7307 (0.7609)\tAcc 0.875 (0.707)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/12]\tTime 0.270 (0.270)\tData 0.239 (0.239)\tLoss 0.8620 (0.8620)\tAcc 0.625 (0.625)\n",
      "Epoch: [36][2/12]\tTime 0.079 (0.175)\tData 0.054 (0.146)\tLoss 0.7870 (0.8245)\tAcc 0.812 (0.719)\n",
      "Epoch: [36][3/12]\tTime 0.086 (0.145)\tData 0.060 (0.118)\tLoss 1.1300 (0.9263)\tAcc 0.500 (0.646)\n",
      "Epoch: [36][4/12]\tTime 0.083 (0.130)\tData 0.058 (0.103)\tLoss 0.7585 (0.8844)\tAcc 0.750 (0.672)\n",
      "Epoch: [36][5/12]\tTime 0.082 (0.120)\tData 0.058 (0.094)\tLoss 0.7730 (0.8621)\tAcc 0.688 (0.675)\n",
      "Epoch: [36][6/12]\tTime 0.086 (0.115)\tData 0.059 (0.088)\tLoss 0.3155 (0.7710)\tAcc 0.938 (0.719)\n",
      "Epoch: [36][7/12]\tTime 0.081 (0.110)\tData 0.056 (0.083)\tLoss 0.6772 (0.7576)\tAcc 0.750 (0.723)\n",
      "Epoch: [36][8/12]\tTime 0.082 (0.106)\tData 0.059 (0.080)\tLoss 0.6654 (0.7461)\tAcc 0.625 (0.711)\n",
      "Epoch: [36][9/12]\tTime 0.084 (0.104)\tData 0.059 (0.078)\tLoss 0.6163 (0.7317)\tAcc 0.750 (0.715)\n",
      "Epoch: [36][10/12]\tTime 0.083 (0.102)\tData 0.058 (0.076)\tLoss 0.3721 (0.6957)\tAcc 0.875 (0.731)\n",
      "Epoch: [36][11/12]\tTime 0.082 (0.100)\tData 0.058 (0.074)\tLoss 0.6806 (0.6943)\tAcc 0.812 (0.739)\n",
      "Epoch: [36][12/12]\tTime 0.078 (0.098)\tData 0.055 (0.073)\tLoss 0.6010 (0.6870)\tAcc 0.733 (0.738)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/18]\tTime 0.220 (0.220)\tData 0.190 (0.190)\tLoss 0.4340 (0.4340)\tAcc 0.875 (0.875)\n",
      "Epoch: [36][2/18]\tTime 0.067 (0.143)\tData 0.045 (0.118)\tLoss 0.8483 (0.6412)\tAcc 0.688 (0.781)\n",
      "Epoch: [36][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.5863 (0.6229)\tAcc 0.688 (0.750)\n",
      "Epoch: [36][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.5616 (0.6076)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][5/18]\tTime 0.075 (0.102)\tData 0.055 (0.079)\tLoss 0.8732 (0.6607)\tAcc 0.688 (0.738)\n",
      "Epoch: [36][6/18]\tTime 0.073 (0.097)\tData 0.053 (0.075)\tLoss 0.3112 (0.6024)\tAcc 0.938 (0.771)\n",
      "Epoch: [36][7/18]\tTime 0.073 (0.093)\tData 0.053 (0.072)\tLoss 0.5907 (0.6008)\tAcc 0.875 (0.786)\n",
      "Epoch: [36][8/18]\tTime 0.076 (0.091)\tData 0.055 (0.070)\tLoss 0.9506 (0.6445)\tAcc 0.625 (0.766)\n",
      "Epoch: [36][9/18]\tTime 0.074 (0.089)\tData 0.053 (0.068)\tLoss 0.1095 (0.5850)\tAcc 1.000 (0.792)\n",
      "Epoch: [36][10/18]\tTime 0.074 (0.088)\tData 0.053 (0.066)\tLoss 1.0805 (0.6346)\tAcc 0.812 (0.794)\n",
      "Epoch: [36][11/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 1.3472 (0.6994)\tAcc 0.375 (0.756)\n",
      "Epoch: [36][12/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.9034 (0.7164)\tAcc 0.812 (0.760)\n",
      "Epoch: [36][13/18]\tTime 0.074 (0.084)\tData 0.054 (0.064)\tLoss 0.9366 (0.7333)\tAcc 0.625 (0.750)\n",
      "Epoch: [36][14/18]\tTime 0.075 (0.084)\tData 0.056 (0.063)\tLoss 0.8340 (0.7405)\tAcc 0.625 (0.741)\n",
      "Epoch: [36][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.7816 (0.7433)\tAcc 0.750 (0.742)\n",
      "Epoch: [36][16/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.7387 (0.7430)\tAcc 0.625 (0.734)\n",
      "Epoch: [36][17/18]\tTime 0.075 (0.082)\tData 0.055 (0.062)\tLoss 0.7366 (0.7426)\tAcc 0.625 (0.728)\n",
      "Epoch: [36][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.7333 (0.7423)\tAcc 0.750 (0.729)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/12]\tTime 0.276 (0.276)\tData 0.246 (0.246)\tLoss 0.7355 (0.7355)\tAcc 0.750 (0.750)\n",
      "Epoch: [37][2/12]\tTime 0.076 (0.176)\tData 0.050 (0.148)\tLoss 0.5977 (0.6666)\tAcc 0.688 (0.719)\n",
      "Epoch: [37][3/12]\tTime 0.078 (0.143)\tData 0.053 (0.116)\tLoss 0.5336 (0.6223)\tAcc 0.750 (0.729)\n",
      "Epoch: [37][4/12]\tTime 0.079 (0.127)\tData 0.053 (0.101)\tLoss 0.7246 (0.6479)\tAcc 0.750 (0.734)\n",
      "Epoch: [37][5/12]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 0.6360 (0.6455)\tAcc 0.688 (0.725)\n",
      "Epoch: [37][6/12]\tTime 0.078 (0.111)\tData 0.054 (0.085)\tLoss 0.5048 (0.6220)\tAcc 0.875 (0.750)\n",
      "Epoch: [37][7/12]\tTime 0.077 (0.106)\tData 0.054 (0.081)\tLoss 0.6951 (0.6325)\tAcc 0.750 (0.750)\n",
      "Epoch: [37][8/12]\tTime 0.079 (0.103)\tData 0.056 (0.077)\tLoss 0.7299 (0.6447)\tAcc 0.688 (0.742)\n",
      "Epoch: [37][9/12]\tTime 0.078 (0.100)\tData 0.055 (0.075)\tLoss 0.8071 (0.6627)\tAcc 0.750 (0.743)\n",
      "Epoch: [37][10/12]\tTime 0.078 (0.098)\tData 0.054 (0.073)\tLoss 0.6914 (0.6656)\tAcc 0.688 (0.738)\n",
      "Epoch: [37][11/12]\tTime 0.079 (0.096)\tData 0.056 (0.071)\tLoss 0.8384 (0.6813)\tAcc 0.625 (0.727)\n",
      "Epoch: [37][12/12]\tTime 0.078 (0.094)\tData 0.054 (0.070)\tLoss 0.4082 (0.6598)\tAcc 0.933 (0.743)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/18]\tTime 0.220 (0.220)\tData 0.196 (0.196)\tLoss 0.3120 (0.3120)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/18]\tTime 0.076 (0.148)\tData 0.051 (0.123)\tLoss 0.8927 (0.6023)\tAcc 0.688 (0.812)\n",
      "Epoch: [37][3/18]\tTime 0.069 (0.122)\tData 0.049 (0.098)\tLoss 0.6515 (0.6187)\tAcc 0.688 (0.771)\n",
      "Epoch: [37][4/18]\tTime 0.074 (0.110)\tData 0.053 (0.087)\tLoss 0.5489 (0.6013)\tAcc 0.750 (0.766)\n",
      "Epoch: [37][5/18]\tTime 0.075 (0.103)\tData 0.054 (0.081)\tLoss 0.7214 (0.6253)\tAcc 0.812 (0.775)\n",
      "Epoch: [37][6/18]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.2622 (0.5648)\tAcc 1.000 (0.812)\n",
      "Epoch: [37][7/18]\tTime 0.073 (0.094)\tData 0.053 (0.073)\tLoss 0.5044 (0.5562)\tAcc 0.938 (0.830)\n",
      "Epoch: [37][8/18]\tTime 0.075 (0.092)\tData 0.054 (0.070)\tLoss 0.9255 (0.6023)\tAcc 0.625 (0.805)\n",
      "Epoch: [37][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.069)\tLoss 0.1041 (0.5470)\tAcc 1.000 (0.826)\n",
      "Epoch: [37][10/18]\tTime 0.074 (0.088)\tData 0.053 (0.067)\tLoss 1.1713 (0.6094)\tAcc 0.500 (0.794)\n",
      "Epoch: [37][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.2286 (0.6657)\tAcc 0.375 (0.756)\n",
      "Epoch: [37][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8560 (0.6816)\tAcc 0.812 (0.760)\n",
      "Epoch: [37][13/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.9818 (0.7046)\tAcc 0.562 (0.745)\n",
      "Epoch: [37][14/18]\tTime 0.075 (0.084)\tData 0.056 (0.064)\tLoss 0.7730 (0.7095)\tAcc 0.625 (0.737)\n",
      "Epoch: [37][15/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.7850 (0.7146)\tAcc 0.750 (0.738)\n",
      "Epoch: [37][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.8013 (0.7200)\tAcc 0.812 (0.742)\n",
      "Epoch: [37][17/18]\tTime 0.075 (0.082)\tData 0.055 (0.062)\tLoss 0.7282 (0.7205)\tAcc 0.625 (0.735)\n",
      "Epoch: [37][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.7180 (0.7204)\tAcc 0.750 (0.736)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/12]\tTime 0.261 (0.261)\tData 0.230 (0.230)\tLoss 0.6824 (0.6824)\tAcc 0.688 (0.688)\n",
      "Epoch: [38][2/12]\tTime 0.075 (0.168)\tData 0.049 (0.140)\tLoss 0.5322 (0.6073)\tAcc 0.875 (0.781)\n",
      "Epoch: [38][3/12]\tTime 0.081 (0.139)\tData 0.053 (0.111)\tLoss 0.6917 (0.6354)\tAcc 0.750 (0.771)\n",
      "Epoch: [38][4/12]\tTime 0.075 (0.123)\tData 0.050 (0.096)\tLoss 0.6668 (0.6433)\tAcc 0.750 (0.766)\n",
      "Epoch: [38][5/12]\tTime 0.081 (0.115)\tData 0.055 (0.087)\tLoss 0.9250 (0.6996)\tAcc 0.625 (0.738)\n",
      "Epoch: [38][6/12]\tTime 0.077 (0.108)\tData 0.052 (0.082)\tLoss 0.6970 (0.6992)\tAcc 0.812 (0.750)\n",
      "Epoch: [38][7/12]\tTime 0.076 (0.104)\tData 0.053 (0.077)\tLoss 0.8898 (0.7264)\tAcc 0.625 (0.732)\n",
      "Epoch: [38][8/12]\tTime 0.080 (0.101)\tData 0.056 (0.075)\tLoss 0.8978 (0.7478)\tAcc 0.562 (0.711)\n",
      "Epoch: [38][9/12]\tTime 0.079 (0.098)\tData 0.055 (0.073)\tLoss 0.5726 (0.7284)\tAcc 0.750 (0.715)\n",
      "Epoch: [38][10/12]\tTime 0.078 (0.096)\tData 0.054 (0.071)\tLoss 0.6090 (0.7164)\tAcc 0.750 (0.719)\n",
      "Epoch: [38][11/12]\tTime 0.080 (0.095)\tData 0.056 (0.069)\tLoss 0.6277 (0.7084)\tAcc 0.812 (0.727)\n",
      "Epoch: [38][12/12]\tTime 0.077 (0.093)\tData 0.054 (0.068)\tLoss 0.6600 (0.7046)\tAcc 0.733 (0.728)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/18]\tTime 0.216 (0.216)\tData 0.189 (0.189)\tLoss 0.3378 (0.3378)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/18]\tTime 0.070 (0.143)\tData 0.048 (0.118)\tLoss 0.8575 (0.5976)\tAcc 0.562 (0.750)\n",
      "Epoch: [38][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.6120 (0.6024)\tAcc 0.688 (0.729)\n",
      "Epoch: [38][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.5767 (0.5960)\tAcc 0.625 (0.703)\n",
      "Epoch: [38][5/18]\tTime 0.075 (0.101)\tData 0.054 (0.079)\tLoss 0.8401 (0.6448)\tAcc 0.688 (0.700)\n",
      "Epoch: [38][6/18]\tTime 0.073 (0.097)\tData 0.053 (0.075)\tLoss 0.2984 (0.5871)\tAcc 1.000 (0.750)\n",
      "Epoch: [38][7/18]\tTime 0.074 (0.093)\tData 0.053 (0.072)\tLoss 0.6837 (0.6009)\tAcc 0.812 (0.759)\n",
      "Epoch: [38][8/18]\tTime 0.075 (0.091)\tData 0.055 (0.070)\tLoss 0.8791 (0.6357)\tAcc 0.688 (0.750)\n",
      "Epoch: [38][9/18]\tTime 0.073 (0.089)\tData 0.053 (0.068)\tLoss 0.1855 (0.5856)\tAcc 1.000 (0.778)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 1.1376 (0.6408)\tAcc 0.750 (0.775)\n",
      "Epoch: [38][11/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 1.0908 (0.6817)\tAcc 0.375 (0.739)\n",
      "Epoch: [38][12/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.8465 (0.6955)\tAcc 0.812 (0.745)\n",
      "Epoch: [38][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.064)\tLoss 1.2123 (0.7352)\tAcc 0.438 (0.721)\n",
      "Epoch: [38][14/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.7681 (0.7376)\tAcc 0.625 (0.714)\n",
      "Epoch: [38][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.9059 (0.7488)\tAcc 0.688 (0.713)\n",
      "Epoch: [38][16/18]\tTime 0.074 (0.082)\tData 0.054 (0.062)\tLoss 0.8656 (0.7561)\tAcc 0.562 (0.703)\n",
      "Epoch: [38][17/18]\tTime 0.075 (0.082)\tData 0.055 (0.062)\tLoss 0.7304 (0.7546)\tAcc 0.625 (0.699)\n",
      "Epoch: [38][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.8337 (0.7569)\tAcc 0.625 (0.696)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/12]\tTime 0.310 (0.310)\tData 0.279 (0.279)\tLoss 0.5784 (0.5784)\tAcc 0.812 (0.812)\n",
      "Epoch: [39][2/12]\tTime 0.073 (0.191)\tData 0.048 (0.164)\tLoss 0.6692 (0.6238)\tAcc 0.750 (0.781)\n",
      "Epoch: [39][3/12]\tTime 0.078 (0.154)\tData 0.053 (0.127)\tLoss 0.8292 (0.6923)\tAcc 0.625 (0.729)\n",
      "Epoch: [39][4/12]\tTime 0.080 (0.135)\tData 0.054 (0.108)\tLoss 0.6747 (0.6879)\tAcc 0.750 (0.734)\n",
      "Epoch: [39][5/12]\tTime 0.077 (0.124)\tData 0.053 (0.097)\tLoss 0.4172 (0.6337)\tAcc 0.875 (0.762)\n",
      "Epoch: [39][6/12]\tTime 0.079 (0.116)\tData 0.054 (0.090)\tLoss 0.8842 (0.6755)\tAcc 0.688 (0.750)\n",
      "Epoch: [39][7/12]\tTime 0.076 (0.110)\tData 0.052 (0.085)\tLoss 0.7954 (0.6926)\tAcc 0.688 (0.741)\n",
      "Epoch: [39][8/12]\tTime 0.079 (0.107)\tData 0.056 (0.081)\tLoss 0.3896 (0.6547)\tAcc 0.875 (0.758)\n",
      "Epoch: [39][9/12]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.7649 (0.6670)\tAcc 0.750 (0.757)\n",
      "Epoch: [39][10/12]\tTime 0.078 (0.101)\tData 0.055 (0.076)\tLoss 0.8688 (0.6872)\tAcc 0.688 (0.750)\n",
      "Epoch: [39][11/12]\tTime 0.079 (0.099)\tData 0.056 (0.074)\tLoss 0.5445 (0.6742)\tAcc 0.750 (0.750)\n",
      "Epoch: [39][12/12]\tTime 0.078 (0.097)\tData 0.055 (0.072)\tLoss 0.5952 (0.6680)\tAcc 0.733 (0.749)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/18]\tTime 0.221 (0.221)\tData 0.197 (0.197)\tLoss 0.3472 (0.3472)\tAcc 0.875 (0.875)\n",
      "Epoch: [39][2/18]\tTime 0.076 (0.149)\tData 0.051 (0.124)\tLoss 0.8297 (0.5885)\tAcc 0.625 (0.750)\n",
      "Epoch: [39][3/18]\tTime 0.069 (0.122)\tData 0.049 (0.099)\tLoss 0.5731 (0.5834)\tAcc 0.812 (0.771)\n",
      "Epoch: [39][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.088)\tLoss 0.5293 (0.5699)\tAcc 0.688 (0.750)\n",
      "Epoch: [39][5/18]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.8525 (0.6264)\tAcc 0.750 (0.750)\n",
      "Epoch: [39][6/18]\tTime 0.073 (0.098)\tData 0.054 (0.076)\tLoss 0.2893 (0.5702)\tAcc 1.000 (0.792)\n",
      "Epoch: [39][7/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.6082 (0.5756)\tAcc 0.750 (0.786)\n",
      "Epoch: [39][8/18]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.8294 (0.6074)\tAcc 0.750 (0.781)\n",
      "Epoch: [39][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.1482 (0.5563)\tAcc 1.000 (0.806)\n",
      "Epoch: [39][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1307 (0.6138)\tAcc 0.625 (0.788)\n",
      "Epoch: [39][11/18]\tTime 0.075 (0.087)\tData 0.054 (0.066)\tLoss 1.2777 (0.6741)\tAcc 0.375 (0.750)\n",
      "Epoch: [39][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8921 (0.6923)\tAcc 0.812 (0.755)\n",
      "Epoch: [39][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.9612 (0.7130)\tAcc 0.562 (0.740)\n",
      "Epoch: [39][14/18]\tTime 0.074 (0.084)\tData 0.054 (0.064)\tLoss 0.7452 (0.7153)\tAcc 0.625 (0.732)\n",
      "Epoch: [39][15/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.7562 (0.7180)\tAcc 0.750 (0.733)\n",
      "Epoch: [39][16/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.7925 (0.7227)\tAcc 0.812 (0.738)\n",
      "Epoch: [39][17/18]\tTime 0.075 (0.082)\tData 0.056 (0.062)\tLoss 0.8058 (0.7276)\tAcc 0.562 (0.728)\n",
      "Epoch: [39][18/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.6339 (0.7249)\tAcc 1.000 (0.736)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/12]\tTime 0.257 (0.257)\tData 0.224 (0.224)\tLoss 0.6504 (0.6504)\tAcc 0.812 (0.812)\n",
      "Epoch: [40][2/12]\tTime 0.072 (0.165)\tData 0.046 (0.135)\tLoss 0.9338 (0.7921)\tAcc 0.625 (0.719)\n",
      "Epoch: [40][3/12]\tTime 0.082 (0.137)\tData 0.053 (0.108)\tLoss 0.8170 (0.8004)\tAcc 0.688 (0.708)\n",
      "Epoch: [40][4/12]\tTime 0.074 (0.122)\tData 0.049 (0.093)\tLoss 0.6004 (0.7504)\tAcc 0.812 (0.734)\n",
      "Epoch: [40][5/12]\tTime 0.081 (0.113)\tData 0.054 (0.085)\tLoss 0.7996 (0.7602)\tAcc 0.750 (0.738)\n",
      "Epoch: [40][6/12]\tTime 0.075 (0.107)\tData 0.051 (0.080)\tLoss 0.4845 (0.7143)\tAcc 0.812 (0.750)\n",
      "Epoch: [40][7/12]\tTime 0.078 (0.103)\tData 0.054 (0.076)\tLoss 0.6096 (0.6993)\tAcc 0.688 (0.741)\n",
      "Epoch: [40][8/12]\tTime 0.079 (0.100)\tData 0.055 (0.073)\tLoss 0.7012 (0.6995)\tAcc 0.750 (0.742)\n",
      "Epoch: [40][9/12]\tTime 0.077 (0.097)\tData 0.054 (0.071)\tLoss 0.3810 (0.6642)\tAcc 0.875 (0.757)\n",
      "Epoch: [40][10/12]\tTime 0.079 (0.096)\tData 0.055 (0.070)\tLoss 0.6563 (0.6634)\tAcc 0.688 (0.750)\n",
      "Epoch: [40][11/12]\tTime 0.079 (0.094)\tData 0.056 (0.068)\tLoss 0.3633 (0.6361)\tAcc 0.875 (0.761)\n",
      "Epoch: [40][12/12]\tTime 0.078 (0.093)\tData 0.054 (0.067)\tLoss 0.4985 (0.6253)\tAcc 0.800 (0.764)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/18]\tTime 0.219 (0.219)\tData 0.194 (0.194)\tLoss 0.3354 (0.3354)\tAcc 0.875 (0.875)\n",
      "Epoch: [40][2/18]\tTime 0.074 (0.146)\tData 0.049 (0.121)\tLoss 0.8602 (0.5978)\tAcc 0.625 (0.750)\n",
      "Epoch: [40][3/18]\tTime 0.070 (0.121)\tData 0.050 (0.098)\tLoss 0.5987 (0.5981)\tAcc 0.812 (0.771)\n",
      "Epoch: [40][4/18]\tTime 0.073 (0.109)\tData 0.053 (0.086)\tLoss 0.5454 (0.5849)\tAcc 0.750 (0.766)\n",
      "Epoch: [40][5/18]\tTime 0.074 (0.102)\tData 0.054 (0.080)\tLoss 0.8191 (0.6318)\tAcc 0.750 (0.762)\n",
      "Epoch: [40][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.3159 (0.5791)\tAcc 1.000 (0.802)\n",
      "Epoch: [40][7/18]\tTime 0.073 (0.094)\tData 0.053 (0.073)\tLoss 0.6713 (0.5923)\tAcc 0.750 (0.795)\n",
      "Epoch: [40][8/18]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.9609 (0.6384)\tAcc 0.625 (0.773)\n",
      "Epoch: [40][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.1219 (0.5810)\tAcc 1.000 (0.799)\n",
      "Epoch: [40][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1549 (0.6384)\tAcc 0.625 (0.781)\n",
      "Epoch: [40][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.2202 (0.6913)\tAcc 0.375 (0.744)\n",
      "Epoch: [40][12/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.9459 (0.7125)\tAcc 0.812 (0.750)\n",
      "Epoch: [40][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1865 (0.7490)\tAcc 0.312 (0.716)\n",
      "Epoch: [40][14/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.6754 (0.7437)\tAcc 0.625 (0.710)\n",
      "Epoch: [40][15/18]\tTime 0.075 (0.083)\tData 0.055 (0.063)\tLoss 0.8520 (0.7509)\tAcc 0.688 (0.708)\n",
      "Epoch: [40][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 1.0035 (0.7667)\tAcc 0.562 (0.699)\n",
      "Epoch: [40][17/18]\tTime 0.075 (0.082)\tData 0.056 (0.062)\tLoss 0.7304 (0.7646)\tAcc 0.625 (0.695)\n",
      "Epoch: [40][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.8415 (0.7668)\tAcc 0.625 (0.693)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/12]\tTime 0.303 (0.303)\tData 0.273 (0.273)\tLoss 0.7875 (0.7875)\tAcc 0.625 (0.625)\n",
      "Epoch: [41][2/12]\tTime 0.076 (0.189)\tData 0.050 (0.162)\tLoss 0.6909 (0.7392)\tAcc 0.812 (0.719)\n",
      "Epoch: [41][3/12]\tTime 0.078 (0.152)\tData 0.053 (0.125)\tLoss 0.4697 (0.6494)\tAcc 0.812 (0.750)\n",
      "Epoch: [41][4/12]\tTime 0.078 (0.133)\tData 0.053 (0.107)\tLoss 0.4913 (0.6098)\tAcc 0.688 (0.734)\n",
      "Epoch: [41][5/12]\tTime 0.081 (0.123)\tData 0.055 (0.097)\tLoss 1.2228 (0.7324)\tAcc 0.500 (0.688)\n",
      "Epoch: [41][6/12]\tTime 0.078 (0.115)\tData 0.053 (0.090)\tLoss 0.5367 (0.6998)\tAcc 0.875 (0.719)\n",
      "Epoch: [41][7/12]\tTime 0.076 (0.110)\tData 0.052 (0.084)\tLoss 0.7175 (0.7023)\tAcc 0.812 (0.732)\n",
      "Epoch: [41][8/12]\tTime 0.078 (0.106)\tData 0.054 (0.080)\tLoss 0.8606 (0.7221)\tAcc 0.500 (0.703)\n",
      "Epoch: [41][9/12]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.4563 (0.6926)\tAcc 0.812 (0.715)\n",
      "Epoch: [41][10/12]\tTime 0.079 (0.100)\tData 0.055 (0.075)\tLoss 1.1321 (0.7365)\tAcc 0.562 (0.700)\n",
      "Epoch: [41][11/12]\tTime 0.079 (0.098)\tData 0.056 (0.074)\tLoss 0.6179 (0.7257)\tAcc 0.750 (0.705)\n",
      "Epoch: [41][12/12]\tTime 0.078 (0.097)\tData 0.054 (0.072)\tLoss 0.3956 (0.6998)\tAcc 0.867 (0.717)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/18]\tTime 0.220 (0.220)\tData 0.196 (0.196)\tLoss 0.3586 (0.3586)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/18]\tTime 0.075 (0.148)\tData 0.051 (0.123)\tLoss 0.9361 (0.6473)\tAcc 0.500 (0.719)\n",
      "Epoch: [41][3/18]\tTime 0.070 (0.122)\tData 0.049 (0.099)\tLoss 0.6166 (0.6371)\tAcc 0.688 (0.708)\n",
      "Epoch: [41][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.5970 (0.6271)\tAcc 0.688 (0.703)\n",
      "Epoch: [41][5/18]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.7764 (0.6569)\tAcc 0.750 (0.713)\n",
      "Epoch: [41][6/18]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.2994 (0.5973)\tAcc 0.938 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41][7/18]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.6439 (0.6040)\tAcc 0.688 (0.741)\n",
      "Epoch: [41][8/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.9589 (0.6484)\tAcc 0.625 (0.727)\n",
      "Epoch: [41][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.1327 (0.5911)\tAcc 1.000 (0.757)\n",
      "Epoch: [41][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1693 (0.6489)\tAcc 0.625 (0.744)\n",
      "Epoch: [41][11/18]\tTime 0.075 (0.087)\tData 0.055 (0.066)\tLoss 1.2439 (0.7030)\tAcc 0.375 (0.710)\n",
      "Epoch: [41][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.9359 (0.7224)\tAcc 0.812 (0.719)\n",
      "Epoch: [41][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1900 (0.7584)\tAcc 0.500 (0.702)\n",
      "Epoch: [41][14/18]\tTime 0.075 (0.084)\tData 0.056 (0.064)\tLoss 0.8164 (0.7625)\tAcc 0.625 (0.696)\n",
      "Epoch: [41][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.9506 (0.7750)\tAcc 0.688 (0.696)\n",
      "Epoch: [41][16/18]\tTime 0.073 (0.083)\tData 0.055 (0.063)\tLoss 0.6750 (0.7688)\tAcc 0.812 (0.703)\n",
      "Epoch: [41][17/18]\tTime 0.075 (0.082)\tData 0.056 (0.062)\tLoss 0.7941 (0.7703)\tAcc 0.625 (0.699)\n",
      "Epoch: [41][18/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.6332 (0.7664)\tAcc 0.875 (0.704)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/12]\tTime 0.284 (0.284)\tData 0.253 (0.253)\tLoss 0.8523 (0.8523)\tAcc 0.750 (0.750)\n",
      "Epoch: [42][2/12]\tTime 0.074 (0.179)\tData 0.049 (0.151)\tLoss 0.5661 (0.7092)\tAcc 0.750 (0.750)\n",
      "Epoch: [42][3/12]\tTime 0.080 (0.146)\tData 0.054 (0.119)\tLoss 0.9067 (0.7751)\tAcc 0.625 (0.708)\n",
      "Epoch: [42][4/12]\tTime 0.079 (0.129)\tData 0.052 (0.102)\tLoss 0.7318 (0.7642)\tAcc 0.688 (0.703)\n",
      "Epoch: [42][5/12]\tTime 0.077 (0.119)\tData 0.053 (0.092)\tLoss 0.9045 (0.7923)\tAcc 0.688 (0.700)\n",
      "Epoch: [42][6/12]\tTime 0.077 (0.112)\tData 0.054 (0.086)\tLoss 0.8156 (0.7962)\tAcc 0.625 (0.688)\n",
      "Epoch: [42][7/12]\tTime 0.077 (0.107)\tData 0.054 (0.081)\tLoss 0.6244 (0.7716)\tAcc 0.750 (0.696)\n",
      "Epoch: [42][8/12]\tTime 0.079 (0.103)\tData 0.056 (0.078)\tLoss 0.7146 (0.7645)\tAcc 0.750 (0.703)\n",
      "Epoch: [42][9/12]\tTime 0.078 (0.101)\tData 0.055 (0.076)\tLoss 0.7468 (0.7625)\tAcc 0.812 (0.715)\n",
      "Epoch: [42][10/12]\tTime 0.078 (0.098)\tData 0.055 (0.073)\tLoss 0.4940 (0.7357)\tAcc 0.812 (0.725)\n",
      "Epoch: [42][11/12]\tTime 0.080 (0.097)\tData 0.056 (0.072)\tLoss 0.8546 (0.7465)\tAcc 0.562 (0.710)\n",
      "Epoch: [42][12/12]\tTime 0.078 (0.095)\tData 0.054 (0.070)\tLoss 0.4756 (0.7252)\tAcc 0.800 (0.717)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/18]\tTime 0.219 (0.219)\tData 0.194 (0.194)\tLoss 0.2297 (0.2297)\tAcc 1.000 (1.000)\n",
      "Epoch: [42][2/18]\tTime 0.074 (0.147)\tData 0.049 (0.121)\tLoss 0.8426 (0.5361)\tAcc 0.750 (0.875)\n",
      "Epoch: [42][3/18]\tTime 0.070 (0.121)\tData 0.049 (0.097)\tLoss 0.5953 (0.5559)\tAcc 0.688 (0.812)\n",
      "Epoch: [42][4/18]\tTime 0.074 (0.109)\tData 0.053 (0.086)\tLoss 0.4802 (0.5370)\tAcc 0.812 (0.812)\n",
      "Epoch: [42][5/18]\tTime 0.074 (0.102)\tData 0.054 (0.080)\tLoss 0.8820 (0.6060)\tAcc 0.688 (0.788)\n",
      "Epoch: [42][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.2216 (0.5419)\tAcc 1.000 (0.823)\n",
      "Epoch: [42][7/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.7258 (0.5682)\tAcc 0.750 (0.813)\n",
      "Epoch: [42][8/18]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.9063 (0.6104)\tAcc 0.688 (0.797)\n",
      "Epoch: [42][9/18]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.1220 (0.5562)\tAcc 1.000 (0.819)\n",
      "Epoch: [42][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.9859 (0.5991)\tAcc 0.500 (0.788)\n",
      "Epoch: [42][11/18]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 1.3679 (0.6690)\tAcc 0.375 (0.750)\n",
      "Epoch: [42][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.7451 (0.6754)\tAcc 0.812 (0.755)\n",
      "Epoch: [42][13/18]\tTime 0.074 (0.085)\tData 0.055 (0.064)\tLoss 1.0423 (0.7036)\tAcc 0.625 (0.745)\n",
      "Epoch: [42][14/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.7271 (0.7053)\tAcc 0.562 (0.732)\n",
      "Epoch: [42][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.8773 (0.7167)\tAcc 0.688 (0.729)\n",
      "Epoch: [42][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.9597 (0.7319)\tAcc 0.688 (0.727)\n",
      "Epoch: [42][17/18]\tTime 0.075 (0.082)\tData 0.055 (0.062)\tLoss 0.7358 (0.7322)\tAcc 0.625 (0.721)\n",
      "Epoch: [42][18/18]\tTime 0.074 (0.082)\tData 0.054 (0.061)\tLoss 0.8135 (0.7345)\tAcc 0.750 (0.721)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/12]\tTime 0.284 (0.284)\tData 0.256 (0.256)\tLoss 0.9562 (0.9562)\tAcc 0.625 (0.625)\n",
      "Epoch: [43][2/12]\tTime 0.076 (0.180)\tData 0.051 (0.153)\tLoss 0.6954 (0.8258)\tAcc 0.750 (0.688)\n",
      "Epoch: [43][3/12]\tTime 0.080 (0.147)\tData 0.053 (0.120)\tLoss 0.3813 (0.6776)\tAcc 0.875 (0.750)\n",
      "Epoch: [43][4/12]\tTime 0.077 (0.129)\tData 0.052 (0.103)\tLoss 0.8596 (0.7231)\tAcc 0.562 (0.703)\n",
      "Epoch: [43][5/12]\tTime 0.081 (0.120)\tData 0.054 (0.093)\tLoss 0.4431 (0.6671)\tAcc 0.812 (0.725)\n",
      "Epoch: [43][6/12]\tTime 0.077 (0.112)\tData 0.052 (0.086)\tLoss 0.4925 (0.6380)\tAcc 0.875 (0.750)\n",
      "Epoch: [43][7/12]\tTime 0.078 (0.107)\tData 0.054 (0.082)\tLoss 1.2528 (0.7259)\tAcc 0.500 (0.714)\n",
      "Epoch: [43][8/12]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 0.7658 (0.7308)\tAcc 0.688 (0.711)\n",
      "Epoch: [43][9/12]\tTime 0.077 (0.101)\tData 0.054 (0.076)\tLoss 0.4375 (0.6983)\tAcc 0.938 (0.736)\n",
      "Epoch: [43][10/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.8203 (0.7105)\tAcc 0.625 (0.725)\n",
      "Epoch: [43][11/12]\tTime 0.080 (0.097)\tData 0.056 (0.072)\tLoss 0.6664 (0.7064)\tAcc 0.750 (0.727)\n",
      "Epoch: [43][12/12]\tTime 0.078 (0.095)\tData 0.055 (0.070)\tLoss 0.7741 (0.7118)\tAcc 0.667 (0.723)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/18]\tTime 0.223 (0.223)\tData 0.199 (0.199)\tLoss 0.3515 (0.3515)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/18]\tTime 0.077 (0.150)\tData 0.050 (0.125)\tLoss 0.8813 (0.6164)\tAcc 0.562 (0.750)\n",
      "Epoch: [43][3/18]\tTime 0.068 (0.123)\tData 0.047 (0.099)\tLoss 0.5877 (0.6068)\tAcc 0.875 (0.792)\n",
      "Epoch: [43][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.6057 (0.6065)\tAcc 0.750 (0.781)\n",
      "Epoch: [43][5/18]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.7413 (0.6335)\tAcc 0.750 (0.775)\n",
      "Epoch: [43][6/18]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.2563 (0.5706)\tAcc 1.000 (0.812)\n",
      "Epoch: [43][7/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.7549 (0.5970)\tAcc 0.562 (0.777)\n",
      "Epoch: [43][8/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.9686 (0.6434)\tAcc 0.688 (0.766)\n",
      "Epoch: [43][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.1588 (0.5896)\tAcc 1.000 (0.792)\n",
      "Epoch: [43][10/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 1.0979 (0.6404)\tAcc 0.688 (0.781)\n",
      "Epoch: [43][11/18]\tTime 0.075 (0.087)\tData 0.055 (0.066)\tLoss 1.2933 (0.6998)\tAcc 0.375 (0.744)\n",
      "Epoch: [43][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8602 (0.7131)\tAcc 0.812 (0.750)\n",
      "Epoch: [43][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1320 (0.7454)\tAcc 0.500 (0.731)\n",
      "Epoch: [43][14/18]\tTime 0.075 (0.084)\tData 0.056 (0.064)\tLoss 0.7409 (0.7450)\tAcc 0.625 (0.723)\n",
      "Epoch: [43][15/18]\tTime 0.073 (0.084)\tData 0.055 (0.063)\tLoss 0.7961 (0.7484)\tAcc 0.750 (0.725)\n",
      "Epoch: [43][16/18]\tTime 0.074 (0.083)\tData 0.055 (0.063)\tLoss 0.7781 (0.7503)\tAcc 0.750 (0.727)\n",
      "Epoch: [43][17/18]\tTime 0.076 (0.083)\tData 0.056 (0.062)\tLoss 0.7621 (0.7510)\tAcc 0.625 (0.721)\n",
      "Epoch: [43][18/18]\tTime 0.074 (0.082)\tData 0.054 (0.062)\tLoss 0.8202 (0.7530)\tAcc 0.625 (0.718)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/12]\tTime 0.268 (0.268)\tData 0.239 (0.239)\tLoss 0.6360 (0.6360)\tAcc 0.750 (0.750)\n",
      "Epoch: [44][2/12]\tTime 0.075 (0.172)\tData 0.050 (0.145)\tLoss 0.5303 (0.5832)\tAcc 0.875 (0.812)\n",
      "Epoch: [44][3/12]\tTime 0.078 (0.141)\tData 0.053 (0.114)\tLoss 0.9917 (0.7193)\tAcc 0.500 (0.708)\n",
      "Epoch: [44][4/12]\tTime 0.078 (0.125)\tData 0.053 (0.099)\tLoss 0.6920 (0.7125)\tAcc 0.750 (0.719)\n",
      "Epoch: [44][5/12]\tTime 0.080 (0.116)\tData 0.054 (0.090)\tLoss 0.5876 (0.6875)\tAcc 0.812 (0.738)\n",
      "Epoch: [44][6/12]\tTime 0.077 (0.109)\tData 0.052 (0.084)\tLoss 0.4684 (0.6510)\tAcc 0.812 (0.750)\n",
      "Epoch: [44][7/12]\tTime 0.077 (0.105)\tData 0.054 (0.079)\tLoss 0.8469 (0.6790)\tAcc 0.625 (0.732)\n",
      "Epoch: [44][8/12]\tTime 0.079 (0.102)\tData 0.056 (0.076)\tLoss 0.6434 (0.6745)\tAcc 0.688 (0.727)\n",
      "Epoch: [44][9/12]\tTime 0.078 (0.099)\tData 0.054 (0.074)\tLoss 0.7631 (0.6844)\tAcc 0.688 (0.722)\n",
      "Epoch: [44][10/12]\tTime 0.078 (0.097)\tData 0.054 (0.072)\tLoss 0.9948 (0.7154)\tAcc 0.625 (0.713)\n",
      "Epoch: [44][11/12]\tTime 0.079 (0.095)\tData 0.056 (0.071)\tLoss 0.3802 (0.6849)\tAcc 0.875 (0.727)\n",
      "Epoch: [44][12/12]\tTime 0.078 (0.094)\tData 0.054 (0.069)\tLoss 0.6094 (0.6790)\tAcc 0.733 (0.728)\n",
      "validation at epoch 44\n",
      "Epoch: [44][1/18]\tTime 0.220 (0.220)\tData 0.192 (0.192)\tLoss 0.3662 (0.3662)\tAcc 0.875 (0.875)\n",
      "Epoch: [44][2/18]\tTime 0.074 (0.147)\tData 0.047 (0.119)\tLoss 0.8901 (0.6282)\tAcc 0.500 (0.688)\n",
      "Epoch: [44][3/18]\tTime 0.070 (0.121)\tData 0.049 (0.096)\tLoss 0.6233 (0.6266)\tAcc 0.812 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][4/18]\tTime 0.073 (0.109)\tData 0.053 (0.085)\tLoss 0.5760 (0.6139)\tAcc 0.750 (0.734)\n",
      "Epoch: [44][5/18]\tTime 0.074 (0.102)\tData 0.054 (0.079)\tLoss 0.7450 (0.6401)\tAcc 0.750 (0.738)\n",
      "Epoch: [44][6/18]\tTime 0.073 (0.097)\tData 0.053 (0.075)\tLoss 0.2426 (0.5739)\tAcc 1.000 (0.781)\n",
      "Epoch: [44][7/18]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.6201 (0.5805)\tAcc 0.750 (0.777)\n",
      "Epoch: [44][8/18]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.9649 (0.6285)\tAcc 0.625 (0.758)\n",
      "Epoch: [44][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.068)\tLoss 0.1145 (0.5714)\tAcc 1.000 (0.785)\n",
      "Epoch: [44][10/18]\tTime 0.074 (0.088)\tData 0.053 (0.066)\tLoss 1.1797 (0.6322)\tAcc 0.625 (0.769)\n",
      "Epoch: [44][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 1.1821 (0.6822)\tAcc 0.375 (0.733)\n",
      "Epoch: [44][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 0.9392 (0.7036)\tAcc 0.812 (0.740)\n",
      "Epoch: [44][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1128 (0.7351)\tAcc 0.500 (0.721)\n",
      "Epoch: [44][14/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.7944 (0.7394)\tAcc 0.562 (0.710)\n",
      "Epoch: [44][15/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.7383 (0.7393)\tAcc 0.750 (0.713)\n",
      "Epoch: [44][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.8491 (0.7462)\tAcc 0.625 (0.707)\n",
      "Epoch: [44][17/18]\tTime 0.076 (0.082)\tData 0.056 (0.062)\tLoss 0.7247 (0.7449)\tAcc 0.688 (0.706)\n",
      "Epoch: [44][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.9416 (0.7505)\tAcc 0.625 (0.704)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/12]\tTime 0.268 (0.268)\tData 0.239 (0.239)\tLoss 0.8605 (0.8605)\tAcc 0.625 (0.625)\n",
      "Epoch: [45][2/12]\tTime 0.076 (0.172)\tData 0.051 (0.145)\tLoss 0.5952 (0.7279)\tAcc 0.812 (0.719)\n",
      "Epoch: [45][3/12]\tTime 0.081 (0.142)\tData 0.054 (0.115)\tLoss 1.0477 (0.8345)\tAcc 0.562 (0.667)\n",
      "Epoch: [45][4/12]\tTime 0.077 (0.125)\tData 0.051 (0.099)\tLoss 0.5075 (0.7527)\tAcc 0.812 (0.703)\n",
      "Epoch: [45][5/12]\tTime 0.080 (0.116)\tData 0.054 (0.090)\tLoss 0.7715 (0.7565)\tAcc 0.625 (0.688)\n",
      "Epoch: [45][6/12]\tTime 0.077 (0.110)\tData 0.053 (0.084)\tLoss 0.5371 (0.7199)\tAcc 0.875 (0.719)\n",
      "Epoch: [45][7/12]\tTime 0.077 (0.105)\tData 0.054 (0.079)\tLoss 0.4202 (0.6771)\tAcc 0.812 (0.732)\n",
      "Epoch: [45][8/12]\tTime 0.079 (0.102)\tData 0.056 (0.076)\tLoss 0.5852 (0.6656)\tAcc 0.750 (0.734)\n",
      "Epoch: [45][9/12]\tTime 0.078 (0.099)\tData 0.054 (0.074)\tLoss 0.5982 (0.6581)\tAcc 0.688 (0.729)\n",
      "Epoch: [45][10/12]\tTime 0.078 (0.097)\tData 0.054 (0.072)\tLoss 1.2098 (0.7133)\tAcc 0.500 (0.706)\n",
      "Epoch: [45][11/12]\tTime 0.079 (0.095)\tData 0.056 (0.070)\tLoss 0.7144 (0.7134)\tAcc 0.688 (0.705)\n",
      "Epoch: [45][12/12]\tTime 0.077 (0.094)\tData 0.054 (0.069)\tLoss 0.5674 (0.7019)\tAcc 0.800 (0.712)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/18]\tTime 0.217 (0.217)\tData 0.190 (0.190)\tLoss 0.3114 (0.3114)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/18]\tTime 0.072 (0.145)\tData 0.048 (0.119)\tLoss 0.9163 (0.6139)\tAcc 0.625 (0.781)\n",
      "Epoch: [45][3/18]\tTime 0.070 (0.120)\tData 0.050 (0.096)\tLoss 0.5745 (0.6008)\tAcc 0.750 (0.771)\n",
      "Epoch: [45][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.5587 (0.5902)\tAcc 0.750 (0.766)\n",
      "Epoch: [45][5/18]\tTime 0.075 (0.102)\tData 0.054 (0.079)\tLoss 0.6903 (0.6103)\tAcc 0.750 (0.762)\n",
      "Epoch: [45][6/18]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.2900 (0.5569)\tAcc 1.000 (0.802)\n",
      "Epoch: [45][7/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 0.7310 (0.5817)\tAcc 0.562 (0.768)\n",
      "Epoch: [45][8/18]\tTime 0.075 (0.091)\tData 0.054 (0.070)\tLoss 0.9624 (0.6293)\tAcc 0.688 (0.758)\n",
      "Epoch: [45][9/18]\tTime 0.073 (0.089)\tData 0.053 (0.068)\tLoss 0.1196 (0.5727)\tAcc 1.000 (0.785)\n",
      "Epoch: [45][10/18]\tTime 0.073 (0.088)\tData 0.053 (0.066)\tLoss 1.1124 (0.6267)\tAcc 0.688 (0.775)\n",
      "Epoch: [45][11/18]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 1.2668 (0.6849)\tAcc 0.375 (0.739)\n",
      "Epoch: [45][12/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.8700 (0.7003)\tAcc 0.750 (0.740)\n",
      "Epoch: [45][13/18]\tTime 0.073 (0.084)\tData 0.054 (0.064)\tLoss 0.9546 (0.7198)\tAcc 0.625 (0.731)\n",
      "Epoch: [45][14/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.8032 (0.7258)\tAcc 0.562 (0.719)\n",
      "Epoch: [45][15/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.7967 (0.7305)\tAcc 0.750 (0.721)\n",
      "Epoch: [45][16/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.9075 (0.7416)\tAcc 0.688 (0.719)\n",
      "Epoch: [45][17/18]\tTime 0.075 (0.082)\tData 0.055 (0.062)\tLoss 0.7003 (0.7392)\tAcc 0.625 (0.713)\n",
      "Epoch: [45][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.7145 (0.7385)\tAcc 0.750 (0.714)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/12]\tTime 0.234 (0.234)\tData 0.202 (0.202)\tLoss 0.9348 (0.9348)\tAcc 0.625 (0.625)\n",
      "Epoch: [46][2/12]\tTime 0.073 (0.153)\tData 0.048 (0.125)\tLoss 0.3525 (0.6437)\tAcc 0.938 (0.781)\n",
      "Epoch: [46][3/12]\tTime 0.081 (0.129)\tData 0.053 (0.101)\tLoss 0.7851 (0.6908)\tAcc 0.625 (0.729)\n",
      "Epoch: [46][4/12]\tTime 0.075 (0.116)\tData 0.051 (0.089)\tLoss 0.4323 (0.6262)\tAcc 0.938 (0.781)\n",
      "Epoch: [46][5/12]\tTime 0.083 (0.109)\tData 0.055 (0.082)\tLoss 0.6766 (0.6363)\tAcc 0.750 (0.775)\n",
      "Epoch: [46][6/12]\tTime 0.074 (0.103)\tData 0.050 (0.077)\tLoss 1.0199 (0.7002)\tAcc 0.500 (0.729)\n",
      "Epoch: [46][7/12]\tTime 0.077 (0.100)\tData 0.054 (0.073)\tLoss 0.7663 (0.7096)\tAcc 0.688 (0.723)\n",
      "Epoch: [46][8/12]\tTime 0.079 (0.097)\tData 0.056 (0.071)\tLoss 0.5391 (0.6883)\tAcc 0.875 (0.742)\n",
      "Epoch: [46][9/12]\tTime 0.078 (0.095)\tData 0.054 (0.069)\tLoss 0.5621 (0.6743)\tAcc 0.688 (0.736)\n",
      "Epoch: [46][10/12]\tTime 0.078 (0.093)\tData 0.055 (0.068)\tLoss 0.8300 (0.6899)\tAcc 0.625 (0.725)\n",
      "Epoch: [46][11/12]\tTime 0.079 (0.092)\tData 0.055 (0.067)\tLoss 0.6843 (0.6894)\tAcc 0.625 (0.716)\n",
      "Epoch: [46][12/12]\tTime 0.078 (0.091)\tData 0.054 (0.066)\tLoss 0.5103 (0.6753)\tAcc 0.733 (0.717)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/18]\tTime 0.215 (0.215)\tData 0.185 (0.185)\tLoss 0.2937 (0.2937)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/18]\tTime 0.066 (0.141)\tData 0.045 (0.115)\tLoss 0.8535 (0.5736)\tAcc 0.562 (0.750)\n",
      "Epoch: [46][3/18]\tTime 0.073 (0.118)\tData 0.053 (0.094)\tLoss 0.5865 (0.5779)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][4/18]\tTime 0.073 (0.107)\tData 0.053 (0.084)\tLoss 0.6183 (0.5880)\tAcc 0.688 (0.734)\n",
      "Epoch: [46][5/18]\tTime 0.076 (0.101)\tData 0.055 (0.078)\tLoss 0.8643 (0.6432)\tAcc 0.688 (0.725)\n",
      "Epoch: [46][6/18]\tTime 0.081 (0.097)\tData 0.060 (0.075)\tLoss 0.2515 (0.5779)\tAcc 1.000 (0.771)\n",
      "Epoch: [46][7/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.6536 (0.5888)\tAcc 0.812 (0.777)\n",
      "Epoch: [46][8/18]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.8548 (0.6220)\tAcc 0.750 (0.773)\n",
      "Epoch: [46][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.1729 (0.5721)\tAcc 1.000 (0.799)\n",
      "Epoch: [46][10/18]\tTime 0.073 (0.088)\tData 0.053 (0.067)\tLoss 0.8375 (0.5987)\tAcc 0.750 (0.794)\n",
      "Epoch: [46][11/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 1.2089 (0.6541)\tAcc 0.375 (0.756)\n",
      "Epoch: [46][12/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 0.9072 (0.6752)\tAcc 0.750 (0.755)\n",
      "Epoch: [46][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1524 (0.7119)\tAcc 0.562 (0.740)\n",
      "Epoch: [46][14/18]\tTime 0.075 (0.084)\tData 0.056 (0.063)\tLoss 0.9047 (0.7257)\tAcc 0.500 (0.723)\n",
      "Epoch: [46][15/18]\tTime 0.073 (0.083)\tData 0.055 (0.063)\tLoss 0.9639 (0.7416)\tAcc 0.625 (0.717)\n",
      "Epoch: [46][16/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.8565 (0.7488)\tAcc 0.625 (0.711)\n",
      "Epoch: [46][17/18]\tTime 0.075 (0.082)\tData 0.056 (0.062)\tLoss 0.7346 (0.7479)\tAcc 0.625 (0.706)\n",
      "Epoch: [46][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.8165 (0.7499)\tAcc 0.625 (0.704)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/12]\tTime 0.214 (0.214)\tData 0.183 (0.183)\tLoss 0.5206 (0.5206)\tAcc 0.750 (0.750)\n",
      "Epoch: [47][2/12]\tTime 0.076 (0.145)\tData 0.050 (0.117)\tLoss 0.5106 (0.5156)\tAcc 0.875 (0.812)\n",
      "Epoch: [47][3/12]\tTime 0.080 (0.123)\tData 0.053 (0.096)\tLoss 0.7695 (0.6003)\tAcc 0.812 (0.812)\n",
      "Epoch: [47][4/12]\tTime 0.079 (0.112)\tData 0.053 (0.085)\tLoss 0.6009 (0.6004)\tAcc 0.875 (0.828)\n",
      "Epoch: [47][5/12]\tTime 0.080 (0.106)\tData 0.054 (0.079)\tLoss 0.7763 (0.6356)\tAcc 0.625 (0.788)\n",
      "Epoch: [47][6/12]\tTime 0.077 (0.101)\tData 0.053 (0.074)\tLoss 0.4671 (0.6075)\tAcc 0.812 (0.792)\n",
      "Epoch: [47][7/12]\tTime 0.078 (0.098)\tData 0.054 (0.072)\tLoss 0.4828 (0.5897)\tAcc 0.938 (0.813)\n",
      "Epoch: [47][8/12]\tTime 0.080 (0.095)\tData 0.056 (0.070)\tLoss 0.8581 (0.6233)\tAcc 0.625 (0.789)\n",
      "Epoch: [47][9/12]\tTime 0.080 (0.094)\tData 0.056 (0.068)\tLoss 0.4786 (0.6072)\tAcc 0.750 (0.785)\n",
      "Epoch: [47][10/12]\tTime 0.082 (0.093)\tData 0.058 (0.067)\tLoss 0.7964 (0.6261)\tAcc 0.688 (0.775)\n",
      "Epoch: [47][11/12]\tTime 0.085 (0.092)\tData 0.061 (0.067)\tLoss 0.9538 (0.6559)\tAcc 0.562 (0.756)\n",
      "Epoch: [47][12/12]\tTime 0.085 (0.091)\tData 0.059 (0.066)\tLoss 0.5334 (0.6463)\tAcc 0.667 (0.749)\n",
      "validation at epoch 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [47][1/18]\tTime 0.240 (0.240)\tData 0.208 (0.208)\tLoss 0.2683 (0.2683)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/18]\tTime 0.082 (0.161)\tData 0.050 (0.129)\tLoss 0.8518 (0.5601)\tAcc 0.562 (0.750)\n",
      "Epoch: [47][3/18]\tTime 0.068 (0.130)\tData 0.047 (0.102)\tLoss 0.6834 (0.6012)\tAcc 0.812 (0.771)\n",
      "Epoch: [47][4/18]\tTime 0.077 (0.117)\tData 0.056 (0.090)\tLoss 0.5953 (0.5997)\tAcc 0.688 (0.750)\n",
      "Epoch: [47][5/18]\tTime 0.078 (0.109)\tData 0.057 (0.084)\tLoss 0.6983 (0.6194)\tAcc 0.750 (0.750)\n",
      "Epoch: [47][6/18]\tTime 0.080 (0.104)\tData 0.059 (0.080)\tLoss 0.3219 (0.5698)\tAcc 0.938 (0.781)\n",
      "Epoch: [47][7/18]\tTime 0.076 (0.100)\tData 0.056 (0.076)\tLoss 0.6985 (0.5882)\tAcc 0.750 (0.777)\n",
      "Epoch: [47][8/18]\tTime 0.076 (0.097)\tData 0.055 (0.074)\tLoss 0.9426 (0.6325)\tAcc 0.688 (0.766)\n",
      "Epoch: [47][9/18]\tTime 0.078 (0.095)\tData 0.057 (0.072)\tLoss 0.0965 (0.5730)\tAcc 1.000 (0.792)\n",
      "Epoch: [47][10/18]\tTime 0.073 (0.093)\tData 0.053 (0.070)\tLoss 1.1179 (0.6274)\tAcc 0.625 (0.775)\n",
      "Epoch: [47][11/18]\tTime 0.074 (0.091)\tData 0.054 (0.068)\tLoss 1.0414 (0.6651)\tAcc 0.375 (0.739)\n",
      "Epoch: [47][12/18]\tTime 0.074 (0.090)\tData 0.054 (0.067)\tLoss 0.8306 (0.6789)\tAcc 0.812 (0.745)\n",
      "Epoch: [47][13/18]\tTime 0.073 (0.089)\tData 0.054 (0.066)\tLoss 1.2516 (0.7229)\tAcc 0.500 (0.726)\n",
      "Epoch: [47][14/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.8905 (0.7349)\tAcc 0.562 (0.714)\n",
      "Epoch: [47][15/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.9729 (0.7508)\tAcc 0.625 (0.708)\n",
      "Epoch: [47][16/18]\tTime 0.077 (0.086)\tData 0.057 (0.064)\tLoss 0.7665 (0.7518)\tAcc 0.875 (0.719)\n",
      "Epoch: [47][17/18]\tTime 0.074 (0.085)\tData 0.054 (0.063)\tLoss 0.7860 (0.7538)\tAcc 0.625 (0.713)\n",
      "Epoch: [47][18/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.7000 (0.7522)\tAcc 1.000 (0.721)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/12]\tTime 0.280 (0.280)\tData 0.251 (0.251)\tLoss 0.8092 (0.8092)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][2/12]\tTime 0.077 (0.179)\tData 0.050 (0.150)\tLoss 0.6281 (0.7187)\tAcc 0.750 (0.719)\n",
      "Epoch: [48][3/12]\tTime 0.077 (0.145)\tData 0.051 (0.117)\tLoss 0.7526 (0.7300)\tAcc 0.688 (0.708)\n",
      "Epoch: [48][4/12]\tTime 0.085 (0.130)\tData 0.056 (0.102)\tLoss 0.6488 (0.7097)\tAcc 0.688 (0.703)\n",
      "Epoch: [48][5/12]\tTime 0.083 (0.120)\tData 0.058 (0.093)\tLoss 0.7666 (0.7211)\tAcc 0.750 (0.713)\n",
      "Epoch: [48][6/12]\tTime 0.088 (0.115)\tData 0.062 (0.088)\tLoss 0.6106 (0.7027)\tAcc 0.625 (0.698)\n",
      "Epoch: [48][7/12]\tTime 0.082 (0.110)\tData 0.057 (0.084)\tLoss 0.5408 (0.6795)\tAcc 0.750 (0.705)\n",
      "Epoch: [48][8/12]\tTime 0.082 (0.107)\tData 0.057 (0.080)\tLoss 0.5001 (0.6571)\tAcc 0.875 (0.727)\n",
      "Epoch: [48][9/12]\tTime 0.086 (0.104)\tData 0.060 (0.078)\tLoss 0.8273 (0.6760)\tAcc 0.688 (0.722)\n",
      "Epoch: [48][10/12]\tTime 0.087 (0.103)\tData 0.061 (0.076)\tLoss 0.5854 (0.6669)\tAcc 0.812 (0.731)\n",
      "Epoch: [48][11/12]\tTime 0.086 (0.101)\tData 0.060 (0.075)\tLoss 0.5582 (0.6571)\tAcc 0.812 (0.739)\n",
      "Epoch: [48][12/12]\tTime 0.086 (0.100)\tData 0.061 (0.074)\tLoss 0.5023 (0.6449)\tAcc 0.800 (0.743)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/18]\tTime 0.241 (0.241)\tData 0.212 (0.212)\tLoss 0.3142 (0.3142)\tAcc 0.938 (0.938)\n",
      "Epoch: [48][2/18]\tTime 0.071 (0.156)\tData 0.046 (0.129)\tLoss 0.8276 (0.5709)\tAcc 0.688 (0.812)\n",
      "Epoch: [48][3/18]\tTime 0.070 (0.127)\tData 0.049 (0.102)\tLoss 0.5820 (0.5746)\tAcc 0.812 (0.812)\n",
      "Epoch: [48][4/18]\tTime 0.074 (0.114)\tData 0.054 (0.090)\tLoss 0.5612 (0.5713)\tAcc 0.688 (0.781)\n",
      "Epoch: [48][5/18]\tTime 0.074 (0.106)\tData 0.053 (0.083)\tLoss 0.7951 (0.6160)\tAcc 0.688 (0.762)\n",
      "Epoch: [48][6/18]\tTime 0.074 (0.101)\tData 0.053 (0.078)\tLoss 0.2890 (0.5615)\tAcc 1.000 (0.802)\n",
      "Epoch: [48][7/18]\tTime 0.086 (0.099)\tData 0.053 (0.074)\tLoss 0.7227 (0.5846)\tAcc 0.688 (0.786)\n",
      "Epoch: [48][8/18]\tTime 0.073 (0.095)\tData 0.051 (0.071)\tLoss 0.9450 (0.6296)\tAcc 0.750 (0.781)\n",
      "Epoch: [48][9/18]\tTime 0.079 (0.094)\tData 0.058 (0.070)\tLoss 0.1159 (0.5725)\tAcc 1.000 (0.806)\n",
      "Epoch: [48][10/18]\tTime 0.080 (0.092)\tData 0.059 (0.069)\tLoss 1.2348 (0.6388)\tAcc 0.625 (0.788)\n",
      "Epoch: [48][11/18]\tTime 0.077 (0.091)\tData 0.057 (0.068)\tLoss 1.5310 (0.7199)\tAcc 0.375 (0.750)\n",
      "Epoch: [48][12/18]\tTime 0.077 (0.090)\tData 0.057 (0.067)\tLoss 0.8586 (0.7314)\tAcc 0.750 (0.750)\n",
      "Epoch: [48][13/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 1.0649 (0.7571)\tAcc 0.625 (0.740)\n",
      "Epoch: [48][14/18]\tTime 0.076 (0.088)\tData 0.056 (0.065)\tLoss 0.8107 (0.7609)\tAcc 0.625 (0.732)\n",
      "Epoch: [48][15/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 0.8765 (0.7686)\tAcc 0.750 (0.733)\n",
      "Epoch: [48][16/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 0.7576 (0.7679)\tAcc 0.688 (0.730)\n",
      "Epoch: [48][17/18]\tTime 0.075 (0.086)\tData 0.055 (0.063)\tLoss 0.7457 (0.7666)\tAcc 0.625 (0.724)\n",
      "Epoch: [48][18/18]\tTime 0.079 (0.085)\tData 0.060 (0.063)\tLoss 0.7207 (0.7653)\tAcc 0.750 (0.725)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/12]\tTime 0.252 (0.252)\tData 0.220 (0.220)\tLoss 0.9523 (0.9523)\tAcc 0.625 (0.625)\n",
      "Epoch: [49][2/12]\tTime 0.082 (0.167)\tData 0.055 (0.138)\tLoss 0.9380 (0.9451)\tAcc 0.562 (0.594)\n",
      "Epoch: [49][3/12]\tTime 0.088 (0.140)\tData 0.061 (0.112)\tLoss 0.6326 (0.8410)\tAcc 0.875 (0.688)\n",
      "Epoch: [49][4/12]\tTime 0.089 (0.128)\tData 0.060 (0.099)\tLoss 0.4695 (0.7481)\tAcc 0.750 (0.703)\n",
      "Epoch: [49][5/12]\tTime 0.084 (0.119)\tData 0.058 (0.091)\tLoss 0.5797 (0.7144)\tAcc 0.875 (0.738)\n",
      "Epoch: [49][6/12]\tTime 0.079 (0.112)\tData 0.055 (0.085)\tLoss 0.4877 (0.6766)\tAcc 0.812 (0.750)\n",
      "Epoch: [49][7/12]\tTime 0.086 (0.108)\tData 0.061 (0.081)\tLoss 0.7589 (0.6884)\tAcc 0.688 (0.741)\n",
      "Epoch: [49][8/12]\tTime 0.087 (0.106)\tData 0.062 (0.079)\tLoss 0.5782 (0.6746)\tAcc 0.688 (0.734)\n",
      "Epoch: [49][9/12]\tTime 0.087 (0.104)\tData 0.061 (0.077)\tLoss 0.5510 (0.6609)\tAcc 0.875 (0.750)\n",
      "Epoch: [49][10/12]\tTime 0.087 (0.102)\tData 0.061 (0.075)\tLoss 0.4924 (0.6440)\tAcc 0.938 (0.769)\n",
      "Epoch: [49][11/12]\tTime 0.087 (0.101)\tData 0.061 (0.074)\tLoss 0.6601 (0.6455)\tAcc 0.625 (0.756)\n",
      "Epoch: [49][12/12]\tTime 0.086 (0.099)\tData 0.061 (0.073)\tLoss 0.9557 (0.6699)\tAcc 0.667 (0.749)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/18]\tTime 0.231 (0.231)\tData 0.194 (0.194)\tLoss 0.3215 (0.3215)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/18]\tTime 0.065 (0.148)\tData 0.041 (0.118)\tLoss 0.8968 (0.6092)\tAcc 0.562 (0.750)\n",
      "Epoch: [49][3/18]\tTime 0.071 (0.123)\tData 0.051 (0.095)\tLoss 0.6566 (0.6250)\tAcc 0.688 (0.729)\n",
      "Epoch: [49][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.085)\tLoss 0.6266 (0.6254)\tAcc 0.750 (0.734)\n",
      "Epoch: [49][5/18]\tTime 0.074 (0.103)\tData 0.054 (0.079)\tLoss 0.8008 (0.6605)\tAcc 0.688 (0.725)\n",
      "Epoch: [49][6/18]\tTime 0.074 (0.098)\tData 0.054 (0.074)\tLoss 0.3461 (0.6081)\tAcc 0.938 (0.760)\n",
      "Epoch: [49][7/18]\tTime 0.075 (0.095)\tData 0.055 (0.072)\tLoss 0.6663 (0.6164)\tAcc 0.688 (0.750)\n",
      "Epoch: [49][8/18]\tTime 0.075 (0.092)\tData 0.054 (0.069)\tLoss 1.0163 (0.6664)\tAcc 0.688 (0.742)\n",
      "Epoch: [49][9/18]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.1458 (0.6085)\tAcc 1.000 (0.771)\n",
      "Epoch: [49][10/18]\tTime 0.075 (0.089)\tData 0.053 (0.066)\tLoss 1.0467 (0.6524)\tAcc 0.750 (0.769)\n",
      "Epoch: [49][11/18]\tTime 0.076 (0.088)\tData 0.055 (0.065)\tLoss 1.2995 (0.7112)\tAcc 0.375 (0.733)\n",
      "Epoch: [49][12/18]\tTime 0.075 (0.086)\tData 0.055 (0.064)\tLoss 0.9495 (0.7310)\tAcc 0.750 (0.734)\n",
      "Epoch: [49][13/18]\tTime 0.076 (0.086)\tData 0.055 (0.064)\tLoss 1.0949 (0.7590)\tAcc 0.562 (0.721)\n",
      "Epoch: [49][14/18]\tTime 0.075 (0.085)\tData 0.055 (0.063)\tLoss 0.8576 (0.7661)\tAcc 0.688 (0.719)\n",
      "Epoch: [49][15/18]\tTime 0.075 (0.084)\tData 0.054 (0.062)\tLoss 0.8032 (0.7686)\tAcc 0.750 (0.721)\n",
      "Epoch: [49][16/18]\tTime 0.079 (0.084)\tData 0.059 (0.062)\tLoss 0.6996 (0.7642)\tAcc 0.750 (0.723)\n",
      "Epoch: [49][17/18]\tTime 0.075 (0.083)\tData 0.055 (0.062)\tLoss 0.7976 (0.7662)\tAcc 0.625 (0.717)\n",
      "Epoch: [49][18/18]\tTime 0.073 (0.083)\tData 0.054 (0.061)\tLoss 0.6626 (0.7632)\tAcc 0.750 (0.718)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/12]\tTime 0.256 (0.256)\tData 0.227 (0.227)\tLoss 0.6889 (0.6889)\tAcc 0.750 (0.750)\n",
      "Epoch: [50][2/12]\tTime 0.081 (0.168)\tData 0.054 (0.140)\tLoss 0.4086 (0.5488)\tAcc 0.812 (0.781)\n",
      "Epoch: [50][3/12]\tTime 0.077 (0.138)\tData 0.053 (0.111)\tLoss 0.7306 (0.6094)\tAcc 0.750 (0.771)\n",
      "Epoch: [50][4/12]\tTime 0.079 (0.123)\tData 0.053 (0.097)\tLoss 0.6492 (0.6193)\tAcc 0.750 (0.766)\n",
      "Epoch: [50][5/12]\tTime 0.078 (0.114)\tData 0.054 (0.088)\tLoss 0.5923 (0.6139)\tAcc 0.750 (0.762)\n",
      "Epoch: [50][6/12]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.9247 (0.6657)\tAcc 0.562 (0.729)\n",
      "Epoch: [50][7/12]\tTime 0.078 (0.104)\tData 0.055 (0.079)\tLoss 0.6414 (0.6623)\tAcc 0.812 (0.741)\n",
      "Epoch: [50][8/12]\tTime 0.081 (0.101)\tData 0.058 (0.076)\tLoss 0.5816 (0.6522)\tAcc 0.750 (0.742)\n",
      "Epoch: [50][9/12]\tTime 0.079 (0.099)\tData 0.056 (0.074)\tLoss 1.1204 (0.7042)\tAcc 0.500 (0.715)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][10/12]\tTime 0.079 (0.097)\tData 0.056 (0.072)\tLoss 0.4502 (0.6788)\tAcc 0.812 (0.725)\n",
      "Epoch: [50][11/12]\tTime 0.079 (0.095)\tData 0.056 (0.070)\tLoss 0.3953 (0.6530)\tAcc 0.812 (0.733)\n",
      "Epoch: [50][12/12]\tTime 0.081 (0.094)\tData 0.057 (0.069)\tLoss 0.8810 (0.6709)\tAcc 0.733 (0.733)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/18]\tTime 0.216 (0.216)\tData 0.188 (0.188)\tLoss 0.2388 (0.2388)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/18]\tTime 0.071 (0.144)\tData 0.048 (0.118)\tLoss 0.9408 (0.5898)\tAcc 0.625 (0.781)\n",
      "Epoch: [50][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.5908 (0.5901)\tAcc 0.750 (0.771)\n",
      "Epoch: [50][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.085)\tLoss 0.6084 (0.5947)\tAcc 0.688 (0.750)\n",
      "Epoch: [50][5/18]\tTime 0.073 (0.101)\tData 0.053 (0.079)\tLoss 0.8756 (0.6509)\tAcc 0.688 (0.738)\n",
      "Epoch: [50][6/18]\tTime 0.073 (0.097)\tData 0.054 (0.075)\tLoss 0.3076 (0.5937)\tAcc 1.000 (0.781)\n",
      "Epoch: [50][7/18]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.5985 (0.5944)\tAcc 0.812 (0.786)\n",
      "Epoch: [50][8/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.9413 (0.6377)\tAcc 0.688 (0.773)\n",
      "Epoch: [50][9/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.1489 (0.5834)\tAcc 1.000 (0.799)\n",
      "Epoch: [50][10/18]\tTime 0.075 (0.088)\tData 0.055 (0.067)\tLoss 1.0411 (0.6292)\tAcc 0.562 (0.775)\n",
      "Epoch: [50][11/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.4361 (0.7025)\tAcc 0.375 (0.739)\n",
      "Epoch: [50][12/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.9224 (0.7209)\tAcc 0.750 (0.740)\n",
      "Epoch: [50][13/18]\tTime 0.074 (0.084)\tData 0.055 (0.064)\tLoss 1.0824 (0.7487)\tAcc 0.500 (0.721)\n",
      "Epoch: [50][14/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.7931 (0.7518)\tAcc 0.625 (0.714)\n",
      "Epoch: [50][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.8524 (0.7585)\tAcc 0.688 (0.713)\n",
      "Epoch: [50][16/18]\tTime 0.073 (0.082)\tData 0.054 (0.062)\tLoss 0.7468 (0.7578)\tAcc 0.750 (0.715)\n",
      "Epoch: [50][17/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.7600 (0.7579)\tAcc 0.625 (0.710)\n",
      "Epoch: [50][18/18]\tTime 0.074 (0.081)\tData 0.054 (0.061)\tLoss 0.7718 (0.7583)\tAcc 0.750 (0.711)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/12]\tTime 0.269 (0.269)\tData 0.235 (0.235)\tLoss 0.6090 (0.6090)\tAcc 0.625 (0.625)\n",
      "Epoch: [51][2/12]\tTime 0.072 (0.170)\tData 0.046 (0.140)\tLoss 0.5984 (0.6037)\tAcc 0.688 (0.656)\n",
      "Epoch: [51][3/12]\tTime 0.079 (0.140)\tData 0.053 (0.111)\tLoss 0.4844 (0.5639)\tAcc 0.812 (0.708)\n",
      "Epoch: [51][4/12]\tTime 0.078 (0.124)\tData 0.053 (0.097)\tLoss 0.3853 (0.5193)\tAcc 0.875 (0.750)\n",
      "Epoch: [51][5/12]\tTime 0.079 (0.115)\tData 0.055 (0.088)\tLoss 0.7304 (0.5615)\tAcc 0.688 (0.738)\n",
      "Epoch: [51][6/12]\tTime 0.081 (0.110)\tData 0.057 (0.083)\tLoss 0.5453 (0.5588)\tAcc 0.875 (0.760)\n",
      "Epoch: [51][7/12]\tTime 0.087 (0.106)\tData 0.061 (0.080)\tLoss 1.0114 (0.6234)\tAcc 0.625 (0.741)\n",
      "Epoch: [51][8/12]\tTime 0.086 (0.104)\tData 0.061 (0.078)\tLoss 0.8050 (0.6461)\tAcc 0.688 (0.734)\n",
      "Epoch: [51][9/12]\tTime 0.086 (0.102)\tData 0.062 (0.076)\tLoss 0.5119 (0.6312)\tAcc 0.750 (0.736)\n",
      "Epoch: [51][10/12]\tTime 0.086 (0.100)\tData 0.062 (0.074)\tLoss 0.4141 (0.6095)\tAcc 0.812 (0.744)\n",
      "Epoch: [51][11/12]\tTime 0.087 (0.099)\tData 0.062 (0.073)\tLoss 0.5378 (0.6030)\tAcc 0.750 (0.744)\n",
      "Epoch: [51][12/12]\tTime 0.086 (0.098)\tData 0.061 (0.072)\tLoss 0.7906 (0.6177)\tAcc 0.667 (0.738)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/18]\tTime 0.243 (0.243)\tData 0.207 (0.207)\tLoss 0.2920 (0.2920)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/18]\tTime 0.072 (0.158)\tData 0.044 (0.126)\tLoss 0.9229 (0.6075)\tAcc 0.500 (0.719)\n",
      "Epoch: [51][3/18]\tTime 0.072 (0.129)\tData 0.050 (0.101)\tLoss 0.5775 (0.5975)\tAcc 0.750 (0.729)\n",
      "Epoch: [51][4/18]\tTime 0.080 (0.117)\tData 0.059 (0.090)\tLoss 0.5974 (0.5975)\tAcc 0.750 (0.734)\n",
      "Epoch: [51][5/18]\tTime 0.081 (0.110)\tData 0.059 (0.084)\tLoss 0.7682 (0.6316)\tAcc 0.812 (0.750)\n",
      "Epoch: [51][6/18]\tTime 0.080 (0.105)\tData 0.058 (0.080)\tLoss 0.3146 (0.5788)\tAcc 0.938 (0.781)\n",
      "Epoch: [51][7/18]\tTime 0.079 (0.101)\tData 0.058 (0.077)\tLoss 0.6201 (0.5847)\tAcc 0.812 (0.786)\n",
      "Epoch: [51][8/18]\tTime 0.080 (0.099)\tData 0.059 (0.074)\tLoss 0.9585 (0.6314)\tAcc 0.688 (0.773)\n",
      "Epoch: [51][9/18]\tTime 0.081 (0.097)\tData 0.059 (0.073)\tLoss 0.1183 (0.5744)\tAcc 1.000 (0.799)\n",
      "Epoch: [51][10/18]\tTime 0.078 (0.095)\tData 0.057 (0.071)\tLoss 1.1795 (0.6349)\tAcc 0.688 (0.788)\n",
      "Epoch: [51][11/18]\tTime 0.077 (0.093)\tData 0.057 (0.070)\tLoss 1.2560 (0.6914)\tAcc 0.375 (0.750)\n",
      "Epoch: [51][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.069)\tLoss 0.8950 (0.7083)\tAcc 0.688 (0.745)\n",
      "Epoch: [51][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.1416 (0.7417)\tAcc 0.438 (0.721)\n",
      "Epoch: [51][14/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.6749 (0.7369)\tAcc 0.688 (0.719)\n",
      "Epoch: [51][15/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 0.8105 (0.7418)\tAcc 0.688 (0.717)\n",
      "Epoch: [51][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.7436 (0.7419)\tAcc 0.750 (0.719)\n",
      "Epoch: [51][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8240 (0.7467)\tAcc 0.625 (0.713)\n",
      "Epoch: [51][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 1.0393 (0.7551)\tAcc 0.625 (0.711)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/12]\tTime 0.247 (0.247)\tData 0.218 (0.218)\tLoss 1.0078 (1.0078)\tAcc 0.625 (0.625)\n",
      "Epoch: [52][2/12]\tTime 0.077 (0.162)\tData 0.050 (0.134)\tLoss 0.4459 (0.7268)\tAcc 0.812 (0.719)\n",
      "Epoch: [52][3/12]\tTime 0.076 (0.133)\tData 0.052 (0.106)\tLoss 0.6688 (0.7075)\tAcc 0.688 (0.708)\n",
      "Epoch: [52][4/12]\tTime 0.080 (0.120)\tData 0.053 (0.093)\tLoss 0.5739 (0.6741)\tAcc 0.812 (0.734)\n",
      "Epoch: [52][5/12]\tTime 0.076 (0.111)\tData 0.051 (0.085)\tLoss 0.6506 (0.6694)\tAcc 0.750 (0.738)\n",
      "Epoch: [52][6/12]\tTime 0.078 (0.106)\tData 0.054 (0.080)\tLoss 0.6528 (0.6666)\tAcc 0.750 (0.740)\n",
      "Epoch: [52][7/12]\tTime 0.085 (0.103)\tData 0.060 (0.077)\tLoss 0.8278 (0.6897)\tAcc 0.562 (0.714)\n",
      "Epoch: [52][8/12]\tTime 0.087 (0.101)\tData 0.061 (0.075)\tLoss 0.4574 (0.6606)\tAcc 0.812 (0.727)\n",
      "Epoch: [52][9/12]\tTime 0.086 (0.099)\tData 0.061 (0.073)\tLoss 0.5056 (0.6434)\tAcc 0.812 (0.736)\n",
      "Epoch: [52][10/12]\tTime 0.086 (0.098)\tData 0.062 (0.072)\tLoss 0.3179 (0.6108)\tAcc 0.938 (0.756)\n",
      "Epoch: [52][11/12]\tTime 0.086 (0.097)\tData 0.062 (0.071)\tLoss 0.4935 (0.6002)\tAcc 0.875 (0.767)\n",
      "Epoch: [52][12/12]\tTime 0.086 (0.096)\tData 0.062 (0.070)\tLoss 0.8391 (0.6189)\tAcc 0.733 (0.764)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/18]\tTime 0.219 (0.219)\tData 0.188 (0.188)\tLoss 0.3370 (0.3370)\tAcc 0.875 (0.875)\n",
      "Epoch: [52][2/18]\tTime 0.066 (0.143)\tData 0.044 (0.116)\tLoss 0.8839 (0.6105)\tAcc 0.625 (0.750)\n",
      "Epoch: [52][3/18]\tTime 0.073 (0.119)\tData 0.052 (0.095)\tLoss 0.6264 (0.6158)\tAcc 0.750 (0.750)\n",
      "Epoch: [52][4/18]\tTime 0.073 (0.108)\tData 0.053 (0.084)\tLoss 0.6317 (0.6198)\tAcc 0.688 (0.734)\n",
      "Epoch: [52][5/18]\tTime 0.073 (0.101)\tData 0.053 (0.078)\tLoss 0.7834 (0.6525)\tAcc 0.750 (0.738)\n",
      "Epoch: [52][6/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.2903 (0.5921)\tAcc 0.938 (0.771)\n",
      "Epoch: [52][7/18]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.7132 (0.6094)\tAcc 0.750 (0.768)\n",
      "Epoch: [52][8/18]\tTime 0.075 (0.091)\tData 0.054 (0.069)\tLoss 0.9471 (0.6516)\tAcc 0.562 (0.742)\n",
      "Epoch: [52][9/18]\tTime 0.078 (0.089)\tData 0.057 (0.068)\tLoss 0.1598 (0.5970)\tAcc 1.000 (0.771)\n",
      "Epoch: [52][10/18]\tTime 0.078 (0.088)\tData 0.057 (0.067)\tLoss 1.2193 (0.6592)\tAcc 0.625 (0.756)\n",
      "Epoch: [52][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 1.2797 (0.7156)\tAcc 0.375 (0.722)\n",
      "Epoch: [52][12/18]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 0.9341 (0.7338)\tAcc 0.750 (0.724)\n",
      "Epoch: [52][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1801 (0.7682)\tAcc 0.500 (0.707)\n",
      "Epoch: [52][14/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.7431 (0.7664)\tAcc 0.625 (0.701)\n",
      "Epoch: [52][15/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.8637 (0.7729)\tAcc 0.625 (0.696)\n",
      "Epoch: [52][16/18]\tTime 0.075 (0.083)\tData 0.055 (0.062)\tLoss 0.8573 (0.7781)\tAcc 0.688 (0.695)\n",
      "Epoch: [52][17/18]\tTime 0.074 (0.082)\tData 0.054 (0.062)\tLoss 0.7540 (0.7767)\tAcc 0.625 (0.691)\n",
      "Epoch: [52][18/18]\tTime 0.077 (0.082)\tData 0.057 (0.061)\tLoss 1.0137 (0.7835)\tAcc 0.500 (0.686)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/12]\tTime 0.240 (0.240)\tData 0.209 (0.209)\tLoss 0.5400 (0.5400)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][2/12]\tTime 0.074 (0.157)\tData 0.049 (0.129)\tLoss 0.6685 (0.6043)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][3/12]\tTime 0.082 (0.132)\tData 0.056 (0.105)\tLoss 0.6206 (0.6097)\tAcc 0.812 (0.771)\n",
      "Epoch: [53][4/12]\tTime 0.082 (0.119)\tData 0.054 (0.092)\tLoss 0.8013 (0.6576)\tAcc 0.625 (0.734)\n",
      "Epoch: [53][5/12]\tTime 0.076 (0.111)\tData 0.051 (0.084)\tLoss 1.0857 (0.7432)\tAcc 0.562 (0.700)\n",
      "Epoch: [53][6/12]\tTime 0.078 (0.105)\tData 0.054 (0.079)\tLoss 0.4946 (0.7018)\tAcc 0.812 (0.719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53][7/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.4495 (0.6657)\tAcc 0.875 (0.741)\n",
      "Epoch: [53][8/12]\tTime 0.078 (0.098)\tData 0.054 (0.073)\tLoss 0.7890 (0.6811)\tAcc 0.688 (0.734)\n",
      "Epoch: [53][9/12]\tTime 0.078 (0.096)\tData 0.054 (0.071)\tLoss 0.4905 (0.6600)\tAcc 0.688 (0.729)\n",
      "Epoch: [53][10/12]\tTime 0.080 (0.094)\tData 0.056 (0.069)\tLoss 0.8635 (0.6803)\tAcc 0.750 (0.731)\n",
      "Epoch: [53][11/12]\tTime 0.079 (0.093)\tData 0.054 (0.068)\tLoss 0.3535 (0.6506)\tAcc 0.938 (0.750)\n",
      "Epoch: [53][12/12]\tTime 0.079 (0.092)\tData 0.055 (0.067)\tLoss 0.7983 (0.6622)\tAcc 0.600 (0.738)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/18]\tTime 0.221 (0.221)\tData 0.194 (0.194)\tLoss 0.3404 (0.3404)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/18]\tTime 0.071 (0.146)\tData 0.048 (0.121)\tLoss 0.8998 (0.6201)\tAcc 0.562 (0.750)\n",
      "Epoch: [53][3/18]\tTime 0.071 (0.121)\tData 0.051 (0.097)\tLoss 0.5826 (0.6076)\tAcc 0.812 (0.771)\n",
      "Epoch: [53][4/18]\tTime 0.075 (0.110)\tData 0.055 (0.087)\tLoss 0.5964 (0.6048)\tAcc 0.750 (0.766)\n",
      "Epoch: [53][5/18]\tTime 0.074 (0.103)\tData 0.054 (0.080)\tLoss 0.7766 (0.6392)\tAcc 0.750 (0.762)\n",
      "Epoch: [53][6/18]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.2383 (0.5723)\tAcc 1.000 (0.802)\n",
      "Epoch: [53][7/18]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.6033 (0.5768)\tAcc 0.750 (0.795)\n",
      "Epoch: [53][8/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 1.0139 (0.6314)\tAcc 0.688 (0.781)\n",
      "Epoch: [53][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.068)\tLoss 0.1313 (0.5758)\tAcc 1.000 (0.806)\n",
      "Epoch: [53][10/18]\tTime 0.074 (0.088)\tData 0.053 (0.067)\tLoss 1.1188 (0.6301)\tAcc 0.750 (0.800)\n",
      "Epoch: [53][11/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 1.1652 (0.6788)\tAcc 0.375 (0.761)\n",
      "Epoch: [53][12/18]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 0.8450 (0.6926)\tAcc 0.812 (0.766)\n",
      "Epoch: [53][13/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 1.0696 (0.7216)\tAcc 0.562 (0.750)\n",
      "Epoch: [53][14/18]\tTime 0.075 (0.084)\tData 0.055 (0.063)\tLoss 0.7701 (0.7251)\tAcc 0.625 (0.741)\n",
      "Epoch: [53][15/18]\tTime 0.074 (0.083)\tData 0.054 (0.063)\tLoss 0.8104 (0.7308)\tAcc 0.688 (0.738)\n",
      "Epoch: [53][16/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.8314 (0.7371)\tAcc 0.688 (0.734)\n",
      "Epoch: [53][17/18]\tTime 0.074 (0.082)\tData 0.054 (0.062)\tLoss 0.8864 (0.7459)\tAcc 0.625 (0.728)\n",
      "Epoch: [53][18/18]\tTime 0.072 (0.082)\tData 0.054 (0.061)\tLoss 0.7451 (0.7458)\tAcc 0.875 (0.732)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/12]\tTime 0.241 (0.241)\tData 0.206 (0.206)\tLoss 0.7442 (0.7442)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][2/12]\tTime 0.071 (0.156)\tData 0.045 (0.126)\tLoss 0.7435 (0.7439)\tAcc 0.688 (0.719)\n",
      "Epoch: [54][3/12]\tTime 0.082 (0.131)\tData 0.054 (0.102)\tLoss 0.4379 (0.6419)\tAcc 0.875 (0.771)\n",
      "Epoch: [54][4/12]\tTime 0.078 (0.118)\tData 0.051 (0.089)\tLoss 0.9249 (0.7126)\tAcc 0.625 (0.734)\n",
      "Epoch: [54][5/12]\tTime 0.081 (0.110)\tData 0.054 (0.082)\tLoss 0.7174 (0.7136)\tAcc 0.750 (0.738)\n",
      "Epoch: [54][6/12]\tTime 0.077 (0.105)\tData 0.052 (0.077)\tLoss 0.5271 (0.6825)\tAcc 0.812 (0.750)\n",
      "Epoch: [54][7/12]\tTime 0.078 (0.101)\tData 0.054 (0.074)\tLoss 0.5575 (0.6646)\tAcc 0.812 (0.759)\n",
      "Epoch: [54][8/12]\tTime 0.085 (0.099)\tData 0.060 (0.072)\tLoss 0.7210 (0.6717)\tAcc 0.688 (0.750)\n",
      "Epoch: [54][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.071)\tLoss 0.6021 (0.6640)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][10/12]\tTime 0.087 (0.097)\tData 0.062 (0.070)\tLoss 0.3351 (0.6311)\tAcc 0.938 (0.769)\n",
      "Epoch: [54][11/12]\tTime 0.086 (0.096)\tData 0.062 (0.069)\tLoss 0.9264 (0.6579)\tAcc 0.688 (0.761)\n",
      "Epoch: [54][12/12]\tTime 0.086 (0.095)\tData 0.062 (0.069)\tLoss 0.6261 (0.6554)\tAcc 0.667 (0.754)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/18]\tTime 0.236 (0.236)\tData 0.210 (0.210)\tLoss 0.2804 (0.2804)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/18]\tTime 0.082 (0.159)\tData 0.055 (0.132)\tLoss 0.8415 (0.5610)\tAcc 0.500 (0.719)\n",
      "Epoch: [54][3/18]\tTime 0.074 (0.131)\tData 0.053 (0.106)\tLoss 0.6385 (0.5868)\tAcc 0.812 (0.750)\n",
      "Epoch: [54][4/18]\tTime 0.080 (0.118)\tData 0.059 (0.094)\tLoss 0.5922 (0.5882)\tAcc 0.688 (0.734)\n",
      "Epoch: [54][5/18]\tTime 0.082 (0.111)\tData 0.059 (0.087)\tLoss 0.7813 (0.6268)\tAcc 0.750 (0.738)\n",
      "Epoch: [54][6/18]\tTime 0.079 (0.105)\tData 0.058 (0.082)\tLoss 0.3072 (0.5735)\tAcc 1.000 (0.781)\n",
      "Epoch: [54][7/18]\tTime 0.081 (0.102)\tData 0.058 (0.079)\tLoss 0.7019 (0.5919)\tAcc 0.750 (0.777)\n",
      "Epoch: [54][8/18]\tTime 0.079 (0.099)\tData 0.057 (0.076)\tLoss 1.0159 (0.6449)\tAcc 0.688 (0.766)\n",
      "Epoch: [54][9/18]\tTime 0.080 (0.097)\tData 0.059 (0.074)\tLoss 0.1153 (0.5860)\tAcc 1.000 (0.792)\n",
      "Epoch: [54][10/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 1.1443 (0.6419)\tAcc 0.625 (0.775)\n",
      "Epoch: [54][11/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 1.2080 (0.6933)\tAcc 0.375 (0.739)\n",
      "Epoch: [54][12/18]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.8526 (0.7066)\tAcc 0.812 (0.745)\n",
      "Epoch: [54][13/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 1.1304 (0.7392)\tAcc 0.562 (0.731)\n",
      "Epoch: [54][14/18]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.6884 (0.7356)\tAcc 0.625 (0.723)\n",
      "Epoch: [54][15/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.8366 (0.7423)\tAcc 0.688 (0.721)\n",
      "Epoch: [54][16/18]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 0.9657 (0.7563)\tAcc 0.562 (0.711)\n",
      "Epoch: [54][17/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.8404 (0.7612)\tAcc 0.625 (0.706)\n",
      "Epoch: [54][18/18]\tTime 0.077 (0.086)\tData 0.057 (0.065)\tLoss 0.6472 (0.7580)\tAcc 0.750 (0.707)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/12]\tTime 0.257 (0.257)\tData 0.222 (0.222)\tLoss 0.5397 (0.5397)\tAcc 0.750 (0.750)\n",
      "Epoch: [55][2/12]\tTime 0.080 (0.169)\tData 0.052 (0.137)\tLoss 0.9131 (0.7264)\tAcc 0.688 (0.719)\n",
      "Epoch: [55][3/12]\tTime 0.083 (0.140)\tData 0.058 (0.111)\tLoss 0.7208 (0.7246)\tAcc 0.625 (0.688)\n",
      "Epoch: [55][4/12]\tTime 0.087 (0.127)\tData 0.061 (0.098)\tLoss 0.5743 (0.6870)\tAcc 0.812 (0.719)\n",
      "Epoch: [55][5/12]\tTime 0.087 (0.119)\tData 0.061 (0.091)\tLoss 0.6245 (0.6745)\tAcc 0.875 (0.750)\n",
      "Epoch: [55][6/12]\tTime 0.086 (0.113)\tData 0.062 (0.086)\tLoss 0.3881 (0.6268)\tAcc 0.875 (0.771)\n",
      "Epoch: [55][7/12]\tTime 0.086 (0.110)\tData 0.062 (0.083)\tLoss 0.8454 (0.6580)\tAcc 0.688 (0.759)\n",
      "Epoch: [55][8/12]\tTime 0.081 (0.106)\tData 0.058 (0.080)\tLoss 0.7493 (0.6694)\tAcc 0.625 (0.742)\n",
      "Epoch: [55][9/12]\tTime 0.078 (0.103)\tData 0.054 (0.077)\tLoss 0.5567 (0.6569)\tAcc 0.750 (0.743)\n",
      "Epoch: [55][10/12]\tTime 0.078 (0.100)\tData 0.055 (0.075)\tLoss 0.4311 (0.6343)\tAcc 0.812 (0.750)\n",
      "Epoch: [55][11/12]\tTime 0.079 (0.098)\tData 0.055 (0.073)\tLoss 0.6570 (0.6364)\tAcc 0.750 (0.750)\n",
      "Epoch: [55][12/12]\tTime 0.082 (0.097)\tData 0.058 (0.072)\tLoss 0.8534 (0.6534)\tAcc 0.467 (0.728)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/18]\tTime 0.230 (0.230)\tData 0.195 (0.195)\tLoss 0.2600 (0.2600)\tAcc 1.000 (1.000)\n",
      "Epoch: [55][2/18]\tTime 0.071 (0.150)\tData 0.046 (0.120)\tLoss 0.8511 (0.5555)\tAcc 0.625 (0.812)\n",
      "Epoch: [55][3/18]\tTime 0.073 (0.125)\tData 0.052 (0.097)\tLoss 0.5817 (0.5642)\tAcc 0.812 (0.812)\n",
      "Epoch: [55][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.088)\tLoss 0.5658 (0.5646)\tAcc 0.688 (0.781)\n",
      "Epoch: [55][5/18]\tTime 0.082 (0.107)\tData 0.059 (0.082)\tLoss 0.7875 (0.6092)\tAcc 0.688 (0.762)\n",
      "Epoch: [55][6/18]\tTime 0.080 (0.103)\tData 0.058 (0.078)\tLoss 0.2541 (0.5500)\tAcc 1.000 (0.802)\n",
      "Epoch: [55][7/18]\tTime 0.080 (0.099)\tData 0.059 (0.075)\tLoss 0.6515 (0.5645)\tAcc 0.750 (0.795)\n",
      "Epoch: [55][8/18]\tTime 0.082 (0.097)\tData 0.059 (0.073)\tLoss 1.0083 (0.6200)\tAcc 0.562 (0.766)\n",
      "Epoch: [55][9/18]\tTime 0.079 (0.095)\tData 0.058 (0.072)\tLoss 0.1033 (0.5626)\tAcc 1.000 (0.792)\n",
      "Epoch: [55][10/18]\tTime 0.076 (0.093)\tData 0.056 (0.070)\tLoss 1.0055 (0.6069)\tAcc 0.688 (0.781)\n",
      "Epoch: [55][11/18]\tTime 0.074 (0.092)\tData 0.054 (0.069)\tLoss 1.2888 (0.6689)\tAcc 0.375 (0.744)\n",
      "Epoch: [55][12/18]\tTime 0.078 (0.090)\tData 0.058 (0.068)\tLoss 0.9704 (0.6940)\tAcc 0.812 (0.750)\n",
      "Epoch: [55][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 1.0706 (0.7230)\tAcc 0.375 (0.721)\n",
      "Epoch: [55][14/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.7645 (0.7259)\tAcc 0.625 (0.714)\n",
      "Epoch: [55][15/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8619 (0.7350)\tAcc 0.750 (0.717)\n",
      "Epoch: [55][16/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7443 (0.7356)\tAcc 0.750 (0.719)\n",
      "Epoch: [55][17/18]\tTime 0.080 (0.087)\tData 0.060 (0.066)\tLoss 0.8269 (0.7409)\tAcc 0.625 (0.713)\n",
      "Epoch: [55][18/18]\tTime 0.078 (0.087)\tData 0.059 (0.065)\tLoss 0.8186 (0.7432)\tAcc 0.750 (0.714)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/12]\tTime 0.245 (0.245)\tData 0.210 (0.210)\tLoss 0.8402 (0.8402)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][2/12]\tTime 0.071 (0.158)\tData 0.044 (0.127)\tLoss 0.7646 (0.8024)\tAcc 0.625 (0.656)\n",
      "Epoch: [56][3/12]\tTime 0.087 (0.134)\tData 0.061 (0.105)\tLoss 0.5403 (0.7150)\tAcc 0.812 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][4/12]\tTime 0.091 (0.123)\tData 0.063 (0.094)\tLoss 0.8432 (0.7471)\tAcc 0.625 (0.688)\n",
      "Epoch: [56][5/12]\tTime 0.084 (0.116)\tData 0.059 (0.087)\tLoss 0.3996 (0.6776)\tAcc 0.875 (0.725)\n",
      "Epoch: [56][6/12]\tTime 0.086 (0.111)\tData 0.061 (0.083)\tLoss 0.6622 (0.6750)\tAcc 0.688 (0.719)\n",
      "Epoch: [56][7/12]\tTime 0.086 (0.107)\tData 0.061 (0.080)\tLoss 0.6004 (0.6644)\tAcc 0.812 (0.732)\n",
      "Epoch: [56][8/12]\tTime 0.087 (0.105)\tData 0.062 (0.078)\tLoss 0.5871 (0.6547)\tAcc 0.750 (0.734)\n",
      "Epoch: [56][9/12]\tTime 0.084 (0.102)\tData 0.059 (0.075)\tLoss 0.7473 (0.6650)\tAcc 0.750 (0.736)\n",
      "Epoch: [56][10/12]\tTime 0.087 (0.101)\tData 0.062 (0.074)\tLoss 0.6044 (0.6589)\tAcc 0.812 (0.744)\n",
      "Epoch: [56][11/12]\tTime 0.086 (0.099)\tData 0.062 (0.073)\tLoss 0.5900 (0.6527)\tAcc 0.750 (0.744)\n",
      "Epoch: [56][12/12]\tTime 0.086 (0.098)\tData 0.061 (0.072)\tLoss 0.7747 (0.6622)\tAcc 0.667 (0.738)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/18]\tTime 0.240 (0.240)\tData 0.203 (0.203)\tLoss 0.2744 (0.2744)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/18]\tTime 0.076 (0.158)\tData 0.044 (0.124)\tLoss 0.8295 (0.5519)\tAcc 0.625 (0.781)\n",
      "Epoch: [56][3/18]\tTime 0.070 (0.129)\tData 0.049 (0.099)\tLoss 0.6380 (0.5806)\tAcc 0.688 (0.750)\n",
      "Epoch: [56][4/18]\tTime 0.080 (0.116)\tData 0.059 (0.089)\tLoss 0.5558 (0.5744)\tAcc 0.750 (0.750)\n",
      "Epoch: [56][5/18]\tTime 0.075 (0.108)\tData 0.055 (0.082)\tLoss 0.7453 (0.6086)\tAcc 0.688 (0.738)\n",
      "Epoch: [56][6/18]\tTime 0.076 (0.103)\tData 0.055 (0.078)\tLoss 0.3332 (0.5627)\tAcc 0.938 (0.771)\n",
      "Epoch: [56][7/18]\tTime 0.081 (0.100)\tData 0.060 (0.075)\tLoss 0.5843 (0.5658)\tAcc 0.750 (0.768)\n",
      "Epoch: [56][8/18]\tTime 0.082 (0.097)\tData 0.059 (0.073)\tLoss 0.8629 (0.6029)\tAcc 0.688 (0.758)\n",
      "Epoch: [56][9/18]\tTime 0.079 (0.095)\tData 0.058 (0.071)\tLoss 0.1057 (0.5477)\tAcc 1.000 (0.785)\n",
      "Epoch: [56][10/18]\tTime 0.081 (0.094)\tData 0.059 (0.070)\tLoss 0.9914 (0.5920)\tAcc 0.688 (0.775)\n",
      "Epoch: [56][11/18]\tTime 0.079 (0.093)\tData 0.058 (0.069)\tLoss 1.3511 (0.6611)\tAcc 0.375 (0.739)\n",
      "Epoch: [56][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.068)\tLoss 0.8853 (0.6797)\tAcc 0.812 (0.745)\n",
      "Epoch: [56][13/18]\tTime 0.074 (0.090)\tData 0.056 (0.067)\tLoss 1.0281 (0.7065)\tAcc 0.625 (0.736)\n",
      "Epoch: [56][14/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 0.7664 (0.7108)\tAcc 0.688 (0.732)\n",
      "Epoch: [56][15/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 0.8274 (0.7186)\tAcc 0.750 (0.733)\n",
      "Epoch: [56][16/18]\tTime 0.075 (0.087)\tData 0.055 (0.065)\tLoss 0.8424 (0.7263)\tAcc 0.625 (0.727)\n",
      "Epoch: [56][17/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.7289 (0.7265)\tAcc 0.625 (0.721)\n",
      "Epoch: [56][18/18]\tTime 0.080 (0.086)\tData 0.061 (0.065)\tLoss 0.6593 (0.7246)\tAcc 0.875 (0.725)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/12]\tTime 0.242 (0.242)\tData 0.211 (0.211)\tLoss 0.7750 (0.7750)\tAcc 0.688 (0.688)\n",
      "Epoch: [57][2/12]\tTime 0.084 (0.163)\tData 0.058 (0.135)\tLoss 0.6241 (0.6996)\tAcc 0.750 (0.719)\n",
      "Epoch: [57][3/12]\tTime 0.084 (0.137)\tData 0.058 (0.109)\tLoss 0.6648 (0.6880)\tAcc 0.688 (0.708)\n",
      "Epoch: [57][4/12]\tTime 0.091 (0.125)\tData 0.061 (0.097)\tLoss 0.5952 (0.6648)\tAcc 0.812 (0.734)\n",
      "Epoch: [57][5/12]\tTime 0.082 (0.117)\tData 0.057 (0.089)\tLoss 0.5535 (0.6425)\tAcc 0.688 (0.725)\n",
      "Epoch: [57][6/12]\tTime 0.087 (0.112)\tData 0.062 (0.085)\tLoss 0.8993 (0.6853)\tAcc 0.562 (0.698)\n",
      "Epoch: [57][7/12]\tTime 0.087 (0.108)\tData 0.062 (0.081)\tLoss 0.7310 (0.6918)\tAcc 0.750 (0.705)\n",
      "Epoch: [57][8/12]\tTime 0.085 (0.105)\tData 0.060 (0.079)\tLoss 0.4823 (0.6656)\tAcc 0.812 (0.719)\n",
      "Epoch: [57][9/12]\tTime 0.083 (0.103)\tData 0.059 (0.076)\tLoss 0.4756 (0.6445)\tAcc 0.812 (0.729)\n",
      "Epoch: [57][10/12]\tTime 0.087 (0.101)\tData 0.062 (0.075)\tLoss 0.8471 (0.6648)\tAcc 0.750 (0.731)\n",
      "Epoch: [57][11/12]\tTime 0.086 (0.100)\tData 0.061 (0.074)\tLoss 0.7319 (0.6709)\tAcc 0.812 (0.739)\n",
      "Epoch: [57][12/12]\tTime 0.086 (0.099)\tData 0.062 (0.073)\tLoss 0.4199 (0.6512)\tAcc 0.800 (0.743)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/18]\tTime 0.233 (0.233)\tData 0.193 (0.193)\tLoss 0.2641 (0.2641)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/18]\tTime 0.067 (0.150)\tData 0.042 (0.118)\tLoss 0.9272 (0.5956)\tAcc 0.500 (0.719)\n",
      "Epoch: [57][3/18]\tTime 0.077 (0.126)\tData 0.056 (0.097)\tLoss 0.6136 (0.6016)\tAcc 0.750 (0.729)\n",
      "Epoch: [57][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.088)\tLoss 0.5601 (0.5912)\tAcc 0.875 (0.766)\n",
      "Epoch: [57][5/18]\tTime 0.076 (0.107)\tData 0.055 (0.081)\tLoss 0.8320 (0.6394)\tAcc 0.625 (0.738)\n",
      "Epoch: [57][6/18]\tTime 0.074 (0.101)\tData 0.053 (0.077)\tLoss 0.2338 (0.5718)\tAcc 1.000 (0.781)\n",
      "Epoch: [57][7/18]\tTime 0.081 (0.098)\tData 0.059 (0.074)\tLoss 0.6535 (0.5835)\tAcc 0.688 (0.768)\n",
      "Epoch: [57][8/18]\tTime 0.081 (0.096)\tData 0.059 (0.072)\tLoss 1.0039 (0.6360)\tAcc 0.562 (0.742)\n",
      "Epoch: [57][9/18]\tTime 0.080 (0.094)\tData 0.058 (0.071)\tLoss 0.1142 (0.5781)\tAcc 1.000 (0.771)\n",
      "Epoch: [57][10/18]\tTime 0.081 (0.093)\tData 0.059 (0.069)\tLoss 1.2598 (0.6462)\tAcc 0.562 (0.750)\n",
      "Epoch: [57][11/18]\tTime 0.078 (0.092)\tData 0.058 (0.068)\tLoss 1.2239 (0.6987)\tAcc 0.375 (0.716)\n",
      "Epoch: [57][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.9196 (0.7171)\tAcc 0.750 (0.719)\n",
      "Epoch: [57][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 1.1554 (0.7509)\tAcc 0.562 (0.707)\n",
      "Epoch: [57][14/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.5849 (0.7390)\tAcc 0.688 (0.705)\n",
      "Epoch: [57][15/18]\tTime 0.078 (0.088)\tData 0.057 (0.066)\tLoss 0.9746 (0.7547)\tAcc 0.625 (0.700)\n",
      "Epoch: [57][16/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7808 (0.7563)\tAcc 0.750 (0.703)\n",
      "Epoch: [57][17/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.7531 (0.7561)\tAcc 0.625 (0.699)\n",
      "Epoch: [57][18/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.8062 (0.7576)\tAcc 0.750 (0.700)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/12]\tTime 0.291 (0.291)\tData 0.260 (0.260)\tLoss 0.7130 (0.7130)\tAcc 0.625 (0.625)\n",
      "Epoch: [58][2/12]\tTime 0.077 (0.184)\tData 0.049 (0.154)\tLoss 0.6233 (0.6681)\tAcc 0.812 (0.719)\n",
      "Epoch: [58][3/12]\tTime 0.077 (0.149)\tData 0.050 (0.120)\tLoss 0.6670 (0.6678)\tAcc 0.812 (0.750)\n",
      "Epoch: [58][4/12]\tTime 0.078 (0.131)\tData 0.051 (0.102)\tLoss 0.6804 (0.6709)\tAcc 0.750 (0.750)\n",
      "Epoch: [58][5/12]\tTime 0.076 (0.120)\tData 0.052 (0.092)\tLoss 0.7002 (0.6768)\tAcc 0.750 (0.750)\n",
      "Epoch: [58][6/12]\tTime 0.077 (0.113)\tData 0.053 (0.086)\tLoss 0.5722 (0.6594)\tAcc 0.812 (0.760)\n",
      "Epoch: [58][7/12]\tTime 0.078 (0.108)\tData 0.054 (0.081)\tLoss 0.5706 (0.6467)\tAcc 0.750 (0.759)\n",
      "Epoch: [58][8/12]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 0.5658 (0.6366)\tAcc 0.688 (0.750)\n",
      "Epoch: [58][9/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.8568 (0.6610)\tAcc 0.625 (0.736)\n",
      "Epoch: [58][10/12]\tTime 0.078 (0.099)\tData 0.055 (0.073)\tLoss 0.3972 (0.6346)\tAcc 0.875 (0.750)\n",
      "Epoch: [58][11/12]\tTime 0.079 (0.097)\tData 0.055 (0.072)\tLoss 0.7372 (0.6440)\tAcc 0.688 (0.744)\n",
      "Epoch: [58][12/12]\tTime 0.079 (0.096)\tData 0.055 (0.070)\tLoss 0.6159 (0.6418)\tAcc 0.733 (0.743)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/18]\tTime 0.222 (0.222)\tData 0.190 (0.190)\tLoss 0.3537 (0.3537)\tAcc 0.875 (0.875)\n",
      "Epoch: [58][2/18]\tTime 0.066 (0.144)\tData 0.043 (0.117)\tLoss 0.9308 (0.6423)\tAcc 0.562 (0.719)\n",
      "Epoch: [58][3/18]\tTime 0.076 (0.121)\tData 0.055 (0.096)\tLoss 0.5576 (0.6140)\tAcc 0.688 (0.708)\n",
      "Epoch: [58][4/18]\tTime 0.074 (0.110)\tData 0.054 (0.085)\tLoss 0.5963 (0.6096)\tAcc 0.812 (0.734)\n",
      "Epoch: [58][5/18]\tTime 0.075 (0.103)\tData 0.054 (0.079)\tLoss 0.8573 (0.6591)\tAcc 0.750 (0.738)\n",
      "Epoch: [58][6/18]\tTime 0.075 (0.098)\tData 0.055 (0.075)\tLoss 0.2680 (0.5939)\tAcc 1.000 (0.781)\n",
      "Epoch: [58][7/18]\tTime 0.074 (0.095)\tData 0.053 (0.072)\tLoss 0.6495 (0.6019)\tAcc 0.688 (0.768)\n",
      "Epoch: [58][8/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9148 (0.6410)\tAcc 0.750 (0.766)\n",
      "Epoch: [58][9/18]\tTime 0.074 (0.090)\tData 0.053 (0.068)\tLoss 0.1190 (0.5830)\tAcc 1.000 (0.792)\n",
      "Epoch: [58][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1033 (0.6350)\tAcc 0.688 (0.781)\n",
      "Epoch: [58][11/18]\tTime 0.073 (0.087)\tData 0.053 (0.065)\tLoss 1.2464 (0.6906)\tAcc 0.375 (0.744)\n",
      "Epoch: [58][12/18]\tTime 0.075 (0.086)\tData 0.055 (0.064)\tLoss 0.8976 (0.7079)\tAcc 0.750 (0.745)\n",
      "Epoch: [58][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1994 (0.7457)\tAcc 0.375 (0.716)\n",
      "Epoch: [58][14/18]\tTime 0.073 (0.084)\tData 0.054 (0.063)\tLoss 0.8128 (0.7505)\tAcc 0.625 (0.710)\n",
      "Epoch: [58][15/18]\tTime 0.075 (0.084)\tData 0.055 (0.062)\tLoss 0.8543 (0.7574)\tAcc 0.688 (0.708)\n",
      "Epoch: [58][16/18]\tTime 0.075 (0.083)\tData 0.054 (0.062)\tLoss 0.9170 (0.7674)\tAcc 0.562 (0.699)\n",
      "Epoch: [58][17/18]\tTime 0.075 (0.083)\tData 0.055 (0.062)\tLoss 0.7855 (0.7684)\tAcc 0.688 (0.699)\n",
      "Epoch: [58][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.9250 (0.7729)\tAcc 0.625 (0.696)\n",
      "train at epoch 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [59][1/12]\tTime 0.244 (0.244)\tData 0.214 (0.214)\tLoss 0.7598 (0.7598)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][2/12]\tTime 0.075 (0.159)\tData 0.050 (0.132)\tLoss 0.7466 (0.7532)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][3/12]\tTime 0.079 (0.132)\tData 0.053 (0.106)\tLoss 0.5895 (0.6986)\tAcc 0.812 (0.729)\n",
      "Epoch: [59][4/12]\tTime 0.078 (0.119)\tData 0.053 (0.092)\tLoss 0.5898 (0.6714)\tAcc 0.812 (0.750)\n",
      "Epoch: [59][5/12]\tTime 0.077 (0.110)\tData 0.053 (0.085)\tLoss 0.5861 (0.6544)\tAcc 0.688 (0.738)\n",
      "Epoch: [59][6/12]\tTime 0.082 (0.106)\tData 0.058 (0.080)\tLoss 0.7956 (0.6779)\tAcc 0.750 (0.740)\n",
      "Epoch: [59][7/12]\tTime 0.079 (0.102)\tData 0.055 (0.076)\tLoss 0.4702 (0.6482)\tAcc 0.812 (0.750)\n",
      "Epoch: [59][8/12]\tTime 0.084 (0.100)\tData 0.060 (0.074)\tLoss 0.4394 (0.6221)\tAcc 0.812 (0.758)\n",
      "Epoch: [59][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.073)\tLoss 0.7540 (0.6368)\tAcc 0.750 (0.757)\n",
      "Epoch: [59][10/12]\tTime 0.086 (0.097)\tData 0.062 (0.072)\tLoss 0.5290 (0.6260)\tAcc 0.750 (0.756)\n",
      "Epoch: [59][11/12]\tTime 0.086 (0.096)\tData 0.062 (0.071)\tLoss 0.5063 (0.6151)\tAcc 0.812 (0.761)\n",
      "Epoch: [59][12/12]\tTime 0.087 (0.095)\tData 0.062 (0.070)\tLoss 0.8211 (0.6313)\tAcc 0.600 (0.749)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/18]\tTime 0.238 (0.238)\tData 0.212 (0.212)\tLoss 0.2528 (0.2528)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/18]\tTime 0.082 (0.160)\tData 0.056 (0.134)\tLoss 0.9159 (0.5844)\tAcc 0.625 (0.781)\n",
      "Epoch: [59][3/18]\tTime 0.076 (0.132)\tData 0.055 (0.107)\tLoss 0.6111 (0.5933)\tAcc 0.750 (0.771)\n",
      "Epoch: [59][4/18]\tTime 0.080 (0.119)\tData 0.059 (0.095)\tLoss 0.5543 (0.5835)\tAcc 0.812 (0.781)\n",
      "Epoch: [59][5/18]\tTime 0.081 (0.111)\tData 0.059 (0.088)\tLoss 0.7213 (0.6111)\tAcc 0.875 (0.800)\n",
      "Epoch: [59][6/18]\tTime 0.079 (0.106)\tData 0.058 (0.083)\tLoss 0.2837 (0.5565)\tAcc 1.000 (0.833)\n",
      "Epoch: [59][7/18]\tTime 0.081 (0.102)\tData 0.059 (0.080)\tLoss 0.5332 (0.5532)\tAcc 0.938 (0.848)\n",
      "Epoch: [59][8/18]\tTime 0.075 (0.099)\tData 0.055 (0.076)\tLoss 0.9541 (0.6033)\tAcc 0.625 (0.820)\n",
      "Epoch: [59][9/18]\tTime 0.079 (0.097)\tData 0.059 (0.074)\tLoss 0.1065 (0.5481)\tAcc 1.000 (0.840)\n",
      "Epoch: [59][10/18]\tTime 0.081 (0.095)\tData 0.059 (0.073)\tLoss 0.9972 (0.5930)\tAcc 0.562 (0.812)\n",
      "Epoch: [59][11/18]\tTime 0.079 (0.094)\tData 0.059 (0.072)\tLoss 1.2935 (0.6567)\tAcc 0.375 (0.773)\n",
      "Epoch: [59][12/18]\tTime 0.080 (0.093)\tData 0.060 (0.071)\tLoss 0.8422 (0.6722)\tAcc 0.750 (0.771)\n",
      "Epoch: [59][13/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 1.2356 (0.7155)\tAcc 0.562 (0.755)\n",
      "Epoch: [59][14/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.6712 (0.7123)\tAcc 0.688 (0.750)\n",
      "Epoch: [59][15/18]\tTime 0.078 (0.090)\tData 0.058 (0.068)\tLoss 0.8974 (0.7247)\tAcc 0.688 (0.746)\n",
      "Epoch: [59][16/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.8054 (0.7297)\tAcc 0.625 (0.738)\n",
      "Epoch: [59][17/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.7113 (0.7286)\tAcc 0.688 (0.735)\n",
      "Epoch: [59][18/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.8610 (0.7324)\tAcc 0.625 (0.732)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/12]\tTime 0.238 (0.238)\tData 0.204 (0.204)\tLoss 0.8750 (0.8750)\tAcc 0.688 (0.688)\n",
      "Epoch: [60][2/12]\tTime 0.074 (0.156)\tData 0.047 (0.125)\tLoss 0.4539 (0.6644)\tAcc 0.812 (0.750)\n",
      "Epoch: [60][3/12]\tTime 0.079 (0.130)\tData 0.054 (0.102)\tLoss 0.5597 (0.6295)\tAcc 0.875 (0.792)\n",
      "Epoch: [60][4/12]\tTime 0.095 (0.121)\tData 0.062 (0.092)\tLoss 0.3230 (0.5529)\tAcc 1.000 (0.844)\n",
      "Epoch: [60][5/12]\tTime 0.085 (0.114)\tData 0.061 (0.086)\tLoss 0.8657 (0.6155)\tAcc 0.688 (0.812)\n",
      "Epoch: [60][6/12]\tTime 0.087 (0.110)\tData 0.062 (0.082)\tLoss 0.6917 (0.6282)\tAcc 0.688 (0.792)\n",
      "Epoch: [60][7/12]\tTime 0.086 (0.106)\tData 0.061 (0.079)\tLoss 0.6595 (0.6326)\tAcc 0.812 (0.795)\n",
      "Epoch: [60][8/12]\tTime 0.086 (0.104)\tData 0.062 (0.077)\tLoss 0.5660 (0.6243)\tAcc 0.812 (0.797)\n",
      "Epoch: [60][9/12]\tTime 0.086 (0.102)\tData 0.062 (0.075)\tLoss 0.5010 (0.6106)\tAcc 0.812 (0.799)\n",
      "Epoch: [60][10/12]\tTime 0.088 (0.101)\tData 0.062 (0.074)\tLoss 1.1497 (0.6645)\tAcc 0.688 (0.788)\n",
      "Epoch: [60][11/12]\tTime 0.082 (0.099)\tData 0.057 (0.072)\tLoss 0.7232 (0.6698)\tAcc 0.750 (0.784)\n",
      "Epoch: [60][12/12]\tTime 0.087 (0.098)\tData 0.061 (0.071)\tLoss 0.9460 (0.6915)\tAcc 0.600 (0.770)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/18]\tTime 0.227 (0.227)\tData 0.203 (0.203)\tLoss 0.2927 (0.2927)\tAcc 1.000 (1.000)\n",
      "Epoch: [60][2/18]\tTime 0.079 (0.153)\tData 0.050 (0.126)\tLoss 0.8239 (0.5583)\tAcc 0.625 (0.812)\n",
      "Epoch: [60][3/18]\tTime 0.071 (0.126)\tData 0.049 (0.101)\tLoss 0.5005 (0.5390)\tAcc 0.812 (0.812)\n",
      "Epoch: [60][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.090)\tLoss 0.5952 (0.5531)\tAcc 0.688 (0.781)\n",
      "Epoch: [60][5/18]\tTime 0.081 (0.108)\tData 0.059 (0.084)\tLoss 0.8058 (0.6036)\tAcc 0.688 (0.762)\n",
      "Epoch: [60][6/18]\tTime 0.080 (0.103)\tData 0.058 (0.080)\tLoss 0.2427 (0.5435)\tAcc 1.000 (0.802)\n",
      "Epoch: [60][7/18]\tTime 0.081 (0.100)\tData 0.059 (0.077)\tLoss 0.6625 (0.5605)\tAcc 0.812 (0.804)\n",
      "Epoch: [60][8/18]\tTime 0.079 (0.097)\tData 0.058 (0.074)\tLoss 0.9805 (0.6130)\tAcc 0.625 (0.781)\n",
      "Epoch: [60][9/18]\tTime 0.077 (0.095)\tData 0.057 (0.072)\tLoss 0.1337 (0.5597)\tAcc 1.000 (0.806)\n",
      "Epoch: [60][10/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 0.9830 (0.6020)\tAcc 0.688 (0.794)\n",
      "Epoch: [60][11/18]\tTime 0.077 (0.092)\tData 0.057 (0.069)\tLoss 1.2280 (0.6589)\tAcc 0.375 (0.756)\n",
      "Epoch: [60][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.7891 (0.6698)\tAcc 0.750 (0.755)\n",
      "Epoch: [60][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 1.1177 (0.7042)\tAcc 0.438 (0.731)\n",
      "Epoch: [60][14/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.7915 (0.7105)\tAcc 0.562 (0.719)\n",
      "Epoch: [60][15/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.7858 (0.7155)\tAcc 0.750 (0.721)\n",
      "Epoch: [60][16/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8326 (0.7228)\tAcc 0.625 (0.715)\n",
      "Epoch: [60][17/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7568 (0.7248)\tAcc 0.625 (0.710)\n",
      "Epoch: [60][18/18]\tTime 0.078 (0.087)\tData 0.058 (0.066)\tLoss 0.6848 (0.7237)\tAcc 0.875 (0.714)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/12]\tTime 0.229 (0.229)\tData 0.199 (0.199)\tLoss 0.8653 (0.8653)\tAcc 0.688 (0.688)\n",
      "Epoch: [61][2/12]\tTime 0.084 (0.156)\tData 0.058 (0.129)\tLoss 0.4985 (0.6819)\tAcc 0.812 (0.750)\n",
      "Epoch: [61][3/12]\tTime 0.087 (0.133)\tData 0.062 (0.106)\tLoss 0.5245 (0.6294)\tAcc 0.812 (0.771)\n",
      "Epoch: [61][4/12]\tTime 0.083 (0.121)\tData 0.055 (0.093)\tLoss 0.9659 (0.7135)\tAcc 0.625 (0.734)\n",
      "Epoch: [61][5/12]\tTime 0.075 (0.111)\tData 0.051 (0.085)\tLoss 0.6639 (0.7036)\tAcc 0.750 (0.738)\n",
      "Epoch: [61][6/12]\tTime 0.078 (0.106)\tData 0.054 (0.080)\tLoss 0.9648 (0.7471)\tAcc 0.562 (0.708)\n",
      "Epoch: [61][7/12]\tTime 0.079 (0.102)\tData 0.055 (0.076)\tLoss 0.6523 (0.7336)\tAcc 0.750 (0.714)\n",
      "Epoch: [61][8/12]\tTime 0.086 (0.100)\tData 0.061 (0.074)\tLoss 0.5276 (0.7078)\tAcc 0.688 (0.711)\n",
      "Epoch: [61][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.073)\tLoss 0.6843 (0.7052)\tAcc 0.688 (0.708)\n",
      "Epoch: [61][10/12]\tTime 0.086 (0.097)\tData 0.062 (0.072)\tLoss 0.4718 (0.6819)\tAcc 0.875 (0.725)\n",
      "Epoch: [61][11/12]\tTime 0.087 (0.096)\tData 0.062 (0.071)\tLoss 0.3636 (0.6530)\tAcc 0.875 (0.739)\n",
      "Epoch: [61][12/12]\tTime 0.086 (0.095)\tData 0.062 (0.070)\tLoss 0.4268 (0.6352)\tAcc 0.800 (0.743)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/18]\tTime 0.225 (0.225)\tData 0.187 (0.187)\tLoss 0.2573 (0.2573)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/18]\tTime 0.081 (0.153)\tData 0.052 (0.120)\tLoss 0.8155 (0.5364)\tAcc 0.625 (0.781)\n",
      "Epoch: [61][3/18]\tTime 0.071 (0.126)\tData 0.050 (0.096)\tLoss 0.5994 (0.5574)\tAcc 0.875 (0.812)\n",
      "Epoch: [61][4/18]\tTime 0.081 (0.115)\tData 0.059 (0.087)\tLoss 0.5488 (0.5553)\tAcc 0.750 (0.797)\n",
      "Epoch: [61][5/18]\tTime 0.082 (0.108)\tData 0.059 (0.082)\tLoss 0.8052 (0.6052)\tAcc 0.688 (0.775)\n",
      "Epoch: [61][6/18]\tTime 0.080 (0.103)\tData 0.059 (0.078)\tLoss 0.3079 (0.5557)\tAcc 1.000 (0.812)\n",
      "Epoch: [61][7/18]\tTime 0.081 (0.100)\tData 0.059 (0.075)\tLoss 0.7059 (0.5771)\tAcc 0.688 (0.795)\n",
      "Epoch: [61][8/18]\tTime 0.081 (0.098)\tData 0.059 (0.073)\tLoss 0.9491 (0.6236)\tAcc 0.688 (0.781)\n",
      "Epoch: [61][9/18]\tTime 0.073 (0.095)\tData 0.052 (0.071)\tLoss 0.1224 (0.5679)\tAcc 1.000 (0.806)\n",
      "Epoch: [61][10/18]\tTime 0.073 (0.093)\tData 0.054 (0.069)\tLoss 1.1002 (0.6212)\tAcc 0.625 (0.788)\n",
      "Epoch: [61][11/18]\tTime 0.073 (0.091)\tData 0.054 (0.068)\tLoss 1.0370 (0.6590)\tAcc 0.375 (0.750)\n",
      "Epoch: [61][12/18]\tTime 0.074 (0.090)\tData 0.054 (0.067)\tLoss 0.8618 (0.6759)\tAcc 0.812 (0.755)\n",
      "Epoch: [61][13/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 1.1282 (0.7107)\tAcc 0.625 (0.745)\n",
      "Epoch: [61][14/18]\tTime 0.074 (0.087)\tData 0.055 (0.065)\tLoss 0.8539 (0.7209)\tAcc 0.562 (0.732)\n",
      "Epoch: [61][15/18]\tTime 0.074 (0.086)\tData 0.055 (0.064)\tLoss 0.7690 (0.7241)\tAcc 0.750 (0.733)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61][16/18]\tTime 0.075 (0.086)\tData 0.055 (0.064)\tLoss 0.8003 (0.7289)\tAcc 0.625 (0.727)\n",
      "Epoch: [61][17/18]\tTime 0.081 (0.085)\tData 0.061 (0.063)\tLoss 0.6390 (0.7236)\tAcc 0.625 (0.721)\n",
      "Epoch: [61][18/18]\tTime 0.080 (0.085)\tData 0.060 (0.063)\tLoss 0.7018 (0.7230)\tAcc 0.875 (0.725)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/12]\tTime 0.238 (0.238)\tData 0.208 (0.208)\tLoss 0.7745 (0.7745)\tAcc 0.750 (0.750)\n",
      "Epoch: [62][2/12]\tTime 0.078 (0.158)\tData 0.049 (0.129)\tLoss 1.0098 (0.8921)\tAcc 0.625 (0.688)\n",
      "Epoch: [62][3/12]\tTime 0.074 (0.130)\tData 0.050 (0.102)\tLoss 0.6448 (0.8097)\tAcc 0.750 (0.708)\n",
      "Epoch: [62][4/12]\tTime 0.079 (0.117)\tData 0.054 (0.090)\tLoss 0.8518 (0.8202)\tAcc 0.688 (0.703)\n",
      "Epoch: [62][5/12]\tTime 0.077 (0.109)\tData 0.054 (0.083)\tLoss 0.4146 (0.7391)\tAcc 0.875 (0.738)\n",
      "Epoch: [62][6/12]\tTime 0.078 (0.104)\tData 0.054 (0.078)\tLoss 0.4717 (0.6945)\tAcc 0.812 (0.750)\n",
      "Epoch: [62][7/12]\tTime 0.078 (0.100)\tData 0.055 (0.075)\tLoss 0.6740 (0.6916)\tAcc 0.750 (0.750)\n",
      "Epoch: [62][8/12]\tTime 0.078 (0.098)\tData 0.055 (0.072)\tLoss 0.7095 (0.6938)\tAcc 0.688 (0.742)\n",
      "Epoch: [62][9/12]\tTime 0.078 (0.095)\tData 0.055 (0.070)\tLoss 0.6697 (0.6911)\tAcc 0.750 (0.743)\n",
      "Epoch: [62][10/12]\tTime 0.078 (0.094)\tData 0.055 (0.069)\tLoss 0.7834 (0.7004)\tAcc 0.750 (0.744)\n",
      "Epoch: [62][11/12]\tTime 0.080 (0.092)\tData 0.055 (0.068)\tLoss 0.6735 (0.6979)\tAcc 0.688 (0.739)\n",
      "Epoch: [62][12/12]\tTime 0.081 (0.091)\tData 0.055 (0.067)\tLoss 0.8703 (0.7115)\tAcc 0.667 (0.733)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/18]\tTime 0.220 (0.220)\tData 0.195 (0.195)\tLoss 0.2585 (0.2585)\tAcc 1.000 (1.000)\n",
      "Epoch: [62][2/18]\tTime 0.075 (0.147)\tData 0.050 (0.122)\tLoss 0.9323 (0.5954)\tAcc 0.500 (0.750)\n",
      "Epoch: [62][3/18]\tTime 0.070 (0.121)\tData 0.049 (0.098)\tLoss 0.5740 (0.5883)\tAcc 0.812 (0.771)\n",
      "Epoch: [62][4/18]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.5654 (0.5825)\tAcc 0.688 (0.750)\n",
      "Epoch: [62][5/18]\tTime 0.074 (0.102)\tData 0.054 (0.080)\tLoss 0.7791 (0.6219)\tAcc 0.688 (0.738)\n",
      "Epoch: [62][6/18]\tTime 0.074 (0.098)\tData 0.053 (0.076)\tLoss 0.3170 (0.5711)\tAcc 0.938 (0.771)\n",
      "Epoch: [62][7/18]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.6592 (0.5836)\tAcc 0.688 (0.759)\n",
      "Epoch: [62][8/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.8938 (0.6224)\tAcc 0.625 (0.742)\n",
      "Epoch: [62][9/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.1346 (0.5682)\tAcc 1.000 (0.771)\n",
      "Epoch: [62][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.1797 (0.6294)\tAcc 0.562 (0.750)\n",
      "Epoch: [62][11/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 1.1372 (0.6755)\tAcc 0.438 (0.722)\n",
      "Epoch: [62][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8956 (0.6939)\tAcc 0.750 (0.724)\n",
      "Epoch: [62][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.0716 (0.7229)\tAcc 0.562 (0.712)\n",
      "Epoch: [62][14/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.7451 (0.7245)\tAcc 0.562 (0.701)\n",
      "Epoch: [62][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.7549 (0.7265)\tAcc 0.688 (0.700)\n",
      "Epoch: [62][16/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.8094 (0.7317)\tAcc 0.750 (0.703)\n",
      "Epoch: [62][17/18]\tTime 0.074 (0.082)\tData 0.055 (0.062)\tLoss 0.8165 (0.7367)\tAcc 0.625 (0.699)\n",
      "Epoch: [62][18/18]\tTime 0.073 (0.082)\tData 0.054 (0.061)\tLoss 0.4735 (0.7292)\tAcc 1.000 (0.707)\n",
      "train at epoch 63\n",
      "Epoch: [63][1/12]\tTime 0.256 (0.256)\tData 0.227 (0.227)\tLoss 0.5404 (0.5404)\tAcc 0.750 (0.750)\n",
      "Epoch: [63][2/12]\tTime 0.085 (0.171)\tData 0.059 (0.143)\tLoss 0.9392 (0.7398)\tAcc 0.562 (0.656)\n",
      "Epoch: [63][3/12]\tTime 0.086 (0.142)\tData 0.060 (0.116)\tLoss 1.1044 (0.8613)\tAcc 0.500 (0.604)\n",
      "Epoch: [63][4/12]\tTime 0.087 (0.128)\tData 0.062 (0.102)\tLoss 0.8205 (0.8511)\tAcc 0.562 (0.594)\n",
      "Epoch: [63][5/12]\tTime 0.087 (0.120)\tData 0.061 (0.094)\tLoss 0.8330 (0.8475)\tAcc 0.562 (0.588)\n",
      "Epoch: [63][6/12]\tTime 0.078 (0.113)\tData 0.054 (0.087)\tLoss 0.4050 (0.7737)\tAcc 0.938 (0.646)\n",
      "Epoch: [63][7/12]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.7444 (0.7695)\tAcc 0.750 (0.661)\n",
      "Epoch: [63][8/12]\tTime 0.077 (0.104)\tData 0.054 (0.079)\tLoss 0.6536 (0.7551)\tAcc 0.688 (0.664)\n",
      "Epoch: [63][9/12]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.4365 (0.7197)\tAcc 0.750 (0.674)\n",
      "Epoch: [63][10/12]\tTime 0.079 (0.099)\tData 0.055 (0.074)\tLoss 0.5312 (0.7008)\tAcc 0.812 (0.688)\n",
      "Epoch: [63][11/12]\tTime 0.077 (0.097)\tData 0.054 (0.072)\tLoss 0.4679 (0.6796)\tAcc 0.812 (0.699)\n",
      "Epoch: [63][12/12]\tTime 0.078 (0.096)\tData 0.054 (0.071)\tLoss 0.6316 (0.6759)\tAcc 0.733 (0.702)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/18]\tTime 0.227 (0.227)\tData 0.196 (0.196)\tLoss 0.3422 (0.3422)\tAcc 0.875 (0.875)\n",
      "Epoch: [63][2/18]\tTime 0.081 (0.154)\tData 0.052 (0.124)\tLoss 0.8767 (0.6095)\tAcc 0.625 (0.750)\n",
      "Epoch: [63][3/18]\tTime 0.073 (0.127)\tData 0.052 (0.100)\tLoss 0.5571 (0.5920)\tAcc 0.875 (0.792)\n",
      "Epoch: [63][4/18]\tTime 0.080 (0.115)\tData 0.059 (0.089)\tLoss 0.6506 (0.6067)\tAcc 0.688 (0.766)\n",
      "Epoch: [63][5/18]\tTime 0.081 (0.109)\tData 0.059 (0.083)\tLoss 0.7903 (0.6434)\tAcc 0.750 (0.762)\n",
      "Epoch: [63][6/18]\tTime 0.081 (0.104)\tData 0.058 (0.079)\tLoss 0.3258 (0.5905)\tAcc 1.000 (0.802)\n",
      "Epoch: [63][7/18]\tTime 0.081 (0.101)\tData 0.058 (0.076)\tLoss 0.6783 (0.6030)\tAcc 0.625 (0.777)\n",
      "Epoch: [63][8/18]\tTime 0.074 (0.097)\tData 0.053 (0.073)\tLoss 0.8783 (0.6374)\tAcc 0.688 (0.766)\n",
      "Epoch: [63][9/18]\tTime 0.078 (0.095)\tData 0.057 (0.072)\tLoss 0.1273 (0.5807)\tAcc 1.000 (0.792)\n",
      "Epoch: [63][10/18]\tTime 0.077 (0.093)\tData 0.056 (0.070)\tLoss 1.1057 (0.6332)\tAcc 0.562 (0.769)\n",
      "Epoch: [63][11/18]\tTime 0.076 (0.092)\tData 0.056 (0.069)\tLoss 1.1832 (0.6832)\tAcc 0.375 (0.733)\n",
      "Epoch: [63][12/18]\tTime 0.074 (0.090)\tData 0.055 (0.068)\tLoss 0.9033 (0.7016)\tAcc 0.750 (0.734)\n",
      "Epoch: [63][13/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.9507 (0.7207)\tAcc 0.688 (0.731)\n",
      "Epoch: [63][14/18]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 0.6859 (0.7182)\tAcc 0.625 (0.723)\n",
      "Epoch: [63][15/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.8146 (0.7247)\tAcc 0.688 (0.721)\n",
      "Epoch: [63][16/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 0.8525 (0.7327)\tAcc 0.688 (0.719)\n",
      "Epoch: [63][17/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.7821 (0.7356)\tAcc 0.625 (0.713)\n",
      "Epoch: [63][18/18]\tTime 0.076 (0.085)\tData 0.056 (0.063)\tLoss 0.7166 (0.7350)\tAcc 0.625 (0.711)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/12]\tTime 0.254 (0.254)\tData 0.224 (0.224)\tLoss 0.5266 (0.5266)\tAcc 0.875 (0.875)\n",
      "Epoch: [64][2/12]\tTime 0.075 (0.164)\tData 0.049 (0.137)\tLoss 0.5737 (0.5501)\tAcc 0.812 (0.844)\n",
      "Epoch: [64][3/12]\tTime 0.078 (0.136)\tData 0.053 (0.109)\tLoss 0.6362 (0.5788)\tAcc 0.750 (0.812)\n",
      "Epoch: [64][4/12]\tTime 0.080 (0.122)\tData 0.054 (0.095)\tLoss 0.6248 (0.5903)\tAcc 0.688 (0.781)\n",
      "Epoch: [64][5/12]\tTime 0.077 (0.113)\tData 0.053 (0.086)\tLoss 0.8744 (0.6471)\tAcc 0.750 (0.775)\n",
      "Epoch: [64][6/12]\tTime 0.078 (0.107)\tData 0.053 (0.081)\tLoss 0.5544 (0.6317)\tAcc 0.812 (0.781)\n",
      "Epoch: [64][7/12]\tTime 0.078 (0.103)\tData 0.054 (0.077)\tLoss 0.3099 (0.5857)\tAcc 0.938 (0.804)\n",
      "Epoch: [64][8/12]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 0.8547 (0.6193)\tAcc 0.688 (0.789)\n",
      "Epoch: [64][9/12]\tTime 0.078 (0.097)\tData 0.054 (0.072)\tLoss 0.9270 (0.6535)\tAcc 0.688 (0.778)\n",
      "Epoch: [64][10/12]\tTime 0.077 (0.095)\tData 0.054 (0.070)\tLoss 0.7035 (0.6585)\tAcc 0.750 (0.775)\n",
      "Epoch: [64][11/12]\tTime 0.078 (0.094)\tData 0.054 (0.069)\tLoss 0.6599 (0.6586)\tAcc 0.750 (0.773)\n",
      "Epoch: [64][12/12]\tTime 0.078 (0.092)\tData 0.054 (0.067)\tLoss 0.6652 (0.6592)\tAcc 0.733 (0.770)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/18]\tTime 0.221 (0.221)\tData 0.197 (0.197)\tLoss 0.3054 (0.3054)\tAcc 0.875 (0.875)\n",
      "Epoch: [64][2/18]\tTime 0.076 (0.149)\tData 0.051 (0.124)\tLoss 0.9307 (0.6180)\tAcc 0.625 (0.750)\n",
      "Epoch: [64][3/18]\tTime 0.069 (0.122)\tData 0.048 (0.099)\tLoss 0.7462 (0.6608)\tAcc 0.625 (0.708)\n",
      "Epoch: [64][4/18]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.5570 (0.6348)\tAcc 0.750 (0.719)\n",
      "Epoch: [64][5/18]\tTime 0.074 (0.103)\tData 0.053 (0.080)\tLoss 0.8572 (0.6793)\tAcc 0.750 (0.725)\n",
      "Epoch: [64][6/18]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.3522 (0.6248)\tAcc 0.938 (0.760)\n",
      "Epoch: [64][7/18]\tTime 0.074 (0.094)\tData 0.053 (0.073)\tLoss 0.7229 (0.6388)\tAcc 0.625 (0.741)\n",
      "Epoch: [64][8/18]\tTime 0.073 (0.092)\tData 0.053 (0.070)\tLoss 0.8873 (0.6699)\tAcc 0.688 (0.734)\n",
      "Epoch: [64][9/18]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.1229 (0.6091)\tAcc 1.000 (0.764)\n",
      "Epoch: [64][10/18]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.0482 (0.6530)\tAcc 0.625 (0.750)\n",
      "Epoch: [64][11/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 1.1552 (0.6987)\tAcc 0.375 (0.716)\n",
      "Epoch: [64][12/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.9820 (0.7223)\tAcc 0.750 (0.719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [64][13/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 1.1878 (0.7581)\tAcc 0.438 (0.697)\n",
      "Epoch: [64][14/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.8053 (0.7615)\tAcc 0.625 (0.692)\n",
      "Epoch: [64][15/18]\tTime 0.073 (0.083)\tData 0.054 (0.063)\tLoss 0.9438 (0.7736)\tAcc 0.688 (0.692)\n",
      "Epoch: [64][16/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.9280 (0.7833)\tAcc 0.500 (0.680)\n",
      "Epoch: [64][17/18]\tTime 0.074 (0.082)\tData 0.054 (0.062)\tLoss 0.8208 (0.7855)\tAcc 0.500 (0.669)\n",
      "Epoch: [64][18/18]\tTime 0.073 (0.081)\tData 0.054 (0.061)\tLoss 0.6771 (0.7824)\tAcc 0.750 (0.671)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/12]\tTime 0.222 (0.222)\tData 0.187 (0.187)\tLoss 0.5490 (0.5490)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][2/12]\tTime 0.071 (0.146)\tData 0.045 (0.116)\tLoss 0.5000 (0.5245)\tAcc 0.938 (0.906)\n",
      "Epoch: [65][3/12]\tTime 0.077 (0.123)\tData 0.053 (0.095)\tLoss 0.5192 (0.5227)\tAcc 0.750 (0.854)\n",
      "Epoch: [65][4/12]\tTime 0.084 (0.113)\tData 0.057 (0.085)\tLoss 0.4090 (0.4943)\tAcc 0.812 (0.844)\n",
      "Epoch: [65][5/12]\tTime 0.086 (0.108)\tData 0.060 (0.080)\tLoss 1.1191 (0.6193)\tAcc 0.500 (0.775)\n",
      "Epoch: [65][6/12]\tTime 0.085 (0.104)\tData 0.060 (0.077)\tLoss 0.5614 (0.6096)\tAcc 0.750 (0.771)\n",
      "Epoch: [65][7/12]\tTime 0.086 (0.101)\tData 0.062 (0.075)\tLoss 0.7064 (0.6234)\tAcc 0.688 (0.759)\n",
      "Epoch: [65][8/12]\tTime 0.086 (0.100)\tData 0.062 (0.073)\tLoss 0.3574 (0.5902)\tAcc 0.938 (0.781)\n",
      "Epoch: [65][9/12]\tTime 0.086 (0.098)\tData 0.063 (0.072)\tLoss 0.8205 (0.6158)\tAcc 0.688 (0.771)\n",
      "Epoch: [65][10/12]\tTime 0.087 (0.097)\tData 0.062 (0.071)\tLoss 0.7462 (0.6288)\tAcc 0.688 (0.762)\n",
      "Epoch: [65][11/12]\tTime 0.083 (0.096)\tData 0.058 (0.070)\tLoss 0.6599 (0.6316)\tAcc 0.750 (0.761)\n",
      "Epoch: [65][12/12]\tTime 0.086 (0.095)\tData 0.062 (0.069)\tLoss 0.6988 (0.6369)\tAcc 0.733 (0.759)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/18]\tTime 0.215 (0.215)\tData 0.185 (0.185)\tLoss 0.2869 (0.2869)\tAcc 0.938 (0.938)\n",
      "Epoch: [65][2/18]\tTime 0.066 (0.141)\tData 0.045 (0.115)\tLoss 0.8714 (0.5791)\tAcc 0.500 (0.719)\n",
      "Epoch: [65][3/18]\tTime 0.074 (0.118)\tData 0.053 (0.094)\tLoss 0.6353 (0.5978)\tAcc 0.688 (0.708)\n",
      "Epoch: [65][4/18]\tTime 0.078 (0.108)\tData 0.057 (0.085)\tLoss 0.5799 (0.5934)\tAcc 0.750 (0.719)\n",
      "Epoch: [65][5/18]\tTime 0.081 (0.103)\tData 0.059 (0.080)\tLoss 0.7726 (0.6292)\tAcc 0.688 (0.713)\n",
      "Epoch: [65][6/18]\tTime 0.080 (0.099)\tData 0.059 (0.076)\tLoss 0.3179 (0.5773)\tAcc 1.000 (0.760)\n",
      "Epoch: [65][7/18]\tTime 0.081 (0.096)\tData 0.060 (0.074)\tLoss 0.6936 (0.5939)\tAcc 0.812 (0.768)\n",
      "Epoch: [65][8/18]\tTime 0.075 (0.094)\tData 0.054 (0.071)\tLoss 0.9776 (0.6419)\tAcc 0.688 (0.758)\n",
      "Epoch: [65][9/18]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.1148 (0.5833)\tAcc 1.000 (0.785)\n",
      "Epoch: [65][10/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.2240 (0.6474)\tAcc 0.688 (0.775)\n",
      "Epoch: [65][11/18]\tTime 0.075 (0.088)\tData 0.054 (0.067)\tLoss 1.1785 (0.6957)\tAcc 0.375 (0.739)\n",
      "Epoch: [65][12/18]\tTime 0.073 (0.087)\tData 0.053 (0.065)\tLoss 0.8441 (0.7080)\tAcc 0.750 (0.740)\n",
      "Epoch: [65][13/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 1.2101 (0.7467)\tAcc 0.500 (0.721)\n",
      "Epoch: [65][14/18]\tTime 0.075 (0.085)\tData 0.055 (0.064)\tLoss 0.7047 (0.7437)\tAcc 0.688 (0.719)\n",
      "Epoch: [65][15/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.7686 (0.7453)\tAcc 0.750 (0.721)\n",
      "Epoch: [65][16/18]\tTime 0.076 (0.084)\tData 0.057 (0.063)\tLoss 0.7427 (0.7452)\tAcc 0.750 (0.723)\n",
      "Epoch: [65][17/18]\tTime 0.074 (0.083)\tData 0.054 (0.062)\tLoss 0.7616 (0.7461)\tAcc 0.625 (0.717)\n",
      "Epoch: [65][18/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.9611 (0.7523)\tAcc 0.500 (0.711)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/12]\tTime 0.236 (0.236)\tData 0.201 (0.201)\tLoss 0.3934 (0.3934)\tAcc 0.875 (0.875)\n",
      "Epoch: [66][2/12]\tTime 0.079 (0.157)\tData 0.050 (0.125)\tLoss 0.6164 (0.5049)\tAcc 0.750 (0.812)\n",
      "Epoch: [66][3/12]\tTime 0.083 (0.132)\tData 0.057 (0.102)\tLoss 0.7681 (0.5926)\tAcc 0.688 (0.771)\n",
      "Epoch: [66][4/12]\tTime 0.088 (0.121)\tData 0.061 (0.092)\tLoss 1.0398 (0.7044)\tAcc 0.562 (0.719)\n",
      "Epoch: [66][5/12]\tTime 0.081 (0.113)\tData 0.055 (0.085)\tLoss 0.8325 (0.7300)\tAcc 0.625 (0.700)\n",
      "Epoch: [66][6/12]\tTime 0.077 (0.107)\tData 0.053 (0.079)\tLoss 0.6341 (0.7140)\tAcc 0.688 (0.698)\n",
      "Epoch: [66][7/12]\tTime 0.084 (0.104)\tData 0.059 (0.076)\tLoss 0.7799 (0.7234)\tAcc 0.688 (0.696)\n",
      "Epoch: [66][8/12]\tTime 0.084 (0.101)\tData 0.059 (0.074)\tLoss 0.3576 (0.6777)\tAcc 0.938 (0.727)\n",
      "Epoch: [66][9/12]\tTime 0.078 (0.099)\tData 0.054 (0.072)\tLoss 1.0229 (0.7161)\tAcc 0.625 (0.715)\n",
      "Epoch: [66][10/12]\tTime 0.079 (0.097)\tData 0.054 (0.070)\tLoss 0.5357 (0.6980)\tAcc 0.812 (0.725)\n",
      "Epoch: [66][11/12]\tTime 0.080 (0.095)\tData 0.055 (0.069)\tLoss 0.3719 (0.6684)\tAcc 0.938 (0.744)\n",
      "Epoch: [66][12/12]\tTime 0.078 (0.094)\tData 0.053 (0.068)\tLoss 0.5584 (0.6597)\tAcc 0.867 (0.754)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/18]\tTime 0.248 (0.248)\tData 0.202 (0.202)\tLoss 0.3020 (0.3020)\tAcc 0.938 (0.938)\n",
      "Epoch: [66][2/18]\tTime 0.072 (0.160)\tData 0.036 (0.119)\tLoss 0.8225 (0.5623)\tAcc 0.500 (0.719)\n",
      "Epoch: [66][3/18]\tTime 0.068 (0.129)\tData 0.047 (0.095)\tLoss 0.6090 (0.5779)\tAcc 0.750 (0.729)\n",
      "Epoch: [66][4/18]\tTime 0.080 (0.117)\tData 0.059 (0.086)\tLoss 0.6596 (0.5983)\tAcc 0.625 (0.703)\n",
      "Epoch: [66][5/18]\tTime 0.078 (0.109)\tData 0.057 (0.080)\tLoss 0.8320 (0.6450)\tAcc 0.750 (0.713)\n",
      "Epoch: [66][6/18]\tTime 0.082 (0.105)\tData 0.059 (0.077)\tLoss 0.3083 (0.5889)\tAcc 1.000 (0.760)\n",
      "Epoch: [66][7/18]\tTime 0.079 (0.101)\tData 0.058 (0.074)\tLoss 0.6249 (0.5941)\tAcc 0.812 (0.768)\n",
      "Epoch: [66][8/18]\tTime 0.081 (0.099)\tData 0.059 (0.072)\tLoss 0.9632 (0.6402)\tAcc 0.688 (0.758)\n",
      "Epoch: [66][9/18]\tTime 0.080 (0.097)\tData 0.058 (0.071)\tLoss 0.1352 (0.5841)\tAcc 1.000 (0.785)\n",
      "Epoch: [66][10/18]\tTime 0.078 (0.095)\tData 0.057 (0.069)\tLoss 1.1577 (0.6415)\tAcc 0.688 (0.775)\n",
      "Epoch: [66][11/18]\tTime 0.080 (0.093)\tData 0.059 (0.068)\tLoss 1.2302 (0.6950)\tAcc 0.375 (0.739)\n",
      "Epoch: [66][12/18]\tTime 0.080 (0.092)\tData 0.059 (0.068)\tLoss 0.8054 (0.7042)\tAcc 0.750 (0.740)\n",
      "Epoch: [66][13/18]\tTime 0.080 (0.091)\tData 0.059 (0.067)\tLoss 0.9212 (0.7209)\tAcc 0.750 (0.740)\n",
      "Epoch: [66][14/18]\tTime 0.079 (0.091)\tData 0.059 (0.067)\tLoss 0.8301 (0.7287)\tAcc 0.625 (0.732)\n",
      "Epoch: [66][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.066)\tLoss 0.7814 (0.7322)\tAcc 0.688 (0.729)\n",
      "Epoch: [66][16/18]\tTime 0.081 (0.089)\tData 0.060 (0.066)\tLoss 0.7827 (0.7353)\tAcc 0.750 (0.730)\n",
      "Epoch: [66][17/18]\tTime 0.080 (0.089)\tData 0.059 (0.065)\tLoss 0.7955 (0.7389)\tAcc 0.625 (0.724)\n",
      "Epoch: [66][18/18]\tTime 0.079 (0.088)\tData 0.059 (0.065)\tLoss 0.8316 (0.7415)\tAcc 0.750 (0.725)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/12]\tTime 0.244 (0.244)\tData 0.206 (0.206)\tLoss 0.7210 (0.7210)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][2/12]\tTime 0.075 (0.160)\tData 0.049 (0.127)\tLoss 0.5270 (0.6240)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][3/12]\tTime 0.080 (0.133)\tData 0.054 (0.103)\tLoss 0.7157 (0.6546)\tAcc 0.812 (0.771)\n",
      "Epoch: [67][4/12]\tTime 0.077 (0.119)\tData 0.052 (0.090)\tLoss 0.7385 (0.6755)\tAcc 0.812 (0.781)\n",
      "Epoch: [67][5/12]\tTime 0.084 (0.112)\tData 0.059 (0.084)\tLoss 1.1186 (0.7641)\tAcc 0.500 (0.725)\n",
      "Epoch: [67][6/12]\tTime 0.086 (0.108)\tData 0.061 (0.080)\tLoss 0.7183 (0.7565)\tAcc 0.688 (0.719)\n",
      "Epoch: [67][7/12]\tTime 0.086 (0.105)\tData 0.061 (0.078)\tLoss 0.7126 (0.7502)\tAcc 0.688 (0.714)\n",
      "Epoch: [67][8/12]\tTime 0.086 (0.102)\tData 0.062 (0.076)\tLoss 0.9502 (0.7752)\tAcc 0.688 (0.711)\n",
      "Epoch: [67][9/12]\tTime 0.086 (0.101)\tData 0.062 (0.074)\tLoss 0.3815 (0.7315)\tAcc 0.812 (0.722)\n",
      "Epoch: [67][10/12]\tTime 0.087 (0.099)\tData 0.062 (0.073)\tLoss 0.4484 (0.7032)\tAcc 0.812 (0.731)\n",
      "Epoch: [67][11/12]\tTime 0.082 (0.098)\tData 0.059 (0.072)\tLoss 0.6430 (0.6977)\tAcc 0.812 (0.739)\n",
      "Epoch: [67][12/12]\tTime 0.078 (0.096)\tData 0.055 (0.070)\tLoss 0.4664 (0.6795)\tAcc 0.867 (0.749)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/18]\tTime 0.220 (0.220)\tData 0.194 (0.194)\tLoss 0.3583 (0.3583)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/18]\tTime 0.074 (0.147)\tData 0.049 (0.121)\tLoss 0.7874 (0.5729)\tAcc 0.688 (0.812)\n",
      "Epoch: [67][3/18]\tTime 0.070 (0.121)\tData 0.049 (0.097)\tLoss 0.6840 (0.6099)\tAcc 0.688 (0.771)\n",
      "Epoch: [67][4/18]\tTime 0.074 (0.109)\tData 0.053 (0.086)\tLoss 0.5728 (0.6006)\tAcc 0.875 (0.797)\n",
      "Epoch: [67][5/18]\tTime 0.077 (0.103)\tData 0.054 (0.080)\tLoss 0.8810 (0.6567)\tAcc 0.625 (0.762)\n",
      "Epoch: [67][6/18]\tTime 0.075 (0.098)\tData 0.054 (0.075)\tLoss 0.3254 (0.6015)\tAcc 1.000 (0.802)\n",
      "Epoch: [67][7/18]\tTime 0.075 (0.095)\tData 0.054 (0.072)\tLoss 0.7671 (0.6251)\tAcc 0.625 (0.777)\n",
      "Epoch: [67][8/18]\tTime 0.079 (0.093)\tData 0.058 (0.070)\tLoss 0.9342 (0.6638)\tAcc 0.625 (0.758)\n",
      "Epoch: [67][9/18]\tTime 0.081 (0.091)\tData 0.060 (0.069)\tLoss 0.1103 (0.6023)\tAcc 1.000 (0.785)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [67][10/18]\tTime 0.083 (0.091)\tData 0.059 (0.068)\tLoss 1.2928 (0.6713)\tAcc 0.500 (0.756)\n",
      "Epoch: [67][11/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 1.2625 (0.7251)\tAcc 0.375 (0.722)\n",
      "Epoch: [67][12/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.9189 (0.7412)\tAcc 0.812 (0.729)\n",
      "Epoch: [67][13/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.9830 (0.7598)\tAcc 0.750 (0.731)\n",
      "Epoch: [67][14/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7437 (0.7587)\tAcc 0.750 (0.732)\n",
      "Epoch: [67][15/18]\tTime 0.081 (0.087)\tData 0.060 (0.065)\tLoss 0.8689 (0.7660)\tAcc 0.688 (0.729)\n",
      "Epoch: [67][16/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.7552 (0.7653)\tAcc 0.750 (0.730)\n",
      "Epoch: [67][17/18]\tTime 0.080 (0.086)\tData 0.059 (0.065)\tLoss 0.6691 (0.7597)\tAcc 0.688 (0.728)\n",
      "Epoch: [67][18/18]\tTime 0.079 (0.086)\tData 0.059 (0.064)\tLoss 0.7637 (0.7598)\tAcc 0.750 (0.729)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/12]\tTime 0.271 (0.271)\tData 0.243 (0.243)\tLoss 0.5667 (0.5667)\tAcc 0.750 (0.750)\n",
      "Epoch: [68][2/12]\tTime 0.086 (0.179)\tData 0.057 (0.150)\tLoss 0.9762 (0.7715)\tAcc 0.688 (0.719)\n",
      "Epoch: [68][3/12]\tTime 0.093 (0.150)\tData 0.059 (0.119)\tLoss 0.8179 (0.7869)\tAcc 0.750 (0.729)\n",
      "Epoch: [68][4/12]\tTime 0.081 (0.133)\tData 0.053 (0.103)\tLoss 0.8344 (0.7988)\tAcc 0.688 (0.719)\n",
      "Epoch: [68][5/12]\tTime 0.085 (0.123)\tData 0.060 (0.094)\tLoss 0.6066 (0.7604)\tAcc 0.750 (0.725)\n",
      "Epoch: [68][6/12]\tTime 0.085 (0.117)\tData 0.061 (0.089)\tLoss 0.7533 (0.7592)\tAcc 0.625 (0.708)\n",
      "Epoch: [68][7/12]\tTime 0.087 (0.113)\tData 0.062 (0.085)\tLoss 0.7395 (0.7564)\tAcc 0.625 (0.696)\n",
      "Epoch: [68][8/12]\tTime 0.087 (0.110)\tData 0.062 (0.082)\tLoss 0.5487 (0.7304)\tAcc 0.875 (0.719)\n",
      "Epoch: [68][9/12]\tTime 0.086 (0.107)\tData 0.061 (0.080)\tLoss 0.8645 (0.7453)\tAcc 0.625 (0.708)\n",
      "Epoch: [68][10/12]\tTime 0.088 (0.105)\tData 0.062 (0.078)\tLoss 0.5488 (0.7257)\tAcc 0.812 (0.719)\n",
      "Epoch: [68][11/12]\tTime 0.085 (0.103)\tData 0.060 (0.076)\tLoss 0.3570 (0.6921)\tAcc 0.938 (0.739)\n",
      "Epoch: [68][12/12]\tTime 0.086 (0.102)\tData 0.060 (0.075)\tLoss 0.3730 (0.6671)\tAcc 0.933 (0.754)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/18]\tTime 0.243 (0.243)\tData 0.193 (0.193)\tLoss 0.2696 (0.2696)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/18]\tTime 0.070 (0.157)\tData 0.034 (0.113)\tLoss 0.8160 (0.5428)\tAcc 0.625 (0.781)\n",
      "Epoch: [68][3/18]\tTime 0.066 (0.127)\tData 0.045 (0.091)\tLoss 0.6224 (0.5694)\tAcc 0.875 (0.812)\n",
      "Epoch: [68][4/18]\tTime 0.080 (0.115)\tData 0.059 (0.083)\tLoss 0.5915 (0.5749)\tAcc 0.688 (0.781)\n",
      "Epoch: [68][5/18]\tTime 0.080 (0.108)\tData 0.059 (0.078)\tLoss 0.8830 (0.6365)\tAcc 0.750 (0.775)\n",
      "Epoch: [68][6/18]\tTime 0.081 (0.104)\tData 0.059 (0.075)\tLoss 0.3386 (0.5869)\tAcc 1.000 (0.812)\n",
      "Epoch: [68][7/18]\tTime 0.080 (0.100)\tData 0.059 (0.073)\tLoss 0.7457 (0.6096)\tAcc 0.625 (0.786)\n",
      "Epoch: [68][8/18]\tTime 0.081 (0.098)\tData 0.059 (0.071)\tLoss 0.9208 (0.6485)\tAcc 0.688 (0.773)\n",
      "Epoch: [68][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.070)\tLoss 0.1654 (0.5948)\tAcc 1.000 (0.799)\n",
      "Epoch: [68][10/18]\tTime 0.080 (0.094)\tData 0.059 (0.069)\tLoss 1.0911 (0.6444)\tAcc 0.688 (0.788)\n",
      "Epoch: [68][11/18]\tTime 0.080 (0.093)\tData 0.059 (0.068)\tLoss 1.2482 (0.6993)\tAcc 0.375 (0.750)\n",
      "Epoch: [68][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.067)\tLoss 0.8799 (0.7143)\tAcc 0.812 (0.755)\n",
      "Epoch: [68][13/18]\tTime 0.081 (0.091)\tData 0.060 (0.066)\tLoss 1.0958 (0.7437)\tAcc 0.688 (0.750)\n",
      "Epoch: [68][14/18]\tTime 0.081 (0.090)\tData 0.060 (0.066)\tLoss 1.0307 (0.7642)\tAcc 0.500 (0.732)\n",
      "Epoch: [68][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.066)\tLoss 0.7997 (0.7666)\tAcc 0.688 (0.729)\n",
      "Epoch: [68][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.065)\tLoss 0.9210 (0.7762)\tAcc 0.562 (0.719)\n",
      "Epoch: [68][17/18]\tTime 0.081 (0.089)\tData 0.060 (0.065)\tLoss 0.6836 (0.7708)\tAcc 0.625 (0.713)\n",
      "Epoch: [68][18/18]\tTime 0.079 (0.088)\tData 0.059 (0.065)\tLoss 0.6779 (0.7681)\tAcc 0.750 (0.714)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/12]\tTime 0.250 (0.250)\tData 0.216 (0.216)\tLoss 0.8078 (0.8078)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][2/12]\tTime 0.081 (0.165)\tData 0.054 (0.135)\tLoss 0.7101 (0.7589)\tAcc 0.750 (0.719)\n",
      "Epoch: [69][3/12]\tTime 0.084 (0.138)\tData 0.058 (0.110)\tLoss 0.8635 (0.7938)\tAcc 0.562 (0.667)\n",
      "Epoch: [69][4/12]\tTime 0.087 (0.125)\tData 0.061 (0.097)\tLoss 0.6267 (0.7520)\tAcc 0.750 (0.688)\n",
      "Epoch: [69][5/12]\tTime 0.088 (0.118)\tData 0.061 (0.090)\tLoss 0.5388 (0.7094)\tAcc 0.812 (0.713)\n",
      "Epoch: [69][6/12]\tTime 0.083 (0.112)\tData 0.058 (0.085)\tLoss 0.6360 (0.6971)\tAcc 0.812 (0.729)\n",
      "Epoch: [69][7/12]\tTime 0.083 (0.108)\tData 0.059 (0.081)\tLoss 0.5760 (0.6798)\tAcc 0.812 (0.741)\n",
      "Epoch: [69][8/12]\tTime 0.086 (0.105)\tData 0.062 (0.079)\tLoss 0.8265 (0.6982)\tAcc 0.750 (0.742)\n",
      "Epoch: [69][9/12]\tTime 0.086 (0.103)\tData 0.062 (0.077)\tLoss 0.5453 (0.6812)\tAcc 0.750 (0.743)\n",
      "Epoch: [69][10/12]\tTime 0.085 (0.101)\tData 0.060 (0.075)\tLoss 0.7159 (0.6846)\tAcc 0.688 (0.738)\n",
      "Epoch: [69][11/12]\tTime 0.087 (0.100)\tData 0.062 (0.074)\tLoss 0.7650 (0.6919)\tAcc 0.688 (0.733)\n",
      "Epoch: [69][12/12]\tTime 0.087 (0.099)\tData 0.062 (0.073)\tLoss 0.9271 (0.7104)\tAcc 0.667 (0.728)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/18]\tTime 0.217 (0.217)\tData 0.191 (0.191)\tLoss 0.3766 (0.3766)\tAcc 0.938 (0.938)\n",
      "Epoch: [69][2/18]\tTime 0.087 (0.152)\tData 0.055 (0.123)\tLoss 0.8624 (0.6195)\tAcc 0.500 (0.719)\n",
      "Epoch: [69][3/18]\tTime 0.074 (0.126)\tData 0.050 (0.099)\tLoss 0.6140 (0.6177)\tAcc 0.688 (0.708)\n",
      "Epoch: [69][4/18]\tTime 0.080 (0.115)\tData 0.058 (0.089)\tLoss 0.5503 (0.6008)\tAcc 0.750 (0.719)\n",
      "Epoch: [69][5/18]\tTime 0.082 (0.108)\tData 0.059 (0.083)\tLoss 0.8054 (0.6417)\tAcc 0.688 (0.713)\n",
      "Epoch: [69][6/18]\tTime 0.080 (0.103)\tData 0.058 (0.079)\tLoss 0.2976 (0.5844)\tAcc 1.000 (0.760)\n",
      "Epoch: [69][7/18]\tTime 0.081 (0.100)\tData 0.059 (0.076)\tLoss 0.6301 (0.5909)\tAcc 0.750 (0.759)\n",
      "Epoch: [69][8/18]\tTime 0.081 (0.098)\tData 0.059 (0.074)\tLoss 0.9427 (0.6349)\tAcc 0.688 (0.750)\n",
      "Epoch: [69][9/18]\tTime 0.082 (0.096)\tData 0.060 (0.072)\tLoss 0.1024 (0.5757)\tAcc 1.000 (0.778)\n",
      "Epoch: [69][10/18]\tTime 0.080 (0.094)\tData 0.058 (0.071)\tLoss 1.1828 (0.6364)\tAcc 0.625 (0.762)\n",
      "Epoch: [69][11/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 1.2045 (0.6881)\tAcc 0.375 (0.727)\n",
      "Epoch: [69][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.069)\tLoss 0.8530 (0.7018)\tAcc 0.812 (0.734)\n",
      "Epoch: [69][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.9961 (0.7245)\tAcc 0.625 (0.726)\n",
      "Epoch: [69][14/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.7884 (0.7290)\tAcc 0.625 (0.719)\n",
      "Epoch: [69][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.8426 (0.7366)\tAcc 0.688 (0.717)\n",
      "Epoch: [69][16/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.7318 (0.7363)\tAcc 0.688 (0.715)\n",
      "Epoch: [69][17/18]\tTime 0.081 (0.089)\tData 0.061 (0.066)\tLoss 0.8539 (0.7432)\tAcc 0.625 (0.710)\n",
      "Epoch: [69][18/18]\tTime 0.079 (0.088)\tData 0.060 (0.066)\tLoss 0.9477 (0.7491)\tAcc 0.625 (0.707)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/12]\tTime 0.247 (0.247)\tData 0.214 (0.214)\tLoss 0.6743 (0.6743)\tAcc 0.812 (0.812)\n",
      "Epoch: [70][2/12]\tTime 0.087 (0.167)\tData 0.054 (0.134)\tLoss 0.8910 (0.7827)\tAcc 0.688 (0.750)\n",
      "Epoch: [70][3/12]\tTime 0.082 (0.139)\tData 0.052 (0.107)\tLoss 0.7808 (0.7821)\tAcc 0.625 (0.708)\n",
      "Epoch: [70][4/12]\tTime 0.085 (0.125)\tData 0.059 (0.095)\tLoss 0.3800 (0.6815)\tAcc 0.938 (0.766)\n",
      "Epoch: [70][5/12]\tTime 0.087 (0.118)\tData 0.060 (0.088)\tLoss 0.6635 (0.6779)\tAcc 0.750 (0.762)\n",
      "Epoch: [70][6/12]\tTime 0.084 (0.112)\tData 0.059 (0.083)\tLoss 0.4367 (0.6377)\tAcc 0.875 (0.781)\n",
      "Epoch: [70][7/12]\tTime 0.085 (0.108)\tData 0.060 (0.080)\tLoss 0.4804 (0.6152)\tAcc 0.812 (0.786)\n",
      "Epoch: [70][8/12]\tTime 0.088 (0.106)\tData 0.062 (0.078)\tLoss 0.8792 (0.6482)\tAcc 0.750 (0.781)\n",
      "Epoch: [70][9/12]\tTime 0.085 (0.103)\tData 0.061 (0.076)\tLoss 0.7646 (0.6612)\tAcc 0.688 (0.771)\n",
      "Epoch: [70][10/12]\tTime 0.086 (0.102)\tData 0.061 (0.074)\tLoss 0.4219 (0.6372)\tAcc 0.750 (0.769)\n",
      "Epoch: [70][11/12]\tTime 0.086 (0.100)\tData 0.061 (0.073)\tLoss 0.9029 (0.6614)\tAcc 0.562 (0.750)\n",
      "Epoch: [70][12/12]\tTime 0.086 (0.099)\tData 0.060 (0.072)\tLoss 1.4312 (0.7219)\tAcc 0.467 (0.728)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/18]\tTime 0.246 (0.246)\tData 0.208 (0.208)\tLoss 0.2150 (0.2150)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/18]\tTime 0.074 (0.160)\tData 0.049 (0.128)\tLoss 0.7975 (0.5063)\tAcc 0.500 (0.719)\n",
      "Epoch: [70][3/18]\tTime 0.079 (0.133)\tData 0.056 (0.104)\tLoss 0.5986 (0.5371)\tAcc 0.812 (0.750)\n",
      "Epoch: [70][4/18]\tTime 0.081 (0.120)\tData 0.059 (0.093)\tLoss 0.5330 (0.5360)\tAcc 0.812 (0.766)\n",
      "Epoch: [70][5/18]\tTime 0.081 (0.112)\tData 0.058 (0.086)\tLoss 0.7280 (0.5744)\tAcc 0.812 (0.775)\n",
      "Epoch: [70][6/18]\tTime 0.079 (0.107)\tData 0.059 (0.081)\tLoss 0.2677 (0.5233)\tAcc 1.000 (0.812)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [70][7/18]\tTime 0.081 (0.103)\tData 0.060 (0.078)\tLoss 0.6774 (0.5453)\tAcc 0.625 (0.786)\n",
      "Epoch: [70][8/18]\tTime 0.081 (0.100)\tData 0.060 (0.076)\tLoss 0.9702 (0.5984)\tAcc 0.625 (0.766)\n",
      "Epoch: [70][9/18]\tTime 0.081 (0.098)\tData 0.059 (0.074)\tLoss 0.1031 (0.5434)\tAcc 1.000 (0.792)\n",
      "Epoch: [70][10/18]\tTime 0.080 (0.096)\tData 0.058 (0.072)\tLoss 1.3044 (0.6195)\tAcc 0.625 (0.775)\n",
      "Epoch: [70][11/18]\tTime 0.080 (0.095)\tData 0.059 (0.071)\tLoss 1.2166 (0.6738)\tAcc 0.375 (0.739)\n",
      "Epoch: [70][12/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.9956 (0.7006)\tAcc 0.750 (0.740)\n",
      "Epoch: [70][13/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 1.1528 (0.7354)\tAcc 0.562 (0.726)\n",
      "Epoch: [70][14/18]\tTime 0.080 (0.092)\tData 0.060 (0.069)\tLoss 0.8128 (0.7409)\tAcc 0.562 (0.714)\n",
      "Epoch: [70][15/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.7363 (0.7406)\tAcc 0.750 (0.717)\n",
      "Epoch: [70][16/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.7929 (0.7439)\tAcc 0.812 (0.723)\n",
      "Epoch: [70][17/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.8190 (0.7483)\tAcc 0.562 (0.713)\n",
      "Epoch: [70][18/18]\tTime 0.079 (0.089)\tData 0.059 (0.067)\tLoss 0.9527 (0.7541)\tAcc 0.750 (0.714)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/12]\tTime 0.233 (0.233)\tData 0.198 (0.198)\tLoss 0.8044 (0.8044)\tAcc 0.625 (0.625)\n",
      "Epoch: [71][2/12]\tTime 0.081 (0.157)\tData 0.051 (0.125)\tLoss 0.7995 (0.8019)\tAcc 0.688 (0.656)\n",
      "Epoch: [71][3/12]\tTime 0.082 (0.132)\tData 0.057 (0.102)\tLoss 0.5169 (0.7069)\tAcc 0.875 (0.729)\n",
      "Epoch: [71][4/12]\tTime 0.087 (0.121)\tData 0.061 (0.092)\tLoss 0.5823 (0.6758)\tAcc 0.750 (0.734)\n",
      "Epoch: [71][5/12]\tTime 0.083 (0.113)\tData 0.058 (0.085)\tLoss 0.4763 (0.6359)\tAcc 0.812 (0.750)\n",
      "Epoch: [71][6/12]\tTime 0.086 (0.109)\tData 0.061 (0.081)\tLoss 0.7833 (0.6604)\tAcc 0.750 (0.750)\n",
      "Epoch: [71][7/12]\tTime 0.086 (0.105)\tData 0.062 (0.078)\tLoss 0.9068 (0.6956)\tAcc 0.500 (0.714)\n",
      "Epoch: [71][8/12]\tTime 0.085 (0.103)\tData 0.060 (0.076)\tLoss 0.6850 (0.6943)\tAcc 0.812 (0.727)\n",
      "Epoch: [71][9/12]\tTime 0.087 (0.101)\tData 0.062 (0.074)\tLoss 0.4092 (0.6626)\tAcc 0.812 (0.736)\n",
      "Epoch: [71][10/12]\tTime 0.086 (0.100)\tData 0.062 (0.073)\tLoss 0.5078 (0.6471)\tAcc 0.938 (0.756)\n",
      "Epoch: [71][11/12]\tTime 0.087 (0.098)\tData 0.062 (0.072)\tLoss 0.5235 (0.6359)\tAcc 0.875 (0.767)\n",
      "Epoch: [71][12/12]\tTime 0.086 (0.097)\tData 0.062 (0.071)\tLoss 0.9755 (0.6626)\tAcc 0.533 (0.749)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/18]\tTime 0.236 (0.236)\tData 0.204 (0.204)\tLoss 0.2382 (0.2382)\tAcc 1.000 (1.000)\n",
      "Epoch: [71][2/18]\tTime 0.083 (0.159)\tData 0.049 (0.127)\tLoss 0.8648 (0.5515)\tAcc 0.625 (0.812)\n",
      "Epoch: [71][3/18]\tTime 0.068 (0.129)\tData 0.046 (0.100)\tLoss 0.6012 (0.5680)\tAcc 0.812 (0.812)\n",
      "Epoch: [71][4/18]\tTime 0.079 (0.116)\tData 0.058 (0.089)\tLoss 0.5629 (0.5668)\tAcc 0.812 (0.812)\n",
      "Epoch: [71][5/18]\tTime 0.082 (0.110)\tData 0.060 (0.084)\tLoss 0.8398 (0.6214)\tAcc 0.688 (0.788)\n",
      "Epoch: [71][6/18]\tTime 0.079 (0.105)\tData 0.057 (0.079)\tLoss 0.3036 (0.5684)\tAcc 1.000 (0.823)\n",
      "Epoch: [71][7/18]\tTime 0.080 (0.101)\tData 0.059 (0.076)\tLoss 0.5496 (0.5657)\tAcc 0.750 (0.813)\n",
      "Epoch: [71][8/18]\tTime 0.081 (0.099)\tData 0.059 (0.074)\tLoss 1.0139 (0.6217)\tAcc 0.750 (0.805)\n",
      "Epoch: [71][9/18]\tTime 0.079 (0.096)\tData 0.058 (0.072)\tLoss 0.1058 (0.5644)\tAcc 1.000 (0.826)\n",
      "Epoch: [71][10/18]\tTime 0.080 (0.095)\tData 0.059 (0.071)\tLoss 1.2197 (0.6299)\tAcc 0.562 (0.800)\n",
      "Epoch: [71][11/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 1.3517 (0.6956)\tAcc 0.375 (0.761)\n",
      "Epoch: [71][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.069)\tLoss 0.8128 (0.7053)\tAcc 0.812 (0.766)\n",
      "Epoch: [71][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.0537 (0.7321)\tAcc 0.625 (0.755)\n",
      "Epoch: [71][14/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.7617 (0.7342)\tAcc 0.625 (0.746)\n",
      "Epoch: [71][15/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 0.7773 (0.7371)\tAcc 0.750 (0.746)\n",
      "Epoch: [71][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.7774 (0.7396)\tAcc 0.625 (0.738)\n",
      "Epoch: [71][17/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.8302 (0.7450)\tAcc 0.625 (0.732)\n",
      "Epoch: [71][18/18]\tTime 0.078 (0.088)\tData 0.058 (0.066)\tLoss 0.5495 (0.7394)\tAcc 1.000 (0.739)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/12]\tTime 0.247 (0.247)\tData 0.216 (0.216)\tLoss 0.5386 (0.5386)\tAcc 0.812 (0.812)\n",
      "Epoch: [72][2/12]\tTime 0.096 (0.171)\tData 0.056 (0.136)\tLoss 0.9255 (0.7321)\tAcc 0.562 (0.688)\n",
      "Epoch: [72][3/12]\tTime 0.077 (0.140)\tData 0.050 (0.108)\tLoss 0.5951 (0.6864)\tAcc 0.812 (0.729)\n",
      "Epoch: [72][4/12]\tTime 0.087 (0.127)\tData 0.060 (0.096)\tLoss 0.8294 (0.7221)\tAcc 0.688 (0.719)\n",
      "Epoch: [72][5/12]\tTime 0.084 (0.118)\tData 0.058 (0.088)\tLoss 0.4155 (0.6608)\tAcc 0.875 (0.750)\n",
      "Epoch: [72][6/12]\tTime 0.084 (0.113)\tData 0.059 (0.083)\tLoss 0.9794 (0.7139)\tAcc 0.500 (0.708)\n",
      "Epoch: [72][7/12]\tTime 0.086 (0.109)\tData 0.062 (0.080)\tLoss 0.5107 (0.6849)\tAcc 0.875 (0.732)\n",
      "Epoch: [72][8/12]\tTime 0.087 (0.106)\tData 0.062 (0.078)\tLoss 0.6624 (0.6821)\tAcc 0.688 (0.727)\n",
      "Epoch: [72][9/12]\tTime 0.086 (0.104)\tData 0.061 (0.076)\tLoss 0.4221 (0.6532)\tAcc 0.812 (0.736)\n",
      "Epoch: [72][10/12]\tTime 0.085 (0.102)\tData 0.060 (0.074)\tLoss 0.7539 (0.6633)\tAcc 0.625 (0.725)\n",
      "Epoch: [72][11/12]\tTime 0.086 (0.101)\tData 0.062 (0.073)\tLoss 0.6437 (0.6615)\tAcc 0.812 (0.733)\n",
      "Epoch: [72][12/12]\tTime 0.087 (0.099)\tData 0.062 (0.072)\tLoss 0.8343 (0.6751)\tAcc 0.667 (0.728)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/18]\tTime 0.235 (0.235)\tData 0.194 (0.194)\tLoss 0.3242 (0.3242)\tAcc 0.875 (0.875)\n",
      "Epoch: [72][2/18]\tTime 0.076 (0.156)\tData 0.040 (0.117)\tLoss 0.9031 (0.6136)\tAcc 0.625 (0.750)\n",
      "Epoch: [72][3/18]\tTime 0.066 (0.126)\tData 0.045 (0.093)\tLoss 0.5802 (0.6025)\tAcc 0.750 (0.750)\n",
      "Epoch: [72][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.084)\tLoss 0.5516 (0.5897)\tAcc 0.750 (0.750)\n",
      "Epoch: [72][5/18]\tTime 0.081 (0.108)\tData 0.060 (0.079)\tLoss 0.8041 (0.6326)\tAcc 0.750 (0.750)\n",
      "Epoch: [72][6/18]\tTime 0.080 (0.103)\tData 0.059 (0.076)\tLoss 0.2259 (0.5648)\tAcc 1.000 (0.792)\n",
      "Epoch: [72][7/18]\tTime 0.080 (0.100)\tData 0.059 (0.074)\tLoss 0.5542 (0.5633)\tAcc 0.812 (0.795)\n",
      "Epoch: [72][8/18]\tTime 0.081 (0.097)\tData 0.060 (0.072)\tLoss 0.8797 (0.6028)\tAcc 0.625 (0.773)\n",
      "Epoch: [72][9/18]\tTime 0.082 (0.096)\tData 0.060 (0.071)\tLoss 0.1136 (0.5485)\tAcc 1.000 (0.799)\n",
      "Epoch: [72][10/18]\tTime 0.080 (0.094)\tData 0.059 (0.069)\tLoss 0.9647 (0.5901)\tAcc 0.625 (0.781)\n",
      "Epoch: [72][11/18]\tTime 0.080 (0.093)\tData 0.060 (0.069)\tLoss 1.1711 (0.6429)\tAcc 0.375 (0.744)\n",
      "Epoch: [72][12/18]\tTime 0.081 (0.092)\tData 0.060 (0.068)\tLoss 0.8928 (0.6638)\tAcc 0.750 (0.745)\n",
      "Epoch: [72][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.067)\tLoss 1.0602 (0.6943)\tAcc 0.625 (0.736)\n",
      "Epoch: [72][14/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 0.7305 (0.6968)\tAcc 0.625 (0.728)\n",
      "Epoch: [72][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.066)\tLoss 0.8980 (0.7102)\tAcc 0.625 (0.721)\n",
      "Epoch: [72][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.7321 (0.7116)\tAcc 0.750 (0.723)\n",
      "Epoch: [72][17/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7858 (0.7160)\tAcc 0.625 (0.717)\n",
      "Epoch: [72][18/18]\tTime 0.081 (0.088)\tData 0.060 (0.065)\tLoss 0.8180 (0.7189)\tAcc 0.750 (0.718)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/12]\tTime 0.244 (0.244)\tData 0.213 (0.213)\tLoss 0.4214 (0.4214)\tAcc 0.812 (0.812)\n",
      "Epoch: [73][2/12]\tTime 0.086 (0.165)\tData 0.057 (0.135)\tLoss 0.7659 (0.5937)\tAcc 0.812 (0.812)\n",
      "Epoch: [73][3/12]\tTime 0.084 (0.138)\tData 0.058 (0.109)\tLoss 0.4074 (0.5316)\tAcc 0.875 (0.833)\n",
      "Epoch: [73][4/12]\tTime 0.087 (0.125)\tData 0.061 (0.097)\tLoss 0.4389 (0.5084)\tAcc 0.875 (0.844)\n",
      "Epoch: [73][5/12]\tTime 0.085 (0.117)\tData 0.060 (0.090)\tLoss 0.7277 (0.5523)\tAcc 0.750 (0.825)\n",
      "Epoch: [73][6/12]\tTime 0.086 (0.112)\tData 0.062 (0.085)\tLoss 0.6785 (0.5733)\tAcc 0.625 (0.792)\n",
      "Epoch: [73][7/12]\tTime 0.086 (0.108)\tData 0.061 (0.082)\tLoss 0.8634 (0.6147)\tAcc 0.688 (0.777)\n",
      "Epoch: [73][8/12]\tTime 0.086 (0.106)\tData 0.061 (0.079)\tLoss 0.7557 (0.6324)\tAcc 0.750 (0.773)\n",
      "Epoch: [73][9/12]\tTime 0.085 (0.103)\tData 0.061 (0.077)\tLoss 0.7391 (0.6442)\tAcc 0.688 (0.764)\n",
      "Epoch: [73][10/12]\tTime 0.084 (0.101)\tData 0.059 (0.075)\tLoss 0.8855 (0.6683)\tAcc 0.688 (0.756)\n",
      "Epoch: [73][11/12]\tTime 0.086 (0.100)\tData 0.061 (0.074)\tLoss 0.4767 (0.6509)\tAcc 0.875 (0.767)\n",
      "Epoch: [73][12/12]\tTime 0.086 (0.099)\tData 0.061 (0.073)\tLoss 0.9209 (0.6721)\tAcc 0.600 (0.754)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/18]\tTime 0.228 (0.228)\tData 0.199 (0.199)\tLoss 0.3092 (0.3092)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/18]\tTime 0.079 (0.154)\tData 0.051 (0.125)\tLoss 0.8865 (0.5979)\tAcc 0.625 (0.781)\n",
      "Epoch: [73][3/18]\tTime 0.073 (0.127)\tData 0.052 (0.100)\tLoss 0.6118 (0.6025)\tAcc 0.750 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [73][4/18]\tTime 0.081 (0.115)\tData 0.060 (0.090)\tLoss 0.5590 (0.5916)\tAcc 0.750 (0.766)\n",
      "Epoch: [73][5/18]\tTime 0.081 (0.109)\tData 0.059 (0.084)\tLoss 0.7776 (0.6288)\tAcc 0.625 (0.738)\n",
      "Epoch: [73][6/18]\tTime 0.079 (0.104)\tData 0.058 (0.080)\tLoss 0.2785 (0.5704)\tAcc 0.938 (0.771)\n",
      "Epoch: [73][7/18]\tTime 0.080 (0.100)\tData 0.059 (0.077)\tLoss 0.6591 (0.5831)\tAcc 0.875 (0.786)\n",
      "Epoch: [73][8/18]\tTime 0.080 (0.098)\tData 0.059 (0.074)\tLoss 0.9126 (0.6243)\tAcc 0.750 (0.781)\n",
      "Epoch: [73][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.073)\tLoss 0.1565 (0.5723)\tAcc 1.000 (0.806)\n",
      "Epoch: [73][10/18]\tTime 0.086 (0.095)\tData 0.059 (0.071)\tLoss 1.0753 (0.6226)\tAcc 0.625 (0.788)\n",
      "Epoch: [73][11/18]\tTime 0.078 (0.093)\tData 0.057 (0.070)\tLoss 1.2409 (0.6788)\tAcc 0.375 (0.750)\n",
      "Epoch: [73][12/18]\tTime 0.081 (0.092)\tData 0.060 (0.069)\tLoss 0.8812 (0.6957)\tAcc 0.750 (0.750)\n",
      "Epoch: [73][13/18]\tTime 0.081 (0.091)\tData 0.060 (0.069)\tLoss 0.9592 (0.7159)\tAcc 0.750 (0.750)\n",
      "Epoch: [73][14/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.9244 (0.7308)\tAcc 0.562 (0.737)\n",
      "Epoch: [73][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.8362 (0.7379)\tAcc 0.688 (0.733)\n",
      "Epoch: [73][16/18]\tTime 0.080 (0.089)\tData 0.059 (0.067)\tLoss 0.9416 (0.7506)\tAcc 0.625 (0.727)\n",
      "Epoch: [73][17/18]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 0.6736 (0.7461)\tAcc 0.625 (0.721)\n",
      "Epoch: [73][18/18]\tTime 0.075 (0.088)\tData 0.056 (0.066)\tLoss 0.5255 (0.7398)\tAcc 1.000 (0.729)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/12]\tTime 0.230 (0.230)\tData 0.197 (0.197)\tLoss 0.3479 (0.3479)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/12]\tTime 0.073 (0.151)\tData 0.046 (0.121)\tLoss 0.5573 (0.4526)\tAcc 0.812 (0.875)\n",
      "Epoch: [74][3/12]\tTime 0.082 (0.128)\tData 0.056 (0.100)\tLoss 0.8861 (0.5971)\tAcc 0.750 (0.833)\n",
      "Epoch: [74][4/12]\tTime 0.083 (0.117)\tData 0.055 (0.088)\tLoss 0.5355 (0.5817)\tAcc 0.812 (0.828)\n",
      "Epoch: [74][5/12]\tTime 0.078 (0.109)\tData 0.051 (0.081)\tLoss 0.7620 (0.6178)\tAcc 0.750 (0.812)\n",
      "Epoch: [74][6/12]\tTime 0.081 (0.104)\tData 0.056 (0.077)\tLoss 0.6852 (0.6290)\tAcc 0.688 (0.792)\n",
      "Epoch: [74][7/12]\tTime 0.087 (0.102)\tData 0.061 (0.075)\tLoss 0.6211 (0.6279)\tAcc 0.750 (0.786)\n",
      "Epoch: [74][8/12]\tTime 0.086 (0.100)\tData 0.061 (0.073)\tLoss 0.7036 (0.6374)\tAcc 0.688 (0.773)\n",
      "Epoch: [74][9/12]\tTime 0.086 (0.098)\tData 0.061 (0.072)\tLoss 0.6711 (0.6411)\tAcc 0.625 (0.757)\n",
      "Epoch: [74][10/12]\tTime 0.087 (0.097)\tData 0.062 (0.071)\tLoss 0.7762 (0.6546)\tAcc 0.688 (0.750)\n",
      "Epoch: [74][11/12]\tTime 0.086 (0.096)\tData 0.062 (0.070)\tLoss 0.4970 (0.6403)\tAcc 0.688 (0.744)\n",
      "Epoch: [74][12/12]\tTime 0.088 (0.096)\tData 0.062 (0.069)\tLoss 0.6055 (0.6376)\tAcc 0.800 (0.749)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/18]\tTime 0.234 (0.234)\tData 0.190 (0.190)\tLoss 0.2870 (0.2870)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/18]\tTime 0.072 (0.153)\tData 0.036 (0.113)\tLoss 0.8861 (0.5866)\tAcc 0.688 (0.812)\n",
      "Epoch: [74][3/18]\tTime 0.068 (0.125)\tData 0.047 (0.091)\tLoss 0.5878 (0.5870)\tAcc 0.812 (0.812)\n",
      "Epoch: [74][4/18]\tTime 0.073 (0.112)\tData 0.053 (0.081)\tLoss 0.5732 (0.5836)\tAcc 0.750 (0.797)\n",
      "Epoch: [74][5/18]\tTime 0.077 (0.105)\tData 0.057 (0.077)\tLoss 0.7050 (0.6078)\tAcc 0.875 (0.812)\n",
      "Epoch: [74][6/18]\tTime 0.077 (0.100)\tData 0.056 (0.073)\tLoss 0.2728 (0.5520)\tAcc 1.000 (0.844)\n",
      "Epoch: [74][7/18]\tTime 0.078 (0.097)\tData 0.057 (0.071)\tLoss 0.6382 (0.5643)\tAcc 0.688 (0.821)\n",
      "Epoch: [74][8/18]\tTime 0.080 (0.095)\tData 0.058 (0.069)\tLoss 0.8500 (0.6000)\tAcc 0.750 (0.812)\n",
      "Epoch: [74][9/18]\tTime 0.075 (0.093)\tData 0.054 (0.068)\tLoss 0.1276 (0.5475)\tAcc 1.000 (0.833)\n",
      "Epoch: [74][10/18]\tTime 0.076 (0.091)\tData 0.055 (0.066)\tLoss 1.1628 (0.6091)\tAcc 0.625 (0.812)\n",
      "Epoch: [74][11/18]\tTime 0.079 (0.090)\tData 0.059 (0.066)\tLoss 1.2158 (0.6642)\tAcc 0.375 (0.773)\n",
      "Epoch: [74][12/18]\tTime 0.074 (0.089)\tData 0.054 (0.065)\tLoss 1.0247 (0.6942)\tAcc 0.625 (0.760)\n",
      "Epoch: [74][13/18]\tTime 0.077 (0.088)\tData 0.057 (0.064)\tLoss 1.2066 (0.7337)\tAcc 0.500 (0.740)\n",
      "Epoch: [74][14/18]\tTime 0.075 (0.087)\tData 0.055 (0.063)\tLoss 0.7243 (0.7330)\tAcc 0.750 (0.741)\n",
      "Epoch: [74][15/18]\tTime 0.073 (0.086)\tData 0.054 (0.063)\tLoss 0.7442 (0.7337)\tAcc 0.625 (0.733)\n",
      "Epoch: [74][16/18]\tTime 0.076 (0.085)\tData 0.057 (0.062)\tLoss 0.8772 (0.7427)\tAcc 0.625 (0.727)\n",
      "Epoch: [74][17/18]\tTime 0.075 (0.085)\tData 0.055 (0.062)\tLoss 0.8604 (0.7496)\tAcc 0.625 (0.721)\n",
      "Epoch: [74][18/18]\tTime 0.077 (0.084)\tData 0.058 (0.062)\tLoss 0.6112 (0.7457)\tAcc 0.750 (0.721)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/12]\tTime 0.232 (0.232)\tData 0.200 (0.200)\tLoss 1.1123 (1.1123)\tAcc 0.500 (0.500)\n",
      "Epoch: [75][2/12]\tTime 0.082 (0.157)\tData 0.052 (0.126)\tLoss 0.5363 (0.8243)\tAcc 0.812 (0.656)\n",
      "Epoch: [75][3/12]\tTime 0.075 (0.130)\tData 0.050 (0.100)\tLoss 0.4769 (0.7085)\tAcc 0.875 (0.729)\n",
      "Epoch: [75][4/12]\tTime 0.079 (0.117)\tData 0.054 (0.089)\tLoss 0.6225 (0.6870)\tAcc 0.688 (0.719)\n",
      "Epoch: [75][5/12]\tTime 0.084 (0.110)\tData 0.059 (0.083)\tLoss 0.4851 (0.6466)\tAcc 0.750 (0.725)\n",
      "Epoch: [75][6/12]\tTime 0.077 (0.105)\tData 0.053 (0.078)\tLoss 0.5151 (0.6247)\tAcc 0.812 (0.740)\n",
      "Epoch: [75][7/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 1.0445 (0.6847)\tAcc 0.438 (0.696)\n",
      "Epoch: [75][8/12]\tTime 0.081 (0.099)\tData 0.058 (0.072)\tLoss 0.4232 (0.6520)\tAcc 0.875 (0.719)\n",
      "Epoch: [75][9/12]\tTime 0.085 (0.097)\tData 0.059 (0.071)\tLoss 0.6200 (0.6484)\tAcc 0.750 (0.722)\n",
      "Epoch: [75][10/12]\tTime 0.086 (0.096)\tData 0.061 (0.070)\tLoss 0.6548 (0.6491)\tAcc 0.688 (0.719)\n",
      "Epoch: [75][11/12]\tTime 0.087 (0.095)\tData 0.062 (0.069)\tLoss 0.3076 (0.6180)\tAcc 0.938 (0.739)\n",
      "Epoch: [75][12/12]\tTime 0.087 (0.094)\tData 0.063 (0.069)\tLoss 0.5568 (0.6132)\tAcc 0.800 (0.743)\n",
      "validation at epoch 75\n",
      "Epoch: [75][1/18]\tTime 0.233 (0.233)\tData 0.207 (0.207)\tLoss 0.2573 (0.2573)\tAcc 0.938 (0.938)\n",
      "Epoch: [75][2/18]\tTime 0.085 (0.159)\tData 0.054 (0.131)\tLoss 0.8783 (0.5678)\tAcc 0.625 (0.781)\n",
      "Epoch: [75][3/18]\tTime 0.070 (0.130)\tData 0.049 (0.104)\tLoss 0.6120 (0.5825)\tAcc 0.688 (0.750)\n",
      "Epoch: [75][4/18]\tTime 0.078 (0.117)\tData 0.057 (0.092)\tLoss 0.4962 (0.5609)\tAcc 0.875 (0.781)\n",
      "Epoch: [75][5/18]\tTime 0.080 (0.109)\tData 0.059 (0.085)\tLoss 0.7512 (0.5990)\tAcc 0.812 (0.788)\n",
      "Epoch: [75][6/18]\tTime 0.079 (0.104)\tData 0.058 (0.081)\tLoss 0.2610 (0.5427)\tAcc 1.000 (0.823)\n",
      "Epoch: [75][7/18]\tTime 0.080 (0.101)\tData 0.059 (0.078)\tLoss 0.6318 (0.5554)\tAcc 0.875 (0.830)\n",
      "Epoch: [75][8/18]\tTime 0.082 (0.098)\tData 0.060 (0.075)\tLoss 0.9187 (0.6008)\tAcc 0.625 (0.805)\n",
      "Epoch: [75][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.074)\tLoss 0.1256 (0.5480)\tAcc 1.000 (0.826)\n",
      "Epoch: [75][10/18]\tTime 0.080 (0.095)\tData 0.059 (0.072)\tLoss 1.3352 (0.6267)\tAcc 0.562 (0.800)\n",
      "Epoch: [75][11/18]\tTime 0.080 (0.093)\tData 0.060 (0.071)\tLoss 1.2543 (0.6838)\tAcc 0.375 (0.761)\n",
      "Epoch: [75][12/18]\tTime 0.081 (0.092)\tData 0.060 (0.070)\tLoss 0.8856 (0.7006)\tAcc 0.750 (0.760)\n",
      "Epoch: [75][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 1.0786 (0.7297)\tAcc 0.625 (0.750)\n",
      "Epoch: [75][14/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.7557 (0.7315)\tAcc 0.625 (0.741)\n",
      "Epoch: [75][15/18]\tTime 0.081 (0.090)\tData 0.061 (0.068)\tLoss 0.8478 (0.7393)\tAcc 0.625 (0.733)\n",
      "Epoch: [75][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.7538 (0.7402)\tAcc 0.688 (0.730)\n",
      "Epoch: [75][17/18]\tTime 0.077 (0.089)\tData 0.057 (0.067)\tLoss 0.8405 (0.7461)\tAcc 0.625 (0.724)\n",
      "Epoch: [75][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.6629 (0.7437)\tAcc 0.875 (0.729)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/12]\tTime 0.252 (0.252)\tData 0.222 (0.222)\tLoss 1.0240 (1.0240)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][2/12]\tTime 0.090 (0.171)\tData 0.058 (0.140)\tLoss 0.3261 (0.6750)\tAcc 0.938 (0.812)\n",
      "Epoch: [76][3/12]\tTime 0.083 (0.142)\tData 0.053 (0.111)\tLoss 0.4788 (0.6096)\tAcc 0.750 (0.792)\n",
      "Epoch: [76][4/12]\tTime 0.086 (0.128)\tData 0.059 (0.098)\tLoss 0.3256 (0.5386)\tAcc 0.938 (0.828)\n",
      "Epoch: [76][5/12]\tTime 0.087 (0.119)\tData 0.061 (0.091)\tLoss 0.7539 (0.5817)\tAcc 0.625 (0.788)\n",
      "Epoch: [76][6/12]\tTime 0.086 (0.114)\tData 0.061 (0.086)\tLoss 0.6040 (0.5854)\tAcc 0.750 (0.781)\n",
      "Epoch: [76][7/12]\tTime 0.086 (0.110)\tData 0.061 (0.082)\tLoss 0.4077 (0.5600)\tAcc 0.812 (0.786)\n",
      "Epoch: [76][8/12]\tTime 0.087 (0.107)\tData 0.062 (0.080)\tLoss 0.5089 (0.5536)\tAcc 0.750 (0.781)\n",
      "Epoch: [76][9/12]\tTime 0.087 (0.105)\tData 0.062 (0.078)\tLoss 0.5919 (0.5579)\tAcc 0.812 (0.785)\n",
      "Epoch: [76][10/12]\tTime 0.086 (0.103)\tData 0.061 (0.076)\tLoss 0.6543 (0.5675)\tAcc 0.750 (0.781)\n",
      "Epoch: [76][11/12]\tTime 0.087 (0.101)\tData 0.061 (0.075)\tLoss 0.6035 (0.5708)\tAcc 0.750 (0.778)\n",
      "Epoch: [76][12/12]\tTime 0.087 (0.100)\tData 0.062 (0.074)\tLoss 1.0014 (0.6046)\tAcc 0.600 (0.764)\n",
      "validation at epoch 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][1/18]\tTime 0.232 (0.232)\tData 0.207 (0.207)\tLoss 0.3241 (0.3241)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/18]\tTime 0.084 (0.158)\tData 0.056 (0.131)\tLoss 0.8815 (0.6028)\tAcc 0.500 (0.719)\n",
      "Epoch: [76][3/18]\tTime 0.076 (0.131)\tData 0.055 (0.106)\tLoss 0.5903 (0.5986)\tAcc 0.812 (0.750)\n",
      "Epoch: [76][4/18]\tTime 0.081 (0.118)\tData 0.060 (0.094)\tLoss 0.5957 (0.5979)\tAcc 0.750 (0.750)\n",
      "Epoch: [76][5/18]\tTime 0.081 (0.111)\tData 0.060 (0.087)\tLoss 0.8035 (0.6390)\tAcc 0.688 (0.738)\n",
      "Epoch: [76][6/18]\tTime 0.081 (0.106)\tData 0.059 (0.083)\tLoss 0.2463 (0.5736)\tAcc 1.000 (0.781)\n",
      "Epoch: [76][7/18]\tTime 0.081 (0.102)\tData 0.059 (0.079)\tLoss 0.6586 (0.5857)\tAcc 0.812 (0.786)\n",
      "Epoch: [76][8/18]\tTime 0.082 (0.100)\tData 0.059 (0.077)\tLoss 0.8617 (0.6202)\tAcc 0.688 (0.773)\n",
      "Epoch: [76][9/18]\tTime 0.079 (0.098)\tData 0.058 (0.075)\tLoss 0.1073 (0.5632)\tAcc 1.000 (0.799)\n",
      "Epoch: [76][10/18]\tTime 0.078 (0.096)\tData 0.057 (0.073)\tLoss 1.1127 (0.6182)\tAcc 0.688 (0.788)\n",
      "Epoch: [76][11/18]\tTime 0.079 (0.094)\tData 0.058 (0.072)\tLoss 1.2466 (0.6753)\tAcc 0.375 (0.750)\n",
      "Epoch: [76][12/18]\tTime 0.081 (0.093)\tData 0.060 (0.071)\tLoss 0.7787 (0.6839)\tAcc 0.812 (0.755)\n",
      "Epoch: [76][13/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.9706 (0.7060)\tAcc 0.625 (0.745)\n",
      "Epoch: [76][14/18]\tTime 0.077 (0.091)\tData 0.056 (0.069)\tLoss 0.9149 (0.7209)\tAcc 0.625 (0.737)\n",
      "Epoch: [76][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.7913 (0.7256)\tAcc 0.750 (0.738)\n",
      "Epoch: [76][16/18]\tTime 0.081 (0.090)\tData 0.060 (0.068)\tLoss 0.6917 (0.7235)\tAcc 0.750 (0.738)\n",
      "Epoch: [76][17/18]\tTime 0.080 (0.089)\tData 0.059 (0.067)\tLoss 0.7297 (0.7238)\tAcc 0.625 (0.732)\n",
      "Epoch: [76][18/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.5490 (0.7188)\tAcc 1.000 (0.739)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/12]\tTime 0.238 (0.238)\tData 0.205 (0.205)\tLoss 0.4024 (0.4024)\tAcc 0.875 (0.875)\n",
      "Epoch: [77][2/12]\tTime 0.077 (0.158)\tData 0.047 (0.126)\tLoss 0.3294 (0.3659)\tAcc 0.938 (0.906)\n",
      "Epoch: [77][3/12]\tTime 0.076 (0.131)\tData 0.051 (0.101)\tLoss 0.8231 (0.5183)\tAcc 0.750 (0.854)\n",
      "Epoch: [77][4/12]\tTime 0.085 (0.119)\tData 0.060 (0.091)\tLoss 0.8231 (0.5945)\tAcc 0.688 (0.812)\n",
      "Epoch: [77][5/12]\tTime 0.088 (0.113)\tData 0.062 (0.085)\tLoss 0.3751 (0.5506)\tAcc 0.938 (0.838)\n",
      "Epoch: [77][6/12]\tTime 0.084 (0.108)\tData 0.060 (0.081)\tLoss 0.8328 (0.5976)\tAcc 0.562 (0.792)\n",
      "Epoch: [77][7/12]\tTime 0.086 (0.105)\tData 0.062 (0.078)\tLoss 0.4615 (0.5782)\tAcc 0.875 (0.804)\n",
      "Epoch: [77][8/12]\tTime 0.082 (0.102)\tData 0.058 (0.076)\tLoss 0.6121 (0.5824)\tAcc 0.750 (0.797)\n",
      "Epoch: [77][9/12]\tTime 0.079 (0.100)\tData 0.056 (0.073)\tLoss 0.7815 (0.6046)\tAcc 0.688 (0.785)\n",
      "Epoch: [77][10/12]\tTime 0.078 (0.097)\tData 0.055 (0.072)\tLoss 0.5394 (0.5980)\tAcc 0.688 (0.775)\n",
      "Epoch: [77][11/12]\tTime 0.082 (0.096)\tData 0.058 (0.070)\tLoss 1.1344 (0.6468)\tAcc 0.500 (0.750)\n",
      "Epoch: [77][12/12]\tTime 0.078 (0.095)\tData 0.055 (0.069)\tLoss 0.7057 (0.6514)\tAcc 0.667 (0.743)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/18]\tTime 0.239 (0.239)\tData 0.207 (0.207)\tLoss 0.2031 (0.2031)\tAcc 1.000 (1.000)\n",
      "Epoch: [77][2/18]\tTime 0.076 (0.157)\tData 0.049 (0.128)\tLoss 0.9404 (0.5718)\tAcc 0.562 (0.781)\n",
      "Epoch: [77][3/18]\tTime 0.075 (0.130)\tData 0.054 (0.103)\tLoss 0.5862 (0.5766)\tAcc 0.750 (0.771)\n",
      "Epoch: [77][4/18]\tTime 0.079 (0.117)\tData 0.059 (0.092)\tLoss 0.5807 (0.5776)\tAcc 0.750 (0.766)\n",
      "Epoch: [77][5/18]\tTime 0.076 (0.109)\tData 0.056 (0.085)\tLoss 0.7779 (0.6177)\tAcc 0.750 (0.762)\n",
      "Epoch: [77][6/18]\tTime 0.075 (0.103)\tData 0.055 (0.080)\tLoss 0.2198 (0.5513)\tAcc 1.000 (0.802)\n",
      "Epoch: [77][7/18]\tTime 0.074 (0.099)\tData 0.054 (0.076)\tLoss 0.6868 (0.5707)\tAcc 0.688 (0.786)\n",
      "Epoch: [77][8/18]\tTime 0.080 (0.097)\tData 0.059 (0.074)\tLoss 0.9816 (0.6221)\tAcc 0.500 (0.750)\n",
      "Epoch: [77][9/18]\tTime 0.081 (0.095)\tData 0.060 (0.073)\tLoss 0.0917 (0.5631)\tAcc 1.000 (0.778)\n",
      "Epoch: [77][10/18]\tTime 0.081 (0.094)\tData 0.060 (0.071)\tLoss 0.9893 (0.6058)\tAcc 0.812 (0.781)\n",
      "Epoch: [77][11/18]\tTime 0.085 (0.093)\tData 0.060 (0.070)\tLoss 1.3823 (0.6763)\tAcc 0.375 (0.744)\n",
      "Epoch: [77][12/18]\tTime 0.076 (0.091)\tData 0.056 (0.069)\tLoss 1.0293 (0.7058)\tAcc 0.750 (0.745)\n",
      "Epoch: [77][13/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 1.0406 (0.7315)\tAcc 0.562 (0.731)\n",
      "Epoch: [77][14/18]\tTime 0.076 (0.089)\tData 0.056 (0.067)\tLoss 0.8463 (0.7397)\tAcc 0.562 (0.719)\n",
      "Epoch: [77][15/18]\tTime 0.079 (0.088)\tData 0.059 (0.067)\tLoss 0.8403 (0.7464)\tAcc 0.750 (0.721)\n",
      "Epoch: [77][16/18]\tTime 0.076 (0.088)\tData 0.057 (0.066)\tLoss 0.8524 (0.7530)\tAcc 0.625 (0.715)\n",
      "Epoch: [77][17/18]\tTime 0.074 (0.087)\tData 0.055 (0.065)\tLoss 0.8238 (0.7572)\tAcc 0.625 (0.710)\n",
      "Epoch: [77][18/18]\tTime 0.078 (0.086)\tData 0.058 (0.065)\tLoss 0.7072 (0.7558)\tAcc 0.750 (0.711)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/12]\tTime 0.243 (0.243)\tData 0.213 (0.213)\tLoss 0.8107 (0.8107)\tAcc 0.625 (0.625)\n",
      "Epoch: [78][2/12]\tTime 0.093 (0.168)\tData 0.049 (0.131)\tLoss 1.1087 (0.9597)\tAcc 0.625 (0.625)\n",
      "Epoch: [78][3/12]\tTime 0.070 (0.136)\tData 0.042 (0.101)\tLoss 0.4190 (0.7795)\tAcc 0.875 (0.708)\n",
      "Epoch: [78][4/12]\tTime 0.078 (0.121)\tData 0.052 (0.089)\tLoss 0.6403 (0.7447)\tAcc 0.688 (0.703)\n",
      "Epoch: [78][5/12]\tTime 0.081 (0.113)\tData 0.055 (0.082)\tLoss 0.7845 (0.7526)\tAcc 0.750 (0.713)\n",
      "Epoch: [78][6/12]\tTime 0.082 (0.108)\tData 0.058 (0.078)\tLoss 0.4154 (0.6964)\tAcc 0.938 (0.750)\n",
      "Epoch: [78][7/12]\tTime 0.083 (0.104)\tData 0.059 (0.075)\tLoss 0.7102 (0.6984)\tAcc 0.688 (0.741)\n",
      "Epoch: [78][8/12]\tTime 0.083 (0.102)\tData 0.060 (0.073)\tLoss 0.6977 (0.6983)\tAcc 0.562 (0.719)\n",
      "Epoch: [78][9/12]\tTime 0.079 (0.099)\tData 0.056 (0.072)\tLoss 0.5369 (0.6804)\tAcc 0.812 (0.729)\n",
      "Epoch: [78][10/12]\tTime 0.078 (0.097)\tData 0.055 (0.070)\tLoss 0.3642 (0.6488)\tAcc 0.875 (0.744)\n",
      "Epoch: [78][11/12]\tTime 0.081 (0.096)\tData 0.056 (0.069)\tLoss 0.5962 (0.6440)\tAcc 0.750 (0.744)\n",
      "Epoch: [78][12/12]\tTime 0.080 (0.094)\tData 0.057 (0.068)\tLoss 0.5465 (0.6363)\tAcc 0.667 (0.738)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/18]\tTime 0.233 (0.233)\tData 0.202 (0.202)\tLoss 0.2154 (0.2154)\tAcc 1.000 (1.000)\n",
      "Epoch: [78][2/18]\tTime 0.069 (0.151)\tData 0.045 (0.123)\tLoss 0.8399 (0.5276)\tAcc 0.625 (0.812)\n",
      "Epoch: [78][3/18]\tTime 0.076 (0.126)\tData 0.054 (0.100)\tLoss 0.5928 (0.5494)\tAcc 0.812 (0.812)\n",
      "Epoch: [78][4/18]\tTime 0.079 (0.114)\tData 0.058 (0.090)\tLoss 0.5548 (0.5507)\tAcc 0.688 (0.781)\n",
      "Epoch: [78][5/18]\tTime 0.075 (0.106)\tData 0.055 (0.083)\tLoss 0.7483 (0.5902)\tAcc 0.688 (0.762)\n",
      "Epoch: [78][6/18]\tTime 0.075 (0.101)\tData 0.054 (0.078)\tLoss 0.2932 (0.5407)\tAcc 0.938 (0.792)\n",
      "Epoch: [78][7/18]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.7122 (0.5652)\tAcc 0.688 (0.777)\n",
      "Epoch: [78][8/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 1.0798 (0.6296)\tAcc 0.625 (0.758)\n",
      "Epoch: [78][9/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 0.1162 (0.5725)\tAcc 1.000 (0.785)\n",
      "Epoch: [78][10/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.0892 (0.6242)\tAcc 0.688 (0.775)\n",
      "Epoch: [78][11/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 1.1865 (0.6753)\tAcc 0.375 (0.739)\n",
      "Epoch: [78][12/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.7395 (0.6807)\tAcc 0.812 (0.745)\n",
      "Epoch: [78][13/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 1.0912 (0.7122)\tAcc 0.438 (0.721)\n",
      "Epoch: [78][14/18]\tTime 0.073 (0.085)\tData 0.054 (0.064)\tLoss 0.7968 (0.7183)\tAcc 0.625 (0.714)\n",
      "Epoch: [78][15/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.7086 (0.7176)\tAcc 0.750 (0.717)\n",
      "Epoch: [78][16/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.7131 (0.7173)\tAcc 0.688 (0.715)\n",
      "Epoch: [78][17/18]\tTime 0.074 (0.083)\tData 0.055 (0.062)\tLoss 0.8054 (0.7225)\tAcc 0.625 (0.710)\n",
      "Epoch: [78][18/18]\tTime 0.073 (0.083)\tData 0.054 (0.062)\tLoss 0.9979 (0.7304)\tAcc 0.625 (0.707)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/12]\tTime 0.232 (0.232)\tData 0.201 (0.201)\tLoss 0.5978 (0.5978)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][2/12]\tTime 0.077 (0.154)\tData 0.049 (0.125)\tLoss 0.6417 (0.6198)\tAcc 0.625 (0.719)\n",
      "Epoch: [79][3/12]\tTime 0.076 (0.128)\tData 0.051 (0.100)\tLoss 0.5602 (0.5999)\tAcc 0.812 (0.750)\n",
      "Epoch: [79][4/12]\tTime 0.081 (0.116)\tData 0.053 (0.089)\tLoss 0.9776 (0.6943)\tAcc 0.562 (0.703)\n",
      "Epoch: [79][5/12]\tTime 0.077 (0.108)\tData 0.051 (0.081)\tLoss 0.7677 (0.7090)\tAcc 0.688 (0.700)\n",
      "Epoch: [79][6/12]\tTime 0.076 (0.103)\tData 0.052 (0.076)\tLoss 0.8446 (0.7316)\tAcc 0.688 (0.698)\n",
      "Epoch: [79][7/12]\tTime 0.079 (0.100)\tData 0.055 (0.073)\tLoss 0.7835 (0.7390)\tAcc 0.688 (0.696)\n",
      "Epoch: [79][8/12]\tTime 0.079 (0.097)\tData 0.054 (0.071)\tLoss 0.7758 (0.7436)\tAcc 0.750 (0.703)\n",
      "Epoch: [79][9/12]\tTime 0.078 (0.095)\tData 0.053 (0.069)\tLoss 0.4302 (0.7088)\tAcc 0.875 (0.722)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [79][10/12]\tTime 0.082 (0.094)\tData 0.058 (0.068)\tLoss 0.5349 (0.6914)\tAcc 0.938 (0.744)\n",
      "Epoch: [79][11/12]\tTime 0.085 (0.093)\tData 0.061 (0.067)\tLoss 0.6096 (0.6840)\tAcc 0.875 (0.756)\n",
      "Epoch: [79][12/12]\tTime 0.083 (0.092)\tData 0.059 (0.066)\tLoss 0.5180 (0.6709)\tAcc 0.800 (0.759)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/18]\tTime 0.219 (0.219)\tData 0.192 (0.192)\tLoss 0.3075 (0.3075)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/18]\tTime 0.079 (0.149)\tData 0.048 (0.120)\tLoss 0.8731 (0.5903)\tAcc 0.562 (0.750)\n",
      "Epoch: [79][3/18]\tTime 0.067 (0.122)\tData 0.045 (0.095)\tLoss 0.6373 (0.6060)\tAcc 0.812 (0.771)\n",
      "Epoch: [79][4/18]\tTime 0.075 (0.110)\tData 0.055 (0.085)\tLoss 0.6167 (0.6087)\tAcc 0.812 (0.781)\n",
      "Epoch: [79][5/18]\tTime 0.079 (0.104)\tData 0.059 (0.080)\tLoss 0.8435 (0.6556)\tAcc 0.625 (0.750)\n",
      "Epoch: [79][6/18]\tTime 0.078 (0.100)\tData 0.058 (0.076)\tLoss 0.3116 (0.5983)\tAcc 1.000 (0.792)\n",
      "Epoch: [79][7/18]\tTime 0.083 (0.097)\tData 0.058 (0.074)\tLoss 0.6756 (0.6093)\tAcc 0.750 (0.786)\n",
      "Epoch: [79][8/18]\tTime 0.077 (0.095)\tData 0.056 (0.071)\tLoss 0.8883 (0.6442)\tAcc 0.750 (0.781)\n",
      "Epoch: [79][9/18]\tTime 0.081 (0.093)\tData 0.059 (0.070)\tLoss 0.1325 (0.5873)\tAcc 1.000 (0.806)\n",
      "Epoch: [79][10/18]\tTime 0.076 (0.091)\tData 0.055 (0.068)\tLoss 1.0841 (0.6370)\tAcc 0.625 (0.788)\n",
      "Epoch: [79][11/18]\tTime 0.077 (0.090)\tData 0.057 (0.067)\tLoss 1.3307 (0.7001)\tAcc 0.375 (0.750)\n",
      "Epoch: [79][12/18]\tTime 0.075 (0.089)\tData 0.055 (0.066)\tLoss 0.9287 (0.7191)\tAcc 0.750 (0.750)\n",
      "Epoch: [79][13/18]\tTime 0.073 (0.088)\tData 0.054 (0.065)\tLoss 1.1597 (0.7530)\tAcc 0.562 (0.736)\n",
      "Epoch: [79][14/18]\tTime 0.076 (0.087)\tData 0.055 (0.065)\tLoss 0.8683 (0.7613)\tAcc 0.562 (0.723)\n",
      "Epoch: [79][15/18]\tTime 0.074 (0.086)\tData 0.053 (0.064)\tLoss 0.8087 (0.7644)\tAcc 0.688 (0.721)\n",
      "Epoch: [79][16/18]\tTime 0.074 (0.085)\tData 0.054 (0.063)\tLoss 0.8709 (0.7711)\tAcc 0.688 (0.719)\n",
      "Epoch: [79][17/18]\tTime 0.074 (0.084)\tData 0.054 (0.063)\tLoss 0.7002 (0.7669)\tAcc 0.625 (0.713)\n",
      "Epoch: [79][18/18]\tTime 0.075 (0.084)\tData 0.055 (0.062)\tLoss 0.5600 (0.7610)\tAcc 1.000 (0.721)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/12]\tTime 0.240 (0.240)\tData 0.202 (0.202)\tLoss 0.8412 (0.8412)\tAcc 0.562 (0.562)\n",
      "Epoch: [80][2/12]\tTime 0.077 (0.158)\tData 0.049 (0.125)\tLoss 1.0933 (0.9672)\tAcc 0.375 (0.469)\n",
      "Epoch: [80][3/12]\tTime 0.084 (0.134)\tData 0.058 (0.103)\tLoss 0.6400 (0.8581)\tAcc 0.625 (0.521)\n",
      "Epoch: [80][4/12]\tTime 0.089 (0.123)\tData 0.061 (0.092)\tLoss 0.5397 (0.7785)\tAcc 0.875 (0.609)\n",
      "Epoch: [80][5/12]\tTime 0.085 (0.115)\tData 0.058 (0.085)\tLoss 0.3475 (0.6923)\tAcc 0.938 (0.675)\n",
      "Epoch: [80][6/12]\tTime 0.084 (0.110)\tData 0.060 (0.081)\tLoss 0.6647 (0.6877)\tAcc 0.812 (0.698)\n",
      "Epoch: [80][7/12]\tTime 0.086 (0.107)\tData 0.062 (0.078)\tLoss 0.4576 (0.6549)\tAcc 0.812 (0.714)\n",
      "Epoch: [80][8/12]\tTime 0.086 (0.104)\tData 0.062 (0.076)\tLoss 0.4628 (0.6308)\tAcc 0.938 (0.742)\n",
      "Epoch: [80][9/12]\tTime 0.079 (0.101)\tData 0.056 (0.074)\tLoss 0.7134 (0.6400)\tAcc 0.688 (0.736)\n",
      "Epoch: [80][10/12]\tTime 0.077 (0.099)\tData 0.054 (0.072)\tLoss 0.7833 (0.6543)\tAcc 0.750 (0.738)\n",
      "Epoch: [80][11/12]\tTime 0.083 (0.097)\tData 0.058 (0.071)\tLoss 0.4254 (0.6335)\tAcc 0.875 (0.750)\n",
      "Epoch: [80][12/12]\tTime 0.083 (0.096)\tData 0.058 (0.070)\tLoss 0.5120 (0.6240)\tAcc 0.867 (0.759)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/18]\tTime 0.227 (0.227)\tData 0.203 (0.203)\tLoss 0.3353 (0.3353)\tAcc 0.938 (0.938)\n",
      "Epoch: [80][2/18]\tTime 0.076 (0.151)\tData 0.051 (0.127)\tLoss 0.9261 (0.6307)\tAcc 0.625 (0.781)\n",
      "Epoch: [80][3/18]\tTime 0.069 (0.124)\tData 0.048 (0.100)\tLoss 0.6246 (0.6287)\tAcc 0.875 (0.812)\n",
      "Epoch: [80][4/18]\tTime 0.073 (0.111)\tData 0.053 (0.089)\tLoss 0.6540 (0.6350)\tAcc 0.812 (0.812)\n",
      "Epoch: [80][5/18]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 0.6634 (0.6407)\tAcc 0.875 (0.825)\n",
      "Epoch: [80][6/18]\tTime 0.081 (0.100)\tData 0.060 (0.078)\tLoss 0.2829 (0.5811)\tAcc 1.000 (0.854)\n",
      "Epoch: [80][7/18]\tTime 0.080 (0.097)\tData 0.059 (0.075)\tLoss 0.7416 (0.6040)\tAcc 0.562 (0.813)\n",
      "Epoch: [80][8/18]\tTime 0.080 (0.095)\tData 0.060 (0.073)\tLoss 0.9386 (0.6458)\tAcc 0.562 (0.781)\n",
      "Epoch: [80][9/18]\tTime 0.080 (0.093)\tData 0.060 (0.072)\tLoss 0.1451 (0.5902)\tAcc 1.000 (0.806)\n",
      "Epoch: [80][10/18]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 1.1189 (0.6431)\tAcc 0.625 (0.788)\n",
      "Epoch: [80][11/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 1.2722 (0.7003)\tAcc 0.375 (0.750)\n",
      "Epoch: [80][12/18]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.8057 (0.7090)\tAcc 0.750 (0.750)\n",
      "Epoch: [80][13/18]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 1.1373 (0.7420)\tAcc 0.625 (0.740)\n",
      "Epoch: [80][14/18]\tTime 0.075 (0.086)\tData 0.056 (0.066)\tLoss 0.8747 (0.7515)\tAcc 0.500 (0.723)\n",
      "Epoch: [80][15/18]\tTime 0.080 (0.086)\tData 0.060 (0.065)\tLoss 0.7515 (0.7515)\tAcc 0.750 (0.725)\n",
      "Epoch: [80][16/18]\tTime 0.080 (0.086)\tData 0.060 (0.065)\tLoss 0.8144 (0.7554)\tAcc 0.750 (0.727)\n",
      "Epoch: [80][17/18]\tTime 0.081 (0.085)\tData 0.061 (0.065)\tLoss 0.8174 (0.7590)\tAcc 0.625 (0.721)\n",
      "Epoch: [80][18/18]\tTime 0.079 (0.085)\tData 0.060 (0.065)\tLoss 0.7460 (0.7587)\tAcc 0.625 (0.718)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/12]\tTime 0.227 (0.227)\tData 0.186 (0.186)\tLoss 0.7208 (0.7208)\tAcc 0.688 (0.688)\n",
      "Epoch: [81][2/12]\tTime 0.072 (0.150)\tData 0.044 (0.115)\tLoss 1.0396 (0.8802)\tAcc 0.500 (0.594)\n",
      "Epoch: [81][3/12]\tTime 0.085 (0.128)\tData 0.059 (0.096)\tLoss 0.3591 (0.7065)\tAcc 0.938 (0.708)\n",
      "Epoch: [81][4/12]\tTime 0.090 (0.118)\tData 0.063 (0.088)\tLoss 0.5679 (0.6719)\tAcc 0.875 (0.750)\n",
      "Epoch: [81][5/12]\tTime 0.085 (0.112)\tData 0.059 (0.082)\tLoss 0.8452 (0.7065)\tAcc 0.688 (0.738)\n",
      "Epoch: [81][6/12]\tTime 0.078 (0.106)\tData 0.054 (0.078)\tLoss 0.6507 (0.6972)\tAcc 0.688 (0.729)\n",
      "Epoch: [81][7/12]\tTime 0.078 (0.102)\tData 0.054 (0.074)\tLoss 0.8283 (0.7159)\tAcc 0.562 (0.705)\n",
      "Epoch: [81][8/12]\tTime 0.082 (0.100)\tData 0.057 (0.072)\tLoss 0.4975 (0.6886)\tAcc 0.875 (0.727)\n",
      "Epoch: [81][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.071)\tLoss 0.5754 (0.6761)\tAcc 0.812 (0.736)\n",
      "Epoch: [81][10/12]\tTime 0.085 (0.097)\tData 0.061 (0.070)\tLoss 0.5167 (0.6601)\tAcc 0.750 (0.738)\n",
      "Epoch: [81][11/12]\tTime 0.086 (0.096)\tData 0.062 (0.069)\tLoss 0.8500 (0.6774)\tAcc 0.688 (0.733)\n",
      "Epoch: [81][12/12]\tTime 0.079 (0.094)\tData 0.056 (0.068)\tLoss 0.5547 (0.6677)\tAcc 0.800 (0.738)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/18]\tTime 0.242 (0.242)\tData 0.197 (0.197)\tLoss 0.3094 (0.3094)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/18]\tTime 0.068 (0.155)\tData 0.039 (0.118)\tLoss 0.8840 (0.5967)\tAcc 0.500 (0.719)\n",
      "Epoch: [81][3/18]\tTime 0.073 (0.128)\tData 0.052 (0.096)\tLoss 0.5802 (0.5912)\tAcc 0.812 (0.750)\n",
      "Epoch: [81][4/18]\tTime 0.081 (0.116)\tData 0.059 (0.087)\tLoss 0.5829 (0.5891)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][5/18]\tTime 0.077 (0.108)\tData 0.056 (0.080)\tLoss 0.8165 (0.6346)\tAcc 0.688 (0.738)\n",
      "Epoch: [81][6/18]\tTime 0.074 (0.102)\tData 0.054 (0.076)\tLoss 0.2743 (0.5746)\tAcc 1.000 (0.781)\n",
      "Epoch: [81][7/18]\tTime 0.074 (0.098)\tData 0.053 (0.073)\tLoss 0.7901 (0.6054)\tAcc 0.625 (0.759)\n",
      "Epoch: [81][8/18]\tTime 0.075 (0.095)\tData 0.054 (0.070)\tLoss 0.9527 (0.6488)\tAcc 0.625 (0.742)\n",
      "Epoch: [81][9/18]\tTime 0.080 (0.094)\tData 0.059 (0.069)\tLoss 0.1088 (0.5888)\tAcc 1.000 (0.771)\n",
      "Epoch: [81][10/18]\tTime 0.081 (0.092)\tData 0.059 (0.068)\tLoss 1.1475 (0.6447)\tAcc 0.562 (0.750)\n",
      "Epoch: [81][11/18]\tTime 0.080 (0.091)\tData 0.059 (0.067)\tLoss 1.3561 (0.7093)\tAcc 0.375 (0.716)\n",
      "Epoch: [81][12/18]\tTime 0.081 (0.090)\tData 0.059 (0.067)\tLoss 0.9411 (0.7286)\tAcc 0.750 (0.719)\n",
      "Epoch: [81][13/18]\tTime 0.074 (0.089)\tData 0.054 (0.066)\tLoss 1.1428 (0.7605)\tAcc 0.562 (0.707)\n",
      "Epoch: [81][14/18]\tTime 0.074 (0.088)\tData 0.054 (0.065)\tLoss 0.7369 (0.7588)\tAcc 0.688 (0.705)\n",
      "Epoch: [81][15/18]\tTime 0.075 (0.087)\tData 0.055 (0.064)\tLoss 0.8265 (0.7633)\tAcc 0.625 (0.700)\n",
      "Epoch: [81][16/18]\tTime 0.076 (0.087)\tData 0.056 (0.064)\tLoss 0.7774 (0.7642)\tAcc 0.688 (0.699)\n",
      "Epoch: [81][17/18]\tTime 0.082 (0.086)\tData 0.061 (0.064)\tLoss 0.7815 (0.7652)\tAcc 0.625 (0.695)\n",
      "Epoch: [81][18/18]\tTime 0.080 (0.086)\tData 0.060 (0.063)\tLoss 0.8859 (0.7687)\tAcc 0.750 (0.696)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/12]\tTime 0.235 (0.235)\tData 0.201 (0.201)\tLoss 0.7314 (0.7314)\tAcc 0.750 (0.750)\n",
      "Epoch: [82][2/12]\tTime 0.074 (0.154)\tData 0.047 (0.124)\tLoss 0.4621 (0.5967)\tAcc 0.938 (0.844)\n",
      "Epoch: [82][3/12]\tTime 0.080 (0.130)\tData 0.053 (0.100)\tLoss 0.5878 (0.5938)\tAcc 0.750 (0.812)\n",
      "Epoch: [82][4/12]\tTime 0.085 (0.118)\tData 0.059 (0.090)\tLoss 0.9339 (0.6788)\tAcc 0.688 (0.781)\n",
      "Epoch: [82][5/12]\tTime 0.089 (0.113)\tData 0.062 (0.085)\tLoss 0.8684 (0.7167)\tAcc 0.625 (0.750)\n",
      "Epoch: [82][6/12]\tTime 0.084 (0.108)\tData 0.060 (0.080)\tLoss 0.6337 (0.7029)\tAcc 0.688 (0.740)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [82][7/12]\tTime 0.079 (0.104)\tData 0.055 (0.077)\tLoss 0.4410 (0.6655)\tAcc 0.812 (0.750)\n",
      "Epoch: [82][8/12]\tTime 0.081 (0.101)\tData 0.057 (0.074)\tLoss 0.4218 (0.6350)\tAcc 0.812 (0.758)\n",
      "Epoch: [82][9/12]\tTime 0.079 (0.098)\tData 0.055 (0.072)\tLoss 1.0404 (0.6800)\tAcc 0.500 (0.729)\n",
      "Epoch: [82][10/12]\tTime 0.078 (0.096)\tData 0.054 (0.070)\tLoss 0.5114 (0.6632)\tAcc 0.750 (0.731)\n",
      "Epoch: [82][11/12]\tTime 0.085 (0.095)\tData 0.060 (0.069)\tLoss 0.3727 (0.6368)\tAcc 0.938 (0.750)\n",
      "Epoch: [82][12/12]\tTime 0.086 (0.095)\tData 0.061 (0.069)\tLoss 0.5028 (0.6263)\tAcc 0.867 (0.759)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/18]\tTime 0.226 (0.226)\tData 0.202 (0.202)\tLoss 0.2932 (0.2932)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/18]\tTime 0.080 (0.153)\tData 0.052 (0.127)\tLoss 0.9056 (0.5994)\tAcc 0.625 (0.781)\n",
      "Epoch: [82][3/18]\tTime 0.071 (0.126)\tData 0.049 (0.101)\tLoss 0.5916 (0.5968)\tAcc 0.750 (0.771)\n",
      "Epoch: [82][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.090)\tLoss 0.6193 (0.6024)\tAcc 0.625 (0.734)\n",
      "Epoch: [82][5/18]\tTime 0.081 (0.107)\tData 0.060 (0.084)\tLoss 0.6975 (0.6214)\tAcc 0.750 (0.738)\n",
      "Epoch: [82][6/18]\tTime 0.080 (0.103)\tData 0.060 (0.080)\tLoss 0.2375 (0.5574)\tAcc 1.000 (0.781)\n",
      "Epoch: [82][7/18]\tTime 0.081 (0.100)\tData 0.060 (0.077)\tLoss 0.6536 (0.5712)\tAcc 0.688 (0.768)\n",
      "Epoch: [82][8/18]\tTime 0.076 (0.097)\tData 0.056 (0.075)\tLoss 0.9501 (0.6185)\tAcc 0.688 (0.758)\n",
      "Epoch: [82][9/18]\tTime 0.075 (0.094)\tData 0.055 (0.073)\tLoss 0.1062 (0.5616)\tAcc 1.000 (0.785)\n",
      "Epoch: [82][10/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 1.0335 (0.6088)\tAcc 0.562 (0.762)\n",
      "Epoch: [82][11/18]\tTime 0.076 (0.091)\tData 0.055 (0.069)\tLoss 1.2455 (0.6667)\tAcc 0.375 (0.727)\n",
      "Epoch: [82][12/18]\tTime 0.077 (0.090)\tData 0.057 (0.068)\tLoss 0.8819 (0.6846)\tAcc 0.812 (0.734)\n",
      "Epoch: [82][13/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 1.0503 (0.7127)\tAcc 0.625 (0.726)\n",
      "Epoch: [82][14/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.8404 (0.7219)\tAcc 0.625 (0.719)\n",
      "Epoch: [82][15/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.7664 (0.7248)\tAcc 0.750 (0.721)\n",
      "Epoch: [82][16/18]\tTime 0.080 (0.087)\tData 0.060 (0.066)\tLoss 0.8364 (0.7318)\tAcc 0.688 (0.719)\n",
      "Epoch: [82][17/18]\tTime 0.076 (0.087)\tData 0.056 (0.066)\tLoss 0.8474 (0.7386)\tAcc 0.625 (0.713)\n",
      "Epoch: [82][18/18]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 0.6175 (0.7351)\tAcc 0.875 (0.718)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/12]\tTime 0.234 (0.234)\tData 0.203 (0.203)\tLoss 0.9042 (0.9042)\tAcc 0.688 (0.688)\n",
      "Epoch: [83][2/12]\tTime 0.083 (0.158)\tData 0.056 (0.129)\tLoss 0.8993 (0.9018)\tAcc 0.688 (0.688)\n",
      "Epoch: [83][3/12]\tTime 0.085 (0.134)\tData 0.059 (0.106)\tLoss 0.5053 (0.7696)\tAcc 0.812 (0.729)\n",
      "Epoch: [83][4/12]\tTime 0.087 (0.122)\tData 0.061 (0.094)\tLoss 0.9696 (0.8196)\tAcc 0.688 (0.719)\n",
      "Epoch: [83][5/12]\tTime 0.081 (0.114)\tData 0.055 (0.087)\tLoss 0.3074 (0.7172)\tAcc 0.875 (0.750)\n",
      "Epoch: [83][6/12]\tTime 0.082 (0.109)\tData 0.057 (0.082)\tLoss 0.4397 (0.6709)\tAcc 0.875 (0.771)\n",
      "Epoch: [83][7/12]\tTime 0.086 (0.105)\tData 0.061 (0.079)\tLoss 0.8631 (0.6984)\tAcc 0.625 (0.750)\n",
      "Epoch: [83][8/12]\tTime 0.086 (0.103)\tData 0.061 (0.077)\tLoss 0.6939 (0.6978)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][9/12]\tTime 0.087 (0.101)\tData 0.062 (0.075)\tLoss 0.6644 (0.6941)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][10/12]\tTime 0.079 (0.099)\tData 0.055 (0.073)\tLoss 0.6089 (0.6856)\tAcc 0.812 (0.756)\n",
      "Epoch: [83][11/12]\tTime 0.081 (0.097)\tData 0.057 (0.072)\tLoss 0.3710 (0.6570)\tAcc 0.938 (0.773)\n",
      "Epoch: [83][12/12]\tTime 0.079 (0.096)\tData 0.055 (0.070)\tLoss 0.4805 (0.6431)\tAcc 0.733 (0.770)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/18]\tTime 0.229 (0.229)\tData 0.192 (0.192)\tLoss 0.3702 (0.3702)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/18]\tTime 0.078 (0.153)\tData 0.045 (0.119)\tLoss 0.8431 (0.6067)\tAcc 0.750 (0.844)\n",
      "Epoch: [83][3/18]\tTime 0.071 (0.126)\tData 0.048 (0.095)\tLoss 0.5995 (0.6043)\tAcc 0.688 (0.792)\n",
      "Epoch: [83][4/18]\tTime 0.079 (0.114)\tData 0.059 (0.086)\tLoss 0.5926 (0.6014)\tAcc 0.812 (0.797)\n",
      "Epoch: [83][5/18]\tTime 0.075 (0.106)\tData 0.055 (0.080)\tLoss 0.6970 (0.6205)\tAcc 0.688 (0.775)\n",
      "Epoch: [83][6/18]\tTime 0.075 (0.101)\tData 0.055 (0.076)\tLoss 0.2360 (0.5564)\tAcc 1.000 (0.812)\n",
      "Epoch: [83][7/18]\tTime 0.075 (0.097)\tData 0.054 (0.073)\tLoss 0.7334 (0.5817)\tAcc 0.688 (0.795)\n",
      "Epoch: [83][8/18]\tTime 0.074 (0.095)\tData 0.054 (0.070)\tLoss 1.0269 (0.6373)\tAcc 0.500 (0.758)\n",
      "Epoch: [83][9/18]\tTime 0.075 (0.092)\tData 0.055 (0.068)\tLoss 0.0892 (0.5764)\tAcc 1.000 (0.785)\n",
      "Epoch: [83][10/18]\tTime 0.075 (0.091)\tData 0.055 (0.067)\tLoss 1.2295 (0.6417)\tAcc 0.688 (0.775)\n",
      "Epoch: [83][11/18]\tTime 0.075 (0.089)\tData 0.055 (0.066)\tLoss 1.2863 (0.7003)\tAcc 0.375 (0.739)\n",
      "Epoch: [83][12/18]\tTime 0.075 (0.088)\tData 0.055 (0.065)\tLoss 0.9054 (0.7174)\tAcc 0.688 (0.734)\n",
      "Epoch: [83][13/18]\tTime 0.074 (0.087)\tData 0.054 (0.064)\tLoss 1.0711 (0.7446)\tAcc 0.500 (0.716)\n",
      "Epoch: [83][14/18]\tTime 0.075 (0.086)\tData 0.055 (0.064)\tLoss 0.7442 (0.7446)\tAcc 0.625 (0.710)\n",
      "Epoch: [83][15/18]\tTime 0.080 (0.086)\tData 0.060 (0.063)\tLoss 0.8331 (0.7505)\tAcc 0.750 (0.713)\n",
      "Epoch: [83][16/18]\tTime 0.076 (0.085)\tData 0.056 (0.063)\tLoss 0.7522 (0.7506)\tAcc 0.625 (0.707)\n",
      "Epoch: [83][17/18]\tTime 0.081 (0.085)\tData 0.060 (0.063)\tLoss 0.7420 (0.7501)\tAcc 0.625 (0.702)\n",
      "Epoch: [83][18/18]\tTime 0.079 (0.084)\tData 0.059 (0.063)\tLoss 0.7085 (0.7489)\tAcc 0.750 (0.704)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/12]\tTime 0.228 (0.228)\tData 0.198 (0.198)\tLoss 0.6797 (0.6797)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][2/12]\tTime 0.078 (0.153)\tData 0.050 (0.124)\tLoss 0.8504 (0.7650)\tAcc 0.625 (0.688)\n",
      "Epoch: [84][3/12]\tTime 0.075 (0.127)\tData 0.050 (0.099)\tLoss 1.0335 (0.8545)\tAcc 0.688 (0.688)\n",
      "Epoch: [84][4/12]\tTime 0.078 (0.115)\tData 0.053 (0.088)\tLoss 0.9527 (0.8791)\tAcc 0.688 (0.688)\n",
      "Epoch: [84][5/12]\tTime 0.082 (0.108)\tData 0.056 (0.081)\tLoss 0.3548 (0.7742)\tAcc 0.875 (0.725)\n",
      "Epoch: [84][6/12]\tTime 0.077 (0.103)\tData 0.053 (0.077)\tLoss 0.5340 (0.7342)\tAcc 0.812 (0.740)\n",
      "Epoch: [84][7/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.5339 (0.7056)\tAcc 0.750 (0.741)\n",
      "Epoch: [84][8/12]\tTime 0.081 (0.097)\tData 0.057 (0.071)\tLoss 0.7197 (0.7073)\tAcc 0.812 (0.750)\n",
      "Epoch: [84][9/12]\tTime 0.078 (0.095)\tData 0.054 (0.070)\tLoss 0.6857 (0.7049)\tAcc 0.812 (0.757)\n",
      "Epoch: [84][10/12]\tTime 0.078 (0.093)\tData 0.054 (0.068)\tLoss 0.8038 (0.7148)\tAcc 0.625 (0.744)\n",
      "Epoch: [84][11/12]\tTime 0.081 (0.092)\tData 0.056 (0.067)\tLoss 0.5869 (0.7032)\tAcc 0.812 (0.750)\n",
      "Epoch: [84][12/12]\tTime 0.087 (0.092)\tData 0.062 (0.067)\tLoss 0.4870 (0.6862)\tAcc 0.867 (0.759)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/18]\tTime 0.220 (0.220)\tData 0.191 (0.191)\tLoss 0.3263 (0.3263)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/18]\tTime 0.068 (0.144)\tData 0.045 (0.118)\tLoss 0.8428 (0.5845)\tAcc 0.625 (0.781)\n",
      "Epoch: [84][3/18]\tTime 0.073 (0.120)\tData 0.052 (0.096)\tLoss 0.6712 (0.6134)\tAcc 0.688 (0.750)\n",
      "Epoch: [84][4/18]\tTime 0.079 (0.110)\tData 0.058 (0.087)\tLoss 0.6276 (0.6169)\tAcc 0.625 (0.719)\n",
      "Epoch: [84][5/18]\tTime 0.081 (0.104)\tData 0.060 (0.081)\tLoss 0.7995 (0.6535)\tAcc 0.625 (0.700)\n",
      "Epoch: [84][6/18]\tTime 0.082 (0.100)\tData 0.060 (0.078)\tLoss 0.3251 (0.5987)\tAcc 1.000 (0.750)\n",
      "Epoch: [84][7/18]\tTime 0.081 (0.098)\tData 0.058 (0.075)\tLoss 0.6026 (0.5993)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][8/18]\tTime 0.075 (0.095)\tData 0.055 (0.072)\tLoss 0.9766 (0.6464)\tAcc 0.688 (0.742)\n",
      "Epoch: [84][9/18]\tTime 0.075 (0.093)\tData 0.055 (0.070)\tLoss 0.1512 (0.5914)\tAcc 1.000 (0.771)\n",
      "Epoch: [84][10/18]\tTime 0.076 (0.091)\tData 0.055 (0.069)\tLoss 1.1387 (0.6461)\tAcc 0.500 (0.744)\n",
      "Epoch: [84][11/18]\tTime 0.080 (0.090)\tData 0.059 (0.068)\tLoss 1.2359 (0.6998)\tAcc 0.375 (0.710)\n",
      "Epoch: [84][12/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.8624 (0.7133)\tAcc 0.812 (0.719)\n",
      "Epoch: [84][13/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 1.0123 (0.7363)\tAcc 0.625 (0.712)\n",
      "Epoch: [84][14/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8165 (0.7420)\tAcc 0.562 (0.701)\n",
      "Epoch: [84][15/18]\tTime 0.075 (0.087)\tData 0.055 (0.066)\tLoss 0.7921 (0.7454)\tAcc 0.750 (0.704)\n",
      "Epoch: [84][16/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.8565 (0.7523)\tAcc 0.688 (0.703)\n",
      "Epoch: [84][17/18]\tTime 0.080 (0.086)\tData 0.059 (0.064)\tLoss 0.7645 (0.7530)\tAcc 0.625 (0.699)\n",
      "Epoch: [84][18/18]\tTime 0.080 (0.086)\tData 0.060 (0.064)\tLoss 0.7143 (0.7519)\tAcc 0.625 (0.696)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/12]\tTime 0.228 (0.228)\tData 0.198 (0.198)\tLoss 0.5959 (0.5959)\tAcc 0.812 (0.812)\n",
      "Epoch: [85][2/12]\tTime 0.086 (0.157)\tData 0.050 (0.124)\tLoss 0.4524 (0.5242)\tAcc 0.875 (0.844)\n",
      "Epoch: [85][3/12]\tTime 0.076 (0.130)\tData 0.051 (0.100)\tLoss 1.0956 (0.7146)\tAcc 0.500 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [85][4/12]\tTime 0.086 (0.119)\tData 0.061 (0.090)\tLoss 0.8268 (0.7427)\tAcc 0.688 (0.719)\n",
      "Epoch: [85][5/12]\tTime 0.087 (0.113)\tData 0.061 (0.084)\tLoss 0.7186 (0.7379)\tAcc 0.688 (0.713)\n",
      "Epoch: [85][6/12]\tTime 0.078 (0.107)\tData 0.054 (0.079)\tLoss 0.7838 (0.7455)\tAcc 0.750 (0.719)\n",
      "Epoch: [85][7/12]\tTime 0.078 (0.103)\tData 0.054 (0.075)\tLoss 0.6728 (0.7351)\tAcc 0.625 (0.705)\n",
      "Epoch: [85][8/12]\tTime 0.080 (0.100)\tData 0.056 (0.073)\tLoss 0.6726 (0.7273)\tAcc 0.750 (0.711)\n",
      "Epoch: [85][9/12]\tTime 0.078 (0.097)\tData 0.055 (0.071)\tLoss 0.6246 (0.7159)\tAcc 0.688 (0.708)\n",
      "Epoch: [85][10/12]\tTime 0.078 (0.095)\tData 0.054 (0.069)\tLoss 1.0205 (0.7464)\tAcc 0.625 (0.700)\n",
      "Epoch: [85][11/12]\tTime 0.081 (0.094)\tData 0.057 (0.068)\tLoss 0.6386 (0.7366)\tAcc 0.688 (0.699)\n",
      "Epoch: [85][12/12]\tTime 0.079 (0.093)\tData 0.055 (0.067)\tLoss 0.5090 (0.7187)\tAcc 0.867 (0.712)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/18]\tTime 0.250 (0.250)\tData 0.210 (0.210)\tLoss 0.3613 (0.3613)\tAcc 0.875 (0.875)\n",
      "Epoch: [85][2/18]\tTime 0.065 (0.158)\tData 0.037 (0.124)\tLoss 0.8068 (0.5841)\tAcc 0.625 (0.750)\n",
      "Epoch: [85][3/18]\tTime 0.067 (0.127)\tData 0.046 (0.098)\tLoss 0.5494 (0.5725)\tAcc 0.812 (0.771)\n",
      "Epoch: [85][4/18]\tTime 0.074 (0.114)\tData 0.053 (0.087)\tLoss 0.5594 (0.5692)\tAcc 0.750 (0.766)\n",
      "Epoch: [85][5/18]\tTime 0.074 (0.106)\tData 0.054 (0.080)\tLoss 0.8044 (0.6163)\tAcc 0.750 (0.762)\n",
      "Epoch: [85][6/18]\tTime 0.081 (0.102)\tData 0.059 (0.077)\tLoss 0.2954 (0.5628)\tAcc 1.000 (0.802)\n",
      "Epoch: [85][7/18]\tTime 0.081 (0.099)\tData 0.060 (0.074)\tLoss 0.6639 (0.5772)\tAcc 0.812 (0.804)\n",
      "Epoch: [85][8/18]\tTime 0.080 (0.096)\tData 0.059 (0.072)\tLoss 0.9911 (0.6290)\tAcc 0.562 (0.773)\n",
      "Epoch: [85][9/18]\tTime 0.082 (0.095)\tData 0.060 (0.071)\tLoss 0.1236 (0.5728)\tAcc 1.000 (0.799)\n",
      "Epoch: [85][10/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 1.0425 (0.6198)\tAcc 0.562 (0.775)\n",
      "Epoch: [85][11/18]\tTime 0.075 (0.092)\tData 0.055 (0.069)\tLoss 1.2403 (0.6762)\tAcc 0.375 (0.739)\n",
      "Epoch: [85][12/18]\tTime 0.076 (0.090)\tData 0.056 (0.068)\tLoss 0.8316 (0.6891)\tAcc 0.750 (0.740)\n",
      "Epoch: [85][13/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 0.9435 (0.7087)\tAcc 0.688 (0.736)\n",
      "Epoch: [85][14/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.7739 (0.7134)\tAcc 0.562 (0.723)\n",
      "Epoch: [85][15/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.9689 (0.7304)\tAcc 0.750 (0.725)\n",
      "Epoch: [85][16/18]\tTime 0.081 (0.088)\tData 0.061 (0.066)\tLoss 0.8199 (0.7360)\tAcc 0.688 (0.723)\n",
      "Epoch: [85][17/18]\tTime 0.078 (0.087)\tData 0.059 (0.065)\tLoss 0.8040 (0.7400)\tAcc 0.625 (0.717)\n",
      "Epoch: [85][18/18]\tTime 0.075 (0.087)\tData 0.056 (0.065)\tLoss 0.8456 (0.7430)\tAcc 0.625 (0.714)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/12]\tTime 0.221 (0.221)\tData 0.189 (0.189)\tLoss 0.8586 (0.8586)\tAcc 0.625 (0.625)\n",
      "Epoch: [86][2/12]\tTime 0.090 (0.155)\tData 0.055 (0.122)\tLoss 0.6074 (0.7330)\tAcc 0.750 (0.688)\n",
      "Epoch: [86][3/12]\tTime 0.080 (0.130)\tData 0.052 (0.099)\tLoss 0.9182 (0.7948)\tAcc 0.688 (0.688)\n",
      "Epoch: [86][4/12]\tTime 0.088 (0.120)\tData 0.061 (0.089)\tLoss 0.5704 (0.7387)\tAcc 0.875 (0.734)\n",
      "Epoch: [86][5/12]\tTime 0.082 (0.112)\tData 0.057 (0.083)\tLoss 0.6993 (0.7308)\tAcc 0.688 (0.725)\n",
      "Epoch: [86][6/12]\tTime 0.077 (0.106)\tData 0.054 (0.078)\tLoss 0.5692 (0.7039)\tAcc 0.812 (0.740)\n",
      "Epoch: [86][7/12]\tTime 0.078 (0.102)\tData 0.055 (0.075)\tLoss 0.9763 (0.7428)\tAcc 0.562 (0.714)\n",
      "Epoch: [86][8/12]\tTime 0.079 (0.099)\tData 0.055 (0.072)\tLoss 0.5592 (0.7198)\tAcc 0.812 (0.727)\n",
      "Epoch: [86][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.071)\tLoss 0.4164 (0.6861)\tAcc 0.875 (0.743)\n",
      "Epoch: [86][10/12]\tTime 0.086 (0.097)\tData 0.062 (0.070)\tLoss 0.5012 (0.6676)\tAcc 0.750 (0.744)\n",
      "Epoch: [86][11/12]\tTime 0.086 (0.096)\tData 0.062 (0.069)\tLoss 0.8734 (0.6863)\tAcc 0.625 (0.733)\n",
      "Epoch: [86][12/12]\tTime 0.085 (0.095)\tData 0.061 (0.069)\tLoss 0.4319 (0.6664)\tAcc 0.800 (0.738)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/18]\tTime 0.234 (0.234)\tData 0.201 (0.201)\tLoss 0.3494 (0.3494)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/18]\tTime 0.077 (0.156)\tData 0.049 (0.125)\tLoss 0.7727 (0.5610)\tAcc 0.562 (0.750)\n",
      "Epoch: [86][3/18]\tTime 0.074 (0.129)\tData 0.054 (0.101)\tLoss 0.6152 (0.5791)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][4/18]\tTime 0.080 (0.116)\tData 0.060 (0.091)\tLoss 0.5823 (0.5799)\tAcc 0.688 (0.734)\n",
      "Epoch: [86][5/18]\tTime 0.075 (0.108)\tData 0.055 (0.084)\tLoss 0.8498 (0.6339)\tAcc 0.750 (0.738)\n",
      "Epoch: [86][6/18]\tTime 0.075 (0.103)\tData 0.055 (0.079)\tLoss 0.3075 (0.5795)\tAcc 0.938 (0.771)\n",
      "Epoch: [86][7/18]\tTime 0.074 (0.099)\tData 0.053 (0.075)\tLoss 0.6708 (0.5925)\tAcc 0.688 (0.759)\n",
      "Epoch: [86][8/18]\tTime 0.076 (0.096)\tData 0.055 (0.073)\tLoss 0.8400 (0.6235)\tAcc 0.688 (0.750)\n",
      "Epoch: [86][9/18]\tTime 0.080 (0.094)\tData 0.059 (0.071)\tLoss 0.2257 (0.5793)\tAcc 1.000 (0.778)\n",
      "Epoch: [86][10/18]\tTime 0.083 (0.093)\tData 0.059 (0.070)\tLoss 1.0030 (0.6216)\tAcc 0.812 (0.781)\n",
      "Epoch: [86][11/18]\tTime 0.077 (0.092)\tData 0.057 (0.069)\tLoss 1.2350 (0.6774)\tAcc 0.375 (0.744)\n",
      "Epoch: [86][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.9260 (0.6981)\tAcc 0.750 (0.745)\n",
      "Epoch: [86][13/18]\tTime 0.074 (0.089)\tData 0.056 (0.067)\tLoss 1.0755 (0.7271)\tAcc 0.562 (0.731)\n",
      "Epoch: [86][14/18]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 0.7375 (0.7279)\tAcc 0.625 (0.723)\n",
      "Epoch: [86][15/18]\tTime 0.075 (0.087)\tData 0.056 (0.066)\tLoss 0.8122 (0.7335)\tAcc 0.688 (0.721)\n",
      "Epoch: [86][16/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 0.8025 (0.7378)\tAcc 0.750 (0.723)\n",
      "Epoch: [86][17/18]\tTime 0.076 (0.086)\tData 0.056 (0.064)\tLoss 0.8005 (0.7415)\tAcc 0.625 (0.717)\n",
      "Epoch: [86][18/18]\tTime 0.080 (0.086)\tData 0.061 (0.064)\tLoss 0.6139 (0.7379)\tAcc 1.000 (0.725)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/12]\tTime 0.252 (0.252)\tData 0.211 (0.211)\tLoss 0.5039 (0.5039)\tAcc 0.812 (0.812)\n",
      "Epoch: [87][2/12]\tTime 0.079 (0.166)\tData 0.045 (0.128)\tLoss 0.6881 (0.5960)\tAcc 0.625 (0.719)\n",
      "Epoch: [87][3/12]\tTime 0.078 (0.137)\tData 0.053 (0.103)\tLoss 0.6338 (0.6086)\tAcc 0.750 (0.729)\n",
      "Epoch: [87][4/12]\tTime 0.080 (0.123)\tData 0.054 (0.091)\tLoss 0.9208 (0.6867)\tAcc 0.625 (0.703)\n",
      "Epoch: [87][5/12]\tTime 0.081 (0.114)\tData 0.054 (0.083)\tLoss 0.5468 (0.6587)\tAcc 0.750 (0.713)\n",
      "Epoch: [87][6/12]\tTime 0.083 (0.109)\tData 0.059 (0.079)\tLoss 0.5838 (0.6462)\tAcc 0.875 (0.740)\n",
      "Epoch: [87][7/12]\tTime 0.085 (0.106)\tData 0.061 (0.077)\tLoss 0.6761 (0.6505)\tAcc 0.750 (0.741)\n",
      "Epoch: [87][8/12]\tTime 0.086 (0.103)\tData 0.062 (0.075)\tLoss 0.4630 (0.6270)\tAcc 0.750 (0.742)\n",
      "Epoch: [87][9/12]\tTime 0.085 (0.101)\tData 0.061 (0.073)\tLoss 0.5304 (0.6163)\tAcc 0.812 (0.750)\n",
      "Epoch: [87][10/12]\tTime 0.080 (0.099)\tData 0.055 (0.071)\tLoss 0.7859 (0.6333)\tAcc 0.625 (0.738)\n",
      "Epoch: [87][11/12]\tTime 0.081 (0.097)\tData 0.056 (0.070)\tLoss 0.8228 (0.6505)\tAcc 0.688 (0.733)\n",
      "Epoch: [87][12/12]\tTime 0.079 (0.096)\tData 0.055 (0.069)\tLoss 0.9291 (0.6724)\tAcc 0.733 (0.733)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/18]\tTime 0.241 (0.241)\tData 0.213 (0.213)\tLoss 0.4211 (0.4211)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][2/18]\tTime 0.084 (0.162)\tData 0.054 (0.133)\tLoss 0.8949 (0.6580)\tAcc 0.625 (0.750)\n",
      "Epoch: [87][3/18]\tTime 0.077 (0.134)\tData 0.054 (0.107)\tLoss 0.6265 (0.6475)\tAcc 0.812 (0.771)\n",
      "Epoch: [87][4/18]\tTime 0.080 (0.120)\tData 0.058 (0.095)\tLoss 0.5483 (0.6227)\tAcc 0.750 (0.766)\n",
      "Epoch: [87][5/18]\tTime 0.082 (0.113)\tData 0.059 (0.088)\tLoss 0.8439 (0.6670)\tAcc 0.750 (0.762)\n",
      "Epoch: [87][6/18]\tTime 0.077 (0.107)\tData 0.057 (0.083)\tLoss 0.3312 (0.6110)\tAcc 0.938 (0.792)\n",
      "Epoch: [87][7/18]\tTime 0.075 (0.102)\tData 0.055 (0.079)\tLoss 0.7766 (0.6346)\tAcc 0.625 (0.768)\n",
      "Epoch: [87][8/18]\tTime 0.074 (0.099)\tData 0.053 (0.075)\tLoss 0.9634 (0.6757)\tAcc 0.562 (0.742)\n",
      "Epoch: [87][9/18]\tTime 0.080 (0.097)\tData 0.059 (0.074)\tLoss 0.1622 (0.6187)\tAcc 1.000 (0.771)\n",
      "Epoch: [87][10/18]\tTime 0.077 (0.095)\tData 0.057 (0.072)\tLoss 1.0632 (0.6631)\tAcc 0.625 (0.756)\n",
      "Epoch: [87][11/18]\tTime 0.080 (0.093)\tData 0.059 (0.071)\tLoss 1.1339 (0.7059)\tAcc 0.375 (0.722)\n",
      "Epoch: [87][12/18]\tTime 0.081 (0.092)\tData 0.060 (0.070)\tLoss 0.8766 (0.7202)\tAcc 0.812 (0.729)\n",
      "Epoch: [87][13/18]\tTime 0.081 (0.091)\tData 0.060 (0.069)\tLoss 1.1079 (0.7500)\tAcc 0.500 (0.712)\n",
      "Epoch: [87][14/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.7634 (0.7509)\tAcc 0.688 (0.710)\n",
      "Epoch: [87][15/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.8581 (0.7581)\tAcc 0.688 (0.708)\n",
      "Epoch: [87][16/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.8397 (0.7632)\tAcc 0.750 (0.711)\n",
      "Epoch: [87][17/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 0.7132 (0.7602)\tAcc 0.625 (0.706)\n",
      "Epoch: [87][18/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.6409 (0.7568)\tAcc 0.875 (0.711)\n",
      "train at epoch 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [88][1/12]\tTime 0.220 (0.220)\tData 0.186 (0.186)\tLoss 0.4976 (0.4976)\tAcc 0.812 (0.812)\n",
      "Epoch: [88][2/12]\tTime 0.071 (0.145)\tData 0.045 (0.115)\tLoss 0.6941 (0.5958)\tAcc 0.750 (0.781)\n",
      "Epoch: [88][3/12]\tTime 0.078 (0.123)\tData 0.053 (0.094)\tLoss 0.8109 (0.6675)\tAcc 0.562 (0.708)\n",
      "Epoch: [88][4/12]\tTime 0.079 (0.112)\tData 0.053 (0.084)\tLoss 0.6874 (0.6725)\tAcc 0.688 (0.703)\n",
      "Epoch: [88][5/12]\tTime 0.080 (0.106)\tData 0.053 (0.078)\tLoss 0.7307 (0.6841)\tAcc 0.688 (0.700)\n",
      "Epoch: [88][6/12]\tTime 0.084 (0.102)\tData 0.059 (0.075)\tLoss 0.7937 (0.7024)\tAcc 0.688 (0.698)\n",
      "Epoch: [88][7/12]\tTime 0.087 (0.100)\tData 0.062 (0.073)\tLoss 0.9820 (0.7423)\tAcc 0.625 (0.688)\n",
      "Epoch: [88][8/12]\tTime 0.086 (0.098)\tData 0.061 (0.071)\tLoss 0.5843 (0.7226)\tAcc 0.750 (0.695)\n",
      "Epoch: [88][9/12]\tTime 0.086 (0.097)\tData 0.061 (0.070)\tLoss 0.5566 (0.7041)\tAcc 0.875 (0.715)\n",
      "Epoch: [88][10/12]\tTime 0.087 (0.096)\tData 0.062 (0.069)\tLoss 0.7528 (0.7090)\tAcc 0.750 (0.719)\n",
      "Epoch: [88][11/12]\tTime 0.087 (0.095)\tData 0.061 (0.069)\tLoss 0.4885 (0.6889)\tAcc 0.812 (0.727)\n",
      "Epoch: [88][12/12]\tTime 0.086 (0.094)\tData 0.061 (0.068)\tLoss 0.3902 (0.6655)\tAcc 0.800 (0.733)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/18]\tTime 0.226 (0.226)\tData 0.201 (0.201)\tLoss 0.4455 (0.4455)\tAcc 0.875 (0.875)\n",
      "Epoch: [88][2/18]\tTime 0.077 (0.151)\tData 0.050 (0.126)\tLoss 0.9229 (0.6842)\tAcc 0.500 (0.688)\n",
      "Epoch: [88][3/18]\tTime 0.068 (0.124)\tData 0.047 (0.100)\tLoss 0.5728 (0.6471)\tAcc 0.750 (0.708)\n",
      "Epoch: [88][4/18]\tTime 0.074 (0.111)\tData 0.053 (0.088)\tLoss 0.6371 (0.6446)\tAcc 0.625 (0.688)\n",
      "Epoch: [88][5/18]\tTime 0.075 (0.104)\tData 0.054 (0.081)\tLoss 0.8190 (0.6795)\tAcc 0.688 (0.688)\n",
      "Epoch: [88][6/18]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.3049 (0.6170)\tAcc 1.000 (0.740)\n",
      "Epoch: [88][7/18]\tTime 0.074 (0.095)\tData 0.053 (0.073)\tLoss 0.7744 (0.6395)\tAcc 0.688 (0.732)\n",
      "Epoch: [88][8/18]\tTime 0.077 (0.093)\tData 0.056 (0.071)\tLoss 0.9288 (0.6757)\tAcc 0.750 (0.734)\n",
      "Epoch: [88][9/18]\tTime 0.081 (0.092)\tData 0.059 (0.070)\tLoss 0.1378 (0.6159)\tAcc 1.000 (0.764)\n",
      "Epoch: [88][10/18]\tTime 0.080 (0.090)\tData 0.059 (0.069)\tLoss 1.0370 (0.6580)\tAcc 0.750 (0.762)\n",
      "Epoch: [88][11/18]\tTime 0.080 (0.089)\tData 0.059 (0.068)\tLoss 1.3281 (0.7189)\tAcc 0.375 (0.727)\n",
      "Epoch: [88][12/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.8934 (0.7335)\tAcc 0.750 (0.729)\n",
      "Epoch: [88][13/18]\tTime 0.081 (0.088)\tData 0.060 (0.067)\tLoss 1.1116 (0.7626)\tAcc 0.562 (0.716)\n",
      "Epoch: [88][14/18]\tTime 0.079 (0.087)\tData 0.059 (0.066)\tLoss 0.8072 (0.7658)\tAcc 0.625 (0.710)\n",
      "Epoch: [88][15/18]\tTime 0.078 (0.087)\tData 0.058 (0.066)\tLoss 0.8695 (0.7727)\tAcc 0.688 (0.708)\n",
      "Epoch: [88][16/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 0.8113 (0.7751)\tAcc 0.688 (0.707)\n",
      "Epoch: [88][17/18]\tTime 0.075 (0.085)\tData 0.056 (0.064)\tLoss 0.9336 (0.7844)\tAcc 0.625 (0.702)\n",
      "Epoch: [88][18/18]\tTime 0.073 (0.085)\tData 0.055 (0.064)\tLoss 0.8315 (0.7858)\tAcc 0.750 (0.704)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/12]\tTime 0.261 (0.261)\tData 0.231 (0.231)\tLoss 0.7053 (0.7053)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][2/12]\tTime 0.076 (0.168)\tData 0.050 (0.141)\tLoss 0.5142 (0.6098)\tAcc 0.812 (0.750)\n",
      "Epoch: [89][3/12]\tTime 0.078 (0.138)\tData 0.053 (0.111)\tLoss 0.7116 (0.6437)\tAcc 0.688 (0.729)\n",
      "Epoch: [89][4/12]\tTime 0.080 (0.124)\tData 0.054 (0.097)\tLoss 0.7265 (0.6644)\tAcc 0.625 (0.703)\n",
      "Epoch: [89][5/12]\tTime 0.079 (0.115)\tData 0.053 (0.088)\tLoss 1.0220 (0.7359)\tAcc 0.500 (0.663)\n",
      "Epoch: [89][6/12]\tTime 0.084 (0.110)\tData 0.059 (0.083)\tLoss 0.5594 (0.7065)\tAcc 0.812 (0.688)\n",
      "Epoch: [89][7/12]\tTime 0.086 (0.106)\tData 0.062 (0.080)\tLoss 0.4430 (0.6688)\tAcc 0.812 (0.705)\n",
      "Epoch: [89][8/12]\tTime 0.087 (0.104)\tData 0.062 (0.078)\tLoss 0.5423 (0.6530)\tAcc 0.875 (0.727)\n",
      "Epoch: [89][9/12]\tTime 0.087 (0.102)\tData 0.062 (0.076)\tLoss 0.7031 (0.6586)\tAcc 0.750 (0.729)\n",
      "Epoch: [89][10/12]\tTime 0.087 (0.100)\tData 0.061 (0.075)\tLoss 0.4972 (0.6425)\tAcc 0.875 (0.744)\n",
      "Epoch: [89][11/12]\tTime 0.086 (0.099)\tData 0.061 (0.073)\tLoss 0.6422 (0.6424)\tAcc 0.750 (0.744)\n",
      "Epoch: [89][12/12]\tTime 0.086 (0.098)\tData 0.062 (0.072)\tLoss 1.0217 (0.6722)\tAcc 0.533 (0.728)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/18]\tTime 0.225 (0.225)\tData 0.192 (0.192)\tLoss 0.2693 (0.2693)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/18]\tTime 0.070 (0.147)\tData 0.048 (0.120)\tLoss 0.8524 (0.5608)\tAcc 0.688 (0.812)\n",
      "Epoch: [89][3/18]\tTime 0.084 (0.126)\tData 0.058 (0.099)\tLoss 0.6098 (0.5772)\tAcc 0.750 (0.792)\n",
      "Epoch: [89][4/18]\tTime 0.076 (0.114)\tData 0.055 (0.088)\tLoss 0.6004 (0.5830)\tAcc 0.625 (0.750)\n",
      "Epoch: [89][5/18]\tTime 0.081 (0.107)\tData 0.059 (0.082)\tLoss 0.8252 (0.6314)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][6/18]\tTime 0.081 (0.103)\tData 0.059 (0.078)\tLoss 0.2331 (0.5650)\tAcc 1.000 (0.792)\n",
      "Epoch: [89][7/18]\tTime 0.080 (0.100)\tData 0.058 (0.075)\tLoss 0.6519 (0.5774)\tAcc 0.750 (0.786)\n",
      "Epoch: [89][8/18]\tTime 0.081 (0.097)\tData 0.059 (0.073)\tLoss 0.9937 (0.6295)\tAcc 0.625 (0.766)\n",
      "Epoch: [89][9/18]\tTime 0.080 (0.095)\tData 0.058 (0.072)\tLoss 0.0971 (0.5703)\tAcc 1.000 (0.792)\n",
      "Epoch: [89][10/18]\tTime 0.081 (0.094)\tData 0.059 (0.070)\tLoss 1.1299 (0.6263)\tAcc 0.625 (0.775)\n",
      "Epoch: [89][11/18]\tTime 0.079 (0.092)\tData 0.058 (0.069)\tLoss 1.4014 (0.6967)\tAcc 0.375 (0.739)\n",
      "Epoch: [89][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.8556 (0.7100)\tAcc 0.750 (0.740)\n",
      "Epoch: [89][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.2552 (0.7519)\tAcc 0.438 (0.716)\n",
      "Epoch: [89][14/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 0.8452 (0.7586)\tAcc 0.625 (0.710)\n",
      "Epoch: [89][15/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.9380 (0.7705)\tAcc 0.688 (0.708)\n",
      "Epoch: [89][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.6992 (0.7661)\tAcc 0.625 (0.703)\n",
      "Epoch: [89][17/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.8352 (0.7701)\tAcc 0.625 (0.699)\n",
      "Epoch: [89][18/18]\tTime 0.079 (0.088)\tData 0.059 (0.066)\tLoss 0.5739 (0.7645)\tAcc 0.875 (0.704)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/12]\tTime 0.221 (0.221)\tData 0.186 (0.186)\tLoss 0.7384 (0.7384)\tAcc 0.750 (0.750)\n",
      "Epoch: [90][2/12]\tTime 0.070 (0.146)\tData 0.044 (0.115)\tLoss 0.5748 (0.6566)\tAcc 0.812 (0.781)\n",
      "Epoch: [90][3/12]\tTime 0.077 (0.123)\tData 0.052 (0.094)\tLoss 1.1582 (0.8238)\tAcc 0.562 (0.708)\n",
      "Epoch: [90][4/12]\tTime 0.080 (0.112)\tData 0.054 (0.084)\tLoss 0.5993 (0.7677)\tAcc 0.625 (0.688)\n",
      "Epoch: [90][5/12]\tTime 0.085 (0.107)\tData 0.060 (0.079)\tLoss 0.4924 (0.7126)\tAcc 0.812 (0.713)\n",
      "Epoch: [90][6/12]\tTime 0.086 (0.103)\tData 0.061 (0.076)\tLoss 0.6576 (0.7035)\tAcc 0.688 (0.708)\n",
      "Epoch: [90][7/12]\tTime 0.087 (0.101)\tData 0.062 (0.074)\tLoss 0.6492 (0.6957)\tAcc 0.812 (0.723)\n",
      "Epoch: [90][8/12]\tTime 0.086 (0.099)\tData 0.062 (0.073)\tLoss 0.7667 (0.7046)\tAcc 0.688 (0.719)\n",
      "Epoch: [90][9/12]\tTime 0.086 (0.098)\tData 0.062 (0.071)\tLoss 0.5579 (0.6883)\tAcc 0.688 (0.715)\n",
      "Epoch: [90][10/12]\tTime 0.086 (0.096)\tData 0.062 (0.070)\tLoss 0.4382 (0.6633)\tAcc 0.875 (0.731)\n",
      "Epoch: [90][11/12]\tTime 0.081 (0.095)\tData 0.058 (0.069)\tLoss 0.6813 (0.6649)\tAcc 0.688 (0.727)\n",
      "Epoch: [90][12/12]\tTime 0.078 (0.094)\tData 0.055 (0.068)\tLoss 0.5572 (0.6565)\tAcc 0.800 (0.733)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/18]\tTime 0.215 (0.215)\tData 0.185 (0.185)\tLoss 0.3098 (0.3098)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/18]\tTime 0.067 (0.141)\tData 0.046 (0.115)\tLoss 0.8957 (0.6028)\tAcc 0.562 (0.750)\n",
      "Epoch: [90][3/18]\tTime 0.078 (0.120)\tData 0.057 (0.096)\tLoss 0.5762 (0.5939)\tAcc 0.750 (0.750)\n",
      "Epoch: [90][4/18]\tTime 0.081 (0.110)\tData 0.059 (0.087)\tLoss 0.5827 (0.5911)\tAcc 0.688 (0.734)\n",
      "Epoch: [90][5/18]\tTime 0.081 (0.104)\tData 0.059 (0.081)\tLoss 0.7926 (0.6314)\tAcc 0.750 (0.738)\n",
      "Epoch: [90][6/18]\tTime 0.081 (0.101)\tData 0.058 (0.077)\tLoss 0.3272 (0.5807)\tAcc 0.938 (0.771)\n",
      "Epoch: [90][7/18]\tTime 0.079 (0.097)\tData 0.058 (0.075)\tLoss 0.6096 (0.5849)\tAcc 0.750 (0.768)\n",
      "Epoch: [90][8/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 0.9510 (0.6306)\tAcc 0.562 (0.742)\n",
      "Epoch: [90][9/18]\tTime 0.080 (0.094)\tData 0.059 (0.071)\tLoss 0.1435 (0.5765)\tAcc 1.000 (0.771)\n",
      "Epoch: [90][10/18]\tTime 0.078 (0.092)\tData 0.058 (0.070)\tLoss 1.1464 (0.6335)\tAcc 0.750 (0.769)\n",
      "Epoch: [90][11/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 1.1433 (0.6798)\tAcc 0.375 (0.733)\n",
      "Epoch: [90][12/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.8455 (0.6936)\tAcc 0.812 (0.740)\n",
      "Epoch: [90][13/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 1.2195 (0.7341)\tAcc 0.438 (0.716)\n",
      "Epoch: [90][14/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.9000 (0.7459)\tAcc 0.625 (0.710)\n",
      "Epoch: [90][15/18]\tTime 0.081 (0.088)\tData 0.060 (0.067)\tLoss 0.8317 (0.7517)\tAcc 0.750 (0.713)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [90][16/18]\tTime 0.079 (0.088)\tData 0.059 (0.066)\tLoss 0.7878 (0.7539)\tAcc 0.688 (0.711)\n",
      "Epoch: [90][17/18]\tTime 0.081 (0.087)\tData 0.061 (0.066)\tLoss 0.6848 (0.7498)\tAcc 0.625 (0.706)\n",
      "Epoch: [90][18/18]\tTime 0.079 (0.087)\tData 0.060 (0.066)\tLoss 0.7277 (0.7492)\tAcc 0.875 (0.711)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/12]\tTime 0.242 (0.242)\tData 0.203 (0.203)\tLoss 0.8779 (0.8779)\tAcc 0.625 (0.625)\n",
      "Epoch: [91][2/12]\tTime 0.076 (0.159)\tData 0.048 (0.125)\tLoss 0.4190 (0.6484)\tAcc 0.938 (0.781)\n",
      "Epoch: [91][3/12]\tTime 0.087 (0.135)\tData 0.060 (0.104)\tLoss 0.5215 (0.6061)\tAcc 0.875 (0.812)\n",
      "Epoch: [91][4/12]\tTime 0.086 (0.123)\tData 0.061 (0.093)\tLoss 0.6178 (0.6090)\tAcc 0.688 (0.781)\n",
      "Epoch: [91][5/12]\tTime 0.087 (0.116)\tData 0.061 (0.086)\tLoss 0.4936 (0.5860)\tAcc 0.750 (0.775)\n",
      "Epoch: [91][6/12]\tTime 0.086 (0.111)\tData 0.060 (0.082)\tLoss 0.8552 (0.6308)\tAcc 0.688 (0.760)\n",
      "Epoch: [91][7/12]\tTime 0.085 (0.107)\tData 0.060 (0.079)\tLoss 0.8112 (0.6566)\tAcc 0.625 (0.741)\n",
      "Epoch: [91][8/12]\tTime 0.086 (0.104)\tData 0.061 (0.077)\tLoss 0.6068 (0.6504)\tAcc 0.812 (0.750)\n",
      "Epoch: [91][9/12]\tTime 0.084 (0.102)\tData 0.059 (0.075)\tLoss 0.9318 (0.6816)\tAcc 0.625 (0.736)\n",
      "Epoch: [91][10/12]\tTime 0.078 (0.100)\tData 0.054 (0.073)\tLoss 1.0192 (0.7154)\tAcc 0.562 (0.719)\n",
      "Epoch: [91][11/12]\tTime 0.086 (0.098)\tData 0.061 (0.072)\tLoss 0.9217 (0.7342)\tAcc 0.688 (0.716)\n",
      "Epoch: [91][12/12]\tTime 0.087 (0.097)\tData 0.062 (0.071)\tLoss 0.5961 (0.7233)\tAcc 0.733 (0.717)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/18]\tTime 0.228 (0.228)\tData 0.203 (0.203)\tLoss 0.3835 (0.3835)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/18]\tTime 0.077 (0.152)\tData 0.051 (0.127)\tLoss 0.8744 (0.6289)\tAcc 0.562 (0.750)\n",
      "Epoch: [91][3/18]\tTime 0.068 (0.124)\tData 0.048 (0.101)\tLoss 0.6124 (0.6234)\tAcc 0.812 (0.771)\n",
      "Epoch: [91][4/18]\tTime 0.076 (0.112)\tData 0.055 (0.089)\tLoss 0.6259 (0.6240)\tAcc 0.750 (0.766)\n",
      "Epoch: [91][5/18]\tTime 0.083 (0.106)\tData 0.060 (0.083)\tLoss 0.7661 (0.6524)\tAcc 0.625 (0.738)\n",
      "Epoch: [91][6/18]\tTime 0.080 (0.102)\tData 0.059 (0.079)\tLoss 0.3144 (0.5961)\tAcc 1.000 (0.781)\n",
      "Epoch: [91][7/18]\tTime 0.080 (0.099)\tData 0.059 (0.076)\tLoss 0.7087 (0.6122)\tAcc 0.750 (0.777)\n",
      "Epoch: [91][8/18]\tTime 0.081 (0.096)\tData 0.059 (0.074)\tLoss 0.9745 (0.6575)\tAcc 0.625 (0.758)\n",
      "Epoch: [91][9/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 0.1416 (0.6002)\tAcc 1.000 (0.785)\n",
      "Epoch: [91][10/18]\tTime 0.080 (0.093)\tData 0.059 (0.071)\tLoss 1.0713 (0.6473)\tAcc 0.688 (0.775)\n",
      "Epoch: [91][11/18]\tTime 0.080 (0.092)\tData 0.059 (0.070)\tLoss 1.4596 (0.7211)\tAcc 0.375 (0.739)\n",
      "Epoch: [91][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.8772 (0.7341)\tAcc 0.812 (0.745)\n",
      "Epoch: [91][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.069)\tLoss 0.9712 (0.7524)\tAcc 0.562 (0.731)\n",
      "Epoch: [91][14/18]\tTime 0.081 (0.089)\tData 0.060 (0.068)\tLoss 0.8587 (0.7600)\tAcc 0.625 (0.723)\n",
      "Epoch: [91][15/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.8030 (0.7628)\tAcc 0.750 (0.725)\n",
      "Epoch: [91][16/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.9400 (0.7739)\tAcc 0.688 (0.723)\n",
      "Epoch: [91][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.8079 (0.7759)\tAcc 0.625 (0.717)\n",
      "Epoch: [91][18/18]\tTime 0.079 (0.087)\tData 0.060 (0.066)\tLoss 0.7121 (0.7741)\tAcc 0.625 (0.714)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/12]\tTime 0.226 (0.226)\tData 0.190 (0.190)\tLoss 0.7921 (0.7921)\tAcc 0.625 (0.625)\n",
      "Epoch: [92][2/12]\tTime 0.087 (0.157)\tData 0.044 (0.117)\tLoss 0.7541 (0.7731)\tAcc 0.688 (0.656)\n",
      "Epoch: [92][3/12]\tTime 0.070 (0.128)\tData 0.043 (0.092)\tLoss 0.7385 (0.7616)\tAcc 0.750 (0.688)\n",
      "Epoch: [92][4/12]\tTime 0.087 (0.117)\tData 0.061 (0.084)\tLoss 0.5653 (0.7125)\tAcc 0.875 (0.734)\n",
      "Epoch: [92][5/12]\tTime 0.087 (0.111)\tData 0.060 (0.079)\tLoss 0.5702 (0.6841)\tAcc 0.750 (0.738)\n",
      "Epoch: [92][6/12]\tTime 0.086 (0.107)\tData 0.061 (0.076)\tLoss 0.7014 (0.6869)\tAcc 0.750 (0.740)\n",
      "Epoch: [92][7/12]\tTime 0.083 (0.103)\tData 0.058 (0.074)\tLoss 0.8598 (0.7116)\tAcc 0.562 (0.714)\n",
      "Epoch: [92][8/12]\tTime 0.086 (0.101)\tData 0.061 (0.072)\tLoss 0.7896 (0.7214)\tAcc 0.562 (0.695)\n",
      "Epoch: [92][9/12]\tTime 0.087 (0.100)\tData 0.062 (0.071)\tLoss 0.6418 (0.7125)\tAcc 0.750 (0.701)\n",
      "Epoch: [92][10/12]\tTime 0.086 (0.098)\tData 0.061 (0.070)\tLoss 0.7929 (0.7206)\tAcc 0.625 (0.694)\n",
      "Epoch: [92][11/12]\tTime 0.086 (0.097)\tData 0.062 (0.069)\tLoss 0.7666 (0.7248)\tAcc 0.750 (0.699)\n",
      "Epoch: [92][12/12]\tTime 0.087 (0.096)\tData 0.062 (0.069)\tLoss 0.4826 (0.7057)\tAcc 0.867 (0.712)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/18]\tTime 0.222 (0.222)\tData 0.194 (0.194)\tLoss 0.3236 (0.3236)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/18]\tTime 0.092 (0.157)\tData 0.055 (0.124)\tLoss 0.8385 (0.5810)\tAcc 0.438 (0.688)\n",
      "Epoch: [92][3/18]\tTime 0.064 (0.126)\tData 0.042 (0.097)\tLoss 0.6167 (0.5929)\tAcc 0.750 (0.708)\n",
      "Epoch: [92][4/18]\tTime 0.082 (0.115)\tData 0.060 (0.088)\tLoss 0.5326 (0.5778)\tAcc 0.750 (0.719)\n",
      "Epoch: [92][5/18]\tTime 0.082 (0.108)\tData 0.060 (0.082)\tLoss 0.7797 (0.6182)\tAcc 0.625 (0.700)\n",
      "Epoch: [92][6/18]\tTime 0.081 (0.104)\tData 0.059 (0.078)\tLoss 0.2806 (0.5620)\tAcc 0.938 (0.740)\n",
      "Epoch: [92][7/18]\tTime 0.080 (0.100)\tData 0.059 (0.075)\tLoss 0.6970 (0.5812)\tAcc 0.688 (0.732)\n",
      "Epoch: [92][8/18]\tTime 0.076 (0.097)\tData 0.056 (0.073)\tLoss 0.9508 (0.6274)\tAcc 0.688 (0.727)\n",
      "Epoch: [92][9/18]\tTime 0.075 (0.095)\tData 0.054 (0.071)\tLoss 0.1093 (0.5699)\tAcc 1.000 (0.757)\n",
      "Epoch: [92][10/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 1.0743 (0.6203)\tAcc 0.625 (0.744)\n",
      "Epoch: [92][11/18]\tTime 0.080 (0.092)\tData 0.060 (0.069)\tLoss 1.0907 (0.6631)\tAcc 0.375 (0.710)\n",
      "Epoch: [92][12/18]\tTime 0.081 (0.091)\tData 0.060 (0.068)\tLoss 0.9616 (0.6879)\tAcc 0.812 (0.719)\n",
      "Epoch: [92][13/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 1.1411 (0.7228)\tAcc 0.500 (0.702)\n",
      "Epoch: [92][14/18]\tTime 0.079 (0.089)\tData 0.058 (0.067)\tLoss 0.7241 (0.7229)\tAcc 0.625 (0.696)\n",
      "Epoch: [92][15/18]\tTime 0.080 (0.089)\tData 0.059 (0.066)\tLoss 0.8827 (0.7336)\tAcc 0.688 (0.696)\n",
      "Epoch: [92][16/18]\tTime 0.080 (0.088)\tData 0.059 (0.066)\tLoss 0.7411 (0.7340)\tAcc 0.688 (0.695)\n",
      "Epoch: [92][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.065)\tLoss 0.7451 (0.7347)\tAcc 0.625 (0.691)\n",
      "Epoch: [92][18/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.8726 (0.7386)\tAcc 0.750 (0.693)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/12]\tTime 0.249 (0.249)\tData 0.218 (0.218)\tLoss 0.8259 (0.8259)\tAcc 0.625 (0.625)\n",
      "Epoch: [93][2/12]\tTime 0.086 (0.167)\tData 0.058 (0.138)\tLoss 0.6248 (0.7254)\tAcc 0.750 (0.688)\n",
      "Epoch: [93][3/12]\tTime 0.079 (0.138)\tData 0.053 (0.110)\tLoss 0.6488 (0.6999)\tAcc 0.750 (0.708)\n",
      "Epoch: [93][4/12]\tTime 0.077 (0.123)\tData 0.052 (0.095)\tLoss 0.3277 (0.6068)\tAcc 0.875 (0.750)\n",
      "Epoch: [93][5/12]\tTime 0.080 (0.114)\tData 0.054 (0.087)\tLoss 0.8013 (0.6457)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][6/12]\tTime 0.083 (0.109)\tData 0.059 (0.082)\tLoss 0.5700 (0.6331)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][7/12]\tTime 0.086 (0.106)\tData 0.062 (0.079)\tLoss 0.9861 (0.6835)\tAcc 0.625 (0.732)\n",
      "Epoch: [93][8/12]\tTime 0.086 (0.103)\tData 0.062 (0.077)\tLoss 0.8450 (0.7037)\tAcc 0.750 (0.734)\n",
      "Epoch: [93][9/12]\tTime 0.086 (0.101)\tData 0.062 (0.076)\tLoss 0.5886 (0.6909)\tAcc 0.688 (0.729)\n",
      "Epoch: [93][10/12]\tTime 0.087 (0.100)\tData 0.062 (0.074)\tLoss 0.9292 (0.7148)\tAcc 0.562 (0.713)\n",
      "Epoch: [93][11/12]\tTime 0.085 (0.099)\tData 0.061 (0.073)\tLoss 0.4774 (0.6932)\tAcc 0.812 (0.722)\n",
      "Epoch: [93][12/12]\tTime 0.087 (0.098)\tData 0.062 (0.072)\tLoss 0.3505 (0.6663)\tAcc 0.933 (0.738)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/18]\tTime 0.222 (0.222)\tData 0.189 (0.189)\tLoss 0.2779 (0.2779)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/18]\tTime 0.078 (0.150)\tData 0.049 (0.119)\tLoss 0.8352 (0.5565)\tAcc 0.688 (0.812)\n",
      "Epoch: [93][3/18]\tTime 0.068 (0.123)\tData 0.047 (0.095)\tLoss 0.5467 (0.5532)\tAcc 0.875 (0.833)\n",
      "Epoch: [93][4/18]\tTime 0.074 (0.111)\tData 0.054 (0.085)\tLoss 0.5907 (0.5626)\tAcc 0.750 (0.812)\n",
      "Epoch: [93][5/18]\tTime 0.074 (0.103)\tData 0.054 (0.078)\tLoss 0.9096 (0.6320)\tAcc 0.688 (0.788)\n",
      "Epoch: [93][6/18]\tTime 0.076 (0.099)\tData 0.055 (0.075)\tLoss 0.2804 (0.5734)\tAcc 1.000 (0.823)\n",
      "Epoch: [93][7/18]\tTime 0.075 (0.095)\tData 0.055 (0.072)\tLoss 0.6435 (0.5834)\tAcc 0.688 (0.804)\n",
      "Epoch: [93][8/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.8815 (0.6207)\tAcc 0.750 (0.797)\n",
      "Epoch: [93][9/18]\tTime 0.081 (0.092)\tData 0.060 (0.069)\tLoss 0.1429 (0.5676)\tAcc 1.000 (0.819)\n",
      "Epoch: [93][10/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.1057 (0.6214)\tAcc 0.750 (0.812)\n",
      "Epoch: [93][11/18]\tTime 0.081 (0.090)\tData 0.060 (0.067)\tLoss 1.3494 (0.6876)\tAcc 0.438 (0.778)\n",
      "Epoch: [93][12/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.8821 (0.7038)\tAcc 0.812 (0.781)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [93][13/18]\tTime 0.080 (0.088)\tData 0.061 (0.066)\tLoss 1.0226 (0.7283)\tAcc 0.688 (0.774)\n",
      "Epoch: [93][14/18]\tTime 0.077 (0.088)\tData 0.057 (0.066)\tLoss 0.8251 (0.7352)\tAcc 0.625 (0.763)\n",
      "Epoch: [93][15/18]\tTime 0.075 (0.087)\tData 0.055 (0.065)\tLoss 0.8495 (0.7428)\tAcc 0.750 (0.763)\n",
      "Epoch: [93][16/18]\tTime 0.073 (0.086)\tData 0.054 (0.064)\tLoss 0.8811 (0.7515)\tAcc 0.688 (0.758)\n",
      "Epoch: [93][17/18]\tTime 0.074 (0.085)\tData 0.054 (0.064)\tLoss 0.7768 (0.7530)\tAcc 0.688 (0.754)\n",
      "Epoch: [93][18/18]\tTime 0.079 (0.085)\tData 0.060 (0.063)\tLoss 0.6511 (0.7501)\tAcc 0.750 (0.754)\n",
      "train at epoch 94\n",
      "Epoch: [94][1/12]\tTime 0.241 (0.241)\tData 0.207 (0.207)\tLoss 1.1850 (1.1850)\tAcc 0.500 (0.500)\n",
      "Epoch: [94][2/12]\tTime 0.088 (0.165)\tData 0.055 (0.131)\tLoss 0.6201 (0.9026)\tAcc 0.812 (0.656)\n",
      "Epoch: [94][3/12]\tTime 0.081 (0.137)\tData 0.054 (0.105)\tLoss 0.5800 (0.7950)\tAcc 0.750 (0.688)\n",
      "Epoch: [94][4/12]\tTime 0.086 (0.124)\tData 0.060 (0.094)\tLoss 0.9961 (0.8453)\tAcc 0.625 (0.672)\n",
      "Epoch: [94][5/12]\tTime 0.086 (0.116)\tData 0.060 (0.087)\tLoss 0.6944 (0.8151)\tAcc 0.688 (0.675)\n",
      "Epoch: [94][6/12]\tTime 0.084 (0.111)\tData 0.060 (0.083)\tLoss 0.4336 (0.7515)\tAcc 0.875 (0.708)\n",
      "Epoch: [94][7/12]\tTime 0.086 (0.107)\tData 0.061 (0.080)\tLoss 0.3850 (0.6992)\tAcc 0.812 (0.723)\n",
      "Epoch: [94][8/12]\tTime 0.086 (0.105)\tData 0.062 (0.077)\tLoss 0.5589 (0.6816)\tAcc 0.875 (0.742)\n",
      "Epoch: [94][9/12]\tTime 0.083 (0.102)\tData 0.058 (0.075)\tLoss 0.4777 (0.6590)\tAcc 0.812 (0.750)\n",
      "Epoch: [94][10/12]\tTime 0.086 (0.101)\tData 0.061 (0.074)\tLoss 0.7695 (0.6700)\tAcc 0.750 (0.750)\n",
      "Epoch: [94][11/12]\tTime 0.087 (0.099)\tData 0.062 (0.073)\tLoss 0.4725 (0.6521)\tAcc 0.875 (0.761)\n",
      "Epoch: [94][12/12]\tTime 0.086 (0.098)\tData 0.062 (0.072)\tLoss 0.7381 (0.6588)\tAcc 0.800 (0.764)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/18]\tTime 0.228 (0.228)\tData 0.201 (0.201)\tLoss 0.2695 (0.2695)\tAcc 1.000 (1.000)\n",
      "Epoch: [94][2/18]\tTime 0.082 (0.155)\tData 0.054 (0.127)\tLoss 0.8291 (0.5493)\tAcc 0.625 (0.812)\n",
      "Epoch: [94][3/18]\tTime 0.073 (0.128)\tData 0.052 (0.102)\tLoss 0.5861 (0.5616)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][4/18]\tTime 0.081 (0.116)\tData 0.060 (0.092)\tLoss 0.6072 (0.5730)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][5/18]\tTime 0.081 (0.109)\tData 0.059 (0.085)\tLoss 0.7970 (0.6178)\tAcc 0.688 (0.788)\n",
      "Epoch: [94][6/18]\tTime 0.076 (0.104)\tData 0.056 (0.080)\tLoss 0.2899 (0.5632)\tAcc 1.000 (0.823)\n",
      "Epoch: [94][7/18]\tTime 0.081 (0.100)\tData 0.059 (0.077)\tLoss 0.6985 (0.5825)\tAcc 0.688 (0.804)\n",
      "Epoch: [94][8/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 0.8504 (0.6160)\tAcc 0.688 (0.789)\n",
      "Epoch: [94][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.073)\tLoss 0.1398 (0.5631)\tAcc 1.000 (0.812)\n",
      "Epoch: [94][10/18]\tTime 0.082 (0.094)\tData 0.060 (0.072)\tLoss 0.9460 (0.6014)\tAcc 0.750 (0.806)\n",
      "Epoch: [94][11/18]\tTime 0.078 (0.093)\tData 0.058 (0.071)\tLoss 1.3652 (0.6708)\tAcc 0.375 (0.767)\n",
      "Epoch: [94][12/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.9556 (0.6945)\tAcc 0.750 (0.766)\n",
      "Epoch: [94][13/18]\tTime 0.078 (0.091)\tData 0.058 (0.069)\tLoss 0.9851 (0.7169)\tAcc 0.750 (0.764)\n",
      "Epoch: [94][14/18]\tTime 0.081 (0.090)\tData 0.060 (0.068)\tLoss 0.8595 (0.7271)\tAcc 0.562 (0.750)\n",
      "Epoch: [94][15/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.8467 (0.7350)\tAcc 0.750 (0.750)\n",
      "Epoch: [94][16/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.8842 (0.7444)\tAcc 0.688 (0.746)\n",
      "Epoch: [94][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.7620 (0.7454)\tAcc 0.625 (0.739)\n",
      "Epoch: [94][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.6527 (0.7428)\tAcc 0.875 (0.743)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/12]\tTime 0.238 (0.238)\tData 0.206 (0.206)\tLoss 0.9531 (0.9531)\tAcc 0.688 (0.688)\n",
      "Epoch: [95][2/12]\tTime 0.087 (0.162)\tData 0.057 (0.132)\tLoss 0.7963 (0.8747)\tAcc 0.750 (0.719)\n",
      "Epoch: [95][3/12]\tTime 0.080 (0.135)\tData 0.053 (0.105)\tLoss 0.6510 (0.8001)\tAcc 0.812 (0.750)\n",
      "Epoch: [95][4/12]\tTime 0.086 (0.123)\tData 0.060 (0.094)\tLoss 0.6152 (0.7539)\tAcc 0.688 (0.734)\n",
      "Epoch: [95][5/12]\tTime 0.087 (0.115)\tData 0.060 (0.087)\tLoss 0.8949 (0.7821)\tAcc 0.625 (0.713)\n",
      "Epoch: [95][6/12]\tTime 0.085 (0.110)\tData 0.060 (0.083)\tLoss 0.6419 (0.7587)\tAcc 0.688 (0.708)\n",
      "Epoch: [95][7/12]\tTime 0.087 (0.107)\tData 0.062 (0.080)\tLoss 0.5293 (0.7260)\tAcc 0.750 (0.714)\n",
      "Epoch: [95][8/12]\tTime 0.086 (0.104)\tData 0.061 (0.077)\tLoss 0.5983 (0.7100)\tAcc 0.750 (0.719)\n",
      "Epoch: [95][9/12]\tTime 0.083 (0.102)\tData 0.059 (0.075)\tLoss 0.5105 (0.6878)\tAcc 0.812 (0.729)\n",
      "Epoch: [95][10/12]\tTime 0.086 (0.100)\tData 0.062 (0.074)\tLoss 0.5626 (0.6753)\tAcc 0.812 (0.738)\n",
      "Epoch: [95][11/12]\tTime 0.086 (0.099)\tData 0.062 (0.073)\tLoss 0.8498 (0.6912)\tAcc 0.625 (0.727)\n",
      "Epoch: [95][12/12]\tTime 0.087 (0.098)\tData 0.062 (0.072)\tLoss 0.3813 (0.6668)\tAcc 0.867 (0.738)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/18]\tTime 0.229 (0.229)\tData 0.199 (0.199)\tLoss 0.3910 (0.3910)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/18]\tTime 0.078 (0.153)\tData 0.051 (0.125)\tLoss 0.8135 (0.6023)\tAcc 0.562 (0.750)\n",
      "Epoch: [95][3/18]\tTime 0.077 (0.128)\tData 0.054 (0.101)\tLoss 0.5346 (0.5797)\tAcc 0.812 (0.771)\n",
      "Epoch: [95][4/18]\tTime 0.081 (0.116)\tData 0.059 (0.091)\tLoss 0.5864 (0.5814)\tAcc 0.688 (0.750)\n",
      "Epoch: [95][5/18]\tTime 0.078 (0.109)\tData 0.057 (0.084)\tLoss 0.7436 (0.6138)\tAcc 0.812 (0.762)\n",
      "Epoch: [95][6/18]\tTime 0.082 (0.104)\tData 0.059 (0.080)\tLoss 0.2616 (0.5551)\tAcc 1.000 (0.802)\n",
      "Epoch: [95][7/18]\tTime 0.080 (0.101)\tData 0.059 (0.077)\tLoss 0.6415 (0.5675)\tAcc 0.688 (0.786)\n",
      "Epoch: [95][8/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 1.1108 (0.6354)\tAcc 0.562 (0.758)\n",
      "Epoch: [95][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.073)\tLoss 0.1436 (0.5807)\tAcc 1.000 (0.785)\n",
      "Epoch: [95][10/18]\tTime 0.075 (0.094)\tData 0.054 (0.071)\tLoss 1.0151 (0.6242)\tAcc 0.750 (0.781)\n",
      "Epoch: [95][11/18]\tTime 0.078 (0.092)\tData 0.057 (0.070)\tLoss 1.1787 (0.6746)\tAcc 0.375 (0.744)\n",
      "Epoch: [95][12/18]\tTime 0.081 (0.092)\tData 0.060 (0.069)\tLoss 0.8551 (0.6896)\tAcc 0.750 (0.745)\n",
      "Epoch: [95][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.0465 (0.7171)\tAcc 0.562 (0.731)\n",
      "Epoch: [95][14/18]\tTime 0.081 (0.090)\tData 0.060 (0.068)\tLoss 0.8109 (0.7238)\tAcc 0.562 (0.719)\n",
      "Epoch: [95][15/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.7494 (0.7255)\tAcc 0.688 (0.717)\n",
      "Epoch: [95][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 1.0485 (0.7457)\tAcc 0.500 (0.703)\n",
      "Epoch: [95][17/18]\tTime 0.078 (0.088)\tData 0.058 (0.066)\tLoss 0.8161 (0.7498)\tAcc 0.625 (0.699)\n",
      "Epoch: [95][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.7430 (0.7496)\tAcc 0.750 (0.700)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/12]\tTime 0.227 (0.227)\tData 0.196 (0.196)\tLoss 0.6024 (0.6024)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][2/12]\tTime 0.090 (0.159)\tData 0.053 (0.124)\tLoss 0.5914 (0.5969)\tAcc 0.812 (0.750)\n",
      "Epoch: [96][3/12]\tTime 0.074 (0.130)\tData 0.048 (0.099)\tLoss 0.4624 (0.5521)\tAcc 0.875 (0.792)\n",
      "Epoch: [96][4/12]\tTime 0.087 (0.120)\tData 0.061 (0.089)\tLoss 0.8630 (0.6298)\tAcc 0.625 (0.750)\n",
      "Epoch: [96][5/12]\tTime 0.086 (0.113)\tData 0.061 (0.084)\tLoss 0.4953 (0.6029)\tAcc 0.750 (0.750)\n",
      "Epoch: [96][6/12]\tTime 0.085 (0.108)\tData 0.061 (0.080)\tLoss 0.6945 (0.6182)\tAcc 0.688 (0.740)\n",
      "Epoch: [96][7/12]\tTime 0.079 (0.104)\tData 0.056 (0.076)\tLoss 0.2982 (0.5725)\tAcc 1.000 (0.777)\n",
      "Epoch: [96][8/12]\tTime 0.082 (0.101)\tData 0.058 (0.074)\tLoss 0.9640 (0.6214)\tAcc 0.625 (0.758)\n",
      "Epoch: [96][9/12]\tTime 0.087 (0.100)\tData 0.062 (0.073)\tLoss 0.7099 (0.6312)\tAcc 0.812 (0.764)\n",
      "Epoch: [96][10/12]\tTime 0.086 (0.098)\tData 0.062 (0.072)\tLoss 0.4356 (0.6117)\tAcc 0.875 (0.775)\n",
      "Epoch: [96][11/12]\tTime 0.087 (0.097)\tData 0.062 (0.071)\tLoss 0.8040 (0.6291)\tAcc 0.688 (0.767)\n",
      "Epoch: [96][12/12]\tTime 0.087 (0.096)\tData 0.062 (0.070)\tLoss 0.8109 (0.6434)\tAcc 0.533 (0.749)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/18]\tTime 0.226 (0.226)\tData 0.188 (0.188)\tLoss 0.2535 (0.2535)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/18]\tTime 0.065 (0.146)\tData 0.043 (0.115)\tLoss 0.8605 (0.5570)\tAcc 0.562 (0.750)\n",
      "Epoch: [96][3/18]\tTime 0.080 (0.124)\tData 0.058 (0.096)\tLoss 0.6208 (0.5783)\tAcc 0.688 (0.729)\n",
      "Epoch: [96][4/18]\tTime 0.083 (0.113)\tData 0.060 (0.087)\tLoss 0.5115 (0.5616)\tAcc 0.750 (0.734)\n",
      "Epoch: [96][5/18]\tTime 0.081 (0.107)\tData 0.058 (0.081)\tLoss 0.8444 (0.6181)\tAcc 0.812 (0.750)\n",
      "Epoch: [96][6/18]\tTime 0.073 (0.101)\tData 0.053 (0.077)\tLoss 0.2770 (0.5613)\tAcc 1.000 (0.792)\n",
      "Epoch: [96][7/18]\tTime 0.081 (0.098)\tData 0.059 (0.074)\tLoss 0.6248 (0.5704)\tAcc 0.688 (0.777)\n",
      "Epoch: [96][8/18]\tTime 0.082 (0.096)\tData 0.059 (0.072)\tLoss 1.0003 (0.6241)\tAcc 0.688 (0.766)\n",
      "Epoch: [96][9/18]\tTime 0.081 (0.095)\tData 0.059 (0.071)\tLoss 0.1216 (0.5683)\tAcc 1.000 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [96][10/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 1.1259 (0.6240)\tAcc 0.625 (0.775)\n",
      "Epoch: [96][11/18]\tTime 0.080 (0.092)\tData 0.059 (0.069)\tLoss 1.2818 (0.6838)\tAcc 0.375 (0.739)\n",
      "Epoch: [96][12/18]\tTime 0.076 (0.091)\tData 0.056 (0.068)\tLoss 0.9518 (0.7062)\tAcc 0.812 (0.745)\n",
      "Epoch: [96][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 1.1732 (0.7421)\tAcc 0.438 (0.721)\n",
      "Epoch: [96][14/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.7728 (0.7443)\tAcc 0.562 (0.710)\n",
      "Epoch: [96][15/18]\tTime 0.081 (0.089)\tData 0.060 (0.066)\tLoss 0.7812 (0.7468)\tAcc 0.750 (0.713)\n",
      "Epoch: [96][16/18]\tTime 0.081 (0.088)\tData 0.060 (0.066)\tLoss 0.7788 (0.7488)\tAcc 0.688 (0.711)\n",
      "Epoch: [96][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.065)\tLoss 0.8182 (0.7528)\tAcc 0.688 (0.710)\n",
      "Epoch: [96][18/18]\tTime 0.074 (0.087)\tData 0.054 (0.065)\tLoss 0.6358 (0.7495)\tAcc 0.875 (0.714)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/12]\tTime 0.248 (0.248)\tData 0.215 (0.215)\tLoss 0.5061 (0.5061)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][2/12]\tTime 0.088 (0.168)\tData 0.054 (0.135)\tLoss 0.6143 (0.5602)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][3/12]\tTime 0.082 (0.139)\tData 0.054 (0.108)\tLoss 0.6106 (0.5770)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][4/12]\tTime 0.077 (0.124)\tData 0.051 (0.094)\tLoss 0.7060 (0.6093)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][5/12]\tTime 0.085 (0.116)\tData 0.059 (0.087)\tLoss 0.6488 (0.6172)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][6/12]\tTime 0.086 (0.111)\tData 0.061 (0.082)\tLoss 0.4094 (0.5825)\tAcc 0.875 (0.771)\n",
      "Epoch: [97][7/12]\tTime 0.086 (0.107)\tData 0.061 (0.079)\tLoss 0.6892 (0.5978)\tAcc 0.688 (0.759)\n",
      "Epoch: [97][8/12]\tTime 0.087 (0.105)\tData 0.062 (0.077)\tLoss 0.7425 (0.6159)\tAcc 0.688 (0.750)\n",
      "Epoch: [97][9/12]\tTime 0.086 (0.103)\tData 0.061 (0.075)\tLoss 0.5830 (0.6122)\tAcc 0.812 (0.757)\n",
      "Epoch: [97][10/12]\tTime 0.082 (0.101)\tData 0.058 (0.074)\tLoss 0.8951 (0.6405)\tAcc 0.625 (0.744)\n",
      "Epoch: [97][11/12]\tTime 0.086 (0.099)\tData 0.062 (0.073)\tLoss 0.7968 (0.6547)\tAcc 0.750 (0.744)\n",
      "Epoch: [97][12/12]\tTime 0.087 (0.098)\tData 0.062 (0.072)\tLoss 0.8182 (0.6676)\tAcc 0.733 (0.743)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/18]\tTime 0.233 (0.233)\tData 0.190 (0.190)\tLoss 0.2500 (0.2500)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/18]\tTime 0.069 (0.151)\tData 0.038 (0.114)\tLoss 0.8139 (0.5320)\tAcc 0.625 (0.781)\n",
      "Epoch: [97][3/18]\tTime 0.073 (0.125)\tData 0.051 (0.093)\tLoss 0.5852 (0.5497)\tAcc 0.750 (0.771)\n",
      "Epoch: [97][4/18]\tTime 0.080 (0.114)\tData 0.059 (0.085)\tLoss 0.5541 (0.5508)\tAcc 0.750 (0.766)\n",
      "Epoch: [97][5/18]\tTime 0.079 (0.107)\tData 0.058 (0.079)\tLoss 0.7620 (0.5930)\tAcc 0.812 (0.775)\n",
      "Epoch: [97][6/18]\tTime 0.075 (0.101)\tData 0.055 (0.075)\tLoss 0.2915 (0.5428)\tAcc 1.000 (0.812)\n",
      "Epoch: [97][7/18]\tTime 0.075 (0.098)\tData 0.054 (0.072)\tLoss 0.7157 (0.5675)\tAcc 0.688 (0.795)\n",
      "Epoch: [97][8/18]\tTime 0.081 (0.095)\tData 0.059 (0.071)\tLoss 0.9348 (0.6134)\tAcc 0.688 (0.781)\n",
      "Epoch: [97][9/18]\tTime 0.080 (0.094)\tData 0.059 (0.069)\tLoss 0.1369 (0.5604)\tAcc 1.000 (0.806)\n",
      "Epoch: [97][10/18]\tTime 0.080 (0.092)\tData 0.060 (0.068)\tLoss 1.1899 (0.6234)\tAcc 0.625 (0.788)\n",
      "Epoch: [97][11/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 1.3413 (0.6887)\tAcc 0.375 (0.750)\n",
      "Epoch: [97][12/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.9965 (0.7143)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][13/18]\tTime 0.075 (0.089)\tData 0.055 (0.066)\tLoss 1.0688 (0.7416)\tAcc 0.625 (0.740)\n",
      "Epoch: [97][14/18]\tTime 0.075 (0.088)\tData 0.054 (0.065)\tLoss 0.6597 (0.7357)\tAcc 0.625 (0.732)\n",
      "Epoch: [97][15/18]\tTime 0.079 (0.088)\tData 0.059 (0.065)\tLoss 0.8402 (0.7427)\tAcc 0.688 (0.729)\n",
      "Epoch: [97][16/18]\tTime 0.080 (0.087)\tData 0.060 (0.064)\tLoss 0.8339 (0.7484)\tAcc 0.750 (0.730)\n",
      "Epoch: [97][17/18]\tTime 0.080 (0.087)\tData 0.060 (0.064)\tLoss 0.8117 (0.7521)\tAcc 0.625 (0.724)\n",
      "Epoch: [97][18/18]\tTime 0.080 (0.086)\tData 0.060 (0.064)\tLoss 0.6865 (0.7502)\tAcc 0.875 (0.729)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/12]\tTime 0.251 (0.251)\tData 0.215 (0.215)\tLoss 0.7457 (0.7457)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][2/12]\tTime 0.082 (0.166)\tData 0.052 (0.133)\tLoss 0.6192 (0.6824)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][3/12]\tTime 0.087 (0.140)\tData 0.057 (0.108)\tLoss 0.8651 (0.7433)\tAcc 0.625 (0.708)\n",
      "Epoch: [98][4/12]\tTime 0.087 (0.127)\tData 0.061 (0.096)\tLoss 0.9331 (0.7908)\tAcc 0.688 (0.703)\n",
      "Epoch: [98][5/12]\tTime 0.083 (0.118)\tData 0.057 (0.088)\tLoss 0.5832 (0.7492)\tAcc 0.750 (0.713)\n",
      "Epoch: [98][6/12]\tTime 0.078 (0.111)\tData 0.054 (0.083)\tLoss 0.5134 (0.7099)\tAcc 0.750 (0.719)\n",
      "Epoch: [98][7/12]\tTime 0.078 (0.106)\tData 0.055 (0.079)\tLoss 0.6914 (0.7073)\tAcc 0.688 (0.714)\n",
      "Epoch: [98][8/12]\tTime 0.086 (0.104)\tData 0.061 (0.076)\tLoss 0.5192 (0.6838)\tAcc 0.812 (0.727)\n",
      "Epoch: [98][9/12]\tTime 0.086 (0.102)\tData 0.062 (0.075)\tLoss 0.6391 (0.6788)\tAcc 0.750 (0.729)\n",
      "Epoch: [98][10/12]\tTime 0.088 (0.100)\tData 0.063 (0.074)\tLoss 0.8158 (0.6925)\tAcc 0.562 (0.713)\n",
      "Epoch: [98][11/12]\tTime 0.087 (0.099)\tData 0.062 (0.073)\tLoss 0.8509 (0.7069)\tAcc 0.688 (0.710)\n",
      "Epoch: [98][12/12]\tTime 0.087 (0.098)\tData 0.062 (0.072)\tLoss 0.4470 (0.6865)\tAcc 0.867 (0.723)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/18]\tTime 0.235 (0.235)\tData 0.207 (0.207)\tLoss 0.2755 (0.2755)\tAcc 1.000 (1.000)\n",
      "Epoch: [98][2/18]\tTime 0.083 (0.159)\tData 0.053 (0.130)\tLoss 0.8996 (0.5875)\tAcc 0.625 (0.812)\n",
      "Epoch: [98][3/18]\tTime 0.071 (0.129)\tData 0.050 (0.103)\tLoss 0.6449 (0.6067)\tAcc 0.812 (0.812)\n",
      "Epoch: [98][4/18]\tTime 0.073 (0.115)\tData 0.053 (0.091)\tLoss 0.5159 (0.5840)\tAcc 0.750 (0.797)\n",
      "Epoch: [98][5/18]\tTime 0.075 (0.107)\tData 0.054 (0.084)\tLoss 0.7824 (0.6237)\tAcc 0.688 (0.775)\n",
      "Epoch: [98][6/18]\tTime 0.077 (0.102)\tData 0.056 (0.079)\tLoss 0.2801 (0.5664)\tAcc 1.000 (0.812)\n",
      "Epoch: [98][7/18]\tTime 0.082 (0.099)\tData 0.060 (0.076)\tLoss 0.7415 (0.5914)\tAcc 0.625 (0.786)\n",
      "Epoch: [98][8/18]\tTime 0.080 (0.097)\tData 0.058 (0.074)\tLoss 0.9297 (0.6337)\tAcc 0.625 (0.766)\n",
      "Epoch: [98][9/18]\tTime 0.080 (0.095)\tData 0.060 (0.072)\tLoss 0.1255 (0.5772)\tAcc 1.000 (0.792)\n",
      "Epoch: [98][10/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 1.0441 (0.6239)\tAcc 0.750 (0.788)\n",
      "Epoch: [98][11/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 1.0909 (0.6664)\tAcc 0.375 (0.750)\n",
      "Epoch: [98][12/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.7570 (0.6739)\tAcc 0.812 (0.755)\n",
      "Epoch: [98][13/18]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 1.0408 (0.7021)\tAcc 0.500 (0.736)\n",
      "Epoch: [98][14/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.8048 (0.7095)\tAcc 0.562 (0.723)\n",
      "Epoch: [98][15/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.9138 (0.7231)\tAcc 0.625 (0.717)\n",
      "Epoch: [98][16/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.7660 (0.7258)\tAcc 0.688 (0.715)\n",
      "Epoch: [98][17/18]\tTime 0.077 (0.087)\tData 0.057 (0.066)\tLoss 0.6898 (0.7237)\tAcc 0.688 (0.713)\n",
      "Epoch: [98][18/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.6415 (0.7213)\tAcc 0.875 (0.718)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/12]\tTime 0.232 (0.232)\tData 0.203 (0.203)\tLoss 0.7288 (0.7288)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][2/12]\tTime 0.083 (0.157)\tData 0.051 (0.127)\tLoss 1.0676 (0.8982)\tAcc 0.625 (0.656)\n",
      "Epoch: [99][3/12]\tTime 0.071 (0.129)\tData 0.046 (0.100)\tLoss 0.4909 (0.7624)\tAcc 0.812 (0.708)\n",
      "Epoch: [99][4/12]\tTime 0.086 (0.118)\tData 0.060 (0.090)\tLoss 0.4406 (0.6820)\tAcc 0.875 (0.750)\n",
      "Epoch: [99][5/12]\tTime 0.087 (0.112)\tData 0.061 (0.084)\tLoss 0.4109 (0.6277)\tAcc 0.875 (0.775)\n",
      "Epoch: [99][6/12]\tTime 0.085 (0.107)\tData 0.060 (0.080)\tLoss 0.3611 (0.5833)\tAcc 0.812 (0.781)\n",
      "Epoch: [99][7/12]\tTime 0.086 (0.104)\tData 0.062 (0.078)\tLoss 0.4703 (0.5672)\tAcc 0.875 (0.795)\n",
      "Epoch: [99][8/12]\tTime 0.083 (0.102)\tData 0.059 (0.075)\tLoss 0.8211 (0.5989)\tAcc 0.750 (0.789)\n",
      "Epoch: [99][9/12]\tTime 0.083 (0.100)\tData 0.059 (0.073)\tLoss 0.9252 (0.6352)\tAcc 0.688 (0.778)\n",
      "Epoch: [99][10/12]\tTime 0.086 (0.098)\tData 0.062 (0.072)\tLoss 0.6749 (0.6391)\tAcc 0.750 (0.775)\n",
      "Epoch: [99][11/12]\tTime 0.086 (0.097)\tData 0.062 (0.071)\tLoss 0.5405 (0.6302)\tAcc 0.688 (0.767)\n",
      "Epoch: [99][12/12]\tTime 0.085 (0.096)\tData 0.062 (0.070)\tLoss 0.6868 (0.6346)\tAcc 0.667 (0.759)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/18]\tTime 0.232 (0.232)\tData 0.197 (0.197)\tLoss 0.3271 (0.3271)\tAcc 1.000 (1.000)\n",
      "Epoch: [99][2/18]\tTime 0.074 (0.153)\tData 0.047 (0.122)\tLoss 0.8952 (0.6111)\tAcc 0.625 (0.812)\n",
      "Epoch: [99][3/18]\tTime 0.075 (0.127)\tData 0.054 (0.099)\tLoss 0.6116 (0.6113)\tAcc 0.688 (0.771)\n",
      "Epoch: [99][4/18]\tTime 0.075 (0.114)\tData 0.054 (0.088)\tLoss 0.4963 (0.5826)\tAcc 0.750 (0.766)\n",
      "Epoch: [99][5/18]\tTime 0.074 (0.106)\tData 0.053 (0.081)\tLoss 0.8293 (0.6319)\tAcc 0.688 (0.750)\n",
      "Epoch: [99][6/18]\tTime 0.080 (0.102)\tData 0.060 (0.078)\tLoss 0.3761 (0.5893)\tAcc 0.875 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [99][7/18]\tTime 0.076 (0.098)\tData 0.056 (0.074)\tLoss 0.6651 (0.6001)\tAcc 0.812 (0.777)\n",
      "Epoch: [99][8/18]\tTime 0.081 (0.096)\tData 0.059 (0.073)\tLoss 0.9020 (0.6378)\tAcc 0.688 (0.766)\n",
      "Epoch: [99][9/18]\tTime 0.080 (0.094)\tData 0.059 (0.071)\tLoss 0.1253 (0.5809)\tAcc 1.000 (0.792)\n",
      "Epoch: [99][10/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.9748 (0.6203)\tAcc 0.625 (0.775)\n",
      "Epoch: [99][11/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 1.2230 (0.6751)\tAcc 0.375 (0.739)\n",
      "Epoch: [99][12/18]\tTime 0.075 (0.090)\tData 0.055 (0.068)\tLoss 0.9228 (0.6957)\tAcc 0.750 (0.740)\n",
      "Epoch: [99][13/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 1.0486 (0.7229)\tAcc 0.438 (0.716)\n",
      "Epoch: [99][14/18]\tTime 0.079 (0.088)\tData 0.059 (0.066)\tLoss 0.8064 (0.7288)\tAcc 0.562 (0.705)\n",
      "Epoch: [99][15/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8800 (0.7389)\tAcc 0.688 (0.704)\n",
      "Epoch: [99][16/18]\tTime 0.081 (0.087)\tData 0.061 (0.065)\tLoss 0.8345 (0.7449)\tAcc 0.625 (0.699)\n",
      "Epoch: [99][17/18]\tTime 0.077 (0.087)\tData 0.057 (0.065)\tLoss 0.8153 (0.7490)\tAcc 0.625 (0.695)\n",
      "Epoch: [99][18/18]\tTime 0.074 (0.086)\tData 0.055 (0.064)\tLoss 0.8300 (0.7513)\tAcc 0.750 (0.696)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/12]\tTime 0.233 (0.233)\tData 0.199 (0.199)\tLoss 0.4241 (0.4241)\tAcc 0.812 (0.812)\n",
      "Epoch: [100][2/12]\tTime 0.094 (0.163)\tData 0.053 (0.126)\tLoss 0.7516 (0.5879)\tAcc 0.750 (0.781)\n",
      "Epoch: [100][3/12]\tTime 0.074 (0.133)\tData 0.047 (0.100)\tLoss 0.4760 (0.5506)\tAcc 0.812 (0.792)\n",
      "Epoch: [100][4/12]\tTime 0.078 (0.120)\tData 0.053 (0.088)\tLoss 0.7114 (0.5908)\tAcc 0.688 (0.766)\n",
      "Epoch: [100][5/12]\tTime 0.083 (0.112)\tData 0.057 (0.082)\tLoss 0.8526 (0.6431)\tAcc 0.625 (0.738)\n",
      "Epoch: [100][6/12]\tTime 0.082 (0.107)\tData 0.057 (0.078)\tLoss 0.6637 (0.6466)\tAcc 0.750 (0.740)\n",
      "Epoch: [100][7/12]\tTime 0.086 (0.104)\tData 0.062 (0.076)\tLoss 0.5519 (0.6330)\tAcc 0.812 (0.750)\n",
      "Epoch: [100][8/12]\tTime 0.087 (0.102)\tData 0.062 (0.074)\tLoss 0.6505 (0.6352)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][9/12]\tTime 0.086 (0.100)\tData 0.061 (0.073)\tLoss 1.2505 (0.7036)\tAcc 0.562 (0.729)\n",
      "Epoch: [100][10/12]\tTime 0.086 (0.099)\tData 0.061 (0.071)\tLoss 0.4258 (0.6758)\tAcc 0.938 (0.750)\n",
      "Epoch: [100][11/12]\tTime 0.087 (0.098)\tData 0.062 (0.071)\tLoss 0.5170 (0.6614)\tAcc 0.812 (0.756)\n",
      "Epoch: [100][12/12]\tTime 0.087 (0.097)\tData 0.062 (0.070)\tLoss 0.6068 (0.6571)\tAcc 0.733 (0.754)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/18]\tTime 0.235 (0.235)\tData 0.205 (0.205)\tLoss 0.2997 (0.2997)\tAcc 0.875 (0.875)\n",
      "Epoch: [100][2/18]\tTime 0.079 (0.157)\tData 0.052 (0.128)\tLoss 0.8012 (0.5504)\tAcc 0.625 (0.750)\n",
      "Epoch: [100][3/18]\tTime 0.075 (0.130)\tData 0.054 (0.104)\tLoss 0.7208 (0.6072)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][4/18]\tTime 0.079 (0.117)\tData 0.059 (0.092)\tLoss 0.5754 (0.5993)\tAcc 0.812 (0.766)\n",
      "Epoch: [100][5/18]\tTime 0.075 (0.109)\tData 0.054 (0.085)\tLoss 0.8979 (0.6590)\tAcc 0.688 (0.750)\n",
      "Epoch: [100][6/18]\tTime 0.079 (0.104)\tData 0.058 (0.080)\tLoss 0.2491 (0.5907)\tAcc 1.000 (0.792)\n",
      "Epoch: [100][7/18]\tTime 0.081 (0.101)\tData 0.060 (0.077)\tLoss 0.5415 (0.5837)\tAcc 0.812 (0.795)\n",
      "Epoch: [100][8/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 0.8661 (0.6190)\tAcc 0.750 (0.789)\n",
      "Epoch: [100][9/18]\tTime 0.080 (0.096)\tData 0.059 (0.073)\tLoss 0.1273 (0.5643)\tAcc 1.000 (0.812)\n",
      "Epoch: [100][10/18]\tTime 0.078 (0.094)\tData 0.055 (0.072)\tLoss 1.0734 (0.6152)\tAcc 0.625 (0.794)\n",
      "Epoch: [100][11/18]\tTime 0.076 (0.093)\tData 0.056 (0.070)\tLoss 1.1627 (0.6650)\tAcc 0.375 (0.756)\n",
      "Epoch: [100][12/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.9088 (0.6853)\tAcc 0.812 (0.760)\n",
      "Epoch: [100][13/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 1.1090 (0.7179)\tAcc 0.375 (0.731)\n",
      "Epoch: [100][14/18]\tTime 0.081 (0.090)\tData 0.061 (0.068)\tLoss 0.7881 (0.7229)\tAcc 0.750 (0.732)\n",
      "Epoch: [100][15/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.7948 (0.7277)\tAcc 0.750 (0.733)\n",
      "Epoch: [100][16/18]\tTime 0.076 (0.088)\tData 0.056 (0.067)\tLoss 0.8351 (0.7344)\tAcc 0.562 (0.723)\n",
      "Epoch: [100][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.7261 (0.7339)\tAcc 0.625 (0.717)\n",
      "Epoch: [100][18/18]\tTime 0.080 (0.087)\tData 0.060 (0.066)\tLoss 0.6740 (0.7322)\tAcc 0.625 (0.714)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:17.558349Z",
     "start_time": "2020-05-01T02:29:17.532000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/56]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:17.568547Z",
     "start_time": "2020-05-01T02:29:17.559510Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:30.028849Z",
     "start_time": "2020-05-01T02:29:17.569784Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:30.068773Z",
     "start_time": "2020-05-01T02:29:30.030144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 2.2168850898742676},\n",
       " {'label': 'none', 'score': 2.2168850898742676},\n",
       " {'label': 'none', 'score': 2.2168850898742676},\n",
       " {'label': 'none', 'score': 1.8935729265213013},\n",
       " {'label': 'none', 'score': 1.8935729265213013},\n",
       " {'label': 'none', 'score': 1.8935729265213013},\n",
       " {'label': 'none', 'score': 1.6308348178863525},\n",
       " {'label': 'none', 'score': 1.6308348178863525},\n",
       " {'label': 'none', 'score': 1.6308348178863525},\n",
       " {'label': 'none', 'score': 2.12884783744812},\n",
       " {'label': 'none', 'score': 2.12884783744812},\n",
       " {'label': 'none', 'score': 2.12884783744812},\n",
       " {'label': 'none', 'score': 1.6220297813415527},\n",
       " {'label': 'none', 'score': 1.6220297813415527},\n",
       " {'label': 'none', 'score': 1.6220297813415527},\n",
       " {'label': 'none', 'score': 2.020247459411621},\n",
       " {'label': 'none', 'score': 2.020247459411621},\n",
       " {'label': 'none', 'score': 2.020247459411621},\n",
       " {'label': 'none', 'score': 1.6690795421600342},\n",
       " {'label': 'none', 'score': 1.6690795421600342},\n",
       " {'label': 'none', 'score': 1.6690795421600342},\n",
       " {'label': 'none', 'score': 1.951772928237915},\n",
       " {'label': 'none', 'score': 1.951772928237915},\n",
       " {'label': 'none', 'score': 1.951772928237915},\n",
       " {'label': 'none', 'score': 1.5219217538833618},\n",
       " {'label': 'none', 'score': 1.5219217538833618},\n",
       " {'label': 'none', 'score': 1.5219217538833618},\n",
       " {'label': 'none', 'score': 1.8799107074737549},\n",
       " {'label': 'none', 'score': 1.8799107074737549},\n",
       " {'label': 'none', 'score': 1.8799107074737549},\n",
       " {'label': 'none', 'score': 1.8328843116760254},\n",
       " {'label': 'none', 'score': 1.8328843116760254},\n",
       " {'label': 'none', 'score': 1.8328843116760254},\n",
       " {'label': 'none', 'score': 1.4276511669158936},\n",
       " {'label': 'none', 'score': 1.4276511669158936},\n",
       " {'label': 'none', 'score': 1.4276511669158936},\n",
       " {'label': 'none', 'score': 1.7761950492858887},\n",
       " {'label': 'none', 'score': 1.7761950492858887},\n",
       " {'label': 'none', 'score': 1.7761950492858887},\n",
       " {'label': 'none', 'score': 1.7352169752120972},\n",
       " {'label': 'none', 'score': 1.7352169752120972},\n",
       " {'label': 'none', 'score': 1.7352169752120972},\n",
       " {'label': 'none', 'score': 1.5978349447250366},\n",
       " {'label': 'none', 'score': 1.5978349447250366},\n",
       " {'label': 'none', 'score': 1.5978349447250366},\n",
       " {'label': 'none', 'score': 1.94992995262146},\n",
       " {'label': 'none', 'score': 1.94992995262146},\n",
       " {'label': 'none', 'score': 1.94992995262146},\n",
       " {'label': 'none', 'score': 2.045818567276001},\n",
       " {'label': 'none', 'score': 2.045818567276001},\n",
       " {'label': 'none', 'score': 2.045818567276001},\n",
       " {'label': 'none', 'score': 1.7254239320755005},\n",
       " {'label': 'none', 'score': 1.7254239320755005},\n",
       " {'label': 'none', 'score': 1.7254239320755005},\n",
       " {'label': 'none', 'score': 1.7824393510818481},\n",
       " {'label': 'none', 'score': 1.7824393510818481},\n",
       " {'label': 'none', 'score': 1.7824393510818481},\n",
       " {'label': 'none', 'score': 1.7560749053955078},\n",
       " {'label': 'none', 'score': 1.7560749053955078},\n",
       " {'label': 'none', 'score': 1.7560749053955078},\n",
       " {'label': 'none', 'score': 1.8353687524795532},\n",
       " {'label': 'none', 'score': 1.8353687524795532},\n",
       " {'label': 'none', 'score': 1.8353687524795532},\n",
       " {'label': 'none', 'score': 1.7324854135513306},\n",
       " {'label': 'none', 'score': 1.7324854135513306},\n",
       " {'label': 'none', 'score': 1.7324854135513306},\n",
       " {'label': 'none', 'score': 1.6461292505264282},\n",
       " {'label': 'none', 'score': 1.6461292505264282},\n",
       " {'label': 'none', 'score': 1.6461292505264282},\n",
       " {'label': 'returning', 'score': 0.35176631808280945},\n",
       " {'label': 'returning', 'score': 0.35176631808280945},\n",
       " {'label': 'returning', 'score': 0.35176631808280945},\n",
       " {'label': 'returning', 'score': 0.38680320978164673},\n",
       " {'label': 'returning', 'score': 0.38680320978164673},\n",
       " {'label': 'returning', 'score': 0.38680320978164673},\n",
       " {'label': 'returning', 'score': 0.2254239022731781},\n",
       " {'label': 'returning', 'score': 0.2254239022731781},\n",
       " {'label': 'returning', 'score': 0.2254239022731781},\n",
       " {'label': 'leaving', 'score': 0.8105305433273315},\n",
       " {'label': 'leaving', 'score': 0.8105305433273315},\n",
       " {'label': 'leaving', 'score': 0.8105305433273315},\n",
       " {'label': 'leaving', 'score': 0.4666284918785095},\n",
       " {'label': 'leaving', 'score': 0.4666284918785095},\n",
       " {'label': 'leaving', 'score': 0.4666284918785095},\n",
       " {'label': 'returning', 'score': 0.3086194396018982},\n",
       " {'label': 'returning', 'score': 0.3086194396018982},\n",
       " {'label': 'returning', 'score': 0.3086194396018982},\n",
       " {'label': 'returning', 'score': 0.4243113100528717},\n",
       " {'label': 'returning', 'score': 0.4243113100528717},\n",
       " {'label': 'returning', 'score': 0.4243113100528717},\n",
       " {'label': 'returning', 'score': 0.5236905813217163},\n",
       " {'label': 'returning', 'score': 0.5236905813217163},\n",
       " {'label': 'returning', 'score': 0.5236905813217163},\n",
       " {'label': 'returning', 'score': 0.4979623854160309},\n",
       " {'label': 'returning', 'score': 0.4979623854160309},\n",
       " {'label': 'returning', 'score': 0.4979623854160309},\n",
       " {'label': 'returning', 'score': 0.33352476358413696},\n",
       " {'label': 'returning', 'score': 0.33352476358413696},\n",
       " {'label': 'returning', 'score': 0.33352476358413696},\n",
       " {'label': 'returning', 'score': 1.104820966720581},\n",
       " {'label': 'returning', 'score': 1.104820966720581},\n",
       " {'label': 'returning', 'score': 1.104820966720581},\n",
       " {'label': 'none', 'score': 1.655505657196045},\n",
       " {'label': 'none', 'score': 1.655505657196045},\n",
       " {'label': 'none', 'score': 1.655505657196045},\n",
       " {'label': 'none', 'score': 1.7607417106628418},\n",
       " {'label': 'none', 'score': 1.7607417106628418},\n",
       " {'label': 'none', 'score': 1.7607417106628418},\n",
       " {'label': 'none', 'score': 1.9917521476745605},\n",
       " {'label': 'none', 'score': 1.9917521476745605},\n",
       " {'label': 'none', 'score': 1.9917521476745605},\n",
       " {'label': 'none', 'score': 1.7134013175964355},\n",
       " {'label': 'none', 'score': 1.7134013175964355},\n",
       " {'label': 'none', 'score': 1.7134013175964355},\n",
       " {'label': 'none', 'score': 2.043680191040039},\n",
       " {'label': 'none', 'score': 2.043680191040039},\n",
       " {'label': 'none', 'score': 2.043680191040039},\n",
       " {'label': 'none', 'score': 1.9474313259124756},\n",
       " {'label': 'none', 'score': 1.9474313259124756},\n",
       " {'label': 'none', 'score': 1.9474313259124756},\n",
       " {'label': 'none', 'score': 2.0549161434173584},\n",
       " {'label': 'none', 'score': 2.0549161434173584},\n",
       " {'label': 'none', 'score': 2.0549161434173584},\n",
       " {'label': 'none', 'score': 1.958313226699829},\n",
       " {'label': 'none', 'score': 1.958313226699829},\n",
       " {'label': 'none', 'score': 1.958313226699829},\n",
       " {'label': 'none', 'score': 1.4536879062652588},\n",
       " {'label': 'none', 'score': 1.4536879062652588},\n",
       " {'label': 'none', 'score': 1.4536879062652588},\n",
       " {'label': 'none', 'score': 1.6560882329940796},\n",
       " {'label': 'none', 'score': 1.6560882329940796},\n",
       " {'label': 'none', 'score': 1.6560882329940796},\n",
       " {'label': 'none', 'score': 1.977367639541626},\n",
       " {'label': 'none', 'score': 1.977367639541626},\n",
       " {'label': 'none', 'score': 1.977367639541626},\n",
       " {'label': 'none', 'score': 1.7017872333526611},\n",
       " {'label': 'none', 'score': 1.7017872333526611},\n",
       " {'label': 'none', 'score': 1.7017872333526611},\n",
       " {'label': 'none', 'score': 1.864851951599121},\n",
       " {'label': 'none', 'score': 1.864851951599121},\n",
       " {'label': 'none', 'score': 1.864851951599121},\n",
       " {'label': 'none', 'score': 1.6654473543167114},\n",
       " {'label': 'none', 'score': 1.6654473543167114},\n",
       " {'label': 'none', 'score': 1.6654473543167114},\n",
       " {'label': 'none', 'score': 2.243950366973877},\n",
       " {'label': 'none', 'score': 2.243950366973877},\n",
       " {'label': 'none', 'score': 2.243950366973877},\n",
       " {'label': 'none', 'score': 2.166120767593384},\n",
       " {'label': 'none', 'score': 2.166120767593384},\n",
       " {'label': 'none', 'score': 2.166120767593384},\n",
       " {'label': 'none', 'score': 1.5058765411376953},\n",
       " {'label': 'none', 'score': 1.5058765411376953},\n",
       " {'label': 'none', 'score': 1.5058765411376953},\n",
       " {'label': 'returning', 'score': 0.43354153633117676},\n",
       " {'label': 'returning', 'score': 0.43354153633117676},\n",
       " {'label': 'returning', 'score': 0.43354153633117676},\n",
       " {'label': 'returning', 'score': 0.5585355162620544},\n",
       " {'label': 'returning', 'score': 0.5585355162620544},\n",
       " {'label': 'returning', 'score': 0.5585355162620544},\n",
       " {'label': 'returning', 'score': 0.5671021342277527},\n",
       " {'label': 'returning', 'score': 0.5671021342277527},\n",
       " {'label': 'returning', 'score': 0.5671021342277527},\n",
       " {'label': 'returning', 'score': 0.5941416621208191},\n",
       " {'label': 'returning', 'score': 0.5941416621208191},\n",
       " {'label': 'returning', 'score': 0.5941416621208191},\n",
       " {'label': 'returning', 'score': 0.4825611412525177},\n",
       " {'label': 'returning', 'score': 0.4825611412525177},\n",
       " {'label': 'returning', 'score': 0.4825611412525177},\n",
       " {'label': 'returning', 'score': 0.2986384630203247},\n",
       " {'label': 'returning', 'score': 0.2986384630203247},\n",
       " {'label': 'returning', 'score': 0.2986384630203247},\n",
       " {'label': 'returning', 'score': 0.3350500166416168},\n",
       " {'label': 'returning', 'score': 0.3350500166416168},\n",
       " {'label': 'returning', 'score': 0.3350500166416168},\n",
       " {'label': 'returning', 'score': 0.49310141801834106},\n",
       " {'label': 'returning', 'score': 0.49310141801834106},\n",
       " {'label': 'returning', 'score': 0.49310141801834106},\n",
       " {'label': 'returning', 'score': 0.7326975464820862},\n",
       " {'label': 'returning', 'score': 0.7326975464820862},\n",
       " {'label': 'returning', 'score': 0.7326975464820862},\n",
       " {'label': 'returning', 'score': 1.33608877658844},\n",
       " {'label': 'returning', 'score': 1.33608877658844},\n",
       " {'label': 'returning', 'score': 1.33608877658844},\n",
       " {'label': 'none', 'score': 1.7492836713790894},\n",
       " {'label': 'none', 'score': 1.7492836713790894},\n",
       " {'label': 'none', 'score': 1.7492836713790894},\n",
       " {'label': 'none', 'score': 2.163867473602295},\n",
       " {'label': 'none', 'score': 2.163867473602295},\n",
       " {'label': 'none', 'score': 2.163867473602295},\n",
       " {'label': 'none', 'score': 1.664940595626831},\n",
       " {'label': 'none', 'score': 1.664940595626831},\n",
       " {'label': 'none', 'score': 1.664940595626831},\n",
       " {'label': 'none', 'score': 1.6137977838516235},\n",
       " {'label': 'none', 'score': 1.6137977838516235},\n",
       " {'label': 'none', 'score': 1.6137977838516235},\n",
       " {'label': 'none', 'score': 1.8784034252166748},\n",
       " {'label': 'none', 'score': 1.8784034252166748},\n",
       " {'label': 'none', 'score': 1.8784034252166748},\n",
       " {'label': 'none', 'score': 1.8908989429473877},\n",
       " {'label': 'none', 'score': 1.8908989429473877},\n",
       " {'label': 'none', 'score': 1.8908989429473877},\n",
       " {'label': 'none', 'score': 1.9349086284637451},\n",
       " {'label': 'none', 'score': 1.9349086284637451},\n",
       " {'label': 'none', 'score': 1.9349086284637451},\n",
       " {'label': 'none', 'score': 1.9369920492172241},\n",
       " {'label': 'none', 'score': 1.9369920492172241},\n",
       " {'label': 'none', 'score': 1.9369920492172241},\n",
       " {'label': 'none', 'score': 1.6837389469146729},\n",
       " {'label': 'none', 'score': 1.6837389469146729},\n",
       " {'label': 'none', 'score': 1.6837389469146729},\n",
       " {'label': 'none', 'score': 1.8977627754211426},\n",
       " {'label': 'none', 'score': 1.8977627754211426},\n",
       " {'label': 'none', 'score': 1.8977627754211426},\n",
       " {'label': 'none', 'score': 1.684059977531433},\n",
       " {'label': 'none', 'score': 1.684059977531433},\n",
       " {'label': 'none', 'score': 1.684059977531433},\n",
       " {'label': 'none', 'score': 1.8087602853775024},\n",
       " {'label': 'none', 'score': 1.8087602853775024},\n",
       " {'label': 'none', 'score': 1.8087602853775024},\n",
       " {'label': 'none', 'score': 2.1004106998443604},\n",
       " {'label': 'none', 'score': 2.1004106998443604},\n",
       " {'label': 'none', 'score': 2.1004106998443604},\n",
       " {'label': 'none', 'score': 1.7519421577453613},\n",
       " {'label': 'none', 'score': 1.7519421577453613},\n",
       " {'label': 'none', 'score': 1.7519421577453613},\n",
       " {'label': 'none', 'score': 1.9610939025878906},\n",
       " {'label': 'none', 'score': 1.9610939025878906},\n",
       " {'label': 'none', 'score': 1.9610939025878906},\n",
       " {'label': 'none', 'score': 1.9959156513214111},\n",
       " {'label': 'none', 'score': 1.9959156513214111},\n",
       " {'label': 'none', 'score': 1.9959156513214111},\n",
       " {'label': 'none', 'score': 1.7678930759429932},\n",
       " {'label': 'none', 'score': 1.7678930759429932},\n",
       " {'label': 'none', 'score': 1.7678930759429932},\n",
       " {'label': 'none', 'score': 1.7280958890914917},\n",
       " {'label': 'none', 'score': 1.7280958890914917},\n",
       " {'label': 'none', 'score': 1.7280958890914917},\n",
       " {'label': 'none', 'score': 1.740316390991211},\n",
       " {'label': 'none', 'score': 1.740316390991211},\n",
       " {'label': 'none', 'score': 1.740316390991211},\n",
       " {'label': 'none', 'score': 1.801701307296753},\n",
       " {'label': 'none', 'score': 1.801701307296753},\n",
       " {'label': 'none', 'score': 1.801701307296753},\n",
       " {'label': 'leaving', 'score': 0.6784539818763733},\n",
       " {'label': 'leaving', 'score': 0.6784539818763733},\n",
       " {'label': 'leaving', 'score': 0.6784539818763733},\n",
       " {'label': 'returning', 'score': 0.30444657802581787},\n",
       " {'label': 'returning', 'score': 0.30444657802581787},\n",
       " {'label': 'returning', 'score': 0.30444657802581787},\n",
       " {'label': 'returning', 'score': 0.3581332564353943},\n",
       " {'label': 'returning', 'score': 0.3581332564353943},\n",
       " {'label': 'returning', 'score': 0.3581332564353943},\n",
       " {'label': 'returning', 'score': 0.1616646647453308},\n",
       " {'label': 'returning', 'score': 0.1616646647453308},\n",
       " {'label': 'returning', 'score': 0.1616646647453308},\n",
       " {'label': 'returning', 'score': 0.3838687241077423},\n",
       " {'label': 'returning', 'score': 0.3838687241077423},\n",
       " {'label': 'returning', 'score': 0.3838687241077423},\n",
       " {'label': 'returning', 'score': 0.539482057094574},\n",
       " {'label': 'returning', 'score': 0.539482057094574},\n",
       " {'label': 'returning', 'score': 0.539482057094574},\n",
       " {'label': 'returning', 'score': 0.5637826323509216},\n",
       " {'label': 'returning', 'score': 0.5637826323509216},\n",
       " {'label': 'returning', 'score': 0.5637826323509216},\n",
       " {'label': 'returning', 'score': 0.3921932876110077},\n",
       " {'label': 'returning', 'score': 0.3921932876110077},\n",
       " {'label': 'returning', 'score': 0.3921932876110077},\n",
       " {'label': 'leaving', 'score': 1.1414183378219604},\n",
       " {'label': 'leaving', 'score': 1.1414183378219604},\n",
       " {'label': 'leaving', 'score': 1.1414183378219604},\n",
       " {'label': 'none', 'score': 1.9675956964492798},\n",
       " {'label': 'none', 'score': 1.9675956964492798},\n",
       " {'label': 'none', 'score': 1.9675956964492798},\n",
       " {'label': 'none', 'score': 1.937551736831665},\n",
       " {'label': 'none', 'score': 1.937551736831665},\n",
       " {'label': 'none', 'score': 1.937551736831665},\n",
       " {'label': 'none', 'score': 1.8272204399108887},\n",
       " {'label': 'none', 'score': 1.8272204399108887},\n",
       " {'label': 'none', 'score': 1.8272204399108887},\n",
       " {'label': 'none', 'score': 1.9332685470581055},\n",
       " {'label': 'none', 'score': 1.9332685470581055},\n",
       " {'label': 'none', 'score': 1.9332685470581055},\n",
       " {'label': 'none', 'score': 1.8215246200561523},\n",
       " {'label': 'none', 'score': 1.8215246200561523},\n",
       " {'label': 'none', 'score': 1.8215246200561523},\n",
       " {'label': 'none', 'score': 2.1555376052856445},\n",
       " {'label': 'none', 'score': 2.1555376052856445},\n",
       " {'label': 'none', 'score': 2.1555376052856445},\n",
       " {'label': 'none', 'score': 1.6158230304718018},\n",
       " {'label': 'none', 'score': 1.6158230304718018},\n",
       " {'label': 'none', 'score': 1.6158230304718018},\n",
       " {'label': 'none', 'score': 2.088805913925171},\n",
       " {'label': 'none', 'score': 2.088805913925171},\n",
       " {'label': 'none', 'score': 2.088805913925171},\n",
       " {'label': 'none', 'score': 2.077460527420044},\n",
       " {'label': 'none', 'score': 2.077460527420044},\n",
       " {'label': 'none', 'score': 2.077460527420044},\n",
       " {'label': 'none', 'score': 1.6395025253295898},\n",
       " {'label': 'none', 'score': 1.6395025253295898},\n",
       " {'label': 'none', 'score': 1.6395025253295898},\n",
       " {'label': 'none', 'score': 1.608859896659851},\n",
       " {'label': 'none', 'score': 1.608859896659851},\n",
       " {'label': 'none', 'score': 1.608859896659851},\n",
       " {'label': 'none', 'score': 1.8899754285812378},\n",
       " {'label': 'none', 'score': 1.8899754285812378},\n",
       " {'label': 'none', 'score': 1.8899754285812378},\n",
       " {'label': 'none', 'score': 1.4839792251586914},\n",
       " {'label': 'none', 'score': 1.4839792251586914},\n",
       " {'label': 'none', 'score': 1.4839792251586914},\n",
       " {'label': 'none', 'score': 1.8174303770065308},\n",
       " {'label': 'none', 'score': 1.8174303770065308},\n",
       " {'label': 'none', 'score': 1.8174303770065308},\n",
       " {'label': 'none', 'score': 1.875913143157959},\n",
       " {'label': 'none', 'score': 1.875913143157959},\n",
       " {'label': 'none', 'score': 1.875913143157959},\n",
       " {'label': 'none', 'score': 1.9971696138381958},\n",
       " {'label': 'none', 'score': 1.9971696138381958},\n",
       " {'label': 'none', 'score': 1.9971696138381958},\n",
       " {'label': 'none', 'score': 1.9437326192855835},\n",
       " {'label': 'none', 'score': 1.9437326192855835},\n",
       " {'label': 'none', 'score': 1.9437326192855835},\n",
       " {'label': 'none', 'score': 1.8574514389038086},\n",
       " {'label': 'none', 'score': 1.8574514389038086},\n",
       " {'label': 'none', 'score': 1.8574514389038086},\n",
       " {'label': 'none', 'score': 0.7276155352592468},\n",
       " {'label': 'none', 'score': 0.7276155352592468},\n",
       " {'label': 'none', 'score': 0.7276155352592468},\n",
       " {'label': 'returning', 'score': 0.45710062980651855},\n",
       " {'label': 'returning', 'score': 0.45710062980651855},\n",
       " {'label': 'returning', 'score': 0.45710062980651855},\n",
       " {'label': 'returning', 'score': 0.6305330395698547},\n",
       " {'label': 'returning', 'score': 0.6305330395698547},\n",
       " {'label': 'returning', 'score': 0.6305330395698547},\n",
       " {'label': 'returning', 'score': 0.5749362111091614},\n",
       " {'label': 'returning', 'score': 0.5749362111091614},\n",
       " {'label': 'returning', 'score': 0.5749362111091614},\n",
       " {'label': 'returning', 'score': 0.5578526854515076},\n",
       " {'label': 'returning', 'score': 0.5578526854515076},\n",
       " {'label': 'returning', 'score': 0.5578526854515076},\n",
       " {'label': 'returning', 'score': 0.2785998284816742},\n",
       " {'label': 'returning', 'score': 0.2785998284816742},\n",
       " {'label': 'returning', 'score': 0.2785998284816742},\n",
       " {'label': 'returning', 'score': 0.4596688151359558},\n",
       " {'label': 'returning', 'score': 0.4596688151359558},\n",
       " {'label': 'returning', 'score': 0.4596688151359558},\n",
       " {'label': 'returning', 'score': 0.7312605381011963},\n",
       " {'label': 'returning', 'score': 0.7312605381011963},\n",
       " {'label': 'returning', 'score': 0.7312605381011963},\n",
       " {'label': 'none', 'score': 1.8869670629501343},\n",
       " {'label': 'none', 'score': 1.8869670629501343},\n",
       " {'label': 'none', 'score': 1.8869670629501343},\n",
       " {'label': 'none', 'score': 1.8832643032073975},\n",
       " {'label': 'none', 'score': 1.8832643032073975},\n",
       " {'label': 'none', 'score': 1.8832643032073975},\n",
       " {'label': 'none', 'score': 2.0854456424713135},\n",
       " {'label': 'none', 'score': 2.0854456424713135},\n",
       " {'label': 'none', 'score': 2.0854456424713135},\n",
       " {'label': 'none', 'score': 2.135453939437866},\n",
       " {'label': 'none', 'score': 2.135453939437866},\n",
       " {'label': 'none', 'score': 2.135453939437866},\n",
       " {'label': 'none', 'score': 2.0667009353637695},\n",
       " {'label': 'none', 'score': 2.0667009353637695},\n",
       " {'label': 'none', 'score': 2.0667009353637695},\n",
       " {'label': 'none', 'score': 1.4723949432373047},\n",
       " {'label': 'none', 'score': 1.4723949432373047},\n",
       " {'label': 'none', 'score': 1.4723949432373047},\n",
       " {'label': 'none', 'score': 1.6388946771621704},\n",
       " {'label': 'none', 'score': 1.6388946771621704},\n",
       " {'label': 'none', 'score': 1.6388946771621704},\n",
       " {'label': 'none', 'score': 2.0023539066314697},\n",
       " {'label': 'none', 'score': 2.0023539066314697},\n",
       " {'label': 'none', 'score': 2.0023539066314697},\n",
       " {'label': 'none', 'score': 1.8500314950942993},\n",
       " {'label': 'none', 'score': 1.8500314950942993},\n",
       " {'label': 'none', 'score': 1.8500314950942993},\n",
       " {'label': 'none', 'score': 1.744659185409546},\n",
       " {'label': 'none', 'score': 1.744659185409546},\n",
       " {'label': 'none', 'score': 1.744659185409546},\n",
       " {'label': 'none', 'score': 1.930379033088684},\n",
       " {'label': 'none', 'score': 1.930379033088684},\n",
       " {'label': 'none', 'score': 1.930379033088684},\n",
       " {'label': 'none', 'score': 1.9434814453125},\n",
       " {'label': 'none', 'score': 1.9434814453125},\n",
       " {'label': 'none', 'score': 1.9434814453125},\n",
       " {'label': 'none', 'score': 2.0820913314819336},\n",
       " {'label': 'none', 'score': 2.0820913314819336},\n",
       " {'label': 'none', 'score': 2.0820913314819336},\n",
       " {'label': 'none', 'score': 1.9626750946044922},\n",
       " {'label': 'none', 'score': 1.9626750946044922},\n",
       " {'label': 'none', 'score': 1.9626750946044922},\n",
       " {'label': 'none', 'score': 1.7227023839950562},\n",
       " {'label': 'none', 'score': 1.7227023839950562},\n",
       " {'label': 'none', 'score': 1.7227023839950562},\n",
       " {'label': 'none', 'score': 1.678184986114502},\n",
       " {'label': 'none', 'score': 1.678184986114502},\n",
       " {'label': 'none', 'score': 1.678184986114502},\n",
       " {'label': 'none', 'score': 1.9781196117401123},\n",
       " {'label': 'none', 'score': 1.9781196117401123},\n",
       " {'label': 'none', 'score': 1.9781196117401123},\n",
       " {'label': 'none', 'score': 1.9319145679473877},\n",
       " {'label': 'none', 'score': 1.9319145679473877},\n",
       " {'label': 'none', 'score': 1.9319145679473877},\n",
       " {'label': 'returning', 'score': 1.2496261596679688},\n",
       " {'label': 'returning', 'score': 1.2496261596679688},\n",
       " {'label': 'returning', 'score': 1.2496261596679688},\n",
       " {'label': 'leaving', 'score': 0.7821471691131592},\n",
       " {'label': 'leaving', 'score': 0.7821471691131592},\n",
       " {'label': 'leaving', 'score': 0.7821471691131592},\n",
       " {'label': 'none', 'score': 1.667211651802063},\n",
       " {'label': 'none', 'score': 1.667211651802063},\n",
       " {'label': 'none', 'score': 1.667211651802063},\n",
       " {'label': 'none', 'score': 1.6774557828903198},\n",
       " {'label': 'none', 'score': 1.6774557828903198},\n",
       " {'label': 'none', 'score': 1.6774557828903198},\n",
       " {'label': 'none', 'score': 1.6045048236846924},\n",
       " {'label': 'none', 'score': 1.6045048236846924},\n",
       " {'label': 'none', 'score': 1.6045048236846924},\n",
       " {'label': 'none', 'score': 1.6761634349822998},\n",
       " {'label': 'none', 'score': 1.6761634349822998},\n",
       " {'label': 'none', 'score': 1.6761634349822998},\n",
       " {'label': 'none', 'score': 1.2061854600906372},\n",
       " {'label': 'none', 'score': 1.2061854600906372},\n",
       " {'label': 'none', 'score': 1.2061854600906372},\n",
       " {'label': 'none', 'score': 1.8399252891540527},\n",
       " {'label': 'none', 'score': 1.8399252891540527},\n",
       " {'label': 'none', 'score': 1.8399252891540527},\n",
       " {'label': 'none', 'score': 2.0806946754455566},\n",
       " {'label': 'none', 'score': 2.0806946754455566},\n",
       " {'label': 'none', 'score': 2.0806946754455566},\n",
       " {'label': 'none', 'score': 1.732957363128662},\n",
       " {'label': 'none', 'score': 1.732957363128662},\n",
       " {'label': 'none', 'score': 1.732957363128662},\n",
       " {'label': 'none', 'score': 1.527299404144287},\n",
       " {'label': 'none', 'score': 1.527299404144287},\n",
       " {'label': 'none', 'score': 1.527299404144287},\n",
       " {'label': 'returning', 'score': 0.929271399974823},\n",
       " {'label': 'returning', 'score': 0.929271399974823},\n",
       " {'label': 'returning', 'score': 0.929271399974823},\n",
       " {'label': 'none', 'score': 0.5035115480422974},\n",
       " {'label': 'none', 'score': 0.5035115480422974},\n",
       " {'label': 'none', 'score': 0.5035115480422974},\n",
       " {'label': 'returning', 'score': 0.27405446767807007},\n",
       " {'label': 'returning', 'score': 0.27405446767807007},\n",
       " {'label': 'returning', 'score': 0.27405446767807007},\n",
       " {'label': 'returning', 'score': 0.3889846205711365},\n",
       " {'label': 'returning', 'score': 0.3889846205711365},\n",
       " {'label': 'returning', 'score': 0.3889846205711365},\n",
       " {'label': 'returning', 'score': 0.928852915763855},\n",
       " {'label': 'returning', 'score': 0.928852915763855},\n",
       " {'label': 'returning', 'score': 0.928852915763855},\n",
       " {'label': 'none', 'score': 1.4376124143600464},\n",
       " {'label': 'none', 'score': 1.4376124143600464},\n",
       " {'label': 'none', 'score': 1.4376124143600464},\n",
       " {'label': 'none', 'score': 1.785364031791687},\n",
       " {'label': 'none', 'score': 1.785364031791687},\n",
       " {'label': 'none', 'score': 1.785364031791687},\n",
       " {'label': 'none', 'score': 1.6944859027862549},\n",
       " {'label': 'none', 'score': 1.6944859027862549},\n",
       " {'label': 'none', 'score': 1.6944859027862549},\n",
       " {'label': 'none', 'score': 1.674977421760559},\n",
       " {'label': 'none', 'score': 1.674977421760559},\n",
       " {'label': 'none', 'score': 1.674977421760559},\n",
       " {'label': 'none', 'score': 1.8585238456726074},\n",
       " {'label': 'none', 'score': 1.8585238456726074},\n",
       " {'label': 'none', 'score': 1.8585238456726074},\n",
       " {'label': 'none', 'score': 1.914414882659912},\n",
       " {'label': 'none', 'score': 1.914414882659912},\n",
       " {'label': 'none', 'score': 1.914414882659912},\n",
       " {'label': 'none', 'score': 1.4727421998977661},\n",
       " {'label': 'none', 'score': 1.4727421998977661},\n",
       " {'label': 'none', 'score': 1.4727421998977661},\n",
       " {'label': 'none', 'score': 1.8498468399047852},\n",
       " {'label': 'none', 'score': 1.8498468399047852},\n",
       " {'label': 'none', 'score': 1.8498468399047852},\n",
       " {'label': 'none', 'score': 1.7482304573059082},\n",
       " {'label': 'none', 'score': 1.7482304573059082},\n",
       " {'label': 'none', 'score': 1.7482304573059082},\n",
       " {'label': 'none', 'score': 1.7526118755340576},\n",
       " {'label': 'none', 'score': 1.7526118755340576},\n",
       " {'label': 'none', 'score': 1.7526118755340576},\n",
       " {'label': 'none', 'score': 1.4278355836868286},\n",
       " {'label': 'none', 'score': 1.4278355836868286},\n",
       " {'label': 'none', 'score': 1.4278355836868286},\n",
       " {'label': 'none', 'score': 1.0609925985336304},\n",
       " {'label': 'none', 'score': 1.0609925985336304},\n",
       " {'label': 'none', 'score': 1.0609925985336304},\n",
       " {'label': 'returning', 'score': 0.28755655884742737},\n",
       " {'label': 'returning', 'score': 0.28755655884742737},\n",
       " {'label': 'returning', 'score': 0.28755655884742737},\n",
       " {'label': 'leaving', 'score': 0.25605103373527527},\n",
       " {'label': 'leaving', 'score': 0.25605103373527527},\n",
       " {'label': 'leaving', 'score': 0.25605103373527527},\n",
       " {'label': 'leaving', 'score': 0.421060711145401},\n",
       " {'label': 'leaving', 'score': 0.421060711145401},\n",
       " {'label': 'leaving', 'score': 0.421060711145401},\n",
       " {'label': 'returning', 'score': 0.3435029685497284},\n",
       " {'label': 'returning', 'score': 0.3435029685497284},\n",
       " {'label': 'returning', 'score': 0.3435029685497284},\n",
       " {'label': 'returning', 'score': 0.5019115805625916},\n",
       " {'label': 'returning', 'score': 0.5019115805625916},\n",
       " {'label': 'returning', 'score': 0.5019115805625916},\n",
       " {'label': 'returning', 'score': 0.44502320885658264},\n",
       " {'label': 'returning', 'score': 0.44502320885658264},\n",
       " {'label': 'returning', 'score': 0.44502320885658264},\n",
       " {'label': 'leaving', 'score': 0.2999800443649292},\n",
       " {'label': 'leaving', 'score': 0.2999800443649292},\n",
       " {'label': 'leaving', 'score': 0.2999800443649292},\n",
       " {'label': 'leaving', 'score': 1.3745120763778687},\n",
       " {'label': 'leaving', 'score': 1.3745120763778687},\n",
       " {'label': 'leaving', 'score': 1.3745120763778687},\n",
       " {'label': 'none', 'score': 1.7990984916687012},\n",
       " {'label': 'none', 'score': 1.7990984916687012},\n",
       " {'label': 'none', 'score': 1.7990984916687012},\n",
       " {'label': 'none', 'score': 1.8253769874572754},\n",
       " {'label': 'none', 'score': 1.8253769874572754},\n",
       " {'label': 'none', 'score': 1.8253769874572754},\n",
       " {'label': 'none', 'score': 2.0692429542541504},\n",
       " {'label': 'none', 'score': 2.0692429542541504},\n",
       " {'label': 'none', 'score': 2.0692429542541504},\n",
       " {'label': 'none', 'score': 2.1655359268188477},\n",
       " {'label': 'none', 'score': 2.1655359268188477},\n",
       " {'label': 'none', 'score': 2.1655359268188477},\n",
       " {'label': 'none', 'score': 1.8979893922805786},\n",
       " {'label': 'none', 'score': 1.8979893922805786},\n",
       " {'label': 'none', 'score': 1.8979893922805786},\n",
       " {'label': 'none', 'score': 1.6680407524108887},\n",
       " {'label': 'none', 'score': 1.6680407524108887},\n",
       " {'label': 'none', 'score': 1.6680407524108887},\n",
       " {'label': 'none', 'score': 1.7982420921325684},\n",
       " {'label': 'none', 'score': 1.7982420921325684},\n",
       " {'label': 'none', 'score': 1.7982420921325684},\n",
       " {'label': 'none', 'score': 1.7474159002304077},\n",
       " {'label': 'none', 'score': 1.7474159002304077},\n",
       " {'label': 'none', 'score': 1.7474159002304077},\n",
       " {'label': 'none', 'score': 1.7489615678787231},\n",
       " {'label': 'none', 'score': 1.7489615678787231},\n",
       " {'label': 'none', 'score': 1.7489615678787231},\n",
       " {'label': 'none', 'score': 1.4639289379119873},\n",
       " {'label': 'none', 'score': 1.4639289379119873},\n",
       " {'label': 'none', 'score': 1.4639289379119873},\n",
       " {'label': 'none', 'score': 1.8919821977615356},\n",
       " {'label': 'none', 'score': 1.8919821977615356},\n",
       " {'label': 'none', 'score': 1.8919821977615356},\n",
       " {'label': 'leaving', 'score': 0.7266862988471985},\n",
       " {'label': 'leaving', 'score': 0.7266862988471985},\n",
       " {'label': 'leaving', 'score': 0.7266862988471985},\n",
       " {'label': 'returning', 'score': 0.47733333706855774},\n",
       " {'label': 'returning', 'score': 0.47733333706855774},\n",
       " {'label': 'returning', 'score': 0.47733333706855774},\n",
       " {'label': 'returning', 'score': 0.6362605690956116},\n",
       " {'label': 'returning', 'score': 0.6362605690956116},\n",
       " {'label': 'returning', 'score': 0.6362605690956116},\n",
       " {'label': 'returning', 'score': 0.7173575758934021},\n",
       " {'label': 'returning', 'score': 0.7173575758934021},\n",
       " {'label': 'returning', 'score': 0.7173575758934021},\n",
       " {'label': 'returning', 'score': 0.6451071500778198},\n",
       " {'label': 'returning', 'score': 0.6451071500778198},\n",
       " {'label': 'returning', 'score': 0.6451071500778198},\n",
       " {'label': 'returning', 'score': 0.43675053119659424},\n",
       " {'label': 'returning', 'score': 0.43675053119659424},\n",
       " {'label': 'returning', 'score': 0.43675053119659424},\n",
       " {'label': 'returning', 'score': 0.3523370325565338},\n",
       " {'label': 'returning', 'score': 0.3523370325565338},\n",
       " {'label': 'returning', 'score': 0.3523370325565338},\n",
       " {'label': 'returning', 'score': 0.398195743560791},\n",
       " {'label': 'returning', 'score': 0.398195743560791},\n",
       " {'label': 'returning', 'score': 0.398195743560791},\n",
       " {'label': 'returning', 'score': 0.9468013048171997},\n",
       " {'label': 'returning', 'score': 0.9468013048171997},\n",
       " {'label': 'returning', 'score': 0.9468013048171997},\n",
       " {'label': 'none', 'score': 1.298919677734375},\n",
       " {'label': 'none', 'score': 1.298919677734375},\n",
       " {'label': 'none', 'score': 1.298919677734375},\n",
       " {'label': 'none', 'score': 2.209566593170166},\n",
       " {'label': 'none', 'score': 2.209566593170166},\n",
       " {'label': 'none', 'score': 2.209566593170166},\n",
       " {'label': 'none', 'score': 2.1784565448760986},\n",
       " {'label': 'none', 'score': 2.1784565448760986},\n",
       " {'label': 'none', 'score': 2.1784565448760986},\n",
       " {'label': 'none', 'score': 1.6002534627914429},\n",
       " {'label': 'none', 'score': 1.6002534627914429},\n",
       " {'label': 'none', 'score': 1.6002534627914429},\n",
       " {'label': 'none', 'score': 2.1974422931671143},\n",
       " {'label': 'none', 'score': 2.1974422931671143},\n",
       " {'label': 'none', 'score': 2.1974422931671143},\n",
       " {'label': 'none', 'score': 2.5340213775634766},\n",
       " {'label': 'none', 'score': 2.5340213775634766},\n",
       " {'label': 'none', 'score': 2.5340213775634766},\n",
       " {'label': 'none', 'score': 1.9645220041275024},\n",
       " {'label': 'none', 'score': 1.9645220041275024},\n",
       " {'label': 'none', 'score': 1.9645220041275024},\n",
       " {'label': 'none', 'score': 2.3722572326660156},\n",
       " {'label': 'none', 'score': 2.3722572326660156},\n",
       " {'label': 'none', 'score': 2.3722572326660156},\n",
       " {'label': 'none', 'score': 2.2678678035736084},\n",
       " {'label': 'none', 'score': 2.2678678035736084},\n",
       " {'label': 'none', 'score': 2.2678678035736084},\n",
       " {'label': 'none', 'score': 2.1122679710388184},\n",
       " {'label': 'none', 'score': 2.1122679710388184},\n",
       " {'label': 'none', 'score': 2.1122679710388184},\n",
       " {'label': 'none', 'score': 2.1929023265838623},\n",
       " {'label': 'none', 'score': 2.1929023265838623},\n",
       " {'label': 'none', 'score': 2.1929023265838623},\n",
       " {'label': 'none', 'score': 2.5853123664855957},\n",
       " {'label': 'none', 'score': 2.5853123664855957},\n",
       " {'label': 'none', 'score': 2.5853123664855957},\n",
       " {'label': 'none', 'score': 2.096935987472534},\n",
       " {'label': 'none', 'score': 2.096935987472534},\n",
       " {'label': 'none', 'score': 2.096935987472534},\n",
       " {'label': 'none', 'score': 2.005692958831787},\n",
       " {'label': 'none', 'score': 2.005692958831787},\n",
       " {'label': 'none', 'score': 2.005692958831787},\n",
       " {'label': 'none', 'score': 2.3536813259124756},\n",
       " {'label': 'none', 'score': 2.3536813259124756},\n",
       " {'label': 'none', 'score': 2.3536813259124756},\n",
       " {'label': 'none', 'score': 2.5934369564056396},\n",
       " {'label': 'none', 'score': 2.5934369564056396},\n",
       " {'label': 'none', 'score': 2.5934369564056396},\n",
       " {'label': 'none', 'score': 2.157327890396118},\n",
       " {'label': 'none', 'score': 2.157327890396118},\n",
       " {'label': 'none', 'score': 2.157327890396118},\n",
       " {'label': 'none', 'score': 2.188446044921875},\n",
       " {'label': 'none', 'score': 2.188446044921875},\n",
       " {'label': 'none', 'score': 2.188446044921875},\n",
       " {'label': 'none', 'score': 2.2530136108398438},\n",
       " {'label': 'none', 'score': 2.2530136108398438},\n",
       " {'label': 'none', 'score': 2.2530136108398438},\n",
       " {'label': 'none', 'score': 2.2251923084259033},\n",
       " {'label': 'none', 'score': 2.2251923084259033},\n",
       " {'label': 'none', 'score': 2.2251923084259033},\n",
       " {'label': 'none', 'score': 2.7341578006744385},\n",
       " {'label': 'none', 'score': 2.7341578006744385},\n",
       " {'label': 'none', 'score': 2.7341578006744385},\n",
       " {'label': 'none', 'score': 2.0411994457244873},\n",
       " {'label': 'none', 'score': 2.0411994457244873},\n",
       " {'label': 'none', 'score': 2.0411994457244873},\n",
       " {'label': 'none', 'score': 2.764857769012451},\n",
       " {'label': 'none', 'score': 2.764857769012451},\n",
       " {'label': 'none', 'score': 2.764857769012451},\n",
       " {'label': 'none', 'score': 2.559537410736084},\n",
       " {'label': 'none', 'score': 2.559537410736084},\n",
       " {'label': 'none', 'score': 2.559537410736084},\n",
       " {'label': 'none', 'score': 2.629002094268799},\n",
       " {'label': 'none', 'score': 2.629002094268799},\n",
       " {'label': 'none', 'score': 2.629002094268799},\n",
       " {'label': 'none', 'score': 2.4192066192626953},\n",
       " {'label': 'none', 'score': 2.4192066192626953},\n",
       " {'label': 'none', 'score': 2.4192066192626953},\n",
       " {'label': 'none', 'score': 2.225079298019409},\n",
       " {'label': 'none', 'score': 2.225079298019409},\n",
       " {'label': 'none', 'score': 2.225079298019409},\n",
       " {'label': 'none', 'score': 2.2916033267974854},\n",
       " {'label': 'none', 'score': 2.2916033267974854},\n",
       " {'label': 'none', 'score': 2.2916033267974854},\n",
       " {'label': 'none', 'score': 2.4586615562438965},\n",
       " {'label': 'none', 'score': 2.4586615562438965},\n",
       " {'label': 'none', 'score': 2.4586615562438965},\n",
       " {'label': 'none', 'score': 2.648446559906006},\n",
       " {'label': 'none', 'score': 2.648446559906006},\n",
       " {'label': 'none', 'score': 2.648446559906006},\n",
       " {'label': 'none', 'score': 2.1002442836761475},\n",
       " {'label': 'none', 'score': 2.1002442836761475},\n",
       " {'label': 'none', 'score': 2.1002442836761475},\n",
       " {'label': 'returning', 'score': 0.7540897130966187},\n",
       " {'label': 'returning', 'score': 0.7540897130966187},\n",
       " {'label': 'returning', 'score': 0.7540897130966187},\n",
       " {'label': 'returning', 'score': 0.5397589802742004},\n",
       " {'label': 'returning', 'score': 0.5397589802742004},\n",
       " {'label': 'returning', 'score': 0.5397589802742004},\n",
       " {'label': 'returning', 'score': 0.3067965507507324},\n",
       " {'label': 'returning', 'score': 0.3067965507507324},\n",
       " {'label': 'returning', 'score': 0.3067965507507324},\n",
       " {'label': 'returning', 'score': 0.57623291015625},\n",
       " {'label': 'returning', 'score': 0.57623291015625},\n",
       " {'label': 'returning', 'score': 0.57623291015625},\n",
       " {'label': 'returning', 'score': 0.5472733378410339},\n",
       " {'label': 'returning', 'score': 0.5472733378410339},\n",
       " {'label': 'returning', 'score': 0.5472733378410339},\n",
       " {'label': 'returning', 'score': 0.4575364589691162},\n",
       " {'label': 'returning', 'score': 0.4575364589691162},\n",
       " {'label': 'returning', 'score': 0.4575364589691162},\n",
       " {'label': 'returning', 'score': 0.509978711605072},\n",
       " {'label': 'returning', 'score': 0.509978711605072},\n",
       " {'label': 'returning', 'score': 0.509978711605072},\n",
       " {'label': 'returning', 'score': 0.6586060523986816},\n",
       " {'label': 'returning', 'score': 0.6586060523986816},\n",
       " {'label': 'returning', 'score': 0.6586060523986816},\n",
       " {'label': 'none', 'score': 0.68778395652771},\n",
       " {'label': 'none', 'score': 0.68778395652771},\n",
       " {'label': 'none', 'score': 0.68778395652771},\n",
       " {'label': 'returning', 'score': 0.6915460228919983},\n",
       " {'label': 'returning', 'score': 0.6915460228919983},\n",
       " {'label': 'returning', 'score': 0.6915460228919983},\n",
       " {'label': 'returning', 'score': 1.4172974824905396},\n",
       " {'label': 'returning', 'score': 1.4172974824905396},\n",
       " {'label': 'returning', 'score': 1.4172974824905396},\n",
       " {'label': 'none', 'score': 2.0670244693756104},\n",
       " {'label': 'none', 'score': 2.0670244693756104},\n",
       " {'label': 'none', 'score': 2.0670244693756104},\n",
       " {'label': 'none', 'score': 1.9872236251831055},\n",
       " {'label': 'none', 'score': 1.9872236251831055},\n",
       " {'label': 'none', 'score': 1.9872236251831055},\n",
       " {'label': 'none', 'score': 2.413698434829712},\n",
       " {'label': 'none', 'score': 2.413698434829712},\n",
       " {'label': 'none', 'score': 2.413698434829712},\n",
       " {'label': 'none', 'score': 3.0067226886749268},\n",
       " {'label': 'none', 'score': 3.0067226886749268},\n",
       " {'label': 'none', 'score': 3.0067226886749268},\n",
       " {'label': 'none', 'score': 2.7313599586486816},\n",
       " {'label': 'none', 'score': 2.7313599586486816},\n",
       " {'label': 'none', 'score': 2.7313599586486816},\n",
       " {'label': 'none', 'score': 2.340254783630371},\n",
       " {'label': 'none', 'score': 2.340254783630371},\n",
       " {'label': 'none', 'score': 2.340254783630371},\n",
       " {'label': 'none', 'score': 2.4715704917907715},\n",
       " {'label': 'none', 'score': 2.4715704917907715},\n",
       " {'label': 'none', 'score': 2.4715704917907715},\n",
       " {'label': 'none', 'score': 1.918101191520691},\n",
       " {'label': 'none', 'score': 1.918101191520691},\n",
       " {'label': 'none', 'score': 1.918101191520691},\n",
       " {'label': 'none', 'score': 2.719074010848999},\n",
       " {'label': 'none', 'score': 2.719074010848999},\n",
       " {'label': 'none', 'score': 2.719074010848999},\n",
       " {'label': 'none', 'score': 2.0883982181549072},\n",
       " {'label': 'none', 'score': 2.0883982181549072},\n",
       " {'label': 'none', 'score': 2.0883982181549072},\n",
       " {'label': 'none', 'score': 2.2327370643615723},\n",
       " {'label': 'none', 'score': 2.2327370643615723},\n",
       " {'label': 'none', 'score': 2.2327370643615723},\n",
       " {'label': 'none', 'score': 2.4002816677093506},\n",
       " {'label': 'none', 'score': 2.4002816677093506},\n",
       " {'label': 'none', 'score': 2.4002816677093506},\n",
       " {'label': 'none', 'score': 2.615945339202881},\n",
       " {'label': 'none', 'score': 2.615945339202881},\n",
       " {'label': 'none', 'score': 2.615945339202881},\n",
       " {'label': 'none', 'score': 2.471405267715454},\n",
       " {'label': 'none', 'score': 2.471405267715454},\n",
       " {'label': 'none', 'score': 2.471405267715454},\n",
       " {'label': 'none', 'score': 2.2577409744262695},\n",
       " {'label': 'none', 'score': 2.2577409744262695},\n",
       " {'label': 'none', 'score': 2.2577409744262695},\n",
       " {'label': 'none', 'score': 2.3621857166290283},\n",
       " {'label': 'none', 'score': 2.3621857166290283},\n",
       " {'label': 'none', 'score': 2.3621857166290283},\n",
       " {'label': 'none', 'score': 2.292485475540161},\n",
       " {'label': 'none', 'score': 2.292485475540161},\n",
       " {'label': 'none', 'score': 2.292485475540161},\n",
       " {'label': 'none', 'score': 2.5953195095062256},\n",
       " {'label': 'none', 'score': 2.5953195095062256},\n",
       " {'label': 'none', 'score': 2.5953195095062256},\n",
       " {'label': 'none', 'score': 1.9728792905807495},\n",
       " {'label': 'none', 'score': 1.9728792905807495},\n",
       " {'label': 'none', 'score': 1.9728792905807495},\n",
       " {'label': 'returning', 'score': 0.9215981364250183},\n",
       " {'label': 'returning', 'score': 0.9215981364250183},\n",
       " {'label': 'returning', 'score': 0.9215981364250183},\n",
       " {'label': 'returning', 'score': 1.3711857795715332},\n",
       " {'label': 'returning', 'score': 1.3711857795715332},\n",
       " {'label': 'returning', 'score': 1.3711857795715332},\n",
       " {'label': 'none', 'score': 0.5117146968841553},\n",
       " {'label': 'none', 'score': 0.5117146968841553},\n",
       " {'label': 'none', 'score': 0.5117146968841553},\n",
       " {'label': 'returning', 'score': 0.5975779891014099},\n",
       " {'label': 'returning', 'score': 0.5975779891014099},\n",
       " {'label': 'returning', 'score': 0.5975779891014099},\n",
       " {'label': 'returning', 'score': 0.6411418914794922},\n",
       " {'label': 'returning', 'score': 0.6411418914794922},\n",
       " {'label': 'returning', 'score': 0.6411418914794922},\n",
       " {'label': 'returning', 'score': 0.5411706566810608},\n",
       " {'label': 'returning', 'score': 0.5411706566810608},\n",
       " {'label': 'returning', 'score': 0.5411706566810608},\n",
       " {'label': 'returning', 'score': 0.5126931667327881},\n",
       " {'label': 'returning', 'score': 0.5126931667327881},\n",
       " {'label': 'returning', 'score': 0.5126931667327881},\n",
       " {'label': 'returning', 'score': 0.4438512921333313},\n",
       " {'label': 'returning', 'score': 0.4438512921333313},\n",
       " {'label': 'returning', 'score': 0.4438512921333313},\n",
       " {'label': 'returning', 'score': 0.9694271683692932},\n",
       " {'label': 'returning', 'score': 0.9694271683692932},\n",
       " {'label': 'returning', 'score': 0.9694271683692932},\n",
       " {'label': 'none', 'score': 2.081448793411255},\n",
       " {'label': 'none', 'score': 2.081448793411255},\n",
       " {'label': 'none', 'score': 2.081448793411255},\n",
       " {'label': 'none', 'score': 2.3884823322296143},\n",
       " {'label': 'none', 'score': 2.3884823322296143},\n",
       " {'label': 'none', 'score': 2.3884823322296143},\n",
       " {'label': 'none', 'score': 2.3525092601776123},\n",
       " {'label': 'none', 'score': 2.3525092601776123},\n",
       " {'label': 'none', 'score': 2.3525092601776123},\n",
       " {'label': 'none', 'score': 2.1927881240844727},\n",
       " {'label': 'none', 'score': 2.1927881240844727},\n",
       " {'label': 'none', 'score': 2.1927881240844727},\n",
       " {'label': 'none', 'score': 2.775761127471924},\n",
       " {'label': 'none', 'score': 2.775761127471924},\n",
       " {'label': 'none', 'score': 2.775761127471924},\n",
       " {'label': 'none', 'score': 2.452752113342285},\n",
       " {'label': 'none', 'score': 2.452752113342285},\n",
       " {'label': 'none', 'score': 2.452752113342285},\n",
       " {'label': 'none', 'score': 2.084226608276367},\n",
       " {'label': 'none', 'score': 2.084226608276367},\n",
       " {'label': 'none', 'score': 2.084226608276367},\n",
       " {'label': 'none', 'score': 2.239919900894165},\n",
       " {'label': 'none', 'score': 2.239919900894165},\n",
       " {'label': 'none', 'score': 2.239919900894165},\n",
       " {'label': 'none', 'score': 2.382692575454712},\n",
       " {'label': 'none', 'score': 2.382692575454712},\n",
       " {'label': 'none', 'score': 2.382692575454712},\n",
       " {'label': 'none', 'score': 2.75161075592041},\n",
       " {'label': 'none', 'score': 2.75161075592041},\n",
       " {'label': 'none', 'score': 2.75161075592041},\n",
       " {'label': 'none', 'score': 2.4327609539031982},\n",
       " {'label': 'none', 'score': 2.4327609539031982},\n",
       " {'label': 'none', 'score': 2.4327609539031982},\n",
       " {'label': 'none', 'score': 2.7218070030212402},\n",
       " {'label': 'none', 'score': 2.7218070030212402},\n",
       " {'label': 'none', 'score': 2.7218070030212402},\n",
       " {'label': 'none', 'score': 2.8884825706481934},\n",
       " {'label': 'none', 'score': 2.8884825706481934},\n",
       " {'label': 'none', 'score': 2.8884825706481934},\n",
       " {'label': 'none', 'score': 2.533982515335083},\n",
       " {'label': 'none', 'score': 2.533982515335083},\n",
       " {'label': 'none', 'score': 2.533982515335083},\n",
       " {'label': 'none', 'score': 2.2047109603881836},\n",
       " {'label': 'none', 'score': 2.2047109603881836},\n",
       " {'label': 'none', 'score': 2.2047109603881836},\n",
       " {'label': 'none', 'score': 2.295736312866211},\n",
       " {'label': 'none', 'score': 2.295736312866211},\n",
       " {'label': 'none', 'score': 2.295736312866211},\n",
       " {'label': 'none', 'score': 2.294349431991577},\n",
       " {'label': 'none', 'score': 2.294349431991577},\n",
       " {'label': 'none', 'score': 2.294349431991577},\n",
       " {'label': 'none', 'score': 2.498966932296753},\n",
       " {'label': 'none', 'score': 2.498966932296753},\n",
       " {'label': 'none', 'score': 2.498966932296753},\n",
       " {'label': 'none', 'score': 2.5418429374694824},\n",
       " {'label': 'none', 'score': 2.5418429374694824},\n",
       " {'label': 'none', 'score': 2.5418429374694824},\n",
       " {'label': 'none', 'score': 2.0692899227142334},\n",
       " {'label': 'none', 'score': 2.0692899227142334},\n",
       " {'label': 'none', 'score': 2.0692899227142334},\n",
       " {'label': 'none', 'score': 2.3812808990478516},\n",
       " {'label': 'none', 'score': 2.3812808990478516},\n",
       " {'label': 'none', 'score': 2.3812808990478516},\n",
       " {'label': 'none', 'score': 2.748363971710205},\n",
       " {'label': 'none', 'score': 2.748363971710205},\n",
       " {'label': 'none', 'score': 2.748363971710205},\n",
       " {'label': 'returning', 'score': 0.831038773059845},\n",
       " {'label': 'returning', 'score': 0.831038773059845},\n",
       " {'label': 'returning', 'score': 0.831038773059845},\n",
       " {'label': 'returning', 'score': 0.5067411661148071},\n",
       " {'label': 'returning', 'score': 0.5067411661148071},\n",
       " {'label': 'returning', 'score': 0.5067411661148071},\n",
       " {'label': 'returning', 'score': 0.540630578994751},\n",
       " {'label': 'returning', 'score': 0.540630578994751},\n",
       " {'label': 'returning', 'score': 0.540630578994751},\n",
       " {'label': 'returning', 'score': 0.520182192325592},\n",
       " {'label': 'returning', 'score': 0.520182192325592},\n",
       " {'label': 'returning', 'score': 0.520182192325592},\n",
       " {'label': 'returning', 'score': 0.5477461814880371},\n",
       " {'label': 'returning', 'score': 0.5477461814880371},\n",
       " {'label': 'returning', 'score': 0.5477461814880371},\n",
       " {'label': 'returning', 'score': 0.4785121977329254},\n",
       " {'label': 'returning', 'score': 0.4785121977329254},\n",
       " {'label': 'returning', 'score': 0.4785121977329254},\n",
       " {'label': 'returning', 'score': 0.5663061738014221},\n",
       " {'label': 'returning', 'score': 0.5663061738014221},\n",
       " {'label': 'returning', 'score': 0.5663061738014221},\n",
       " {'label': 'returning', 'score': 0.5834721326828003},\n",
       " {'label': 'returning', 'score': 0.5834721326828003},\n",
       " {'label': 'returning', 'score': 0.5834721326828003},\n",
       " {'label': 'returning', 'score': 0.5065675973892212},\n",
       " {'label': 'returning', 'score': 0.5065675973892212},\n",
       " {'label': 'returning', 'score': 0.5065675973892212},\n",
       " {'label': 'none', 'score': 0.7757402658462524},\n",
       " {'label': 'none', 'score': 0.7757402658462524},\n",
       " {'label': 'none', 'score': 0.7757402658462524},\n",
       " {'label': 'returning', 'score': 0.7536488771438599},\n",
       " {'label': 'returning', 'score': 0.7536488771438599},\n",
       " {'label': 'returning', 'score': 0.7536488771438599},\n",
       " {'label': 'returning', 'score': 0.33329471945762634},\n",
       " {'label': 'returning', 'score': 0.33329471945762634},\n",
       " {'label': 'returning', 'score': 0.33329471945762634},\n",
       " {'label': 'returning', 'score': 0.8275346159934998},\n",
       " {'label': 'returning', 'score': 0.8275346159934998},\n",
       " {'label': 'returning', 'score': 0.8275346159934998},\n",
       " {'label': 'returning', 'score': 0.7682365775108337},\n",
       " {'label': 'returning', 'score': 0.7682365775108337},\n",
       " {'label': 'returning', 'score': 0.7682365775108337},\n",
       " {'label': 'none', 'score': 0.4528353214263916},\n",
       " {'label': 'none', 'score': 0.4528353214263916},\n",
       " {'label': 'none', 'score': 0.4528353214263916},\n",
       " {'label': 'returning', 'score': 0.2570832371711731},\n",
       " {'label': 'returning', 'score': 0.2570832371711731},\n",
       " {'label': 'returning', 'score': 0.2570832371711731},\n",
       " {'label': 'returning', 'score': 0.4557610750198364},\n",
       " {'label': 'returning', 'score': 0.4557610750198364},\n",
       " {'label': 'returning', 'score': 0.4557610750198364},\n",
       " {'label': 'none', 'score': 1.3172671794891357},\n",
       " {'label': 'none', 'score': 1.3172671794891357},\n",
       " {'label': 'none', 'score': 1.3172671794891357},\n",
       " {'label': 'none', 'score': 1.7538280487060547},\n",
       " {'label': 'none', 'score': 1.7538280487060547},\n",
       " {'label': 'none', 'score': 1.7538280487060547},\n",
       " {'label': 'none', 'score': 1.8699885606765747},\n",
       " {'label': 'none', 'score': 1.8699885606765747},\n",
       " {'label': 'none', 'score': 1.8699885606765747},\n",
       " {'label': 'returning', 'score': 0.389818012714386},\n",
       " {'label': 'returning', 'score': 0.389818012714386},\n",
       " {'label': 'returning', 'score': 0.389818012714386},\n",
       " {'label': 'returning', 'score': 0.43283772468566895},\n",
       " {'label': 'returning', 'score': 0.43283772468566895},\n",
       " {'label': 'returning', 'score': 0.43283772468566895},\n",
       " {'label': 'returning', 'score': 0.17235982418060303},\n",
       " {'label': 'returning', 'score': 0.17235982418060303},\n",
       " {'label': 'returning', 'score': 0.17235982418060303},\n",
       " {'label': 'leaving', 'score': 0.7810652852058411},\n",
       " {'label': 'leaving', 'score': 0.7810652852058411},\n",
       " {'label': 'leaving', 'score': 0.7810652852058411},\n",
       " {'label': 'returning', 'score': 0.32912522554397583},\n",
       " {'label': 'returning', 'score': 0.32912522554397583},\n",
       " {'label': 'returning', 'score': 0.32912522554397583},\n",
       " {'label': 'returning', 'score': 0.7736327648162842},\n",
       " {'label': 'returning', 'score': 0.7736327648162842},\n",
       " {'label': 'returning', 'score': 0.7736327648162842},\n",
       " {'label': 'returning', 'score': 0.4336828589439392},\n",
       " {'label': 'returning', 'score': 0.4336828589439392},\n",
       " {'label': 'returning', 'score': 0.4336828589439392},\n",
       " {'label': 'returning', 'score': 0.7891677618026733},\n",
       " {'label': 'returning', 'score': 0.7891677618026733},\n",
       " {'label': 'returning', 'score': 0.7891677618026733},\n",
       " {'label': 'returning', 'score': 0.377736896276474},\n",
       " {'label': 'returning', 'score': 0.377736896276474},\n",
       " {'label': 'returning', 'score': 0.377736896276474},\n",
       " {'label': 'returning', 'score': 1.0359939336776733},\n",
       " {'label': 'returning', 'score': 1.0359939336776733},\n",
       " {'label': 'returning', 'score': 1.0359939336776733},\n",
       " {'label': 'returning', 'score': 0.6157241463661194},\n",
       " {'label': 'returning', 'score': 0.6157241463661194},\n",
       " {'label': 'returning', 'score': 0.6157241463661194},\n",
       " {'label': 'returning', 'score': 1.0945441722869873},\n",
       " {'label': 'returning', 'score': 1.0945441722869873},\n",
       " {'label': 'returning', 'score': 1.0945441722869873},\n",
       " {'label': 'none', 'score': 1.1346718072891235},\n",
       " {'label': 'none', 'score': 1.1346718072891235},\n",
       " {'label': 'none', 'score': 1.1346718072891235},\n",
       " {'label': 'none', 'score': 1.6776947975158691},\n",
       " {'label': 'none', 'score': 1.6776947975158691},\n",
       " {'label': 'none', 'score': 1.6776947975158691},\n",
       " {'label': 'none', 'score': 1.7810084819793701},\n",
       " {'label': 'none', 'score': 1.7810084819793701},\n",
       " {'label': 'none', 'score': 1.7810084819793701},\n",
       " {'label': 'none', 'score': 1.2292197942733765},\n",
       " {'label': 'none', 'score': 1.2292197942733765},\n",
       " {'label': 'none', 'score': 1.2292197942733765},\n",
       " {'label': 'none', 'score': 1.7146192789077759},\n",
       " {'label': 'none', 'score': 1.7146192789077759},\n",
       " {'label': 'none', 'score': 1.7146192789077759},\n",
       " {'label': 'none', 'score': 1.3176980018615723},\n",
       " {'label': 'none', 'score': 1.3176980018615723},\n",
       " {'label': 'none', 'score': 1.3176980018615723},\n",
       " {'label': 'none', 'score': 1.5848863124847412},\n",
       " {'label': 'none', 'score': 1.5848863124847412},\n",
       " {'label': 'none', 'score': 1.5848863124847412},\n",
       " {'label': 'none', 'score': 1.3383034467697144},\n",
       " {'label': 'none', 'score': 1.3383034467697144},\n",
       " {'label': 'none', 'score': 1.3383034467697144},\n",
       " {'label': 'none', 'score': 1.5610235929489136},\n",
       " {'label': 'none', 'score': 1.5610235929489136},\n",
       " {'label': 'none', 'score': 1.5610235929489136},\n",
       " {'label': 'none', 'score': 1.8777449131011963},\n",
       " {'label': 'none', 'score': 1.8777449131011963},\n",
       " {'label': 'none', 'score': 1.8777449131011963},\n",
       " {'label': 'none', 'score': 1.861535668373108},\n",
       " {'label': 'none', 'score': 1.861535668373108},\n",
       " {'label': 'none', 'score': 1.861535668373108},\n",
       " {'label': 'none', 'score': 1.181928038597107},\n",
       " {'label': 'none', 'score': 1.181928038597107},\n",
       " {'label': 'none', 'score': 1.181928038597107},\n",
       " {'label': 'none', 'score': 2.008514165878296},\n",
       " {'label': 'none', 'score': 2.008514165878296},\n",
       " {'label': 'none', 'score': 2.008514165878296},\n",
       " {'label': 'none', 'score': 1.6962065696716309},\n",
       " {'label': 'none', 'score': 1.6962065696716309},\n",
       " {'label': 'none', 'score': 1.6962065696716309},\n",
       " {'label': 'none', 'score': 2.062649965286255},\n",
       " {'label': 'none', 'score': 2.062649965286255},\n",
       " {'label': 'none', 'score': 2.062649965286255},\n",
       " {'label': 'returning', 'score': 0.5290771126747131},\n",
       " {'label': 'returning', 'score': 0.5290771126747131},\n",
       " {'label': 'returning', 'score': 0.5290771126747131},\n",
       " {'label': 'returning', 'score': 0.390095055103302},\n",
       " {'label': 'returning', 'score': 0.390095055103302},\n",
       " {'label': 'returning', 'score': 0.390095055103302},\n",
       " {'label': 'returning', 'score': 0.45481979846954346},\n",
       " {'label': 'returning', 'score': 0.45481979846954346},\n",
       " {'label': 'returning', 'score': 0.45481979846954346},\n",
       " {'label': 'returning', 'score': 0.479805052280426},\n",
       " {'label': 'returning', 'score': 0.479805052280426},\n",
       " {'label': 'returning', 'score': 0.479805052280426},\n",
       " {'label': 'returning', 'score': 0.3893675208091736},\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:30.083314Z",
     "start_time": "2020-05-01T02:29:30.069861Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " with open(os.path.join(results_path,'validation_results3.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:30.092897Z",
     "start_time": "2020-05-01T02:29:30.084351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:30.309305Z",
     "start_time": "2020-05-01T02:29:30.093875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - ~~More diverse dataset~~ (2020-04-01)\n",
    "    - Hyperparameter tuning (some improvement 2020-04-04)\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:29:31.545923Z",
     "start_time": "2020-05-01T02:29:30.312871Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/porta3.pth')\n",
    "torch.save(my_model, weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
