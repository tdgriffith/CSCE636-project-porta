{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:57:03.933457Z",
     "start_time": "2020-04-13T22:57:03.927099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:57:06.695221Z",
     "start_time": "2020-04-13T22:57:05.162547Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:57:12.633072Z",
     "start_time": "2020-04-13T22:57:09.661710Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:04.014355Z",
     "start_time": "2020-04-13T22:58:04.003790Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:05.605358Z",
     "start_time": "2020-04-13T22:58:05.596906Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:05.921013Z",
     "start_time": "2020-04-13T22:58:05.895588Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:06.293041Z",
     "start_time": "2020-04-13T22:58:06.258285Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:08.732441Z",
     "start_time": "2020-04-13T22:58:08.724637Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:09.977896Z",
     "start_time": "2020-04-13T22:58:09.621097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/191]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:10.582206Z",
     "start_time": "2020-04-13T22:58:10.573160Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:38.231161Z",
     "start_time": "2020-04-13T22:58:38.221953Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/val')\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:38.820808Z",
     "start_time": "2020-04-13T22:58:38.785520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/56]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:39.337150Z",
     "start_time": "2020-04-13T22:58:39.312326Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:41.446241Z",
     "start_time": "2020-04-13T22:58:40.742680Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:52.358580Z",
     "start_time": "2020-04-13T22:58:41.974301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:52.368662Z",
     "start_time": "2020-04-13T22:58:52.359723Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:58:56.604033Z",
     "start_time": "2020-04-13T22:58:56.583562Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 1200), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1200,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:59:19.971088Z",
     "start_time": "2020-04-13T22:59:19.942719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1200, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:59:25.103635Z",
     "start_time": "2020-04-13T22:59:25.093386Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-3,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T22:59:35.928381Z",
     "start_time": "2020-04-13T22:59:35.892442Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:04:34.661835Z",
     "start_time": "2020-04-13T22:59:36.850883Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/12]\tTime 2.423 (2.423)\tData 0.697 (0.697)\tLoss 1.1084 (1.1084)\tAcc 0.188 (0.188)\n",
      "Epoch: [1][2/12]\tTime 0.134 (1.279)\tData 0.101 (0.399)\tLoss 1.1002 (1.1043)\tAcc 0.250 (0.219)\n",
      "Epoch: [1][3/12]\tTime 0.090 (0.882)\tData 0.065 (0.288)\tLoss 1.0949 (1.1012)\tAcc 0.188 (0.208)\n",
      "Epoch: [1][4/12]\tTime 0.091 (0.684)\tData 0.064 (0.232)\tLoss 1.1113 (1.1037)\tAcc 0.250 (0.219)\n",
      "Epoch: [1][5/12]\tTime 0.081 (0.564)\tData 0.056 (0.196)\tLoss 1.0905 (1.1011)\tAcc 0.500 (0.275)\n",
      "Epoch: [1][6/12]\tTime 0.077 (0.483)\tData 0.052 (0.172)\tLoss 1.0600 (1.0942)\tAcc 0.812 (0.365)\n",
      "Epoch: [1][7/12]\tTime 0.077 (0.425)\tData 0.052 (0.155)\tLoss 1.0312 (1.0852)\tAcc 0.875 (0.438)\n",
      "Epoch: [1][8/12]\tTime 0.079 (0.381)\tData 0.054 (0.143)\tLoss 1.0886 (1.0857)\tAcc 0.500 (0.445)\n",
      "Epoch: [1][9/12]\tTime 0.077 (0.348)\tData 0.053 (0.133)\tLoss 1.0335 (1.0799)\tAcc 0.625 (0.465)\n",
      "Epoch: [1][10/12]\tTime 0.077 (0.320)\tData 0.053 (0.125)\tLoss 0.9545 (1.0673)\tAcc 0.875 (0.506)\n",
      "Epoch: [1][11/12]\tTime 0.080 (0.299)\tData 0.056 (0.119)\tLoss 0.9724 (1.0587)\tAcc 0.750 (0.528)\n",
      "Epoch: [1][12/12]\tTime 0.077 (0.280)\tData 0.054 (0.113)\tLoss 1.0110 (1.0550)\tAcc 0.533 (0.529)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/18]\tTime 0.303 (0.303)\tData 0.265 (0.265)\tLoss 0.9018 (0.9018)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/18]\tTime 0.064 (0.184)\tData 0.043 (0.154)\tLoss 1.0893 (0.9956)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/18]\tTime 0.083 (0.150)\tData 0.058 (0.122)\tLoss 0.9814 (0.9909)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/18]\tTime 0.085 (0.134)\tData 0.054 (0.105)\tLoss 0.9791 (0.9879)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/18]\tTime 0.069 (0.121)\tData 0.048 (0.094)\tLoss 0.9790 (0.9861)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/18]\tTime 0.082 (0.114)\tData 0.058 (0.088)\tLoss 0.8634 (0.9657)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/18]\tTime 0.077 (0.109)\tData 0.055 (0.083)\tLoss 0.9175 (0.9588)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/18]\tTime 0.077 (0.105)\tData 0.056 (0.080)\tLoss 1.0457 (0.9697)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/18]\tTime 0.076 (0.102)\tData 0.054 (0.077)\tLoss 0.8689 (0.9585)\tAcc 1.000 (0.757)\n",
      "Epoch: [1][10/18]\tTime 0.072 (0.099)\tData 0.051 (0.074)\tLoss 1.0965 (0.9723)\tAcc 0.375 (0.719)\n",
      "Epoch: [1][11/18]\tTime 0.073 (0.097)\tData 0.052 (0.072)\tLoss 1.1125 (0.9850)\tAcc 0.375 (0.688)\n",
      "Epoch: [1][12/18]\tTime 0.075 (0.095)\tData 0.055 (0.071)\tLoss 1.0285 (0.9886)\tAcc 0.562 (0.677)\n",
      "Epoch: [1][13/18]\tTime 0.074 (0.093)\tData 0.054 (0.070)\tLoss 1.1103 (0.9980)\tAcc 0.312 (0.649)\n",
      "Epoch: [1][14/18]\tTime 0.073 (0.092)\tData 0.053 (0.068)\tLoss 1.0101 (0.9989)\tAcc 0.625 (0.647)\n",
      "Epoch: [1][15/18]\tTime 0.077 (0.091)\tData 0.058 (0.068)\tLoss 1.0004 (0.9990)\tAcc 0.625 (0.646)\n",
      "Epoch: [1][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.067)\tLoss 1.0165 (1.0001)\tAcc 0.625 (0.645)\n",
      "Epoch: [1][17/18]\tTime 0.073 (0.089)\tData 0.054 (0.066)\tLoss 1.0120 (1.0008)\tAcc 0.625 (0.643)\n",
      "Epoch: [1][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.066)\tLoss 0.9914 (1.0005)\tAcc 0.625 (0.643)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/12]\tTime 0.376 (0.376)\tData 0.339 (0.339)\tLoss 0.9772 (0.9772)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][2/12]\tTime 0.075 (0.226)\tData 0.047 (0.193)\tLoss 0.9002 (0.9387)\tAcc 0.750 (0.719)\n",
      "Epoch: [2][3/12]\tTime 0.083 (0.178)\tData 0.057 (0.148)\tLoss 0.8797 (0.9190)\tAcc 0.750 (0.729)\n",
      "Epoch: [2][4/12]\tTime 0.090 (0.156)\tData 0.061 (0.126)\tLoss 1.0375 (0.9486)\tAcc 0.500 (0.672)\n",
      "Epoch: [2][5/12]\tTime 0.085 (0.142)\tData 0.058 (0.112)\tLoss 0.8634 (0.9316)\tAcc 0.688 (0.675)\n",
      "Epoch: [2][6/12]\tTime 0.084 (0.132)\tData 0.057 (0.103)\tLoss 0.8866 (0.9241)\tAcc 0.750 (0.688)\n",
      "Epoch: [2][7/12]\tTime 0.078 (0.124)\tData 0.053 (0.096)\tLoss 0.8850 (0.9185)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][8/12]\tTime 0.080 (0.119)\tData 0.056 (0.091)\tLoss 0.6090 (0.8798)\tAcc 0.938 (0.719)\n",
      "Epoch: [2][9/12]\tTime 0.085 (0.115)\tData 0.060 (0.088)\tLoss 1.0716 (0.9011)\tAcc 0.500 (0.694)\n",
      "Epoch: [2][10/12]\tTime 0.085 (0.112)\tData 0.061 (0.085)\tLoss 1.1120 (0.9222)\tAcc 0.500 (0.675)\n",
      "Epoch: [2][11/12]\tTime 0.091 (0.110)\tData 0.068 (0.083)\tLoss 0.7135 (0.9032)\tAcc 0.812 (0.688)\n",
      "Epoch: [2][12/12]\tTime 0.078 (0.107)\tData 0.055 (0.081)\tLoss 0.8912 (0.9023)\tAcc 0.667 (0.686)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/18]\tTime 0.273 (0.273)\tData 0.244 (0.244)\tLoss 0.5238 (0.5238)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/18]\tTime 0.079 (0.176)\tData 0.056 (0.150)\tLoss 1.1649 (0.8443)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/18]\tTime 0.080 (0.144)\tData 0.055 (0.119)\tLoss 0.8424 (0.8437)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/18]\tTime 0.085 (0.129)\tData 0.059 (0.104)\tLoss 0.8778 (0.8522)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/18]\tTime 0.075 (0.118)\tData 0.050 (0.093)\tLoss 0.8501 (0.8518)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/18]\tTime 0.071 (0.110)\tData 0.049 (0.086)\tLoss 0.4366 (0.7826)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/18]\tTime 0.077 (0.106)\tData 0.053 (0.081)\tLoss 0.6259 (0.7602)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/18]\tTime 0.083 (0.103)\tData 0.058 (0.078)\tLoss 1.0678 (0.7987)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/18]\tTime 0.084 (0.101)\tData 0.053 (0.075)\tLoss 0.4809 (0.7634)\tAcc 1.000 (0.757)\n",
      "Epoch: [2][10/18]\tTime 0.074 (0.098)\tData 0.053 (0.073)\tLoss 1.2384 (0.8109)\tAcc 0.375 (0.719)\n",
      "Epoch: [2][11/18]\tTime 0.079 (0.096)\tData 0.058 (0.072)\tLoss 1.2487 (0.8507)\tAcc 0.375 (0.688)\n",
      "Epoch: [2][12/18]\tTime 0.079 (0.095)\tData 0.059 (0.071)\tLoss 0.9936 (0.8626)\tAcc 0.562 (0.677)\n",
      "Epoch: [2][13/18]\tTime 0.075 (0.093)\tData 0.054 (0.070)\tLoss 1.2838 (0.8950)\tAcc 0.312 (0.649)\n",
      "Epoch: [2][14/18]\tTime 0.079 (0.092)\tData 0.059 (0.069)\tLoss 0.9396 (0.8982)\tAcc 0.625 (0.647)\n",
      "Epoch: [2][15/18]\tTime 0.080 (0.092)\tData 0.059 (0.068)\tLoss 0.8973 (0.8981)\tAcc 0.625 (0.646)\n",
      "Epoch: [2][16/18]\tTime 0.080 (0.091)\tData 0.059 (0.068)\tLoss 0.9643 (0.9023)\tAcc 0.625 (0.645)\n",
      "Epoch: [2][17/18]\tTime 0.073 (0.090)\tData 0.054 (0.067)\tLoss 0.9577 (0.9055)\tAcc 0.625 (0.643)\n",
      "Epoch: [2][18/18]\tTime 0.078 (0.089)\tData 0.058 (0.066)\tLoss 0.9517 (0.9068)\tAcc 0.625 (0.643)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/12]\tTime 0.428 (0.428)\tData 0.397 (0.397)\tLoss 0.8350 (0.8350)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][2/12]\tTime 0.075 (0.251)\tData 0.048 (0.223)\tLoss 0.7294 (0.7822)\tAcc 0.812 (0.750)\n",
      "Epoch: [3][3/12]\tTime 0.082 (0.195)\tData 0.056 (0.167)\tLoss 1.0354 (0.8666)\tAcc 0.562 (0.688)\n",
      "Epoch: [3][4/12]\tTime 0.085 (0.167)\tData 0.059 (0.140)\tLoss 0.7205 (0.8301)\tAcc 0.812 (0.719)\n",
      "Epoch: [3][5/12]\tTime 0.085 (0.151)\tData 0.059 (0.124)\tLoss 0.6303 (0.7901)\tAcc 0.812 (0.738)\n",
      "Epoch: [3][6/12]\tTime 0.086 (0.140)\tData 0.060 (0.113)\tLoss 0.8482 (0.7998)\tAcc 0.688 (0.729)\n",
      "Epoch: [3][7/12]\tTime 0.083 (0.132)\tData 0.059 (0.106)\tLoss 1.1741 (0.8533)\tAcc 0.500 (0.696)\n",
      "Epoch: [3][8/12]\tTime 0.081 (0.126)\tData 0.058 (0.100)\tLoss 0.7354 (0.8385)\tAcc 0.750 (0.703)\n",
      "Epoch: [3][9/12]\tTime 0.078 (0.120)\tData 0.055 (0.095)\tLoss 0.7738 (0.8313)\tAcc 0.688 (0.701)\n",
      "Epoch: [3][10/12]\tTime 0.077 (0.116)\tData 0.054 (0.091)\tLoss 0.8516 (0.8334)\tAcc 0.688 (0.700)\n",
      "Epoch: [3][11/12]\tTime 0.082 (0.113)\tData 0.058 (0.088)\tLoss 1.1132 (0.8588)\tAcc 0.500 (0.682)\n",
      "Epoch: [3][12/12]\tTime 0.085 (0.111)\tData 0.061 (0.085)\tLoss 0.7630 (0.8513)\tAcc 0.733 (0.686)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/18]\tTime 0.282 (0.282)\tData 0.258 (0.258)\tLoss 0.4180 (0.4180)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/18]\tTime 0.131 (0.206)\tData 0.107 (0.182)\tLoss 1.2304 (0.8242)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/18]\tTime 0.078 (0.163)\tData 0.055 (0.140)\tLoss 0.8733 (0.8406)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/18]\tTime 0.097 (0.147)\tData 0.057 (0.119)\tLoss 0.8328 (0.8386)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/18]\tTime 0.064 (0.130)\tData 0.041 (0.103)\tLoss 0.8094 (0.8328)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/18]\tTime 0.077 (0.122)\tData 0.056 (0.096)\tLoss 0.3329 (0.7495)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/18]\tTime 0.080 (0.116)\tData 0.058 (0.090)\tLoss 0.5404 (0.7196)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/18]\tTime 0.075 (0.110)\tData 0.053 (0.085)\tLoss 1.2151 (0.7815)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/18]\tTime 0.077 (0.107)\tData 0.055 (0.082)\tLoss 0.3517 (0.7338)\tAcc 1.000 (0.757)\n",
      "Epoch: [3][10/18]\tTime 0.079 (0.104)\tData 0.058 (0.080)\tLoss 1.3399 (0.7944)\tAcc 0.375 (0.719)\n",
      "Epoch: [3][11/18]\tTime 0.081 (0.102)\tData 0.058 (0.078)\tLoss 1.3298 (0.8431)\tAcc 0.375 (0.688)\n",
      "Epoch: [3][12/18]\tTime 0.078 (0.100)\tData 0.057 (0.076)\tLoss 1.1231 (0.8664)\tAcc 0.562 (0.677)\n",
      "Epoch: [3][13/18]\tTime 0.079 (0.098)\tData 0.057 (0.075)\tLoss 1.4989 (0.9151)\tAcc 0.312 (0.649)\n",
      "Epoch: [3][14/18]\tTime 0.078 (0.097)\tData 0.058 (0.073)\tLoss 0.9572 (0.9181)\tAcc 0.625 (0.647)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][15/18]\tTime 0.072 (0.095)\tData 0.053 (0.072)\tLoss 1.0201 (0.9249)\tAcc 0.625 (0.646)\n",
      "Epoch: [3][16/18]\tTime 0.074 (0.094)\tData 0.054 (0.071)\tLoss 0.9711 (0.9278)\tAcc 0.625 (0.645)\n",
      "Epoch: [3][17/18]\tTime 0.076 (0.093)\tData 0.056 (0.070)\tLoss 0.9659 (0.9300)\tAcc 0.625 (0.643)\n",
      "Epoch: [3][18/18]\tTime 0.079 (0.092)\tData 0.059 (0.069)\tLoss 1.0016 (0.9321)\tAcc 0.625 (0.643)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/12]\tTime 0.350 (0.350)\tData 0.320 (0.320)\tLoss 1.0777 (1.0777)\tAcc 0.562 (0.562)\n",
      "Epoch: [4][2/12]\tTime 0.076 (0.213)\tData 0.049 (0.184)\tLoss 0.8108 (0.9443)\tAcc 0.750 (0.656)\n",
      "Epoch: [4][3/12]\tTime 0.083 (0.170)\tData 0.055 (0.141)\tLoss 1.0000 (0.9628)\tAcc 0.625 (0.646)\n",
      "Epoch: [4][4/12]\tTime 0.084 (0.148)\tData 0.058 (0.120)\tLoss 0.9183 (0.9517)\tAcc 0.625 (0.641)\n",
      "Epoch: [4][5/12]\tTime 0.086 (0.136)\tData 0.060 (0.108)\tLoss 0.7067 (0.9027)\tAcc 0.812 (0.675)\n",
      "Epoch: [4][6/12]\tTime 0.086 (0.127)\tData 0.058 (0.100)\tLoss 0.9170 (0.9051)\tAcc 0.688 (0.677)\n",
      "Epoch: [4][7/12]\tTime 0.083 (0.121)\tData 0.058 (0.094)\tLoss 0.4905 (0.8459)\tAcc 0.938 (0.714)\n",
      "Epoch: [4][8/12]\tTime 0.081 (0.116)\tData 0.057 (0.089)\tLoss 1.1599 (0.8851)\tAcc 0.438 (0.680)\n",
      "Epoch: [4][9/12]\tTime 0.080 (0.112)\tData 0.056 (0.086)\tLoss 0.6809 (0.8624)\tAcc 0.750 (0.688)\n",
      "Epoch: [4][10/12]\tTime 0.084 (0.109)\tData 0.060 (0.083)\tLoss 0.9418 (0.8704)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][11/12]\tTime 0.085 (0.107)\tData 0.061 (0.081)\tLoss 0.8788 (0.8711)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][12/12]\tTime 0.085 (0.105)\tData 0.061 (0.079)\tLoss 0.8876 (0.8724)\tAcc 0.667 (0.686)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/18]\tTime 0.316 (0.316)\tData 0.286 (0.286)\tLoss 0.5084 (0.5084)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/18]\tTime 0.075 (0.196)\tData 0.050 (0.168)\tLoss 1.1686 (0.8385)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/18]\tTime 0.083 (0.158)\tData 0.057 (0.131)\tLoss 0.8610 (0.8460)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/18]\tTime 0.084 (0.140)\tData 0.058 (0.113)\tLoss 0.8555 (0.8484)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/18]\tTime 0.076 (0.127)\tData 0.052 (0.101)\tLoss 0.8213 (0.8430)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/18]\tTime 0.077 (0.119)\tData 0.055 (0.093)\tLoss 0.4269 (0.7736)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/18]\tTime 0.074 (0.112)\tData 0.052 (0.087)\tLoss 0.5976 (0.7485)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/18]\tTime 0.077 (0.108)\tData 0.054 (0.083)\tLoss 1.0856 (0.7906)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/18]\tTime 0.081 (0.105)\tData 0.058 (0.080)\tLoss 0.3860 (0.7457)\tAcc 1.000 (0.757)\n",
      "Epoch: [4][10/18]\tTime 0.078 (0.102)\tData 0.057 (0.078)\tLoss 1.2442 (0.7955)\tAcc 0.375 (0.719)\n",
      "Epoch: [4][11/18]\tTime 0.081 (0.100)\tData 0.058 (0.076)\tLoss 1.2732 (0.8389)\tAcc 0.375 (0.688)\n",
      "Epoch: [4][12/18]\tTime 0.077 (0.098)\tData 0.056 (0.075)\tLoss 1.0424 (0.8559)\tAcc 0.562 (0.677)\n",
      "Epoch: [4][13/18]\tTime 0.077 (0.097)\tData 0.058 (0.073)\tLoss 1.2905 (0.8893)\tAcc 0.312 (0.649)\n",
      "Epoch: [4][14/18]\tTime 0.074 (0.095)\tData 0.053 (0.072)\tLoss 0.8769 (0.8884)\tAcc 0.625 (0.647)\n",
      "Epoch: [4][15/18]\tTime 0.074 (0.094)\tData 0.054 (0.071)\tLoss 0.9381 (0.8917)\tAcc 0.625 (0.646)\n",
      "Epoch: [4][16/18]\tTime 0.078 (0.093)\tData 0.058 (0.070)\tLoss 0.9644 (0.8963)\tAcc 0.625 (0.645)\n",
      "Epoch: [4][17/18]\tTime 0.081 (0.092)\tData 0.059 (0.069)\tLoss 0.8999 (0.8965)\tAcc 0.625 (0.643)\n",
      "Epoch: [4][18/18]\tTime 0.079 (0.091)\tData 0.058 (0.069)\tLoss 0.9435 (0.8978)\tAcc 0.625 (0.643)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/12]\tTime 0.339 (0.339)\tData 0.306 (0.306)\tLoss 1.1332 (1.1332)\tAcc 0.500 (0.500)\n",
      "Epoch: [5][2/12]\tTime 0.080 (0.209)\tData 0.052 (0.179)\tLoss 0.9663 (1.0498)\tAcc 0.625 (0.562)\n",
      "Epoch: [5][3/12]\tTime 0.084 (0.168)\tData 0.057 (0.138)\tLoss 0.6202 (0.9066)\tAcc 0.875 (0.667)\n",
      "Epoch: [5][4/12]\tTime 0.085 (0.147)\tData 0.058 (0.118)\tLoss 0.7114 (0.8578)\tAcc 0.812 (0.703)\n",
      "Epoch: [5][5/12]\tTime 0.085 (0.135)\tData 0.058 (0.106)\tLoss 0.9820 (0.8826)\tAcc 0.562 (0.675)\n",
      "Epoch: [5][6/12]\tTime 0.085 (0.126)\tData 0.059 (0.098)\tLoss 0.5617 (0.8291)\tAcc 0.938 (0.719)\n",
      "Epoch: [5][7/12]\tTime 0.078 (0.119)\tData 0.054 (0.092)\tLoss 0.7915 (0.8238)\tAcc 0.750 (0.723)\n",
      "Epoch: [5][8/12]\tTime 0.080 (0.115)\tData 0.056 (0.088)\tLoss 1.1071 (0.8592)\tAcc 0.500 (0.695)\n",
      "Epoch: [5][9/12]\tTime 0.084 (0.111)\tData 0.059 (0.084)\tLoss 0.7649 (0.8487)\tAcc 0.750 (0.701)\n",
      "Epoch: [5][10/12]\tTime 0.084 (0.108)\tData 0.059 (0.082)\tLoss 1.0490 (0.8687)\tAcc 0.500 (0.681)\n",
      "Epoch: [5][11/12]\tTime 0.085 (0.106)\tData 0.061 (0.080)\tLoss 0.8144 (0.8638)\tAcc 0.688 (0.682)\n",
      "Epoch: [5][12/12]\tTime 0.085 (0.105)\tData 0.061 (0.078)\tLoss 0.7246 (0.8529)\tAcc 0.733 (0.686)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/18]\tTime 0.284 (0.284)\tData 0.247 (0.247)\tLoss 0.5127 (0.5127)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/18]\tTime 0.066 (0.175)\tData 0.044 (0.146)\tLoss 1.1473 (0.8300)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/18]\tTime 0.078 (0.143)\tData 0.056 (0.116)\tLoss 0.8680 (0.8427)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/18]\tTime 0.084 (0.128)\tData 0.057 (0.101)\tLoss 0.8442 (0.8431)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/18]\tTime 0.074 (0.117)\tData 0.053 (0.092)\tLoss 0.8617 (0.8468)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/18]\tTime 0.075 (0.110)\tData 0.053 (0.085)\tLoss 0.4302 (0.7774)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/18]\tTime 0.081 (0.106)\tData 0.056 (0.081)\tLoss 0.6042 (0.7526)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/18]\tTime 0.080 (0.103)\tData 0.059 (0.078)\tLoss 1.1071 (0.7969)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/18]\tTime 0.080 (0.100)\tData 0.058 (0.076)\tLoss 0.3983 (0.7526)\tAcc 1.000 (0.757)\n",
      "Epoch: [5][10/18]\tTime 0.078 (0.098)\tData 0.057 (0.074)\tLoss 1.3251 (0.8099)\tAcc 0.375 (0.719)\n",
      "Epoch: [5][11/18]\tTime 0.080 (0.096)\tData 0.060 (0.073)\tLoss 1.2435 (0.8493)\tAcc 0.375 (0.688)\n",
      "Epoch: [5][12/18]\tTime 0.079 (0.095)\tData 0.058 (0.072)\tLoss 1.0227 (0.8638)\tAcc 0.562 (0.677)\n",
      "Epoch: [5][13/18]\tTime 0.073 (0.093)\tData 0.053 (0.070)\tLoss 1.3448 (0.9008)\tAcc 0.312 (0.649)\n",
      "Epoch: [5][14/18]\tTime 0.079 (0.092)\tData 0.059 (0.069)\tLoss 0.9139 (0.9017)\tAcc 0.625 (0.647)\n",
      "Epoch: [5][15/18]\tTime 0.079 (0.091)\tData 0.059 (0.069)\tLoss 0.9431 (0.9045)\tAcc 0.625 (0.646)\n",
      "Epoch: [5][16/18]\tTime 0.080 (0.091)\tData 0.060 (0.068)\tLoss 0.8882 (0.9034)\tAcc 0.625 (0.645)\n",
      "Epoch: [5][17/18]\tTime 0.080 (0.090)\tData 0.059 (0.068)\tLoss 0.9406 (0.9056)\tAcc 0.625 (0.643)\n",
      "Epoch: [5][18/18]\tTime 0.079 (0.089)\tData 0.060 (0.067)\tLoss 0.9581 (0.9071)\tAcc 0.625 (0.643)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/12]\tTime 0.342 (0.342)\tData 0.308 (0.308)\tLoss 0.6634 (0.6634)\tAcc 0.812 (0.812)\n",
      "Epoch: [6][2/12]\tTime 0.071 (0.207)\tData 0.045 (0.177)\tLoss 1.0089 (0.8361)\tAcc 0.500 (0.656)\n",
      "Epoch: [6][3/12]\tTime 0.077 (0.163)\tData 0.052 (0.135)\tLoss 0.7670 (0.8131)\tAcc 0.750 (0.688)\n",
      "Epoch: [6][4/12]\tTime 0.079 (0.142)\tData 0.053 (0.114)\tLoss 1.0552 (0.8736)\tAcc 0.500 (0.641)\n",
      "Epoch: [6][5/12]\tTime 0.085 (0.131)\tData 0.054 (0.102)\tLoss 1.0524 (0.9094)\tAcc 0.562 (0.625)\n",
      "Epoch: [6][6/12]\tTime 0.083 (0.123)\tData 0.054 (0.094)\tLoss 0.8340 (0.8968)\tAcc 0.688 (0.635)\n",
      "Epoch: [6][7/12]\tTime 0.082 (0.117)\tData 0.058 (0.089)\tLoss 0.8517 (0.8904)\tAcc 0.688 (0.643)\n",
      "Epoch: [6][8/12]\tTime 0.085 (0.113)\tData 0.061 (0.086)\tLoss 0.7162 (0.8686)\tAcc 0.750 (0.656)\n",
      "Epoch: [6][9/12]\tTime 0.085 (0.110)\tData 0.062 (0.083)\tLoss 0.7581 (0.8563)\tAcc 0.750 (0.667)\n",
      "Epoch: [6][10/12]\tTime 0.079 (0.107)\tData 0.056 (0.080)\tLoss 0.5791 (0.8286)\tAcc 0.875 (0.688)\n",
      "Epoch: [6][11/12]\tTime 0.083 (0.105)\tData 0.057 (0.078)\tLoss 0.5466 (0.8030)\tAcc 0.875 (0.705)\n",
      "Epoch: [6][12/12]\tTime 0.077 (0.102)\tData 0.053 (0.076)\tLoss 1.1356 (0.8291)\tAcc 0.467 (0.686)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/18]\tTime 0.342 (0.342)\tData 0.308 (0.308)\tLoss 0.4748 (0.4748)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/18]\tTime 0.066 (0.204)\tData 0.041 (0.174)\tLoss 1.1943 (0.8346)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/18]\tTime 0.073 (0.160)\tData 0.049 (0.133)\tLoss 0.8112 (0.8268)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/18]\tTime 0.071 (0.138)\tData 0.050 (0.112)\tLoss 0.8432 (0.8309)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/18]\tTime 0.074 (0.125)\tData 0.053 (0.100)\tLoss 0.8244 (0.8296)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/18]\tTime 0.074 (0.116)\tData 0.053 (0.092)\tLoss 0.3729 (0.7535)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/18]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.5306 (0.7216)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/18]\tTime 0.074 (0.106)\tData 0.054 (0.083)\tLoss 1.0831 (0.7668)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/18]\tTime 0.074 (0.102)\tData 0.053 (0.079)\tLoss 0.3329 (0.7186)\tAcc 1.000 (0.757)\n",
      "Epoch: [6][10/18]\tTime 0.075 (0.099)\tData 0.053 (0.077)\tLoss 1.3429 (0.7810)\tAcc 0.375 (0.719)\n",
      "Epoch: [6][11/18]\tTime 0.071 (0.097)\tData 0.052 (0.074)\tLoss 1.3404 (0.8319)\tAcc 0.375 (0.688)\n",
      "Epoch: [6][12/18]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 1.0906 (0.8534)\tAcc 0.562 (0.677)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][13/18]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 1.4312 (0.8979)\tAcc 0.312 (0.649)\n",
      "Epoch: [6][14/18]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.9330 (0.9004)\tAcc 0.625 (0.647)\n",
      "Epoch: [6][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.9901 (0.9064)\tAcc 0.625 (0.646)\n",
      "Epoch: [6][16/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 1.0332 (0.9143)\tAcc 0.625 (0.645)\n",
      "Epoch: [6][17/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.9581 (0.9169)\tAcc 0.625 (0.643)\n",
      "Epoch: [6][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.9174 (0.9169)\tAcc 0.625 (0.643)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/12]\tTime 0.316 (0.316)\tData 0.280 (0.280)\tLoss 0.6894 (0.6894)\tAcc 0.812 (0.812)\n",
      "Epoch: [7][2/12]\tTime 0.071 (0.193)\tData 0.044 (0.162)\tLoss 0.8508 (0.7701)\tAcc 0.688 (0.750)\n",
      "Epoch: [7][3/12]\tTime 0.079 (0.155)\tData 0.052 (0.125)\tLoss 0.9552 (0.8318)\tAcc 0.625 (0.708)\n",
      "Epoch: [7][4/12]\tTime 0.088 (0.138)\tData 0.057 (0.108)\tLoss 0.7608 (0.8141)\tAcc 0.750 (0.719)\n",
      "Epoch: [7][5/12]\tTime 0.090 (0.129)\tData 0.055 (0.098)\tLoss 0.5709 (0.7654)\tAcc 0.875 (0.750)\n",
      "Epoch: [7][6/12]\tTime 0.078 (0.120)\tData 0.052 (0.090)\tLoss 0.6757 (0.7505)\tAcc 0.812 (0.760)\n",
      "Epoch: [7][7/12]\tTime 0.087 (0.115)\tData 0.061 (0.086)\tLoss 0.6487 (0.7359)\tAcc 0.812 (0.768)\n",
      "Epoch: [7][8/12]\tTime 0.083 (0.111)\tData 0.059 (0.083)\tLoss 1.4451 (0.8246)\tAcc 0.375 (0.719)\n",
      "Epoch: [7][9/12]\tTime 0.083 (0.108)\tData 0.059 (0.080)\tLoss 0.9286 (0.8361)\tAcc 0.625 (0.708)\n",
      "Epoch: [7][10/12]\tTime 0.083 (0.106)\tData 0.059 (0.078)\tLoss 0.8271 (0.8352)\tAcc 0.688 (0.706)\n",
      "Epoch: [7][11/12]\tTime 0.085 (0.104)\tData 0.061 (0.076)\tLoss 1.1851 (0.8670)\tAcc 0.438 (0.682)\n",
      "Epoch: [7][12/12]\tTime 0.085 (0.102)\tData 0.061 (0.075)\tLoss 0.7448 (0.8575)\tAcc 0.733 (0.686)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/18]\tTime 0.403 (0.403)\tData 0.376 (0.376)\tLoss 0.4763 (0.4763)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/18]\tTime 0.074 (0.238)\tData 0.052 (0.214)\tLoss 1.2005 (0.8384)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/18]\tTime 0.074 (0.184)\tData 0.053 (0.160)\tLoss 0.8196 (0.8321)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/18]\tTime 0.074 (0.156)\tData 0.053 (0.134)\tLoss 0.7809 (0.8193)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/18]\tTime 0.076 (0.140)\tData 0.053 (0.117)\tLoss 0.8704 (0.8295)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/18]\tTime 0.080 (0.130)\tData 0.058 (0.108)\tLoss 0.3868 (0.7557)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/18]\tTime 0.080 (0.123)\tData 0.058 (0.101)\tLoss 0.5687 (0.7290)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/18]\tTime 0.081 (0.118)\tData 0.059 (0.095)\tLoss 1.1044 (0.7759)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/18]\tTime 0.081 (0.113)\tData 0.059 (0.091)\tLoss 0.3340 (0.7268)\tAcc 1.000 (0.757)\n",
      "Epoch: [7][10/18]\tTime 0.080 (0.110)\tData 0.059 (0.088)\tLoss 1.3863 (0.7928)\tAcc 0.375 (0.719)\n",
      "Epoch: [7][11/18]\tTime 0.078 (0.107)\tData 0.057 (0.085)\tLoss 1.3179 (0.8405)\tAcc 0.375 (0.688)\n",
      "Epoch: [7][12/18]\tTime 0.079 (0.105)\tData 0.059 (0.083)\tLoss 1.0554 (0.8584)\tAcc 0.562 (0.677)\n",
      "Epoch: [7][13/18]\tTime 0.081 (0.103)\tData 0.060 (0.081)\tLoss 1.4171 (0.9014)\tAcc 0.312 (0.649)\n",
      "Epoch: [7][14/18]\tTime 0.080 (0.101)\tData 0.058 (0.080)\tLoss 0.9276 (0.9033)\tAcc 0.625 (0.647)\n",
      "Epoch: [7][15/18]\tTime 0.072 (0.099)\tData 0.053 (0.078)\tLoss 0.9487 (0.9063)\tAcc 0.625 (0.646)\n",
      "Epoch: [7][16/18]\tTime 0.073 (0.098)\tData 0.054 (0.076)\tLoss 0.8686 (0.9039)\tAcc 0.625 (0.645)\n",
      "Epoch: [7][17/18]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.9422 (0.9062)\tAcc 0.625 (0.643)\n",
      "Epoch: [7][18/18]\tTime 0.078 (0.095)\tData 0.059 (0.074)\tLoss 0.9571 (0.9077)\tAcc 0.625 (0.643)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/12]\tTime 0.367 (0.367)\tData 0.331 (0.331)\tLoss 0.6290 (0.6290)\tAcc 0.812 (0.812)\n",
      "Epoch: [8][2/12]\tTime 0.081 (0.224)\tData 0.051 (0.191)\tLoss 0.6168 (0.6229)\tAcc 0.812 (0.812)\n",
      "Epoch: [8][3/12]\tTime 0.083 (0.177)\tData 0.055 (0.146)\tLoss 0.9279 (0.7246)\tAcc 0.625 (0.750)\n",
      "Epoch: [8][4/12]\tTime 0.095 (0.157)\tData 0.059 (0.124)\tLoss 0.7058 (0.7199)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][5/12]\tTime 0.083 (0.142)\tData 0.057 (0.111)\tLoss 0.7013 (0.7162)\tAcc 0.812 (0.762)\n",
      "Epoch: [8][6/12]\tTime 0.079 (0.131)\tData 0.054 (0.101)\tLoss 0.9251 (0.7510)\tAcc 0.625 (0.740)\n",
      "Epoch: [8][7/12]\tTime 0.078 (0.124)\tData 0.054 (0.095)\tLoss 1.1826 (0.8127)\tAcc 0.438 (0.696)\n",
      "Epoch: [8][8/12]\tTime 0.081 (0.118)\tData 0.056 (0.090)\tLoss 0.7260 (0.8018)\tAcc 0.750 (0.703)\n",
      "Epoch: [8][9/12]\tTime 0.077 (0.114)\tData 0.054 (0.086)\tLoss 0.9376 (0.8169)\tAcc 0.625 (0.694)\n",
      "Epoch: [8][10/12]\tTime 0.078 (0.110)\tData 0.054 (0.083)\tLoss 0.8529 (0.8205)\tAcc 0.625 (0.688)\n",
      "Epoch: [8][11/12]\tTime 0.081 (0.108)\tData 0.056 (0.080)\tLoss 0.9236 (0.8299)\tAcc 0.625 (0.682)\n",
      "Epoch: [8][12/12]\tTime 0.077 (0.105)\tData 0.054 (0.078)\tLoss 0.7570 (0.8242)\tAcc 0.733 (0.686)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/18]\tTime 0.297 (0.297)\tData 0.271 (0.271)\tLoss 0.4968 (0.4968)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/18]\tTime 0.070 (0.184)\tData 0.048 (0.160)\tLoss 1.1339 (0.8154)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/18]\tTime 0.074 (0.147)\tData 0.052 (0.124)\tLoss 0.7693 (0.8000)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/18]\tTime 0.075 (0.129)\tData 0.053 (0.106)\tLoss 0.8034 (0.8009)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/18]\tTime 0.073 (0.118)\tData 0.051 (0.095)\tLoss 0.8573 (0.8121)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/18]\tTime 0.074 (0.111)\tData 0.053 (0.088)\tLoss 0.4318 (0.7488)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/18]\tTime 0.075 (0.105)\tData 0.052 (0.083)\tLoss 0.5970 (0.7271)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/18]\tTime 0.074 (0.102)\tData 0.051 (0.079)\tLoss 1.0703 (0.7700)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/18]\tTime 0.073 (0.098)\tData 0.051 (0.076)\tLoss 0.3909 (0.7279)\tAcc 1.000 (0.757)\n",
      "Epoch: [8][10/18]\tTime 0.073 (0.096)\tData 0.052 (0.074)\tLoss 1.2784 (0.7829)\tAcc 0.375 (0.719)\n",
      "Epoch: [8][11/18]\tTime 0.080 (0.094)\tData 0.056 (0.072)\tLoss 1.2622 (0.8265)\tAcc 0.375 (0.688)\n",
      "Epoch: [8][12/18]\tTime 0.072 (0.092)\tData 0.052 (0.070)\tLoss 0.9365 (0.8356)\tAcc 0.562 (0.677)\n",
      "Epoch: [8][13/18]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 1.2028 (0.8639)\tAcc 0.312 (0.649)\n",
      "Epoch: [8][14/18]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.9233 (0.8681)\tAcc 0.625 (0.647)\n",
      "Epoch: [8][15/18]\tTime 0.080 (0.089)\tData 0.059 (0.067)\tLoss 0.9641 (0.8745)\tAcc 0.625 (0.646)\n",
      "Epoch: [8][16/18]\tTime 0.072 (0.088)\tData 0.053 (0.066)\tLoss 0.9060 (0.8765)\tAcc 0.625 (0.645)\n",
      "Epoch: [8][17/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.9031 (0.8781)\tAcc 0.625 (0.643)\n",
      "Epoch: [8][18/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 0.8937 (0.8785)\tAcc 0.625 (0.643)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/12]\tTime 0.333 (0.333)\tData 0.303 (0.303)\tLoss 0.8628 (0.8628)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][2/12]\tTime 0.076 (0.204)\tData 0.049 (0.176)\tLoss 0.7530 (0.8079)\tAcc 0.750 (0.719)\n",
      "Epoch: [9][3/12]\tTime 0.078 (0.162)\tData 0.052 (0.135)\tLoss 0.7927 (0.8028)\tAcc 0.688 (0.708)\n",
      "Epoch: [9][4/12]\tTime 0.077 (0.141)\tData 0.051 (0.114)\tLoss 0.9552 (0.8409)\tAcc 0.562 (0.672)\n",
      "Epoch: [9][5/12]\tTime 0.081 (0.129)\tData 0.054 (0.102)\tLoss 0.9492 (0.8626)\tAcc 0.562 (0.650)\n",
      "Epoch: [9][6/12]\tTime 0.078 (0.120)\tData 0.052 (0.094)\tLoss 0.7820 (0.8492)\tAcc 0.688 (0.656)\n",
      "Epoch: [9][7/12]\tTime 0.080 (0.115)\tData 0.052 (0.088)\tLoss 0.5169 (0.8017)\tAcc 0.938 (0.696)\n",
      "Epoch: [9][8/12]\tTime 0.078 (0.110)\tData 0.053 (0.083)\tLoss 0.8376 (0.8062)\tAcc 0.688 (0.695)\n",
      "Epoch: [9][9/12]\tTime 0.077 (0.106)\tData 0.054 (0.080)\tLoss 0.8548 (0.8116)\tAcc 0.625 (0.688)\n",
      "Epoch: [9][10/12]\tTime 0.077 (0.103)\tData 0.054 (0.078)\tLoss 0.7363 (0.8041)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][11/12]\tTime 0.081 (0.101)\tData 0.057 (0.076)\tLoss 0.8042 (0.8041)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][12/12]\tTime 0.078 (0.099)\tData 0.054 (0.074)\tLoss 0.8241 (0.8056)\tAcc 0.667 (0.686)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/18]\tTime 0.329 (0.329)\tData 0.305 (0.305)\tLoss 0.4562 (0.4562)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/18]\tTime 0.071 (0.200)\tData 0.051 (0.178)\tLoss 1.1136 (0.7849)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/18]\tTime 0.075 (0.158)\tData 0.053 (0.136)\tLoss 0.6807 (0.7502)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/18]\tTime 0.074 (0.137)\tData 0.051 (0.115)\tLoss 0.8033 (0.7635)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/18]\tTime 0.073 (0.125)\tData 0.052 (0.102)\tLoss 0.8373 (0.7782)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/18]\tTime 0.075 (0.116)\tData 0.053 (0.094)\tLoss 0.3810 (0.7120)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/18]\tTime 0.074 (0.110)\tData 0.051 (0.088)\tLoss 0.6101 (0.6975)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/18]\tTime 0.077 (0.106)\tData 0.052 (0.084)\tLoss 1.0721 (0.7443)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/18]\tTime 0.072 (0.102)\tData 0.050 (0.080)\tLoss 0.3002 (0.6950)\tAcc 1.000 (0.757)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][10/18]\tTime 0.074 (0.099)\tData 0.053 (0.077)\tLoss 1.2971 (0.7552)\tAcc 0.375 (0.719)\n",
      "Epoch: [9][11/18]\tTime 0.075 (0.097)\tData 0.053 (0.075)\tLoss 1.2295 (0.7983)\tAcc 0.375 (0.688)\n",
      "Epoch: [9][12/18]\tTime 0.073 (0.095)\tData 0.052 (0.073)\tLoss 0.9545 (0.8113)\tAcc 0.562 (0.677)\n",
      "Epoch: [9][13/18]\tTime 0.073 (0.093)\tData 0.053 (0.072)\tLoss 1.2890 (0.8481)\tAcc 0.312 (0.649)\n",
      "Epoch: [9][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9181 (0.8531)\tAcc 0.625 (0.647)\n",
      "Epoch: [9][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.9012 (0.8563)\tAcc 0.625 (0.646)\n",
      "Epoch: [9][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.8895 (0.8583)\tAcc 0.625 (0.645)\n",
      "Epoch: [9][17/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.9343 (0.8628)\tAcc 0.625 (0.643)\n",
      "Epoch: [9][18/18]\tTime 0.073 (0.088)\tData 0.053 (0.067)\tLoss 0.8062 (0.8612)\tAcc 0.625 (0.643)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/12]\tTime 0.298 (0.298)\tData 0.267 (0.267)\tLoss 0.6825 (0.6825)\tAcc 0.750 (0.750)\n",
      "Epoch: [10][2/12]\tTime 0.074 (0.186)\tData 0.048 (0.158)\tLoss 0.7503 (0.7164)\tAcc 0.688 (0.719)\n",
      "Epoch: [10][3/12]\tTime 0.080 (0.151)\tData 0.052 (0.123)\tLoss 0.8585 (0.7637)\tAcc 0.625 (0.688)\n",
      "Epoch: [10][4/12]\tTime 0.080 (0.133)\tData 0.051 (0.105)\tLoss 0.8083 (0.7749)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/12]\tTime 0.076 (0.122)\tData 0.050 (0.094)\tLoss 0.8437 (0.7887)\tAcc 0.625 (0.675)\n",
      "Epoch: [10][6/12]\tTime 0.077 (0.114)\tData 0.052 (0.087)\tLoss 0.6814 (0.7708)\tAcc 0.750 (0.688)\n",
      "Epoch: [10][7/12]\tTime 0.079 (0.109)\tData 0.053 (0.082)\tLoss 0.9004 (0.7893)\tAcc 0.625 (0.679)\n",
      "Epoch: [10][8/12]\tTime 0.077 (0.105)\tData 0.053 (0.078)\tLoss 0.9466 (0.8090)\tAcc 0.562 (0.664)\n",
      "Epoch: [10][9/12]\tTime 0.077 (0.102)\tData 0.053 (0.075)\tLoss 0.7302 (0.8002)\tAcc 0.750 (0.674)\n",
      "Epoch: [10][10/12]\tTime 0.078 (0.100)\tData 0.054 (0.073)\tLoss 0.4726 (0.7674)\tAcc 0.875 (0.694)\n",
      "Epoch: [10][11/12]\tTime 0.079 (0.098)\tData 0.055 (0.072)\tLoss 0.8091 (0.7712)\tAcc 0.688 (0.693)\n",
      "Epoch: [10][12/12]\tTime 0.077 (0.096)\tData 0.054 (0.070)\tLoss 0.9485 (0.7852)\tAcc 0.600 (0.686)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/18]\tTime 0.335 (0.335)\tData 0.311 (0.311)\tLoss 0.3432 (0.3432)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/18]\tTime 0.071 (0.203)\tData 0.050 (0.180)\tLoss 1.0464 (0.6948)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/18]\tTime 0.074 (0.160)\tData 0.052 (0.138)\tLoss 0.6805 (0.6900)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/18]\tTime 0.075 (0.139)\tData 0.053 (0.116)\tLoss 0.7395 (0.7024)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/18]\tTime 0.073 (0.126)\tData 0.052 (0.104)\tLoss 0.8808 (0.7381)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/18]\tTime 0.074 (0.117)\tData 0.053 (0.095)\tLoss 0.3186 (0.6682)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/18]\tTime 0.074 (0.111)\tData 0.053 (0.089)\tLoss 0.5425 (0.6502)\tAcc 0.875 (0.759)\n",
      "Epoch: [10][8/18]\tTime 0.073 (0.106)\tData 0.053 (0.085)\tLoss 1.0367 (0.6985)\tAcc 0.500 (0.727)\n",
      "Epoch: [10][9/18]\tTime 0.075 (0.103)\tData 0.053 (0.081)\tLoss 0.2532 (0.6490)\tAcc 1.000 (0.757)\n",
      "Epoch: [10][10/18]\tTime 0.073 (0.100)\tData 0.052 (0.078)\tLoss 1.3307 (0.7172)\tAcc 0.375 (0.719)\n",
      "Epoch: [10][11/18]\tTime 0.075 (0.097)\tData 0.053 (0.076)\tLoss 1.3001 (0.7702)\tAcc 0.375 (0.688)\n",
      "Epoch: [10][12/18]\tTime 0.072 (0.095)\tData 0.052 (0.074)\tLoss 1.0998 (0.7977)\tAcc 0.562 (0.677)\n",
      "Epoch: [10][13/18]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 1.3271 (0.8384)\tAcc 0.312 (0.649)\n",
      "Epoch: [10][14/18]\tTime 0.075 (0.092)\tData 0.054 (0.071)\tLoss 0.8464 (0.8390)\tAcc 0.625 (0.647)\n",
      "Epoch: [10][15/18]\tTime 0.072 (0.091)\tData 0.053 (0.070)\tLoss 0.9492 (0.8463)\tAcc 0.625 (0.646)\n",
      "Epoch: [10][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.8843 (0.8487)\tAcc 0.625 (0.645)\n",
      "Epoch: [10][17/18]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.8707 (0.8500)\tAcc 0.625 (0.643)\n",
      "Epoch: [10][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.7993 (0.8485)\tAcc 0.625 (0.643)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/12]\tTime 0.298 (0.298)\tData 0.268 (0.268)\tLoss 0.9359 (0.9359)\tAcc 0.625 (0.625)\n",
      "Epoch: [11][2/12]\tTime 0.077 (0.188)\tData 0.051 (0.160)\tLoss 0.8549 (0.8954)\tAcc 0.688 (0.656)\n",
      "Epoch: [11][3/12]\tTime 0.078 (0.151)\tData 0.052 (0.124)\tLoss 0.8607 (0.8839)\tAcc 0.625 (0.646)\n",
      "Epoch: [11][4/12]\tTime 0.083 (0.134)\tData 0.054 (0.106)\tLoss 0.9016 (0.8883)\tAcc 0.625 (0.641)\n",
      "Epoch: [11][5/12]\tTime 0.076 (0.123)\tData 0.050 (0.095)\tLoss 0.6246 (0.8356)\tAcc 0.812 (0.675)\n",
      "Epoch: [11][6/12]\tTime 0.078 (0.115)\tData 0.052 (0.088)\tLoss 0.6663 (0.8073)\tAcc 0.750 (0.688)\n",
      "Epoch: [11][7/12]\tTime 0.080 (0.110)\tData 0.052 (0.083)\tLoss 0.9389 (0.8261)\tAcc 0.500 (0.661)\n",
      "Epoch: [11][8/12]\tTime 0.076 (0.106)\tData 0.052 (0.079)\tLoss 0.9001 (0.8354)\tAcc 0.562 (0.648)\n",
      "Epoch: [11][9/12]\tTime 0.077 (0.103)\tData 0.053 (0.076)\tLoss 0.6175 (0.8112)\tAcc 0.812 (0.667)\n",
      "Epoch: [11][10/12]\tTime 0.077 (0.100)\tData 0.054 (0.074)\tLoss 0.9726 (0.8273)\tAcc 0.625 (0.663)\n",
      "Epoch: [11][11/12]\tTime 0.079 (0.098)\tData 0.055 (0.072)\tLoss 0.5658 (0.8036)\tAcc 0.875 (0.682)\n",
      "Epoch: [11][12/12]\tTime 0.078 (0.096)\tData 0.054 (0.071)\tLoss 0.7439 (0.7989)\tAcc 0.733 (0.686)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/18]\tTime 0.303 (0.303)\tData 0.275 (0.275)\tLoss 0.4337 (0.4337)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/18]\tTime 0.067 (0.185)\tData 0.047 (0.161)\tLoss 1.1115 (0.7726)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/18]\tTime 0.074 (0.148)\tData 0.053 (0.125)\tLoss 0.7126 (0.7526)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][4/18]\tTime 0.074 (0.129)\tData 0.053 (0.107)\tLoss 0.7695 (0.7568)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][5/18]\tTime 0.076 (0.119)\tData 0.054 (0.096)\tLoss 0.8732 (0.7801)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][6/18]\tTime 0.072 (0.111)\tData 0.051 (0.089)\tLoss 0.3629 (0.7106)\tAcc 1.000 (0.740)\n",
      "Epoch: [11][7/18]\tTime 0.076 (0.106)\tData 0.053 (0.084)\tLoss 0.5855 (0.6927)\tAcc 0.875 (0.759)\n",
      "Epoch: [11][8/18]\tTime 0.073 (0.102)\tData 0.052 (0.080)\tLoss 1.0590 (0.7385)\tAcc 0.500 (0.727)\n",
      "Epoch: [11][9/18]\tTime 0.074 (0.099)\tData 0.053 (0.077)\tLoss 0.3247 (0.6925)\tAcc 1.000 (0.757)\n",
      "Epoch: [11][10/18]\tTime 0.074 (0.096)\tData 0.053 (0.074)\tLoss 1.2261 (0.7459)\tAcc 0.375 (0.719)\n",
      "Epoch: [11][11/18]\tTime 0.077 (0.095)\tData 0.054 (0.072)\tLoss 1.2527 (0.7919)\tAcc 0.375 (0.688)\n",
      "Epoch: [11][12/18]\tTime 0.070 (0.092)\tData 0.050 (0.071)\tLoss 1.0218 (0.8111)\tAcc 0.562 (0.677)\n",
      "Epoch: [11][13/18]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 1.1260 (0.8353)\tAcc 0.312 (0.649)\n",
      "Epoch: [11][14/18]\tTime 0.075 (0.090)\tData 0.055 (0.068)\tLoss 0.7898 (0.8321)\tAcc 0.625 (0.647)\n",
      "Epoch: [11][15/18]\tTime 0.072 (0.089)\tData 0.053 (0.067)\tLoss 0.8177 (0.8311)\tAcc 0.625 (0.646)\n",
      "Epoch: [11][16/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.8589 (0.8328)\tAcc 0.625 (0.645)\n",
      "Epoch: [11][17/18]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.8416 (0.8334)\tAcc 0.625 (0.643)\n",
      "Epoch: [11][18/18]\tTime 0.073 (0.086)\tData 0.055 (0.065)\tLoss 0.8676 (0.8343)\tAcc 0.625 (0.643)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/12]\tTime 0.318 (0.318)\tData 0.288 (0.288)\tLoss 0.7835 (0.7835)\tAcc 0.750 (0.750)\n",
      "Epoch: [12][2/12]\tTime 0.077 (0.198)\tData 0.050 (0.169)\tLoss 0.8998 (0.8416)\tAcc 0.562 (0.656)\n",
      "Epoch: [12][3/12]\tTime 0.080 (0.158)\tData 0.052 (0.130)\tLoss 0.7930 (0.8254)\tAcc 0.688 (0.667)\n",
      "Epoch: [12][4/12]\tTime 0.080 (0.139)\tData 0.050 (0.110)\tLoss 0.8883 (0.8411)\tAcc 0.625 (0.656)\n",
      "Epoch: [12][5/12]\tTime 0.076 (0.126)\tData 0.050 (0.098)\tLoss 0.7925 (0.8314)\tAcc 0.625 (0.650)\n",
      "Epoch: [12][6/12]\tTime 0.078 (0.118)\tData 0.052 (0.090)\tLoss 0.8287 (0.8310)\tAcc 0.625 (0.646)\n",
      "Epoch: [12][7/12]\tTime 0.079 (0.113)\tData 0.053 (0.085)\tLoss 0.7694 (0.8222)\tAcc 0.750 (0.661)\n",
      "Epoch: [12][8/12]\tTime 0.079 (0.108)\tData 0.054 (0.081)\tLoss 0.6323 (0.7984)\tAcc 0.812 (0.680)\n",
      "Epoch: [12][9/12]\tTime 0.078 (0.105)\tData 0.053 (0.078)\tLoss 0.6535 (0.7823)\tAcc 0.875 (0.701)\n",
      "Epoch: [12][10/12]\tTime 0.077 (0.102)\tData 0.053 (0.076)\tLoss 0.8883 (0.7929)\tAcc 0.625 (0.694)\n",
      "Epoch: [12][11/12]\tTime 0.081 (0.100)\tData 0.057 (0.074)\tLoss 1.1686 (0.8271)\tAcc 0.562 (0.682)\n",
      "Epoch: [12][12/12]\tTime 0.078 (0.098)\tData 0.053 (0.072)\tLoss 0.6673 (0.8145)\tAcc 0.733 (0.686)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/18]\tTime 0.343 (0.343)\tData 0.304 (0.304)\tLoss 0.4418 (0.4418)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/18]\tTime 0.060 (0.201)\tData 0.038 (0.171)\tLoss 1.0137 (0.7278)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/18]\tTime 0.076 (0.160)\tData 0.051 (0.131)\tLoss 0.7213 (0.7256)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][4/18]\tTime 0.072 (0.138)\tData 0.051 (0.111)\tLoss 0.6627 (0.7099)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/18]\tTime 0.081 (0.126)\tData 0.058 (0.100)\tLoss 0.7849 (0.7249)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][6/18]\tTime 0.082 (0.119)\tData 0.057 (0.093)\tLoss 0.3479 (0.6620)\tAcc 1.000 (0.740)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][7/18]\tTime 0.082 (0.114)\tData 0.055 (0.088)\tLoss 0.5955 (0.6525)\tAcc 0.875 (0.759)\n",
      "Epoch: [12][8/18]\tTime 0.083 (0.110)\tData 0.055 (0.084)\tLoss 1.0098 (0.6972)\tAcc 0.500 (0.727)\n",
      "Epoch: [12][9/18]\tTime 0.077 (0.106)\tData 0.056 (0.081)\tLoss 0.3299 (0.6564)\tAcc 1.000 (0.757)\n",
      "Epoch: [12][10/18]\tTime 0.076 (0.103)\tData 0.055 (0.078)\tLoss 1.3977 (0.7305)\tAcc 0.375 (0.719)\n",
      "Epoch: [12][11/18]\tTime 0.079 (0.101)\tData 0.058 (0.076)\tLoss 1.3008 (0.7824)\tAcc 0.375 (0.688)\n",
      "Epoch: [12][12/18]\tTime 0.079 (0.099)\tData 0.058 (0.075)\tLoss 1.0271 (0.8027)\tAcc 0.562 (0.677)\n",
      "Epoch: [12][13/18]\tTime 0.082 (0.098)\tData 0.060 (0.073)\tLoss 1.3521 (0.8450)\tAcc 0.312 (0.649)\n",
      "Epoch: [12][14/18]\tTime 0.079 (0.097)\tData 0.058 (0.072)\tLoss 0.8014 (0.8419)\tAcc 0.625 (0.647)\n",
      "Epoch: [12][15/18]\tTime 0.079 (0.095)\tData 0.059 (0.071)\tLoss 0.9554 (0.8495)\tAcc 0.625 (0.646)\n",
      "Epoch: [12][16/18]\tTime 0.078 (0.094)\tData 0.058 (0.071)\tLoss 0.8124 (0.8471)\tAcc 0.625 (0.645)\n",
      "Epoch: [12][17/18]\tTime 0.078 (0.093)\tData 0.058 (0.070)\tLoss 0.9150 (0.8511)\tAcc 0.625 (0.643)\n",
      "Epoch: [12][18/18]\tTime 0.085 (0.093)\tData 0.065 (0.070)\tLoss 0.8344 (0.8506)\tAcc 0.625 (0.643)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/12]\tTime 0.316 (0.316)\tData 0.282 (0.282)\tLoss 0.9619 (0.9619)\tAcc 0.562 (0.562)\n",
      "Epoch: [13][2/12]\tTime 0.089 (0.203)\tData 0.057 (0.170)\tLoss 0.7473 (0.8546)\tAcc 0.688 (0.625)\n",
      "Epoch: [13][3/12]\tTime 0.085 (0.164)\tData 0.054 (0.131)\tLoss 0.6733 (0.7942)\tAcc 0.688 (0.646)\n",
      "Epoch: [13][4/12]\tTime 0.089 (0.145)\tData 0.055 (0.112)\tLoss 0.7902 (0.7932)\tAcc 0.688 (0.656)\n",
      "Epoch: [13][5/12]\tTime 0.095 (0.135)\tData 0.055 (0.100)\tLoss 0.8491 (0.8044)\tAcc 0.625 (0.650)\n",
      "Epoch: [13][6/12]\tTime 0.079 (0.126)\tData 0.047 (0.092)\tLoss 0.7668 (0.7981)\tAcc 0.688 (0.656)\n",
      "Epoch: [13][7/12]\tTime 0.082 (0.119)\tData 0.058 (0.087)\tLoss 0.9952 (0.8262)\tAcc 0.562 (0.643)\n",
      "Epoch: [13][8/12]\tTime 0.083 (0.115)\tData 0.057 (0.083)\tLoss 0.8602 (0.8305)\tAcc 0.625 (0.641)\n",
      "Epoch: [13][9/12]\tTime 0.084 (0.111)\tData 0.060 (0.080)\tLoss 0.4110 (0.7839)\tAcc 1.000 (0.681)\n",
      "Epoch: [13][10/12]\tTime 0.085 (0.109)\tData 0.061 (0.078)\tLoss 0.5799 (0.7635)\tAcc 0.875 (0.700)\n",
      "Epoch: [13][11/12]\tTime 0.084 (0.107)\tData 0.060 (0.077)\tLoss 0.9929 (0.7843)\tAcc 0.562 (0.688)\n",
      "Epoch: [13][12/12]\tTime 0.086 (0.105)\tData 0.061 (0.075)\tLoss 0.7806 (0.7840)\tAcc 0.667 (0.686)\n",
      "validation at epoch 13\n",
      "Epoch: [13][1/18]\tTime 0.313 (0.313)\tData 0.289 (0.289)\tLoss 0.4114 (0.4114)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/18]\tTime 0.072 (0.192)\tData 0.050 (0.170)\tLoss 1.0122 (0.7118)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/18]\tTime 0.080 (0.155)\tData 0.055 (0.131)\tLoss 0.7004 (0.7080)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/18]\tTime 0.078 (0.136)\tData 0.056 (0.113)\tLoss 0.6797 (0.7009)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][5/18]\tTime 0.081 (0.125)\tData 0.059 (0.102)\tLoss 0.8613 (0.7330)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][6/18]\tTime 0.085 (0.118)\tData 0.059 (0.095)\tLoss 0.3624 (0.6713)\tAcc 1.000 (0.740)\n",
      "Epoch: [13][7/18]\tTime 0.075 (0.112)\tData 0.054 (0.089)\tLoss 0.5573 (0.6550)\tAcc 0.875 (0.759)\n",
      "Epoch: [13][8/18]\tTime 0.080 (0.108)\tData 0.059 (0.085)\tLoss 0.8934 (0.6848)\tAcc 0.500 (0.727)\n",
      "Epoch: [13][9/18]\tTime 0.080 (0.105)\tData 0.059 (0.082)\tLoss 0.3119 (0.6433)\tAcc 1.000 (0.757)\n",
      "Epoch: [13][10/18]\tTime 0.076 (0.102)\tData 0.055 (0.079)\tLoss 1.2447 (0.7035)\tAcc 0.375 (0.719)\n",
      "Epoch: [13][11/18]\tTime 0.073 (0.099)\tData 0.052 (0.077)\tLoss 1.3673 (0.7638)\tAcc 0.375 (0.688)\n",
      "Epoch: [13][12/18]\tTime 0.079 (0.098)\tData 0.059 (0.075)\tLoss 1.0747 (0.7897)\tAcc 0.562 (0.677)\n",
      "Epoch: [13][13/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 1.2708 (0.8267)\tAcc 0.312 (0.649)\n",
      "Epoch: [13][14/18]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.8727 (0.8300)\tAcc 0.625 (0.647)\n",
      "Epoch: [13][15/18]\tTime 0.074 (0.093)\tData 0.055 (0.071)\tLoss 0.9188 (0.8359)\tAcc 0.625 (0.646)\n",
      "Epoch: [13][16/18]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.8310 (0.8356)\tAcc 0.625 (0.645)\n",
      "Epoch: [13][17/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.8128 (0.8343)\tAcc 0.625 (0.643)\n",
      "Epoch: [13][18/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.8208 (0.8339)\tAcc 0.625 (0.643)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/12]\tTime 0.311 (0.311)\tData 0.276 (0.276)\tLoss 0.7440 (0.7440)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][2/12]\tTime 0.076 (0.193)\tData 0.048 (0.162)\tLoss 0.9379 (0.8410)\tAcc 0.625 (0.656)\n",
      "Epoch: [14][3/12]\tTime 0.085 (0.157)\tData 0.057 (0.127)\tLoss 0.5574 (0.7464)\tAcc 0.812 (0.708)\n",
      "Epoch: [14][4/12]\tTime 0.084 (0.139)\tData 0.057 (0.110)\tLoss 1.3631 (0.9006)\tAcc 0.312 (0.609)\n",
      "Epoch: [14][5/12]\tTime 0.086 (0.128)\tData 0.060 (0.100)\tLoss 0.6647 (0.8534)\tAcc 0.750 (0.637)\n",
      "Epoch: [14][6/12]\tTime 0.086 (0.121)\tData 0.058 (0.093)\tLoss 0.6350 (0.8170)\tAcc 0.750 (0.656)\n",
      "Epoch: [14][7/12]\tTime 0.087 (0.116)\tData 0.059 (0.088)\tLoss 0.6627 (0.7950)\tAcc 0.750 (0.670)\n",
      "Epoch: [14][8/12]\tTime 0.079 (0.112)\tData 0.055 (0.084)\tLoss 0.7603 (0.7906)\tAcc 0.688 (0.672)\n",
      "Epoch: [14][9/12]\tTime 0.078 (0.108)\tData 0.055 (0.081)\tLoss 0.8995 (0.8027)\tAcc 0.625 (0.667)\n",
      "Epoch: [14][10/12]\tTime 0.080 (0.105)\tData 0.056 (0.078)\tLoss 0.7358 (0.7960)\tAcc 0.750 (0.675)\n",
      "Epoch: [14][11/12]\tTime 0.086 (0.103)\tData 0.061 (0.077)\tLoss 0.8953 (0.8051)\tAcc 0.688 (0.676)\n",
      "Epoch: [14][12/12]\tTime 0.086 (0.102)\tData 0.061 (0.075)\tLoss 0.5832 (0.7876)\tAcc 0.800 (0.686)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/18]\tTime 0.334 (0.334)\tData 0.306 (0.306)\tLoss 0.3804 (0.3804)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/18]\tTime 0.074 (0.204)\tData 0.052 (0.179)\tLoss 0.9695 (0.6749)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/18]\tTime 0.082 (0.163)\tData 0.059 (0.139)\tLoss 0.6378 (0.6626)\tAcc 0.625 (0.667)\n",
      "Epoch: [14][4/18]\tTime 0.079 (0.142)\tData 0.058 (0.119)\tLoss 0.8361 (0.7059)\tAcc 0.688 (0.672)\n",
      "Epoch: [14][5/18]\tTime 0.081 (0.130)\tData 0.059 (0.107)\tLoss 0.7764 (0.7200)\tAcc 0.688 (0.675)\n",
      "Epoch: [14][6/18]\tTime 0.080 (0.122)\tData 0.058 (0.099)\tLoss 0.3391 (0.6565)\tAcc 1.000 (0.729)\n",
      "Epoch: [14][7/18]\tTime 0.080 (0.116)\tData 0.058 (0.093)\tLoss 0.6739 (0.6590)\tAcc 0.875 (0.750)\n",
      "Epoch: [14][8/18]\tTime 0.082 (0.111)\tData 0.058 (0.088)\tLoss 1.0811 (0.7118)\tAcc 0.500 (0.719)\n",
      "Epoch: [14][9/18]\tTime 0.079 (0.108)\tData 0.058 (0.085)\tLoss 0.2986 (0.6659)\tAcc 1.000 (0.750)\n",
      "Epoch: [14][10/18]\tTime 0.080 (0.105)\tData 0.058 (0.082)\tLoss 1.2833 (0.7276)\tAcc 0.375 (0.713)\n",
      "Epoch: [14][11/18]\tTime 0.079 (0.103)\tData 0.058 (0.080)\tLoss 1.3828 (0.7872)\tAcc 0.375 (0.682)\n",
      "Epoch: [14][12/18]\tTime 0.079 (0.101)\tData 0.060 (0.078)\tLoss 1.0701 (0.8108)\tAcc 0.562 (0.672)\n",
      "Epoch: [14][13/18]\tTime 0.074 (0.099)\tData 0.055 (0.077)\tLoss 1.2087 (0.8414)\tAcc 0.312 (0.644)\n",
      "Epoch: [14][14/18]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.8993 (0.8455)\tAcc 0.625 (0.643)\n",
      "Epoch: [14][15/18]\tTime 0.074 (0.095)\tData 0.055 (0.074)\tLoss 0.7854 (0.8415)\tAcc 0.625 (0.642)\n",
      "Epoch: [14][16/18]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.7887 (0.8382)\tAcc 0.688 (0.645)\n",
      "Epoch: [14][17/18]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.8119 (0.8367)\tAcc 0.625 (0.643)\n",
      "Epoch: [14][18/18]\tTime 0.079 (0.092)\tData 0.059 (0.071)\tLoss 0.7361 (0.8338)\tAcc 0.750 (0.646)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/12]\tTime 0.331 (0.331)\tData 0.299 (0.299)\tLoss 0.8953 (0.8953)\tAcc 0.625 (0.625)\n",
      "Epoch: [15][2/12]\tTime 0.076 (0.203)\tData 0.049 (0.174)\tLoss 1.0891 (0.9922)\tAcc 0.438 (0.531)\n",
      "Epoch: [15][3/12]\tTime 0.086 (0.164)\tData 0.057 (0.135)\tLoss 0.8005 (0.9283)\tAcc 0.750 (0.604)\n",
      "Epoch: [15][4/12]\tTime 0.082 (0.144)\tData 0.056 (0.115)\tLoss 0.6045 (0.8473)\tAcc 0.812 (0.656)\n",
      "Epoch: [15][5/12]\tTime 0.087 (0.132)\tData 0.058 (0.104)\tLoss 0.4901 (0.7759)\tAcc 0.875 (0.700)\n",
      "Epoch: [15][6/12]\tTime 0.086 (0.125)\tData 0.056 (0.096)\tLoss 0.9006 (0.7967)\tAcc 0.625 (0.688)\n",
      "Epoch: [15][7/12]\tTime 0.074 (0.117)\tData 0.050 (0.089)\tLoss 0.6562 (0.7766)\tAcc 0.750 (0.696)\n",
      "Epoch: [15][8/12]\tTime 0.081 (0.113)\tData 0.057 (0.085)\tLoss 0.8419 (0.7847)\tAcc 0.625 (0.688)\n",
      "Epoch: [15][9/12]\tTime 0.082 (0.109)\tData 0.059 (0.082)\tLoss 0.5894 (0.7630)\tAcc 0.750 (0.694)\n",
      "Epoch: [15][10/12]\tTime 0.080 (0.107)\tData 0.056 (0.080)\tLoss 0.9335 (0.7801)\tAcc 0.625 (0.688)\n",
      "Epoch: [15][11/12]\tTime 0.082 (0.104)\tData 0.058 (0.078)\tLoss 0.6250 (0.7660)\tAcc 0.750 (0.693)\n",
      "Epoch: [15][12/12]\tTime 0.085 (0.103)\tData 0.060 (0.076)\tLoss 0.8269 (0.7708)\tAcc 0.667 (0.691)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/18]\tTime 0.283 (0.283)\tData 0.258 (0.258)\tLoss 0.3994 (0.3994)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/18]\tTime 0.071 (0.177)\tData 0.049 (0.154)\tLoss 1.0526 (0.7260)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/18]\tTime 0.073 (0.143)\tData 0.052 (0.120)\tLoss 0.7411 (0.7310)\tAcc 0.625 (0.667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][4/18]\tTime 0.074 (0.125)\tData 0.052 (0.103)\tLoss 0.6704 (0.7159)\tAcc 0.688 (0.672)\n",
      "Epoch: [15][5/18]\tTime 0.076 (0.116)\tData 0.053 (0.093)\tLoss 0.8587 (0.7444)\tAcc 0.688 (0.675)\n",
      "Epoch: [15][6/18]\tTime 0.073 (0.108)\tData 0.051 (0.086)\tLoss 0.3703 (0.6821)\tAcc 1.000 (0.729)\n",
      "Epoch: [15][7/18]\tTime 0.073 (0.103)\tData 0.052 (0.081)\tLoss 0.6359 (0.6755)\tAcc 0.875 (0.750)\n",
      "Epoch: [15][8/18]\tTime 0.075 (0.100)\tData 0.053 (0.078)\tLoss 0.9558 (0.7105)\tAcc 0.500 (0.719)\n",
      "Epoch: [15][9/18]\tTime 0.082 (0.098)\tData 0.053 (0.075)\tLoss 0.2943 (0.6643)\tAcc 1.000 (0.750)\n",
      "Epoch: [15][10/18]\tTime 0.075 (0.096)\tData 0.051 (0.073)\tLoss 1.3377 (0.7316)\tAcc 0.375 (0.713)\n",
      "Epoch: [15][11/18]\tTime 0.078 (0.094)\tData 0.056 (0.071)\tLoss 1.3271 (0.7857)\tAcc 0.375 (0.682)\n",
      "Epoch: [15][12/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9319 (0.7979)\tAcc 0.562 (0.672)\n",
      "Epoch: [15][13/18]\tTime 0.073 (0.091)\tData 0.052 (0.068)\tLoss 1.2622 (0.8336)\tAcc 0.500 (0.659)\n",
      "Epoch: [15][14/18]\tTime 0.074 (0.090)\tData 0.054 (0.067)\tLoss 0.8714 (0.8363)\tAcc 0.625 (0.656)\n",
      "Epoch: [15][15/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.8028 (0.8341)\tAcc 0.625 (0.654)\n",
      "Epoch: [15][16/18]\tTime 0.072 (0.088)\tData 0.054 (0.066)\tLoss 0.8173 (0.8331)\tAcc 0.625 (0.652)\n",
      "Epoch: [15][17/18]\tTime 0.075 (0.087)\tData 0.056 (0.065)\tLoss 0.7822 (0.8301)\tAcc 0.625 (0.651)\n",
      "Epoch: [15][18/18]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.8459 (0.8305)\tAcc 0.500 (0.646)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/12]\tTime 0.331 (0.331)\tData 0.300 (0.300)\tLoss 0.6370 (0.6370)\tAcc 0.812 (0.812)\n",
      "Epoch: [16][2/12]\tTime 0.076 (0.203)\tData 0.049 (0.175)\tLoss 0.8598 (0.7484)\tAcc 0.562 (0.688)\n",
      "Epoch: [16][3/12]\tTime 0.078 (0.161)\tData 0.052 (0.134)\tLoss 0.8275 (0.7747)\tAcc 0.625 (0.667)\n",
      "Epoch: [16][4/12]\tTime 0.078 (0.141)\tData 0.052 (0.113)\tLoss 0.5498 (0.7185)\tAcc 0.875 (0.719)\n",
      "Epoch: [16][5/12]\tTime 0.080 (0.129)\tData 0.054 (0.101)\tLoss 0.5848 (0.6918)\tAcc 0.812 (0.738)\n",
      "Epoch: [16][6/12]\tTime 0.078 (0.120)\tData 0.053 (0.093)\tLoss 0.7123 (0.6952)\tAcc 0.750 (0.740)\n",
      "Epoch: [16][7/12]\tTime 0.078 (0.114)\tData 0.053 (0.088)\tLoss 0.4199 (0.6559)\tAcc 0.938 (0.768)\n",
      "Epoch: [16][8/12]\tTime 0.079 (0.110)\tData 0.055 (0.083)\tLoss 0.8954 (0.6858)\tAcc 0.625 (0.750)\n",
      "Epoch: [16][9/12]\tTime 0.077 (0.106)\tData 0.053 (0.080)\tLoss 0.6292 (0.6795)\tAcc 0.688 (0.743)\n",
      "Epoch: [16][10/12]\tTime 0.077 (0.103)\tData 0.054 (0.078)\tLoss 0.7358 (0.6852)\tAcc 0.812 (0.750)\n",
      "Epoch: [16][11/12]\tTime 0.079 (0.101)\tData 0.056 (0.076)\tLoss 1.3417 (0.7448)\tAcc 0.438 (0.722)\n",
      "Epoch: [16][12/12]\tTime 0.078 (0.099)\tData 0.055 (0.074)\tLoss 1.0835 (0.7714)\tAcc 0.533 (0.707)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/18]\tTime 0.328 (0.328)\tData 0.305 (0.305)\tLoss 0.2651 (0.2651)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/18]\tTime 0.072 (0.200)\tData 0.050 (0.178)\tLoss 1.1004 (0.6828)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/18]\tTime 0.074 (0.158)\tData 0.052 (0.136)\tLoss 0.6510 (0.6722)\tAcc 0.812 (0.729)\n",
      "Epoch: [16][4/18]\tTime 0.073 (0.137)\tData 0.052 (0.115)\tLoss 0.7671 (0.6959)\tAcc 0.625 (0.703)\n",
      "Epoch: [16][5/18]\tTime 0.075 (0.124)\tData 0.054 (0.103)\tLoss 0.7381 (0.7043)\tAcc 0.688 (0.700)\n",
      "Epoch: [16][6/18]\tTime 0.074 (0.116)\tData 0.053 (0.094)\tLoss 0.3248 (0.6411)\tAcc 1.000 (0.750)\n",
      "Epoch: [16][7/18]\tTime 0.073 (0.110)\tData 0.053 (0.088)\tLoss 0.7517 (0.6569)\tAcc 0.750 (0.750)\n",
      "Epoch: [16][8/18]\tTime 0.075 (0.105)\tData 0.054 (0.084)\tLoss 1.0675 (0.7082)\tAcc 0.500 (0.719)\n",
      "Epoch: [16][9/18]\tTime 0.074 (0.102)\tData 0.053 (0.081)\tLoss 0.1670 (0.6481)\tAcc 1.000 (0.750)\n",
      "Epoch: [16][10/18]\tTime 0.074 (0.099)\tData 0.053 (0.078)\tLoss 1.4261 (0.7259)\tAcc 0.375 (0.713)\n",
      "Epoch: [16][11/18]\tTime 0.073 (0.097)\tData 0.053 (0.076)\tLoss 1.4699 (0.7935)\tAcc 0.375 (0.682)\n",
      "Epoch: [16][12/18]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 1.1213 (0.8208)\tAcc 0.562 (0.672)\n",
      "Epoch: [16][13/18]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 1.2324 (0.8525)\tAcc 0.375 (0.649)\n",
      "Epoch: [16][14/18]\tTime 0.079 (0.092)\tData 0.059 (0.071)\tLoss 0.9320 (0.8582)\tAcc 0.625 (0.647)\n",
      "Epoch: [16][15/18]\tTime 0.085 (0.092)\tData 0.065 (0.071)\tLoss 0.7276 (0.8495)\tAcc 0.688 (0.650)\n",
      "Epoch: [16][16/18]\tTime 0.079 (0.091)\tData 0.060 (0.070)\tLoss 0.7751 (0.8448)\tAcc 0.625 (0.648)\n",
      "Epoch: [16][17/18]\tTime 0.077 (0.090)\tData 0.057 (0.069)\tLoss 0.8920 (0.8476)\tAcc 0.625 (0.647)\n",
      "Epoch: [16][18/18]\tTime 0.079 (0.089)\tData 0.060 (0.069)\tLoss 0.8177 (0.8467)\tAcc 0.625 (0.646)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/12]\tTime 0.378 (0.378)\tData 0.348 (0.348)\tLoss 0.6232 (0.6232)\tAcc 0.750 (0.750)\n",
      "Epoch: [17][2/12]\tTime 0.082 (0.230)\tData 0.049 (0.198)\tLoss 0.7838 (0.7035)\tAcc 0.688 (0.719)\n",
      "Epoch: [17][3/12]\tTime 0.075 (0.178)\tData 0.050 (0.149)\tLoss 0.8859 (0.7643)\tAcc 0.688 (0.708)\n",
      "Epoch: [17][4/12]\tTime 0.082 (0.154)\tData 0.056 (0.126)\tLoss 0.7625 (0.7639)\tAcc 0.688 (0.703)\n",
      "Epoch: [17][5/12]\tTime 0.083 (0.140)\tData 0.057 (0.112)\tLoss 0.7057 (0.7522)\tAcc 0.812 (0.725)\n",
      "Epoch: [17][6/12]\tTime 0.080 (0.130)\tData 0.053 (0.102)\tLoss 0.6027 (0.7273)\tAcc 0.875 (0.750)\n",
      "Epoch: [17][7/12]\tTime 0.078 (0.123)\tData 0.055 (0.095)\tLoss 0.7646 (0.7326)\tAcc 0.688 (0.741)\n",
      "Epoch: [17][8/12]\tTime 0.082 (0.117)\tData 0.058 (0.091)\tLoss 1.0713 (0.7750)\tAcc 0.562 (0.719)\n",
      "Epoch: [17][9/12]\tTime 0.083 (0.114)\tData 0.060 (0.087)\tLoss 0.9024 (0.7891)\tAcc 0.625 (0.708)\n",
      "Epoch: [17][10/12]\tTime 0.083 (0.111)\tData 0.060 (0.085)\tLoss 0.5915 (0.7694)\tAcc 0.750 (0.713)\n",
      "Epoch: [17][11/12]\tTime 0.082 (0.108)\tData 0.059 (0.082)\tLoss 0.7291 (0.7657)\tAcc 0.688 (0.710)\n",
      "Epoch: [17][12/12]\tTime 0.077 (0.105)\tData 0.055 (0.080)\tLoss 0.8796 (0.7746)\tAcc 0.600 (0.702)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/18]\tTime 0.347 (0.347)\tData 0.320 (0.320)\tLoss 0.4371 (0.4371)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/18]\tTime 0.068 (0.208)\tData 0.047 (0.184)\tLoss 1.1029 (0.7700)\tAcc 0.438 (0.688)\n",
      "Epoch: [17][3/18]\tTime 0.073 (0.163)\tData 0.053 (0.140)\tLoss 0.6918 (0.7439)\tAcc 0.625 (0.667)\n",
      "Epoch: [17][4/18]\tTime 0.073 (0.140)\tData 0.053 (0.118)\tLoss 0.6652 (0.7242)\tAcc 0.625 (0.656)\n",
      "Epoch: [17][5/18]\tTime 0.075 (0.127)\tData 0.054 (0.105)\tLoss 0.9301 (0.7654)\tAcc 0.750 (0.675)\n",
      "Epoch: [17][6/18]\tTime 0.078 (0.119)\tData 0.057 (0.097)\tLoss 0.3241 (0.6918)\tAcc 1.000 (0.729)\n",
      "Epoch: [17][7/18]\tTime 0.075 (0.113)\tData 0.055 (0.091)\tLoss 0.7758 (0.7038)\tAcc 0.688 (0.723)\n",
      "Epoch: [17][8/18]\tTime 0.077 (0.108)\tData 0.057 (0.087)\tLoss 0.9875 (0.7393)\tAcc 0.500 (0.695)\n",
      "Epoch: [17][9/18]\tTime 0.078 (0.105)\tData 0.056 (0.083)\tLoss 0.3245 (0.6932)\tAcc 1.000 (0.729)\n",
      "Epoch: [17][10/18]\tTime 0.073 (0.102)\tData 0.052 (0.080)\tLoss 1.0918 (0.7331)\tAcc 0.375 (0.694)\n",
      "Epoch: [17][11/18]\tTime 0.075 (0.099)\tData 0.054 (0.078)\tLoss 1.3630 (0.7903)\tAcc 0.375 (0.665)\n",
      "Epoch: [17][12/18]\tTime 0.074 (0.097)\tData 0.053 (0.076)\tLoss 0.9554 (0.8041)\tAcc 0.562 (0.656)\n",
      "Epoch: [17][13/18]\tTime 0.072 (0.095)\tData 0.052 (0.074)\tLoss 1.1807 (0.8331)\tAcc 0.438 (0.639)\n",
      "Epoch: [17][14/18]\tTime 0.075 (0.094)\tData 0.055 (0.073)\tLoss 0.8517 (0.8344)\tAcc 0.625 (0.638)\n",
      "Epoch: [17][15/18]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.7596 (0.8294)\tAcc 0.750 (0.646)\n",
      "Epoch: [17][16/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6951 (0.8210)\tAcc 0.812 (0.656)\n",
      "Epoch: [17][17/18]\tTime 0.075 (0.090)\tData 0.055 (0.069)\tLoss 0.8492 (0.8227)\tAcc 0.625 (0.654)\n",
      "Epoch: [17][18/18]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 0.6885 (0.8188)\tAcc 0.875 (0.661)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/12]\tTime 0.342 (0.342)\tData 0.310 (0.310)\tLoss 1.2089 (1.2089)\tAcc 0.438 (0.438)\n",
      "Epoch: [18][2/12]\tTime 0.080 (0.211)\tData 0.053 (0.182)\tLoss 0.6090 (0.9089)\tAcc 0.812 (0.625)\n",
      "Epoch: [18][3/12]\tTime 0.085 (0.169)\tData 0.057 (0.140)\tLoss 0.7886 (0.8688)\tAcc 0.625 (0.625)\n",
      "Epoch: [18][4/12]\tTime 0.078 (0.146)\tData 0.051 (0.118)\tLoss 0.7693 (0.8439)\tAcc 0.625 (0.625)\n",
      "Epoch: [18][5/12]\tTime 0.079 (0.133)\tData 0.053 (0.105)\tLoss 0.9226 (0.8597)\tAcc 0.562 (0.613)\n",
      "Epoch: [18][6/12]\tTime 0.079 (0.124)\tData 0.053 (0.096)\tLoss 0.5665 (0.8108)\tAcc 0.812 (0.646)\n",
      "Epoch: [18][7/12]\tTime 0.077 (0.117)\tData 0.052 (0.090)\tLoss 0.5947 (0.7799)\tAcc 0.875 (0.679)\n",
      "Epoch: [18][8/12]\tTime 0.079 (0.112)\tData 0.055 (0.085)\tLoss 0.8397 (0.7874)\tAcc 0.688 (0.680)\n",
      "Epoch: [18][9/12]\tTime 0.078 (0.108)\tData 0.054 (0.082)\tLoss 0.5030 (0.7558)\tAcc 0.938 (0.708)\n",
      "Epoch: [18][10/12]\tTime 0.077 (0.105)\tData 0.054 (0.079)\tLoss 0.8244 (0.7627)\tAcc 0.688 (0.706)\n",
      "Epoch: [18][11/12]\tTime 0.080 (0.103)\tData 0.057 (0.077)\tLoss 0.8726 (0.7727)\tAcc 0.750 (0.710)\n",
      "Epoch: [18][12/12]\tTime 0.077 (0.101)\tData 0.054 (0.075)\tLoss 0.8603 (0.7795)\tAcc 0.600 (0.702)\n",
      "validation at epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][1/18]\tTime 0.321 (0.321)\tData 0.295 (0.295)\tLoss 0.2980 (0.2980)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/18]\tTime 0.070 (0.195)\tData 0.048 (0.172)\tLoss 1.0619 (0.6800)\tAcc 0.438 (0.688)\n",
      "Epoch: [18][3/18]\tTime 0.073 (0.155)\tData 0.053 (0.132)\tLoss 0.7010 (0.6870)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][4/18]\tTime 0.074 (0.135)\tData 0.053 (0.112)\tLoss 0.6596 (0.6801)\tAcc 0.625 (0.672)\n",
      "Epoch: [18][5/18]\tTime 0.074 (0.122)\tData 0.053 (0.100)\tLoss 0.7641 (0.6969)\tAcc 0.750 (0.688)\n",
      "Epoch: [18][6/18]\tTime 0.075 (0.115)\tData 0.055 (0.093)\tLoss 0.2712 (0.6260)\tAcc 1.000 (0.740)\n",
      "Epoch: [18][7/18]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.6486 (0.6292)\tAcc 0.812 (0.750)\n",
      "Epoch: [18][8/18]\tTime 0.077 (0.105)\tData 0.055 (0.083)\tLoss 1.0234 (0.6785)\tAcc 0.500 (0.719)\n",
      "Epoch: [18][9/18]\tTime 0.074 (0.101)\tData 0.052 (0.080)\tLoss 0.2390 (0.6296)\tAcc 1.000 (0.750)\n",
      "Epoch: [18][10/18]\tTime 0.077 (0.099)\tData 0.054 (0.077)\tLoss 1.3292 (0.6996)\tAcc 0.375 (0.713)\n",
      "Epoch: [18][11/18]\tTime 0.076 (0.097)\tData 0.055 (0.075)\tLoss 1.5997 (0.7814)\tAcc 0.375 (0.682)\n",
      "Epoch: [18][12/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 1.0957 (0.8076)\tAcc 0.562 (0.672)\n",
      "Epoch: [18][13/18]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 1.1807 (0.8363)\tAcc 0.500 (0.659)\n",
      "Epoch: [18][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.9107 (0.8416)\tAcc 0.562 (0.652)\n",
      "Epoch: [18][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.8133 (0.8397)\tAcc 0.688 (0.654)\n",
      "Epoch: [18][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.9523 (0.8468)\tAcc 0.625 (0.652)\n",
      "Epoch: [18][17/18]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.8524 (0.8471)\tAcc 0.625 (0.651)\n",
      "Epoch: [18][18/18]\tTime 0.072 (0.088)\tData 0.054 (0.067)\tLoss 0.5968 (0.8399)\tAcc 0.875 (0.657)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/12]\tTime 0.285 (0.285)\tData 0.254 (0.254)\tLoss 0.7912 (0.7912)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][2/12]\tTime 0.075 (0.180)\tData 0.049 (0.151)\tLoss 0.6108 (0.7010)\tAcc 0.812 (0.750)\n",
      "Epoch: [19][3/12]\tTime 0.079 (0.146)\tData 0.052 (0.118)\tLoss 0.4891 (0.6304)\tAcc 0.875 (0.792)\n",
      "Epoch: [19][4/12]\tTime 0.077 (0.129)\tData 0.051 (0.101)\tLoss 0.8645 (0.6889)\tAcc 0.688 (0.766)\n",
      "Epoch: [19][5/12]\tTime 0.079 (0.119)\tData 0.053 (0.092)\tLoss 0.9303 (0.7372)\tAcc 0.625 (0.738)\n",
      "Epoch: [19][6/12]\tTime 0.080 (0.113)\tData 0.055 (0.086)\tLoss 0.9780 (0.7773)\tAcc 0.562 (0.708)\n",
      "Epoch: [19][7/12]\tTime 0.083 (0.108)\tData 0.055 (0.081)\tLoss 0.8075 (0.7816)\tAcc 0.688 (0.705)\n",
      "Epoch: [19][8/12]\tTime 0.077 (0.104)\tData 0.052 (0.078)\tLoss 0.6357 (0.7634)\tAcc 0.812 (0.719)\n",
      "Epoch: [19][9/12]\tTime 0.077 (0.101)\tData 0.053 (0.075)\tLoss 0.7507 (0.7620)\tAcc 0.688 (0.715)\n",
      "Epoch: [19][10/12]\tTime 0.077 (0.099)\tData 0.054 (0.073)\tLoss 0.9529 (0.7811)\tAcc 0.688 (0.713)\n",
      "Epoch: [19][11/12]\tTime 0.079 (0.097)\tData 0.055 (0.071)\tLoss 0.7528 (0.7785)\tAcc 0.625 (0.705)\n",
      "Epoch: [19][12/12]\tTime 0.078 (0.095)\tData 0.054 (0.070)\tLoss 0.4855 (0.7555)\tAcc 0.800 (0.712)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/18]\tTime 0.384 (0.384)\tData 0.359 (0.359)\tLoss 0.3554 (0.3554)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/18]\tTime 0.073 (0.229)\tData 0.051 (0.205)\tLoss 1.0798 (0.7176)\tAcc 0.438 (0.688)\n",
      "Epoch: [19][3/18]\tTime 0.077 (0.178)\tData 0.055 (0.155)\tLoss 0.6307 (0.6886)\tAcc 0.750 (0.708)\n",
      "Epoch: [19][4/18]\tTime 0.075 (0.152)\tData 0.053 (0.130)\tLoss 0.7133 (0.6948)\tAcc 0.625 (0.688)\n",
      "Epoch: [19][5/18]\tTime 0.077 (0.137)\tData 0.056 (0.115)\tLoss 0.7450 (0.7048)\tAcc 0.750 (0.700)\n",
      "Epoch: [19][6/18]\tTime 0.075 (0.127)\tData 0.053 (0.105)\tLoss 0.2463 (0.6284)\tAcc 1.000 (0.750)\n",
      "Epoch: [19][7/18]\tTime 0.074 (0.119)\tData 0.051 (0.097)\tLoss 0.8346 (0.6579)\tAcc 0.562 (0.723)\n",
      "Epoch: [19][8/18]\tTime 0.074 (0.114)\tData 0.052 (0.091)\tLoss 0.9898 (0.6994)\tAcc 0.625 (0.711)\n",
      "Epoch: [19][9/18]\tTime 0.074 (0.109)\tData 0.053 (0.087)\tLoss 0.2194 (0.6460)\tAcc 1.000 (0.743)\n",
      "Epoch: [19][10/18]\tTime 0.079 (0.106)\tData 0.057 (0.084)\tLoss 1.2434 (0.7058)\tAcc 0.375 (0.706)\n",
      "Epoch: [19][11/18]\tTime 0.076 (0.103)\tData 0.054 (0.081)\tLoss 1.3466 (0.7640)\tAcc 0.375 (0.676)\n",
      "Epoch: [19][12/18]\tTime 0.074 (0.101)\tData 0.054 (0.079)\tLoss 1.0517 (0.7880)\tAcc 0.562 (0.667)\n",
      "Epoch: [19][13/18]\tTime 0.072 (0.099)\tData 0.053 (0.077)\tLoss 1.3088 (0.8281)\tAcc 0.375 (0.644)\n",
      "Epoch: [19][14/18]\tTime 0.075 (0.097)\tData 0.055 (0.075)\tLoss 0.7339 (0.8213)\tAcc 0.562 (0.638)\n",
      "Epoch: [19][15/18]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.8171 (0.8210)\tAcc 0.625 (0.638)\n",
      "Epoch: [19][16/18]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.8093 (0.8203)\tAcc 0.625 (0.637)\n",
      "Epoch: [19][17/18]\tTime 0.077 (0.093)\tData 0.057 (0.072)\tLoss 0.8589 (0.8226)\tAcc 0.625 (0.636)\n",
      "Epoch: [19][18/18]\tTime 0.076 (0.092)\tData 0.057 (0.071)\tLoss 0.6676 (0.8182)\tAcc 0.875 (0.643)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/12]\tTime 0.343 (0.343)\tData 0.310 (0.310)\tLoss 0.5699 (0.5699)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][2/12]\tTime 0.078 (0.211)\tData 0.051 (0.181)\tLoss 0.4982 (0.5341)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][3/12]\tTime 0.084 (0.168)\tData 0.054 (0.138)\tLoss 0.5495 (0.5392)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][4/12]\tTime 0.078 (0.146)\tData 0.049 (0.116)\tLoss 0.8753 (0.6232)\tAcc 0.562 (0.797)\n",
      "Epoch: [20][5/12]\tTime 0.078 (0.132)\tData 0.053 (0.103)\tLoss 1.0465 (0.7079)\tAcc 0.625 (0.762)\n",
      "Epoch: [20][6/12]\tTime 0.079 (0.123)\tData 0.053 (0.095)\tLoss 0.9568 (0.7494)\tAcc 0.500 (0.719)\n",
      "Epoch: [20][7/12]\tTime 0.078 (0.117)\tData 0.052 (0.089)\tLoss 0.4414 (0.7054)\tAcc 0.938 (0.750)\n",
      "Epoch: [20][8/12]\tTime 0.079 (0.112)\tData 0.055 (0.085)\tLoss 0.8858 (0.7279)\tAcc 0.625 (0.734)\n",
      "Epoch: [20][9/12]\tTime 0.081 (0.109)\tData 0.057 (0.082)\tLoss 0.6429 (0.7185)\tAcc 0.812 (0.743)\n",
      "Epoch: [20][10/12]\tTime 0.087 (0.107)\tData 0.063 (0.080)\tLoss 0.9705 (0.7437)\tAcc 0.562 (0.725)\n",
      "Epoch: [20][11/12]\tTime 0.081 (0.104)\tData 0.057 (0.078)\tLoss 0.6976 (0.7395)\tAcc 0.688 (0.722)\n",
      "Epoch: [20][12/12]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.8645 (0.7493)\tAcc 0.733 (0.723)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/18]\tTime 0.335 (0.335)\tData 0.309 (0.309)\tLoss 0.3087 (0.3087)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/18]\tTime 0.072 (0.203)\tData 0.049 (0.179)\tLoss 1.0644 (0.6865)\tAcc 0.438 (0.688)\n",
      "Epoch: [20][3/18]\tTime 0.076 (0.161)\tData 0.053 (0.137)\tLoss 0.5876 (0.6536)\tAcc 0.812 (0.729)\n",
      "Epoch: [20][4/18]\tTime 0.077 (0.140)\tData 0.055 (0.116)\tLoss 0.6878 (0.6621)\tAcc 0.688 (0.719)\n",
      "Epoch: [20][5/18]\tTime 0.074 (0.127)\tData 0.053 (0.104)\tLoss 0.8904 (0.7078)\tAcc 0.688 (0.713)\n",
      "Epoch: [20][6/18]\tTime 0.074 (0.118)\tData 0.053 (0.095)\tLoss 0.3023 (0.6402)\tAcc 0.938 (0.750)\n",
      "Epoch: [20][7/18]\tTime 0.086 (0.113)\tData 0.054 (0.089)\tLoss 0.6177 (0.6370)\tAcc 0.688 (0.741)\n",
      "Epoch: [20][8/18]\tTime 0.076 (0.109)\tData 0.045 (0.084)\tLoss 1.1220 (0.6976)\tAcc 0.562 (0.719)\n",
      "Epoch: [20][9/18]\tTime 0.071 (0.104)\tData 0.047 (0.080)\tLoss 0.1834 (0.6405)\tAcc 1.000 (0.750)\n",
      "Epoch: [20][10/18]\tTime 0.078 (0.102)\tData 0.056 (0.077)\tLoss 1.3264 (0.7091)\tAcc 0.375 (0.713)\n",
      "Epoch: [20][11/18]\tTime 0.080 (0.100)\tData 0.059 (0.076)\tLoss 1.3988 (0.7718)\tAcc 0.375 (0.682)\n",
      "Epoch: [20][12/18]\tTime 0.079 (0.098)\tData 0.058 (0.074)\tLoss 0.8875 (0.7814)\tAcc 0.562 (0.672)\n",
      "Epoch: [20][13/18]\tTime 0.073 (0.096)\tData 0.053 (0.073)\tLoss 1.2447 (0.8170)\tAcc 0.500 (0.659)\n",
      "Epoch: [20][14/18]\tTime 0.074 (0.095)\tData 0.054 (0.071)\tLoss 0.7334 (0.8111)\tAcc 0.625 (0.656)\n",
      "Epoch: [20][15/18]\tTime 0.074 (0.093)\tData 0.054 (0.070)\tLoss 0.8441 (0.8133)\tAcc 0.688 (0.658)\n",
      "Epoch: [20][16/18]\tTime 0.075 (0.092)\tData 0.055 (0.069)\tLoss 0.7601 (0.8099)\tAcc 0.750 (0.664)\n",
      "Epoch: [20][17/18]\tTime 0.075 (0.091)\tData 0.055 (0.068)\tLoss 0.7974 (0.8092)\tAcc 0.625 (0.662)\n",
      "Epoch: [20][18/18]\tTime 0.079 (0.090)\tData 0.060 (0.068)\tLoss 0.6966 (0.8060)\tAcc 0.625 (0.661)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/12]\tTime 0.323 (0.323)\tData 0.290 (0.290)\tLoss 0.7951 (0.7951)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][2/12]\tTime 0.076 (0.199)\tData 0.050 (0.170)\tLoss 0.9678 (0.8815)\tAcc 0.625 (0.688)\n",
      "Epoch: [21][3/12]\tTime 0.079 (0.159)\tData 0.052 (0.130)\tLoss 0.7797 (0.8475)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][4/12]\tTime 0.077 (0.139)\tData 0.051 (0.111)\tLoss 0.6455 (0.7970)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][5/12]\tTime 0.082 (0.127)\tData 0.054 (0.099)\tLoss 0.6852 (0.7747)\tAcc 0.750 (0.700)\n",
      "Epoch: [21][6/12]\tTime 0.079 (0.119)\tData 0.052 (0.091)\tLoss 0.7789 (0.7754)\tAcc 0.688 (0.698)\n",
      "Epoch: [21][7/12]\tTime 0.078 (0.113)\tData 0.052 (0.086)\tLoss 0.6990 (0.7645)\tAcc 0.688 (0.696)\n",
      "Epoch: [21][8/12]\tTime 0.080 (0.109)\tData 0.055 (0.082)\tLoss 0.6655 (0.7521)\tAcc 0.812 (0.711)\n",
      "Epoch: [21][9/12]\tTime 0.082 (0.106)\tData 0.057 (0.079)\tLoss 0.4892 (0.7229)\tAcc 0.875 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21][10/12]\tTime 0.086 (0.104)\tData 0.061 (0.077)\tLoss 0.6893 (0.7195)\tAcc 0.688 (0.725)\n",
      "Epoch: [21][11/12]\tTime 0.085 (0.102)\tData 0.061 (0.076)\tLoss 0.9886 (0.7440)\tAcc 0.500 (0.705)\n",
      "Epoch: [21][12/12]\tTime 0.087 (0.101)\tData 0.061 (0.075)\tLoss 0.7572 (0.7450)\tAcc 0.733 (0.707)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/18]\tTime 0.390 (0.390)\tData 0.324 (0.324)\tLoss 0.2860 (0.2860)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/18]\tTime 0.040 (0.215)\tData 0.015 (0.170)\tLoss 1.0417 (0.6638)\tAcc 0.438 (0.688)\n",
      "Epoch: [21][3/18]\tTime 0.078 (0.169)\tData 0.055 (0.131)\tLoss 0.5761 (0.6346)\tAcc 0.875 (0.750)\n",
      "Epoch: [21][4/18]\tTime 0.080 (0.147)\tData 0.058 (0.113)\tLoss 0.7334 (0.6593)\tAcc 0.625 (0.719)\n",
      "Epoch: [21][5/18]\tTime 0.079 (0.134)\tData 0.059 (0.102)\tLoss 0.9609 (0.7196)\tAcc 0.688 (0.713)\n",
      "Epoch: [21][6/18]\tTime 0.088 (0.126)\tData 0.059 (0.095)\tLoss 0.2647 (0.6438)\tAcc 1.000 (0.760)\n",
      "Epoch: [21][7/18]\tTime 0.080 (0.119)\tData 0.052 (0.089)\tLoss 0.5800 (0.6347)\tAcc 0.812 (0.768)\n",
      "Epoch: [21][8/18]\tTime 0.073 (0.114)\tData 0.051 (0.084)\tLoss 0.9637 (0.6758)\tAcc 0.562 (0.742)\n",
      "Epoch: [21][9/18]\tTime 0.090 (0.111)\tData 0.058 (0.081)\tLoss 0.2115 (0.6242)\tAcc 1.000 (0.771)\n",
      "Epoch: [21][10/18]\tTime 0.070 (0.107)\tData 0.047 (0.078)\tLoss 1.2191 (0.6837)\tAcc 0.375 (0.731)\n",
      "Epoch: [21][11/18]\tTime 0.082 (0.105)\tData 0.057 (0.076)\tLoss 1.3146 (0.7411)\tAcc 0.375 (0.699)\n",
      "Epoch: [21][12/18]\tTime 0.075 (0.102)\tData 0.055 (0.074)\tLoss 1.0624 (0.7678)\tAcc 0.562 (0.688)\n",
      "Epoch: [21][13/18]\tTime 0.078 (0.100)\tData 0.058 (0.073)\tLoss 1.1896 (0.8003)\tAcc 0.375 (0.663)\n",
      "Epoch: [21][14/18]\tTime 0.077 (0.099)\tData 0.056 (0.072)\tLoss 0.8493 (0.8038)\tAcc 0.625 (0.661)\n",
      "Epoch: [21][15/18]\tTime 0.079 (0.097)\tData 0.059 (0.071)\tLoss 0.8957 (0.8099)\tAcc 0.688 (0.663)\n",
      "Epoch: [21][16/18]\tTime 0.079 (0.096)\tData 0.059 (0.070)\tLoss 0.8218 (0.8107)\tAcc 0.625 (0.660)\n",
      "Epoch: [21][17/18]\tTime 0.080 (0.095)\tData 0.060 (0.070)\tLoss 0.8242 (0.8115)\tAcc 0.625 (0.658)\n",
      "Epoch: [21][18/18]\tTime 0.079 (0.094)\tData 0.060 (0.069)\tLoss 0.8105 (0.8114)\tAcc 0.625 (0.657)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/12]\tTime 0.335 (0.335)\tData 0.304 (0.304)\tLoss 0.8317 (0.8317)\tAcc 0.625 (0.625)\n",
      "Epoch: [22][2/12]\tTime 0.082 (0.209)\tData 0.054 (0.179)\tLoss 1.0446 (0.9381)\tAcc 0.438 (0.531)\n",
      "Epoch: [22][3/12]\tTime 0.083 (0.167)\tData 0.054 (0.138)\tLoss 0.5534 (0.8099)\tAcc 0.750 (0.604)\n",
      "Epoch: [22][4/12]\tTime 0.077 (0.144)\tData 0.050 (0.116)\tLoss 1.0496 (0.8698)\tAcc 0.562 (0.594)\n",
      "Epoch: [22][5/12]\tTime 0.079 (0.131)\tData 0.053 (0.103)\tLoss 0.8267 (0.8612)\tAcc 0.750 (0.625)\n",
      "Epoch: [22][6/12]\tTime 0.079 (0.123)\tData 0.054 (0.095)\tLoss 0.7995 (0.8509)\tAcc 0.688 (0.635)\n",
      "Epoch: [22][7/12]\tTime 0.079 (0.116)\tData 0.053 (0.089)\tLoss 0.5915 (0.8138)\tAcc 0.812 (0.661)\n",
      "Epoch: [22][8/12]\tTime 0.077 (0.111)\tData 0.053 (0.084)\tLoss 0.7771 (0.8092)\tAcc 0.625 (0.656)\n",
      "Epoch: [22][9/12]\tTime 0.077 (0.108)\tData 0.053 (0.081)\tLoss 0.7578 (0.8035)\tAcc 0.625 (0.653)\n",
      "Epoch: [22][10/12]\tTime 0.079 (0.105)\tData 0.055 (0.078)\tLoss 0.6984 (0.7930)\tAcc 0.750 (0.663)\n",
      "Epoch: [22][11/12]\tTime 0.081 (0.103)\tData 0.056 (0.076)\tLoss 0.5123 (0.7675)\tAcc 0.875 (0.682)\n",
      "Epoch: [22][12/12]\tTime 0.082 (0.101)\tData 0.058 (0.075)\tLoss 0.7600 (0.7669)\tAcc 0.667 (0.681)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/18]\tTime 0.342 (0.342)\tData 0.316 (0.316)\tLoss 0.3751 (0.3751)\tAcc 0.875 (0.875)\n",
      "Epoch: [22][2/18]\tTime 0.072 (0.207)\tData 0.049 (0.183)\tLoss 1.1158 (0.7455)\tAcc 0.438 (0.656)\n",
      "Epoch: [22][3/18]\tTime 0.072 (0.162)\tData 0.051 (0.139)\tLoss 0.6007 (0.6972)\tAcc 0.875 (0.729)\n",
      "Epoch: [22][4/18]\tTime 0.081 (0.142)\tData 0.056 (0.118)\tLoss 0.7082 (0.7000)\tAcc 0.688 (0.719)\n",
      "Epoch: [22][5/18]\tTime 0.079 (0.129)\tData 0.055 (0.105)\tLoss 0.7852 (0.7170)\tAcc 0.812 (0.738)\n",
      "Epoch: [22][6/18]\tTime 0.080 (0.121)\tData 0.058 (0.097)\tLoss 0.3026 (0.6479)\tAcc 1.000 (0.781)\n",
      "Epoch: [22][7/18]\tTime 0.077 (0.115)\tData 0.054 (0.091)\tLoss 0.6023 (0.6414)\tAcc 0.688 (0.768)\n",
      "Epoch: [22][8/18]\tTime 0.074 (0.110)\tData 0.053 (0.086)\tLoss 0.9562 (0.6808)\tAcc 0.562 (0.742)\n",
      "Epoch: [22][9/18]\tTime 0.081 (0.106)\tData 0.060 (0.084)\tLoss 0.2126 (0.6288)\tAcc 1.000 (0.771)\n",
      "Epoch: [22][10/18]\tTime 0.081 (0.104)\tData 0.060 (0.081)\tLoss 1.5221 (0.7181)\tAcc 0.375 (0.731)\n",
      "Epoch: [22][11/18]\tTime 0.080 (0.102)\tData 0.060 (0.079)\tLoss 1.2430 (0.7658)\tAcc 0.375 (0.699)\n",
      "Epoch: [22][12/18]\tTime 0.080 (0.100)\tData 0.059 (0.078)\tLoss 1.1514 (0.7979)\tAcc 0.562 (0.688)\n",
      "Epoch: [22][13/18]\tTime 0.079 (0.098)\tData 0.060 (0.076)\tLoss 1.0807 (0.8197)\tAcc 0.625 (0.683)\n",
      "Epoch: [22][14/18]\tTime 0.078 (0.097)\tData 0.058 (0.075)\tLoss 0.8334 (0.8207)\tAcc 0.625 (0.679)\n",
      "Epoch: [22][15/18]\tTime 0.076 (0.096)\tData 0.057 (0.074)\tLoss 0.8971 (0.8258)\tAcc 0.625 (0.675)\n",
      "Epoch: [22][16/18]\tTime 0.076 (0.094)\tData 0.056 (0.073)\tLoss 0.8664 (0.8283)\tAcc 0.688 (0.676)\n",
      "Epoch: [22][17/18]\tTime 0.076 (0.093)\tData 0.057 (0.072)\tLoss 0.8442 (0.8292)\tAcc 0.625 (0.673)\n",
      "Epoch: [22][18/18]\tTime 0.077 (0.092)\tData 0.057 (0.071)\tLoss 0.8949 (0.8311)\tAcc 0.625 (0.671)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/12]\tTime 0.347 (0.347)\tData 0.314 (0.314)\tLoss 0.8676 (0.8676)\tAcc 0.750 (0.750)\n",
      "Epoch: [23][2/12]\tTime 0.073 (0.210)\tData 0.047 (0.180)\tLoss 0.7088 (0.7882)\tAcc 0.812 (0.781)\n",
      "Epoch: [23][3/12]\tTime 0.079 (0.166)\tData 0.051 (0.137)\tLoss 0.8904 (0.8223)\tAcc 0.625 (0.729)\n",
      "Epoch: [23][4/12]\tTime 0.077 (0.144)\tData 0.050 (0.116)\tLoss 0.7828 (0.8124)\tAcc 0.625 (0.703)\n",
      "Epoch: [23][5/12]\tTime 0.088 (0.133)\tData 0.054 (0.103)\tLoss 0.4807 (0.7460)\tAcc 0.812 (0.725)\n",
      "Epoch: [23][6/12]\tTime 0.100 (0.127)\tData 0.053 (0.095)\tLoss 1.2519 (0.8304)\tAcc 0.375 (0.667)\n",
      "Epoch: [23][7/12]\tTime 0.078 (0.120)\tData 0.042 (0.087)\tLoss 0.5169 (0.7856)\tAcc 0.812 (0.688)\n",
      "Epoch: [23][8/12]\tTime 0.067 (0.114)\tData 0.043 (0.082)\tLoss 0.7838 (0.7854)\tAcc 0.625 (0.680)\n",
      "Epoch: [23][9/12]\tTime 0.078 (0.110)\tData 0.054 (0.079)\tLoss 1.0000 (0.8092)\tAcc 0.562 (0.667)\n",
      "Epoch: [23][10/12]\tTime 0.078 (0.107)\tData 0.054 (0.076)\tLoss 0.5947 (0.7878)\tAcc 0.812 (0.681)\n",
      "Epoch: [23][11/12]\tTime 0.079 (0.104)\tData 0.055 (0.074)\tLoss 0.4955 (0.7612)\tAcc 0.875 (0.699)\n",
      "Epoch: [23][12/12]\tTime 0.078 (0.102)\tData 0.054 (0.073)\tLoss 0.7901 (0.7635)\tAcc 0.733 (0.702)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/18]\tTime 0.363 (0.363)\tData 0.333 (0.333)\tLoss 0.4184 (0.4184)\tAcc 0.875 (0.875)\n",
      "Epoch: [23][2/18]\tTime 0.074 (0.219)\tData 0.052 (0.193)\tLoss 1.0910 (0.7547)\tAcc 0.438 (0.656)\n",
      "Epoch: [23][3/18]\tTime 0.079 (0.172)\tData 0.056 (0.147)\tLoss 0.6625 (0.7240)\tAcc 0.812 (0.708)\n",
      "Epoch: [23][4/18]\tTime 0.074 (0.148)\tData 0.052 (0.124)\tLoss 0.7361 (0.7270)\tAcc 0.625 (0.688)\n",
      "Epoch: [23][5/18]\tTime 0.075 (0.133)\tData 0.054 (0.110)\tLoss 0.7280 (0.7272)\tAcc 0.750 (0.700)\n",
      "Epoch: [23][6/18]\tTime 0.077 (0.124)\tData 0.056 (0.101)\tLoss 0.3731 (0.6682)\tAcc 1.000 (0.750)\n",
      "Epoch: [23][7/18]\tTime 0.075 (0.117)\tData 0.053 (0.094)\tLoss 0.7126 (0.6745)\tAcc 0.562 (0.723)\n",
      "Epoch: [23][8/18]\tTime 0.083 (0.113)\tData 0.062 (0.090)\tLoss 1.0803 (0.7253)\tAcc 0.625 (0.711)\n",
      "Epoch: [23][9/18]\tTime 0.081 (0.109)\tData 0.059 (0.087)\tLoss 0.2758 (0.6753)\tAcc 1.000 (0.743)\n",
      "Epoch: [23][10/18]\tTime 0.083 (0.106)\tData 0.058 (0.084)\tLoss 1.3444 (0.7422)\tAcc 0.438 (0.713)\n",
      "Epoch: [23][11/18]\tTime 0.077 (0.104)\tData 0.056 (0.081)\tLoss 1.3494 (0.7974)\tAcc 0.375 (0.682)\n",
      "Epoch: [23][12/18]\tTime 0.077 (0.102)\tData 0.055 (0.079)\tLoss 0.9457 (0.8098)\tAcc 0.625 (0.677)\n",
      "Epoch: [23][13/18]\tTime 0.073 (0.099)\tData 0.052 (0.077)\tLoss 1.0701 (0.8298)\tAcc 0.562 (0.668)\n",
      "Epoch: [23][14/18]\tTime 0.079 (0.098)\tData 0.057 (0.075)\tLoss 0.8241 (0.8294)\tAcc 0.562 (0.661)\n",
      "Epoch: [23][15/18]\tTime 0.076 (0.096)\tData 0.056 (0.074)\tLoss 0.7986 (0.8274)\tAcc 0.688 (0.663)\n",
      "Epoch: [23][16/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 0.6836 (0.8184)\tAcc 0.812 (0.672)\n",
      "Epoch: [23][17/18]\tTime 0.082 (0.095)\tData 0.061 (0.072)\tLoss 0.8941 (0.8228)\tAcc 0.625 (0.669)\n",
      "Epoch: [23][18/18]\tTime 0.079 (0.094)\tData 0.059 (0.072)\tLoss 0.6249 (0.8172)\tAcc 1.000 (0.679)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/12]\tTime 0.258 (0.258)\tData 0.228 (0.228)\tLoss 0.5404 (0.5404)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][2/12]\tTime 0.088 (0.173)\tData 0.060 (0.144)\tLoss 0.7021 (0.6213)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][3/12]\tTime 0.077 (0.141)\tData 0.051 (0.113)\tLoss 0.7915 (0.6780)\tAcc 0.688 (0.729)\n",
      "Epoch: [24][4/12]\tTime 0.093 (0.129)\tData 0.062 (0.100)\tLoss 0.5451 (0.6448)\tAcc 0.750 (0.734)\n",
      "Epoch: [24][5/12]\tTime 0.081 (0.119)\tData 0.051 (0.090)\tLoss 0.7626 (0.6683)\tAcc 0.750 (0.738)\n",
      "Epoch: [24][6/12]\tTime 0.085 (0.114)\tData 0.051 (0.084)\tLoss 0.7345 (0.6794)\tAcc 0.625 (0.719)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24][7/12]\tTime 0.077 (0.108)\tData 0.051 (0.079)\tLoss 0.6698 (0.6780)\tAcc 0.750 (0.723)\n",
      "Epoch: [24][8/12]\tTime 0.084 (0.105)\tData 0.059 (0.077)\tLoss 0.7416 (0.6860)\tAcc 0.688 (0.719)\n",
      "Epoch: [24][9/12]\tTime 0.084 (0.103)\tData 0.059 (0.075)\tLoss 0.6728 (0.6845)\tAcc 0.688 (0.715)\n",
      "Epoch: [24][10/12]\tTime 0.084 (0.101)\tData 0.059 (0.073)\tLoss 1.0489 (0.7209)\tAcc 0.562 (0.700)\n",
      "Epoch: [24][11/12]\tTime 0.084 (0.099)\tData 0.059 (0.072)\tLoss 0.8396 (0.7317)\tAcc 0.688 (0.699)\n",
      "Epoch: [24][12/12]\tTime 0.085 (0.098)\tData 0.059 (0.071)\tLoss 0.4976 (0.7133)\tAcc 0.933 (0.717)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/18]\tTime 0.297 (0.297)\tData 0.271 (0.271)\tLoss 0.3532 (0.3532)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/18]\tTime 0.075 (0.186)\tData 0.053 (0.162)\tLoss 1.0556 (0.7044)\tAcc 0.438 (0.688)\n",
      "Epoch: [24][3/18]\tTime 0.083 (0.152)\tData 0.059 (0.128)\tLoss 0.8384 (0.7491)\tAcc 0.688 (0.688)\n",
      "Epoch: [24][4/18]\tTime 0.081 (0.134)\tData 0.053 (0.109)\tLoss 0.6557 (0.7257)\tAcc 0.625 (0.672)\n",
      "Epoch: [24][5/18]\tTime 0.089 (0.125)\tData 0.050 (0.097)\tLoss 0.8186 (0.7443)\tAcc 0.688 (0.675)\n",
      "Epoch: [24][6/18]\tTime 0.065 (0.115)\tData 0.044 (0.088)\tLoss 0.4090 (0.6884)\tAcc 0.938 (0.719)\n",
      "Epoch: [24][7/18]\tTime 0.077 (0.110)\tData 0.056 (0.084)\tLoss 0.7811 (0.7016)\tAcc 0.625 (0.705)\n",
      "Epoch: [24][8/18]\tTime 0.085 (0.106)\tData 0.059 (0.081)\tLoss 1.0113 (0.7404)\tAcc 0.562 (0.688)\n",
      "Epoch: [24][9/18]\tTime 0.075 (0.103)\tData 0.054 (0.078)\tLoss 0.2884 (0.6901)\tAcc 1.000 (0.722)\n",
      "Epoch: [24][10/18]\tTime 0.087 (0.101)\tData 0.058 (0.076)\tLoss 1.2882 (0.7499)\tAcc 0.375 (0.688)\n",
      "Epoch: [24][11/18]\tTime 0.076 (0.099)\tData 0.050 (0.073)\tLoss 1.4068 (0.8097)\tAcc 0.375 (0.659)\n",
      "Epoch: [24][12/18]\tTime 0.075 (0.097)\tData 0.054 (0.072)\tLoss 0.9879 (0.8245)\tAcc 0.562 (0.651)\n",
      "Epoch: [24][13/18]\tTime 0.081 (0.096)\tData 0.061 (0.071)\tLoss 1.2981 (0.8609)\tAcc 0.438 (0.635)\n",
      "Epoch: [24][14/18]\tTime 0.079 (0.095)\tData 0.059 (0.070)\tLoss 0.8566 (0.8606)\tAcc 0.562 (0.629)\n",
      "Epoch: [24][15/18]\tTime 0.075 (0.093)\tData 0.055 (0.069)\tLoss 0.7960 (0.8563)\tAcc 0.750 (0.638)\n",
      "Epoch: [24][16/18]\tTime 0.075 (0.092)\tData 0.054 (0.068)\tLoss 0.7971 (0.8526)\tAcc 0.688 (0.641)\n",
      "Epoch: [24][17/18]\tTime 0.074 (0.091)\tData 0.054 (0.067)\tLoss 0.9612 (0.8590)\tAcc 0.625 (0.640)\n",
      "Epoch: [24][18/18]\tTime 0.074 (0.090)\tData 0.055 (0.067)\tLoss 0.7077 (0.8547)\tAcc 0.875 (0.646)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/12]\tTime 0.397 (0.397)\tData 0.362 (0.362)\tLoss 0.8981 (0.8981)\tAcc 0.688 (0.688)\n",
      "Epoch: [25][2/12]\tTime 0.074 (0.236)\tData 0.046 (0.204)\tLoss 0.5929 (0.7455)\tAcc 0.875 (0.781)\n",
      "Epoch: [25][3/12]\tTime 0.077 (0.183)\tData 0.051 (0.153)\tLoss 0.5521 (0.6810)\tAcc 0.812 (0.792)\n",
      "Epoch: [25][4/12]\tTime 0.087 (0.159)\tData 0.054 (0.128)\tLoss 0.8414 (0.7211)\tAcc 0.688 (0.766)\n",
      "Epoch: [25][5/12]\tTime 0.080 (0.143)\tData 0.054 (0.113)\tLoss 1.2864 (0.8342)\tAcc 0.438 (0.700)\n",
      "Epoch: [25][6/12]\tTime 0.081 (0.133)\tData 0.052 (0.103)\tLoss 0.7263 (0.8162)\tAcc 0.688 (0.698)\n",
      "Epoch: [25][7/12]\tTime 0.079 (0.125)\tData 0.053 (0.096)\tLoss 0.7616 (0.8084)\tAcc 0.750 (0.705)\n",
      "Epoch: [25][8/12]\tTime 0.078 (0.119)\tData 0.054 (0.091)\tLoss 0.7376 (0.7996)\tAcc 0.750 (0.711)\n",
      "Epoch: [25][9/12]\tTime 0.079 (0.115)\tData 0.054 (0.087)\tLoss 0.8702 (0.8074)\tAcc 0.688 (0.708)\n",
      "Epoch: [25][10/12]\tTime 0.079 (0.111)\tData 0.054 (0.083)\tLoss 0.8148 (0.8082)\tAcc 0.625 (0.700)\n",
      "Epoch: [25][11/12]\tTime 0.083 (0.109)\tData 0.058 (0.081)\tLoss 0.7850 (0.8060)\tAcc 0.688 (0.699)\n",
      "Epoch: [25][12/12]\tTime 0.080 (0.106)\tData 0.056 (0.079)\tLoss 0.5571 (0.7865)\tAcc 0.867 (0.712)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/18]\tTime 0.325 (0.325)\tData 0.297 (0.297)\tLoss 0.3257 (0.3257)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/18]\tTime 0.071 (0.198)\tData 0.048 (0.172)\tLoss 0.9924 (0.6590)\tAcc 0.438 (0.688)\n",
      "Epoch: [25][3/18]\tTime 0.083 (0.159)\tData 0.057 (0.134)\tLoss 0.6387 (0.6523)\tAcc 0.750 (0.708)\n",
      "Epoch: [25][4/18]\tTime 0.078 (0.139)\tData 0.054 (0.114)\tLoss 0.6566 (0.6533)\tAcc 0.625 (0.688)\n",
      "Epoch: [25][5/18]\tTime 0.091 (0.129)\tData 0.056 (0.102)\tLoss 0.8885 (0.7004)\tAcc 0.625 (0.675)\n",
      "Epoch: [25][6/18]\tTime 0.083 (0.122)\tData 0.056 (0.095)\tLoss 0.4173 (0.6532)\tAcc 0.938 (0.719)\n",
      "Epoch: [25][7/18]\tTime 0.075 (0.115)\tData 0.053 (0.089)\tLoss 0.6680 (0.6553)\tAcc 0.688 (0.714)\n",
      "Epoch: [25][8/18]\tTime 0.085 (0.111)\tData 0.056 (0.085)\tLoss 0.9972 (0.6980)\tAcc 0.625 (0.703)\n",
      "Epoch: [25][9/18]\tTime 0.071 (0.107)\tData 0.050 (0.081)\tLoss 0.1885 (0.6414)\tAcc 1.000 (0.736)\n",
      "Epoch: [25][10/18]\tTime 0.078 (0.104)\tData 0.056 (0.078)\tLoss 1.3599 (0.7133)\tAcc 0.438 (0.706)\n",
      "Epoch: [25][11/18]\tTime 0.082 (0.102)\tData 0.055 (0.076)\tLoss 1.2247 (0.7597)\tAcc 0.375 (0.676)\n",
      "Epoch: [25][12/18]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 0.9280 (0.7738)\tAcc 0.625 (0.672)\n",
      "Epoch: [25][13/18]\tTime 0.078 (0.098)\tData 0.058 (0.073)\tLoss 1.2724 (0.8121)\tAcc 0.500 (0.659)\n",
      "Epoch: [25][14/18]\tTime 0.079 (0.097)\tData 0.058 (0.072)\tLoss 0.8365 (0.8139)\tAcc 0.625 (0.656)\n",
      "Epoch: [25][15/18]\tTime 0.080 (0.096)\tData 0.060 (0.071)\tLoss 0.8593 (0.8169)\tAcc 0.750 (0.663)\n",
      "Epoch: [25][16/18]\tTime 0.080 (0.095)\tData 0.060 (0.071)\tLoss 0.6961 (0.8093)\tAcc 0.750 (0.668)\n",
      "Epoch: [25][17/18]\tTime 0.079 (0.094)\tData 0.059 (0.070)\tLoss 0.9636 (0.8184)\tAcc 0.625 (0.665)\n",
      "Epoch: [25][18/18]\tTime 0.080 (0.093)\tData 0.060 (0.069)\tLoss 0.7995 (0.8179)\tAcc 0.750 (0.668)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/12]\tTime 0.365 (0.365)\tData 0.324 (0.324)\tLoss 0.9001 (0.9001)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][2/12]\tTime 0.067 (0.216)\tData 0.039 (0.182)\tLoss 1.2439 (1.0720)\tAcc 0.312 (0.531)\n",
      "Epoch: [26][3/12]\tTime 0.081 (0.171)\tData 0.054 (0.139)\tLoss 0.7550 (0.9663)\tAcc 0.688 (0.583)\n",
      "Epoch: [26][4/12]\tTime 0.089 (0.151)\tData 0.060 (0.119)\tLoss 0.5214 (0.8551)\tAcc 0.750 (0.625)\n",
      "Epoch: [26][5/12]\tTime 0.087 (0.138)\tData 0.059 (0.107)\tLoss 0.5386 (0.7918)\tAcc 0.875 (0.675)\n",
      "Epoch: [26][6/12]\tTime 0.082 (0.129)\tData 0.055 (0.098)\tLoss 0.7564 (0.7859)\tAcc 0.750 (0.688)\n",
      "Epoch: [26][7/12]\tTime 0.076 (0.121)\tData 0.053 (0.092)\tLoss 0.7125 (0.7754)\tAcc 0.688 (0.688)\n",
      "Epoch: [26][8/12]\tTime 0.079 (0.116)\tData 0.056 (0.087)\tLoss 0.6400 (0.7585)\tAcc 0.750 (0.695)\n",
      "Epoch: [26][9/12]\tTime 0.078 (0.112)\tData 0.054 (0.084)\tLoss 0.3858 (0.7171)\tAcc 0.938 (0.722)\n",
      "Epoch: [26][10/12]\tTime 0.078 (0.108)\tData 0.054 (0.081)\tLoss 0.8848 (0.7339)\tAcc 0.688 (0.719)\n",
      "Epoch: [26][11/12]\tTime 0.081 (0.106)\tData 0.057 (0.079)\tLoss 0.7592 (0.7362)\tAcc 0.688 (0.716)\n",
      "Epoch: [26][12/12]\tTime 0.086 (0.104)\tData 0.062 (0.077)\tLoss 0.7694 (0.7388)\tAcc 0.667 (0.712)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/18]\tTime 0.340 (0.340)\tData 0.309 (0.309)\tLoss 0.3330 (0.3330)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/18]\tTime 0.068 (0.204)\tData 0.045 (0.177)\tLoss 0.9298 (0.6314)\tAcc 0.438 (0.688)\n",
      "Epoch: [26][3/18]\tTime 0.079 (0.162)\tData 0.058 (0.138)\tLoss 0.5516 (0.6048)\tAcc 0.812 (0.729)\n",
      "Epoch: [26][4/18]\tTime 0.083 (0.143)\tData 0.059 (0.118)\tLoss 0.6624 (0.6192)\tAcc 0.625 (0.703)\n",
      "Epoch: [26][5/18]\tTime 0.078 (0.130)\tData 0.057 (0.106)\tLoss 0.7432 (0.6440)\tAcc 0.750 (0.713)\n",
      "Epoch: [26][6/18]\tTime 0.076 (0.121)\tData 0.055 (0.097)\tLoss 0.3181 (0.5897)\tAcc 1.000 (0.760)\n",
      "Epoch: [26][7/18]\tTime 0.075 (0.114)\tData 0.053 (0.091)\tLoss 0.7166 (0.6078)\tAcc 0.500 (0.723)\n",
      "Epoch: [26][8/18]\tTime 0.075 (0.109)\tData 0.054 (0.086)\tLoss 1.2863 (0.6926)\tAcc 0.500 (0.695)\n",
      "Epoch: [26][9/18]\tTime 0.075 (0.105)\tData 0.053 (0.083)\tLoss 0.1732 (0.6349)\tAcc 1.000 (0.729)\n",
      "Epoch: [26][10/18]\tTime 0.074 (0.102)\tData 0.053 (0.080)\tLoss 1.4286 (0.7143)\tAcc 0.375 (0.694)\n",
      "Epoch: [26][11/18]\tTime 0.076 (0.100)\tData 0.054 (0.077)\tLoss 1.4284 (0.7792)\tAcc 0.375 (0.665)\n",
      "Epoch: [26][12/18]\tTime 0.072 (0.097)\tData 0.052 (0.075)\tLoss 1.0045 (0.7980)\tAcc 0.625 (0.661)\n",
      "Epoch: [26][13/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 1.0697 (0.8189)\tAcc 0.500 (0.649)\n",
      "Epoch: [26][14/18]\tTime 0.075 (0.094)\tData 0.055 (0.072)\tLoss 0.7833 (0.8163)\tAcc 0.562 (0.643)\n",
      "Epoch: [26][15/18]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.9680 (0.8265)\tAcc 0.750 (0.650)\n",
      "Epoch: [26][16/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.7568 (0.8221)\tAcc 0.688 (0.652)\n",
      "Epoch: [26][17/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.9523 (0.8298)\tAcc 0.625 (0.651)\n",
      "Epoch: [26][18/18]\tTime 0.073 (0.090)\tData 0.055 (0.068)\tLoss 0.7395 (0.8272)\tAcc 0.750 (0.654)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/12]\tTime 0.323 (0.323)\tData 0.291 (0.291)\tLoss 0.7177 (0.7177)\tAcc 0.688 (0.688)\n",
      "Epoch: [27][2/12]\tTime 0.075 (0.199)\tData 0.048 (0.170)\tLoss 0.8326 (0.7751)\tAcc 0.625 (0.656)\n",
      "Epoch: [27][3/12]\tTime 0.080 (0.159)\tData 0.052 (0.130)\tLoss 0.6997 (0.7500)\tAcc 0.812 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][4/12]\tTime 0.076 (0.139)\tData 0.050 (0.110)\tLoss 0.9860 (0.8090)\tAcc 0.562 (0.672)\n",
      "Epoch: [27][5/12]\tTime 0.081 (0.127)\tData 0.054 (0.099)\tLoss 0.7242 (0.7920)\tAcc 0.625 (0.663)\n",
      "Epoch: [27][6/12]\tTime 0.079 (0.119)\tData 0.052 (0.091)\tLoss 0.7037 (0.7773)\tAcc 0.750 (0.677)\n",
      "Epoch: [27][7/12]\tTime 0.077 (0.113)\tData 0.051 (0.085)\tLoss 0.8619 (0.7894)\tAcc 0.625 (0.670)\n",
      "Epoch: [27][8/12]\tTime 0.078 (0.109)\tData 0.054 (0.081)\tLoss 0.5202 (0.7558)\tAcc 0.812 (0.688)\n",
      "Epoch: [27][9/12]\tTime 0.077 (0.105)\tData 0.054 (0.078)\tLoss 0.8650 (0.7679)\tAcc 0.625 (0.681)\n",
      "Epoch: [27][10/12]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.4783 (0.7389)\tAcc 0.938 (0.706)\n",
      "Epoch: [27][11/12]\tTime 0.079 (0.100)\tData 0.055 (0.074)\tLoss 0.5340 (0.7203)\tAcc 0.812 (0.716)\n",
      "Epoch: [27][12/12]\tTime 0.078 (0.098)\tData 0.054 (0.072)\tLoss 0.6812 (0.7172)\tAcc 0.867 (0.728)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/18]\tTime 0.327 (0.327)\tData 0.299 (0.299)\tLoss 0.3149 (0.3149)\tAcc 0.875 (0.875)\n",
      "Epoch: [27][2/18]\tTime 0.073 (0.200)\tData 0.049 (0.174)\tLoss 0.8492 (0.5820)\tAcc 0.438 (0.656)\n",
      "Epoch: [27][3/18]\tTime 0.071 (0.157)\tData 0.051 (0.133)\tLoss 0.7704 (0.6448)\tAcc 0.750 (0.688)\n",
      "Epoch: [27][4/18]\tTime 0.076 (0.137)\tData 0.053 (0.113)\tLoss 0.6962 (0.6577)\tAcc 0.625 (0.672)\n",
      "Epoch: [27][5/18]\tTime 0.073 (0.124)\tData 0.052 (0.101)\tLoss 0.8089 (0.6879)\tAcc 0.750 (0.688)\n",
      "Epoch: [27][6/18]\tTime 0.074 (0.116)\tData 0.053 (0.093)\tLoss 0.2658 (0.6176)\tAcc 1.000 (0.740)\n",
      "Epoch: [27][7/18]\tTime 0.080 (0.111)\tData 0.057 (0.088)\tLoss 0.5568 (0.6089)\tAcc 0.750 (0.741)\n",
      "Epoch: [27][8/18]\tTime 0.079 (0.107)\tData 0.057 (0.084)\tLoss 1.1605 (0.6779)\tAcc 0.625 (0.727)\n",
      "Epoch: [27][9/18]\tTime 0.080 (0.104)\tData 0.059 (0.081)\tLoss 0.1770 (0.6222)\tAcc 1.000 (0.757)\n",
      "Epoch: [27][10/18]\tTime 0.080 (0.101)\tData 0.060 (0.079)\tLoss 1.2504 (0.6850)\tAcc 0.375 (0.719)\n",
      "Epoch: [27][11/18]\tTime 0.079 (0.099)\tData 0.058 (0.077)\tLoss 1.4799 (0.7573)\tAcc 0.375 (0.688)\n",
      "Epoch: [27][12/18]\tTime 0.079 (0.098)\tData 0.059 (0.076)\tLoss 1.0133 (0.7786)\tAcc 0.625 (0.682)\n",
      "Epoch: [27][13/18]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 0.9418 (0.7912)\tAcc 0.625 (0.678)\n",
      "Epoch: [27][14/18]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.7360 (0.7872)\tAcc 0.688 (0.679)\n",
      "Epoch: [27][15/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.9295 (0.7967)\tAcc 0.688 (0.679)\n",
      "Epoch: [27][16/18]\tTime 0.077 (0.093)\tData 0.057 (0.071)\tLoss 0.8045 (0.7972)\tAcc 0.750 (0.684)\n",
      "Epoch: [27][17/18]\tTime 0.080 (0.092)\tData 0.061 (0.071)\tLoss 0.9760 (0.8077)\tAcc 0.625 (0.680)\n",
      "Epoch: [27][18/18]\tTime 0.080 (0.091)\tData 0.061 (0.070)\tLoss 0.6324 (0.8027)\tAcc 0.625 (0.679)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/12]\tTime 0.300 (0.300)\tData 0.270 (0.270)\tLoss 0.3900 (0.3900)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/12]\tTime 0.080 (0.190)\tData 0.049 (0.160)\tLoss 0.5856 (0.4878)\tAcc 0.875 (0.906)\n",
      "Epoch: [28][3/12]\tTime 0.089 (0.156)\tData 0.055 (0.125)\tLoss 1.0048 (0.6602)\tAcc 0.562 (0.792)\n",
      "Epoch: [28][4/12]\tTime 0.095 (0.141)\tData 0.054 (0.107)\tLoss 0.7440 (0.6811)\tAcc 0.688 (0.766)\n",
      "Epoch: [28][5/12]\tTime 0.081 (0.129)\tData 0.049 (0.095)\tLoss 0.7345 (0.6918)\tAcc 0.625 (0.738)\n",
      "Epoch: [28][6/12]\tTime 0.074 (0.120)\tData 0.048 (0.088)\tLoss 0.5950 (0.6757)\tAcc 0.812 (0.750)\n",
      "Epoch: [28][7/12]\tTime 0.079 (0.114)\tData 0.055 (0.083)\tLoss 0.9820 (0.7194)\tAcc 0.562 (0.723)\n",
      "Epoch: [28][8/12]\tTime 0.081 (0.110)\tData 0.055 (0.079)\tLoss 1.0918 (0.7660)\tAcc 0.500 (0.695)\n",
      "Epoch: [28][9/12]\tTime 0.078 (0.106)\tData 0.054 (0.077)\tLoss 0.4702 (0.7331)\tAcc 0.688 (0.694)\n",
      "Epoch: [28][10/12]\tTime 0.081 (0.104)\tData 0.056 (0.074)\tLoss 0.6130 (0.7211)\tAcc 0.688 (0.694)\n",
      "Epoch: [28][11/12]\tTime 0.086 (0.102)\tData 0.061 (0.073)\tLoss 0.6081 (0.7108)\tAcc 0.750 (0.699)\n",
      "Epoch: [28][12/12]\tTime 0.087 (0.101)\tData 0.062 (0.072)\tLoss 0.8577 (0.7224)\tAcc 0.533 (0.686)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/18]\tTime 0.315 (0.315)\tData 0.289 (0.289)\tLoss 0.2730 (0.2730)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/18]\tTime 0.070 (0.193)\tData 0.049 (0.169)\tLoss 0.9391 (0.6061)\tAcc 0.438 (0.688)\n",
      "Epoch: [28][3/18]\tTime 0.075 (0.154)\tData 0.052 (0.130)\tLoss 0.5158 (0.5760)\tAcc 0.938 (0.771)\n",
      "Epoch: [28][4/18]\tTime 0.080 (0.135)\tData 0.051 (0.110)\tLoss 0.7331 (0.6153)\tAcc 0.625 (0.734)\n",
      "Epoch: [28][5/18]\tTime 0.068 (0.122)\tData 0.046 (0.098)\tLoss 0.9601 (0.6842)\tAcc 0.750 (0.738)\n",
      "Epoch: [28][6/18]\tTime 0.075 (0.114)\tData 0.053 (0.090)\tLoss 0.2276 (0.6081)\tAcc 1.000 (0.781)\n",
      "Epoch: [28][7/18]\tTime 0.075 (0.108)\tData 0.052 (0.085)\tLoss 0.6459 (0.6135)\tAcc 0.688 (0.768)\n",
      "Epoch: [28][8/18]\tTime 0.074 (0.104)\tData 0.052 (0.081)\tLoss 0.9741 (0.6586)\tAcc 0.625 (0.750)\n",
      "Epoch: [28][9/18]\tTime 0.074 (0.101)\tData 0.053 (0.078)\tLoss 0.1549 (0.6026)\tAcc 1.000 (0.778)\n",
      "Epoch: [28][10/18]\tTime 0.075 (0.098)\tData 0.053 (0.075)\tLoss 1.2207 (0.6644)\tAcc 0.438 (0.744)\n",
      "Epoch: [28][11/18]\tTime 0.074 (0.096)\tData 0.052 (0.073)\tLoss 1.3556 (0.7273)\tAcc 0.375 (0.710)\n",
      "Epoch: [28][12/18]\tTime 0.072 (0.094)\tData 0.052 (0.071)\tLoss 0.9476 (0.7456)\tAcc 0.625 (0.703)\n",
      "Epoch: [28][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.0287 (0.7674)\tAcc 0.625 (0.697)\n",
      "Epoch: [28][14/18]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.7952 (0.7694)\tAcc 0.562 (0.688)\n",
      "Epoch: [28][15/18]\tTime 0.073 (0.090)\tData 0.055 (0.068)\tLoss 0.8312 (0.7735)\tAcc 0.688 (0.688)\n",
      "Epoch: [28][16/18]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.7480 (0.7719)\tAcc 0.688 (0.688)\n",
      "Epoch: [28][17/18]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 0.8624 (0.7772)\tAcc 0.625 (0.684)\n",
      "Epoch: [28][18/18]\tTime 0.073 (0.087)\tData 0.055 (0.066)\tLoss 0.6273 (0.7730)\tAcc 1.000 (0.693)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/12]\tTime 0.260 (0.260)\tData 0.229 (0.229)\tLoss 0.8160 (0.8160)\tAcc 0.625 (0.625)\n",
      "Epoch: [29][2/12]\tTime 0.075 (0.167)\tData 0.048 (0.139)\tLoss 0.6218 (0.7189)\tAcc 0.688 (0.656)\n",
      "Epoch: [29][3/12]\tTime 0.081 (0.139)\tData 0.053 (0.110)\tLoss 0.9081 (0.7820)\tAcc 0.688 (0.667)\n",
      "Epoch: [29][4/12]\tTime 0.077 (0.123)\tData 0.051 (0.095)\tLoss 0.8197 (0.7914)\tAcc 0.688 (0.672)\n",
      "Epoch: [29][5/12]\tTime 0.079 (0.115)\tData 0.054 (0.087)\tLoss 0.5760 (0.7483)\tAcc 0.875 (0.713)\n",
      "Epoch: [29][6/12]\tTime 0.078 (0.109)\tData 0.053 (0.081)\tLoss 0.7415 (0.7472)\tAcc 0.688 (0.708)\n",
      "Epoch: [29][7/12]\tTime 0.078 (0.104)\tData 0.053 (0.077)\tLoss 0.7547 (0.7483)\tAcc 0.688 (0.705)\n",
      "Epoch: [29][8/12]\tTime 0.081 (0.101)\tData 0.055 (0.075)\tLoss 0.5632 (0.7251)\tAcc 0.812 (0.719)\n",
      "Epoch: [29][9/12]\tTime 0.075 (0.098)\tData 0.052 (0.072)\tLoss 0.6202 (0.7135)\tAcc 0.875 (0.736)\n",
      "Epoch: [29][10/12]\tTime 0.078 (0.096)\tData 0.055 (0.070)\tLoss 1.1339 (0.7555)\tAcc 0.438 (0.706)\n",
      "Epoch: [29][11/12]\tTime 0.079 (0.095)\tData 0.056 (0.069)\tLoss 0.4764 (0.7301)\tAcc 0.875 (0.722)\n",
      "Epoch: [29][12/12]\tTime 0.078 (0.093)\tData 0.054 (0.068)\tLoss 0.7554 (0.7321)\tAcc 0.733 (0.723)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/18]\tTime 0.312 (0.312)\tData 0.286 (0.286)\tLoss 0.3033 (0.3033)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/18]\tTime 0.071 (0.191)\tData 0.049 (0.167)\tLoss 1.0633 (0.6833)\tAcc 0.438 (0.688)\n",
      "Epoch: [29][3/18]\tTime 0.075 (0.152)\tData 0.052 (0.129)\tLoss 0.5551 (0.6406)\tAcc 0.812 (0.729)\n",
      "Epoch: [29][4/18]\tTime 0.073 (0.133)\tData 0.052 (0.110)\tLoss 0.6950 (0.6542)\tAcc 0.625 (0.703)\n",
      "Epoch: [29][5/18]\tTime 0.081 (0.122)\tData 0.059 (0.100)\tLoss 0.7621 (0.6758)\tAcc 0.688 (0.700)\n",
      "Epoch: [29][6/18]\tTime 0.081 (0.115)\tData 0.058 (0.093)\tLoss 0.2467 (0.6042)\tAcc 1.000 (0.750)\n",
      "Epoch: [29][7/18]\tTime 0.083 (0.111)\tData 0.057 (0.088)\tLoss 0.5289 (0.5935)\tAcc 0.750 (0.750)\n",
      "Epoch: [29][8/18]\tTime 0.077 (0.107)\tData 0.056 (0.084)\tLoss 1.0033 (0.6447)\tAcc 0.625 (0.734)\n",
      "Epoch: [29][9/18]\tTime 0.086 (0.104)\tData 0.059 (0.081)\tLoss 0.2409 (0.5998)\tAcc 1.000 (0.764)\n",
      "Epoch: [29][10/18]\tTime 0.075 (0.101)\tData 0.054 (0.078)\tLoss 1.4583 (0.6857)\tAcc 0.375 (0.725)\n",
      "Epoch: [29][11/18]\tTime 0.082 (0.100)\tData 0.057 (0.076)\tLoss 1.3128 (0.7427)\tAcc 0.375 (0.693)\n",
      "Epoch: [29][12/18]\tTime 0.079 (0.098)\tData 0.056 (0.075)\tLoss 0.9343 (0.7587)\tAcc 0.562 (0.682)\n",
      "Epoch: [29][13/18]\tTime 0.076 (0.096)\tData 0.056 (0.073)\tLoss 1.0417 (0.7804)\tAcc 0.688 (0.683)\n",
      "Epoch: [29][14/18]\tTime 0.080 (0.095)\tData 0.059 (0.072)\tLoss 0.8550 (0.7858)\tAcc 0.625 (0.679)\n",
      "Epoch: [29][15/18]\tTime 0.081 (0.094)\tData 0.061 (0.071)\tLoss 0.9562 (0.7971)\tAcc 0.688 (0.679)\n",
      "Epoch: [29][16/18]\tTime 0.079 (0.093)\tData 0.060 (0.071)\tLoss 0.7700 (0.7954)\tAcc 0.750 (0.684)\n",
      "Epoch: [29][17/18]\tTime 0.079 (0.092)\tData 0.059 (0.070)\tLoss 0.7727 (0.7941)\tAcc 0.625 (0.680)\n",
      "Epoch: [29][18/18]\tTime 0.081 (0.092)\tData 0.060 (0.069)\tLoss 0.7076 (0.7916)\tAcc 0.875 (0.686)\n",
      "train at epoch 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][1/12]\tTime 0.308 (0.308)\tData 0.271 (0.271)\tLoss 0.5869 (0.5869)\tAcc 0.812 (0.812)\n",
      "Epoch: [30][2/12]\tTime 0.070 (0.189)\tData 0.043 (0.157)\tLoss 0.6396 (0.6133)\tAcc 0.812 (0.812)\n",
      "Epoch: [30][3/12]\tTime 0.095 (0.158)\tData 0.052 (0.122)\tLoss 0.5198 (0.5821)\tAcc 0.750 (0.792)\n",
      "Epoch: [30][4/12]\tTime 0.067 (0.135)\tData 0.038 (0.101)\tLoss 0.4934 (0.5599)\tAcc 0.812 (0.797)\n",
      "Epoch: [30][5/12]\tTime 0.077 (0.123)\tData 0.051 (0.091)\tLoss 1.0786 (0.6636)\tAcc 0.500 (0.738)\n",
      "Epoch: [30][6/12]\tTime 0.082 (0.116)\tData 0.053 (0.085)\tLoss 0.7172 (0.6726)\tAcc 0.750 (0.740)\n",
      "Epoch: [30][7/12]\tTime 0.077 (0.111)\tData 0.050 (0.080)\tLoss 0.9092 (0.7064)\tAcc 0.625 (0.723)\n",
      "Epoch: [30][8/12]\tTime 0.079 (0.107)\tData 0.053 (0.077)\tLoss 0.7688 (0.7142)\tAcc 0.750 (0.727)\n",
      "Epoch: [30][9/12]\tTime 0.077 (0.103)\tData 0.052 (0.074)\tLoss 0.6919 (0.7117)\tAcc 0.750 (0.729)\n",
      "Epoch: [30][10/12]\tTime 0.078 (0.101)\tData 0.054 (0.072)\tLoss 0.9172 (0.7323)\tAcc 0.688 (0.725)\n",
      "Epoch: [30][11/12]\tTime 0.079 (0.099)\tData 0.055 (0.070)\tLoss 1.0296 (0.7593)\tAcc 0.500 (0.705)\n",
      "Epoch: [30][12/12]\tTime 0.080 (0.097)\tData 0.056 (0.069)\tLoss 0.6830 (0.7533)\tAcc 0.800 (0.712)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/18]\tTime 0.264 (0.264)\tData 0.235 (0.235)\tLoss 0.3129 (0.3129)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/18]\tTime 0.069 (0.167)\tData 0.046 (0.141)\tLoss 1.0237 (0.6683)\tAcc 0.438 (0.688)\n",
      "Epoch: [30][3/18]\tTime 0.078 (0.137)\tData 0.056 (0.113)\tLoss 0.6064 (0.6477)\tAcc 0.812 (0.729)\n",
      "Epoch: [30][4/18]\tTime 0.088 (0.125)\tData 0.058 (0.099)\tLoss 0.7685 (0.6779)\tAcc 0.562 (0.688)\n",
      "Epoch: [30][5/18]\tTime 0.074 (0.115)\tData 0.052 (0.089)\tLoss 0.9726 (0.7368)\tAcc 0.562 (0.663)\n",
      "Epoch: [30][6/18]\tTime 0.079 (0.109)\tData 0.057 (0.084)\tLoss 0.3794 (0.6772)\tAcc 0.875 (0.698)\n",
      "Epoch: [30][7/18]\tTime 0.083 (0.105)\tData 0.058 (0.080)\tLoss 0.8037 (0.6953)\tAcc 0.500 (0.670)\n",
      "Epoch: [30][8/18]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 1.0758 (0.7429)\tAcc 0.625 (0.664)\n",
      "Epoch: [30][9/18]\tTime 0.098 (0.101)\tData 0.058 (0.075)\tLoss 0.2297 (0.6858)\tAcc 1.000 (0.701)\n",
      "Epoch: [30][10/18]\tTime 0.080 (0.099)\tData 0.057 (0.073)\tLoss 1.0837 (0.7256)\tAcc 0.438 (0.675)\n",
      "Epoch: [30][11/18]\tTime 0.081 (0.097)\tData 0.059 (0.072)\tLoss 1.2962 (0.7775)\tAcc 0.375 (0.648)\n",
      "Epoch: [30][12/18]\tTime 0.081 (0.096)\tData 0.060 (0.071)\tLoss 0.9046 (0.7881)\tAcc 0.562 (0.641)\n",
      "Epoch: [30][13/18]\tTime 0.072 (0.094)\tData 0.052 (0.069)\tLoss 1.1750 (0.8179)\tAcc 0.562 (0.635)\n",
      "Epoch: [30][14/18]\tTime 0.077 (0.093)\tData 0.057 (0.069)\tLoss 0.7319 (0.8117)\tAcc 0.688 (0.638)\n",
      "Epoch: [30][15/18]\tTime 0.075 (0.092)\tData 0.055 (0.068)\tLoss 0.9183 (0.8188)\tAcc 0.625 (0.638)\n",
      "Epoch: [30][16/18]\tTime 0.078 (0.091)\tData 0.057 (0.067)\tLoss 0.6985 (0.8113)\tAcc 0.750 (0.645)\n",
      "Epoch: [30][17/18]\tTime 0.076 (0.090)\tData 0.055 (0.066)\tLoss 0.7959 (0.8104)\tAcc 0.625 (0.643)\n",
      "Epoch: [30][18/18]\tTime 0.079 (0.089)\tData 0.060 (0.066)\tLoss 0.6462 (0.8057)\tAcc 1.000 (0.654)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/12]\tTime 0.325 (0.325)\tData 0.291 (0.291)\tLoss 0.6761 (0.6761)\tAcc 0.750 (0.750)\n",
      "Epoch: [31][2/12]\tTime 0.072 (0.199)\tData 0.045 (0.168)\tLoss 0.5729 (0.6245)\tAcc 0.812 (0.781)\n",
      "Epoch: [31][3/12]\tTime 0.081 (0.159)\tData 0.053 (0.130)\tLoss 0.7678 (0.6723)\tAcc 0.750 (0.771)\n",
      "Epoch: [31][4/12]\tTime 0.085 (0.141)\tData 0.057 (0.112)\tLoss 0.7854 (0.7006)\tAcc 0.750 (0.766)\n",
      "Epoch: [31][5/12]\tTime 0.091 (0.131)\tData 0.060 (0.101)\tLoss 0.6186 (0.6842)\tAcc 0.750 (0.762)\n",
      "Epoch: [31][6/12]\tTime 0.081 (0.123)\tData 0.053 (0.093)\tLoss 1.0257 (0.7411)\tAcc 0.562 (0.729)\n",
      "Epoch: [31][7/12]\tTime 0.075 (0.116)\tData 0.051 (0.087)\tLoss 0.6044 (0.7216)\tAcc 0.812 (0.741)\n",
      "Epoch: [31][8/12]\tTime 0.081 (0.111)\tData 0.057 (0.083)\tLoss 0.6363 (0.7109)\tAcc 0.688 (0.734)\n",
      "Epoch: [31][9/12]\tTime 0.083 (0.108)\tData 0.060 (0.081)\tLoss 0.6337 (0.7023)\tAcc 0.688 (0.729)\n",
      "Epoch: [31][10/12]\tTime 0.083 (0.106)\tData 0.059 (0.079)\tLoss 0.7659 (0.7087)\tAcc 0.688 (0.725)\n",
      "Epoch: [31][11/12]\tTime 0.084 (0.104)\tData 0.061 (0.077)\tLoss 0.7947 (0.7165)\tAcc 0.625 (0.716)\n",
      "Epoch: [31][12/12]\tTime 0.084 (0.102)\tData 0.060 (0.076)\tLoss 0.8448 (0.7266)\tAcc 0.667 (0.712)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/18]\tTime 0.335 (0.335)\tData 0.310 (0.310)\tLoss 0.3072 (0.3072)\tAcc 0.875 (0.875)\n",
      "Epoch: [31][2/18]\tTime 0.073 (0.204)\tData 0.051 (0.180)\tLoss 0.9993 (0.6532)\tAcc 0.438 (0.656)\n",
      "Epoch: [31][3/18]\tTime 0.074 (0.161)\tData 0.053 (0.138)\tLoss 0.5687 (0.6251)\tAcc 0.750 (0.688)\n",
      "Epoch: [31][4/18]\tTime 0.074 (0.139)\tData 0.053 (0.117)\tLoss 0.6818 (0.6393)\tAcc 0.625 (0.672)\n",
      "Epoch: [31][5/18]\tTime 0.083 (0.128)\tData 0.055 (0.104)\tLoss 0.8791 (0.6872)\tAcc 0.812 (0.700)\n",
      "Epoch: [31][6/18]\tTime 0.082 (0.120)\tData 0.059 (0.097)\tLoss 0.2204 (0.6094)\tAcc 1.000 (0.750)\n",
      "Epoch: [31][7/18]\tTime 0.081 (0.114)\tData 0.053 (0.091)\tLoss 0.7444 (0.6287)\tAcc 0.562 (0.723)\n",
      "Epoch: [31][8/18]\tTime 0.074 (0.109)\tData 0.052 (0.086)\tLoss 0.9498 (0.6688)\tAcc 0.625 (0.711)\n",
      "Epoch: [31][9/18]\tTime 0.078 (0.106)\tData 0.052 (0.082)\tLoss 0.1585 (0.6121)\tAcc 1.000 (0.743)\n",
      "Epoch: [31][10/18]\tTime 0.069 (0.102)\tData 0.049 (0.079)\tLoss 1.3270 (0.6836)\tAcc 0.375 (0.706)\n",
      "Epoch: [31][11/18]\tTime 0.087 (0.101)\tData 0.059 (0.077)\tLoss 1.3378 (0.7431)\tAcc 0.375 (0.676)\n",
      "Epoch: [31][12/18]\tTime 0.070 (0.098)\tData 0.050 (0.075)\tLoss 0.9290 (0.7586)\tAcc 0.562 (0.667)\n",
      "Epoch: [31][13/18]\tTime 0.087 (0.097)\tData 0.067 (0.074)\tLoss 1.4582 (0.8124)\tAcc 0.438 (0.649)\n",
      "Epoch: [31][14/18]\tTime 0.078 (0.096)\tData 0.058 (0.073)\tLoss 0.7057 (0.8048)\tAcc 0.625 (0.647)\n",
      "Epoch: [31][15/18]\tTime 0.078 (0.095)\tData 0.059 (0.072)\tLoss 0.9000 (0.8111)\tAcc 0.625 (0.646)\n",
      "Epoch: [31][16/18]\tTime 0.077 (0.094)\tData 0.058 (0.071)\tLoss 0.9152 (0.8176)\tAcc 0.625 (0.645)\n",
      "Epoch: [31][17/18]\tTime 0.075 (0.093)\tData 0.055 (0.070)\tLoss 0.8200 (0.8178)\tAcc 0.688 (0.647)\n",
      "Epoch: [31][18/18]\tTime 0.077 (0.092)\tData 0.057 (0.069)\tLoss 1.0546 (0.8246)\tAcc 0.500 (0.643)\n",
      "train at epoch 32\n",
      "Epoch: [32][1/12]\tTime 0.344 (0.344)\tData 0.307 (0.307)\tLoss 0.4525 (0.4525)\tAcc 0.875 (0.875)\n",
      "Epoch: [32][2/12]\tTime 0.069 (0.207)\tData 0.043 (0.175)\tLoss 0.4306 (0.4415)\tAcc 0.875 (0.875)\n",
      "Epoch: [32][3/12]\tTime 0.079 (0.164)\tData 0.052 (0.134)\tLoss 0.3914 (0.4248)\tAcc 0.812 (0.854)\n",
      "Epoch: [32][4/12]\tTime 0.083 (0.144)\tData 0.054 (0.114)\tLoss 1.2384 (0.6282)\tAcc 0.562 (0.781)\n",
      "Epoch: [32][5/12]\tTime 0.082 (0.131)\tData 0.051 (0.101)\tLoss 0.7479 (0.6522)\tAcc 0.625 (0.750)\n",
      "Epoch: [32][6/12]\tTime 0.076 (0.122)\tData 0.051 (0.093)\tLoss 0.8156 (0.6794)\tAcc 0.688 (0.740)\n",
      "Epoch: [32][7/12]\tTime 0.080 (0.116)\tData 0.055 (0.087)\tLoss 0.6865 (0.6804)\tAcc 0.812 (0.750)\n",
      "Epoch: [32][8/12]\tTime 0.080 (0.112)\tData 0.056 (0.083)\tLoss 0.7516 (0.6893)\tAcc 0.688 (0.742)\n",
      "Epoch: [32][9/12]\tTime 0.080 (0.108)\tData 0.056 (0.080)\tLoss 0.5245 (0.6710)\tAcc 0.750 (0.743)\n",
      "Epoch: [32][10/12]\tTime 0.083 (0.106)\tData 0.058 (0.078)\tLoss 0.8670 (0.6906)\tAcc 0.625 (0.731)\n",
      "Epoch: [32][11/12]\tTime 0.082 (0.103)\tData 0.057 (0.076)\tLoss 0.8923 (0.7089)\tAcc 0.625 (0.722)\n",
      "Epoch: [32][12/12]\tTime 0.081 (0.102)\tData 0.056 (0.075)\tLoss 0.6260 (0.7024)\tAcc 0.733 (0.723)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/18]\tTime 0.296 (0.296)\tData 0.272 (0.272)\tLoss 0.2819 (0.2819)\tAcc 0.938 (0.938)\n",
      "Epoch: [32][2/18]\tTime 0.073 (0.185)\tData 0.050 (0.161)\tLoss 0.9457 (0.6138)\tAcc 0.438 (0.688)\n",
      "Epoch: [32][3/18]\tTime 0.074 (0.148)\tData 0.052 (0.124)\tLoss 0.7228 (0.6501)\tAcc 0.625 (0.667)\n",
      "Epoch: [32][4/18]\tTime 0.076 (0.130)\tData 0.052 (0.106)\tLoss 0.6767 (0.6568)\tAcc 0.625 (0.656)\n",
      "Epoch: [32][5/18]\tTime 0.075 (0.119)\tData 0.053 (0.096)\tLoss 0.8833 (0.7021)\tAcc 0.812 (0.688)\n",
      "Epoch: [32][6/18]\tTime 0.078 (0.112)\tData 0.053 (0.089)\tLoss 0.3221 (0.6387)\tAcc 0.938 (0.729)\n",
      "Epoch: [32][7/18]\tTime 0.074 (0.106)\tData 0.052 (0.083)\tLoss 0.7163 (0.6498)\tAcc 0.625 (0.714)\n",
      "Epoch: [32][8/18]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 1.0090 (0.6947)\tAcc 0.688 (0.711)\n",
      "Epoch: [32][9/18]\tTime 0.075 (0.099)\tData 0.054 (0.077)\tLoss 0.2023 (0.6400)\tAcc 1.000 (0.743)\n",
      "Epoch: [32][10/18]\tTime 0.078 (0.097)\tData 0.053 (0.075)\tLoss 1.2952 (0.7055)\tAcc 0.375 (0.706)\n",
      "Epoch: [32][11/18]\tTime 0.071 (0.095)\tData 0.050 (0.072)\tLoss 1.3602 (0.7650)\tAcc 0.438 (0.682)\n",
      "Epoch: [32][12/18]\tTime 0.073 (0.093)\tData 0.053 (0.071)\tLoss 0.8978 (0.7761)\tAcc 0.688 (0.682)\n",
      "Epoch: [32][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.069)\tLoss 0.9812 (0.7919)\tAcc 0.625 (0.678)\n",
      "Epoch: [32][14/18]\tTime 0.074 (0.090)\tData 0.055 (0.068)\tLoss 0.8940 (0.7992)\tAcc 0.625 (0.674)\n",
      "Epoch: [32][15/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 1.0063 (0.8130)\tAcc 0.562 (0.667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][16/18]\tTime 0.081 (0.089)\tData 0.061 (0.067)\tLoss 0.7548 (0.8093)\tAcc 0.688 (0.668)\n",
      "Epoch: [32][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.8123 (0.8095)\tAcc 0.688 (0.669)\n",
      "Epoch: [32][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.066)\tLoss 0.8718 (0.8113)\tAcc 0.750 (0.671)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/12]\tTime 0.333 (0.333)\tData 0.302 (0.302)\tLoss 0.8074 (0.8074)\tAcc 0.625 (0.625)\n",
      "Epoch: [33][2/12]\tTime 0.076 (0.204)\tData 0.050 (0.176)\tLoss 0.7566 (0.7820)\tAcc 0.688 (0.656)\n",
      "Epoch: [33][3/12]\tTime 0.081 (0.163)\tData 0.052 (0.135)\tLoss 0.8637 (0.8092)\tAcc 0.688 (0.667)\n",
      "Epoch: [33][4/12]\tTime 0.079 (0.142)\tData 0.051 (0.114)\tLoss 0.6863 (0.7785)\tAcc 0.812 (0.703)\n",
      "Epoch: [33][5/12]\tTime 0.079 (0.130)\tData 0.053 (0.102)\tLoss 0.7808 (0.7790)\tAcc 0.625 (0.688)\n",
      "Epoch: [33][6/12]\tTime 0.078 (0.121)\tData 0.052 (0.093)\tLoss 0.7946 (0.7816)\tAcc 0.562 (0.667)\n",
      "Epoch: [33][7/12]\tTime 0.076 (0.115)\tData 0.052 (0.087)\tLoss 0.6294 (0.7598)\tAcc 0.750 (0.679)\n",
      "Epoch: [33][8/12]\tTime 0.083 (0.111)\tData 0.059 (0.084)\tLoss 0.6112 (0.7412)\tAcc 0.812 (0.695)\n",
      "Epoch: [33][9/12]\tTime 0.078 (0.107)\tData 0.054 (0.081)\tLoss 0.8280 (0.7509)\tAcc 0.688 (0.694)\n",
      "Epoch: [33][10/12]\tTime 0.080 (0.104)\tData 0.057 (0.078)\tLoss 0.6224 (0.7380)\tAcc 0.750 (0.700)\n",
      "Epoch: [33][11/12]\tTime 0.080 (0.102)\tData 0.057 (0.076)\tLoss 0.9206 (0.7546)\tAcc 0.562 (0.688)\n",
      "Epoch: [33][12/12]\tTime 0.078 (0.100)\tData 0.055 (0.074)\tLoss 0.8749 (0.7641)\tAcc 0.667 (0.686)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/18]\tTime 0.289 (0.289)\tData 0.259 (0.259)\tLoss 0.3554 (0.3554)\tAcc 0.875 (0.875)\n",
      "Epoch: [33][2/18]\tTime 0.076 (0.182)\tData 0.053 (0.156)\tLoss 1.0760 (0.7157)\tAcc 0.562 (0.719)\n",
      "Epoch: [33][3/18]\tTime 0.078 (0.148)\tData 0.055 (0.122)\tLoss 0.6923 (0.7079)\tAcc 0.688 (0.708)\n",
      "Epoch: [33][4/18]\tTime 0.073 (0.129)\tData 0.050 (0.104)\tLoss 0.5594 (0.6708)\tAcc 0.750 (0.719)\n",
      "Epoch: [33][5/18]\tTime 0.077 (0.119)\tData 0.054 (0.094)\tLoss 1.0949 (0.7556)\tAcc 0.625 (0.700)\n",
      "Epoch: [33][6/18]\tTime 0.074 (0.111)\tData 0.051 (0.087)\tLoss 0.3906 (0.6948)\tAcc 0.938 (0.740)\n",
      "Epoch: [33][7/18]\tTime 0.077 (0.106)\tData 0.056 (0.083)\tLoss 0.6774 (0.6923)\tAcc 0.688 (0.732)\n",
      "Epoch: [33][8/18]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 1.0068 (0.7316)\tAcc 0.562 (0.711)\n",
      "Epoch: [33][9/18]\tTime 0.080 (0.100)\tData 0.054 (0.076)\tLoss 0.1385 (0.6657)\tAcc 1.000 (0.743)\n",
      "Epoch: [33][10/18]\tTime 0.078 (0.098)\tData 0.056 (0.074)\tLoss 1.1329 (0.7124)\tAcc 0.438 (0.713)\n",
      "Epoch: [33][11/18]\tTime 0.076 (0.096)\tData 0.056 (0.073)\tLoss 1.4856 (0.7827)\tAcc 0.375 (0.682)\n",
      "Epoch: [33][12/18]\tTime 0.074 (0.094)\tData 0.053 (0.071)\tLoss 1.1095 (0.8099)\tAcc 0.562 (0.672)\n",
      "Epoch: [33][13/18]\tTime 0.076 (0.093)\tData 0.055 (0.070)\tLoss 1.1617 (0.8370)\tAcc 0.562 (0.663)\n",
      "Epoch: [33][14/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.8243 (0.8361)\tAcc 0.625 (0.661)\n",
      "Epoch: [33][15/18]\tTime 0.079 (0.091)\tData 0.059 (0.068)\tLoss 0.9051 (0.8407)\tAcc 0.625 (0.658)\n",
      "Epoch: [33][16/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.7589 (0.8356)\tAcc 0.688 (0.660)\n",
      "Epoch: [33][17/18]\tTime 0.075 (0.089)\tData 0.055 (0.066)\tLoss 0.7478 (0.8304)\tAcc 0.688 (0.662)\n",
      "Epoch: [33][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.9109 (0.8327)\tAcc 0.375 (0.654)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/12]\tTime 0.421 (0.421)\tData 0.385 (0.385)\tLoss 1.0398 (1.0398)\tAcc 0.500 (0.500)\n",
      "Epoch: [34][2/12]\tTime 0.078 (0.249)\tData 0.047 (0.216)\tLoss 0.6628 (0.8513)\tAcc 0.688 (0.594)\n",
      "Epoch: [34][3/12]\tTime 0.079 (0.192)\tData 0.052 (0.161)\tLoss 0.8125 (0.8384)\tAcc 0.562 (0.583)\n",
      "Epoch: [34][4/12]\tTime 0.077 (0.164)\tData 0.051 (0.134)\tLoss 0.4910 (0.7515)\tAcc 0.750 (0.625)\n",
      "Epoch: [34][5/12]\tTime 0.081 (0.147)\tData 0.054 (0.118)\tLoss 0.5497 (0.7112)\tAcc 0.750 (0.650)\n",
      "Epoch: [34][6/12]\tTime 0.078 (0.136)\tData 0.051 (0.107)\tLoss 0.6690 (0.7041)\tAcc 0.688 (0.656)\n",
      "Epoch: [34][7/12]\tTime 0.075 (0.127)\tData 0.051 (0.099)\tLoss 0.9213 (0.7352)\tAcc 0.562 (0.643)\n",
      "Epoch: [34][8/12]\tTime 0.082 (0.121)\tData 0.059 (0.094)\tLoss 0.5337 (0.7100)\tAcc 0.875 (0.672)\n",
      "Epoch: [34][9/12]\tTime 0.082 (0.117)\tData 0.059 (0.090)\tLoss 0.7834 (0.7181)\tAcc 0.688 (0.674)\n",
      "Epoch: [34][10/12]\tTime 0.088 (0.114)\tData 0.065 (0.087)\tLoss 0.6489 (0.7112)\tAcc 0.812 (0.688)\n",
      "Epoch: [34][11/12]\tTime 0.082 (0.111)\tData 0.059 (0.085)\tLoss 0.6861 (0.7089)\tAcc 0.750 (0.693)\n",
      "Epoch: [34][12/12]\tTime 0.083 (0.109)\tData 0.060 (0.083)\tLoss 1.2008 (0.7476)\tAcc 0.400 (0.670)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/18]\tTime 0.297 (0.297)\tData 0.273 (0.273)\tLoss 0.3645 (0.3645)\tAcc 0.875 (0.875)\n",
      "Epoch: [34][2/18]\tTime 0.076 (0.187)\tData 0.055 (0.164)\tLoss 0.9204 (0.6424)\tAcc 0.438 (0.656)\n",
      "Epoch: [34][3/18]\tTime 0.073 (0.149)\tData 0.053 (0.127)\tLoss 0.6368 (0.6406)\tAcc 0.750 (0.688)\n",
      "Epoch: [34][4/18]\tTime 0.078 (0.131)\tData 0.056 (0.109)\tLoss 0.7110 (0.6582)\tAcc 0.750 (0.703)\n",
      "Epoch: [34][5/18]\tTime 0.074 (0.120)\tData 0.053 (0.098)\tLoss 0.8142 (0.6894)\tAcc 0.688 (0.700)\n",
      "Epoch: [34][6/18]\tTime 0.074 (0.112)\tData 0.053 (0.091)\tLoss 0.3074 (0.6257)\tAcc 0.938 (0.740)\n",
      "Epoch: [34][7/18]\tTime 0.074 (0.107)\tData 0.053 (0.085)\tLoss 0.6656 (0.6314)\tAcc 0.688 (0.732)\n",
      "Epoch: [34][8/18]\tTime 0.082 (0.104)\tData 0.055 (0.081)\tLoss 1.0605 (0.6850)\tAcc 0.688 (0.727)\n",
      "Epoch: [34][9/18]\tTime 0.071 (0.100)\tData 0.049 (0.078)\tLoss 0.1897 (0.6300)\tAcc 1.000 (0.757)\n",
      "Epoch: [34][10/18]\tTime 0.073 (0.097)\tData 0.052 (0.075)\tLoss 1.2314 (0.6901)\tAcc 0.500 (0.731)\n",
      "Epoch: [34][11/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 1.4314 (0.7575)\tAcc 0.375 (0.699)\n",
      "Epoch: [34][12/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.8219 (0.7629)\tAcc 0.625 (0.693)\n",
      "Epoch: [34][13/18]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.9213 (0.7751)\tAcc 0.625 (0.688)\n",
      "Epoch: [34][14/18]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 0.8191 (0.7782)\tAcc 0.688 (0.688)\n",
      "Epoch: [34][15/18]\tTime 0.078 (0.090)\tData 0.059 (0.069)\tLoss 0.7915 (0.7791)\tAcc 0.688 (0.688)\n",
      "Epoch: [34][16/18]\tTime 0.077 (0.089)\tData 0.058 (0.068)\tLoss 0.9126 (0.7874)\tAcc 0.625 (0.684)\n",
      "Epoch: [34][17/18]\tTime 0.075 (0.088)\tData 0.055 (0.067)\tLoss 0.8150 (0.7891)\tAcc 0.625 (0.680)\n",
      "Epoch: [34][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8728 (0.7915)\tAcc 0.750 (0.682)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/12]\tTime 0.376 (0.376)\tData 0.342 (0.342)\tLoss 0.4947 (0.4947)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][2/12]\tTime 0.074 (0.225)\tData 0.046 (0.194)\tLoss 0.7049 (0.5998)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][3/12]\tTime 0.080 (0.177)\tData 0.051 (0.147)\tLoss 0.5889 (0.5962)\tAcc 0.688 (0.729)\n",
      "Epoch: [35][4/12]\tTime 0.075 (0.151)\tData 0.049 (0.122)\tLoss 0.5249 (0.5784)\tAcc 0.812 (0.750)\n",
      "Epoch: [35][5/12]\tTime 0.082 (0.137)\tData 0.056 (0.109)\tLoss 0.8724 (0.6372)\tAcc 0.625 (0.725)\n",
      "Epoch: [35][6/12]\tTime 0.079 (0.128)\tData 0.052 (0.100)\tLoss 0.6249 (0.6351)\tAcc 0.875 (0.750)\n",
      "Epoch: [35][7/12]\tTime 0.076 (0.120)\tData 0.052 (0.093)\tLoss 0.4857 (0.6138)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][8/12]\tTime 0.080 (0.115)\tData 0.056 (0.088)\tLoss 0.4121 (0.5886)\tAcc 0.938 (0.773)\n",
      "Epoch: [35][9/12]\tTime 0.083 (0.112)\tData 0.059 (0.085)\tLoss 0.6394 (0.5942)\tAcc 0.812 (0.778)\n",
      "Epoch: [35][10/12]\tTime 0.080 (0.109)\tData 0.056 (0.082)\tLoss 1.2412 (0.6589)\tAcc 0.562 (0.756)\n",
      "Epoch: [35][11/12]\tTime 0.080 (0.106)\tData 0.056 (0.080)\tLoss 1.1242 (0.7012)\tAcc 0.500 (0.733)\n",
      "Epoch: [35][12/12]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 1.0999 (0.7325)\tAcc 0.600 (0.723)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/18]\tTime 0.380 (0.380)\tData 0.355 (0.355)\tLoss 0.3408 (0.3408)\tAcc 0.875 (0.875)\n",
      "Epoch: [35][2/18]\tTime 0.073 (0.226)\tData 0.051 (0.203)\tLoss 1.2584 (0.7996)\tAcc 0.438 (0.656)\n",
      "Epoch: [35][3/18]\tTime 0.077 (0.177)\tData 0.053 (0.153)\tLoss 0.6667 (0.7553)\tAcc 0.688 (0.667)\n",
      "Epoch: [35][4/18]\tTime 0.075 (0.151)\tData 0.051 (0.128)\tLoss 0.5870 (0.7132)\tAcc 0.688 (0.672)\n",
      "Epoch: [35][5/18]\tTime 0.072 (0.135)\tData 0.051 (0.112)\tLoss 0.7855 (0.7277)\tAcc 0.750 (0.688)\n",
      "Epoch: [35][6/18]\tTime 0.075 (0.125)\tData 0.054 (0.103)\tLoss 0.2594 (0.6496)\tAcc 1.000 (0.740)\n",
      "Epoch: [35][7/18]\tTime 0.074 (0.118)\tData 0.054 (0.096)\tLoss 0.7085 (0.6580)\tAcc 0.625 (0.723)\n",
      "Epoch: [35][8/18]\tTime 0.076 (0.113)\tData 0.054 (0.090)\tLoss 0.9898 (0.6995)\tAcc 0.625 (0.711)\n",
      "Epoch: [35][9/18]\tTime 0.076 (0.109)\tData 0.053 (0.086)\tLoss 0.1782 (0.6416)\tAcc 1.000 (0.743)\n",
      "Epoch: [35][10/18]\tTime 0.072 (0.105)\tData 0.051 (0.083)\tLoss 1.2613 (0.7036)\tAcc 0.500 (0.719)\n",
      "Epoch: [35][11/18]\tTime 0.075 (0.102)\tData 0.054 (0.080)\tLoss 1.2728 (0.7553)\tAcc 0.375 (0.688)\n",
      "Epoch: [35][12/18]\tTime 0.073 (0.100)\tData 0.053 (0.078)\tLoss 1.0437 (0.7793)\tAcc 0.625 (0.682)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35][13/18]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 1.2644 (0.8167)\tAcc 0.438 (0.663)\n",
      "Epoch: [35][14/18]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.8046 (0.8158)\tAcc 0.625 (0.661)\n",
      "Epoch: [35][15/18]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.9101 (0.8221)\tAcc 0.625 (0.658)\n",
      "Epoch: [35][16/18]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.7972 (0.8205)\tAcc 0.750 (0.664)\n",
      "Epoch: [35][17/18]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.8191 (0.8204)\tAcc 0.625 (0.662)\n",
      "Epoch: [35][18/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.7873 (0.8195)\tAcc 0.875 (0.668)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/12]\tTime 0.258 (0.258)\tData 0.226 (0.226)\tLoss 0.6228 (0.6228)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][2/12]\tTime 0.074 (0.166)\tData 0.047 (0.136)\tLoss 0.8224 (0.7226)\tAcc 0.688 (0.719)\n",
      "Epoch: [36][3/12]\tTime 0.078 (0.137)\tData 0.052 (0.108)\tLoss 0.4381 (0.6277)\tAcc 0.750 (0.729)\n",
      "Epoch: [36][4/12]\tTime 0.079 (0.122)\tData 0.052 (0.094)\tLoss 0.5045 (0.5969)\tAcc 0.812 (0.750)\n",
      "Epoch: [36][5/12]\tTime 0.078 (0.113)\tData 0.053 (0.086)\tLoss 0.7346 (0.6245)\tAcc 0.688 (0.738)\n",
      "Epoch: [36][6/12]\tTime 0.079 (0.108)\tData 0.053 (0.080)\tLoss 1.0086 (0.6885)\tAcc 0.625 (0.719)\n",
      "Epoch: [36][7/12]\tTime 0.078 (0.103)\tData 0.053 (0.076)\tLoss 0.9288 (0.7228)\tAcc 0.500 (0.688)\n",
      "Epoch: [36][8/12]\tTime 0.079 (0.100)\tData 0.055 (0.074)\tLoss 0.6917 (0.7189)\tAcc 0.812 (0.703)\n",
      "Epoch: [36][9/12]\tTime 0.078 (0.098)\tData 0.054 (0.072)\tLoss 0.8018 (0.7282)\tAcc 0.625 (0.694)\n",
      "Epoch: [36][10/12]\tTime 0.077 (0.096)\tData 0.054 (0.070)\tLoss 0.7933 (0.7347)\tAcc 0.750 (0.700)\n",
      "Epoch: [36][11/12]\tTime 0.079 (0.094)\tData 0.056 (0.068)\tLoss 0.8474 (0.7449)\tAcc 0.812 (0.710)\n",
      "Epoch: [36][12/12]\tTime 0.078 (0.093)\tData 0.054 (0.067)\tLoss 0.6027 (0.7338)\tAcc 0.867 (0.723)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/18]\tTime 0.317 (0.317)\tData 0.289 (0.289)\tLoss 0.4440 (0.4440)\tAcc 0.875 (0.875)\n",
      "Epoch: [36][2/18]\tTime 0.068 (0.193)\tData 0.046 (0.168)\tLoss 0.8942 (0.6691)\tAcc 0.438 (0.656)\n",
      "Epoch: [36][3/18]\tTime 0.074 (0.153)\tData 0.052 (0.129)\tLoss 0.8672 (0.7351)\tAcc 0.625 (0.646)\n",
      "Epoch: [36][4/18]\tTime 0.074 (0.133)\tData 0.052 (0.110)\tLoss 0.7189 (0.7311)\tAcc 0.625 (0.641)\n",
      "Epoch: [36][5/18]\tTime 0.075 (0.122)\tData 0.054 (0.099)\tLoss 0.9063 (0.7661)\tAcc 0.688 (0.650)\n",
      "Epoch: [36][6/18]\tTime 0.073 (0.113)\tData 0.052 (0.091)\tLoss 0.4328 (0.7106)\tAcc 0.875 (0.688)\n",
      "Epoch: [36][7/18]\tTime 0.074 (0.108)\tData 0.053 (0.086)\tLoss 0.7164 (0.7114)\tAcc 0.562 (0.670)\n",
      "Epoch: [36][8/18]\tTime 0.075 (0.104)\tData 0.054 (0.082)\tLoss 1.0239 (0.7505)\tAcc 0.562 (0.656)\n",
      "Epoch: [36][9/18]\tTime 0.077 (0.101)\tData 0.054 (0.079)\tLoss 0.2280 (0.6924)\tAcc 1.000 (0.694)\n",
      "Epoch: [36][10/18]\tTime 0.073 (0.098)\tData 0.052 (0.076)\tLoss 1.2020 (0.7434)\tAcc 0.625 (0.688)\n",
      "Epoch: [36][11/18]\tTime 0.079 (0.096)\tData 0.055 (0.074)\tLoss 1.2932 (0.7934)\tAcc 0.375 (0.659)\n",
      "Epoch: [36][12/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.8220 (0.7957)\tAcc 0.750 (0.667)\n",
      "Epoch: [36][13/18]\tTime 0.082 (0.093)\tData 0.061 (0.071)\tLoss 1.0564 (0.8158)\tAcc 0.750 (0.673)\n",
      "Epoch: [36][14/18]\tTime 0.076 (0.092)\tData 0.056 (0.070)\tLoss 0.6916 (0.8069)\tAcc 0.625 (0.670)\n",
      "Epoch: [36][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.9180 (0.8143)\tAcc 0.688 (0.671)\n",
      "Epoch: [36][16/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.8175 (0.8145)\tAcc 0.625 (0.668)\n",
      "Epoch: [36][17/18]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.8546 (0.8169)\tAcc 0.625 (0.665)\n",
      "Epoch: [36][18/18]\tTime 0.076 (0.088)\tData 0.056 (0.067)\tLoss 0.5809 (0.8101)\tAcc 1.000 (0.675)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/12]\tTime 0.290 (0.290)\tData 0.258 (0.258)\tLoss 0.6198 (0.6198)\tAcc 0.812 (0.812)\n",
      "Epoch: [37][2/12]\tTime 0.076 (0.183)\tData 0.048 (0.153)\tLoss 0.6312 (0.6255)\tAcc 0.625 (0.719)\n",
      "Epoch: [37][3/12]\tTime 0.078 (0.148)\tData 0.051 (0.119)\tLoss 1.0344 (0.7618)\tAcc 0.562 (0.667)\n",
      "Epoch: [37][4/12]\tTime 0.083 (0.132)\tData 0.052 (0.102)\tLoss 1.0644 (0.8374)\tAcc 0.562 (0.641)\n",
      "Epoch: [37][5/12]\tTime 0.086 (0.123)\tData 0.049 (0.091)\tLoss 0.5002 (0.7700)\tAcc 0.812 (0.675)\n",
      "Epoch: [37][6/12]\tTime 0.081 (0.116)\tData 0.042 (0.083)\tLoss 0.5141 (0.7273)\tAcc 0.875 (0.708)\n",
      "Epoch: [37][7/12]\tTime 0.067 (0.109)\tData 0.041 (0.077)\tLoss 0.6727 (0.7195)\tAcc 0.812 (0.723)\n",
      "Epoch: [37][8/12]\tTime 0.079 (0.105)\tData 0.054 (0.074)\tLoss 0.5922 (0.7036)\tAcc 0.812 (0.734)\n",
      "Epoch: [37][9/12]\tTime 0.078 (0.102)\tData 0.054 (0.072)\tLoss 0.6941 (0.7026)\tAcc 0.750 (0.736)\n",
      "Epoch: [37][10/12]\tTime 0.078 (0.099)\tData 0.054 (0.070)\tLoss 1.1501 (0.7473)\tAcc 0.500 (0.713)\n",
      "Epoch: [37][11/12]\tTime 0.079 (0.098)\tData 0.055 (0.069)\tLoss 0.4606 (0.7213)\tAcc 0.812 (0.722)\n",
      "Epoch: [37][12/12]\tTime 0.077 (0.096)\tData 0.054 (0.068)\tLoss 0.5711 (0.7095)\tAcc 0.667 (0.717)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/18]\tTime 0.338 (0.338)\tData 0.312 (0.312)\tLoss 0.2209 (0.2209)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/18]\tTime 0.071 (0.204)\tData 0.049 (0.180)\tLoss 1.0831 (0.6520)\tAcc 0.438 (0.688)\n",
      "Epoch: [37][3/18]\tTime 0.074 (0.161)\tData 0.053 (0.138)\tLoss 0.6750 (0.6597)\tAcc 0.688 (0.688)\n",
      "Epoch: [37][4/18]\tTime 0.075 (0.139)\tData 0.053 (0.117)\tLoss 0.5246 (0.6259)\tAcc 0.688 (0.688)\n",
      "Epoch: [37][5/18]\tTime 0.078 (0.127)\tData 0.055 (0.104)\tLoss 0.7595 (0.6526)\tAcc 0.688 (0.688)\n",
      "Epoch: [37][6/18]\tTime 0.072 (0.118)\tData 0.051 (0.095)\tLoss 0.1955 (0.5764)\tAcc 1.000 (0.740)\n",
      "Epoch: [37][7/18]\tTime 0.074 (0.112)\tData 0.053 (0.089)\tLoss 0.7247 (0.5976)\tAcc 0.625 (0.723)\n",
      "Epoch: [37][8/18]\tTime 0.076 (0.107)\tData 0.054 (0.085)\tLoss 1.1321 (0.6644)\tAcc 0.625 (0.711)\n",
      "Epoch: [37][9/18]\tTime 0.075 (0.103)\tData 0.053 (0.081)\tLoss 0.1221 (0.6042)\tAcc 1.000 (0.743)\n",
      "Epoch: [37][10/18]\tTime 0.082 (0.101)\tData 0.056 (0.079)\tLoss 1.3677 (0.6805)\tAcc 0.375 (0.706)\n",
      "Epoch: [37][11/18]\tTime 0.082 (0.099)\tData 0.055 (0.077)\tLoss 1.4897 (0.7541)\tAcc 0.375 (0.676)\n",
      "Epoch: [37][12/18]\tTime 0.079 (0.098)\tData 0.057 (0.075)\tLoss 1.1634 (0.7882)\tAcc 0.562 (0.667)\n",
      "Epoch: [37][13/18]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 1.0953 (0.8118)\tAcc 0.500 (0.654)\n",
      "Epoch: [37][14/18]\tTime 0.080 (0.095)\tData 0.060 (0.073)\tLoss 0.7981 (0.8108)\tAcc 0.625 (0.652)\n",
      "Epoch: [37][15/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.8915 (0.8162)\tAcc 0.688 (0.654)\n",
      "Epoch: [37][16/18]\tTime 0.080 (0.093)\tData 0.059 (0.071)\tLoss 0.7999 (0.8152)\tAcc 0.688 (0.656)\n",
      "Epoch: [37][17/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.9088 (0.8207)\tAcc 0.625 (0.654)\n",
      "Epoch: [37][18/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.8905 (0.8227)\tAcc 0.750 (0.657)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/12]\tTime 0.367 (0.367)\tData 0.332 (0.332)\tLoss 0.4423 (0.4423)\tAcc 0.812 (0.812)\n",
      "Epoch: [38][2/12]\tTime 0.078 (0.222)\tData 0.051 (0.191)\tLoss 0.6443 (0.5433)\tAcc 0.688 (0.750)\n",
      "Epoch: [38][3/12]\tTime 0.088 (0.177)\tData 0.060 (0.147)\tLoss 0.7784 (0.6217)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][4/12]\tTime 0.086 (0.155)\tData 0.058 (0.125)\tLoss 0.8364 (0.6754)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][5/12]\tTime 0.088 (0.141)\tData 0.058 (0.112)\tLoss 0.8359 (0.7075)\tAcc 0.688 (0.738)\n",
      "Epoch: [38][6/12]\tTime 0.085 (0.132)\tData 0.056 (0.102)\tLoss 0.6320 (0.6949)\tAcc 0.875 (0.760)\n",
      "Epoch: [38][7/12]\tTime 0.087 (0.126)\tData 0.058 (0.096)\tLoss 0.8357 (0.7150)\tAcc 0.625 (0.741)\n",
      "Epoch: [38][8/12]\tTime 0.083 (0.120)\tData 0.058 (0.091)\tLoss 1.3401 (0.7931)\tAcc 0.500 (0.711)\n",
      "Epoch: [38][9/12]\tTime 0.086 (0.116)\tData 0.062 (0.088)\tLoss 0.6306 (0.7751)\tAcc 0.812 (0.722)\n",
      "Epoch: [38][10/12]\tTime 0.083 (0.113)\tData 0.058 (0.085)\tLoss 0.9453 (0.7921)\tAcc 0.562 (0.706)\n",
      "Epoch: [38][11/12]\tTime 0.086 (0.111)\tData 0.061 (0.083)\tLoss 0.4439 (0.7605)\tAcc 0.875 (0.722)\n",
      "Epoch: [38][12/12]\tTime 0.087 (0.109)\tData 0.062 (0.081)\tLoss 0.6828 (0.7544)\tAcc 0.733 (0.723)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/18]\tTime 0.362 (0.362)\tData 0.337 (0.337)\tLoss 0.3864 (0.3864)\tAcc 0.875 (0.875)\n",
      "Epoch: [38][2/18]\tTime 0.074 (0.218)\tData 0.053 (0.195)\tLoss 1.0074 (0.6969)\tAcc 0.438 (0.656)\n",
      "Epoch: [38][3/18]\tTime 0.083 (0.173)\tData 0.059 (0.150)\tLoss 0.5506 (0.6482)\tAcc 0.875 (0.729)\n",
      "Epoch: [38][4/18]\tTime 0.084 (0.151)\tData 0.057 (0.127)\tLoss 0.8255 (0.6925)\tAcc 0.625 (0.703)\n",
      "Epoch: [38][5/18]\tTime 0.078 (0.136)\tData 0.054 (0.112)\tLoss 0.8417 (0.7224)\tAcc 0.688 (0.700)\n",
      "Epoch: [38][6/18]\tTime 0.088 (0.128)\tData 0.058 (0.103)\tLoss 0.3672 (0.6632)\tAcc 1.000 (0.750)\n",
      "Epoch: [38][7/18]\tTime 0.072 (0.120)\tData 0.050 (0.096)\tLoss 0.8541 (0.6904)\tAcc 0.562 (0.723)\n",
      "Epoch: [38][8/18]\tTime 0.080 (0.115)\tData 0.058 (0.091)\tLoss 1.0588 (0.7365)\tAcc 0.562 (0.703)\n",
      "Epoch: [38][9/18]\tTime 0.080 (0.111)\tData 0.059 (0.087)\tLoss 0.2779 (0.6855)\tAcc 1.000 (0.736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][10/18]\tTime 0.081 (0.108)\tData 0.060 (0.085)\tLoss 0.9919 (0.7162)\tAcc 0.562 (0.719)\n",
      "Epoch: [38][11/18]\tTime 0.080 (0.106)\tData 0.057 (0.082)\tLoss 1.2722 (0.7667)\tAcc 0.375 (0.688)\n",
      "Epoch: [38][12/18]\tTime 0.077 (0.103)\tData 0.057 (0.080)\tLoss 0.8748 (0.7757)\tAcc 0.688 (0.688)\n",
      "Epoch: [38][13/18]\tTime 0.080 (0.102)\tData 0.060 (0.079)\tLoss 0.9740 (0.7910)\tAcc 0.688 (0.688)\n",
      "Epoch: [38][14/18]\tTime 0.080 (0.100)\tData 0.061 (0.077)\tLoss 0.7349 (0.7870)\tAcc 0.688 (0.688)\n",
      "Epoch: [38][15/18]\tTime 0.078 (0.099)\tData 0.058 (0.076)\tLoss 1.0817 (0.8066)\tAcc 0.562 (0.679)\n",
      "Epoch: [38][16/18]\tTime 0.079 (0.097)\tData 0.059 (0.075)\tLoss 0.8946 (0.8121)\tAcc 0.625 (0.676)\n",
      "Epoch: [38][17/18]\tTime 0.081 (0.096)\tData 0.061 (0.074)\tLoss 0.8583 (0.8148)\tAcc 0.625 (0.673)\n",
      "Epoch: [38][18/18]\tTime 0.080 (0.095)\tData 0.061 (0.073)\tLoss 0.8513 (0.8159)\tAcc 0.750 (0.675)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/12]\tTime 0.360 (0.360)\tData 0.318 (0.318)\tLoss 0.6457 (0.6457)\tAcc 0.875 (0.875)\n",
      "Epoch: [39][2/12]\tTime 0.075 (0.218)\tData 0.044 (0.181)\tLoss 1.1052 (0.8754)\tAcc 0.500 (0.688)\n",
      "Epoch: [39][3/12]\tTime 0.086 (0.174)\tData 0.054 (0.139)\tLoss 0.6412 (0.7973)\tAcc 0.750 (0.708)\n",
      "Epoch: [39][4/12]\tTime 0.089 (0.153)\tData 0.057 (0.119)\tLoss 0.5531 (0.7363)\tAcc 0.750 (0.719)\n",
      "Epoch: [39][5/12]\tTime 0.080 (0.138)\tData 0.053 (0.105)\tLoss 0.9397 (0.7770)\tAcc 0.500 (0.675)\n",
      "Epoch: [39][6/12]\tTime 0.089 (0.130)\tData 0.060 (0.098)\tLoss 0.7390 (0.7706)\tAcc 0.750 (0.688)\n",
      "Epoch: [39][7/12]\tTime 0.081 (0.123)\tData 0.057 (0.092)\tLoss 0.4571 (0.7258)\tAcc 0.875 (0.714)\n",
      "Epoch: [39][8/12]\tTime 0.086 (0.118)\tData 0.061 (0.088)\tLoss 0.7366 (0.7272)\tAcc 0.750 (0.719)\n",
      "Epoch: [39][9/12]\tTime 0.086 (0.115)\tData 0.061 (0.085)\tLoss 0.8226 (0.7378)\tAcc 0.625 (0.708)\n",
      "Epoch: [39][10/12]\tTime 0.087 (0.112)\tData 0.062 (0.083)\tLoss 0.9505 (0.7591)\tAcc 0.625 (0.700)\n",
      "Epoch: [39][11/12]\tTime 0.087 (0.110)\tData 0.062 (0.081)\tLoss 0.7304 (0.7565)\tAcc 0.625 (0.693)\n",
      "Epoch: [39][12/12]\tTime 0.087 (0.108)\tData 0.062 (0.079)\tLoss 0.7105 (0.7528)\tAcc 0.733 (0.696)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/18]\tTime 0.322 (0.322)\tData 0.297 (0.297)\tLoss 0.2768 (0.2768)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/18]\tTime 0.078 (0.200)\tData 0.056 (0.176)\tLoss 1.0949 (0.6858)\tAcc 0.438 (0.688)\n",
      "Epoch: [39][3/18]\tTime 0.083 (0.161)\tData 0.058 (0.137)\tLoss 0.6641 (0.6786)\tAcc 0.812 (0.729)\n",
      "Epoch: [39][4/18]\tTime 0.077 (0.140)\tData 0.056 (0.117)\tLoss 0.6728 (0.6771)\tAcc 0.625 (0.703)\n",
      "Epoch: [39][5/18]\tTime 0.080 (0.128)\tData 0.059 (0.105)\tLoss 0.8776 (0.7172)\tAcc 0.750 (0.713)\n",
      "Epoch: [39][6/18]\tTime 0.080 (0.120)\tData 0.059 (0.097)\tLoss 0.3112 (0.6496)\tAcc 1.000 (0.760)\n",
      "Epoch: [39][7/18]\tTime 0.082 (0.115)\tData 0.059 (0.092)\tLoss 0.6615 (0.6513)\tAcc 0.625 (0.741)\n",
      "Epoch: [39][8/18]\tTime 0.080 (0.110)\tData 0.058 (0.088)\tLoss 1.0731 (0.7040)\tAcc 0.500 (0.711)\n",
      "Epoch: [39][9/18]\tTime 0.080 (0.107)\tData 0.058 (0.084)\tLoss 0.1744 (0.6452)\tAcc 1.000 (0.743)\n",
      "Epoch: [39][10/18]\tTime 0.080 (0.104)\tData 0.059 (0.082)\tLoss 1.2224 (0.7029)\tAcc 0.500 (0.719)\n",
      "Epoch: [39][11/18]\tTime 0.084 (0.102)\tData 0.059 (0.080)\tLoss 1.4958 (0.7750)\tAcc 0.375 (0.688)\n",
      "Epoch: [39][12/18]\tTime 0.078 (0.100)\tData 0.057 (0.078)\tLoss 0.8380 (0.7802)\tAcc 0.625 (0.682)\n",
      "Epoch: [39][13/18]\tTime 0.080 (0.099)\tData 0.059 (0.076)\tLoss 1.0600 (0.8017)\tAcc 0.562 (0.673)\n",
      "Epoch: [39][14/18]\tTime 0.078 (0.097)\tData 0.057 (0.075)\tLoss 0.8015 (0.8017)\tAcc 0.625 (0.670)\n",
      "Epoch: [39][15/18]\tTime 0.080 (0.096)\tData 0.060 (0.074)\tLoss 0.9072 (0.8088)\tAcc 0.625 (0.667)\n",
      "Epoch: [39][16/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 0.8142 (0.8091)\tAcc 0.625 (0.664)\n",
      "Epoch: [39][17/18]\tTime 0.080 (0.094)\tData 0.059 (0.072)\tLoss 0.8015 (0.8086)\tAcc 0.625 (0.662)\n",
      "Epoch: [39][18/18]\tTime 0.077 (0.093)\tData 0.057 (0.071)\tLoss 0.7420 (0.8067)\tAcc 0.875 (0.668)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/12]\tTime 0.339 (0.339)\tData 0.305 (0.305)\tLoss 0.8573 (0.8573)\tAcc 0.625 (0.625)\n",
      "Epoch: [40][2/12]\tTime 0.083 (0.211)\tData 0.052 (0.179)\tLoss 1.0702 (0.9637)\tAcc 0.562 (0.594)\n",
      "Epoch: [40][3/12]\tTime 0.080 (0.168)\tData 0.053 (0.137)\tLoss 0.7393 (0.8889)\tAcc 0.688 (0.625)\n",
      "Epoch: [40][4/12]\tTime 0.089 (0.148)\tData 0.060 (0.118)\tLoss 0.7029 (0.8424)\tAcc 0.812 (0.672)\n",
      "Epoch: [40][5/12]\tTime 0.081 (0.135)\tData 0.055 (0.105)\tLoss 0.5640 (0.7867)\tAcc 0.875 (0.713)\n",
      "Epoch: [40][6/12]\tTime 0.087 (0.127)\tData 0.061 (0.098)\tLoss 0.7145 (0.7747)\tAcc 0.625 (0.698)\n",
      "Epoch: [40][7/12]\tTime 0.085 (0.121)\tData 0.061 (0.092)\tLoss 0.9229 (0.7959)\tAcc 0.562 (0.679)\n",
      "Epoch: [40][8/12]\tTime 0.086 (0.116)\tData 0.061 (0.089)\tLoss 0.5135 (0.7606)\tAcc 0.812 (0.695)\n",
      "Epoch: [40][9/12]\tTime 0.084 (0.113)\tData 0.060 (0.085)\tLoss 0.7081 (0.7547)\tAcc 0.688 (0.694)\n",
      "Epoch: [40][10/12]\tTime 0.086 (0.110)\tData 0.062 (0.083)\tLoss 0.7917 (0.7584)\tAcc 0.688 (0.694)\n",
      "Epoch: [40][11/12]\tTime 0.086 (0.108)\tData 0.062 (0.081)\tLoss 0.7407 (0.7568)\tAcc 0.688 (0.693)\n",
      "Epoch: [40][12/12]\tTime 0.086 (0.106)\tData 0.062 (0.079)\tLoss 0.8286 (0.7625)\tAcc 0.667 (0.691)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/18]\tTime 0.340 (0.340)\tData 0.311 (0.311)\tLoss 0.3787 (0.3787)\tAcc 0.875 (0.875)\n",
      "Epoch: [40][2/18]\tTime 0.078 (0.209)\tData 0.056 (0.184)\tLoss 1.0234 (0.7010)\tAcc 0.438 (0.656)\n",
      "Epoch: [40][3/18]\tTime 0.079 (0.166)\tData 0.057 (0.142)\tLoss 0.5979 (0.6667)\tAcc 0.875 (0.729)\n",
      "Epoch: [40][4/18]\tTime 0.083 (0.145)\tData 0.058 (0.121)\tLoss 0.6690 (0.6672)\tAcc 0.688 (0.719)\n",
      "Epoch: [40][5/18]\tTime 0.076 (0.131)\tData 0.055 (0.107)\tLoss 0.7820 (0.6902)\tAcc 0.688 (0.713)\n",
      "Epoch: [40][6/18]\tTime 0.080 (0.123)\tData 0.059 (0.099)\tLoss 0.3403 (0.6319)\tAcc 1.000 (0.760)\n",
      "Epoch: [40][7/18]\tTime 0.081 (0.117)\tData 0.059 (0.094)\tLoss 0.7978 (0.6556)\tAcc 0.500 (0.723)\n",
      "Epoch: [40][8/18]\tTime 0.083 (0.113)\tData 0.059 (0.089)\tLoss 0.9838 (0.6966)\tAcc 0.625 (0.711)\n",
      "Epoch: [40][9/18]\tTime 0.078 (0.109)\tData 0.054 (0.085)\tLoss 0.1844 (0.6397)\tAcc 1.000 (0.743)\n",
      "Epoch: [40][10/18]\tTime 0.079 (0.106)\tData 0.057 (0.083)\tLoss 1.2857 (0.7043)\tAcc 0.438 (0.713)\n",
      "Epoch: [40][11/18]\tTime 0.083 (0.104)\tData 0.059 (0.080)\tLoss 1.4474 (0.7719)\tAcc 0.375 (0.682)\n",
      "Epoch: [40][12/18]\tTime 0.079 (0.102)\tData 0.059 (0.079)\tLoss 0.9016 (0.7827)\tAcc 0.625 (0.677)\n",
      "Epoch: [40][13/18]\tTime 0.080 (0.100)\tData 0.060 (0.077)\tLoss 1.0551 (0.8036)\tAcc 0.562 (0.668)\n",
      "Epoch: [40][14/18]\tTime 0.082 (0.099)\tData 0.060 (0.076)\tLoss 0.7966 (0.8031)\tAcc 0.625 (0.665)\n",
      "Epoch: [40][15/18]\tTime 0.079 (0.097)\tData 0.059 (0.075)\tLoss 0.8861 (0.8087)\tAcc 0.688 (0.667)\n",
      "Epoch: [40][16/18]\tTime 0.080 (0.096)\tData 0.060 (0.074)\tLoss 0.7945 (0.8078)\tAcc 0.688 (0.668)\n",
      "Epoch: [40][17/18]\tTime 0.080 (0.095)\tData 0.060 (0.073)\tLoss 0.8568 (0.8107)\tAcc 0.625 (0.665)\n",
      "Epoch: [40][18/18]\tTime 0.075 (0.094)\tData 0.056 (0.072)\tLoss 0.7556 (0.8091)\tAcc 0.750 (0.668)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/12]\tTime 0.283 (0.283)\tData 0.252 (0.252)\tLoss 1.0525 (1.0525)\tAcc 0.562 (0.562)\n",
      "Epoch: [41][2/12]\tTime 0.075 (0.179)\tData 0.049 (0.150)\tLoss 1.0146 (1.0336)\tAcc 0.500 (0.531)\n",
      "Epoch: [41][3/12]\tTime 0.084 (0.147)\tData 0.058 (0.120)\tLoss 0.5819 (0.8830)\tAcc 0.750 (0.604)\n",
      "Epoch: [41][4/12]\tTime 0.097 (0.135)\tData 0.061 (0.105)\tLoss 0.6531 (0.8256)\tAcc 0.875 (0.672)\n",
      "Epoch: [41][5/12]\tTime 0.082 (0.124)\tData 0.054 (0.095)\tLoss 0.5956 (0.7796)\tAcc 0.812 (0.700)\n",
      "Epoch: [41][6/12]\tTime 0.085 (0.118)\tData 0.058 (0.089)\tLoss 0.6518 (0.7583)\tAcc 0.750 (0.708)\n",
      "Epoch: [41][7/12]\tTime 0.085 (0.113)\tData 0.060 (0.084)\tLoss 0.4893 (0.7199)\tAcc 0.875 (0.732)\n",
      "Epoch: [41][8/12]\tTime 0.085 (0.110)\tData 0.061 (0.082)\tLoss 0.8394 (0.7348)\tAcc 0.625 (0.719)\n",
      "Epoch: [41][9/12]\tTime 0.086 (0.107)\tData 0.061 (0.079)\tLoss 0.7807 (0.7399)\tAcc 0.750 (0.722)\n",
      "Epoch: [41][10/12]\tTime 0.086 (0.105)\tData 0.062 (0.078)\tLoss 0.7086 (0.7368)\tAcc 0.750 (0.725)\n",
      "Epoch: [41][11/12]\tTime 0.086 (0.103)\tData 0.062 (0.076)\tLoss 0.6344 (0.7275)\tAcc 0.750 (0.727)\n",
      "Epoch: [41][12/12]\tTime 0.084 (0.102)\tData 0.060 (0.075)\tLoss 0.7815 (0.7317)\tAcc 0.667 (0.723)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/18]\tTime 0.336 (0.336)\tData 0.299 (0.299)\tLoss 0.4265 (0.4265)\tAcc 0.875 (0.875)\n",
      "Epoch: [41][2/18]\tTime 0.093 (0.215)\tData 0.049 (0.174)\tLoss 1.0850 (0.7557)\tAcc 0.438 (0.656)\n",
      "Epoch: [41][3/18]\tTime 0.064 (0.165)\tData 0.042 (0.130)\tLoss 0.6178 (0.7097)\tAcc 0.875 (0.729)\n",
      "Epoch: [41][4/18]\tTime 0.099 (0.148)\tData 0.053 (0.111)\tLoss 0.7459 (0.7188)\tAcc 0.625 (0.703)\n",
      "Epoch: [41][5/18]\tTime 0.074 (0.133)\tData 0.032 (0.095)\tLoss 0.8460 (0.7442)\tAcc 0.688 (0.700)\n",
      "Epoch: [41][6/18]\tTime 0.080 (0.124)\tData 0.044 (0.087)\tLoss 0.3051 (0.6710)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41][7/18]\tTime 0.070 (0.117)\tData 0.047 (0.081)\tLoss 0.9041 (0.7043)\tAcc 0.500 (0.714)\n",
      "Epoch: [41][8/18]\tTime 0.083 (0.112)\tData 0.059 (0.078)\tLoss 1.0636 (0.7492)\tAcc 0.562 (0.695)\n",
      "Epoch: [41][9/18]\tTime 0.082 (0.109)\tData 0.059 (0.076)\tLoss 0.2409 (0.6928)\tAcc 1.000 (0.729)\n",
      "Epoch: [41][10/18]\tTime 0.092 (0.107)\tData 0.058 (0.074)\tLoss 1.3237 (0.7558)\tAcc 0.500 (0.706)\n",
      "Epoch: [41][11/18]\tTime 0.076 (0.105)\tData 0.051 (0.072)\tLoss 1.3792 (0.8125)\tAcc 0.375 (0.676)\n",
      "Epoch: [41][12/18]\tTime 0.077 (0.102)\tData 0.056 (0.071)\tLoss 0.8588 (0.8164)\tAcc 0.688 (0.677)\n",
      "Epoch: [41][13/18]\tTime 0.081 (0.101)\tData 0.060 (0.070)\tLoss 1.0438 (0.8339)\tAcc 0.625 (0.673)\n",
      "Epoch: [41][14/18]\tTime 0.080 (0.099)\tData 0.059 (0.069)\tLoss 0.7906 (0.8308)\tAcc 0.688 (0.674)\n",
      "Epoch: [41][15/18]\tTime 0.081 (0.098)\tData 0.060 (0.069)\tLoss 0.8403 (0.8314)\tAcc 0.688 (0.675)\n",
      "Epoch: [41][16/18]\tTime 0.080 (0.097)\tData 0.059 (0.068)\tLoss 0.7687 (0.8275)\tAcc 0.750 (0.680)\n",
      "Epoch: [41][17/18]\tTime 0.081 (0.096)\tData 0.060 (0.068)\tLoss 0.7249 (0.8215)\tAcc 0.625 (0.676)\n",
      "Epoch: [41][18/18]\tTime 0.080 (0.095)\tData 0.060 (0.067)\tLoss 0.7810 (0.8203)\tAcc 0.750 (0.679)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/12]\tTime 0.363 (0.363)\tData 0.331 (0.331)\tLoss 0.5758 (0.5758)\tAcc 0.750 (0.750)\n",
      "Epoch: [42][2/12]\tTime 0.089 (0.226)\tData 0.062 (0.197)\tLoss 0.7622 (0.6690)\tAcc 0.812 (0.781)\n",
      "Epoch: [42][3/12]\tTime 0.080 (0.177)\tData 0.054 (0.149)\tLoss 0.8909 (0.7430)\tAcc 0.688 (0.750)\n",
      "Epoch: [42][4/12]\tTime 0.087 (0.155)\tData 0.058 (0.126)\tLoss 0.4083 (0.6593)\tAcc 1.000 (0.812)\n",
      "Epoch: [42][5/12]\tTime 0.090 (0.142)\tData 0.057 (0.112)\tLoss 0.6836 (0.6642)\tAcc 0.688 (0.788)\n",
      "Epoch: [42][6/12]\tTime 0.085 (0.132)\tData 0.056 (0.103)\tLoss 0.8031 (0.6873)\tAcc 0.562 (0.750)\n",
      "Epoch: [42][7/12]\tTime 0.085 (0.126)\tData 0.059 (0.097)\tLoss 0.6342 (0.6798)\tAcc 0.875 (0.768)\n",
      "Epoch: [42][8/12]\tTime 0.082 (0.120)\tData 0.058 (0.092)\tLoss 0.9341 (0.7115)\tAcc 0.562 (0.742)\n",
      "Epoch: [42][9/12]\tTime 0.086 (0.116)\tData 0.062 (0.089)\tLoss 1.3020 (0.7771)\tAcc 0.438 (0.708)\n",
      "Epoch: [42][10/12]\tTime 0.087 (0.113)\tData 0.063 (0.086)\tLoss 0.8517 (0.7846)\tAcc 0.688 (0.706)\n",
      "Epoch: [42][11/12]\tTime 0.086 (0.111)\tData 0.062 (0.084)\tLoss 0.6938 (0.7763)\tAcc 0.688 (0.705)\n",
      "Epoch: [42][12/12]\tTime 0.079 (0.108)\tData 0.055 (0.081)\tLoss 0.4845 (0.7534)\tAcc 0.800 (0.712)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/18]\tTime 0.360 (0.360)\tData 0.337 (0.337)\tLoss 0.3663 (0.3663)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/18]\tTime 0.083 (0.222)\tData 0.057 (0.197)\tLoss 1.0883 (0.7273)\tAcc 0.438 (0.688)\n",
      "Epoch: [42][3/18]\tTime 0.077 (0.173)\tData 0.054 (0.150)\tLoss 0.6435 (0.6994)\tAcc 0.750 (0.708)\n",
      "Epoch: [42][4/18]\tTime 0.078 (0.150)\tData 0.057 (0.127)\tLoss 0.6656 (0.6909)\tAcc 0.688 (0.703)\n",
      "Epoch: [42][5/18]\tTime 0.080 (0.136)\tData 0.059 (0.113)\tLoss 0.7977 (0.7123)\tAcc 0.750 (0.713)\n",
      "Epoch: [42][6/18]\tTime 0.081 (0.127)\tData 0.060 (0.104)\tLoss 0.2923 (0.6423)\tAcc 0.938 (0.750)\n",
      "Epoch: [42][7/18]\tTime 0.079 (0.120)\tData 0.057 (0.098)\tLoss 0.6649 (0.6455)\tAcc 0.688 (0.741)\n",
      "Epoch: [42][8/18]\tTime 0.080 (0.115)\tData 0.058 (0.093)\tLoss 0.9204 (0.6799)\tAcc 0.688 (0.734)\n",
      "Epoch: [42][9/18]\tTime 0.082 (0.111)\tData 0.059 (0.089)\tLoss 0.2852 (0.6360)\tAcc 1.000 (0.764)\n",
      "Epoch: [42][10/18]\tTime 0.079 (0.108)\tData 0.058 (0.086)\tLoss 1.3786 (0.7103)\tAcc 0.375 (0.725)\n",
      "Epoch: [42][11/18]\tTime 0.082 (0.105)\tData 0.060 (0.083)\tLoss 1.3085 (0.7647)\tAcc 0.375 (0.693)\n",
      "Epoch: [42][12/18]\tTime 0.080 (0.103)\tData 0.060 (0.081)\tLoss 1.0760 (0.7906)\tAcc 0.562 (0.682)\n",
      "Epoch: [42][13/18]\tTime 0.073 (0.101)\tData 0.054 (0.079)\tLoss 1.1276 (0.8165)\tAcc 0.562 (0.673)\n",
      "Epoch: [42][14/18]\tTime 0.074 (0.099)\tData 0.055 (0.078)\tLoss 0.8241 (0.8171)\tAcc 0.562 (0.665)\n",
      "Epoch: [42][15/18]\tTime 0.076 (0.098)\tData 0.056 (0.076)\tLoss 0.8365 (0.8184)\tAcc 0.750 (0.671)\n",
      "Epoch: [42][16/18]\tTime 0.081 (0.097)\tData 0.060 (0.075)\tLoss 0.8257 (0.8188)\tAcc 0.688 (0.672)\n",
      "Epoch: [42][17/18]\tTime 0.081 (0.096)\tData 0.060 (0.074)\tLoss 0.8705 (0.8219)\tAcc 0.625 (0.669)\n",
      "Epoch: [42][18/18]\tTime 0.080 (0.095)\tData 0.060 (0.073)\tLoss 0.8591 (0.8229)\tAcc 0.625 (0.668)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/12]\tTime 0.306 (0.306)\tData 0.272 (0.272)\tLoss 0.5977 (0.5977)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][2/12]\tTime 0.072 (0.189)\tData 0.046 (0.159)\tLoss 0.9160 (0.7569)\tAcc 0.562 (0.625)\n",
      "Epoch: [43][3/12]\tTime 0.081 (0.153)\tData 0.053 (0.124)\tLoss 0.8279 (0.7806)\tAcc 0.625 (0.625)\n",
      "Epoch: [43][4/12]\tTime 0.078 (0.134)\tData 0.050 (0.105)\tLoss 0.7657 (0.7769)\tAcc 0.688 (0.641)\n",
      "Epoch: [43][5/12]\tTime 0.081 (0.124)\tData 0.055 (0.095)\tLoss 0.8383 (0.7891)\tAcc 0.625 (0.637)\n",
      "Epoch: [43][6/12]\tTime 0.079 (0.116)\tData 0.053 (0.088)\tLoss 0.6880 (0.7723)\tAcc 0.812 (0.667)\n",
      "Epoch: [43][7/12]\tTime 0.078 (0.111)\tData 0.052 (0.083)\tLoss 0.5891 (0.7461)\tAcc 0.750 (0.679)\n",
      "Epoch: [43][8/12]\tTime 0.080 (0.107)\tData 0.056 (0.080)\tLoss 0.5731 (0.7245)\tAcc 0.812 (0.695)\n",
      "Epoch: [43][9/12]\tTime 0.077 (0.104)\tData 0.054 (0.077)\tLoss 0.5957 (0.7102)\tAcc 0.812 (0.708)\n",
      "Epoch: [43][10/12]\tTime 0.078 (0.101)\tData 0.055 (0.075)\tLoss 0.6677 (0.7059)\tAcc 0.750 (0.713)\n",
      "Epoch: [43][11/12]\tTime 0.081 (0.099)\tData 0.057 (0.073)\tLoss 0.8059 (0.7150)\tAcc 0.625 (0.705)\n",
      "Epoch: [43][12/12]\tTime 0.078 (0.097)\tData 0.055 (0.071)\tLoss 0.6548 (0.7103)\tAcc 0.867 (0.717)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/18]\tTime 0.319 (0.319)\tData 0.293 (0.293)\tLoss 0.3480 (0.3480)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/18]\tTime 0.077 (0.198)\tData 0.055 (0.174)\tLoss 1.0088 (0.6784)\tAcc 0.438 (0.688)\n",
      "Epoch: [43][3/18]\tTime 0.073 (0.156)\tData 0.053 (0.134)\tLoss 0.7225 (0.6931)\tAcc 0.750 (0.708)\n",
      "Epoch: [43][4/18]\tTime 0.078 (0.137)\tData 0.053 (0.114)\tLoss 0.7303 (0.7024)\tAcc 0.625 (0.688)\n",
      "Epoch: [43][5/18]\tTime 0.072 (0.124)\tData 0.051 (0.101)\tLoss 0.9071 (0.7433)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][6/18]\tTime 0.074 (0.116)\tData 0.053 (0.093)\tLoss 0.2566 (0.6622)\tAcc 1.000 (0.740)\n",
      "Epoch: [43][7/18]\tTime 0.077 (0.110)\tData 0.053 (0.087)\tLoss 0.7256 (0.6713)\tAcc 0.625 (0.723)\n",
      "Epoch: [43][8/18]\tTime 0.072 (0.105)\tData 0.051 (0.083)\tLoss 0.9999 (0.7124)\tAcc 0.562 (0.703)\n",
      "Epoch: [43][9/18]\tTime 0.075 (0.102)\tData 0.054 (0.080)\tLoss 0.1715 (0.6523)\tAcc 1.000 (0.736)\n",
      "Epoch: [43][10/18]\tTime 0.074 (0.099)\tData 0.053 (0.077)\tLoss 1.3959 (0.7266)\tAcc 0.562 (0.719)\n",
      "Epoch: [43][11/18]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 1.2934 (0.7782)\tAcc 0.375 (0.688)\n",
      "Epoch: [43][12/18]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.9756 (0.7946)\tAcc 0.625 (0.682)\n",
      "Epoch: [43][13/18]\tTime 0.073 (0.093)\tData 0.053 (0.072)\tLoss 1.0775 (0.8164)\tAcc 0.625 (0.678)\n",
      "Epoch: [43][14/18]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.8543 (0.8191)\tAcc 0.625 (0.674)\n",
      "Epoch: [43][15/18]\tTime 0.073 (0.091)\tData 0.055 (0.069)\tLoss 0.8216 (0.8192)\tAcc 0.688 (0.675)\n",
      "Epoch: [43][16/18]\tTime 0.073 (0.089)\tData 0.055 (0.068)\tLoss 0.8334 (0.8201)\tAcc 0.688 (0.676)\n",
      "Epoch: [43][17/18]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.8659 (0.8228)\tAcc 0.625 (0.673)\n",
      "Epoch: [43][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.5774 (0.8158)\tAcc 1.000 (0.682)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/12]\tTime 0.338 (0.338)\tData 0.309 (0.309)\tLoss 0.9458 (0.9458)\tAcc 0.562 (0.562)\n",
      "Epoch: [44][2/12]\tTime 0.076 (0.207)\tData 0.050 (0.179)\tLoss 0.9985 (0.9721)\tAcc 0.562 (0.562)\n",
      "Epoch: [44][3/12]\tTime 0.080 (0.165)\tData 0.052 (0.137)\tLoss 0.6320 (0.8588)\tAcc 0.750 (0.625)\n",
      "Epoch: [44][4/12]\tTime 0.077 (0.143)\tData 0.051 (0.116)\tLoss 0.6802 (0.8141)\tAcc 0.750 (0.656)\n",
      "Epoch: [44][5/12]\tTime 0.083 (0.131)\tData 0.055 (0.103)\tLoss 1.1878 (0.8889)\tAcc 0.562 (0.637)\n",
      "Epoch: [44][6/12]\tTime 0.076 (0.122)\tData 0.051 (0.095)\tLoss 0.4210 (0.8109)\tAcc 0.938 (0.688)\n",
      "Epoch: [44][7/12]\tTime 0.079 (0.116)\tData 0.053 (0.089)\tLoss 0.7587 (0.8034)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][8/12]\tTime 0.079 (0.111)\tData 0.055 (0.085)\tLoss 0.6777 (0.7877)\tAcc 0.750 (0.695)\n",
      "Epoch: [44][9/12]\tTime 0.081 (0.108)\tData 0.055 (0.081)\tLoss 0.6592 (0.7734)\tAcc 0.812 (0.708)\n",
      "Epoch: [44][10/12]\tTime 0.078 (0.105)\tData 0.053 (0.078)\tLoss 0.5491 (0.7510)\tAcc 0.750 (0.713)\n",
      "Epoch: [44][11/12]\tTime 0.081 (0.103)\tData 0.056 (0.076)\tLoss 0.8237 (0.7576)\tAcc 0.812 (0.722)\n",
      "Epoch: [44][12/12]\tTime 0.086 (0.101)\tData 0.061 (0.075)\tLoss 0.7886 (0.7600)\tAcc 0.733 (0.723)\n",
      "validation at epoch 44\n",
      "Epoch: [44][1/18]\tTime 0.364 (0.364)\tData 0.331 (0.331)\tLoss 0.2863 (0.2863)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/18]\tTime 0.072 (0.218)\tData 0.049 (0.190)\tLoss 0.9306 (0.6085)\tAcc 0.438 (0.688)\n",
      "Epoch: [44][3/18]\tTime 0.082 (0.173)\tData 0.061 (0.147)\tLoss 0.6585 (0.6251)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][4/18]\tTime 0.082 (0.150)\tData 0.058 (0.125)\tLoss 0.6830 (0.6396)\tAcc 0.688 (0.703)\n",
      "Epoch: [44][5/18]\tTime 0.080 (0.136)\tData 0.057 (0.111)\tLoss 0.8511 (0.6819)\tAcc 0.750 (0.713)\n",
      "Epoch: [44][6/18]\tTime 0.082 (0.127)\tData 0.058 (0.103)\tLoss 0.3504 (0.6267)\tAcc 0.938 (0.750)\n",
      "Epoch: [44][7/18]\tTime 0.079 (0.120)\tData 0.057 (0.096)\tLoss 0.8138 (0.6534)\tAcc 0.625 (0.732)\n",
      "Epoch: [44][8/18]\tTime 0.088 (0.116)\tData 0.058 (0.091)\tLoss 1.0827 (0.7071)\tAcc 0.688 (0.727)\n",
      "Epoch: [44][9/18]\tTime 0.077 (0.112)\tData 0.055 (0.087)\tLoss 0.2355 (0.6547)\tAcc 1.000 (0.757)\n",
      "Epoch: [44][10/18]\tTime 0.078 (0.108)\tData 0.057 (0.084)\tLoss 1.3994 (0.7291)\tAcc 0.500 (0.731)\n",
      "Epoch: [44][11/18]\tTime 0.082 (0.106)\tData 0.059 (0.082)\tLoss 1.2944 (0.7805)\tAcc 0.375 (0.699)\n",
      "Epoch: [44][12/18]\tTime 0.079 (0.104)\tData 0.057 (0.080)\tLoss 0.9619 (0.7956)\tAcc 0.625 (0.693)\n",
      "Epoch: [44][13/18]\tTime 0.079 (0.102)\tData 0.059 (0.078)\tLoss 1.1620 (0.8238)\tAcc 0.438 (0.673)\n",
      "Epoch: [44][14/18]\tTime 0.080 (0.100)\tData 0.060 (0.077)\tLoss 0.7730 (0.8202)\tAcc 0.625 (0.670)\n",
      "Epoch: [44][15/18]\tTime 0.078 (0.099)\tData 0.058 (0.076)\tLoss 0.8399 (0.8215)\tAcc 0.750 (0.675)\n",
      "Epoch: [44][16/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 0.8706 (0.8246)\tAcc 0.562 (0.668)\n",
      "Epoch: [44][17/18]\tTime 0.082 (0.097)\tData 0.061 (0.074)\tLoss 0.8138 (0.8239)\tAcc 0.625 (0.665)\n",
      "Epoch: [44][18/18]\tTime 0.081 (0.096)\tData 0.061 (0.073)\tLoss 0.9041 (0.8262)\tAcc 0.625 (0.664)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/12]\tTime 0.313 (0.313)\tData 0.279 (0.279)\tLoss 0.6482 (0.6482)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][2/12]\tTime 0.082 (0.198)\tData 0.054 (0.167)\tLoss 0.6895 (0.6689)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][3/12]\tTime 0.089 (0.161)\tData 0.057 (0.130)\tLoss 0.5674 (0.6350)\tAcc 0.812 (0.771)\n",
      "Epoch: [45][4/12]\tTime 0.086 (0.142)\tData 0.055 (0.111)\tLoss 0.6411 (0.6365)\tAcc 0.812 (0.781)\n",
      "Epoch: [45][5/12]\tTime 0.084 (0.131)\tData 0.057 (0.101)\tLoss 0.5780 (0.6248)\tAcc 0.750 (0.775)\n",
      "Epoch: [45][6/12]\tTime 0.085 (0.123)\tData 0.058 (0.094)\tLoss 0.6359 (0.6267)\tAcc 0.812 (0.781)\n",
      "Epoch: [45][7/12]\tTime 0.085 (0.118)\tData 0.060 (0.089)\tLoss 0.9415 (0.6717)\tAcc 0.688 (0.768)\n",
      "Epoch: [45][8/12]\tTime 0.086 (0.114)\tData 0.061 (0.085)\tLoss 0.7575 (0.6824)\tAcc 0.688 (0.758)\n",
      "Epoch: [45][9/12]\tTime 0.086 (0.111)\tData 0.061 (0.083)\tLoss 0.7869 (0.6940)\tAcc 0.625 (0.743)\n",
      "Epoch: [45][10/12]\tTime 0.086 (0.108)\tData 0.061 (0.080)\tLoss 0.6372 (0.6883)\tAcc 0.750 (0.744)\n",
      "Epoch: [45][11/12]\tTime 0.088 (0.106)\tData 0.062 (0.079)\tLoss 0.8343 (0.7016)\tAcc 0.562 (0.727)\n",
      "Epoch: [45][12/12]\tTime 0.083 (0.104)\tData 0.059 (0.077)\tLoss 0.7141 (0.7026)\tAcc 0.733 (0.728)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/18]\tTime 0.368 (0.368)\tData 0.337 (0.337)\tLoss 0.3971 (0.3971)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/18]\tTime 0.068 (0.218)\tData 0.045 (0.191)\tLoss 1.0390 (0.7180)\tAcc 0.438 (0.688)\n",
      "Epoch: [45][3/18]\tTime 0.078 (0.172)\tData 0.055 (0.146)\tLoss 0.7595 (0.7318)\tAcc 0.625 (0.667)\n",
      "Epoch: [45][4/18]\tTime 0.093 (0.152)\tData 0.057 (0.124)\tLoss 0.7011 (0.7241)\tAcc 0.625 (0.656)\n",
      "Epoch: [45][5/18]\tTime 0.065 (0.135)\tData 0.044 (0.108)\tLoss 0.8995 (0.7592)\tAcc 0.750 (0.675)\n",
      "Epoch: [45][6/18]\tTime 0.081 (0.126)\tData 0.059 (0.100)\tLoss 0.3323 (0.6881)\tAcc 1.000 (0.729)\n",
      "Epoch: [45][7/18]\tTime 0.082 (0.120)\tData 0.059 (0.094)\tLoss 0.6127 (0.6773)\tAcc 0.812 (0.741)\n",
      "Epoch: [45][8/18]\tTime 0.079 (0.115)\tData 0.059 (0.089)\tLoss 1.0429 (0.7230)\tAcc 0.438 (0.703)\n",
      "Epoch: [45][9/18]\tTime 0.081 (0.111)\tData 0.059 (0.086)\tLoss 0.1760 (0.6622)\tAcc 1.000 (0.736)\n",
      "Epoch: [45][10/18]\tTime 0.080 (0.108)\tData 0.058 (0.083)\tLoss 1.2362 (0.7196)\tAcc 0.438 (0.706)\n",
      "Epoch: [45][11/18]\tTime 0.080 (0.105)\tData 0.059 (0.081)\tLoss 1.3087 (0.7732)\tAcc 0.375 (0.676)\n",
      "Epoch: [45][12/18]\tTime 0.080 (0.103)\tData 0.059 (0.079)\tLoss 0.9999 (0.7921)\tAcc 0.688 (0.677)\n",
      "Epoch: [45][13/18]\tTime 0.079 (0.101)\tData 0.059 (0.078)\tLoss 1.1468 (0.8194)\tAcc 0.562 (0.668)\n",
      "Epoch: [45][14/18]\tTime 0.080 (0.100)\tData 0.060 (0.076)\tLoss 0.8200 (0.8194)\tAcc 0.625 (0.665)\n",
      "Epoch: [45][15/18]\tTime 0.080 (0.098)\tData 0.060 (0.075)\tLoss 0.9299 (0.8268)\tAcc 0.750 (0.671)\n",
      "Epoch: [45][16/18]\tTime 0.076 (0.097)\tData 0.056 (0.074)\tLoss 0.9050 (0.8317)\tAcc 0.625 (0.668)\n",
      "Epoch: [45][17/18]\tTime 0.073 (0.096)\tData 0.054 (0.073)\tLoss 0.8062 (0.8302)\tAcc 0.625 (0.665)\n",
      "Epoch: [45][18/18]\tTime 0.074 (0.094)\tData 0.056 (0.072)\tLoss 0.6402 (0.8247)\tAcc 1.000 (0.675)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/12]\tTime 0.344 (0.344)\tData 0.314 (0.314)\tLoss 1.0059 (1.0059)\tAcc 0.562 (0.562)\n",
      "Epoch: [46][2/12]\tTime 0.078 (0.211)\tData 0.052 (0.183)\tLoss 0.6727 (0.8393)\tAcc 0.750 (0.656)\n",
      "Epoch: [46][3/12]\tTime 0.091 (0.171)\tData 0.060 (0.142)\tLoss 0.5928 (0.7571)\tAcc 0.750 (0.688)\n",
      "Epoch: [46][4/12]\tTime 0.082 (0.149)\tData 0.056 (0.121)\tLoss 0.7103 (0.7454)\tAcc 0.750 (0.703)\n",
      "Epoch: [46][5/12]\tTime 0.087 (0.136)\tData 0.061 (0.109)\tLoss 0.6747 (0.7313)\tAcc 0.750 (0.713)\n",
      "Epoch: [46][6/12]\tTime 0.085 (0.128)\tData 0.060 (0.100)\tLoss 1.1055 (0.7936)\tAcc 0.500 (0.677)\n",
      "Epoch: [46][7/12]\tTime 0.085 (0.122)\tData 0.061 (0.095)\tLoss 0.8076 (0.7956)\tAcc 0.625 (0.670)\n",
      "Epoch: [46][8/12]\tTime 0.084 (0.117)\tData 0.061 (0.090)\tLoss 0.6320 (0.7752)\tAcc 0.750 (0.680)\n",
      "Epoch: [46][9/12]\tTime 0.079 (0.113)\tData 0.056 (0.087)\tLoss 0.6050 (0.7563)\tAcc 0.812 (0.694)\n",
      "Epoch: [46][10/12]\tTime 0.078 (0.109)\tData 0.055 (0.083)\tLoss 0.8496 (0.7656)\tAcc 0.688 (0.694)\n",
      "Epoch: [46][11/12]\tTime 0.081 (0.107)\tData 0.058 (0.081)\tLoss 0.7623 (0.7653)\tAcc 0.750 (0.699)\n",
      "Epoch: [46][12/12]\tTime 0.078 (0.104)\tData 0.055 (0.079)\tLoss 0.6039 (0.7526)\tAcc 0.800 (0.707)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/18]\tTime 0.353 (0.353)\tData 0.328 (0.328)\tLoss 0.3314 (0.3314)\tAcc 0.875 (0.875)\n",
      "Epoch: [46][2/18]\tTime 0.078 (0.216)\tData 0.057 (0.193)\tLoss 1.1621 (0.7467)\tAcc 0.438 (0.656)\n",
      "Epoch: [46][3/18]\tTime 0.081 (0.171)\tData 0.059 (0.148)\tLoss 0.5770 (0.6901)\tAcc 0.938 (0.750)\n",
      "Epoch: [46][4/18]\tTime 0.080 (0.148)\tData 0.058 (0.125)\tLoss 0.5819 (0.6631)\tAcc 0.688 (0.734)\n",
      "Epoch: [46][5/18]\tTime 0.081 (0.135)\tData 0.059 (0.112)\tLoss 0.8065 (0.6918)\tAcc 0.750 (0.738)\n",
      "Epoch: [46][6/18]\tTime 0.084 (0.126)\tData 0.059 (0.103)\tLoss 0.3732 (0.6387)\tAcc 0.938 (0.771)\n",
      "Epoch: [46][7/18]\tTime 0.074 (0.119)\tData 0.054 (0.096)\tLoss 0.7825 (0.6592)\tAcc 0.562 (0.741)\n",
      "Epoch: [46][8/18]\tTime 0.078 (0.114)\tData 0.056 (0.091)\tLoss 0.9927 (0.7009)\tAcc 0.500 (0.711)\n",
      "Epoch: [46][9/18]\tTime 0.080 (0.110)\tData 0.059 (0.088)\tLoss 0.2363 (0.6493)\tAcc 1.000 (0.743)\n",
      "Epoch: [46][10/18]\tTime 0.082 (0.107)\tData 0.059 (0.085)\tLoss 1.2699 (0.7114)\tAcc 0.625 (0.731)\n",
      "Epoch: [46][11/18]\tTime 0.078 (0.104)\tData 0.057 (0.082)\tLoss 1.3310 (0.7677)\tAcc 0.375 (0.699)\n",
      "Epoch: [46][12/18]\tTime 0.081 (0.102)\tData 0.059 (0.080)\tLoss 0.8365 (0.7734)\tAcc 0.750 (0.703)\n",
      "Epoch: [46][13/18]\tTime 0.079 (0.101)\tData 0.059 (0.079)\tLoss 1.2666 (0.8114)\tAcc 0.562 (0.692)\n",
      "Epoch: [46][14/18]\tTime 0.080 (0.099)\tData 0.060 (0.077)\tLoss 0.8800 (0.8163)\tAcc 0.562 (0.683)\n",
      "Epoch: [46][15/18]\tTime 0.078 (0.098)\tData 0.059 (0.076)\tLoss 0.9652 (0.8262)\tAcc 0.562 (0.675)\n",
      "Epoch: [46][16/18]\tTime 0.075 (0.096)\tData 0.056 (0.075)\tLoss 0.7747 (0.8230)\tAcc 0.750 (0.680)\n",
      "Epoch: [46][17/18]\tTime 0.074 (0.095)\tData 0.055 (0.074)\tLoss 0.8407 (0.8240)\tAcc 0.625 (0.676)\n",
      "Epoch: [46][18/18]\tTime 0.079 (0.094)\tData 0.060 (0.073)\tLoss 0.6870 (0.8201)\tAcc 0.750 (0.679)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/12]\tTime 0.284 (0.284)\tData 0.251 (0.251)\tLoss 0.8667 (0.8667)\tAcc 0.625 (0.625)\n",
      "Epoch: [47][2/12]\tTime 0.081 (0.182)\tData 0.054 (0.152)\tLoss 0.5257 (0.6962)\tAcc 0.875 (0.750)\n",
      "Epoch: [47][3/12]\tTime 0.085 (0.150)\tData 0.059 (0.121)\tLoss 0.5350 (0.6425)\tAcc 0.812 (0.771)\n",
      "Epoch: [47][4/12]\tTime 0.087 (0.134)\tData 0.060 (0.106)\tLoss 0.6702 (0.6494)\tAcc 0.750 (0.766)\n",
      "Epoch: [47][5/12]\tTime 0.085 (0.125)\tData 0.058 (0.096)\tLoss 0.6571 (0.6509)\tAcc 0.750 (0.762)\n",
      "Epoch: [47][6/12]\tTime 0.084 (0.118)\tData 0.058 (0.090)\tLoss 0.9324 (0.6978)\tAcc 0.562 (0.729)\n",
      "Epoch: [47][7/12]\tTime 0.087 (0.113)\tData 0.061 (0.086)\tLoss 0.5830 (0.6814)\tAcc 0.812 (0.741)\n",
      "Epoch: [47][8/12]\tTime 0.083 (0.110)\tData 0.058 (0.082)\tLoss 0.7816 (0.6940)\tAcc 0.688 (0.734)\n",
      "Epoch: [47][9/12]\tTime 0.086 (0.107)\tData 0.061 (0.080)\tLoss 1.0078 (0.7288)\tAcc 0.500 (0.708)\n",
      "Epoch: [47][10/12]\tTime 0.086 (0.105)\tData 0.062 (0.078)\tLoss 0.8758 (0.7435)\tAcc 0.750 (0.713)\n",
      "Epoch: [47][11/12]\tTime 0.087 (0.103)\tData 0.063 (0.077)\tLoss 0.9850 (0.7655)\tAcc 0.625 (0.705)\n",
      "Epoch: [47][12/12]\tTime 0.085 (0.102)\tData 0.062 (0.075)\tLoss 0.6948 (0.7599)\tAcc 0.733 (0.707)\n",
      "validation at epoch 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [47][1/18]\tTime 0.327 (0.327)\tData 0.299 (0.299)\tLoss 0.3291 (0.3291)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/18]\tTime 0.080 (0.203)\tData 0.053 (0.176)\tLoss 1.0580 (0.6935)\tAcc 0.438 (0.688)\n",
      "Epoch: [47][3/18]\tTime 0.076 (0.161)\tData 0.053 (0.135)\tLoss 0.6312 (0.6727)\tAcc 0.750 (0.708)\n",
      "Epoch: [47][4/18]\tTime 0.079 (0.141)\tData 0.058 (0.116)\tLoss 0.6467 (0.6662)\tAcc 0.625 (0.688)\n",
      "Epoch: [47][5/18]\tTime 0.081 (0.129)\tData 0.060 (0.104)\tLoss 0.8773 (0.7085)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][6/18]\tTime 0.080 (0.121)\tData 0.059 (0.097)\tLoss 0.2173 (0.6266)\tAcc 1.000 (0.740)\n",
      "Epoch: [47][7/18]\tTime 0.080 (0.115)\tData 0.058 (0.091)\tLoss 0.6772 (0.6338)\tAcc 0.625 (0.723)\n",
      "Epoch: [47][8/18]\tTime 0.075 (0.110)\tData 0.055 (0.087)\tLoss 1.1089 (0.6932)\tAcc 0.500 (0.695)\n",
      "Epoch: [47][9/18]\tTime 0.077 (0.106)\tData 0.054 (0.083)\tLoss 0.1755 (0.6357)\tAcc 1.000 (0.729)\n",
      "Epoch: [47][10/18]\tTime 0.072 (0.103)\tData 0.051 (0.080)\tLoss 1.1304 (0.6852)\tAcc 0.625 (0.719)\n",
      "Epoch: [47][11/18]\tTime 0.077 (0.100)\tData 0.053 (0.078)\tLoss 1.5498 (0.7638)\tAcc 0.375 (0.688)\n",
      "Epoch: [47][12/18]\tTime 0.070 (0.098)\tData 0.050 (0.075)\tLoss 0.8359 (0.7698)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][13/18]\tTime 0.073 (0.096)\tData 0.054 (0.074)\tLoss 1.0396 (0.7905)\tAcc 0.562 (0.678)\n",
      "Epoch: [47][14/18]\tTime 0.076 (0.095)\tData 0.056 (0.072)\tLoss 0.9216 (0.7999)\tAcc 0.562 (0.670)\n",
      "Epoch: [47][15/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.7652 (0.7976)\tAcc 0.688 (0.671)\n",
      "Epoch: [47][16/18]\tTime 0.080 (0.093)\tData 0.060 (0.071)\tLoss 0.8472 (0.8007)\tAcc 0.688 (0.672)\n",
      "Epoch: [47][17/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.7150 (0.7956)\tAcc 0.688 (0.673)\n",
      "Epoch: [47][18/18]\tTime 0.079 (0.091)\tData 0.059 (0.070)\tLoss 0.7826 (0.7953)\tAcc 0.625 (0.671)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/12]\tTime 0.304 (0.304)\tData 0.274 (0.274)\tLoss 0.8380 (0.8380)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][2/12]\tTime 0.085 (0.194)\tData 0.059 (0.166)\tLoss 0.7469 (0.7924)\tAcc 0.625 (0.656)\n",
      "Epoch: [48][3/12]\tTime 0.088 (0.159)\tData 0.061 (0.131)\tLoss 0.8574 (0.8141)\tAcc 0.688 (0.667)\n",
      "Epoch: [48][4/12]\tTime 0.086 (0.141)\tData 0.059 (0.113)\tLoss 0.5469 (0.7473)\tAcc 0.812 (0.703)\n",
      "Epoch: [48][5/12]\tTime 0.085 (0.129)\tData 0.059 (0.103)\tLoss 0.6860 (0.7350)\tAcc 0.750 (0.713)\n",
      "Epoch: [48][6/12]\tTime 0.085 (0.122)\tData 0.060 (0.095)\tLoss 0.9722 (0.7746)\tAcc 0.688 (0.708)\n",
      "Epoch: [48][7/12]\tTime 0.086 (0.117)\tData 0.061 (0.091)\tLoss 0.6165 (0.7520)\tAcc 0.812 (0.723)\n",
      "Epoch: [48][8/12]\tTime 0.082 (0.113)\tData 0.057 (0.086)\tLoss 0.4924 (0.7195)\tAcc 0.812 (0.734)\n",
      "Epoch: [48][9/12]\tTime 0.081 (0.109)\tData 0.056 (0.083)\tLoss 0.6092 (0.7073)\tAcc 0.750 (0.736)\n",
      "Epoch: [48][10/12]\tTime 0.078 (0.106)\tData 0.054 (0.080)\tLoss 0.9486 (0.7314)\tAcc 0.625 (0.725)\n",
      "Epoch: [48][11/12]\tTime 0.081 (0.104)\tData 0.056 (0.078)\tLoss 0.8646 (0.7435)\tAcc 0.688 (0.722)\n",
      "Epoch: [48][12/12]\tTime 0.079 (0.102)\tData 0.054 (0.076)\tLoss 0.9877 (0.7627)\tAcc 0.533 (0.707)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/18]\tTime 0.335 (0.335)\tData 0.309 (0.309)\tLoss 0.3773 (0.3773)\tAcc 0.938 (0.938)\n",
      "Epoch: [48][2/18]\tTime 0.071 (0.203)\tData 0.050 (0.179)\tLoss 1.0612 (0.7192)\tAcc 0.438 (0.688)\n",
      "Epoch: [48][3/18]\tTime 0.076 (0.161)\tData 0.053 (0.137)\tLoss 0.7231 (0.7205)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][4/18]\tTime 0.074 (0.139)\tData 0.051 (0.116)\tLoss 0.6940 (0.7139)\tAcc 0.625 (0.672)\n",
      "Epoch: [48][5/18]\tTime 0.073 (0.126)\tData 0.051 (0.103)\tLoss 0.8842 (0.7480)\tAcc 0.750 (0.688)\n",
      "Epoch: [48][6/18]\tTime 0.075 (0.117)\tData 0.053 (0.094)\tLoss 0.3768 (0.6861)\tAcc 0.938 (0.729)\n",
      "Epoch: [48][7/18]\tTime 0.074 (0.111)\tData 0.053 (0.088)\tLoss 0.7325 (0.6927)\tAcc 0.625 (0.714)\n",
      "Epoch: [48][8/18]\tTime 0.077 (0.107)\tData 0.053 (0.084)\tLoss 0.9924 (0.7302)\tAcc 0.562 (0.695)\n",
      "Epoch: [48][9/18]\tTime 0.072 (0.103)\tData 0.051 (0.080)\tLoss 0.1699 (0.6679)\tAcc 1.000 (0.729)\n",
      "Epoch: [48][10/18]\tTime 0.074 (0.100)\tData 0.053 (0.078)\tLoss 1.1751 (0.7187)\tAcc 0.562 (0.713)\n",
      "Epoch: [48][11/18]\tTime 0.075 (0.098)\tData 0.054 (0.075)\tLoss 1.3627 (0.7772)\tAcc 0.375 (0.682)\n",
      "Epoch: [48][12/18]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.7809 (0.7775)\tAcc 0.625 (0.677)\n",
      "Epoch: [48][13/18]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 1.1118 (0.8032)\tAcc 0.500 (0.663)\n",
      "Epoch: [48][14/18]\tTime 0.076 (0.093)\tData 0.055 (0.071)\tLoss 0.7729 (0.8011)\tAcc 0.562 (0.656)\n",
      "Epoch: [48][15/18]\tTime 0.072 (0.091)\tData 0.053 (0.070)\tLoss 0.7567 (0.7981)\tAcc 0.750 (0.663)\n",
      "Epoch: [48][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.9618 (0.8083)\tAcc 0.500 (0.652)\n",
      "Epoch: [48][17/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.9521 (0.8168)\tAcc 0.562 (0.647)\n",
      "Epoch: [48][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.6501 (0.8120)\tAcc 0.875 (0.654)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/12]\tTime 0.306 (0.306)\tData 0.276 (0.276)\tLoss 0.7694 (0.7694)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][2/12]\tTime 0.076 (0.191)\tData 0.049 (0.162)\tLoss 0.6451 (0.7072)\tAcc 0.875 (0.812)\n",
      "Epoch: [49][3/12]\tTime 0.088 (0.157)\tData 0.057 (0.127)\tLoss 0.9377 (0.7840)\tAcc 0.625 (0.750)\n",
      "Epoch: [49][4/12]\tTime 0.086 (0.139)\tData 0.056 (0.109)\tLoss 0.6876 (0.7599)\tAcc 0.688 (0.734)\n",
      "Epoch: [49][5/12]\tTime 0.089 (0.129)\tData 0.061 (0.100)\tLoss 0.9471 (0.7974)\tAcc 0.625 (0.713)\n",
      "Epoch: [49][6/12]\tTime 0.085 (0.122)\tData 0.058 (0.093)\tLoss 0.7717 (0.7931)\tAcc 0.750 (0.719)\n",
      "Epoch: [49][7/12]\tTime 0.077 (0.115)\tData 0.052 (0.087)\tLoss 0.5945 (0.7647)\tAcc 0.750 (0.723)\n",
      "Epoch: [49][8/12]\tTime 0.080 (0.111)\tData 0.055 (0.083)\tLoss 0.7271 (0.7600)\tAcc 0.688 (0.719)\n",
      "Epoch: [49][9/12]\tTime 0.079 (0.107)\tData 0.055 (0.080)\tLoss 0.5969 (0.7419)\tAcc 0.750 (0.722)\n",
      "Epoch: [49][10/12]\tTime 0.079 (0.105)\tData 0.055 (0.077)\tLoss 0.5411 (0.7218)\tAcc 0.750 (0.725)\n",
      "Epoch: [49][11/12]\tTime 0.081 (0.102)\tData 0.057 (0.075)\tLoss 0.6330 (0.7137)\tAcc 0.812 (0.733)\n",
      "Epoch: [49][12/12]\tTime 0.078 (0.100)\tData 0.055 (0.074)\tLoss 1.1641 (0.7491)\tAcc 0.400 (0.707)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/18]\tTime 0.348 (0.348)\tData 0.324 (0.324)\tLoss 0.3276 (0.3276)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/18]\tTime 0.072 (0.210)\tData 0.051 (0.187)\tLoss 0.9912 (0.6594)\tAcc 0.438 (0.688)\n",
      "Epoch: [49][3/18]\tTime 0.075 (0.165)\tData 0.054 (0.143)\tLoss 0.6281 (0.6490)\tAcc 0.812 (0.729)\n",
      "Epoch: [49][4/18]\tTime 0.077 (0.143)\tData 0.053 (0.120)\tLoss 0.7124 (0.6648)\tAcc 0.625 (0.703)\n",
      "Epoch: [49][5/18]\tTime 0.072 (0.129)\tData 0.051 (0.106)\tLoss 0.7438 (0.6806)\tAcc 0.750 (0.713)\n",
      "Epoch: [49][6/18]\tTime 0.081 (0.121)\tData 0.059 (0.099)\tLoss 0.3223 (0.6209)\tAcc 1.000 (0.760)\n",
      "Epoch: [49][7/18]\tTime 0.074 (0.114)\tData 0.053 (0.092)\tLoss 0.6584 (0.6263)\tAcc 0.812 (0.768)\n",
      "Epoch: [49][8/18]\tTime 0.076 (0.109)\tData 0.053 (0.087)\tLoss 1.0087 (0.6741)\tAcc 0.625 (0.750)\n",
      "Epoch: [49][9/18]\tTime 0.073 (0.105)\tData 0.053 (0.083)\tLoss 0.2043 (0.6219)\tAcc 1.000 (0.778)\n",
      "Epoch: [49][10/18]\tTime 0.074 (0.102)\tData 0.053 (0.080)\tLoss 1.2443 (0.6841)\tAcc 0.438 (0.744)\n",
      "Epoch: [49][11/18]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 1.3112 (0.7411)\tAcc 0.375 (0.710)\n",
      "Epoch: [49][12/18]\tTime 0.079 (0.098)\tData 0.059 (0.076)\tLoss 0.8805 (0.7527)\tAcc 0.625 (0.703)\n",
      "Epoch: [49][13/18]\tTime 0.074 (0.096)\tData 0.054 (0.075)\tLoss 1.0108 (0.7726)\tAcc 0.688 (0.702)\n",
      "Epoch: [49][14/18]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.8372 (0.7772)\tAcc 0.625 (0.696)\n",
      "Epoch: [49][15/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.8152 (0.7797)\tAcc 0.688 (0.696)\n",
      "Epoch: [49][16/18]\tTime 0.080 (0.093)\tData 0.060 (0.072)\tLoss 0.9308 (0.7892)\tAcc 0.625 (0.691)\n",
      "Epoch: [49][17/18]\tTime 0.080 (0.092)\tData 0.060 (0.071)\tLoss 0.7683 (0.7879)\tAcc 0.625 (0.688)\n",
      "Epoch: [49][18/18]\tTime 0.079 (0.091)\tData 0.060 (0.070)\tLoss 0.7966 (0.7882)\tAcc 0.875 (0.693)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/12]\tTime 0.320 (0.320)\tData 0.290 (0.290)\tLoss 0.6402 (0.6402)\tAcc 0.750 (0.750)\n",
      "Epoch: [50][2/12]\tTime 0.078 (0.199)\tData 0.051 (0.171)\tLoss 0.8886 (0.7644)\tAcc 0.500 (0.625)\n",
      "Epoch: [50][3/12]\tTime 0.081 (0.160)\tData 0.052 (0.131)\tLoss 0.7858 (0.7715)\tAcc 0.750 (0.667)\n",
      "Epoch: [50][4/12]\tTime 0.077 (0.139)\tData 0.049 (0.111)\tLoss 0.5516 (0.7166)\tAcc 0.750 (0.688)\n",
      "Epoch: [50][5/12]\tTime 0.080 (0.127)\tData 0.053 (0.099)\tLoss 0.7022 (0.7137)\tAcc 0.750 (0.700)\n",
      "Epoch: [50][6/12]\tTime 0.084 (0.120)\tData 0.052 (0.091)\tLoss 0.6906 (0.7098)\tAcc 0.812 (0.719)\n",
      "Epoch: [50][7/12]\tTime 0.074 (0.113)\tData 0.048 (0.085)\tLoss 0.8746 (0.7334)\tAcc 0.625 (0.705)\n",
      "Epoch: [50][8/12]\tTime 0.079 (0.109)\tData 0.055 (0.081)\tLoss 0.9960 (0.7662)\tAcc 0.625 (0.695)\n",
      "Epoch: [50][9/12]\tTime 0.080 (0.106)\tData 0.056 (0.078)\tLoss 1.0510 (0.7978)\tAcc 0.625 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][10/12]\tTime 0.078 (0.103)\tData 0.054 (0.076)\tLoss 0.7813 (0.7962)\tAcc 0.812 (0.700)\n",
      "Epoch: [50][11/12]\tTime 0.080 (0.101)\tData 0.056 (0.074)\tLoss 0.4320 (0.7631)\tAcc 0.875 (0.716)\n",
      "Epoch: [50][12/12]\tTime 0.078 (0.099)\tData 0.055 (0.073)\tLoss 0.8958 (0.7735)\tAcc 0.733 (0.717)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/18]\tTime 0.299 (0.299)\tData 0.276 (0.276)\tLoss 0.3368 (0.3368)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/18]\tTime 0.072 (0.186)\tData 0.051 (0.163)\tLoss 1.1946 (0.7657)\tAcc 0.438 (0.688)\n",
      "Epoch: [50][3/18]\tTime 0.074 (0.148)\tData 0.053 (0.126)\tLoss 0.7006 (0.7440)\tAcc 0.750 (0.708)\n",
      "Epoch: [50][4/18]\tTime 0.081 (0.131)\tData 0.053 (0.108)\tLoss 0.7202 (0.7380)\tAcc 0.625 (0.688)\n",
      "Epoch: [50][5/18]\tTime 0.070 (0.119)\tData 0.048 (0.096)\tLoss 0.8061 (0.7516)\tAcc 0.750 (0.700)\n",
      "Epoch: [50][6/18]\tTime 0.074 (0.112)\tData 0.053 (0.089)\tLoss 0.2864 (0.6741)\tAcc 1.000 (0.750)\n",
      "Epoch: [50][7/18]\tTime 0.075 (0.106)\tData 0.054 (0.084)\tLoss 0.7805 (0.6893)\tAcc 0.625 (0.732)\n",
      "Epoch: [50][8/18]\tTime 0.074 (0.102)\tData 0.053 (0.080)\tLoss 0.9706 (0.7245)\tAcc 0.562 (0.711)\n",
      "Epoch: [50][9/18]\tTime 0.076 (0.099)\tData 0.055 (0.077)\tLoss 0.1978 (0.6660)\tAcc 1.000 (0.743)\n",
      "Epoch: [50][10/18]\tTime 0.080 (0.097)\tData 0.059 (0.075)\tLoss 1.1403 (0.7134)\tAcc 0.500 (0.719)\n",
      "Epoch: [50][11/18]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 1.4921 (0.7842)\tAcc 0.375 (0.688)\n",
      "Epoch: [50][12/18]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 1.0150 (0.8034)\tAcc 0.688 (0.688)\n",
      "Epoch: [50][13/18]\tTime 0.080 (0.093)\tData 0.059 (0.072)\tLoss 0.9955 (0.8182)\tAcc 0.688 (0.688)\n",
      "Epoch: [50][14/18]\tTime 0.080 (0.092)\tData 0.060 (0.071)\tLoss 0.7615 (0.8141)\tAcc 0.625 (0.683)\n",
      "Epoch: [50][15/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.9256 (0.8216)\tAcc 0.625 (0.679)\n",
      "Epoch: [50][16/18]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.8619 (0.8241)\tAcc 0.688 (0.680)\n",
      "Epoch: [50][17/18]\tTime 0.077 (0.090)\tData 0.057 (0.069)\tLoss 0.9568 (0.8319)\tAcc 0.625 (0.676)\n",
      "Epoch: [50][18/18]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.7575 (0.8298)\tAcc 0.750 (0.679)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/12]\tTime 0.346 (0.346)\tData 0.316 (0.316)\tLoss 0.6950 (0.6950)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][2/12]\tTime 0.076 (0.211)\tData 0.049 (0.183)\tLoss 0.7931 (0.7441)\tAcc 0.562 (0.625)\n",
      "Epoch: [51][3/12]\tTime 0.083 (0.168)\tData 0.053 (0.139)\tLoss 0.5983 (0.6955)\tAcc 0.750 (0.667)\n",
      "Epoch: [51][4/12]\tTime 0.073 (0.144)\tData 0.047 (0.116)\tLoss 0.6103 (0.6742)\tAcc 0.812 (0.703)\n",
      "Epoch: [51][5/12]\tTime 0.081 (0.132)\tData 0.054 (0.104)\tLoss 0.8121 (0.7018)\tAcc 0.625 (0.688)\n",
      "Epoch: [51][6/12]\tTime 0.079 (0.123)\tData 0.053 (0.095)\tLoss 0.7951 (0.7173)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][7/12]\tTime 0.078 (0.116)\tData 0.053 (0.089)\tLoss 0.7082 (0.7160)\tAcc 0.750 (0.696)\n",
      "Epoch: [51][8/12]\tTime 0.078 (0.112)\tData 0.054 (0.085)\tLoss 0.5707 (0.6978)\tAcc 0.875 (0.719)\n",
      "Epoch: [51][9/12]\tTime 0.078 (0.108)\tData 0.055 (0.082)\tLoss 0.5786 (0.6846)\tAcc 0.812 (0.729)\n",
      "Epoch: [51][10/12]\tTime 0.078 (0.105)\tData 0.055 (0.079)\tLoss 0.7767 (0.6938)\tAcc 0.750 (0.731)\n",
      "Epoch: [51][11/12]\tTime 0.080 (0.103)\tData 0.056 (0.077)\tLoss 0.5491 (0.6807)\tAcc 0.750 (0.733)\n",
      "Epoch: [51][12/12]\tTime 0.079 (0.101)\tData 0.055 (0.075)\tLoss 0.8800 (0.6963)\tAcc 0.600 (0.723)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/18]\tTime 0.330 (0.330)\tData 0.298 (0.298)\tLoss 0.3426 (0.3426)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/18]\tTime 0.068 (0.199)\tData 0.045 (0.171)\tLoss 0.9568 (0.6497)\tAcc 0.438 (0.688)\n",
      "Epoch: [51][3/18]\tTime 0.075 (0.158)\tData 0.051 (0.131)\tLoss 0.7108 (0.6701)\tAcc 0.750 (0.708)\n",
      "Epoch: [51][4/18]\tTime 0.074 (0.137)\tData 0.051 (0.111)\tLoss 0.6811 (0.6728)\tAcc 0.625 (0.688)\n",
      "Epoch: [51][5/18]\tTime 0.073 (0.124)\tData 0.052 (0.100)\tLoss 0.8033 (0.6989)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][6/18]\tTime 0.077 (0.116)\tData 0.057 (0.092)\tLoss 0.4512 (0.6576)\tAcc 0.938 (0.729)\n",
      "Epoch: [51][7/18]\tTime 0.076 (0.110)\tData 0.055 (0.087)\tLoss 0.7491 (0.6707)\tAcc 0.625 (0.714)\n",
      "Epoch: [51][8/18]\tTime 0.075 (0.106)\tData 0.053 (0.083)\tLoss 1.1352 (0.7288)\tAcc 0.688 (0.711)\n",
      "Epoch: [51][9/18]\tTime 0.076 (0.103)\tData 0.055 (0.080)\tLoss 0.2003 (0.6700)\tAcc 1.000 (0.743)\n",
      "Epoch: [51][10/18]\tTime 0.074 (0.100)\tData 0.053 (0.077)\tLoss 1.3033 (0.7334)\tAcc 0.438 (0.713)\n",
      "Epoch: [51][11/18]\tTime 0.075 (0.098)\tData 0.054 (0.075)\tLoss 1.3685 (0.7911)\tAcc 0.375 (0.682)\n",
      "Epoch: [51][12/18]\tTime 0.073 (0.095)\tData 0.053 (0.073)\tLoss 0.9483 (0.8042)\tAcc 0.562 (0.672)\n",
      "Epoch: [51][13/18]\tTime 0.074 (0.094)\tData 0.055 (0.072)\tLoss 1.0583 (0.8238)\tAcc 0.688 (0.673)\n",
      "Epoch: [51][14/18]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.9029 (0.8294)\tAcc 0.562 (0.665)\n",
      "Epoch: [51][15/18]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 0.8565 (0.8312)\tAcc 0.625 (0.663)\n",
      "Epoch: [51][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.7620 (0.8269)\tAcc 0.688 (0.664)\n",
      "Epoch: [51][17/18]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8176 (0.8263)\tAcc 0.625 (0.662)\n",
      "Epoch: [51][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.7598 (0.8244)\tAcc 0.750 (0.664)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/12]\tTime 0.266 (0.266)\tData 0.236 (0.236)\tLoss 0.5016 (0.5016)\tAcc 0.812 (0.812)\n",
      "Epoch: [52][2/12]\tTime 0.077 (0.171)\tData 0.051 (0.143)\tLoss 0.9533 (0.7275)\tAcc 0.562 (0.688)\n",
      "Epoch: [52][3/12]\tTime 0.079 (0.141)\tData 0.052 (0.113)\tLoss 0.8402 (0.7650)\tAcc 0.625 (0.667)\n",
      "Epoch: [52][4/12]\tTime 0.081 (0.126)\tData 0.053 (0.098)\tLoss 0.8739 (0.7922)\tAcc 0.750 (0.688)\n",
      "Epoch: [52][5/12]\tTime 0.077 (0.116)\tData 0.052 (0.089)\tLoss 0.6820 (0.7702)\tAcc 0.625 (0.675)\n",
      "Epoch: [52][6/12]\tTime 0.084 (0.111)\tData 0.058 (0.084)\tLoss 0.5530 (0.7340)\tAcc 0.875 (0.708)\n",
      "Epoch: [52][7/12]\tTime 0.080 (0.106)\tData 0.053 (0.079)\tLoss 0.7235 (0.7325)\tAcc 0.688 (0.705)\n",
      "Epoch: [52][8/12]\tTime 0.077 (0.103)\tData 0.053 (0.076)\tLoss 0.8465 (0.7468)\tAcc 0.625 (0.695)\n",
      "Epoch: [52][9/12]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 0.8857 (0.7622)\tAcc 0.625 (0.688)\n",
      "Epoch: [52][10/12]\tTime 0.077 (0.098)\tData 0.054 (0.072)\tLoss 0.7180 (0.7578)\tAcc 0.625 (0.681)\n",
      "Epoch: [52][11/12]\tTime 0.080 (0.096)\tData 0.055 (0.070)\tLoss 0.6412 (0.7472)\tAcc 0.750 (0.688)\n",
      "Epoch: [52][12/12]\tTime 0.080 (0.095)\tData 0.056 (0.069)\tLoss 0.5906 (0.7349)\tAcc 0.800 (0.696)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/18]\tTime 0.309 (0.309)\tData 0.277 (0.277)\tLoss 0.4179 (0.4179)\tAcc 0.938 (0.938)\n",
      "Epoch: [52][2/18]\tTime 0.067 (0.188)\tData 0.043 (0.160)\tLoss 1.0014 (0.7097)\tAcc 0.438 (0.688)\n",
      "Epoch: [52][3/18]\tTime 0.075 (0.150)\tData 0.052 (0.124)\tLoss 0.7377 (0.7190)\tAcc 0.688 (0.688)\n",
      "Epoch: [52][4/18]\tTime 0.077 (0.132)\tData 0.051 (0.106)\tLoss 0.7989 (0.7390)\tAcc 0.625 (0.672)\n",
      "Epoch: [52][5/18]\tTime 0.084 (0.122)\tData 0.063 (0.097)\tLoss 0.7793 (0.7470)\tAcc 0.688 (0.675)\n",
      "Epoch: [52][6/18]\tTime 0.074 (0.114)\tData 0.053 (0.090)\tLoss 0.2682 (0.6672)\tAcc 1.000 (0.729)\n",
      "Epoch: [52][7/18]\tTime 0.077 (0.109)\tData 0.053 (0.085)\tLoss 0.7431 (0.6781)\tAcc 0.500 (0.696)\n",
      "Epoch: [52][8/18]\tTime 0.074 (0.104)\tData 0.051 (0.080)\tLoss 0.9620 (0.7136)\tAcc 0.625 (0.688)\n",
      "Epoch: [52][9/18]\tTime 0.073 (0.101)\tData 0.052 (0.077)\tLoss 0.1769 (0.6540)\tAcc 1.000 (0.722)\n",
      "Epoch: [52][10/18]\tTime 0.075 (0.098)\tData 0.053 (0.075)\tLoss 1.2322 (0.7118)\tAcc 0.438 (0.694)\n",
      "Epoch: [52][11/18]\tTime 0.076 (0.096)\tData 0.054 (0.073)\tLoss 1.4417 (0.7781)\tAcc 0.375 (0.665)\n",
      "Epoch: [52][12/18]\tTime 0.074 (0.095)\tData 0.053 (0.071)\tLoss 0.8781 (0.7865)\tAcc 0.562 (0.656)\n",
      "Epoch: [52][13/18]\tTime 0.077 (0.093)\tData 0.057 (0.070)\tLoss 1.0438 (0.8063)\tAcc 0.500 (0.644)\n",
      "Epoch: [52][14/18]\tTime 0.076 (0.092)\tData 0.056 (0.069)\tLoss 0.8306 (0.8080)\tAcc 0.625 (0.643)\n",
      "Epoch: [52][15/18]\tTime 0.078 (0.091)\tData 0.057 (0.068)\tLoss 0.9575 (0.8180)\tAcc 0.688 (0.646)\n",
      "Epoch: [52][16/18]\tTime 0.079 (0.090)\tData 0.059 (0.068)\tLoss 0.8206 (0.8181)\tAcc 0.688 (0.648)\n",
      "Epoch: [52][17/18]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 0.9014 (0.8230)\tAcc 0.625 (0.647)\n",
      "Epoch: [52][18/18]\tTime 0.081 (0.089)\tData 0.060 (0.067)\tLoss 0.5718 (0.8159)\tAcc 0.875 (0.654)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/12]\tTime 0.315 (0.315)\tData 0.282 (0.282)\tLoss 0.8238 (0.8238)\tAcc 0.625 (0.625)\n",
      "Epoch: [53][2/12]\tTime 0.078 (0.197)\tData 0.052 (0.167)\tLoss 0.5967 (0.7102)\tAcc 0.812 (0.719)\n",
      "Epoch: [53][3/12]\tTime 0.080 (0.158)\tData 0.054 (0.129)\tLoss 0.8789 (0.7665)\tAcc 0.562 (0.667)\n",
      "Epoch: [53][4/12]\tTime 0.084 (0.139)\tData 0.057 (0.111)\tLoss 0.5621 (0.7154)\tAcc 0.812 (0.703)\n",
      "Epoch: [53][5/12]\tTime 0.081 (0.128)\tData 0.055 (0.100)\tLoss 0.4995 (0.6722)\tAcc 0.750 (0.713)\n",
      "Epoch: [53][6/12]\tTime 0.081 (0.120)\tData 0.054 (0.092)\tLoss 0.7972 (0.6930)\tAcc 0.562 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53][7/12]\tTime 0.086 (0.115)\tData 0.058 (0.087)\tLoss 0.7596 (0.7025)\tAcc 0.688 (0.688)\n",
      "Epoch: [53][8/12]\tTime 0.080 (0.111)\tData 0.056 (0.083)\tLoss 0.8761 (0.7242)\tAcc 0.562 (0.672)\n",
      "Epoch: [53][9/12]\tTime 0.087 (0.108)\tData 0.062 (0.081)\tLoss 0.5157 (0.7010)\tAcc 0.875 (0.694)\n",
      "Epoch: [53][10/12]\tTime 0.086 (0.106)\tData 0.062 (0.079)\tLoss 0.9913 (0.7301)\tAcc 0.625 (0.688)\n",
      "Epoch: [53][11/12]\tTime 0.087 (0.104)\tData 0.063 (0.078)\tLoss 0.6000 (0.7182)\tAcc 0.812 (0.699)\n",
      "Epoch: [53][12/12]\tTime 0.083 (0.102)\tData 0.060 (0.076)\tLoss 0.6358 (0.7118)\tAcc 0.800 (0.707)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/18]\tTime 0.305 (0.305)\tData 0.271 (0.271)\tLoss 0.3896 (0.3896)\tAcc 0.875 (0.875)\n",
      "Epoch: [53][2/18]\tTime 0.061 (0.183)\tData 0.040 (0.155)\tLoss 1.0834 (0.7365)\tAcc 0.438 (0.656)\n",
      "Epoch: [53][3/18]\tTime 0.075 (0.147)\tData 0.054 (0.122)\tLoss 0.5503 (0.6744)\tAcc 0.875 (0.729)\n",
      "Epoch: [53][4/18]\tTime 0.076 (0.129)\tData 0.055 (0.105)\tLoss 0.6794 (0.6757)\tAcc 0.688 (0.719)\n",
      "Epoch: [53][5/18]\tTime 0.075 (0.118)\tData 0.054 (0.095)\tLoss 0.7809 (0.6967)\tAcc 0.750 (0.725)\n",
      "Epoch: [53][6/18]\tTime 0.074 (0.111)\tData 0.053 (0.088)\tLoss 0.2562 (0.6233)\tAcc 1.000 (0.771)\n",
      "Epoch: [53][7/18]\tTime 0.079 (0.106)\tData 0.055 (0.083)\tLoss 0.6062 (0.6209)\tAcc 0.688 (0.759)\n",
      "Epoch: [53][8/18]\tTime 0.075 (0.103)\tData 0.054 (0.079)\tLoss 1.0466 (0.6741)\tAcc 0.562 (0.734)\n",
      "Epoch: [53][9/18]\tTime 0.075 (0.099)\tData 0.054 (0.077)\tLoss 0.2015 (0.6216)\tAcc 1.000 (0.764)\n",
      "Epoch: [53][10/18]\tTime 0.081 (0.098)\tData 0.057 (0.075)\tLoss 1.0733 (0.6667)\tAcc 0.500 (0.738)\n",
      "Epoch: [53][11/18]\tTime 0.073 (0.095)\tData 0.053 (0.073)\tLoss 1.2846 (0.7229)\tAcc 0.375 (0.705)\n",
      "Epoch: [53][12/18]\tTime 0.075 (0.094)\tData 0.055 (0.071)\tLoss 1.0775 (0.7525)\tAcc 0.562 (0.693)\n",
      "Epoch: [53][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.0835 (0.7779)\tAcc 0.625 (0.688)\n",
      "Epoch: [53][14/18]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.9666 (0.7914)\tAcc 0.562 (0.679)\n",
      "Epoch: [53][15/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 0.8296 (0.7939)\tAcc 0.750 (0.683)\n",
      "Epoch: [53][16/18]\tTime 0.076 (0.089)\tData 0.057 (0.067)\tLoss 0.8986 (0.8005)\tAcc 0.750 (0.688)\n",
      "Epoch: [53][17/18]\tTime 0.076 (0.088)\tData 0.057 (0.067)\tLoss 0.9279 (0.8080)\tAcc 0.625 (0.684)\n",
      "Epoch: [53][18/18]\tTime 0.076 (0.088)\tData 0.058 (0.066)\tLoss 0.6984 (0.8048)\tAcc 0.875 (0.689)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/12]\tTime 0.336 (0.336)\tData 0.300 (0.300)\tLoss 0.4787 (0.4787)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/12]\tTime 0.076 (0.206)\tData 0.048 (0.174)\tLoss 1.2324 (0.8555)\tAcc 0.562 (0.750)\n",
      "Epoch: [54][3/12]\tTime 0.081 (0.164)\tData 0.054 (0.134)\tLoss 0.6613 (0.7908)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][4/12]\tTime 0.078 (0.143)\tData 0.051 (0.113)\tLoss 0.9149 (0.8218)\tAcc 0.625 (0.719)\n",
      "Epoch: [54][5/12]\tTime 0.079 (0.130)\tData 0.053 (0.101)\tLoss 0.4848 (0.7544)\tAcc 0.875 (0.750)\n",
      "Epoch: [54][6/12]\tTime 0.082 (0.122)\tData 0.055 (0.094)\tLoss 0.7338 (0.7510)\tAcc 0.625 (0.729)\n",
      "Epoch: [54][7/12]\tTime 0.075 (0.115)\tData 0.051 (0.087)\tLoss 0.8704 (0.7681)\tAcc 0.500 (0.696)\n",
      "Epoch: [54][8/12]\tTime 0.081 (0.111)\tData 0.056 (0.084)\tLoss 0.7025 (0.7599)\tAcc 0.750 (0.703)\n",
      "Epoch: [54][9/12]\tTime 0.081 (0.108)\tData 0.057 (0.081)\tLoss 0.6337 (0.7458)\tAcc 0.750 (0.708)\n",
      "Epoch: [54][10/12]\tTime 0.080 (0.105)\tData 0.057 (0.078)\tLoss 0.7005 (0.7413)\tAcc 0.750 (0.713)\n",
      "Epoch: [54][11/12]\tTime 0.082 (0.103)\tData 0.058 (0.076)\tLoss 0.6224 (0.7305)\tAcc 0.750 (0.716)\n",
      "Epoch: [54][12/12]\tTime 0.080 (0.101)\tData 0.057 (0.075)\tLoss 0.6912 (0.7274)\tAcc 0.800 (0.723)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/18]\tTime 0.316 (0.316)\tData 0.290 (0.290)\tLoss 0.3169 (0.3169)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/18]\tTime 0.070 (0.193)\tData 0.049 (0.169)\tLoss 1.0349 (0.6759)\tAcc 0.438 (0.688)\n",
      "Epoch: [54][3/18]\tTime 0.074 (0.153)\tData 0.053 (0.130)\tLoss 0.6226 (0.6581)\tAcc 0.875 (0.750)\n",
      "Epoch: [54][4/18]\tTime 0.074 (0.133)\tData 0.053 (0.111)\tLoss 0.6983 (0.6682)\tAcc 0.625 (0.719)\n",
      "Epoch: [54][5/18]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.8511 (0.7047)\tAcc 0.750 (0.725)\n",
      "Epoch: [54][6/18]\tTime 0.074 (0.114)\tData 0.053 (0.092)\tLoss 0.2844 (0.6347)\tAcc 1.000 (0.771)\n",
      "Epoch: [54][7/18]\tTime 0.076 (0.108)\tData 0.053 (0.086)\tLoss 0.7449 (0.6504)\tAcc 0.562 (0.741)\n",
      "Epoch: [54][8/18]\tTime 0.087 (0.106)\tData 0.055 (0.082)\tLoss 0.9464 (0.6874)\tAcc 0.688 (0.734)\n",
      "Epoch: [54][9/18]\tTime 0.073 (0.102)\tData 0.052 (0.079)\tLoss 0.1715 (0.6301)\tAcc 1.000 (0.764)\n",
      "Epoch: [54][10/18]\tTime 0.075 (0.099)\tData 0.053 (0.076)\tLoss 1.2159 (0.6887)\tAcc 0.500 (0.738)\n",
      "Epoch: [54][11/18]\tTime 0.075 (0.097)\tData 0.052 (0.074)\tLoss 1.4512 (0.7580)\tAcc 0.375 (0.705)\n",
      "Epoch: [54][12/18]\tTime 0.072 (0.095)\tData 0.053 (0.072)\tLoss 0.9168 (0.7712)\tAcc 0.625 (0.698)\n",
      "Epoch: [54][13/18]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 1.0753 (0.7946)\tAcc 0.438 (0.678)\n",
      "Epoch: [54][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9515 (0.8058)\tAcc 0.625 (0.674)\n",
      "Epoch: [54][15/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.7943 (0.8051)\tAcc 0.688 (0.675)\n",
      "Epoch: [54][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.7422 (0.8011)\tAcc 0.750 (0.680)\n",
      "Epoch: [54][17/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.7391 (0.7975)\tAcc 0.625 (0.676)\n",
      "Epoch: [54][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.066)\tLoss 0.7065 (0.7949)\tAcc 0.625 (0.675)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/12]\tTime 0.394 (0.394)\tData 0.358 (0.358)\tLoss 0.6104 (0.6104)\tAcc 0.750 (0.750)\n",
      "Epoch: [55][2/12]\tTime 0.076 (0.235)\tData 0.046 (0.202)\tLoss 0.7304 (0.6704)\tAcc 0.688 (0.719)\n",
      "Epoch: [55][3/12]\tTime 0.075 (0.182)\tData 0.049 (0.151)\tLoss 0.6344 (0.6584)\tAcc 0.812 (0.750)\n",
      "Epoch: [55][4/12]\tTime 0.079 (0.156)\tData 0.052 (0.126)\tLoss 0.7515 (0.6817)\tAcc 0.625 (0.719)\n",
      "Epoch: [55][5/12]\tTime 0.081 (0.141)\tData 0.054 (0.112)\tLoss 0.5318 (0.6517)\tAcc 0.875 (0.750)\n",
      "Epoch: [55][6/12]\tTime 0.083 (0.131)\tData 0.051 (0.102)\tLoss 0.7701 (0.6714)\tAcc 0.750 (0.750)\n",
      "Epoch: [55][7/12]\tTime 0.071 (0.123)\tData 0.047 (0.094)\tLoss 1.0101 (0.7198)\tAcc 0.438 (0.705)\n",
      "Epoch: [55][8/12]\tTime 0.079 (0.117)\tData 0.055 (0.089)\tLoss 1.1203 (0.7699)\tAcc 0.562 (0.688)\n",
      "Epoch: [55][9/12]\tTime 0.078 (0.113)\tData 0.054 (0.085)\tLoss 0.6538 (0.7570)\tAcc 0.875 (0.708)\n",
      "Epoch: [55][10/12]\tTime 0.078 (0.109)\tData 0.054 (0.082)\tLoss 0.8722 (0.7685)\tAcc 0.625 (0.700)\n",
      "Epoch: [55][11/12]\tTime 0.079 (0.107)\tData 0.055 (0.080)\tLoss 0.4419 (0.7388)\tAcc 0.875 (0.716)\n",
      "Epoch: [55][12/12]\tTime 0.078 (0.104)\tData 0.054 (0.077)\tLoss 0.6742 (0.7337)\tAcc 0.800 (0.723)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/18]\tTime 0.297 (0.297)\tData 0.269 (0.269)\tLoss 0.4024 (0.4024)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/18]\tTime 0.075 (0.186)\tData 0.054 (0.161)\tLoss 0.9532 (0.6778)\tAcc 0.438 (0.688)\n",
      "Epoch: [55][3/18]\tTime 0.074 (0.148)\tData 0.052 (0.125)\tLoss 0.7318 (0.6958)\tAcc 0.688 (0.688)\n",
      "Epoch: [55][4/18]\tTime 0.078 (0.131)\tData 0.053 (0.107)\tLoss 0.7112 (0.6996)\tAcc 0.625 (0.672)\n",
      "Epoch: [55][5/18]\tTime 0.071 (0.119)\tData 0.049 (0.095)\tLoss 0.8545 (0.7306)\tAcc 0.688 (0.675)\n",
      "Epoch: [55][6/18]\tTime 0.074 (0.111)\tData 0.053 (0.088)\tLoss 0.2960 (0.6582)\tAcc 1.000 (0.729)\n",
      "Epoch: [55][7/18]\tTime 0.077 (0.107)\tData 0.053 (0.083)\tLoss 0.7833 (0.6760)\tAcc 0.562 (0.705)\n",
      "Epoch: [55][8/18]\tTime 0.072 (0.102)\tData 0.051 (0.079)\tLoss 0.9594 (0.7115)\tAcc 0.562 (0.688)\n",
      "Epoch: [55][9/18]\tTime 0.076 (0.099)\tData 0.054 (0.076)\tLoss 0.2332 (0.6583)\tAcc 1.000 (0.722)\n",
      "Epoch: [55][10/18]\tTime 0.076 (0.097)\tData 0.053 (0.074)\tLoss 1.1933 (0.7118)\tAcc 0.438 (0.694)\n",
      "Epoch: [55][11/18]\tTime 0.072 (0.095)\tData 0.052 (0.072)\tLoss 1.4317 (0.7773)\tAcc 0.375 (0.665)\n",
      "Epoch: [55][12/18]\tTime 0.075 (0.093)\tData 0.054 (0.070)\tLoss 0.9834 (0.7944)\tAcc 0.562 (0.656)\n",
      "Epoch: [55][13/18]\tTime 0.072 (0.091)\tData 0.052 (0.069)\tLoss 0.9637 (0.8075)\tAcc 0.688 (0.659)\n",
      "Epoch: [55][14/18]\tTime 0.075 (0.090)\tData 0.055 (0.068)\tLoss 0.7350 (0.8023)\tAcc 0.625 (0.656)\n",
      "Epoch: [55][15/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 0.6448 (0.7918)\tAcc 0.750 (0.663)\n",
      "Epoch: [55][16/18]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.9092 (0.7991)\tAcc 0.688 (0.664)\n",
      "Epoch: [55][17/18]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 0.7896 (0.7986)\tAcc 0.625 (0.662)\n",
      "Epoch: [55][18/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.8358 (0.7996)\tAcc 0.750 (0.664)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/12]\tTime 0.362 (0.362)\tData 0.332 (0.332)\tLoss 1.0810 (1.0810)\tAcc 0.562 (0.562)\n",
      "Epoch: [56][2/12]\tTime 0.077 (0.220)\tData 0.050 (0.191)\tLoss 0.5657 (0.8234)\tAcc 0.750 (0.656)\n",
      "Epoch: [56][3/12]\tTime 0.078 (0.172)\tData 0.052 (0.145)\tLoss 0.8818 (0.8428)\tAcc 0.625 (0.646)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][4/12]\tTime 0.079 (0.149)\tData 0.053 (0.122)\tLoss 0.4882 (0.7542)\tAcc 0.875 (0.703)\n",
      "Epoch: [56][5/12]\tTime 0.082 (0.135)\tData 0.054 (0.108)\tLoss 0.6882 (0.7410)\tAcc 0.625 (0.688)\n",
      "Epoch: [56][6/12]\tTime 0.076 (0.126)\tData 0.051 (0.099)\tLoss 0.6256 (0.7217)\tAcc 0.750 (0.698)\n",
      "Epoch: [56][7/12]\tTime 0.078 (0.119)\tData 0.054 (0.092)\tLoss 0.6867 (0.7167)\tAcc 0.688 (0.696)\n",
      "Epoch: [56][8/12]\tTime 0.079 (0.114)\tData 0.055 (0.088)\tLoss 0.5838 (0.7001)\tAcc 0.750 (0.703)\n",
      "Epoch: [56][9/12]\tTime 0.078 (0.110)\tData 0.054 (0.084)\tLoss 0.6100 (0.6901)\tAcc 0.750 (0.708)\n",
      "Epoch: [56][10/12]\tTime 0.079 (0.107)\tData 0.056 (0.081)\tLoss 0.5463 (0.6757)\tAcc 0.875 (0.725)\n",
      "Epoch: [56][11/12]\tTime 0.078 (0.104)\tData 0.055 (0.079)\tLoss 0.6158 (0.6703)\tAcc 0.750 (0.727)\n",
      "Epoch: [56][12/12]\tTime 0.081 (0.102)\tData 0.057 (0.077)\tLoss 1.0623 (0.7011)\tAcc 0.533 (0.712)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/18]\tTime 0.261 (0.261)\tData 0.237 (0.237)\tLoss 0.2962 (0.2962)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/18]\tTime 0.077 (0.169)\tData 0.051 (0.144)\tLoss 0.9053 (0.6007)\tAcc 0.438 (0.688)\n",
      "Epoch: [56][3/18]\tTime 0.069 (0.136)\tData 0.048 (0.112)\tLoss 0.4732 (0.5582)\tAcc 0.938 (0.771)\n",
      "Epoch: [56][4/18]\tTime 0.076 (0.121)\tData 0.053 (0.097)\tLoss 0.7465 (0.6053)\tAcc 0.625 (0.734)\n",
      "Epoch: [56][5/18]\tTime 0.073 (0.111)\tData 0.052 (0.088)\tLoss 0.8984 (0.6639)\tAcc 0.625 (0.713)\n",
      "Epoch: [56][6/18]\tTime 0.075 (0.105)\tData 0.054 (0.082)\tLoss 0.3154 (0.6058)\tAcc 1.000 (0.760)\n",
      "Epoch: [56][7/18]\tTime 0.076 (0.101)\tData 0.053 (0.078)\tLoss 0.6421 (0.6110)\tAcc 0.750 (0.759)\n",
      "Epoch: [56][8/18]\tTime 0.074 (0.098)\tData 0.052 (0.075)\tLoss 1.0476 (0.6656)\tAcc 0.562 (0.734)\n",
      "Epoch: [56][9/18]\tTime 0.075 (0.095)\tData 0.054 (0.073)\tLoss 0.1317 (0.6063)\tAcc 1.000 (0.764)\n",
      "Epoch: [56][10/18]\tTime 0.074 (0.093)\tData 0.053 (0.071)\tLoss 1.1646 (0.6621)\tAcc 0.562 (0.744)\n",
      "Epoch: [56][11/18]\tTime 0.076 (0.091)\tData 0.054 (0.069)\tLoss 1.3137 (0.7213)\tAcc 0.375 (0.710)\n",
      "Epoch: [56][12/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.0980 (0.7527)\tAcc 0.625 (0.703)\n",
      "Epoch: [56][13/18]\tTime 0.079 (0.089)\tData 0.060 (0.067)\tLoss 0.9756 (0.7699)\tAcc 0.625 (0.697)\n",
      "Epoch: [56][14/18]\tTime 0.076 (0.088)\tData 0.055 (0.066)\tLoss 0.8348 (0.7745)\tAcc 0.562 (0.688)\n",
      "Epoch: [56][15/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.8278 (0.7781)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][16/18]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.9221 (0.7871)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][17/18]\tTime 0.081 (0.086)\tData 0.061 (0.065)\tLoss 0.8539 (0.7910)\tAcc 0.625 (0.684)\n",
      "Epoch: [56][18/18]\tTime 0.075 (0.085)\tData 0.056 (0.064)\tLoss 0.8567 (0.7929)\tAcc 0.625 (0.682)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/12]\tTime 0.358 (0.358)\tData 0.327 (0.327)\tLoss 0.6191 (0.6191)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][2/12]\tTime 0.078 (0.218)\tData 0.049 (0.188)\tLoss 1.0185 (0.8188)\tAcc 0.625 (0.688)\n",
      "Epoch: [57][3/12]\tTime 0.092 (0.176)\tData 0.054 (0.143)\tLoss 0.5462 (0.7279)\tAcc 0.812 (0.729)\n",
      "Epoch: [57][4/12]\tTime 0.073 (0.150)\tData 0.046 (0.119)\tLoss 0.7798 (0.7409)\tAcc 0.688 (0.719)\n",
      "Epoch: [57][5/12]\tTime 0.084 (0.137)\tData 0.054 (0.106)\tLoss 0.6605 (0.7248)\tAcc 0.750 (0.725)\n",
      "Epoch: [57][6/12]\tTime 0.075 (0.127)\tData 0.049 (0.097)\tLoss 0.9038 (0.7546)\tAcc 0.562 (0.698)\n",
      "Epoch: [57][7/12]\tTime 0.077 (0.120)\tData 0.053 (0.090)\tLoss 0.4460 (0.7106)\tAcc 0.938 (0.732)\n",
      "Epoch: [57][8/12]\tTime 0.079 (0.114)\tData 0.055 (0.086)\tLoss 0.9684 (0.7428)\tAcc 0.625 (0.719)\n",
      "Epoch: [57][9/12]\tTime 0.079 (0.110)\tData 0.054 (0.082)\tLoss 0.8694 (0.7569)\tAcc 0.688 (0.715)\n",
      "Epoch: [57][10/12]\tTime 0.079 (0.107)\tData 0.055 (0.080)\tLoss 0.5804 (0.7392)\tAcc 0.875 (0.731)\n",
      "Epoch: [57][11/12]\tTime 0.078 (0.105)\tData 0.054 (0.077)\tLoss 0.5891 (0.7256)\tAcc 0.750 (0.733)\n",
      "Epoch: [57][12/12]\tTime 0.079 (0.103)\tData 0.055 (0.075)\tLoss 0.6622 (0.7206)\tAcc 0.733 (0.733)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/18]\tTime 0.311 (0.311)\tData 0.283 (0.283)\tLoss 0.4632 (0.4632)\tAcc 0.875 (0.875)\n",
      "Epoch: [57][2/18]\tTime 0.071 (0.191)\tData 0.047 (0.165)\tLoss 1.0102 (0.7367)\tAcc 0.438 (0.656)\n",
      "Epoch: [57][3/18]\tTime 0.073 (0.152)\tData 0.052 (0.127)\tLoss 0.6477 (0.7070)\tAcc 0.812 (0.708)\n",
      "Epoch: [57][4/18]\tTime 0.081 (0.134)\tData 0.055 (0.109)\tLoss 0.6852 (0.7016)\tAcc 0.688 (0.703)\n",
      "Epoch: [57][5/18]\tTime 0.071 (0.121)\tData 0.049 (0.097)\tLoss 0.8103 (0.7233)\tAcc 0.625 (0.688)\n",
      "Epoch: [57][6/18]\tTime 0.074 (0.113)\tData 0.053 (0.090)\tLoss 0.4595 (0.6793)\tAcc 0.875 (0.719)\n",
      "Epoch: [57][7/18]\tTime 0.075 (0.108)\tData 0.053 (0.085)\tLoss 0.7530 (0.6899)\tAcc 0.625 (0.705)\n",
      "Epoch: [57][8/18]\tTime 0.074 (0.104)\tData 0.051 (0.080)\tLoss 1.0818 (0.7389)\tAcc 0.562 (0.688)\n",
      "Epoch: [57][9/18]\tTime 0.075 (0.101)\tData 0.054 (0.077)\tLoss 0.2088 (0.6800)\tAcc 1.000 (0.722)\n",
      "Epoch: [57][10/18]\tTime 0.076 (0.098)\tData 0.054 (0.075)\tLoss 1.2999 (0.7420)\tAcc 0.500 (0.700)\n",
      "Epoch: [57][11/18]\tTime 0.073 (0.096)\tData 0.052 (0.073)\tLoss 1.2734 (0.7903)\tAcc 0.375 (0.670)\n",
      "Epoch: [57][12/18]\tTime 0.073 (0.094)\tData 0.054 (0.071)\tLoss 0.9191 (0.8010)\tAcc 0.625 (0.667)\n",
      "Epoch: [57][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.0184 (0.8177)\tAcc 0.688 (0.668)\n",
      "Epoch: [57][14/18]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 0.6900 (0.8086)\tAcc 0.625 (0.665)\n",
      "Epoch: [57][15/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 0.8373 (0.8105)\tAcc 0.688 (0.667)\n",
      "Epoch: [57][16/18]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.9582 (0.8197)\tAcc 0.625 (0.664)\n",
      "Epoch: [57][17/18]\tTime 0.076 (0.088)\tData 0.057 (0.067)\tLoss 0.8347 (0.8206)\tAcc 0.625 (0.662)\n",
      "Epoch: [57][18/18]\tTime 0.075 (0.088)\tData 0.056 (0.066)\tLoss 0.6409 (0.8155)\tAcc 0.875 (0.668)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/12]\tTime 0.284 (0.284)\tData 0.251 (0.251)\tLoss 0.9467 (0.9467)\tAcc 0.688 (0.688)\n",
      "Epoch: [58][2/12]\tTime 0.074 (0.179)\tData 0.048 (0.149)\tLoss 0.5185 (0.7326)\tAcc 0.875 (0.781)\n",
      "Epoch: [58][3/12]\tTime 0.090 (0.149)\tData 0.056 (0.118)\tLoss 0.5599 (0.6751)\tAcc 0.875 (0.812)\n",
      "Epoch: [58][4/12]\tTime 0.079 (0.132)\tData 0.050 (0.101)\tLoss 0.7999 (0.7063)\tAcc 0.562 (0.750)\n",
      "Epoch: [58][5/12]\tTime 0.079 (0.121)\tData 0.051 (0.091)\tLoss 0.6531 (0.6956)\tAcc 0.812 (0.762)\n",
      "Epoch: [58][6/12]\tTime 0.083 (0.115)\tData 0.052 (0.085)\tLoss 0.8337 (0.7187)\tAcc 0.562 (0.729)\n",
      "Epoch: [58][7/12]\tTime 0.080 (0.110)\tData 0.053 (0.080)\tLoss 0.7603 (0.7246)\tAcc 0.625 (0.714)\n",
      "Epoch: [58][8/12]\tTime 0.079 (0.106)\tData 0.054 (0.077)\tLoss 0.7619 (0.7293)\tAcc 0.750 (0.719)\n",
      "Epoch: [58][9/12]\tTime 0.079 (0.103)\tData 0.055 (0.075)\tLoss 0.4915 (0.7028)\tAcc 0.875 (0.736)\n",
      "Epoch: [58][10/12]\tTime 0.078 (0.101)\tData 0.054 (0.072)\tLoss 0.7191 (0.7045)\tAcc 0.688 (0.731)\n",
      "Epoch: [58][11/12]\tTime 0.079 (0.099)\tData 0.055 (0.071)\tLoss 0.7771 (0.7111)\tAcc 0.688 (0.727)\n",
      "Epoch: [58][12/12]\tTime 0.079 (0.097)\tData 0.056 (0.070)\tLoss 1.0781 (0.7399)\tAcc 0.533 (0.712)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/18]\tTime 0.298 (0.298)\tData 0.268 (0.268)\tLoss 0.3634 (0.3634)\tAcc 0.875 (0.875)\n",
      "Epoch: [58][2/18]\tTime 0.071 (0.185)\tData 0.048 (0.158)\tLoss 1.0266 (0.6950)\tAcc 0.438 (0.656)\n",
      "Epoch: [58][3/18]\tTime 0.074 (0.148)\tData 0.053 (0.123)\tLoss 0.7164 (0.7022)\tAcc 0.750 (0.688)\n",
      "Epoch: [58][4/18]\tTime 0.080 (0.131)\tData 0.053 (0.106)\tLoss 0.6705 (0.6942)\tAcc 0.625 (0.672)\n",
      "Epoch: [58][5/18]\tTime 0.074 (0.119)\tData 0.050 (0.095)\tLoss 0.8575 (0.7269)\tAcc 0.688 (0.675)\n",
      "Epoch: [58][6/18]\tTime 0.075 (0.112)\tData 0.054 (0.088)\tLoss 0.2639 (0.6497)\tAcc 1.000 (0.729)\n",
      "Epoch: [58][7/18]\tTime 0.076 (0.107)\tData 0.053 (0.083)\tLoss 0.8239 (0.6746)\tAcc 0.438 (0.688)\n",
      "Epoch: [58][8/18]\tTime 0.076 (0.103)\tData 0.051 (0.079)\tLoss 1.0908 (0.7266)\tAcc 0.500 (0.664)\n",
      "Epoch: [58][9/18]\tTime 0.075 (0.100)\tData 0.054 (0.076)\tLoss 0.1825 (0.6662)\tAcc 1.000 (0.701)\n",
      "Epoch: [58][10/18]\tTime 0.074 (0.097)\tData 0.053 (0.074)\tLoss 1.1218 (0.7117)\tAcc 0.500 (0.681)\n",
      "Epoch: [58][11/18]\tTime 0.076 (0.095)\tData 0.053 (0.072)\tLoss 1.4701 (0.7807)\tAcc 0.438 (0.659)\n",
      "Epoch: [58][12/18]\tTime 0.074 (0.094)\tData 0.053 (0.070)\tLoss 1.0175 (0.8004)\tAcc 0.688 (0.661)\n",
      "Epoch: [58][13/18]\tTime 0.075 (0.092)\tData 0.053 (0.069)\tLoss 1.2078 (0.8318)\tAcc 0.562 (0.654)\n",
      "Epoch: [58][14/18]\tTime 0.072 (0.091)\tData 0.052 (0.068)\tLoss 0.8542 (0.8334)\tAcc 0.625 (0.652)\n",
      "Epoch: [58][15/18]\tTime 0.073 (0.090)\tData 0.054 (0.067)\tLoss 0.8207 (0.8325)\tAcc 0.688 (0.654)\n",
      "Epoch: [58][16/18]\tTime 0.074 (0.089)\tData 0.054 (0.066)\tLoss 0.8294 (0.8323)\tAcc 0.688 (0.656)\n",
      "Epoch: [58][17/18]\tTime 0.075 (0.088)\tData 0.055 (0.065)\tLoss 0.7705 (0.8287)\tAcc 0.625 (0.654)\n",
      "Epoch: [58][18/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.8693 (0.8298)\tAcc 0.750 (0.657)\n",
      "train at epoch 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [59][1/12]\tTime 0.291 (0.291)\tData 0.259 (0.259)\tLoss 0.5602 (0.5602)\tAcc 0.812 (0.812)\n",
      "Epoch: [59][2/12]\tTime 0.075 (0.183)\tData 0.048 (0.154)\tLoss 1.1856 (0.8729)\tAcc 0.562 (0.688)\n",
      "Epoch: [59][3/12]\tTime 0.078 (0.148)\tData 0.052 (0.120)\tLoss 0.7942 (0.8467)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][4/12]\tTime 0.078 (0.130)\tData 0.052 (0.103)\tLoss 0.6974 (0.8093)\tAcc 0.750 (0.703)\n",
      "Epoch: [59][5/12]\tTime 0.080 (0.120)\tData 0.054 (0.093)\tLoss 0.6816 (0.7838)\tAcc 0.812 (0.725)\n",
      "Epoch: [59][6/12]\tTime 0.080 (0.114)\tData 0.053 (0.086)\tLoss 0.9294 (0.8081)\tAcc 0.562 (0.698)\n",
      "Epoch: [59][7/12]\tTime 0.076 (0.108)\tData 0.052 (0.081)\tLoss 0.4247 (0.7533)\tAcc 0.938 (0.732)\n",
      "Epoch: [59][8/12]\tTime 0.079 (0.105)\tData 0.055 (0.078)\tLoss 0.7421 (0.7519)\tAcc 0.688 (0.727)\n",
      "Epoch: [59][9/12]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.4182 (0.7148)\tAcc 0.875 (0.743)\n",
      "Epoch: [59][10/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.7191 (0.7153)\tAcc 0.812 (0.750)\n",
      "Epoch: [59][11/12]\tTime 0.080 (0.097)\tData 0.056 (0.072)\tLoss 0.7081 (0.7146)\tAcc 0.750 (0.750)\n",
      "Epoch: [59][12/12]\tTime 0.082 (0.096)\tData 0.059 (0.071)\tLoss 1.0777 (0.7431)\tAcc 0.533 (0.733)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/18]\tTime 0.248 (0.248)\tData 0.224 (0.224)\tLoss 0.3419 (0.3419)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/18]\tTime 0.074 (0.161)\tData 0.051 (0.137)\tLoss 0.9728 (0.6574)\tAcc 0.438 (0.688)\n",
      "Epoch: [59][3/18]\tTime 0.072 (0.131)\tData 0.051 (0.108)\tLoss 0.6587 (0.6578)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][4/18]\tTime 0.075 (0.117)\tData 0.052 (0.094)\tLoss 0.7162 (0.6724)\tAcc 0.625 (0.672)\n",
      "Epoch: [59][5/18]\tTime 0.073 (0.108)\tData 0.052 (0.086)\tLoss 0.7228 (0.6825)\tAcc 0.750 (0.688)\n",
      "Epoch: [59][6/18]\tTime 0.075 (0.103)\tData 0.053 (0.080)\tLoss 0.4532 (0.6443)\tAcc 0.875 (0.719)\n",
      "Epoch: [59][7/18]\tTime 0.074 (0.099)\tData 0.053 (0.077)\tLoss 0.7240 (0.6557)\tAcc 0.625 (0.705)\n",
      "Epoch: [59][8/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 1.0797 (0.7087)\tAcc 0.688 (0.703)\n",
      "Epoch: [59][9/18]\tTime 0.079 (0.094)\tData 0.058 (0.072)\tLoss 0.2040 (0.6526)\tAcc 1.000 (0.736)\n",
      "Epoch: [59][10/18]\tTime 0.076 (0.092)\tData 0.054 (0.070)\tLoss 1.3088 (0.7182)\tAcc 0.375 (0.700)\n",
      "Epoch: [59][11/18]\tTime 0.075 (0.090)\tData 0.053 (0.069)\tLoss 1.2273 (0.7645)\tAcc 0.375 (0.670)\n",
      "Epoch: [59][12/18]\tTime 0.076 (0.089)\tData 0.054 (0.067)\tLoss 0.9384 (0.7790)\tAcc 0.625 (0.667)\n",
      "Epoch: [59][13/18]\tTime 0.071 (0.088)\tData 0.052 (0.066)\tLoss 1.1094 (0.8044)\tAcc 0.562 (0.659)\n",
      "Epoch: [59][14/18]\tTime 0.074 (0.087)\tData 0.055 (0.065)\tLoss 0.9115 (0.8121)\tAcc 0.688 (0.661)\n",
      "Epoch: [59][15/18]\tTime 0.074 (0.086)\tData 0.055 (0.065)\tLoss 0.7626 (0.8088)\tAcc 0.688 (0.663)\n",
      "Epoch: [59][16/18]\tTime 0.074 (0.085)\tData 0.055 (0.064)\tLoss 0.7896 (0.8076)\tAcc 0.688 (0.664)\n",
      "Epoch: [59][17/18]\tTime 0.074 (0.085)\tData 0.055 (0.063)\tLoss 0.8400 (0.8095)\tAcc 0.625 (0.662)\n",
      "Epoch: [59][18/18]\tTime 0.074 (0.084)\tData 0.055 (0.063)\tLoss 0.6752 (0.8056)\tAcc 0.875 (0.668)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/12]\tTime 0.332 (0.332)\tData 0.302 (0.302)\tLoss 0.7407 (0.7407)\tAcc 0.812 (0.812)\n",
      "Epoch: [60][2/12]\tTime 0.076 (0.204)\tData 0.049 (0.175)\tLoss 0.5806 (0.6607)\tAcc 0.875 (0.844)\n",
      "Epoch: [60][3/12]\tTime 0.083 (0.164)\tData 0.054 (0.135)\tLoss 0.5437 (0.6217)\tAcc 0.875 (0.854)\n",
      "Epoch: [60][4/12]\tTime 0.079 (0.143)\tData 0.054 (0.115)\tLoss 0.6052 (0.6176)\tAcc 0.750 (0.828)\n",
      "Epoch: [60][5/12]\tTime 0.081 (0.130)\tData 0.055 (0.103)\tLoss 0.9731 (0.6887)\tAcc 0.562 (0.775)\n",
      "Epoch: [60][6/12]\tTime 0.078 (0.122)\tData 0.053 (0.094)\tLoss 0.5443 (0.6646)\tAcc 0.812 (0.781)\n",
      "Epoch: [60][7/12]\tTime 0.085 (0.116)\tData 0.060 (0.089)\tLoss 0.5556 (0.6490)\tAcc 0.875 (0.795)\n",
      "Epoch: [60][8/12]\tTime 0.078 (0.112)\tData 0.055 (0.085)\tLoss 1.1573 (0.7126)\tAcc 0.438 (0.750)\n",
      "Epoch: [60][9/12]\tTime 0.080 (0.108)\tData 0.057 (0.082)\tLoss 0.8094 (0.7233)\tAcc 0.625 (0.736)\n",
      "Epoch: [60][10/12]\tTime 0.079 (0.105)\tData 0.056 (0.079)\tLoss 0.7658 (0.7276)\tAcc 0.625 (0.725)\n",
      "Epoch: [60][11/12]\tTime 0.080 (0.103)\tData 0.056 (0.077)\tLoss 0.9312 (0.7461)\tAcc 0.562 (0.710)\n",
      "Epoch: [60][12/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.7744 (0.7483)\tAcc 0.667 (0.707)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/18]\tTime 0.266 (0.266)\tData 0.241 (0.241)\tLoss 0.3537 (0.3537)\tAcc 0.875 (0.875)\n",
      "Epoch: [60][2/18]\tTime 0.074 (0.170)\tData 0.050 (0.146)\tLoss 1.0369 (0.6953)\tAcc 0.438 (0.656)\n",
      "Epoch: [60][3/18]\tTime 0.072 (0.137)\tData 0.051 (0.114)\tLoss 0.5430 (0.6446)\tAcc 0.875 (0.729)\n",
      "Epoch: [60][4/18]\tTime 0.075 (0.122)\tData 0.053 (0.099)\tLoss 0.7234 (0.6643)\tAcc 0.625 (0.703)\n",
      "Epoch: [60][5/18]\tTime 0.075 (0.112)\tData 0.053 (0.090)\tLoss 0.9415 (0.7197)\tAcc 0.750 (0.713)\n",
      "Epoch: [60][6/18]\tTime 0.077 (0.107)\tData 0.056 (0.084)\tLoss 0.3924 (0.6651)\tAcc 0.938 (0.750)\n",
      "Epoch: [60][7/18]\tTime 0.082 (0.103)\tData 0.055 (0.080)\tLoss 0.8021 (0.6847)\tAcc 0.562 (0.723)\n",
      "Epoch: [60][8/18]\tTime 0.072 (0.099)\tData 0.050 (0.076)\tLoss 0.9836 (0.7221)\tAcc 0.688 (0.719)\n",
      "Epoch: [60][9/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 0.1691 (0.6606)\tAcc 1.000 (0.750)\n",
      "Epoch: [60][10/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 1.1981 (0.7144)\tAcc 0.438 (0.719)\n",
      "Epoch: [60][11/18]\tTime 0.075 (0.093)\tData 0.054 (0.070)\tLoss 1.2716 (0.7650)\tAcc 0.375 (0.688)\n",
      "Epoch: [60][12/18]\tTime 0.078 (0.091)\tData 0.056 (0.069)\tLoss 0.9466 (0.7802)\tAcc 0.562 (0.677)\n",
      "Epoch: [60][13/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 1.1271 (0.8069)\tAcc 0.438 (0.659)\n",
      "Epoch: [60][14/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 0.8309 (0.8086)\tAcc 0.562 (0.652)\n",
      "Epoch: [60][15/18]\tTime 0.080 (0.088)\tData 0.059 (0.066)\tLoss 0.8480 (0.8112)\tAcc 0.688 (0.654)\n",
      "Epoch: [60][16/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.6901 (0.8036)\tAcc 0.750 (0.660)\n",
      "Epoch: [60][17/18]\tTime 0.075 (0.087)\tData 0.056 (0.065)\tLoss 0.7776 (0.8021)\tAcc 0.625 (0.658)\n",
      "Epoch: [60][18/18]\tTime 0.076 (0.086)\tData 0.057 (0.065)\tLoss 0.7903 (0.8018)\tAcc 0.875 (0.664)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/12]\tTime 0.295 (0.295)\tData 0.265 (0.265)\tLoss 0.5135 (0.5135)\tAcc 0.875 (0.875)\n",
      "Epoch: [61][2/12]\tTime 0.075 (0.185)\tData 0.049 (0.157)\tLoss 0.9698 (0.7416)\tAcc 0.625 (0.750)\n",
      "Epoch: [61][3/12]\tTime 0.078 (0.150)\tData 0.052 (0.122)\tLoss 0.6044 (0.6959)\tAcc 0.812 (0.771)\n",
      "Epoch: [61][4/12]\tTime 0.081 (0.132)\tData 0.053 (0.105)\tLoss 0.7997 (0.7218)\tAcc 0.688 (0.750)\n",
      "Epoch: [61][5/12]\tTime 0.079 (0.122)\tData 0.053 (0.094)\tLoss 0.7384 (0.7252)\tAcc 0.688 (0.738)\n",
      "Epoch: [61][6/12]\tTime 0.082 (0.115)\tData 0.056 (0.088)\tLoss 0.6958 (0.7203)\tAcc 0.625 (0.719)\n",
      "Epoch: [61][7/12]\tTime 0.077 (0.110)\tData 0.052 (0.083)\tLoss 0.9745 (0.7566)\tAcc 0.625 (0.705)\n",
      "Epoch: [61][8/12]\tTime 0.078 (0.106)\tData 0.054 (0.079)\tLoss 0.6495 (0.7432)\tAcc 0.688 (0.703)\n",
      "Epoch: [61][9/12]\tTime 0.078 (0.103)\tData 0.054 (0.076)\tLoss 0.8859 (0.7590)\tAcc 0.562 (0.688)\n",
      "Epoch: [61][10/12]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 0.8913 (0.7723)\tAcc 0.688 (0.688)\n",
      "Epoch: [61][11/12]\tTime 0.079 (0.098)\tData 0.056 (0.072)\tLoss 0.4605 (0.7439)\tAcc 0.938 (0.710)\n",
      "Epoch: [61][12/12]\tTime 0.079 (0.097)\tData 0.056 (0.071)\tLoss 0.7077 (0.7411)\tAcc 0.733 (0.712)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/18]\tTime 0.315 (0.315)\tData 0.289 (0.289)\tLoss 0.3335 (0.3335)\tAcc 0.875 (0.875)\n",
      "Epoch: [61][2/18]\tTime 0.070 (0.193)\tData 0.049 (0.169)\tLoss 1.0085 (0.6710)\tAcc 0.438 (0.656)\n",
      "Epoch: [61][3/18]\tTime 0.077 (0.154)\tData 0.054 (0.130)\tLoss 0.6147 (0.6522)\tAcc 0.938 (0.750)\n",
      "Epoch: [61][4/18]\tTime 0.072 (0.133)\tData 0.051 (0.110)\tLoss 0.6356 (0.6481)\tAcc 0.625 (0.719)\n",
      "Epoch: [61][5/18]\tTime 0.075 (0.122)\tData 0.054 (0.099)\tLoss 0.8644 (0.6913)\tAcc 0.688 (0.713)\n",
      "Epoch: [61][6/18]\tTime 0.074 (0.114)\tData 0.053 (0.091)\tLoss 0.2901 (0.6245)\tAcc 1.000 (0.760)\n",
      "Epoch: [61][7/18]\tTime 0.074 (0.108)\tData 0.053 (0.086)\tLoss 0.6212 (0.6240)\tAcc 0.750 (0.759)\n",
      "Epoch: [61][8/18]\tTime 0.075 (0.104)\tData 0.054 (0.082)\tLoss 1.0499 (0.6772)\tAcc 0.562 (0.734)\n",
      "Epoch: [61][9/18]\tTime 0.077 (0.101)\tData 0.057 (0.079)\tLoss 0.1755 (0.6215)\tAcc 1.000 (0.764)\n",
      "Epoch: [61][10/18]\tTime 0.077 (0.099)\tData 0.055 (0.077)\tLoss 1.1797 (0.6773)\tAcc 0.500 (0.738)\n",
      "Epoch: [61][11/18]\tTime 0.073 (0.096)\tData 0.052 (0.074)\tLoss 1.2046 (0.7252)\tAcc 0.375 (0.705)\n",
      "Epoch: [61][12/18]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.9771 (0.7462)\tAcc 0.625 (0.698)\n",
      "Epoch: [61][13/18]\tTime 0.076 (0.093)\tData 0.056 (0.072)\tLoss 1.1125 (0.7744)\tAcc 0.688 (0.697)\n",
      "Epoch: [61][14/18]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.8745 (0.7816)\tAcc 0.625 (0.692)\n",
      "Epoch: [61][15/18]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.7941 (0.7824)\tAcc 0.750 (0.696)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61][16/18]\tTime 0.076 (0.090)\tData 0.057 (0.069)\tLoss 0.9218 (0.7911)\tAcc 0.562 (0.688)\n",
      "Epoch: [61][17/18]\tTime 0.077 (0.089)\tData 0.057 (0.068)\tLoss 0.8796 (0.7963)\tAcc 0.625 (0.684)\n",
      "Epoch: [61][18/18]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.8489 (0.7978)\tAcc 0.750 (0.686)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/12]\tTime 0.343 (0.343)\tData 0.313 (0.313)\tLoss 0.8588 (0.8588)\tAcc 0.625 (0.625)\n",
      "Epoch: [62][2/12]\tTime 0.077 (0.210)\tData 0.051 (0.182)\tLoss 0.4431 (0.6509)\tAcc 0.875 (0.750)\n",
      "Epoch: [62][3/12]\tTime 0.079 (0.166)\tData 0.052 (0.139)\tLoss 1.0224 (0.7748)\tAcc 0.438 (0.646)\n",
      "Epoch: [62][4/12]\tTime 0.078 (0.144)\tData 0.052 (0.117)\tLoss 0.6076 (0.7330)\tAcc 0.750 (0.672)\n",
      "Epoch: [62][5/12]\tTime 0.081 (0.132)\tData 0.054 (0.105)\tLoss 0.6872 (0.7238)\tAcc 0.750 (0.688)\n",
      "Epoch: [62][6/12]\tTime 0.081 (0.123)\tData 0.055 (0.096)\tLoss 0.5827 (0.7003)\tAcc 0.812 (0.708)\n",
      "Epoch: [62][7/12]\tTime 0.079 (0.117)\tData 0.053 (0.090)\tLoss 0.7355 (0.7053)\tAcc 0.750 (0.714)\n",
      "Epoch: [62][8/12]\tTime 0.077 (0.112)\tData 0.053 (0.086)\tLoss 0.8667 (0.7255)\tAcc 0.688 (0.711)\n",
      "Epoch: [62][9/12]\tTime 0.079 (0.108)\tData 0.056 (0.082)\tLoss 0.6197 (0.7138)\tAcc 0.750 (0.715)\n",
      "Epoch: [62][10/12]\tTime 0.078 (0.105)\tData 0.054 (0.079)\tLoss 1.0033 (0.7427)\tAcc 0.625 (0.706)\n",
      "Epoch: [62][11/12]\tTime 0.080 (0.103)\tData 0.056 (0.077)\tLoss 0.5476 (0.7250)\tAcc 0.812 (0.716)\n",
      "Epoch: [62][12/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.7867 (0.7298)\tAcc 0.733 (0.717)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/18]\tTime 0.269 (0.269)\tData 0.245 (0.245)\tLoss 0.4781 (0.4781)\tAcc 0.875 (0.875)\n",
      "Epoch: [62][2/18]\tTime 0.072 (0.170)\tData 0.051 (0.148)\tLoss 0.9872 (0.7326)\tAcc 0.438 (0.656)\n",
      "Epoch: [62][3/18]\tTime 0.077 (0.139)\tData 0.053 (0.116)\tLoss 0.7248 (0.7300)\tAcc 0.688 (0.667)\n",
      "Epoch: [62][4/18]\tTime 0.074 (0.123)\tData 0.050 (0.099)\tLoss 0.7545 (0.7361)\tAcc 0.562 (0.641)\n",
      "Epoch: [62][5/18]\tTime 0.073 (0.113)\tData 0.050 (0.090)\tLoss 0.7941 (0.7477)\tAcc 0.688 (0.650)\n",
      "Epoch: [62][6/18]\tTime 0.076 (0.107)\tData 0.053 (0.083)\tLoss 0.3522 (0.6818)\tAcc 0.938 (0.698)\n",
      "Epoch: [62][7/18]\tTime 0.079 (0.103)\tData 0.052 (0.079)\tLoss 0.6338 (0.6750)\tAcc 0.625 (0.688)\n",
      "Epoch: [62][8/18]\tTime 0.076 (0.100)\tData 0.048 (0.075)\tLoss 0.9403 (0.7081)\tAcc 0.625 (0.680)\n",
      "Epoch: [62][9/18]\tTime 0.069 (0.096)\tData 0.047 (0.072)\tLoss 0.2400 (0.6561)\tAcc 1.000 (0.715)\n",
      "Epoch: [62][10/18]\tTime 0.075 (0.094)\tData 0.052 (0.070)\tLoss 1.0799 (0.6985)\tAcc 0.625 (0.706)\n",
      "Epoch: [62][11/18]\tTime 0.073 (0.092)\tData 0.052 (0.068)\tLoss 1.2312 (0.7469)\tAcc 0.375 (0.676)\n",
      "Epoch: [62][12/18]\tTime 0.074 (0.091)\tData 0.054 (0.067)\tLoss 0.8737 (0.7575)\tAcc 0.625 (0.672)\n",
      "Epoch: [62][13/18]\tTime 0.074 (0.089)\tData 0.054 (0.066)\tLoss 1.0846 (0.7826)\tAcc 0.625 (0.668)\n",
      "Epoch: [62][14/18]\tTime 0.073 (0.088)\tData 0.054 (0.065)\tLoss 0.8086 (0.7845)\tAcc 0.625 (0.665)\n",
      "Epoch: [62][15/18]\tTime 0.074 (0.087)\tData 0.056 (0.065)\tLoss 0.7343 (0.7812)\tAcc 0.750 (0.671)\n",
      "Epoch: [62][16/18]\tTime 0.074 (0.086)\tData 0.054 (0.064)\tLoss 0.8262 (0.7840)\tAcc 0.688 (0.672)\n",
      "Epoch: [62][17/18]\tTime 0.074 (0.086)\tData 0.054 (0.063)\tLoss 0.7919 (0.7844)\tAcc 0.625 (0.669)\n",
      "Epoch: [62][18/18]\tTime 0.075 (0.085)\tData 0.056 (0.063)\tLoss 0.9187 (0.7883)\tAcc 0.625 (0.668)\n",
      "train at epoch 63\n",
      "Epoch: [63][1/12]\tTime 0.254 (0.254)\tData 0.222 (0.222)\tLoss 0.9604 (0.9604)\tAcc 0.562 (0.562)\n",
      "Epoch: [63][2/12]\tTime 0.077 (0.165)\tData 0.048 (0.135)\tLoss 0.3795 (0.6700)\tAcc 0.938 (0.750)\n",
      "Epoch: [63][3/12]\tTime 0.078 (0.136)\tData 0.051 (0.107)\tLoss 0.4688 (0.6029)\tAcc 0.938 (0.812)\n",
      "Epoch: [63][4/12]\tTime 0.094 (0.126)\tData 0.059 (0.095)\tLoss 0.7708 (0.6449)\tAcc 0.750 (0.797)\n",
      "Epoch: [63][5/12]\tTime 0.073 (0.115)\tData 0.046 (0.085)\tLoss 1.0633 (0.7286)\tAcc 0.500 (0.738)\n",
      "Epoch: [63][6/12]\tTime 0.079 (0.109)\tData 0.052 (0.079)\tLoss 0.7763 (0.7365)\tAcc 0.688 (0.729)\n",
      "Epoch: [63][7/12]\tTime 0.080 (0.105)\tData 0.052 (0.076)\tLoss 0.7534 (0.7389)\tAcc 0.625 (0.714)\n",
      "Epoch: [63][8/12]\tTime 0.076 (0.101)\tData 0.052 (0.073)\tLoss 0.6966 (0.7336)\tAcc 0.688 (0.711)\n",
      "Epoch: [63][9/12]\tTime 0.078 (0.099)\tData 0.054 (0.071)\tLoss 0.6429 (0.7236)\tAcc 0.750 (0.715)\n",
      "Epoch: [63][10/12]\tTime 0.078 (0.097)\tData 0.054 (0.069)\tLoss 1.3790 (0.7891)\tAcc 0.438 (0.688)\n",
      "Epoch: [63][11/12]\tTime 0.079 (0.095)\tData 0.055 (0.068)\tLoss 0.5325 (0.7658)\tAcc 0.812 (0.699)\n",
      "Epoch: [63][12/12]\tTime 0.078 (0.094)\tData 0.054 (0.066)\tLoss 0.5673 (0.7502)\tAcc 0.867 (0.712)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/18]\tTime 0.310 (0.310)\tData 0.285 (0.285)\tLoss 0.3089 (0.3089)\tAcc 0.938 (0.938)\n",
      "Epoch: [63][2/18]\tTime 0.077 (0.193)\tData 0.054 (0.169)\tLoss 1.0304 (0.6697)\tAcc 0.438 (0.688)\n",
      "Epoch: [63][3/18]\tTime 0.081 (0.156)\tData 0.055 (0.131)\tLoss 0.6873 (0.6756)\tAcc 0.812 (0.729)\n",
      "Epoch: [63][4/18]\tTime 0.078 (0.136)\tData 0.054 (0.112)\tLoss 0.7064 (0.6833)\tAcc 0.625 (0.703)\n",
      "Epoch: [63][5/18]\tTime 0.077 (0.125)\tData 0.056 (0.101)\tLoss 0.8968 (0.7260)\tAcc 0.688 (0.700)\n",
      "Epoch: [63][6/18]\tTime 0.077 (0.117)\tData 0.056 (0.093)\tLoss 0.3170 (0.6578)\tAcc 1.000 (0.750)\n",
      "Epoch: [63][7/18]\tTime 0.075 (0.111)\tData 0.053 (0.087)\tLoss 0.7219 (0.6670)\tAcc 0.688 (0.741)\n",
      "Epoch: [63][8/18]\tTime 0.074 (0.106)\tData 0.052 (0.083)\tLoss 0.9202 (0.6986)\tAcc 0.625 (0.727)\n",
      "Epoch: [63][9/18]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 0.2396 (0.6476)\tAcc 1.000 (0.757)\n",
      "Epoch: [63][10/18]\tTime 0.074 (0.100)\tData 0.052 (0.077)\tLoss 1.4337 (0.7262)\tAcc 0.438 (0.725)\n",
      "Epoch: [63][11/18]\tTime 0.074 (0.098)\tData 0.054 (0.075)\tLoss 1.2189 (0.7710)\tAcc 0.375 (0.693)\n",
      "Epoch: [63][12/18]\tTime 0.074 (0.096)\tData 0.054 (0.073)\tLoss 0.8742 (0.7796)\tAcc 0.625 (0.688)\n",
      "Epoch: [63][13/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 1.1295 (0.8065)\tAcc 0.438 (0.668)\n",
      "Epoch: [63][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9008 (0.8133)\tAcc 0.562 (0.661)\n",
      "Epoch: [63][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.8250 (0.8140)\tAcc 0.750 (0.667)\n",
      "Epoch: [63][16/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.8935 (0.8190)\tAcc 0.688 (0.668)\n",
      "Epoch: [63][17/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.8798 (0.8226)\tAcc 0.625 (0.665)\n",
      "Epoch: [63][18/18]\tTime 0.075 (0.088)\tData 0.056 (0.067)\tLoss 0.9995 (0.8276)\tAcc 0.500 (0.661)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/12]\tTime 0.353 (0.353)\tData 0.320 (0.320)\tLoss 0.7226 (0.7226)\tAcc 0.688 (0.688)\n",
      "Epoch: [64][2/12]\tTime 0.074 (0.214)\tData 0.047 (0.184)\tLoss 0.3986 (0.5606)\tAcc 0.938 (0.812)\n",
      "Epoch: [64][3/12]\tTime 0.078 (0.168)\tData 0.052 (0.140)\tLoss 0.4807 (0.5340)\tAcc 0.812 (0.812)\n",
      "Epoch: [64][4/12]\tTime 0.079 (0.146)\tData 0.053 (0.118)\tLoss 0.8296 (0.6079)\tAcc 0.625 (0.766)\n",
      "Epoch: [64][5/12]\tTime 0.079 (0.133)\tData 0.054 (0.105)\tLoss 0.6143 (0.6092)\tAcc 0.750 (0.762)\n",
      "Epoch: [64][6/12]\tTime 0.079 (0.124)\tData 0.053 (0.096)\tLoss 0.7642 (0.6350)\tAcc 0.625 (0.740)\n",
      "Epoch: [64][7/12]\tTime 0.077 (0.117)\tData 0.052 (0.090)\tLoss 0.8891 (0.6713)\tAcc 0.688 (0.732)\n",
      "Epoch: [64][8/12]\tTime 0.081 (0.113)\tData 0.054 (0.086)\tLoss 0.5918 (0.6614)\tAcc 0.750 (0.734)\n",
      "Epoch: [64][9/12]\tTime 0.076 (0.108)\tData 0.052 (0.082)\tLoss 1.1608 (0.7169)\tAcc 0.375 (0.694)\n",
      "Epoch: [64][10/12]\tTime 0.078 (0.105)\tData 0.054 (0.079)\tLoss 0.7306 (0.7182)\tAcc 0.688 (0.694)\n",
      "Epoch: [64][11/12]\tTime 0.079 (0.103)\tData 0.055 (0.077)\tLoss 0.7337 (0.7196)\tAcc 0.688 (0.693)\n",
      "Epoch: [64][12/12]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 0.5691 (0.7078)\tAcc 0.800 (0.702)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/18]\tTime 0.348 (0.348)\tData 0.324 (0.324)\tLoss 0.4125 (0.4125)\tAcc 0.875 (0.875)\n",
      "Epoch: [64][2/18]\tTime 0.073 (0.210)\tData 0.051 (0.187)\tLoss 1.0369 (0.7247)\tAcc 0.438 (0.656)\n",
      "Epoch: [64][3/18]\tTime 0.073 (0.165)\tData 0.052 (0.142)\tLoss 0.6331 (0.6942)\tAcc 0.875 (0.729)\n",
      "Epoch: [64][4/18]\tTime 0.075 (0.142)\tData 0.054 (0.120)\tLoss 0.6742 (0.6892)\tAcc 0.625 (0.703)\n",
      "Epoch: [64][5/18]\tTime 0.074 (0.129)\tData 0.053 (0.107)\tLoss 0.9899 (0.7493)\tAcc 0.562 (0.675)\n",
      "Epoch: [64][6/18]\tTime 0.077 (0.120)\tData 0.054 (0.098)\tLoss 0.2781 (0.6708)\tAcc 1.000 (0.729)\n",
      "Epoch: [64][7/18]\tTime 0.079 (0.114)\tData 0.056 (0.092)\tLoss 0.7365 (0.6802)\tAcc 0.625 (0.714)\n",
      "Epoch: [64][8/18]\tTime 0.078 (0.110)\tData 0.055 (0.087)\tLoss 0.8546 (0.7020)\tAcc 0.625 (0.703)\n",
      "Epoch: [64][9/18]\tTime 0.077 (0.106)\tData 0.055 (0.084)\tLoss 0.1946 (0.6456)\tAcc 1.000 (0.736)\n",
      "Epoch: [64][10/18]\tTime 0.082 (0.104)\tData 0.057 (0.081)\tLoss 1.2693 (0.7080)\tAcc 0.438 (0.706)\n",
      "Epoch: [64][11/18]\tTime 0.073 (0.101)\tData 0.051 (0.078)\tLoss 1.3782 (0.7689)\tAcc 0.375 (0.676)\n",
      "Epoch: [64][12/18]\tTime 0.076 (0.099)\tData 0.056 (0.077)\tLoss 1.0469 (0.7921)\tAcc 0.562 (0.667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [64][13/18]\tTime 0.079 (0.097)\tData 0.058 (0.075)\tLoss 1.2088 (0.8241)\tAcc 0.500 (0.654)\n",
      "Epoch: [64][14/18]\tTime 0.076 (0.096)\tData 0.056 (0.074)\tLoss 0.7871 (0.8215)\tAcc 0.688 (0.656)\n",
      "Epoch: [64][15/18]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.7955 (0.8198)\tAcc 0.688 (0.658)\n",
      "Epoch: [64][16/18]\tTime 0.075 (0.093)\tData 0.056 (0.072)\tLoss 0.8181 (0.8197)\tAcc 0.812 (0.668)\n",
      "Epoch: [64][17/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.9420 (0.8268)\tAcc 0.562 (0.662)\n",
      "Epoch: [64][18/18]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.7587 (0.8249)\tAcc 1.000 (0.671)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/12]\tTime 0.343 (0.343)\tData 0.313 (0.313)\tLoss 0.5104 (0.5104)\tAcc 0.812 (0.812)\n",
      "Epoch: [65][2/12]\tTime 0.076 (0.209)\tData 0.050 (0.182)\tLoss 0.7418 (0.6261)\tAcc 0.688 (0.750)\n",
      "Epoch: [65][3/12]\tTime 0.079 (0.166)\tData 0.053 (0.139)\tLoss 0.7684 (0.6736)\tAcc 0.688 (0.729)\n",
      "Epoch: [65][4/12]\tTime 0.079 (0.144)\tData 0.053 (0.117)\tLoss 0.9720 (0.7482)\tAcc 0.500 (0.672)\n",
      "Epoch: [65][5/12]\tTime 0.081 (0.132)\tData 0.054 (0.105)\tLoss 0.8124 (0.7610)\tAcc 0.750 (0.688)\n",
      "Epoch: [65][6/12]\tTime 0.080 (0.123)\tData 0.054 (0.096)\tLoss 0.8233 (0.7714)\tAcc 0.625 (0.677)\n",
      "Epoch: [65][7/12]\tTime 0.076 (0.116)\tData 0.052 (0.090)\tLoss 0.6126 (0.7487)\tAcc 0.812 (0.696)\n",
      "Epoch: [65][8/12]\tTime 0.079 (0.112)\tData 0.056 (0.086)\tLoss 0.5537 (0.7243)\tAcc 0.812 (0.711)\n",
      "Epoch: [65][9/12]\tTime 0.078 (0.108)\tData 0.054 (0.082)\tLoss 0.8057 (0.7334)\tAcc 0.688 (0.708)\n",
      "Epoch: [65][10/12]\tTime 0.079 (0.105)\tData 0.054 (0.079)\tLoss 0.7412 (0.7342)\tAcc 0.625 (0.700)\n",
      "Epoch: [65][11/12]\tTime 0.079 (0.103)\tData 0.054 (0.077)\tLoss 0.8890 (0.7482)\tAcc 0.625 (0.693)\n",
      "Epoch: [65][12/12]\tTime 0.077 (0.100)\tData 0.054 (0.075)\tLoss 0.4625 (0.7258)\tAcc 0.933 (0.712)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/18]\tTime 0.320 (0.320)\tData 0.294 (0.294)\tLoss 0.3093 (0.3093)\tAcc 0.938 (0.938)\n",
      "Epoch: [65][2/18]\tTime 0.070 (0.195)\tData 0.049 (0.172)\tLoss 1.0132 (0.6613)\tAcc 0.438 (0.688)\n",
      "Epoch: [65][3/18]\tTime 0.074 (0.155)\tData 0.053 (0.132)\tLoss 0.5779 (0.6335)\tAcc 0.875 (0.750)\n",
      "Epoch: [65][4/18]\tTime 0.074 (0.135)\tData 0.053 (0.112)\tLoss 0.5979 (0.6246)\tAcc 0.688 (0.734)\n",
      "Epoch: [65][5/18]\tTime 0.075 (0.123)\tData 0.054 (0.101)\tLoss 0.8321 (0.6661)\tAcc 0.688 (0.725)\n",
      "Epoch: [65][6/18]\tTime 0.075 (0.115)\tData 0.053 (0.093)\tLoss 0.2930 (0.6039)\tAcc 1.000 (0.771)\n",
      "Epoch: [65][7/18]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.6322 (0.6079)\tAcc 0.750 (0.768)\n",
      "Epoch: [65][8/18]\tTime 0.075 (0.104)\tData 0.054 (0.083)\tLoss 0.9200 (0.6469)\tAcc 0.688 (0.758)\n",
      "Epoch: [65][9/18]\tTime 0.074 (0.101)\tData 0.053 (0.080)\tLoss 0.2151 (0.5990)\tAcc 1.000 (0.785)\n",
      "Epoch: [65][10/18]\tTime 0.074 (0.098)\tData 0.053 (0.077)\tLoss 1.2459 (0.6636)\tAcc 0.500 (0.756)\n",
      "Epoch: [65][11/18]\tTime 0.076 (0.096)\tData 0.055 (0.075)\tLoss 1.2514 (0.7171)\tAcc 0.375 (0.722)\n",
      "Epoch: [65][12/18]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.9200 (0.7340)\tAcc 0.625 (0.714)\n",
      "Epoch: [65][13/18]\tTime 0.074 (0.093)\tData 0.053 (0.072)\tLoss 1.0296 (0.7567)\tAcc 0.625 (0.707)\n",
      "Epoch: [65][14/18]\tTime 0.072 (0.091)\tData 0.053 (0.070)\tLoss 0.8865 (0.7660)\tAcc 0.625 (0.701)\n",
      "Epoch: [65][15/18]\tTime 0.075 (0.090)\tData 0.056 (0.069)\tLoss 0.9769 (0.7801)\tAcc 0.688 (0.700)\n",
      "Epoch: [65][16/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.7626 (0.7790)\tAcc 0.750 (0.703)\n",
      "Epoch: [65][17/18]\tTime 0.076 (0.088)\tData 0.056 (0.068)\tLoss 0.8540 (0.7834)\tAcc 0.625 (0.699)\n",
      "Epoch: [65][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.5462 (0.7766)\tAcc 1.000 (0.707)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/12]\tTime 0.380 (0.380)\tData 0.350 (0.350)\tLoss 0.7161 (0.7161)\tAcc 0.812 (0.812)\n",
      "Epoch: [66][2/12]\tTime 0.076 (0.228)\tData 0.050 (0.200)\tLoss 0.5149 (0.6155)\tAcc 0.875 (0.844)\n",
      "Epoch: [66][3/12]\tTime 0.078 (0.178)\tData 0.053 (0.151)\tLoss 0.6335 (0.6215)\tAcc 0.812 (0.833)\n",
      "Epoch: [66][4/12]\tTime 0.082 (0.154)\tData 0.053 (0.127)\tLoss 1.1907 (0.7638)\tAcc 0.500 (0.750)\n",
      "Epoch: [66][5/12]\tTime 0.078 (0.139)\tData 0.052 (0.112)\tLoss 0.9687 (0.8048)\tAcc 0.625 (0.725)\n",
      "Epoch: [66][6/12]\tTime 0.079 (0.129)\tData 0.053 (0.102)\tLoss 0.7767 (0.8001)\tAcc 0.625 (0.708)\n",
      "Epoch: [66][7/12]\tTime 0.079 (0.122)\tData 0.053 (0.095)\tLoss 0.5143 (0.7593)\tAcc 0.875 (0.732)\n",
      "Epoch: [66][8/12]\tTime 0.078 (0.116)\tData 0.053 (0.090)\tLoss 0.5574 (0.7341)\tAcc 0.875 (0.750)\n",
      "Epoch: [66][9/12]\tTime 0.085 (0.113)\tData 0.060 (0.086)\tLoss 0.6423 (0.7239)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][10/12]\tTime 0.080 (0.109)\tData 0.055 (0.083)\tLoss 0.4800 (0.6995)\tAcc 0.812 (0.756)\n",
      "Epoch: [66][11/12]\tTime 0.078 (0.106)\tData 0.053 (0.081)\tLoss 0.6415 (0.6942)\tAcc 0.750 (0.756)\n",
      "Epoch: [66][12/12]\tTime 0.079 (0.104)\tData 0.054 (0.078)\tLoss 0.6875 (0.6937)\tAcc 0.733 (0.754)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/18]\tTime 0.327 (0.327)\tData 0.302 (0.302)\tLoss 0.4063 (0.4063)\tAcc 0.875 (0.875)\n",
      "Epoch: [66][2/18]\tTime 0.071 (0.199)\tData 0.050 (0.176)\tLoss 0.9125 (0.6594)\tAcc 0.438 (0.656)\n",
      "Epoch: [66][3/18]\tTime 0.074 (0.157)\tData 0.053 (0.135)\tLoss 0.6539 (0.6576)\tAcc 0.875 (0.729)\n",
      "Epoch: [66][4/18]\tTime 0.075 (0.137)\tData 0.053 (0.115)\tLoss 0.6516 (0.6561)\tAcc 0.625 (0.703)\n",
      "Epoch: [66][5/18]\tTime 0.077 (0.125)\tData 0.056 (0.103)\tLoss 0.8628 (0.6974)\tAcc 0.625 (0.688)\n",
      "Epoch: [66][6/18]\tTime 0.075 (0.116)\tData 0.054 (0.095)\tLoss 0.4591 (0.6577)\tAcc 0.875 (0.719)\n",
      "Epoch: [66][7/18]\tTime 0.075 (0.111)\tData 0.053 (0.089)\tLoss 0.7823 (0.6755)\tAcc 0.688 (0.714)\n",
      "Epoch: [66][8/18]\tTime 0.077 (0.106)\tData 0.053 (0.084)\tLoss 0.9605 (0.7111)\tAcc 0.562 (0.695)\n",
      "Epoch: [66][9/18]\tTime 0.073 (0.103)\tData 0.051 (0.080)\tLoss 0.2677 (0.6619)\tAcc 1.000 (0.729)\n",
      "Epoch: [66][10/18]\tTime 0.074 (0.100)\tData 0.053 (0.078)\tLoss 1.2350 (0.7192)\tAcc 0.500 (0.706)\n",
      "Epoch: [66][11/18]\tTime 0.074 (0.097)\tData 0.053 (0.076)\tLoss 1.2076 (0.7636)\tAcc 0.375 (0.676)\n",
      "Epoch: [66][12/18]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.9639 (0.7803)\tAcc 0.625 (0.672)\n",
      "Epoch: [66][13/18]\tTime 0.074 (0.094)\tData 0.055 (0.072)\tLoss 1.0031 (0.7974)\tAcc 0.750 (0.678)\n",
      "Epoch: [66][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.7921 (0.7970)\tAcc 0.625 (0.674)\n",
      "Epoch: [66][15/18]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.8286 (0.7991)\tAcc 0.750 (0.679)\n",
      "Epoch: [66][16/18]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.8768 (0.8040)\tAcc 0.688 (0.680)\n",
      "Epoch: [66][17/18]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.9106 (0.8103)\tAcc 0.625 (0.676)\n",
      "Epoch: [66][18/18]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.6689 (0.8062)\tAcc 0.875 (0.682)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/12]\tTime 0.346 (0.346)\tData 0.316 (0.316)\tLoss 0.6349 (0.6349)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][2/12]\tTime 0.077 (0.211)\tData 0.051 (0.184)\tLoss 0.6855 (0.6602)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][3/12]\tTime 0.081 (0.168)\tData 0.054 (0.141)\tLoss 0.5476 (0.6227)\tAcc 0.812 (0.771)\n",
      "Epoch: [67][4/12]\tTime 0.083 (0.147)\tData 0.052 (0.118)\tLoss 0.8650 (0.6833)\tAcc 0.688 (0.750)\n",
      "Epoch: [67][5/12]\tTime 0.074 (0.132)\tData 0.048 (0.104)\tLoss 0.9693 (0.7405)\tAcc 0.500 (0.700)\n",
      "Epoch: [67][6/12]\tTime 0.080 (0.123)\tData 0.054 (0.096)\tLoss 1.2129 (0.8192)\tAcc 0.438 (0.656)\n",
      "Epoch: [67][7/12]\tTime 0.081 (0.117)\tData 0.056 (0.090)\tLoss 0.4779 (0.7704)\tAcc 0.875 (0.688)\n",
      "Epoch: [67][8/12]\tTime 0.080 (0.113)\tData 0.055 (0.086)\tLoss 0.5603 (0.7442)\tAcc 0.875 (0.711)\n",
      "Epoch: [67][9/12]\tTime 0.078 (0.109)\tData 0.054 (0.082)\tLoss 0.6791 (0.7369)\tAcc 0.750 (0.715)\n",
      "Epoch: [67][10/12]\tTime 0.079 (0.106)\tData 0.055 (0.080)\tLoss 0.5314 (0.7164)\tAcc 0.875 (0.731)\n",
      "Epoch: [67][11/12]\tTime 0.079 (0.103)\tData 0.056 (0.078)\tLoss 0.9051 (0.7335)\tAcc 0.562 (0.716)\n",
      "Epoch: [67][12/12]\tTime 0.080 (0.101)\tData 0.056 (0.076)\tLoss 0.7229 (0.7327)\tAcc 0.733 (0.717)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/18]\tTime 0.322 (0.322)\tData 0.298 (0.298)\tLoss 0.3144 (0.3144)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/18]\tTime 0.072 (0.197)\tData 0.050 (0.174)\tLoss 1.0008 (0.6576)\tAcc 0.438 (0.688)\n",
      "Epoch: [67][3/18]\tTime 0.076 (0.157)\tData 0.053 (0.134)\tLoss 0.5118 (0.6090)\tAcc 0.938 (0.771)\n",
      "Epoch: [67][4/18]\tTime 0.074 (0.136)\tData 0.051 (0.113)\tLoss 0.6469 (0.6185)\tAcc 0.625 (0.734)\n",
      "Epoch: [67][5/18]\tTime 0.076 (0.124)\tData 0.054 (0.101)\tLoss 0.8785 (0.6705)\tAcc 0.750 (0.738)\n",
      "Epoch: [67][6/18]\tTime 0.078 (0.116)\tData 0.057 (0.094)\tLoss 0.3610 (0.6189)\tAcc 1.000 (0.781)\n",
      "Epoch: [67][7/18]\tTime 0.076 (0.111)\tData 0.055 (0.088)\tLoss 0.5827 (0.6137)\tAcc 0.750 (0.777)\n",
      "Epoch: [67][8/18]\tTime 0.073 (0.106)\tData 0.052 (0.084)\tLoss 1.1332 (0.6787)\tAcc 0.625 (0.758)\n",
      "Epoch: [67][9/18]\tTime 0.076 (0.103)\tData 0.055 (0.080)\tLoss 0.2331 (0.6292)\tAcc 1.000 (0.785)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [67][10/18]\tTime 0.077 (0.100)\tData 0.053 (0.078)\tLoss 1.1925 (0.6855)\tAcc 0.500 (0.756)\n",
      "Epoch: [67][11/18]\tTime 0.071 (0.097)\tData 0.050 (0.075)\tLoss 1.2379 (0.7357)\tAcc 0.375 (0.722)\n",
      "Epoch: [67][12/18]\tTime 0.075 (0.096)\tData 0.055 (0.073)\tLoss 0.9559 (0.7541)\tAcc 0.562 (0.708)\n",
      "Epoch: [67][13/18]\tTime 0.075 (0.094)\tData 0.054 (0.072)\tLoss 1.0600 (0.7776)\tAcc 0.562 (0.697)\n",
      "Epoch: [67][14/18]\tTime 0.073 (0.092)\tData 0.053 (0.071)\tLoss 0.8233 (0.7809)\tAcc 0.562 (0.688)\n",
      "Epoch: [67][15/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.7301 (0.7775)\tAcc 0.625 (0.683)\n",
      "Epoch: [67][16/18]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.7950 (0.7786)\tAcc 0.688 (0.684)\n",
      "Epoch: [67][17/18]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.8877 (0.7850)\tAcc 0.625 (0.680)\n",
      "Epoch: [67][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.6508 (0.7812)\tAcc 1.000 (0.689)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/12]\tTime 0.345 (0.345)\tData 0.314 (0.314)\tLoss 0.9692 (0.9692)\tAcc 0.625 (0.625)\n",
      "Epoch: [68][2/12]\tTime 0.077 (0.211)\tData 0.049 (0.182)\tLoss 0.9124 (0.9408)\tAcc 0.625 (0.625)\n",
      "Epoch: [68][3/12]\tTime 0.078 (0.167)\tData 0.052 (0.138)\tLoss 0.7687 (0.8834)\tAcc 0.625 (0.625)\n",
      "Epoch: [68][4/12]\tTime 0.078 (0.144)\tData 0.052 (0.117)\tLoss 0.5935 (0.8109)\tAcc 0.750 (0.656)\n",
      "Epoch: [68][5/12]\tTime 0.079 (0.131)\tData 0.053 (0.104)\tLoss 0.8085 (0.8105)\tAcc 0.812 (0.688)\n",
      "Epoch: [68][6/12]\tTime 0.078 (0.122)\tData 0.053 (0.096)\tLoss 0.8978 (0.8250)\tAcc 0.750 (0.698)\n",
      "Epoch: [68][7/12]\tTime 0.079 (0.116)\tData 0.055 (0.090)\tLoss 0.7435 (0.8134)\tAcc 0.688 (0.696)\n",
      "Epoch: [68][8/12]\tTime 0.087 (0.113)\tData 0.062 (0.086)\tLoss 0.6610 (0.7943)\tAcc 0.812 (0.711)\n",
      "Epoch: [68][9/12]\tTime 0.086 (0.110)\tData 0.062 (0.084)\tLoss 0.6908 (0.7828)\tAcc 0.750 (0.715)\n",
      "Epoch: [68][10/12]\tTime 0.086 (0.107)\tData 0.062 (0.081)\tLoss 0.7598 (0.7805)\tAcc 0.750 (0.719)\n",
      "Epoch: [68][11/12]\tTime 0.086 (0.105)\tData 0.062 (0.080)\tLoss 0.7502 (0.7778)\tAcc 0.750 (0.722)\n",
      "Epoch: [68][12/12]\tTime 0.086 (0.104)\tData 0.062 (0.078)\tLoss 0.9125 (0.7884)\tAcc 0.600 (0.712)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/18]\tTime 0.275 (0.275)\tData 0.246 (0.246)\tLoss 0.4013 (0.4013)\tAcc 0.875 (0.875)\n",
      "Epoch: [68][2/18]\tTime 0.093 (0.184)\tData 0.068 (0.157)\tLoss 1.0087 (0.7050)\tAcc 0.438 (0.656)\n",
      "Epoch: [68][3/18]\tTime 0.073 (0.147)\tData 0.050 (0.121)\tLoss 0.6205 (0.6768)\tAcc 0.812 (0.708)\n",
      "Epoch: [68][4/18]\tTime 0.073 (0.128)\tData 0.051 (0.104)\tLoss 0.5771 (0.6519)\tAcc 0.688 (0.703)\n",
      "Epoch: [68][5/18]\tTime 0.092 (0.121)\tData 0.057 (0.094)\tLoss 0.8042 (0.6823)\tAcc 0.688 (0.700)\n",
      "Epoch: [68][6/18]\tTime 0.067 (0.112)\tData 0.045 (0.086)\tLoss 0.3711 (0.6305)\tAcc 0.938 (0.740)\n",
      "Epoch: [68][7/18]\tTime 0.084 (0.108)\tData 0.062 (0.083)\tLoss 0.6392 (0.6317)\tAcc 0.750 (0.741)\n",
      "Epoch: [68][8/18]\tTime 0.081 (0.105)\tData 0.059 (0.080)\tLoss 1.3101 (0.7165)\tAcc 0.562 (0.719)\n",
      "Epoch: [68][9/18]\tTime 0.086 (0.103)\tData 0.059 (0.077)\tLoss 0.1827 (0.6572)\tAcc 1.000 (0.750)\n",
      "Epoch: [68][10/18]\tTime 0.076 (0.100)\tData 0.054 (0.075)\tLoss 1.0503 (0.6965)\tAcc 0.500 (0.725)\n",
      "Epoch: [68][11/18]\tTime 0.081 (0.098)\tData 0.058 (0.074)\tLoss 1.2927 (0.7507)\tAcc 0.375 (0.693)\n",
      "Epoch: [68][12/18]\tTime 0.079 (0.097)\tData 0.058 (0.072)\tLoss 0.8272 (0.7571)\tAcc 0.688 (0.693)\n",
      "Epoch: [68][13/18]\tTime 0.079 (0.095)\tData 0.059 (0.071)\tLoss 1.1586 (0.7880)\tAcc 0.500 (0.678)\n",
      "Epoch: [68][14/18]\tTime 0.076 (0.094)\tData 0.056 (0.070)\tLoss 0.7131 (0.7826)\tAcc 0.625 (0.674)\n",
      "Epoch: [68][15/18]\tTime 0.073 (0.092)\tData 0.054 (0.069)\tLoss 0.7564 (0.7809)\tAcc 0.688 (0.675)\n",
      "Epoch: [68][16/18]\tTime 0.075 (0.091)\tData 0.055 (0.068)\tLoss 0.6827 (0.7747)\tAcc 0.688 (0.676)\n",
      "Epoch: [68][17/18]\tTime 0.076 (0.090)\tData 0.056 (0.068)\tLoss 0.7884 (0.7755)\tAcc 0.625 (0.673)\n",
      "Epoch: [68][18/18]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.8432 (0.7775)\tAcc 0.750 (0.675)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/12]\tTime 0.314 (0.314)\tData 0.284 (0.284)\tLoss 0.4415 (0.4415)\tAcc 0.875 (0.875)\n",
      "Epoch: [69][2/12]\tTime 0.075 (0.195)\tData 0.049 (0.166)\tLoss 1.0331 (0.7373)\tAcc 0.562 (0.719)\n",
      "Epoch: [69][3/12]\tTime 0.079 (0.156)\tData 0.053 (0.129)\tLoss 0.6021 (0.6922)\tAcc 0.750 (0.729)\n",
      "Epoch: [69][4/12]\tTime 0.082 (0.137)\tData 0.052 (0.110)\tLoss 0.8229 (0.7249)\tAcc 0.562 (0.688)\n",
      "Epoch: [69][5/12]\tTime 0.079 (0.126)\tData 0.053 (0.098)\tLoss 0.8006 (0.7400)\tAcc 0.750 (0.700)\n",
      "Epoch: [69][6/12]\tTime 0.082 (0.118)\tData 0.054 (0.091)\tLoss 0.6674 (0.7279)\tAcc 0.875 (0.729)\n",
      "Epoch: [69][7/12]\tTime 0.076 (0.112)\tData 0.051 (0.085)\tLoss 0.8281 (0.7422)\tAcc 0.625 (0.714)\n",
      "Epoch: [69][8/12]\tTime 0.079 (0.108)\tData 0.055 (0.081)\tLoss 0.8310 (0.7533)\tAcc 0.688 (0.711)\n",
      "Epoch: [69][9/12]\tTime 0.079 (0.105)\tData 0.054 (0.078)\tLoss 0.8253 (0.7613)\tAcc 0.750 (0.715)\n",
      "Epoch: [69][10/12]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.6621 (0.7514)\tAcc 0.750 (0.719)\n",
      "Epoch: [69][11/12]\tTime 0.079 (0.100)\tData 0.055 (0.074)\tLoss 0.9139 (0.7662)\tAcc 0.562 (0.705)\n",
      "Epoch: [69][12/12]\tTime 0.078 (0.098)\tData 0.054 (0.072)\tLoss 0.7414 (0.7642)\tAcc 0.800 (0.712)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/18]\tTime 0.292 (0.292)\tData 0.262 (0.262)\tLoss 0.3838 (0.3838)\tAcc 0.875 (0.875)\n",
      "Epoch: [69][2/18]\tTime 0.071 (0.181)\tData 0.047 (0.155)\tLoss 0.9888 (0.6863)\tAcc 0.438 (0.656)\n",
      "Epoch: [69][3/18]\tTime 0.076 (0.146)\tData 0.053 (0.121)\tLoss 0.7811 (0.7179)\tAcc 0.750 (0.688)\n",
      "Epoch: [69][4/18]\tTime 0.085 (0.131)\tData 0.052 (0.104)\tLoss 0.6458 (0.6999)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][5/18]\tTime 0.071 (0.119)\tData 0.048 (0.093)\tLoss 0.7403 (0.7080)\tAcc 0.750 (0.700)\n",
      "Epoch: [69][6/18]\tTime 0.089 (0.114)\tData 0.057 (0.087)\tLoss 0.2905 (0.6384)\tAcc 1.000 (0.750)\n",
      "Epoch: [69][7/18]\tTime 0.070 (0.108)\tData 0.049 (0.081)\tLoss 0.7868 (0.6596)\tAcc 0.625 (0.732)\n",
      "Epoch: [69][8/18]\tTime 0.091 (0.106)\tData 0.059 (0.079)\tLoss 1.0231 (0.7050)\tAcc 0.500 (0.703)\n",
      "Epoch: [69][9/18]\tTime 0.076 (0.102)\tData 0.054 (0.076)\tLoss 0.2249 (0.6517)\tAcc 1.000 (0.736)\n",
      "Epoch: [69][10/18]\tTime 0.082 (0.100)\tData 0.059 (0.074)\tLoss 1.2257 (0.7091)\tAcc 0.375 (0.700)\n",
      "Epoch: [69][11/18]\tTime 0.080 (0.098)\tData 0.058 (0.073)\tLoss 1.1495 (0.7491)\tAcc 0.375 (0.670)\n",
      "Epoch: [69][12/18]\tTime 0.080 (0.097)\tData 0.058 (0.071)\tLoss 0.9245 (0.7637)\tAcc 0.812 (0.682)\n",
      "Epoch: [69][13/18]\tTime 0.078 (0.095)\tData 0.059 (0.070)\tLoss 1.0170 (0.7832)\tAcc 0.688 (0.683)\n",
      "Epoch: [69][14/18]\tTime 0.076 (0.094)\tData 0.056 (0.069)\tLoss 0.9895 (0.7980)\tAcc 0.500 (0.670)\n",
      "Epoch: [69][15/18]\tTime 0.075 (0.093)\tData 0.055 (0.069)\tLoss 1.0208 (0.8128)\tAcc 0.562 (0.663)\n",
      "Epoch: [69][16/18]\tTime 0.073 (0.091)\tData 0.054 (0.068)\tLoss 0.8854 (0.8173)\tAcc 0.688 (0.664)\n",
      "Epoch: [69][17/18]\tTime 0.075 (0.090)\tData 0.055 (0.067)\tLoss 1.0530 (0.8312)\tAcc 0.625 (0.662)\n",
      "Epoch: [69][18/18]\tTime 0.074 (0.090)\tData 0.054 (0.066)\tLoss 0.7507 (0.8289)\tAcc 0.875 (0.668)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/12]\tTime 0.296 (0.296)\tData 0.263 (0.263)\tLoss 0.8549 (0.8549)\tAcc 0.625 (0.625)\n",
      "Epoch: [70][2/12]\tTime 0.080 (0.188)\tData 0.047 (0.155)\tLoss 0.6156 (0.7352)\tAcc 0.812 (0.719)\n",
      "Epoch: [70][3/12]\tTime 0.076 (0.150)\tData 0.047 (0.119)\tLoss 0.6525 (0.7076)\tAcc 0.750 (0.729)\n",
      "Epoch: [70][4/12]\tTime 0.080 (0.133)\tData 0.051 (0.102)\tLoss 1.0342 (0.7893)\tAcc 0.562 (0.688)\n",
      "Epoch: [70][5/12]\tTime 0.078 (0.122)\tData 0.050 (0.092)\tLoss 0.4862 (0.7287)\tAcc 0.812 (0.713)\n",
      "Epoch: [70][6/12]\tTime 0.077 (0.114)\tData 0.051 (0.085)\tLoss 0.7084 (0.7253)\tAcc 0.750 (0.719)\n",
      "Epoch: [70][7/12]\tTime 0.082 (0.110)\tData 0.053 (0.080)\tLoss 0.8504 (0.7432)\tAcc 0.750 (0.723)\n",
      "Epoch: [70][8/12]\tTime 0.076 (0.106)\tData 0.052 (0.077)\tLoss 0.7023 (0.7380)\tAcc 0.688 (0.719)\n",
      "Epoch: [70][9/12]\tTime 0.077 (0.102)\tData 0.054 (0.074)\tLoss 0.9082 (0.7570)\tAcc 0.625 (0.708)\n",
      "Epoch: [70][10/12]\tTime 0.078 (0.100)\tData 0.055 (0.072)\tLoss 0.7269 (0.7540)\tAcc 0.750 (0.713)\n",
      "Epoch: [70][11/12]\tTime 0.079 (0.098)\tData 0.055 (0.071)\tLoss 0.6331 (0.7430)\tAcc 0.750 (0.716)\n",
      "Epoch: [70][12/12]\tTime 0.078 (0.096)\tData 0.055 (0.069)\tLoss 0.9498 (0.7592)\tAcc 0.667 (0.712)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/18]\tTime 0.312 (0.312)\tData 0.287 (0.287)\tLoss 0.3001 (0.3001)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/18]\tTime 0.071 (0.192)\tData 0.049 (0.168)\tLoss 0.8915 (0.5958)\tAcc 0.438 (0.688)\n",
      "Epoch: [70][3/18]\tTime 0.074 (0.152)\tData 0.052 (0.130)\tLoss 0.5539 (0.5818)\tAcc 0.812 (0.729)\n",
      "Epoch: [70][4/18]\tTime 0.076 (0.133)\tData 0.053 (0.110)\tLoss 0.7221 (0.6169)\tAcc 0.688 (0.719)\n",
      "Epoch: [70][5/18]\tTime 0.074 (0.121)\tData 0.053 (0.099)\tLoss 0.8072 (0.6550)\tAcc 0.750 (0.725)\n",
      "Epoch: [70][6/18]\tTime 0.076 (0.114)\tData 0.053 (0.091)\tLoss 0.3539 (0.6048)\tAcc 0.938 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [70][7/18]\tTime 0.073 (0.108)\tData 0.052 (0.086)\tLoss 0.6438 (0.6104)\tAcc 0.750 (0.759)\n",
      "Epoch: [70][8/18]\tTime 0.076 (0.104)\tData 0.053 (0.081)\tLoss 1.0878 (0.6701)\tAcc 0.562 (0.734)\n",
      "Epoch: [70][9/18]\tTime 0.075 (0.101)\tData 0.054 (0.078)\tLoss 0.2521 (0.6236)\tAcc 1.000 (0.764)\n",
      "Epoch: [70][10/18]\tTime 0.074 (0.098)\tData 0.053 (0.076)\tLoss 1.2591 (0.6872)\tAcc 0.562 (0.744)\n",
      "Epoch: [70][11/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 1.3193 (0.7446)\tAcc 0.375 (0.710)\n",
      "Epoch: [70][12/18]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.9204 (0.7593)\tAcc 0.625 (0.703)\n",
      "Epoch: [70][13/18]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 1.1953 (0.7928)\tAcc 0.438 (0.683)\n",
      "Epoch: [70][14/18]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.7851 (0.7923)\tAcc 0.688 (0.683)\n",
      "Epoch: [70][15/18]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.8898 (0.7988)\tAcc 0.688 (0.683)\n",
      "Epoch: [70][16/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9305 (0.8070)\tAcc 0.688 (0.684)\n",
      "Epoch: [70][17/18]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.8211 (0.8078)\tAcc 0.562 (0.676)\n",
      "Epoch: [70][18/18]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.6310 (0.8028)\tAcc 0.875 (0.682)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/12]\tTime 0.345 (0.345)\tData 0.312 (0.312)\tLoss 0.8951 (0.8951)\tAcc 0.625 (0.625)\n",
      "Epoch: [71][2/12]\tTime 0.072 (0.209)\tData 0.046 (0.179)\tLoss 1.0057 (0.9504)\tAcc 0.500 (0.562)\n",
      "Epoch: [71][3/12]\tTime 0.079 (0.166)\tData 0.052 (0.137)\tLoss 1.2320 (1.0443)\tAcc 0.375 (0.500)\n",
      "Epoch: [71][4/12]\tTime 0.081 (0.144)\tData 0.052 (0.116)\tLoss 0.6757 (0.9522)\tAcc 0.688 (0.547)\n",
      "Epoch: [71][5/12]\tTime 0.078 (0.131)\tData 0.051 (0.103)\tLoss 0.8319 (0.9281)\tAcc 0.625 (0.562)\n",
      "Epoch: [71][6/12]\tTime 0.091 (0.124)\tData 0.057 (0.095)\tLoss 0.8931 (0.9223)\tAcc 0.562 (0.562)\n",
      "Epoch: [71][7/12]\tTime 0.086 (0.119)\tData 0.057 (0.090)\tLoss 0.4215 (0.8507)\tAcc 0.875 (0.607)\n",
      "Epoch: [71][8/12]\tTime 0.082 (0.114)\tData 0.058 (0.086)\tLoss 0.4015 (0.7946)\tAcc 0.938 (0.648)\n",
      "Epoch: [71][9/12]\tTime 0.086 (0.111)\tData 0.062 (0.083)\tLoss 0.7913 (0.7942)\tAcc 0.750 (0.660)\n",
      "Epoch: [71][10/12]\tTime 0.086 (0.109)\tData 0.062 (0.081)\tLoss 0.6006 (0.7748)\tAcc 0.812 (0.675)\n",
      "Epoch: [71][11/12]\tTime 0.086 (0.107)\tData 0.062 (0.079)\tLoss 0.6372 (0.7623)\tAcc 0.812 (0.688)\n",
      "Epoch: [71][12/12]\tTime 0.086 (0.105)\tData 0.062 (0.078)\tLoss 0.4264 (0.7359)\tAcc 0.867 (0.702)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/18]\tTime 0.287 (0.287)\tData 0.260 (0.260)\tLoss 0.3075 (0.3075)\tAcc 0.938 (0.938)\n",
      "Epoch: [71][2/18]\tTime 0.069 (0.178)\tData 0.047 (0.153)\tLoss 1.0416 (0.6746)\tAcc 0.438 (0.688)\n",
      "Epoch: [71][3/18]\tTime 0.075 (0.144)\tData 0.053 (0.120)\tLoss 0.5905 (0.6465)\tAcc 0.875 (0.750)\n",
      "Epoch: [71][4/18]\tTime 0.073 (0.126)\tData 0.051 (0.103)\tLoss 0.7142 (0.6634)\tAcc 0.562 (0.703)\n",
      "Epoch: [71][5/18]\tTime 0.076 (0.116)\tData 0.055 (0.093)\tLoss 0.8188 (0.6945)\tAcc 0.750 (0.713)\n",
      "Epoch: [71][6/18]\tTime 0.079 (0.110)\tData 0.058 (0.087)\tLoss 0.2977 (0.6284)\tAcc 1.000 (0.760)\n",
      "Epoch: [71][7/18]\tTime 0.075 (0.105)\tData 0.054 (0.082)\tLoss 0.5758 (0.6209)\tAcc 0.750 (0.759)\n",
      "Epoch: [71][8/18]\tTime 0.082 (0.102)\tData 0.053 (0.079)\tLoss 1.0986 (0.6806)\tAcc 0.500 (0.727)\n",
      "Epoch: [71][9/18]\tTime 0.073 (0.099)\tData 0.047 (0.075)\tLoss 0.2735 (0.6354)\tAcc 1.000 (0.757)\n",
      "Epoch: [71][10/18]\tTime 0.082 (0.097)\tData 0.052 (0.073)\tLoss 1.3396 (0.7058)\tAcc 0.500 (0.731)\n",
      "Epoch: [71][11/18]\tTime 0.069 (0.095)\tData 0.044 (0.070)\tLoss 1.2986 (0.7597)\tAcc 0.375 (0.699)\n",
      "Epoch: [71][12/18]\tTime 0.071 (0.093)\tData 0.051 (0.069)\tLoss 0.9576 (0.7762)\tAcc 0.750 (0.703)\n",
      "Epoch: [71][13/18]\tTime 0.074 (0.091)\tData 0.054 (0.068)\tLoss 1.1035 (0.8014)\tAcc 0.500 (0.688)\n",
      "Epoch: [71][14/18]\tTime 0.075 (0.090)\tData 0.055 (0.067)\tLoss 0.8743 (0.8066)\tAcc 0.562 (0.679)\n",
      "Epoch: [71][15/18]\tTime 0.072 (0.089)\tData 0.053 (0.066)\tLoss 0.7804 (0.8048)\tAcc 0.750 (0.683)\n",
      "Epoch: [71][16/18]\tTime 0.079 (0.088)\tData 0.059 (0.065)\tLoss 0.7043 (0.7985)\tAcc 0.750 (0.688)\n",
      "Epoch: [71][17/18]\tTime 0.081 (0.088)\tData 0.060 (0.065)\tLoss 0.8782 (0.8032)\tAcc 0.625 (0.684)\n",
      "Epoch: [71][18/18]\tTime 0.080 (0.087)\tData 0.060 (0.065)\tLoss 0.8329 (0.8041)\tAcc 0.625 (0.682)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/12]\tTime 0.337 (0.337)\tData 0.308 (0.308)\tLoss 1.1386 (1.1386)\tAcc 0.625 (0.625)\n",
      "Epoch: [72][2/12]\tTime 0.076 (0.207)\tData 0.050 (0.179)\tLoss 0.7347 (0.9367)\tAcc 0.750 (0.688)\n",
      "Epoch: [72][3/12]\tTime 0.078 (0.164)\tData 0.052 (0.137)\tLoss 0.8529 (0.9087)\tAcc 0.562 (0.646)\n",
      "Epoch: [72][4/12]\tTime 0.079 (0.143)\tData 0.052 (0.116)\tLoss 0.8049 (0.8828)\tAcc 0.688 (0.656)\n",
      "Epoch: [72][5/12]\tTime 0.080 (0.130)\tData 0.054 (0.103)\tLoss 0.5898 (0.8242)\tAcc 0.875 (0.700)\n",
      "Epoch: [72][6/12]\tTime 0.079 (0.122)\tData 0.052 (0.095)\tLoss 0.9473 (0.8447)\tAcc 0.625 (0.688)\n",
      "Epoch: [72][7/12]\tTime 0.083 (0.116)\tData 0.055 (0.089)\tLoss 0.6159 (0.8120)\tAcc 0.750 (0.696)\n",
      "Epoch: [72][8/12]\tTime 0.083 (0.112)\tData 0.058 (0.085)\tLoss 0.5572 (0.7802)\tAcc 0.875 (0.719)\n",
      "Epoch: [72][9/12]\tTime 0.086 (0.109)\tData 0.061 (0.083)\tLoss 0.7222 (0.7737)\tAcc 0.688 (0.715)\n",
      "Epoch: [72][10/12]\tTime 0.087 (0.107)\tData 0.061 (0.080)\tLoss 0.6500 (0.7613)\tAcc 0.750 (0.719)\n",
      "Epoch: [72][11/12]\tTime 0.087 (0.105)\tData 0.061 (0.079)\tLoss 0.6576 (0.7519)\tAcc 0.812 (0.727)\n",
      "Epoch: [72][12/12]\tTime 0.087 (0.104)\tData 0.061 (0.077)\tLoss 0.5539 (0.7364)\tAcc 0.800 (0.733)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/18]\tTime 0.324 (0.324)\tData 0.294 (0.294)\tLoss 0.3913 (0.3913)\tAcc 0.875 (0.875)\n",
      "Epoch: [72][2/18]\tTime 0.067 (0.195)\tData 0.045 (0.169)\tLoss 0.9372 (0.6643)\tAcc 0.438 (0.656)\n",
      "Epoch: [72][3/18]\tTime 0.079 (0.157)\tData 0.057 (0.132)\tLoss 0.6172 (0.6486)\tAcc 0.875 (0.729)\n",
      "Epoch: [72][4/18]\tTime 0.080 (0.137)\tData 0.058 (0.114)\tLoss 0.7050 (0.6627)\tAcc 0.625 (0.703)\n",
      "Epoch: [72][5/18]\tTime 0.080 (0.126)\tData 0.058 (0.102)\tLoss 0.7698 (0.6841)\tAcc 0.750 (0.713)\n",
      "Epoch: [72][6/18]\tTime 0.081 (0.118)\tData 0.059 (0.095)\tLoss 0.2459 (0.6111)\tAcc 1.000 (0.760)\n",
      "Epoch: [72][7/18]\tTime 0.081 (0.113)\tData 0.059 (0.090)\tLoss 0.7230 (0.6271)\tAcc 0.625 (0.741)\n",
      "Epoch: [72][8/18]\tTime 0.081 (0.109)\tData 0.059 (0.086)\tLoss 1.1455 (0.6919)\tAcc 0.562 (0.719)\n",
      "Epoch: [72][9/18]\tTime 0.080 (0.106)\tData 0.059 (0.083)\tLoss 0.2634 (0.6443)\tAcc 1.000 (0.750)\n",
      "Epoch: [72][10/18]\tTime 0.084 (0.104)\tData 0.058 (0.081)\tLoss 1.2450 (0.7043)\tAcc 0.562 (0.731)\n",
      "Epoch: [72][11/18]\tTime 0.075 (0.101)\tData 0.054 (0.078)\tLoss 1.3108 (0.7595)\tAcc 0.375 (0.699)\n",
      "Epoch: [72][12/18]\tTime 0.080 (0.099)\tData 0.059 (0.077)\tLoss 0.9977 (0.7793)\tAcc 0.562 (0.688)\n",
      "Epoch: [72][13/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 1.1090 (0.8047)\tAcc 0.625 (0.683)\n",
      "Epoch: [72][14/18]\tTime 0.080 (0.097)\tData 0.060 (0.074)\tLoss 0.7538 (0.8010)\tAcc 0.625 (0.679)\n",
      "Epoch: [72][15/18]\tTime 0.080 (0.095)\tData 0.060 (0.073)\tLoss 0.7709 (0.7990)\tAcc 0.750 (0.683)\n",
      "Epoch: [72][16/18]\tTime 0.080 (0.095)\tData 0.060 (0.072)\tLoss 0.6935 (0.7924)\tAcc 0.750 (0.688)\n",
      "Epoch: [72][17/18]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 0.8198 (0.7941)\tAcc 0.625 (0.684)\n",
      "Epoch: [72][18/18]\tTime 0.081 (0.093)\tData 0.060 (0.071)\tLoss 0.7506 (0.7928)\tAcc 0.750 (0.686)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/12]\tTime 0.285 (0.285)\tData 0.248 (0.248)\tLoss 0.8620 (0.8620)\tAcc 0.688 (0.688)\n",
      "Epoch: [73][2/12]\tTime 0.076 (0.181)\tData 0.050 (0.149)\tLoss 0.9022 (0.8821)\tAcc 0.750 (0.719)\n",
      "Epoch: [73][3/12]\tTime 0.090 (0.151)\tData 0.059 (0.119)\tLoss 0.5321 (0.7654)\tAcc 0.812 (0.750)\n",
      "Epoch: [73][4/12]\tTime 0.095 (0.137)\tData 0.055 (0.103)\tLoss 0.5278 (0.7060)\tAcc 0.938 (0.797)\n",
      "Epoch: [73][5/12]\tTime 0.073 (0.124)\tData 0.047 (0.092)\tLoss 0.4299 (0.6508)\tAcc 0.812 (0.800)\n",
      "Epoch: [73][6/12]\tTime 0.090 (0.118)\tData 0.060 (0.086)\tLoss 0.7335 (0.6646)\tAcc 0.625 (0.771)\n",
      "Epoch: [73][7/12]\tTime 0.082 (0.113)\tData 0.057 (0.082)\tLoss 0.7216 (0.6727)\tAcc 0.688 (0.759)\n",
      "Epoch: [73][8/12]\tTime 0.086 (0.110)\tData 0.061 (0.080)\tLoss 0.9533 (0.7078)\tAcc 0.562 (0.734)\n",
      "Epoch: [73][9/12]\tTime 0.087 (0.107)\tData 0.061 (0.077)\tLoss 0.8600 (0.7247)\tAcc 0.688 (0.729)\n",
      "Epoch: [73][10/12]\tTime 0.086 (0.105)\tData 0.061 (0.076)\tLoss 0.6935 (0.7216)\tAcc 0.812 (0.738)\n",
      "Epoch: [73][11/12]\tTime 0.087 (0.103)\tData 0.062 (0.075)\tLoss 0.6924 (0.7189)\tAcc 0.688 (0.733)\n",
      "Epoch: [73][12/12]\tTime 0.086 (0.102)\tData 0.061 (0.073)\tLoss 0.8513 (0.7293)\tAcc 0.733 (0.733)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/18]\tTime 0.328 (0.328)\tData 0.295 (0.295)\tLoss 0.2760 (0.2760)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/18]\tTime 0.073 (0.201)\tData 0.047 (0.171)\tLoss 0.9895 (0.6328)\tAcc 0.438 (0.688)\n",
      "Epoch: [73][3/18]\tTime 0.081 (0.161)\tData 0.059 (0.134)\tLoss 0.5204 (0.5953)\tAcc 0.938 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [73][4/18]\tTime 0.080 (0.141)\tData 0.059 (0.115)\tLoss 0.7418 (0.6319)\tAcc 0.625 (0.734)\n",
      "Epoch: [73][5/18]\tTime 0.084 (0.129)\tData 0.057 (0.104)\tLoss 0.9281 (0.6912)\tAcc 0.562 (0.700)\n",
      "Epoch: [73][6/18]\tTime 0.075 (0.120)\tData 0.053 (0.095)\tLoss 0.3586 (0.6357)\tAcc 0.875 (0.729)\n",
      "Epoch: [73][7/18]\tTime 0.081 (0.115)\tData 0.057 (0.090)\tLoss 0.7831 (0.6568)\tAcc 0.562 (0.705)\n",
      "Epoch: [73][8/18]\tTime 0.084 (0.111)\tData 0.056 (0.085)\tLoss 1.0419 (0.7049)\tAcc 0.562 (0.688)\n",
      "Epoch: [73][9/18]\tTime 0.075 (0.107)\tData 0.054 (0.082)\tLoss 0.1542 (0.6437)\tAcc 1.000 (0.722)\n",
      "Epoch: [73][10/18]\tTime 0.080 (0.104)\tData 0.059 (0.080)\tLoss 1.2574 (0.7051)\tAcc 0.375 (0.688)\n",
      "Epoch: [73][11/18]\tTime 0.077 (0.102)\tData 0.056 (0.077)\tLoss 1.4231 (0.7704)\tAcc 0.375 (0.659)\n",
      "Epoch: [73][12/18]\tTime 0.075 (0.099)\tData 0.054 (0.076)\tLoss 1.0031 (0.7898)\tAcc 0.625 (0.656)\n",
      "Epoch: [73][13/18]\tTime 0.074 (0.097)\tData 0.053 (0.074)\tLoss 1.0445 (0.8094)\tAcc 0.625 (0.654)\n",
      "Epoch: [73][14/18]\tTime 0.074 (0.096)\tData 0.054 (0.072)\tLoss 0.9093 (0.8165)\tAcc 0.562 (0.647)\n",
      "Epoch: [73][15/18]\tTime 0.080 (0.095)\tData 0.061 (0.072)\tLoss 0.8103 (0.8161)\tAcc 0.688 (0.650)\n",
      "Epoch: [73][16/18]\tTime 0.080 (0.094)\tData 0.060 (0.071)\tLoss 0.8423 (0.8177)\tAcc 0.625 (0.648)\n",
      "Epoch: [73][17/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.7605 (0.8144)\tAcc 0.688 (0.651)\n",
      "Epoch: [73][18/18]\tTime 0.079 (0.092)\tData 0.060 (0.070)\tLoss 0.8047 (0.8141)\tAcc 0.750 (0.654)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/12]\tTime 0.253 (0.253)\tData 0.217 (0.217)\tLoss 0.6009 (0.6009)\tAcc 0.750 (0.750)\n",
      "Epoch: [74][2/12]\tTime 0.103 (0.178)\tData 0.044 (0.130)\tLoss 0.9219 (0.7614)\tAcc 0.562 (0.656)\n",
      "Epoch: [74][3/12]\tTime 0.068 (0.141)\tData 0.024 (0.095)\tLoss 0.5243 (0.6824)\tAcc 0.875 (0.729)\n",
      "Epoch: [74][4/12]\tTime 0.068 (0.123)\tData 0.039 (0.081)\tLoss 0.4587 (0.6265)\tAcc 0.875 (0.766)\n",
      "Epoch: [74][5/12]\tTime 0.080 (0.115)\tData 0.053 (0.076)\tLoss 0.8802 (0.6772)\tAcc 0.688 (0.750)\n",
      "Epoch: [74][6/12]\tTime 0.086 (0.110)\tData 0.060 (0.073)\tLoss 0.7688 (0.6925)\tAcc 0.625 (0.729)\n",
      "Epoch: [74][7/12]\tTime 0.087 (0.106)\tData 0.061 (0.071)\tLoss 0.5001 (0.6650)\tAcc 0.875 (0.750)\n",
      "Epoch: [74][8/12]\tTime 0.086 (0.104)\tData 0.061 (0.070)\tLoss 0.5628 (0.6522)\tAcc 0.750 (0.750)\n",
      "Epoch: [74][9/12]\tTime 0.086 (0.102)\tData 0.061 (0.069)\tLoss 0.7178 (0.6595)\tAcc 0.750 (0.750)\n",
      "Epoch: [74][10/12]\tTime 0.083 (0.100)\tData 0.059 (0.068)\tLoss 0.6555 (0.6591)\tAcc 0.812 (0.756)\n",
      "Epoch: [74][11/12]\tTime 0.087 (0.099)\tData 0.062 (0.067)\tLoss 0.6419 (0.6575)\tAcc 0.688 (0.750)\n",
      "Epoch: [74][12/12]\tTime 0.086 (0.098)\tData 0.061 (0.067)\tLoss 1.0984 (0.6922)\tAcc 0.533 (0.733)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/18]\tTime 0.296 (0.296)\tData 0.262 (0.262)\tLoss 0.3222 (0.3222)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/18]\tTime 0.071 (0.184)\tData 0.049 (0.156)\tLoss 0.9357 (0.6289)\tAcc 0.438 (0.688)\n",
      "Epoch: [74][3/18]\tTime 0.081 (0.150)\tData 0.059 (0.123)\tLoss 0.7160 (0.6580)\tAcc 0.750 (0.708)\n",
      "Epoch: [74][4/18]\tTime 0.085 (0.133)\tData 0.059 (0.107)\tLoss 0.6637 (0.6594)\tAcc 0.688 (0.703)\n",
      "Epoch: [74][5/18]\tTime 0.086 (0.124)\tData 0.054 (0.097)\tLoss 0.7562 (0.6788)\tAcc 0.812 (0.725)\n",
      "Epoch: [74][6/18]\tTime 0.073 (0.115)\tData 0.047 (0.088)\tLoss 0.2767 (0.6118)\tAcc 1.000 (0.771)\n",
      "Epoch: [74][7/18]\tTime 0.083 (0.111)\tData 0.055 (0.084)\tLoss 0.6596 (0.6186)\tAcc 0.688 (0.759)\n",
      "Epoch: [74][8/18]\tTime 0.073 (0.106)\tData 0.052 (0.080)\tLoss 1.0254 (0.6694)\tAcc 0.562 (0.734)\n",
      "Epoch: [74][9/18]\tTime 0.083 (0.104)\tData 0.059 (0.077)\tLoss 0.2182 (0.6193)\tAcc 1.000 (0.764)\n",
      "Epoch: [74][10/18]\tTime 0.084 (0.102)\tData 0.057 (0.075)\tLoss 1.3178 (0.6892)\tAcc 0.438 (0.731)\n",
      "Epoch: [74][11/18]\tTime 0.080 (0.100)\tData 0.056 (0.074)\tLoss 1.3712 (0.7512)\tAcc 0.375 (0.699)\n",
      "Epoch: [74][12/18]\tTime 0.077 (0.098)\tData 0.056 (0.072)\tLoss 0.8428 (0.7588)\tAcc 0.688 (0.698)\n",
      "Epoch: [74][13/18]\tTime 0.080 (0.096)\tData 0.060 (0.071)\tLoss 1.0945 (0.7846)\tAcc 0.625 (0.692)\n",
      "Epoch: [74][14/18]\tTime 0.080 (0.095)\tData 0.060 (0.070)\tLoss 0.8862 (0.7919)\tAcc 0.562 (0.683)\n",
      "Epoch: [74][15/18]\tTime 0.080 (0.094)\tData 0.060 (0.070)\tLoss 0.7295 (0.7877)\tAcc 0.750 (0.688)\n",
      "Epoch: [74][16/18]\tTime 0.079 (0.093)\tData 0.059 (0.069)\tLoss 0.8207 (0.7898)\tAcc 0.688 (0.688)\n",
      "Epoch: [74][17/18]\tTime 0.080 (0.092)\tData 0.059 (0.068)\tLoss 0.7814 (0.7893)\tAcc 0.625 (0.684)\n",
      "Epoch: [74][18/18]\tTime 0.079 (0.092)\tData 0.059 (0.068)\tLoss 0.7087 (0.7870)\tAcc 0.875 (0.689)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/12]\tTime 0.295 (0.295)\tData 0.259 (0.259)\tLoss 0.6395 (0.6395)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][2/12]\tTime 0.080 (0.187)\tData 0.052 (0.156)\tLoss 0.8652 (0.7524)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][3/12]\tTime 0.085 (0.153)\tData 0.058 (0.123)\tLoss 0.7860 (0.7636)\tAcc 0.750 (0.708)\n",
      "Epoch: [75][4/12]\tTime 0.091 (0.138)\tData 0.058 (0.107)\tLoss 0.6043 (0.7237)\tAcc 0.688 (0.703)\n",
      "Epoch: [75][5/12]\tTime 0.079 (0.126)\tData 0.053 (0.096)\tLoss 0.7294 (0.7249)\tAcc 0.750 (0.713)\n",
      "Epoch: [75][6/12]\tTime 0.087 (0.119)\tData 0.059 (0.090)\tLoss 0.9002 (0.7541)\tAcc 0.688 (0.708)\n",
      "Epoch: [75][7/12]\tTime 0.085 (0.115)\tData 0.059 (0.085)\tLoss 0.7537 (0.7540)\tAcc 0.688 (0.705)\n",
      "Epoch: [75][8/12]\tTime 0.086 (0.111)\tData 0.061 (0.082)\tLoss 1.0007 (0.7849)\tAcc 0.562 (0.688)\n",
      "Epoch: [75][9/12]\tTime 0.085 (0.108)\tData 0.061 (0.080)\tLoss 0.5755 (0.7616)\tAcc 0.750 (0.694)\n",
      "Epoch: [75][10/12]\tTime 0.086 (0.106)\tData 0.061 (0.078)\tLoss 0.6749 (0.7529)\tAcc 0.750 (0.700)\n",
      "Epoch: [75][11/12]\tTime 0.084 (0.104)\tData 0.059 (0.076)\tLoss 0.8865 (0.7651)\tAcc 0.750 (0.705)\n",
      "Epoch: [75][12/12]\tTime 0.086 (0.102)\tData 0.061 (0.075)\tLoss 0.8051 (0.7682)\tAcc 0.667 (0.702)\n",
      "validation at epoch 75\n",
      "Epoch: [75][1/18]\tTime 0.311 (0.311)\tData 0.285 (0.285)\tLoss 0.4204 (0.4204)\tAcc 0.875 (0.875)\n",
      "Epoch: [75][2/18]\tTime 0.076 (0.194)\tData 0.055 (0.170)\tLoss 0.9013 (0.6608)\tAcc 0.438 (0.656)\n",
      "Epoch: [75][3/18]\tTime 0.082 (0.156)\tData 0.058 (0.133)\tLoss 0.5867 (0.6361)\tAcc 0.812 (0.708)\n",
      "Epoch: [75][4/18]\tTime 0.080 (0.137)\tData 0.056 (0.114)\tLoss 0.6491 (0.6394)\tAcc 0.625 (0.688)\n",
      "Epoch: [75][5/18]\tTime 0.080 (0.126)\tData 0.058 (0.103)\tLoss 0.9252 (0.6966)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][6/18]\tTime 0.081 (0.118)\tData 0.059 (0.095)\tLoss 0.3635 (0.6411)\tAcc 1.000 (0.740)\n",
      "Epoch: [75][7/18]\tTime 0.080 (0.113)\tData 0.059 (0.090)\tLoss 0.6772 (0.6462)\tAcc 0.562 (0.714)\n",
      "Epoch: [75][8/18]\tTime 0.091 (0.110)\tData 0.059 (0.086)\tLoss 1.1748 (0.7123)\tAcc 0.562 (0.695)\n",
      "Epoch: [75][9/18]\tTime 0.073 (0.106)\tData 0.048 (0.082)\tLoss 0.1752 (0.6526)\tAcc 1.000 (0.729)\n",
      "Epoch: [75][10/18]\tTime 0.078 (0.103)\tData 0.057 (0.079)\tLoss 1.2338 (0.7107)\tAcc 0.500 (0.706)\n",
      "Epoch: [75][11/18]\tTime 0.080 (0.101)\tData 0.059 (0.078)\tLoss 1.4193 (0.7751)\tAcc 0.375 (0.676)\n",
      "Epoch: [75][12/18]\tTime 0.080 (0.099)\tData 0.059 (0.076)\tLoss 0.8609 (0.7823)\tAcc 0.688 (0.677)\n",
      "Epoch: [75][13/18]\tTime 0.081 (0.098)\tData 0.059 (0.075)\tLoss 1.0928 (0.8062)\tAcc 0.438 (0.659)\n",
      "Epoch: [75][14/18]\tTime 0.079 (0.097)\tData 0.059 (0.074)\tLoss 0.9507 (0.8165)\tAcc 0.562 (0.652)\n",
      "Epoch: [75][15/18]\tTime 0.079 (0.095)\tData 0.059 (0.073)\tLoss 0.8041 (0.8157)\tAcc 0.750 (0.658)\n",
      "Epoch: [75][16/18]\tTime 0.077 (0.094)\tData 0.057 (0.072)\tLoss 0.8506 (0.8179)\tAcc 0.625 (0.656)\n",
      "Epoch: [75][17/18]\tTime 0.080 (0.093)\tData 0.059 (0.071)\tLoss 0.8704 (0.8209)\tAcc 0.625 (0.654)\n",
      "Epoch: [75][18/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.9208 (0.8238)\tAcc 0.625 (0.654)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/12]\tTime 0.280 (0.280)\tData 0.251 (0.251)\tLoss 0.5222 (0.5222)\tAcc 0.812 (0.812)\n",
      "Epoch: [76][2/12]\tTime 0.085 (0.183)\tData 0.058 (0.155)\tLoss 1.3345 (0.9283)\tAcc 0.562 (0.688)\n",
      "Epoch: [76][3/12]\tTime 0.090 (0.152)\tData 0.059 (0.123)\tLoss 0.6827 (0.8465)\tAcc 0.750 (0.708)\n",
      "Epoch: [76][4/12]\tTime 0.100 (0.139)\tData 0.058 (0.106)\tLoss 0.7593 (0.8247)\tAcc 0.625 (0.688)\n",
      "Epoch: [76][5/12]\tTime 0.075 (0.126)\tData 0.048 (0.095)\tLoss 0.6392 (0.7876)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][6/12]\tTime 0.091 (0.120)\tData 0.059 (0.089)\tLoss 0.5505 (0.7481)\tAcc 0.812 (0.708)\n",
      "Epoch: [76][7/12]\tTime 0.080 (0.114)\tData 0.055 (0.084)\tLoss 0.3998 (0.6983)\tAcc 0.938 (0.741)\n",
      "Epoch: [76][8/12]\tTime 0.086 (0.111)\tData 0.061 (0.081)\tLoss 0.8419 (0.7163)\tAcc 0.625 (0.727)\n",
      "Epoch: [76][9/12]\tTime 0.085 (0.108)\tData 0.061 (0.079)\tLoss 0.8878 (0.7353)\tAcc 0.688 (0.722)\n",
      "Epoch: [76][10/12]\tTime 0.084 (0.106)\tData 0.060 (0.077)\tLoss 0.3660 (0.6984)\tAcc 0.938 (0.744)\n",
      "Epoch: [76][11/12]\tTime 0.086 (0.104)\tData 0.061 (0.076)\tLoss 0.7629 (0.7043)\tAcc 0.625 (0.733)\n",
      "Epoch: [76][12/12]\tTime 0.086 (0.102)\tData 0.061 (0.074)\tLoss 0.7826 (0.7104)\tAcc 0.667 (0.728)\n",
      "validation at epoch 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][1/18]\tTime 0.287 (0.287)\tData 0.261 (0.261)\tLoss 0.3279 (0.3279)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/18]\tTime 0.077 (0.182)\tData 0.053 (0.157)\tLoss 1.0358 (0.6818)\tAcc 0.438 (0.688)\n",
      "Epoch: [76][3/18]\tTime 0.079 (0.148)\tData 0.057 (0.124)\tLoss 0.6254 (0.6630)\tAcc 0.812 (0.729)\n",
      "Epoch: [76][4/18]\tTime 0.081 (0.131)\tData 0.059 (0.107)\tLoss 0.5473 (0.6341)\tAcc 0.688 (0.719)\n",
      "Epoch: [76][5/18]\tTime 0.091 (0.123)\tData 0.060 (0.098)\tLoss 0.8321 (0.6737)\tAcc 0.812 (0.738)\n",
      "Epoch: [76][6/18]\tTime 0.076 (0.115)\tData 0.050 (0.090)\tLoss 0.2319 (0.6001)\tAcc 1.000 (0.781)\n",
      "Epoch: [76][7/18]\tTime 0.080 (0.110)\tData 0.057 (0.085)\tLoss 0.8727 (0.6390)\tAcc 0.500 (0.741)\n",
      "Epoch: [76][8/18]\tTime 0.079 (0.106)\tData 0.057 (0.082)\tLoss 1.0055 (0.6848)\tAcc 0.625 (0.727)\n",
      "Epoch: [76][9/18]\tTime 0.079 (0.103)\tData 0.057 (0.079)\tLoss 0.1759 (0.6283)\tAcc 1.000 (0.757)\n",
      "Epoch: [76][10/18]\tTime 0.081 (0.101)\tData 0.059 (0.077)\tLoss 1.2010 (0.6855)\tAcc 0.562 (0.738)\n",
      "Epoch: [76][11/18]\tTime 0.079 (0.099)\tData 0.058 (0.075)\tLoss 1.2995 (0.7414)\tAcc 0.375 (0.705)\n",
      "Epoch: [76][12/18]\tTime 0.081 (0.098)\tData 0.060 (0.074)\tLoss 0.9814 (0.7614)\tAcc 0.625 (0.698)\n",
      "Epoch: [76][13/18]\tTime 0.080 (0.096)\tData 0.060 (0.073)\tLoss 1.2402 (0.7982)\tAcc 0.500 (0.683)\n",
      "Epoch: [76][14/18]\tTime 0.078 (0.095)\tData 0.058 (0.072)\tLoss 0.8113 (0.7991)\tAcc 0.562 (0.674)\n",
      "Epoch: [76][15/18]\tTime 0.079 (0.094)\tData 0.059 (0.071)\tLoss 0.9039 (0.8061)\tAcc 0.625 (0.671)\n",
      "Epoch: [76][16/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.7402 (0.8020)\tAcc 0.750 (0.676)\n",
      "Epoch: [76][17/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.8140 (0.8027)\tAcc 0.625 (0.673)\n",
      "Epoch: [76][18/18]\tTime 0.078 (0.092)\tData 0.058 (0.069)\tLoss 0.7017 (0.7998)\tAcc 0.750 (0.675)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/12]\tTime 0.306 (0.306)\tData 0.274 (0.274)\tLoss 0.9556 (0.9556)\tAcc 0.562 (0.562)\n",
      "Epoch: [77][2/12]\tTime 0.086 (0.196)\tData 0.055 (0.165)\tLoss 0.6834 (0.8195)\tAcc 0.812 (0.688)\n",
      "Epoch: [77][3/12]\tTime 0.082 (0.158)\tData 0.055 (0.128)\tLoss 0.6221 (0.7537)\tAcc 0.812 (0.729)\n",
      "Epoch: [77][4/12]\tTime 0.091 (0.141)\tData 0.060 (0.111)\tLoss 1.1255 (0.8467)\tAcc 0.500 (0.672)\n",
      "Epoch: [77][5/12]\tTime 0.086 (0.130)\tData 0.056 (0.100)\tLoss 0.5710 (0.7915)\tAcc 0.875 (0.713)\n",
      "Epoch: [77][6/12]\tTime 0.086 (0.123)\tData 0.057 (0.093)\tLoss 0.4155 (0.7289)\tAcc 0.875 (0.740)\n",
      "Epoch: [77][7/12]\tTime 0.082 (0.117)\tData 0.057 (0.088)\tLoss 0.7530 (0.7323)\tAcc 0.562 (0.714)\n",
      "Epoch: [77][8/12]\tTime 0.086 (0.113)\tData 0.061 (0.084)\tLoss 0.9026 (0.7536)\tAcc 0.688 (0.711)\n",
      "Epoch: [77][9/12]\tTime 0.086 (0.110)\tData 0.061 (0.082)\tLoss 0.7864 (0.7573)\tAcc 0.688 (0.708)\n",
      "Epoch: [77][10/12]\tTime 0.085 (0.108)\tData 0.060 (0.080)\tLoss 0.7326 (0.7548)\tAcc 0.625 (0.700)\n",
      "Epoch: [77][11/12]\tTime 0.085 (0.106)\tData 0.061 (0.078)\tLoss 0.8188 (0.7606)\tAcc 0.688 (0.699)\n",
      "Epoch: [77][12/12]\tTime 0.086 (0.104)\tData 0.061 (0.076)\tLoss 0.6455 (0.7516)\tAcc 0.800 (0.707)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/18]\tTime 0.302 (0.302)\tData 0.272 (0.272)\tLoss 0.4236 (0.4236)\tAcc 0.875 (0.875)\n",
      "Epoch: [77][2/18]\tTime 0.075 (0.189)\tData 0.051 (0.161)\tLoss 1.1277 (0.7756)\tAcc 0.438 (0.656)\n",
      "Epoch: [77][3/18]\tTime 0.083 (0.153)\tData 0.057 (0.127)\tLoss 0.7528 (0.7680)\tAcc 0.688 (0.667)\n",
      "Epoch: [77][4/18]\tTime 0.080 (0.135)\tData 0.054 (0.108)\tLoss 0.5987 (0.7257)\tAcc 0.688 (0.672)\n",
      "Epoch: [77][5/18]\tTime 0.079 (0.124)\tData 0.057 (0.098)\tLoss 0.8970 (0.7600)\tAcc 0.688 (0.675)\n",
      "Epoch: [77][6/18]\tTime 0.080 (0.117)\tData 0.059 (0.092)\tLoss 0.3401 (0.6900)\tAcc 0.938 (0.719)\n",
      "Epoch: [77][7/18]\tTime 0.086 (0.112)\tData 0.059 (0.087)\tLoss 0.6501 (0.6843)\tAcc 0.688 (0.714)\n",
      "Epoch: [77][8/18]\tTime 0.078 (0.108)\tData 0.056 (0.083)\tLoss 1.0422 (0.7290)\tAcc 0.562 (0.695)\n",
      "Epoch: [77][9/18]\tTime 0.081 (0.105)\tData 0.059 (0.080)\tLoss 0.2044 (0.6707)\tAcc 1.000 (0.729)\n",
      "Epoch: [77][10/18]\tTime 0.080 (0.102)\tData 0.059 (0.078)\tLoss 1.2406 (0.7277)\tAcc 0.375 (0.694)\n",
      "Epoch: [77][11/18]\tTime 0.081 (0.100)\tData 0.059 (0.077)\tLoss 1.4098 (0.7897)\tAcc 0.375 (0.665)\n",
      "Epoch: [77][12/18]\tTime 0.079 (0.099)\tData 0.058 (0.075)\tLoss 0.9335 (0.8017)\tAcc 0.688 (0.667)\n",
      "Epoch: [77][13/18]\tTime 0.080 (0.097)\tData 0.060 (0.074)\tLoss 1.0748 (0.8227)\tAcc 0.500 (0.654)\n",
      "Epoch: [77][14/18]\tTime 0.080 (0.096)\tData 0.060 (0.073)\tLoss 0.8207 (0.8226)\tAcc 0.625 (0.652)\n",
      "Epoch: [77][15/18]\tTime 0.081 (0.095)\tData 0.060 (0.072)\tLoss 0.7770 (0.8195)\tAcc 0.750 (0.658)\n",
      "Epoch: [77][16/18]\tTime 0.080 (0.094)\tData 0.059 (0.071)\tLoss 0.7740 (0.8167)\tAcc 0.625 (0.656)\n",
      "Epoch: [77][17/18]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.9270 (0.8232)\tAcc 0.625 (0.654)\n",
      "Epoch: [77][18/18]\tTime 0.080 (0.093)\tData 0.060 (0.070)\tLoss 0.9569 (0.8270)\tAcc 0.625 (0.654)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/12]\tTime 0.318 (0.318)\tData 0.279 (0.279)\tLoss 0.4982 (0.4982)\tAcc 0.812 (0.812)\n",
      "Epoch: [78][2/12]\tTime 0.078 (0.198)\tData 0.048 (0.163)\tLoss 0.5892 (0.5437)\tAcc 0.750 (0.781)\n",
      "Epoch: [78][3/12]\tTime 0.095 (0.164)\tData 0.053 (0.127)\tLoss 0.8629 (0.6501)\tAcc 0.625 (0.729)\n",
      "Epoch: [78][4/12]\tTime 0.081 (0.143)\tData 0.044 (0.106)\tLoss 0.5838 (0.6335)\tAcc 0.812 (0.750)\n",
      "Epoch: [78][5/12]\tTime 0.076 (0.130)\tData 0.050 (0.095)\tLoss 0.5373 (0.6143)\tAcc 0.750 (0.750)\n",
      "Epoch: [78][6/12]\tTime 0.087 (0.123)\tData 0.059 (0.089)\tLoss 0.8729 (0.6574)\tAcc 0.688 (0.740)\n",
      "Epoch: [78][7/12]\tTime 0.083 (0.117)\tData 0.058 (0.084)\tLoss 0.7190 (0.6662)\tAcc 0.688 (0.732)\n",
      "Epoch: [78][8/12]\tTime 0.083 (0.113)\tData 0.059 (0.081)\tLoss 0.5706 (0.6542)\tAcc 0.750 (0.734)\n",
      "Epoch: [78][9/12]\tTime 0.086 (0.110)\tData 0.062 (0.079)\tLoss 0.6855 (0.6577)\tAcc 0.688 (0.729)\n",
      "Epoch: [78][10/12]\tTime 0.086 (0.107)\tData 0.062 (0.077)\tLoss 0.7382 (0.6658)\tAcc 0.688 (0.725)\n",
      "Epoch: [78][11/12]\tTime 0.086 (0.105)\tData 0.061 (0.076)\tLoss 0.9933 (0.6955)\tAcc 0.562 (0.710)\n",
      "Epoch: [78][12/12]\tTime 0.085 (0.104)\tData 0.061 (0.075)\tLoss 0.4989 (0.6801)\tAcc 0.800 (0.717)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/18]\tTime 0.344 (0.344)\tData 0.319 (0.319)\tLoss 0.2673 (0.2673)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/18]\tTime 0.078 (0.211)\tData 0.056 (0.187)\tLoss 0.9420 (0.6046)\tAcc 0.438 (0.688)\n",
      "Epoch: [78][3/18]\tTime 0.083 (0.169)\tData 0.060 (0.145)\tLoss 0.7075 (0.6389)\tAcc 0.688 (0.688)\n",
      "Epoch: [78][4/18]\tTime 0.079 (0.146)\tData 0.058 (0.123)\tLoss 0.7228 (0.6599)\tAcc 0.688 (0.688)\n",
      "Epoch: [78][5/18]\tTime 0.081 (0.133)\tData 0.059 (0.110)\tLoss 0.7360 (0.6751)\tAcc 0.750 (0.700)\n",
      "Epoch: [78][6/18]\tTime 0.080 (0.124)\tData 0.059 (0.102)\tLoss 0.3179 (0.6156)\tAcc 1.000 (0.750)\n",
      "Epoch: [78][7/18]\tTime 0.087 (0.119)\tData 0.059 (0.096)\tLoss 0.7301 (0.6319)\tAcc 0.688 (0.741)\n",
      "Epoch: [78][8/18]\tTime 0.087 (0.115)\tData 0.056 (0.091)\tLoss 1.0920 (0.6894)\tAcc 0.500 (0.711)\n",
      "Epoch: [78][9/18]\tTime 0.074 (0.110)\tData 0.052 (0.086)\tLoss 0.1743 (0.6322)\tAcc 1.000 (0.743)\n",
      "Epoch: [78][10/18]\tTime 0.078 (0.107)\tData 0.055 (0.083)\tLoss 1.2726 (0.6962)\tAcc 0.500 (0.719)\n",
      "Epoch: [78][11/18]\tTime 0.076 (0.104)\tData 0.053 (0.080)\tLoss 1.2651 (0.7480)\tAcc 0.375 (0.688)\n",
      "Epoch: [78][12/18]\tTime 0.079 (0.102)\tData 0.058 (0.079)\tLoss 0.7654 (0.7494)\tAcc 0.750 (0.693)\n",
      "Epoch: [78][13/18]\tTime 0.081 (0.100)\tData 0.060 (0.077)\tLoss 1.0862 (0.7753)\tAcc 0.688 (0.692)\n",
      "Epoch: [78][14/18]\tTime 0.080 (0.099)\tData 0.060 (0.076)\tLoss 0.8554 (0.7810)\tAcc 0.562 (0.683)\n",
      "Epoch: [78][15/18]\tTime 0.080 (0.098)\tData 0.060 (0.075)\tLoss 0.7217 (0.7771)\tAcc 0.750 (0.688)\n",
      "Epoch: [78][16/18]\tTime 0.077 (0.096)\tData 0.057 (0.074)\tLoss 0.8237 (0.7800)\tAcc 0.812 (0.695)\n",
      "Epoch: [78][17/18]\tTime 0.079 (0.095)\tData 0.058 (0.073)\tLoss 0.9851 (0.7921)\tAcc 0.625 (0.691)\n",
      "Epoch: [78][18/18]\tTime 0.080 (0.095)\tData 0.060 (0.072)\tLoss 0.5773 (0.7859)\tAcc 1.000 (0.700)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/12]\tTime 0.282 (0.282)\tData 0.251 (0.251)\tLoss 0.9610 (0.9610)\tAcc 0.500 (0.500)\n",
      "Epoch: [79][2/12]\tTime 0.081 (0.182)\tData 0.055 (0.153)\tLoss 0.5631 (0.7621)\tAcc 0.812 (0.656)\n",
      "Epoch: [79][3/12]\tTime 0.087 (0.150)\tData 0.060 (0.122)\tLoss 0.8700 (0.7980)\tAcc 0.688 (0.667)\n",
      "Epoch: [79][4/12]\tTime 0.092 (0.135)\tData 0.061 (0.107)\tLoss 1.0035 (0.8494)\tAcc 0.625 (0.656)\n",
      "Epoch: [79][5/12]\tTime 0.097 (0.128)\tData 0.058 (0.097)\tLoss 0.8649 (0.8525)\tAcc 0.625 (0.650)\n",
      "Epoch: [79][6/12]\tTime 0.076 (0.119)\tData 0.048 (0.089)\tLoss 0.5952 (0.8096)\tAcc 0.750 (0.667)\n",
      "Epoch: [79][7/12]\tTime 0.085 (0.114)\tData 0.059 (0.085)\tLoss 0.5076 (0.7665)\tAcc 0.938 (0.705)\n",
      "Epoch: [79][8/12]\tTime 0.085 (0.111)\tData 0.060 (0.082)\tLoss 0.6453 (0.7513)\tAcc 0.688 (0.703)\n",
      "Epoch: [79][9/12]\tTime 0.087 (0.108)\tData 0.062 (0.079)\tLoss 0.6644 (0.7417)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [79][10/12]\tTime 0.084 (0.106)\tData 0.060 (0.077)\tLoss 0.4600 (0.7135)\tAcc 0.875 (0.725)\n",
      "Epoch: [79][11/12]\tTime 0.082 (0.103)\tData 0.059 (0.076)\tLoss 0.6035 (0.7035)\tAcc 0.750 (0.727)\n",
      "Epoch: [79][12/12]\tTime 0.078 (0.101)\tData 0.055 (0.074)\tLoss 0.7215 (0.7049)\tAcc 0.733 (0.728)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/18]\tTime 0.280 (0.280)\tData 0.254 (0.254)\tLoss 0.3444 (0.3444)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/18]\tTime 0.071 (0.176)\tData 0.050 (0.152)\tLoss 0.9216 (0.6330)\tAcc 0.438 (0.688)\n",
      "Epoch: [79][3/18]\tTime 0.074 (0.142)\tData 0.053 (0.119)\tLoss 0.6702 (0.6454)\tAcc 0.750 (0.708)\n",
      "Epoch: [79][4/18]\tTime 0.092 (0.129)\tData 0.053 (0.103)\tLoss 0.7096 (0.6614)\tAcc 0.625 (0.688)\n",
      "Epoch: [79][5/18]\tTime 0.065 (0.116)\tData 0.042 (0.090)\tLoss 0.8712 (0.7034)\tAcc 0.688 (0.688)\n",
      "Epoch: [79][6/18]\tTime 0.090 (0.112)\tData 0.061 (0.085)\tLoss 0.3384 (0.6426)\tAcc 0.938 (0.729)\n",
      "Epoch: [79][7/18]\tTime 0.089 (0.109)\tData 0.051 (0.081)\tLoss 0.6840 (0.6485)\tAcc 0.688 (0.723)\n",
      "Epoch: [79][8/18]\tTime 0.064 (0.103)\tData 0.042 (0.076)\tLoss 1.0690 (0.7011)\tAcc 0.562 (0.703)\n",
      "Epoch: [79][9/18]\tTime 0.080 (0.101)\tData 0.059 (0.074)\tLoss 0.2226 (0.6479)\tAcc 1.000 (0.736)\n",
      "Epoch: [79][10/18]\tTime 0.085 (0.099)\tData 0.058 (0.072)\tLoss 1.4220 (0.7253)\tAcc 0.375 (0.700)\n",
      "Epoch: [79][11/18]\tTime 0.074 (0.097)\tData 0.053 (0.071)\tLoss 1.0768 (0.7572)\tAcc 0.375 (0.670)\n",
      "Epoch: [79][12/18]\tTime 0.074 (0.095)\tData 0.054 (0.069)\tLoss 0.8160 (0.7621)\tAcc 0.625 (0.667)\n",
      "Epoch: [79][13/18]\tTime 0.074 (0.093)\tData 0.053 (0.068)\tLoss 1.1103 (0.7889)\tAcc 0.625 (0.663)\n",
      "Epoch: [79][14/18]\tTime 0.076 (0.092)\tData 0.056 (0.067)\tLoss 0.7555 (0.7865)\tAcc 0.625 (0.661)\n",
      "Epoch: [79][15/18]\tTime 0.080 (0.091)\tData 0.060 (0.067)\tLoss 1.0733 (0.8057)\tAcc 0.625 (0.658)\n",
      "Epoch: [79][16/18]\tTime 0.080 (0.091)\tData 0.060 (0.066)\tLoss 0.6969 (0.7989)\tAcc 0.688 (0.660)\n",
      "Epoch: [79][17/18]\tTime 0.080 (0.090)\tData 0.060 (0.066)\tLoss 0.8575 (0.8023)\tAcc 0.625 (0.658)\n",
      "Epoch: [79][18/18]\tTime 0.080 (0.089)\tData 0.060 (0.066)\tLoss 0.7107 (0.7997)\tAcc 0.750 (0.661)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/12]\tTime 0.239 (0.239)\tData 0.201 (0.201)\tLoss 0.5886 (0.5886)\tAcc 0.812 (0.812)\n",
      "Epoch: [80][2/12]\tTime 0.114 (0.176)\tData 0.079 (0.140)\tLoss 0.7326 (0.6606)\tAcc 0.688 (0.750)\n",
      "Epoch: [80][3/12]\tTime 0.079 (0.144)\tData 0.052 (0.111)\tLoss 0.6059 (0.6424)\tAcc 0.812 (0.771)\n",
      "Epoch: [80][4/12]\tTime 0.081 (0.128)\tData 0.053 (0.096)\tLoss 0.4753 (0.6006)\tAcc 0.812 (0.781)\n",
      "Epoch: [80][5/12]\tTime 0.083 (0.119)\tData 0.055 (0.088)\tLoss 0.7567 (0.6318)\tAcc 0.688 (0.762)\n",
      "Epoch: [80][6/12]\tTime 0.079 (0.112)\tData 0.053 (0.082)\tLoss 0.5400 (0.6165)\tAcc 0.750 (0.760)\n",
      "Epoch: [80][7/12]\tTime 0.086 (0.109)\tData 0.060 (0.079)\tLoss 0.7378 (0.6338)\tAcc 0.625 (0.741)\n",
      "Epoch: [80][8/12]\tTime 0.085 (0.106)\tData 0.061 (0.077)\tLoss 0.7686 (0.6507)\tAcc 0.688 (0.734)\n",
      "Epoch: [80][9/12]\tTime 0.086 (0.104)\tData 0.062 (0.075)\tLoss 1.2354 (0.7157)\tAcc 0.562 (0.715)\n",
      "Epoch: [80][10/12]\tTime 0.079 (0.101)\tData 0.056 (0.073)\tLoss 0.6411 (0.7082)\tAcc 0.812 (0.725)\n",
      "Epoch: [80][11/12]\tTime 0.079 (0.099)\tData 0.056 (0.072)\tLoss 0.7712 (0.7139)\tAcc 0.688 (0.722)\n",
      "Epoch: [80][12/12]\tTime 0.080 (0.097)\tData 0.056 (0.070)\tLoss 0.6514 (0.7090)\tAcc 0.667 (0.717)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/18]\tTime 0.321 (0.321)\tData 0.294 (0.294)\tLoss 0.4144 (0.4144)\tAcc 0.875 (0.875)\n",
      "Epoch: [80][2/18]\tTime 0.070 (0.196)\tData 0.048 (0.171)\tLoss 1.0829 (0.7487)\tAcc 0.438 (0.656)\n",
      "Epoch: [80][3/18]\tTime 0.078 (0.157)\tData 0.057 (0.133)\tLoss 0.7673 (0.7549)\tAcc 0.688 (0.667)\n",
      "Epoch: [80][4/18]\tTime 0.080 (0.137)\tData 0.058 (0.114)\tLoss 0.7074 (0.7430)\tAcc 0.625 (0.656)\n",
      "Epoch: [80][5/18]\tTime 0.085 (0.127)\tData 0.059 (0.103)\tLoss 0.8731 (0.7690)\tAcc 0.688 (0.663)\n",
      "Epoch: [80][6/18]\tTime 0.076 (0.118)\tData 0.054 (0.095)\tLoss 0.3566 (0.7003)\tAcc 1.000 (0.719)\n",
      "Epoch: [80][7/18]\tTime 0.081 (0.113)\tData 0.059 (0.090)\tLoss 0.6523 (0.6934)\tAcc 0.625 (0.705)\n",
      "Epoch: [80][8/18]\tTime 0.082 (0.109)\tData 0.059 (0.086)\tLoss 1.0177 (0.7340)\tAcc 0.562 (0.688)\n",
      "Epoch: [80][9/18]\tTime 0.080 (0.106)\tData 0.057 (0.083)\tLoss 0.1847 (0.6729)\tAcc 1.000 (0.722)\n",
      "Epoch: [80][10/18]\tTime 0.084 (0.104)\tData 0.058 (0.080)\tLoss 1.1956 (0.7252)\tAcc 0.562 (0.706)\n",
      "Epoch: [80][11/18]\tTime 0.077 (0.101)\tData 0.055 (0.078)\tLoss 1.2427 (0.7722)\tAcc 0.375 (0.676)\n",
      "Epoch: [80][12/18]\tTime 0.077 (0.099)\tData 0.057 (0.076)\tLoss 0.9675 (0.7885)\tAcc 0.625 (0.672)\n",
      "Epoch: [80][13/18]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 1.0712 (0.8103)\tAcc 0.500 (0.659)\n",
      "Epoch: [80][14/18]\tTime 0.077 (0.096)\tData 0.057 (0.074)\tLoss 0.7911 (0.8089)\tAcc 0.562 (0.652)\n",
      "Epoch: [80][15/18]\tTime 0.080 (0.095)\tData 0.061 (0.073)\tLoss 1.2265 (0.8367)\tAcc 0.562 (0.646)\n",
      "Epoch: [80][16/18]\tTime 0.077 (0.094)\tData 0.058 (0.072)\tLoss 0.8105 (0.8351)\tAcc 0.688 (0.648)\n",
      "Epoch: [80][17/18]\tTime 0.077 (0.093)\tData 0.058 (0.071)\tLoss 0.8295 (0.8348)\tAcc 0.688 (0.651)\n",
      "Epoch: [80][18/18]\tTime 0.078 (0.092)\tData 0.060 (0.070)\tLoss 0.7608 (0.8326)\tAcc 0.750 (0.654)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/12]\tTime 0.329 (0.329)\tData 0.286 (0.286)\tLoss 0.9618 (0.9618)\tAcc 0.500 (0.500)\n",
      "Epoch: [81][2/12]\tTime 0.076 (0.203)\tData 0.047 (0.167)\tLoss 0.6360 (0.7989)\tAcc 0.750 (0.625)\n",
      "Epoch: [81][3/12]\tTime 0.077 (0.161)\tData 0.051 (0.128)\tLoss 1.0128 (0.8702)\tAcc 0.688 (0.646)\n",
      "Epoch: [81][4/12]\tTime 0.080 (0.141)\tData 0.052 (0.109)\tLoss 0.6109 (0.8054)\tAcc 0.750 (0.672)\n",
      "Epoch: [81][5/12]\tTime 0.081 (0.129)\tData 0.053 (0.098)\tLoss 0.3682 (0.7180)\tAcc 0.938 (0.725)\n",
      "Epoch: [81][6/12]\tTime 0.078 (0.120)\tData 0.052 (0.090)\tLoss 0.5758 (0.6943)\tAcc 0.875 (0.750)\n",
      "Epoch: [81][7/12]\tTime 0.081 (0.115)\tData 0.053 (0.085)\tLoss 0.6486 (0.6877)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][8/12]\tTime 0.083 (0.111)\tData 0.059 (0.082)\tLoss 0.7082 (0.6903)\tAcc 0.688 (0.742)\n",
      "Epoch: [81][9/12]\tTime 0.079 (0.107)\tData 0.055 (0.079)\tLoss 0.7253 (0.6942)\tAcc 0.750 (0.743)\n",
      "Epoch: [81][10/12]\tTime 0.078 (0.104)\tData 0.054 (0.076)\tLoss 0.7542 (0.7002)\tAcc 0.625 (0.731)\n",
      "Epoch: [81][11/12]\tTime 0.086 (0.103)\tData 0.061 (0.075)\tLoss 0.5887 (0.6901)\tAcc 0.688 (0.727)\n",
      "Epoch: [81][12/12]\tTime 0.087 (0.101)\tData 0.062 (0.074)\tLoss 0.9401 (0.7097)\tAcc 0.600 (0.717)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/18]\tTime 0.311 (0.311)\tData 0.285 (0.285)\tLoss 0.4233 (0.4233)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/18]\tTime 0.073 (0.192)\tData 0.052 (0.169)\tLoss 1.0154 (0.7193)\tAcc 0.438 (0.688)\n",
      "Epoch: [81][3/18]\tTime 0.080 (0.155)\tData 0.060 (0.132)\tLoss 0.6439 (0.6942)\tAcc 0.812 (0.729)\n",
      "Epoch: [81][4/18]\tTime 0.078 (0.136)\tData 0.055 (0.113)\tLoss 0.6610 (0.6859)\tAcc 0.625 (0.703)\n",
      "Epoch: [81][5/18]\tTime 0.075 (0.123)\tData 0.053 (0.101)\tLoss 0.6941 (0.6875)\tAcc 0.750 (0.713)\n",
      "Epoch: [81][6/18]\tTime 0.075 (0.115)\tData 0.054 (0.093)\tLoss 0.3262 (0.6273)\tAcc 0.938 (0.750)\n",
      "Epoch: [81][7/18]\tTime 0.075 (0.110)\tData 0.053 (0.087)\tLoss 0.6663 (0.6329)\tAcc 0.688 (0.741)\n",
      "Epoch: [81][8/18]\tTime 0.079 (0.106)\tData 0.057 (0.083)\tLoss 1.0610 (0.6864)\tAcc 0.562 (0.719)\n",
      "Epoch: [81][9/18]\tTime 0.081 (0.103)\tData 0.060 (0.081)\tLoss 0.1778 (0.6299)\tAcc 1.000 (0.750)\n",
      "Epoch: [81][10/18]\tTime 0.077 (0.100)\tData 0.054 (0.078)\tLoss 1.2207 (0.6890)\tAcc 0.500 (0.725)\n",
      "Epoch: [81][11/18]\tTime 0.075 (0.098)\tData 0.053 (0.076)\tLoss 1.4660 (0.7596)\tAcc 0.375 (0.693)\n",
      "Epoch: [81][12/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.8940 (0.7708)\tAcc 0.562 (0.682)\n",
      "Epoch: [81][13/18]\tTime 0.076 (0.094)\tData 0.055 (0.072)\tLoss 1.1471 (0.7998)\tAcc 0.688 (0.683)\n",
      "Epoch: [81][14/18]\tTime 0.075 (0.093)\tData 0.054 (0.071)\tLoss 0.8714 (0.8049)\tAcc 0.625 (0.679)\n",
      "Epoch: [81][15/18]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.7123 (0.7987)\tAcc 0.750 (0.683)\n",
      "Epoch: [81][16/18]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.7845 (0.7978)\tAcc 0.750 (0.688)\n",
      "Epoch: [81][17/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.7948 (0.7976)\tAcc 0.625 (0.684)\n",
      "Epoch: [81][18/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.6988 (0.7948)\tAcc 0.750 (0.686)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/12]\tTime 0.363 (0.363)\tData 0.327 (0.327)\tLoss 0.8138 (0.8138)\tAcc 0.688 (0.688)\n",
      "Epoch: [82][2/12]\tTime 0.070 (0.217)\tData 0.044 (0.185)\tLoss 0.6981 (0.7559)\tAcc 0.750 (0.719)\n",
      "Epoch: [82][3/12]\tTime 0.089 (0.174)\tData 0.054 (0.142)\tLoss 0.5965 (0.7028)\tAcc 0.688 (0.708)\n",
      "Epoch: [82][4/12]\tTime 0.072 (0.149)\tData 0.047 (0.118)\tLoss 0.7068 (0.7038)\tAcc 0.688 (0.703)\n",
      "Epoch: [82][5/12]\tTime 0.082 (0.135)\tData 0.056 (0.106)\tLoss 0.6305 (0.6891)\tAcc 0.688 (0.700)\n",
      "Epoch: [82][6/12]\tTime 0.080 (0.126)\tData 0.054 (0.097)\tLoss 0.3874 (0.6388)\tAcc 0.875 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [82][7/12]\tTime 0.079 (0.119)\tData 0.053 (0.091)\tLoss 0.9357 (0.6812)\tAcc 0.688 (0.723)\n",
      "Epoch: [82][8/12]\tTime 0.079 (0.114)\tData 0.055 (0.086)\tLoss 0.8124 (0.6976)\tAcc 0.750 (0.727)\n",
      "Epoch: [82][9/12]\tTime 0.082 (0.111)\tData 0.058 (0.083)\tLoss 0.6098 (0.6879)\tAcc 0.688 (0.722)\n",
      "Epoch: [82][10/12]\tTime 0.081 (0.108)\tData 0.058 (0.081)\tLoss 0.7477 (0.6939)\tAcc 0.688 (0.719)\n",
      "Epoch: [82][11/12]\tTime 0.081 (0.105)\tData 0.057 (0.078)\tLoss 0.8847 (0.7112)\tAcc 0.625 (0.710)\n",
      "Epoch: [82][12/12]\tTime 0.079 (0.103)\tData 0.056 (0.077)\tLoss 0.8089 (0.7189)\tAcc 0.800 (0.717)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/18]\tTime 0.302 (0.302)\tData 0.277 (0.277)\tLoss 0.3156 (0.3156)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/18]\tTime 0.071 (0.186)\tData 0.050 (0.163)\tLoss 0.9866 (0.6511)\tAcc 0.438 (0.688)\n",
      "Epoch: [82][3/18]\tTime 0.074 (0.149)\tData 0.053 (0.127)\tLoss 0.6100 (0.6374)\tAcc 0.812 (0.729)\n",
      "Epoch: [82][4/18]\tTime 0.074 (0.130)\tData 0.053 (0.108)\tLoss 0.5974 (0.6274)\tAcc 0.688 (0.719)\n",
      "Epoch: [82][5/18]\tTime 0.078 (0.120)\tData 0.057 (0.098)\tLoss 0.9525 (0.6924)\tAcc 0.562 (0.688)\n",
      "Epoch: [82][6/18]\tTime 0.075 (0.112)\tData 0.054 (0.091)\tLoss 0.3482 (0.6350)\tAcc 1.000 (0.740)\n",
      "Epoch: [82][7/18]\tTime 0.075 (0.107)\tData 0.053 (0.085)\tLoss 0.7467 (0.6510)\tAcc 0.562 (0.714)\n",
      "Epoch: [82][8/18]\tTime 0.074 (0.103)\tData 0.053 (0.081)\tLoss 1.0172 (0.6968)\tAcc 0.625 (0.703)\n",
      "Epoch: [82][9/18]\tTime 0.076 (0.100)\tData 0.055 (0.078)\tLoss 0.1936 (0.6408)\tAcc 1.000 (0.736)\n",
      "Epoch: [82][10/18]\tTime 0.074 (0.097)\tData 0.053 (0.076)\tLoss 1.1739 (0.6942)\tAcc 0.438 (0.706)\n",
      "Epoch: [82][11/18]\tTime 0.075 (0.095)\tData 0.054 (0.074)\tLoss 1.3168 (0.7508)\tAcc 0.375 (0.676)\n",
      "Epoch: [82][12/18]\tTime 0.074 (0.093)\tData 0.053 (0.072)\tLoss 0.9495 (0.7673)\tAcc 0.625 (0.672)\n",
      "Epoch: [82][13/18]\tTime 0.072 (0.092)\tData 0.052 (0.070)\tLoss 1.2227 (0.8023)\tAcc 0.500 (0.659)\n",
      "Epoch: [82][14/18]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 0.8372 (0.8048)\tAcc 0.625 (0.656)\n",
      "Epoch: [82][15/18]\tTime 0.076 (0.090)\tData 0.056 (0.068)\tLoss 0.9486 (0.8144)\tAcc 0.688 (0.658)\n",
      "Epoch: [82][16/18]\tTime 0.079 (0.089)\tData 0.059 (0.068)\tLoss 0.8232 (0.8150)\tAcc 0.750 (0.664)\n",
      "Epoch: [82][17/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.9116 (0.8207)\tAcc 0.562 (0.658)\n",
      "Epoch: [82][18/18]\tTime 0.080 (0.088)\tData 0.060 (0.067)\tLoss 0.6528 (0.8159)\tAcc 0.875 (0.664)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/12]\tTime 0.319 (0.319)\tData 0.285 (0.285)\tLoss 0.8644 (0.8644)\tAcc 0.625 (0.625)\n",
      "Epoch: [83][2/12]\tTime 0.110 (0.215)\tData 0.079 (0.182)\tLoss 0.7767 (0.8206)\tAcc 0.750 (0.688)\n",
      "Epoch: [83][3/12]\tTime 0.082 (0.170)\tData 0.054 (0.139)\tLoss 0.6036 (0.7482)\tAcc 0.750 (0.708)\n",
      "Epoch: [83][4/12]\tTime 0.080 (0.148)\tData 0.052 (0.117)\tLoss 0.8818 (0.7816)\tAcc 0.562 (0.672)\n",
      "Epoch: [83][5/12]\tTime 0.078 (0.134)\tData 0.052 (0.104)\tLoss 0.5114 (0.7276)\tAcc 0.938 (0.725)\n",
      "Epoch: [83][6/12]\tTime 0.079 (0.125)\tData 0.053 (0.096)\tLoss 0.7320 (0.7283)\tAcc 0.688 (0.719)\n",
      "Epoch: [83][7/12]\tTime 0.077 (0.118)\tData 0.052 (0.089)\tLoss 0.6885 (0.7226)\tAcc 0.750 (0.723)\n",
      "Epoch: [83][8/12]\tTime 0.079 (0.113)\tData 0.055 (0.085)\tLoss 0.4408 (0.6874)\tAcc 0.812 (0.734)\n",
      "Epoch: [83][9/12]\tTime 0.078 (0.109)\tData 0.054 (0.082)\tLoss 0.9279 (0.7141)\tAcc 0.625 (0.722)\n",
      "Epoch: [83][10/12]\tTime 0.080 (0.106)\tData 0.056 (0.079)\tLoss 0.6446 (0.7072)\tAcc 0.812 (0.731)\n",
      "Epoch: [83][11/12]\tTime 0.080 (0.104)\tData 0.056 (0.077)\tLoss 0.7913 (0.7148)\tAcc 0.750 (0.733)\n",
      "Epoch: [83][12/12]\tTime 0.078 (0.102)\tData 0.054 (0.075)\tLoss 0.7993 (0.7215)\tAcc 0.667 (0.728)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/18]\tTime 0.397 (0.397)\tData 0.373 (0.373)\tLoss 0.3470 (0.3470)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/18]\tTime 0.075 (0.236)\tData 0.050 (0.212)\tLoss 0.9436 (0.6453)\tAcc 0.438 (0.688)\n",
      "Epoch: [83][3/18]\tTime 0.070 (0.181)\tData 0.050 (0.158)\tLoss 0.6813 (0.6573)\tAcc 0.812 (0.729)\n",
      "Epoch: [83][4/18]\tTime 0.074 (0.154)\tData 0.053 (0.132)\tLoss 0.7112 (0.6708)\tAcc 0.625 (0.703)\n",
      "Epoch: [83][5/18]\tTime 0.075 (0.138)\tData 0.054 (0.116)\tLoss 0.8514 (0.7069)\tAcc 0.688 (0.700)\n",
      "Epoch: [83][6/18]\tTime 0.074 (0.128)\tData 0.054 (0.106)\tLoss 0.2876 (0.6370)\tAcc 1.000 (0.750)\n",
      "Epoch: [83][7/18]\tTime 0.074 (0.120)\tData 0.054 (0.098)\tLoss 0.8184 (0.6629)\tAcc 0.625 (0.732)\n",
      "Epoch: [83][8/18]\tTime 0.075 (0.114)\tData 0.054 (0.093)\tLoss 0.9984 (0.7049)\tAcc 0.688 (0.727)\n",
      "Epoch: [83][9/18]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 0.1966 (0.6484)\tAcc 1.000 (0.757)\n",
      "Epoch: [83][10/18]\tTime 0.074 (0.106)\tData 0.053 (0.085)\tLoss 1.1359 (0.6971)\tAcc 0.500 (0.731)\n",
      "Epoch: [83][11/18]\tTime 0.074 (0.103)\tData 0.054 (0.082)\tLoss 1.2823 (0.7503)\tAcc 0.375 (0.699)\n",
      "Epoch: [83][12/18]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.8184 (0.7560)\tAcc 0.625 (0.693)\n",
      "Epoch: [83][13/18]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.9749 (0.7728)\tAcc 0.750 (0.697)\n",
      "Epoch: [83][14/18]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 0.8708 (0.7798)\tAcc 0.625 (0.692)\n",
      "Epoch: [83][15/18]\tTime 0.073 (0.095)\tData 0.055 (0.075)\tLoss 0.8810 (0.7866)\tAcc 0.625 (0.688)\n",
      "Epoch: [83][16/18]\tTime 0.073 (0.094)\tData 0.055 (0.074)\tLoss 0.9022 (0.7938)\tAcc 0.688 (0.688)\n",
      "Epoch: [83][17/18]\tTime 0.075 (0.093)\tData 0.056 (0.073)\tLoss 0.9096 (0.8006)\tAcc 0.625 (0.684)\n",
      "Epoch: [83][18/18]\tTime 0.074 (0.092)\tData 0.056 (0.072)\tLoss 0.5509 (0.7935)\tAcc 0.875 (0.689)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/12]\tTime 0.367 (0.367)\tData 0.337 (0.337)\tLoss 0.3794 (0.3794)\tAcc 1.000 (1.000)\n",
      "Epoch: [84][2/12]\tTime 0.076 (0.222)\tData 0.050 (0.193)\tLoss 0.5845 (0.4820)\tAcc 0.688 (0.844)\n",
      "Epoch: [84][3/12]\tTime 0.081 (0.175)\tData 0.052 (0.146)\tLoss 0.9600 (0.6413)\tAcc 0.562 (0.750)\n",
      "Epoch: [84][4/12]\tTime 0.080 (0.151)\tData 0.054 (0.123)\tLoss 0.8858 (0.7024)\tAcc 0.562 (0.703)\n",
      "Epoch: [84][5/12]\tTime 0.083 (0.138)\tData 0.056 (0.110)\tLoss 0.6996 (0.7019)\tAcc 0.625 (0.688)\n",
      "Epoch: [84][6/12]\tTime 0.077 (0.127)\tData 0.052 (0.100)\tLoss 0.6635 (0.6955)\tAcc 0.812 (0.708)\n",
      "Epoch: [84][7/12]\tTime 0.079 (0.121)\tData 0.053 (0.094)\tLoss 0.9769 (0.7357)\tAcc 0.625 (0.696)\n",
      "Epoch: [84][8/12]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.7495 (0.7374)\tAcc 0.562 (0.680)\n",
      "Epoch: [84][9/12]\tTime 0.077 (0.111)\tData 0.054 (0.085)\tLoss 0.6724 (0.7302)\tAcc 0.812 (0.694)\n",
      "Epoch: [84][10/12]\tTime 0.080 (0.108)\tData 0.057 (0.082)\tLoss 0.8495 (0.7421)\tAcc 0.688 (0.694)\n",
      "Epoch: [84][11/12]\tTime 0.081 (0.105)\tData 0.057 (0.080)\tLoss 0.7341 (0.7414)\tAcc 0.750 (0.699)\n",
      "Epoch: [84][12/12]\tTime 0.081 (0.103)\tData 0.058 (0.078)\tLoss 0.4307 (0.7170)\tAcc 0.867 (0.712)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/18]\tTime 0.254 (0.254)\tData 0.229 (0.229)\tLoss 0.3283 (0.3283)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/18]\tTime 0.077 (0.165)\tData 0.056 (0.143)\tLoss 0.9214 (0.6249)\tAcc 0.438 (0.688)\n",
      "Epoch: [84][3/18]\tTime 0.097 (0.143)\tData 0.076 (0.120)\tLoss 0.5936 (0.6145)\tAcc 0.938 (0.771)\n",
      "Epoch: [84][4/18]\tTime 0.079 (0.127)\tData 0.057 (0.105)\tLoss 0.6115 (0.6137)\tAcc 0.688 (0.750)\n",
      "Epoch: [84][5/18]\tTime 0.077 (0.117)\tData 0.054 (0.095)\tLoss 0.7820 (0.6474)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][6/18]\tTime 0.072 (0.109)\tData 0.051 (0.087)\tLoss 0.3551 (0.5987)\tAcc 1.000 (0.792)\n",
      "Epoch: [84][7/18]\tTime 0.077 (0.105)\tData 0.053 (0.082)\tLoss 0.8268 (0.6313)\tAcc 0.500 (0.750)\n",
      "Epoch: [84][8/18]\tTime 0.073 (0.101)\tData 0.052 (0.079)\tLoss 1.1226 (0.6927)\tAcc 0.500 (0.719)\n",
      "Epoch: [84][9/18]\tTime 0.074 (0.098)\tData 0.053 (0.076)\tLoss 0.2058 (0.6386)\tAcc 1.000 (0.750)\n",
      "Epoch: [84][10/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 1.1514 (0.6899)\tAcc 0.562 (0.731)\n",
      "Epoch: [84][11/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 1.4684 (0.7606)\tAcc 0.375 (0.699)\n",
      "Epoch: [84][12/18]\tTime 0.074 (0.092)\tData 0.053 (0.070)\tLoss 0.9511 (0.7765)\tAcc 0.688 (0.698)\n",
      "Epoch: [84][13/18]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.9272 (0.7881)\tAcc 0.688 (0.697)\n",
      "Epoch: [84][14/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.8202 (0.7904)\tAcc 0.562 (0.688)\n",
      "Epoch: [84][15/18]\tTime 0.075 (0.088)\tData 0.056 (0.067)\tLoss 0.8682 (0.7956)\tAcc 0.750 (0.692)\n",
      "Epoch: [84][16/18]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.6466 (0.7863)\tAcc 0.812 (0.699)\n",
      "Epoch: [84][17/18]\tTime 0.078 (0.087)\tData 0.059 (0.066)\tLoss 0.7644 (0.7850)\tAcc 0.625 (0.695)\n",
      "Epoch: [84][18/18]\tTime 0.077 (0.086)\tData 0.059 (0.065)\tLoss 0.7752 (0.7847)\tAcc 0.875 (0.700)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/12]\tTime 0.279 (0.279)\tData 0.249 (0.249)\tLoss 0.5872 (0.5872)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/12]\tTime 0.078 (0.178)\tData 0.050 (0.149)\tLoss 0.8341 (0.7106)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][3/12]\tTime 0.077 (0.144)\tData 0.051 (0.117)\tLoss 0.7871 (0.7361)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [85][4/12]\tTime 0.081 (0.128)\tData 0.053 (0.101)\tLoss 1.0759 (0.8211)\tAcc 0.562 (0.672)\n",
      "Epoch: [85][5/12]\tTime 0.079 (0.119)\tData 0.054 (0.091)\tLoss 0.7505 (0.8069)\tAcc 0.812 (0.700)\n",
      "Epoch: [85][6/12]\tTime 0.080 (0.112)\tData 0.053 (0.085)\tLoss 0.8254 (0.8100)\tAcc 0.750 (0.708)\n",
      "Epoch: [85][7/12]\tTime 0.085 (0.108)\tData 0.059 (0.081)\tLoss 0.4858 (0.7637)\tAcc 0.750 (0.714)\n",
      "Epoch: [85][8/12]\tTime 0.078 (0.104)\tData 0.055 (0.078)\tLoss 0.3893 (0.7169)\tAcc 0.938 (0.742)\n",
      "Epoch: [85][9/12]\tTime 0.077 (0.101)\tData 0.055 (0.075)\tLoss 0.7483 (0.7204)\tAcc 0.688 (0.736)\n",
      "Epoch: [85][10/12]\tTime 0.078 (0.099)\tData 0.055 (0.073)\tLoss 0.7838 (0.7267)\tAcc 0.688 (0.731)\n",
      "Epoch: [85][11/12]\tTime 0.083 (0.098)\tData 0.060 (0.072)\tLoss 0.8246 (0.7356)\tAcc 0.688 (0.727)\n",
      "Epoch: [85][12/12]\tTime 0.080 (0.096)\tData 0.057 (0.071)\tLoss 1.0269 (0.7585)\tAcc 0.667 (0.723)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/18]\tTime 0.265 (0.265)\tData 0.241 (0.241)\tLoss 0.3163 (0.3163)\tAcc 0.938 (0.938)\n",
      "Epoch: [85][2/18]\tTime 0.094 (0.180)\tData 0.073 (0.157)\tLoss 1.0779 (0.6971)\tAcc 0.438 (0.688)\n",
      "Epoch: [85][3/18]\tTime 0.076 (0.145)\tData 0.055 (0.123)\tLoss 0.5172 (0.6372)\tAcc 0.938 (0.771)\n",
      "Epoch: [85][4/18]\tTime 0.080 (0.129)\tData 0.055 (0.106)\tLoss 0.6753 (0.6467)\tAcc 0.688 (0.750)\n",
      "Epoch: [85][5/18]\tTime 0.081 (0.119)\tData 0.058 (0.096)\tLoss 0.8885 (0.6951)\tAcc 0.625 (0.725)\n",
      "Epoch: [85][6/18]\tTime 0.074 (0.112)\tData 0.052 (0.089)\tLoss 0.2624 (0.6229)\tAcc 1.000 (0.771)\n",
      "Epoch: [85][7/18]\tTime 0.079 (0.107)\tData 0.059 (0.085)\tLoss 0.6981 (0.6337)\tAcc 0.625 (0.750)\n",
      "Epoch: [85][8/18]\tTime 0.080 (0.104)\tData 0.057 (0.081)\tLoss 1.1013 (0.6921)\tAcc 0.500 (0.719)\n",
      "Epoch: [85][9/18]\tTime 0.072 (0.100)\tData 0.051 (0.078)\tLoss 0.2387 (0.6417)\tAcc 1.000 (0.750)\n",
      "Epoch: [85][10/18]\tTime 0.073 (0.098)\tData 0.052 (0.075)\tLoss 1.1197 (0.6895)\tAcc 0.438 (0.719)\n",
      "Epoch: [85][11/18]\tTime 0.076 (0.096)\tData 0.055 (0.073)\tLoss 1.4533 (0.7590)\tAcc 0.375 (0.688)\n",
      "Epoch: [85][12/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 1.0646 (0.7844)\tAcc 0.625 (0.682)\n",
      "Epoch: [85][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.0513 (0.8050)\tAcc 0.625 (0.678)\n",
      "Epoch: [85][14/18]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.7609 (0.8018)\tAcc 0.562 (0.670)\n",
      "Epoch: [85][15/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.7744 (0.8000)\tAcc 0.750 (0.675)\n",
      "Epoch: [85][16/18]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.8742 (0.8046)\tAcc 0.688 (0.676)\n",
      "Epoch: [85][17/18]\tTime 0.080 (0.089)\tData 0.061 (0.067)\tLoss 0.8454 (0.8070)\tAcc 0.625 (0.673)\n",
      "Epoch: [85][18/18]\tTime 0.075 (0.088)\tData 0.056 (0.067)\tLoss 0.7819 (0.8063)\tAcc 0.750 (0.675)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/12]\tTime 0.302 (0.302)\tData 0.270 (0.270)\tLoss 0.5501 (0.5501)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][2/12]\tTime 0.075 (0.188)\tData 0.049 (0.159)\tLoss 0.6820 (0.6161)\tAcc 0.688 (0.719)\n",
      "Epoch: [86][3/12]\tTime 0.084 (0.154)\tData 0.058 (0.126)\tLoss 0.6903 (0.6408)\tAcc 0.688 (0.708)\n",
      "Epoch: [86][4/12]\tTime 0.081 (0.136)\tData 0.055 (0.108)\tLoss 0.5016 (0.6060)\tAcc 0.812 (0.734)\n",
      "Epoch: [86][5/12]\tTime 0.084 (0.125)\tData 0.058 (0.098)\tLoss 0.6932 (0.6235)\tAcc 0.688 (0.725)\n",
      "Epoch: [86][6/12]\tTime 0.085 (0.119)\tData 0.056 (0.091)\tLoss 1.0627 (0.6967)\tAcc 0.562 (0.698)\n",
      "Epoch: [86][7/12]\tTime 0.078 (0.113)\tData 0.054 (0.086)\tLoss 0.7252 (0.7007)\tAcc 0.812 (0.714)\n",
      "Epoch: [86][8/12]\tTime 0.086 (0.109)\tData 0.062 (0.083)\tLoss 0.7128 (0.7022)\tAcc 0.625 (0.703)\n",
      "Epoch: [86][9/12]\tTime 0.082 (0.106)\tData 0.059 (0.080)\tLoss 0.8964 (0.7238)\tAcc 0.562 (0.688)\n",
      "Epoch: [86][10/12]\tTime 0.084 (0.104)\tData 0.060 (0.078)\tLoss 0.5774 (0.7092)\tAcc 0.750 (0.694)\n",
      "Epoch: [86][11/12]\tTime 0.081 (0.102)\tData 0.057 (0.076)\tLoss 0.7846 (0.7160)\tAcc 0.688 (0.693)\n",
      "Epoch: [86][12/12]\tTime 0.078 (0.100)\tData 0.054 (0.074)\tLoss 0.6843 (0.7135)\tAcc 0.667 (0.691)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/18]\tTime 0.300 (0.300)\tData 0.275 (0.275)\tLoss 0.3476 (0.3476)\tAcc 0.875 (0.875)\n",
      "Epoch: [86][2/18]\tTime 0.072 (0.186)\tData 0.050 (0.163)\tLoss 1.0035 (0.6755)\tAcc 0.438 (0.656)\n",
      "Epoch: [86][3/18]\tTime 0.074 (0.148)\tData 0.053 (0.126)\tLoss 0.7538 (0.7016)\tAcc 0.750 (0.688)\n",
      "Epoch: [86][4/18]\tTime 0.076 (0.130)\tData 0.053 (0.108)\tLoss 0.7094 (0.7036)\tAcc 0.625 (0.672)\n",
      "Epoch: [86][5/18]\tTime 0.074 (0.119)\tData 0.052 (0.097)\tLoss 0.9120 (0.7452)\tAcc 0.625 (0.663)\n",
      "Epoch: [86][6/18]\tTime 0.076 (0.112)\tData 0.054 (0.090)\tLoss 0.3676 (0.6823)\tAcc 0.938 (0.708)\n",
      "Epoch: [86][7/18]\tTime 0.073 (0.106)\tData 0.052 (0.084)\tLoss 0.6274 (0.6745)\tAcc 0.750 (0.714)\n",
      "Epoch: [86][8/18]\tTime 0.086 (0.104)\tData 0.054 (0.081)\tLoss 0.9787 (0.7125)\tAcc 0.562 (0.695)\n",
      "Epoch: [86][9/18]\tTime 0.072 (0.100)\tData 0.051 (0.077)\tLoss 0.1555 (0.6506)\tAcc 1.000 (0.729)\n",
      "Epoch: [86][10/18]\tTime 0.074 (0.098)\tData 0.052 (0.075)\tLoss 1.1493 (0.7005)\tAcc 0.500 (0.706)\n",
      "Epoch: [86][11/18]\tTime 0.078 (0.096)\tData 0.054 (0.073)\tLoss 1.3013 (0.7551)\tAcc 0.375 (0.676)\n",
      "Epoch: [86][12/18]\tTime 0.074 (0.094)\tData 0.053 (0.071)\tLoss 1.1463 (0.7877)\tAcc 0.625 (0.672)\n",
      "Epoch: [86][13/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 1.1014 (0.8118)\tAcc 0.500 (0.659)\n",
      "Epoch: [86][14/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 1.0090 (0.8259)\tAcc 0.562 (0.652)\n",
      "Epoch: [86][15/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.9416 (0.8336)\tAcc 0.625 (0.650)\n",
      "Epoch: [86][16/18]\tTime 0.078 (0.089)\tData 0.058 (0.067)\tLoss 0.8140 (0.8324)\tAcc 0.688 (0.652)\n",
      "Epoch: [86][17/18]\tTime 0.076 (0.088)\tData 0.057 (0.067)\tLoss 0.8602 (0.8340)\tAcc 0.688 (0.654)\n",
      "Epoch: [86][18/18]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.5808 (0.8268)\tAcc 0.875 (0.661)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/12]\tTime 0.296 (0.296)\tData 0.261 (0.261)\tLoss 0.8560 (0.8560)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][2/12]\tTime 0.070 (0.183)\tData 0.044 (0.152)\tLoss 1.0564 (0.9562)\tAcc 0.562 (0.656)\n",
      "Epoch: [87][3/12]\tTime 0.080 (0.149)\tData 0.053 (0.119)\tLoss 0.5955 (0.8360)\tAcc 0.812 (0.708)\n",
      "Epoch: [87][4/12]\tTime 0.079 (0.131)\tData 0.051 (0.102)\tLoss 0.7042 (0.8030)\tAcc 0.812 (0.734)\n",
      "Epoch: [87][5/12]\tTime 0.077 (0.121)\tData 0.051 (0.092)\tLoss 0.7502 (0.7924)\tAcc 0.625 (0.713)\n",
      "Epoch: [87][6/12]\tTime 0.078 (0.114)\tData 0.053 (0.085)\tLoss 0.4490 (0.7352)\tAcc 0.938 (0.750)\n",
      "Epoch: [87][7/12]\tTime 0.078 (0.109)\tData 0.054 (0.081)\tLoss 0.8899 (0.7573)\tAcc 0.500 (0.714)\n",
      "Epoch: [87][8/12]\tTime 0.080 (0.105)\tData 0.056 (0.078)\tLoss 0.5003 (0.7252)\tAcc 0.812 (0.727)\n",
      "Epoch: [87][9/12]\tTime 0.077 (0.102)\tData 0.054 (0.075)\tLoss 0.7228 (0.7249)\tAcc 0.750 (0.729)\n",
      "Epoch: [87][10/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.5957 (0.7120)\tAcc 0.688 (0.725)\n",
      "Epoch: [87][11/12]\tTime 0.079 (0.098)\tData 0.056 (0.071)\tLoss 0.8651 (0.7259)\tAcc 0.562 (0.710)\n",
      "Epoch: [87][12/12]\tTime 0.078 (0.096)\tData 0.054 (0.070)\tLoss 0.6698 (0.7215)\tAcc 0.867 (0.723)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/18]\tTime 0.348 (0.348)\tData 0.323 (0.323)\tLoss 0.2687 (0.2687)\tAcc 0.938 (0.938)\n",
      "Epoch: [87][2/18]\tTime 0.075 (0.212)\tData 0.052 (0.188)\tLoss 0.9558 (0.6123)\tAcc 0.438 (0.688)\n",
      "Epoch: [87][3/18]\tTime 0.074 (0.166)\tData 0.052 (0.142)\tLoss 0.6555 (0.6267)\tAcc 0.750 (0.708)\n",
      "Epoch: [87][4/18]\tTime 0.074 (0.143)\tData 0.053 (0.120)\tLoss 0.5602 (0.6101)\tAcc 0.688 (0.703)\n",
      "Epoch: [87][5/18]\tTime 0.081 (0.131)\tData 0.060 (0.108)\tLoss 0.8264 (0.6533)\tAcc 0.688 (0.700)\n",
      "Epoch: [87][6/18]\tTime 0.080 (0.122)\tData 0.059 (0.100)\tLoss 0.2186 (0.5809)\tAcc 1.000 (0.750)\n",
      "Epoch: [87][7/18]\tTime 0.082 (0.116)\tData 0.060 (0.094)\tLoss 0.7318 (0.6024)\tAcc 0.625 (0.732)\n",
      "Epoch: [87][8/18]\tTime 0.080 (0.112)\tData 0.059 (0.090)\tLoss 0.9613 (0.6473)\tAcc 0.562 (0.711)\n",
      "Epoch: [87][9/18]\tTime 0.083 (0.109)\tData 0.056 (0.086)\tLoss 0.1585 (0.5930)\tAcc 1.000 (0.743)\n",
      "Epoch: [87][10/18]\tTime 0.075 (0.105)\tData 0.053 (0.083)\tLoss 1.2037 (0.6540)\tAcc 0.500 (0.719)\n",
      "Epoch: [87][11/18]\tTime 0.081 (0.103)\tData 0.058 (0.080)\tLoss 1.3622 (0.7184)\tAcc 0.375 (0.688)\n",
      "Epoch: [87][12/18]\tTime 0.079 (0.101)\tData 0.059 (0.079)\tLoss 0.9613 (0.7387)\tAcc 0.625 (0.682)\n",
      "Epoch: [87][13/18]\tTime 0.075 (0.099)\tData 0.055 (0.077)\tLoss 1.0813 (0.7650)\tAcc 0.500 (0.668)\n",
      "Epoch: [87][14/18]\tTime 0.075 (0.097)\tData 0.055 (0.075)\tLoss 0.8796 (0.7732)\tAcc 0.625 (0.665)\n",
      "Epoch: [87][15/18]\tTime 0.073 (0.096)\tData 0.054 (0.074)\tLoss 0.8285 (0.7769)\tAcc 0.688 (0.667)\n",
      "Epoch: [87][16/18]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.7311 (0.7740)\tAcc 0.688 (0.668)\n",
      "Epoch: [87][17/18]\tTime 0.075 (0.093)\tData 0.055 (0.072)\tLoss 0.8477 (0.7784)\tAcc 0.625 (0.665)\n",
      "Epoch: [87][18/18]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.9934 (0.7845)\tAcc 0.500 (0.661)\n",
      "train at epoch 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [88][1/12]\tTime 0.372 (0.372)\tData 0.342 (0.342)\tLoss 0.8673 (0.8673)\tAcc 0.688 (0.688)\n",
      "Epoch: [88][2/12]\tTime 0.077 (0.225)\tData 0.049 (0.195)\tLoss 0.5264 (0.6969)\tAcc 0.875 (0.781)\n",
      "Epoch: [88][3/12]\tTime 0.078 (0.176)\tData 0.050 (0.147)\tLoss 0.6026 (0.6654)\tAcc 0.750 (0.771)\n",
      "Epoch: [88][4/12]\tTime 0.078 (0.151)\tData 0.052 (0.123)\tLoss 0.6150 (0.6528)\tAcc 0.750 (0.766)\n",
      "Epoch: [88][5/12]\tTime 0.079 (0.137)\tData 0.053 (0.109)\tLoss 0.7543 (0.6731)\tAcc 0.812 (0.775)\n",
      "Epoch: [88][6/12]\tTime 0.083 (0.128)\tData 0.058 (0.101)\tLoss 0.8059 (0.6952)\tAcc 0.688 (0.760)\n",
      "Epoch: [88][7/12]\tTime 0.081 (0.121)\tData 0.057 (0.094)\tLoss 0.7433 (0.7021)\tAcc 0.750 (0.759)\n",
      "Epoch: [88][8/12]\tTime 0.079 (0.116)\tData 0.055 (0.090)\tLoss 0.7375 (0.7065)\tAcc 0.750 (0.758)\n",
      "Epoch: [88][9/12]\tTime 0.078 (0.112)\tData 0.054 (0.086)\tLoss 0.9633 (0.7351)\tAcc 0.625 (0.743)\n",
      "Epoch: [88][10/12]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.8310 (0.7447)\tAcc 0.688 (0.738)\n",
      "Epoch: [88][11/12]\tTime 0.079 (0.106)\tData 0.056 (0.080)\tLoss 1.0891 (0.7760)\tAcc 0.625 (0.727)\n",
      "Epoch: [88][12/12]\tTime 0.077 (0.103)\tData 0.054 (0.078)\tLoss 0.9973 (0.7934)\tAcc 0.600 (0.717)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/18]\tTime 0.319 (0.319)\tData 0.295 (0.295)\tLoss 0.3470 (0.3470)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/18]\tTime 0.071 (0.195)\tData 0.050 (0.173)\tLoss 0.9201 (0.6336)\tAcc 0.438 (0.688)\n",
      "Epoch: [88][3/18]\tTime 0.073 (0.155)\tData 0.053 (0.133)\tLoss 0.6606 (0.6426)\tAcc 0.750 (0.708)\n",
      "Epoch: [88][4/18]\tTime 0.074 (0.135)\tData 0.053 (0.113)\tLoss 0.7178 (0.6614)\tAcc 0.688 (0.703)\n",
      "Epoch: [88][5/18]\tTime 0.077 (0.123)\tData 0.054 (0.101)\tLoss 0.8911 (0.7073)\tAcc 0.688 (0.700)\n",
      "Epoch: [88][6/18]\tTime 0.076 (0.115)\tData 0.055 (0.093)\tLoss 0.3243 (0.6435)\tAcc 1.000 (0.750)\n",
      "Epoch: [88][7/18]\tTime 0.076 (0.110)\tData 0.055 (0.088)\tLoss 0.8099 (0.6673)\tAcc 0.500 (0.714)\n",
      "Epoch: [88][8/18]\tTime 0.075 (0.105)\tData 0.054 (0.084)\tLoss 1.0578 (0.7161)\tAcc 0.562 (0.695)\n",
      "Epoch: [88][9/18]\tTime 0.077 (0.102)\tData 0.056 (0.081)\tLoss 0.2092 (0.6598)\tAcc 1.000 (0.729)\n",
      "Epoch: [88][10/18]\tTime 0.078 (0.100)\tData 0.053 (0.078)\tLoss 1.2801 (0.7218)\tAcc 0.438 (0.700)\n",
      "Epoch: [88][11/18]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 1.3697 (0.7807)\tAcc 0.375 (0.670)\n",
      "Epoch: [88][12/18]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 1.0486 (0.8030)\tAcc 0.562 (0.661)\n",
      "Epoch: [88][13/18]\tTime 0.071 (0.094)\tData 0.053 (0.072)\tLoss 1.0312 (0.8206)\tAcc 0.562 (0.654)\n",
      "Epoch: [88][14/18]\tTime 0.075 (0.092)\tData 0.056 (0.071)\tLoss 0.7144 (0.8130)\tAcc 0.625 (0.652)\n",
      "Epoch: [88][15/18]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 1.0389 (0.8280)\tAcc 0.625 (0.650)\n",
      "Epoch: [88][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.8315 (0.8283)\tAcc 0.688 (0.652)\n",
      "Epoch: [88][17/18]\tTime 0.077 (0.089)\tData 0.058 (0.068)\tLoss 0.8851 (0.8316)\tAcc 0.625 (0.651)\n",
      "Epoch: [88][18/18]\tTime 0.077 (0.089)\tData 0.058 (0.068)\tLoss 0.7992 (0.8307)\tAcc 0.875 (0.657)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/12]\tTime 0.354 (0.354)\tData 0.324 (0.324)\tLoss 0.9837 (0.9837)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][2/12]\tTime 0.080 (0.217)\tData 0.053 (0.189)\tLoss 0.4721 (0.7279)\tAcc 0.812 (0.750)\n",
      "Epoch: [89][3/12]\tTime 0.083 (0.172)\tData 0.055 (0.144)\tLoss 0.4347 (0.6302)\tAcc 0.938 (0.812)\n",
      "Epoch: [89][4/12]\tTime 0.078 (0.149)\tData 0.051 (0.121)\tLoss 0.4083 (0.5747)\tAcc 0.938 (0.844)\n",
      "Epoch: [89][5/12]\tTime 0.081 (0.135)\tData 0.055 (0.108)\tLoss 1.0667 (0.6731)\tAcc 0.500 (0.775)\n",
      "Epoch: [89][6/12]\tTime 0.081 (0.126)\tData 0.053 (0.099)\tLoss 0.5734 (0.6565)\tAcc 0.812 (0.781)\n",
      "Epoch: [89][7/12]\tTime 0.074 (0.119)\tData 0.050 (0.092)\tLoss 0.8798 (0.6884)\tAcc 0.625 (0.759)\n",
      "Epoch: [89][8/12]\tTime 0.080 (0.114)\tData 0.057 (0.087)\tLoss 0.5996 (0.6773)\tAcc 0.875 (0.773)\n",
      "Epoch: [89][9/12]\tTime 0.084 (0.111)\tData 0.061 (0.084)\tLoss 1.0857 (0.7227)\tAcc 0.562 (0.750)\n",
      "Epoch: [89][10/12]\tTime 0.079 (0.107)\tData 0.056 (0.082)\tLoss 0.9372 (0.7441)\tAcc 0.500 (0.725)\n",
      "Epoch: [89][11/12]\tTime 0.080 (0.105)\tData 0.057 (0.079)\tLoss 0.6004 (0.7311)\tAcc 0.750 (0.727)\n",
      "Epoch: [89][12/12]\tTime 0.084 (0.103)\tData 0.061 (0.078)\tLoss 0.9965 (0.7519)\tAcc 0.467 (0.707)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/18]\tTime 0.322 (0.322)\tData 0.291 (0.291)\tLoss 0.4301 (0.4301)\tAcc 0.875 (0.875)\n",
      "Epoch: [89][2/18]\tTime 0.068 (0.195)\tData 0.045 (0.168)\tLoss 0.9575 (0.6938)\tAcc 0.438 (0.656)\n",
      "Epoch: [89][3/18]\tTime 0.075 (0.155)\tData 0.053 (0.130)\tLoss 0.6054 (0.6644)\tAcc 0.750 (0.688)\n",
      "Epoch: [89][4/18]\tTime 0.083 (0.137)\tData 0.052 (0.111)\tLoss 0.6221 (0.6538)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][5/18]\tTime 0.067 (0.123)\tData 0.046 (0.098)\tLoss 0.7807 (0.6792)\tAcc 0.812 (0.713)\n",
      "Epoch: [89][6/18]\tTime 0.074 (0.115)\tData 0.053 (0.090)\tLoss 0.2097 (0.6009)\tAcc 1.000 (0.760)\n",
      "Epoch: [89][7/18]\tTime 0.075 (0.109)\tData 0.053 (0.085)\tLoss 0.6980 (0.6148)\tAcc 0.625 (0.741)\n",
      "Epoch: [89][8/18]\tTime 0.075 (0.105)\tData 0.054 (0.081)\tLoss 0.9836 (0.6609)\tAcc 0.688 (0.734)\n",
      "Epoch: [89][9/18]\tTime 0.074 (0.102)\tData 0.053 (0.078)\tLoss 0.2149 (0.6113)\tAcc 1.000 (0.764)\n",
      "Epoch: [89][10/18]\tTime 0.075 (0.099)\tData 0.053 (0.075)\tLoss 1.1930 (0.6695)\tAcc 0.500 (0.738)\n",
      "Epoch: [89][11/18]\tTime 0.075 (0.097)\tData 0.053 (0.073)\tLoss 1.1104 (0.7096)\tAcc 0.375 (0.705)\n",
      "Epoch: [89][12/18]\tTime 0.072 (0.095)\tData 0.052 (0.072)\tLoss 0.9067 (0.7260)\tAcc 0.625 (0.698)\n",
      "Epoch: [89][13/18]\tTime 0.073 (0.093)\tData 0.054 (0.070)\tLoss 1.1537 (0.7589)\tAcc 0.625 (0.692)\n",
      "Epoch: [89][14/18]\tTime 0.074 (0.092)\tData 0.055 (0.069)\tLoss 0.7977 (0.7617)\tAcc 0.562 (0.683)\n",
      "Epoch: [89][15/18]\tTime 0.074 (0.090)\tData 0.055 (0.068)\tLoss 0.8731 (0.7691)\tAcc 0.625 (0.679)\n",
      "Epoch: [89][16/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.8586 (0.7747)\tAcc 0.625 (0.676)\n",
      "Epoch: [89][17/18]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.8407 (0.7786)\tAcc 0.625 (0.673)\n",
      "Epoch: [89][18/18]\tTime 0.075 (0.088)\tData 0.056 (0.066)\tLoss 0.6900 (0.7761)\tAcc 0.875 (0.679)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/12]\tTime 0.339 (0.339)\tData 0.298 (0.298)\tLoss 0.5266 (0.5266)\tAcc 0.812 (0.812)\n",
      "Epoch: [90][2/12]\tTime 0.065 (0.202)\tData 0.040 (0.169)\tLoss 0.7530 (0.6398)\tAcc 0.750 (0.781)\n",
      "Epoch: [90][3/12]\tTime 0.087 (0.164)\tData 0.057 (0.131)\tLoss 0.5943 (0.6246)\tAcc 0.875 (0.812)\n",
      "Epoch: [90][4/12]\tTime 0.080 (0.143)\tData 0.051 (0.111)\tLoss 0.6608 (0.6337)\tAcc 0.812 (0.812)\n",
      "Epoch: [90][5/12]\tTime 0.076 (0.129)\tData 0.051 (0.099)\tLoss 0.5937 (0.6257)\tAcc 0.812 (0.812)\n",
      "Epoch: [90][6/12]\tTime 0.080 (0.121)\tData 0.053 (0.091)\tLoss 0.8378 (0.6610)\tAcc 0.625 (0.781)\n",
      "Epoch: [90][7/12]\tTime 0.081 (0.115)\tData 0.052 (0.086)\tLoss 0.7743 (0.6772)\tAcc 0.750 (0.777)\n",
      "Epoch: [90][8/12]\tTime 0.075 (0.110)\tData 0.051 (0.081)\tLoss 0.4207 (0.6452)\tAcc 0.938 (0.797)\n",
      "Epoch: [90][9/12]\tTime 0.085 (0.108)\tData 0.061 (0.079)\tLoss 1.0227 (0.6871)\tAcc 0.562 (0.771)\n",
      "Epoch: [90][10/12]\tTime 0.079 (0.105)\tData 0.055 (0.077)\tLoss 0.5348 (0.6719)\tAcc 0.750 (0.769)\n",
      "Epoch: [90][11/12]\tTime 0.080 (0.102)\tData 0.056 (0.075)\tLoss 0.7787 (0.6816)\tAcc 0.688 (0.761)\n",
      "Epoch: [90][12/12]\tTime 0.081 (0.101)\tData 0.056 (0.073)\tLoss 1.1116 (0.7154)\tAcc 0.467 (0.738)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/18]\tTime 0.310 (0.310)\tData 0.284 (0.284)\tLoss 0.4306 (0.4306)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/18]\tTime 0.071 (0.190)\tData 0.050 (0.167)\tLoss 1.1278 (0.7792)\tAcc 0.438 (0.688)\n",
      "Epoch: [90][3/18]\tTime 0.074 (0.151)\tData 0.053 (0.129)\tLoss 0.7696 (0.7760)\tAcc 0.750 (0.708)\n",
      "Epoch: [90][4/18]\tTime 0.077 (0.133)\tData 0.053 (0.110)\tLoss 0.6729 (0.7502)\tAcc 0.625 (0.688)\n",
      "Epoch: [90][5/18]\tTime 0.074 (0.121)\tData 0.052 (0.099)\tLoss 0.8163 (0.7634)\tAcc 0.688 (0.688)\n",
      "Epoch: [90][6/18]\tTime 0.074 (0.113)\tData 0.053 (0.091)\tLoss 0.2614 (0.6798)\tAcc 1.000 (0.740)\n",
      "Epoch: [90][7/18]\tTime 0.080 (0.108)\tData 0.055 (0.086)\tLoss 0.6787 (0.6796)\tAcc 0.688 (0.732)\n",
      "Epoch: [90][8/18]\tTime 0.072 (0.104)\tData 0.051 (0.081)\tLoss 1.0061 (0.7204)\tAcc 0.562 (0.711)\n",
      "Epoch: [90][9/18]\tTime 0.076 (0.101)\tData 0.055 (0.079)\tLoss 0.1612 (0.6583)\tAcc 1.000 (0.743)\n",
      "Epoch: [90][10/18]\tTime 0.082 (0.099)\tData 0.059 (0.077)\tLoss 1.3338 (0.7258)\tAcc 0.438 (0.713)\n",
      "Epoch: [90][11/18]\tTime 0.074 (0.097)\tData 0.053 (0.074)\tLoss 1.2540 (0.7739)\tAcc 0.375 (0.682)\n",
      "Epoch: [90][12/18]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.8913 (0.7836)\tAcc 0.562 (0.672)\n",
      "Epoch: [90][13/18]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 1.1175 (0.8093)\tAcc 0.625 (0.668)\n",
      "Epoch: [90][14/18]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.9148 (0.8169)\tAcc 0.625 (0.665)\n",
      "Epoch: [90][15/18]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 0.9375 (0.8249)\tAcc 0.688 (0.667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [90][16/18]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.8446 (0.8261)\tAcc 0.688 (0.668)\n",
      "Epoch: [90][17/18]\tTime 0.076 (0.089)\tData 0.057 (0.068)\tLoss 0.8948 (0.8302)\tAcc 0.625 (0.665)\n",
      "Epoch: [90][18/18]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.6934 (0.8263)\tAcc 0.750 (0.668)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/12]\tTime 0.315 (0.315)\tData 0.286 (0.286)\tLoss 0.9130 (0.9130)\tAcc 0.500 (0.500)\n",
      "Epoch: [91][2/12]\tTime 0.076 (0.196)\tData 0.051 (0.168)\tLoss 0.5189 (0.7160)\tAcc 0.812 (0.656)\n",
      "Epoch: [91][3/12]\tTime 0.088 (0.160)\tData 0.056 (0.131)\tLoss 0.5938 (0.6752)\tAcc 0.812 (0.708)\n",
      "Epoch: [91][4/12]\tTime 0.075 (0.139)\tData 0.049 (0.110)\tLoss 0.7116 (0.6843)\tAcc 0.750 (0.719)\n",
      "Epoch: [91][5/12]\tTime 0.080 (0.127)\tData 0.054 (0.099)\tLoss 0.4381 (0.6351)\tAcc 0.875 (0.750)\n",
      "Epoch: [91][6/12]\tTime 0.079 (0.119)\tData 0.054 (0.092)\tLoss 0.7973 (0.6621)\tAcc 0.688 (0.740)\n",
      "Epoch: [91][7/12]\tTime 0.085 (0.114)\tData 0.058 (0.087)\tLoss 0.5534 (0.6466)\tAcc 0.750 (0.741)\n",
      "Epoch: [91][8/12]\tTime 0.078 (0.110)\tData 0.054 (0.083)\tLoss 0.6670 (0.6492)\tAcc 0.688 (0.734)\n",
      "Epoch: [91][9/12]\tTime 0.077 (0.106)\tData 0.054 (0.080)\tLoss 0.5797 (0.6414)\tAcc 0.750 (0.736)\n",
      "Epoch: [91][10/12]\tTime 0.079 (0.103)\tData 0.055 (0.077)\tLoss 1.0025 (0.6775)\tAcc 0.500 (0.713)\n",
      "Epoch: [91][11/12]\tTime 0.080 (0.101)\tData 0.056 (0.075)\tLoss 0.9272 (0.7002)\tAcc 0.500 (0.693)\n",
      "Epoch: [91][12/12]\tTime 0.078 (0.099)\tData 0.054 (0.073)\tLoss 0.7947 (0.7077)\tAcc 0.733 (0.696)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/18]\tTime 0.322 (0.322)\tData 0.298 (0.298)\tLoss 0.3043 (0.3043)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/18]\tTime 0.074 (0.198)\tData 0.052 (0.175)\tLoss 0.8551 (0.5797)\tAcc 0.438 (0.688)\n",
      "Epoch: [91][3/18]\tTime 0.075 (0.157)\tData 0.053 (0.134)\tLoss 0.6709 (0.6101)\tAcc 0.812 (0.729)\n",
      "Epoch: [91][4/18]\tTime 0.073 (0.136)\tData 0.052 (0.114)\tLoss 0.5122 (0.5856)\tAcc 0.688 (0.719)\n",
      "Epoch: [91][5/18]\tTime 0.075 (0.124)\tData 0.054 (0.102)\tLoss 0.7560 (0.6197)\tAcc 0.750 (0.725)\n",
      "Epoch: [91][6/18]\tTime 0.074 (0.116)\tData 0.053 (0.094)\tLoss 0.3100 (0.5681)\tAcc 0.938 (0.760)\n",
      "Epoch: [91][7/18]\tTime 0.077 (0.110)\tData 0.052 (0.088)\tLoss 0.6092 (0.5740)\tAcc 0.750 (0.759)\n",
      "Epoch: [91][8/18]\tTime 0.072 (0.105)\tData 0.051 (0.083)\tLoss 0.9552 (0.6216)\tAcc 0.625 (0.742)\n",
      "Epoch: [91][9/18]\tTime 0.075 (0.102)\tData 0.053 (0.080)\tLoss 0.2273 (0.5778)\tAcc 1.000 (0.771)\n",
      "Epoch: [91][10/18]\tTime 0.078 (0.100)\tData 0.056 (0.077)\tLoss 1.1753 (0.6376)\tAcc 0.438 (0.738)\n",
      "Epoch: [91][11/18]\tTime 0.076 (0.097)\tData 0.055 (0.075)\tLoss 1.4173 (0.7084)\tAcc 0.375 (0.705)\n",
      "Epoch: [91][12/18]\tTime 0.073 (0.095)\tData 0.053 (0.074)\tLoss 1.0417 (0.7362)\tAcc 0.625 (0.698)\n",
      "Epoch: [91][13/18]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 1.1743 (0.7699)\tAcc 0.625 (0.692)\n",
      "Epoch: [91][14/18]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.9976 (0.7862)\tAcc 0.562 (0.683)\n",
      "Epoch: [91][15/18]\tTime 0.077 (0.091)\tData 0.058 (0.070)\tLoss 0.7276 (0.7823)\tAcc 0.750 (0.688)\n",
      "Epoch: [91][16/18]\tTime 0.075 (0.090)\tData 0.056 (0.069)\tLoss 0.8085 (0.7839)\tAcc 0.625 (0.684)\n",
      "Epoch: [91][17/18]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.8717 (0.7891)\tAcc 0.688 (0.684)\n",
      "Epoch: [91][18/18]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.7126 (0.7869)\tAcc 0.875 (0.689)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/12]\tTime 0.352 (0.352)\tData 0.322 (0.322)\tLoss 0.6971 (0.6971)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][2/12]\tTime 0.076 (0.214)\tData 0.050 (0.186)\tLoss 0.7975 (0.7473)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][3/12]\tTime 0.079 (0.169)\tData 0.053 (0.141)\tLoss 0.4275 (0.6407)\tAcc 0.938 (0.771)\n",
      "Epoch: [92][4/12]\tTime 0.080 (0.147)\tData 0.054 (0.120)\tLoss 0.8786 (0.7002)\tAcc 0.750 (0.766)\n",
      "Epoch: [92][5/12]\tTime 0.080 (0.133)\tData 0.055 (0.107)\tLoss 0.7840 (0.7169)\tAcc 0.750 (0.762)\n",
      "Epoch: [92][6/12]\tTime 0.084 (0.125)\tData 0.057 (0.098)\tLoss 0.7044 (0.7148)\tAcc 0.812 (0.771)\n",
      "Epoch: [92][7/12]\tTime 0.082 (0.119)\tData 0.056 (0.092)\tLoss 0.9706 (0.7514)\tAcc 0.500 (0.732)\n",
      "Epoch: [92][8/12]\tTime 0.079 (0.114)\tData 0.055 (0.088)\tLoss 0.6563 (0.7395)\tAcc 0.750 (0.734)\n",
      "Epoch: [92][9/12]\tTime 0.078 (0.110)\tData 0.054 (0.084)\tLoss 0.8958 (0.7569)\tAcc 0.562 (0.715)\n",
      "Epoch: [92][10/12]\tTime 0.085 (0.107)\tData 0.061 (0.082)\tLoss 0.4260 (0.7238)\tAcc 0.938 (0.738)\n",
      "Epoch: [92][11/12]\tTime 0.080 (0.105)\tData 0.057 (0.080)\tLoss 1.1435 (0.7619)\tAcc 0.438 (0.710)\n",
      "Epoch: [92][12/12]\tTime 0.083 (0.103)\tData 0.060 (0.078)\tLoss 0.6650 (0.7543)\tAcc 0.800 (0.717)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/18]\tTime 0.286 (0.286)\tData 0.261 (0.261)\tLoss 0.3485 (0.3485)\tAcc 0.875 (0.875)\n",
      "Epoch: [92][2/18]\tTime 0.094 (0.190)\tData 0.070 (0.166)\tLoss 1.0163 (0.6824)\tAcc 0.438 (0.656)\n",
      "Epoch: [92][3/18]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 0.7889 (0.7179)\tAcc 0.750 (0.688)\n",
      "Epoch: [92][4/18]\tTime 0.075 (0.132)\tData 0.053 (0.109)\tLoss 0.7277 (0.7204)\tAcc 0.562 (0.656)\n",
      "Epoch: [92][5/18]\tTime 0.076 (0.121)\tData 0.053 (0.098)\tLoss 0.8398 (0.7443)\tAcc 0.688 (0.663)\n",
      "Epoch: [92][6/18]\tTime 0.080 (0.114)\tData 0.053 (0.090)\tLoss 0.3683 (0.6816)\tAcc 0.938 (0.708)\n",
      "Epoch: [92][7/18]\tTime 0.070 (0.108)\tData 0.049 (0.084)\tLoss 0.7810 (0.6958)\tAcc 0.562 (0.688)\n",
      "Epoch: [92][8/18]\tTime 0.076 (0.104)\tData 0.053 (0.080)\tLoss 0.9694 (0.7300)\tAcc 0.562 (0.672)\n",
      "Epoch: [92][9/18]\tTime 0.074 (0.101)\tData 0.051 (0.077)\tLoss 0.2136 (0.6726)\tAcc 1.000 (0.708)\n",
      "Epoch: [92][10/18]\tTime 0.072 (0.098)\tData 0.052 (0.075)\tLoss 1.2287 (0.7282)\tAcc 0.375 (0.675)\n",
      "Epoch: [92][11/18]\tTime 0.077 (0.096)\tData 0.055 (0.073)\tLoss 1.4910 (0.7976)\tAcc 0.375 (0.648)\n",
      "Epoch: [92][12/18]\tTime 0.073 (0.094)\tData 0.053 (0.071)\tLoss 1.0730 (0.8205)\tAcc 0.562 (0.641)\n",
      "Epoch: [92][13/18]\tTime 0.072 (0.092)\tData 0.054 (0.070)\tLoss 1.0940 (0.8416)\tAcc 0.500 (0.630)\n",
      "Epoch: [92][14/18]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 0.9038 (0.8460)\tAcc 0.688 (0.634)\n",
      "Epoch: [92][15/18]\tTime 0.073 (0.090)\tData 0.055 (0.068)\tLoss 0.7736 (0.8412)\tAcc 0.750 (0.642)\n",
      "Epoch: [92][16/18]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.6761 (0.8309)\tAcc 0.750 (0.648)\n",
      "Epoch: [92][17/18]\tTime 0.077 (0.088)\tData 0.058 (0.067)\tLoss 0.8563 (0.8324)\tAcc 0.625 (0.647)\n",
      "Epoch: [92][18/18]\tTime 0.078 (0.088)\tData 0.059 (0.066)\tLoss 0.7272 (0.8294)\tAcc 0.875 (0.654)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/12]\tTime 0.399 (0.399)\tData 0.369 (0.369)\tLoss 0.9406 (0.9406)\tAcc 0.562 (0.562)\n",
      "Epoch: [93][2/12]\tTime 0.077 (0.238)\tData 0.050 (0.210)\tLoss 1.0045 (0.9726)\tAcc 0.625 (0.594)\n",
      "Epoch: [93][3/12]\tTime 0.077 (0.184)\tData 0.051 (0.157)\tLoss 0.5340 (0.8264)\tAcc 0.812 (0.667)\n",
      "Epoch: [93][4/12]\tTime 0.081 (0.158)\tData 0.056 (0.132)\tLoss 0.5256 (0.7512)\tAcc 0.875 (0.719)\n",
      "Epoch: [93][5/12]\tTime 0.080 (0.143)\tData 0.055 (0.116)\tLoss 0.4520 (0.6914)\tAcc 0.938 (0.762)\n",
      "Epoch: [93][6/12]\tTime 0.080 (0.132)\tData 0.053 (0.106)\tLoss 1.1068 (0.7606)\tAcc 0.438 (0.708)\n",
      "Epoch: [93][7/12]\tTime 0.077 (0.124)\tData 0.052 (0.098)\tLoss 0.7702 (0.7620)\tAcc 0.688 (0.705)\n",
      "Epoch: [93][8/12]\tTime 0.082 (0.119)\tData 0.058 (0.093)\tLoss 0.6126 (0.7433)\tAcc 0.875 (0.727)\n",
      "Epoch: [93][9/12]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.9273 (0.7638)\tAcc 0.562 (0.708)\n",
      "Epoch: [93][10/12]\tTime 0.078 (0.111)\tData 0.054 (0.085)\tLoss 0.7272 (0.7601)\tAcc 0.688 (0.706)\n",
      "Epoch: [93][11/12]\tTime 0.079 (0.108)\tData 0.056 (0.083)\tLoss 0.6717 (0.7521)\tAcc 0.688 (0.705)\n",
      "Epoch: [93][12/12]\tTime 0.081 (0.106)\tData 0.057 (0.080)\tLoss 1.0144 (0.7727)\tAcc 0.667 (0.702)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/18]\tTime 0.320 (0.320)\tData 0.296 (0.296)\tLoss 0.2683 (0.2683)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/18]\tTime 0.076 (0.198)\tData 0.052 (0.174)\tLoss 1.1282 (0.6983)\tAcc 0.438 (0.688)\n",
      "Epoch: [93][3/18]\tTime 0.075 (0.157)\tData 0.053 (0.134)\tLoss 0.7099 (0.7022)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][4/18]\tTime 0.078 (0.137)\tData 0.056 (0.114)\tLoss 0.6992 (0.7014)\tAcc 0.625 (0.672)\n",
      "Epoch: [93][5/18]\tTime 0.073 (0.124)\tData 0.053 (0.102)\tLoss 0.8611 (0.7334)\tAcc 0.750 (0.688)\n",
      "Epoch: [93][6/18]\tTime 0.076 (0.116)\tData 0.055 (0.094)\tLoss 0.3213 (0.6647)\tAcc 1.000 (0.740)\n",
      "Epoch: [93][7/18]\tTime 0.076 (0.110)\tData 0.053 (0.088)\tLoss 0.6115 (0.6571)\tAcc 0.750 (0.741)\n",
      "Epoch: [93][8/18]\tTime 0.074 (0.106)\tData 0.053 (0.084)\tLoss 1.0026 (0.7003)\tAcc 0.625 (0.727)\n",
      "Epoch: [93][9/18]\tTime 0.075 (0.102)\tData 0.053 (0.080)\tLoss 0.2595 (0.6513)\tAcc 1.000 (0.757)\n",
      "Epoch: [93][10/18]\tTime 0.077 (0.100)\tData 0.055 (0.078)\tLoss 1.3473 (0.7209)\tAcc 0.438 (0.725)\n",
      "Epoch: [93][11/18]\tTime 0.079 (0.098)\tData 0.058 (0.076)\tLoss 1.3411 (0.7773)\tAcc 0.375 (0.693)\n",
      "Epoch: [93][12/18]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 1.0742 (0.8020)\tAcc 0.688 (0.693)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [93][13/18]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 1.1717 (0.8305)\tAcc 0.500 (0.678)\n",
      "Epoch: [93][14/18]\tTime 0.078 (0.093)\tData 0.058 (0.072)\tLoss 0.7513 (0.8248)\tAcc 0.625 (0.674)\n",
      "Epoch: [93][15/18]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.8242 (0.8248)\tAcc 0.688 (0.675)\n",
      "Epoch: [93][16/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.8721 (0.8277)\tAcc 0.688 (0.676)\n",
      "Epoch: [93][17/18]\tTime 0.077 (0.090)\tData 0.056 (0.069)\tLoss 0.8726 (0.8304)\tAcc 0.625 (0.673)\n",
      "Epoch: [93][18/18]\tTime 0.081 (0.089)\tData 0.060 (0.068)\tLoss 0.8268 (0.8303)\tAcc 0.750 (0.675)\n",
      "train at epoch 94\n",
      "Epoch: [94][1/12]\tTime 0.321 (0.321)\tData 0.271 (0.271)\tLoss 0.5160 (0.5160)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][2/12]\tTime 0.077 (0.199)\tData 0.033 (0.152)\tLoss 0.4086 (0.4623)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][3/12]\tTime 0.064 (0.154)\tData 0.036 (0.113)\tLoss 0.7254 (0.5500)\tAcc 0.750 (0.833)\n",
      "Epoch: [94][4/12]\tTime 0.107 (0.142)\tData 0.057 (0.099)\tLoss 0.7239 (0.5935)\tAcc 0.812 (0.828)\n",
      "Epoch: [94][5/12]\tTime 0.064 (0.127)\tData 0.035 (0.087)\tLoss 0.6896 (0.6127)\tAcc 0.750 (0.812)\n",
      "Epoch: [94][6/12]\tTime 0.081 (0.119)\tData 0.053 (0.081)\tLoss 1.1828 (0.7077)\tAcc 0.375 (0.740)\n",
      "Epoch: [94][7/12]\tTime 0.076 (0.113)\tData 0.051 (0.077)\tLoss 0.4320 (0.6683)\tAcc 0.875 (0.759)\n",
      "Epoch: [94][8/12]\tTime 0.080 (0.109)\tData 0.055 (0.074)\tLoss 0.6804 (0.6698)\tAcc 0.688 (0.750)\n",
      "Epoch: [94][9/12]\tTime 0.078 (0.105)\tData 0.054 (0.072)\tLoss 0.7019 (0.6734)\tAcc 0.688 (0.743)\n",
      "Epoch: [94][10/12]\tTime 0.080 (0.103)\tData 0.056 (0.070)\tLoss 0.7958 (0.6856)\tAcc 0.688 (0.738)\n",
      "Epoch: [94][11/12]\tTime 0.086 (0.101)\tData 0.062 (0.069)\tLoss 0.8733 (0.7027)\tAcc 0.625 (0.727)\n",
      "Epoch: [94][12/12]\tTime 0.083 (0.100)\tData 0.059 (0.069)\tLoss 0.7016 (0.7026)\tAcc 0.800 (0.733)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/18]\tTime 0.361 (0.361)\tData 0.336 (0.336)\tLoss 0.3218 (0.3218)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/18]\tTime 0.072 (0.216)\tData 0.050 (0.193)\tLoss 1.0407 (0.6813)\tAcc 0.438 (0.688)\n",
      "Epoch: [94][3/18]\tTime 0.075 (0.169)\tData 0.053 (0.146)\tLoss 0.7361 (0.6996)\tAcc 0.688 (0.688)\n",
      "Epoch: [94][4/18]\tTime 0.076 (0.146)\tData 0.051 (0.122)\tLoss 0.6918 (0.6976)\tAcc 0.625 (0.672)\n",
      "Epoch: [94][5/18]\tTime 0.071 (0.131)\tData 0.050 (0.108)\tLoss 0.7608 (0.7102)\tAcc 0.812 (0.700)\n",
      "Epoch: [94][6/18]\tTime 0.075 (0.122)\tData 0.053 (0.099)\tLoss 0.2850 (0.6394)\tAcc 1.000 (0.750)\n",
      "Epoch: [94][7/18]\tTime 0.075 (0.115)\tData 0.053 (0.092)\tLoss 0.7054 (0.6488)\tAcc 0.625 (0.732)\n",
      "Epoch: [94][8/18]\tTime 0.074 (0.110)\tData 0.053 (0.087)\tLoss 0.9609 (0.6878)\tAcc 0.562 (0.711)\n",
      "Epoch: [94][9/18]\tTime 0.075 (0.106)\tData 0.054 (0.084)\tLoss 0.2448 (0.6386)\tAcc 1.000 (0.743)\n",
      "Epoch: [94][10/18]\tTime 0.073 (0.103)\tData 0.052 (0.081)\tLoss 1.2022 (0.6949)\tAcc 0.438 (0.713)\n",
      "Epoch: [94][11/18]\tTime 0.075 (0.100)\tData 0.054 (0.078)\tLoss 1.2170 (0.7424)\tAcc 0.375 (0.682)\n",
      "Epoch: [94][12/18]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.9325 (0.7583)\tAcc 0.562 (0.672)\n",
      "Epoch: [94][13/18]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 1.1127 (0.7855)\tAcc 0.438 (0.654)\n",
      "Epoch: [94][14/18]\tTime 0.074 (0.095)\tData 0.055 (0.073)\tLoss 0.8226 (0.7882)\tAcc 0.625 (0.652)\n",
      "Epoch: [94][15/18]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.8249 (0.7906)\tAcc 0.750 (0.658)\n",
      "Epoch: [94][16/18]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.8667 (0.7954)\tAcc 0.688 (0.660)\n",
      "Epoch: [94][17/18]\tTime 0.079 (0.091)\tData 0.060 (0.070)\tLoss 0.7721 (0.7940)\tAcc 0.625 (0.658)\n",
      "Epoch: [94][18/18]\tTime 0.074 (0.090)\tData 0.056 (0.069)\tLoss 0.7842 (0.7937)\tAcc 0.750 (0.661)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/12]\tTime 0.271 (0.271)\tData 0.239 (0.239)\tLoss 0.6363 (0.6363)\tAcc 0.750 (0.750)\n",
      "Epoch: [95][2/12]\tTime 0.075 (0.173)\tData 0.048 (0.144)\tLoss 1.0746 (0.8555)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][3/12]\tTime 0.087 (0.144)\tData 0.052 (0.113)\tLoss 0.6170 (0.7760)\tAcc 0.688 (0.688)\n",
      "Epoch: [95][4/12]\tTime 0.079 (0.128)\tData 0.050 (0.097)\tLoss 0.7765 (0.7761)\tAcc 0.625 (0.672)\n",
      "Epoch: [95][5/12]\tTime 0.084 (0.119)\tData 0.055 (0.089)\tLoss 0.8713 (0.7951)\tAcc 0.750 (0.688)\n",
      "Epoch: [95][6/12]\tTime 0.076 (0.112)\tData 0.050 (0.082)\tLoss 0.9880 (0.8273)\tAcc 0.562 (0.667)\n",
      "Epoch: [95][7/12]\tTime 0.079 (0.107)\tData 0.053 (0.078)\tLoss 0.5878 (0.7931)\tAcc 0.812 (0.688)\n",
      "Epoch: [95][8/12]\tTime 0.078 (0.104)\tData 0.054 (0.075)\tLoss 0.5559 (0.7634)\tAcc 0.750 (0.695)\n",
      "Epoch: [95][9/12]\tTime 0.078 (0.101)\tData 0.054 (0.073)\tLoss 1.1175 (0.8028)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][10/12]\tTime 0.078 (0.098)\tData 0.054 (0.071)\tLoss 0.7064 (0.7931)\tAcc 0.688 (0.688)\n",
      "Epoch: [95][11/12]\tTime 0.085 (0.097)\tData 0.061 (0.070)\tLoss 0.6480 (0.7799)\tAcc 0.750 (0.693)\n",
      "Epoch: [95][12/12]\tTime 0.085 (0.096)\tData 0.061 (0.069)\tLoss 0.6224 (0.7676)\tAcc 0.867 (0.707)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/18]\tTime 0.303 (0.303)\tData 0.275 (0.275)\tLoss 0.3446 (0.3446)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/18]\tTime 0.068 (0.186)\tData 0.047 (0.161)\tLoss 1.0244 (0.6845)\tAcc 0.438 (0.688)\n",
      "Epoch: [95][3/18]\tTime 0.077 (0.150)\tData 0.054 (0.125)\tLoss 0.6564 (0.6751)\tAcc 0.812 (0.729)\n",
      "Epoch: [95][4/18]\tTime 0.073 (0.131)\tData 0.051 (0.107)\tLoss 0.6770 (0.6756)\tAcc 0.625 (0.703)\n",
      "Epoch: [95][5/18]\tTime 0.074 (0.119)\tData 0.053 (0.096)\tLoss 0.8478 (0.7101)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][6/18]\tTime 0.083 (0.113)\tData 0.061 (0.090)\tLoss 0.4019 (0.6587)\tAcc 0.938 (0.729)\n",
      "Epoch: [95][7/18]\tTime 0.080 (0.108)\tData 0.058 (0.086)\tLoss 0.8398 (0.6846)\tAcc 0.562 (0.705)\n",
      "Epoch: [95][8/18]\tTime 0.082 (0.105)\tData 0.060 (0.082)\tLoss 1.2125 (0.7505)\tAcc 0.500 (0.680)\n",
      "Epoch: [95][9/18]\tTime 0.079 (0.102)\tData 0.058 (0.080)\tLoss 0.2123 (0.6907)\tAcc 1.000 (0.715)\n",
      "Epoch: [95][10/18]\tTime 0.080 (0.100)\tData 0.055 (0.077)\tLoss 1.1894 (0.7406)\tAcc 0.625 (0.706)\n",
      "Epoch: [95][11/18]\tTime 0.075 (0.098)\tData 0.052 (0.075)\tLoss 1.3286 (0.7941)\tAcc 0.375 (0.676)\n",
      "Epoch: [95][12/18]\tTime 0.071 (0.095)\tData 0.051 (0.073)\tLoss 1.0423 (0.8147)\tAcc 0.625 (0.672)\n",
      "Epoch: [95][13/18]\tTime 0.079 (0.094)\tData 0.060 (0.072)\tLoss 1.1601 (0.8413)\tAcc 0.500 (0.659)\n",
      "Epoch: [95][14/18]\tTime 0.080 (0.093)\tData 0.060 (0.071)\tLoss 0.7736 (0.8365)\tAcc 0.562 (0.652)\n",
      "Epoch: [95][15/18]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.8593 (0.8380)\tAcc 0.688 (0.654)\n",
      "Epoch: [95][16/18]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.8452 (0.8384)\tAcc 0.688 (0.656)\n",
      "Epoch: [95][17/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 0.8996 (0.8420)\tAcc 0.688 (0.658)\n",
      "Epoch: [95][18/18]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.8522 (0.8423)\tAcc 0.750 (0.661)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/12]\tTime 0.320 (0.320)\tData 0.284 (0.284)\tLoss 0.7868 (0.7868)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][2/12]\tTime 0.070 (0.195)\tData 0.045 (0.164)\tLoss 0.5254 (0.6561)\tAcc 0.875 (0.781)\n",
      "Epoch: [96][3/12]\tTime 0.088 (0.160)\tData 0.059 (0.129)\tLoss 0.7109 (0.6744)\tAcc 0.688 (0.750)\n",
      "Epoch: [96][4/12]\tTime 0.084 (0.141)\tData 0.058 (0.111)\tLoss 0.7347 (0.6895)\tAcc 0.688 (0.734)\n",
      "Epoch: [96][5/12]\tTime 0.081 (0.129)\tData 0.055 (0.100)\tLoss 0.7560 (0.7028)\tAcc 0.688 (0.725)\n",
      "Epoch: [96][6/12]\tTime 0.079 (0.120)\tData 0.053 (0.092)\tLoss 0.9069 (0.7368)\tAcc 0.688 (0.719)\n",
      "Epoch: [96][7/12]\tTime 0.077 (0.114)\tData 0.052 (0.087)\tLoss 0.6720 (0.7275)\tAcc 0.812 (0.732)\n",
      "Epoch: [96][8/12]\tTime 0.082 (0.110)\tData 0.057 (0.083)\tLoss 0.8110 (0.7380)\tAcc 0.562 (0.711)\n",
      "Epoch: [96][9/12]\tTime 0.086 (0.107)\tData 0.061 (0.081)\tLoss 0.8001 (0.7449)\tAcc 0.562 (0.694)\n",
      "Epoch: [96][10/12]\tTime 0.086 (0.105)\tData 0.062 (0.079)\tLoss 0.6567 (0.7361)\tAcc 0.750 (0.700)\n",
      "Epoch: [96][11/12]\tTime 0.081 (0.103)\tData 0.058 (0.077)\tLoss 0.7051 (0.7333)\tAcc 0.688 (0.699)\n",
      "Epoch: [96][12/12]\tTime 0.080 (0.101)\tData 0.056 (0.075)\tLoss 0.8322 (0.7410)\tAcc 0.733 (0.702)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/18]\tTime 0.346 (0.346)\tData 0.321 (0.321)\tLoss 0.2782 (0.2782)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/18]\tTime 0.072 (0.209)\tData 0.051 (0.186)\tLoss 1.0368 (0.6575)\tAcc 0.438 (0.688)\n",
      "Epoch: [96][3/18]\tTime 0.083 (0.167)\tData 0.057 (0.143)\tLoss 0.6124 (0.6425)\tAcc 0.812 (0.729)\n",
      "Epoch: [96][4/18]\tTime 0.075 (0.144)\tData 0.054 (0.121)\tLoss 0.6902 (0.6544)\tAcc 0.625 (0.703)\n",
      "Epoch: [96][5/18]\tTime 0.081 (0.131)\tData 0.060 (0.109)\tLoss 0.9009 (0.7037)\tAcc 0.750 (0.713)\n",
      "Epoch: [96][6/18]\tTime 0.075 (0.122)\tData 0.055 (0.100)\tLoss 0.2931 (0.6353)\tAcc 1.000 (0.760)\n",
      "Epoch: [96][7/18]\tTime 0.075 (0.115)\tData 0.053 (0.093)\tLoss 0.5652 (0.6252)\tAcc 0.750 (0.759)\n",
      "Epoch: [96][8/18]\tTime 0.077 (0.111)\tData 0.053 (0.088)\tLoss 0.9464 (0.6654)\tAcc 0.625 (0.742)\n",
      "Epoch: [96][9/18]\tTime 0.084 (0.108)\tData 0.057 (0.085)\tLoss 0.2049 (0.6142)\tAcc 1.000 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [96][10/18]\tTime 0.076 (0.105)\tData 0.053 (0.081)\tLoss 1.3386 (0.6867)\tAcc 0.562 (0.750)\n",
      "Epoch: [96][11/18]\tTime 0.075 (0.102)\tData 0.055 (0.079)\tLoss 1.2866 (0.7412)\tAcc 0.375 (0.716)\n",
      "Epoch: [96][12/18]\tTime 0.074 (0.100)\tData 0.053 (0.077)\tLoss 0.9822 (0.7613)\tAcc 0.688 (0.714)\n",
      "Epoch: [96][13/18]\tTime 0.072 (0.097)\tData 0.053 (0.075)\tLoss 1.1708 (0.7928)\tAcc 0.500 (0.697)\n",
      "Epoch: [96][14/18]\tTime 0.076 (0.096)\tData 0.056 (0.074)\tLoss 0.8447 (0.7965)\tAcc 0.562 (0.688)\n",
      "Epoch: [96][15/18]\tTime 0.077 (0.095)\tData 0.057 (0.073)\tLoss 0.8724 (0.8016)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][16/18]\tTime 0.079 (0.094)\tData 0.059 (0.072)\tLoss 0.7908 (0.8009)\tAcc 0.812 (0.695)\n",
      "Epoch: [96][17/18]\tTime 0.076 (0.093)\tData 0.057 (0.071)\tLoss 0.7776 (0.7995)\tAcc 0.625 (0.691)\n",
      "Epoch: [96][18/18]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6796 (0.7961)\tAcc 0.750 (0.693)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/12]\tTime 0.283 (0.283)\tData 0.248 (0.248)\tLoss 0.5795 (0.5795)\tAcc 0.875 (0.875)\n",
      "Epoch: [97][2/12]\tTime 0.072 (0.177)\tData 0.046 (0.147)\tLoss 0.7940 (0.6867)\tAcc 0.625 (0.750)\n",
      "Epoch: [97][3/12]\tTime 0.079 (0.145)\tData 0.052 (0.116)\tLoss 0.7344 (0.7026)\tAcc 0.562 (0.688)\n",
      "Epoch: [97][4/12]\tTime 0.080 (0.128)\tData 0.052 (0.100)\tLoss 0.5127 (0.6551)\tAcc 0.875 (0.734)\n",
      "Epoch: [97][5/12]\tTime 0.079 (0.119)\tData 0.054 (0.090)\tLoss 0.7590 (0.6759)\tAcc 0.812 (0.750)\n",
      "Epoch: [97][6/12]\tTime 0.078 (0.112)\tData 0.053 (0.084)\tLoss 0.7352 (0.6858)\tAcc 0.688 (0.740)\n",
      "Epoch: [97][7/12]\tTime 0.078 (0.107)\tData 0.053 (0.080)\tLoss 1.1768 (0.7559)\tAcc 0.562 (0.714)\n",
      "Epoch: [97][8/12]\tTime 0.080 (0.104)\tData 0.055 (0.077)\tLoss 0.6053 (0.7371)\tAcc 0.750 (0.719)\n",
      "Epoch: [97][9/12]\tTime 0.077 (0.101)\tData 0.053 (0.074)\tLoss 0.6485 (0.7273)\tAcc 0.750 (0.722)\n",
      "Epoch: [97][10/12]\tTime 0.078 (0.098)\tData 0.055 (0.072)\tLoss 0.5395 (0.7085)\tAcc 0.875 (0.738)\n",
      "Epoch: [97][11/12]\tTime 0.080 (0.097)\tData 0.056 (0.071)\tLoss 0.9863 (0.7337)\tAcc 0.500 (0.716)\n",
      "Epoch: [97][12/12]\tTime 0.078 (0.095)\tData 0.055 (0.069)\tLoss 0.7240 (0.7330)\tAcc 0.800 (0.723)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/18]\tTime 0.375 (0.375)\tData 0.350 (0.350)\tLoss 0.3605 (0.3605)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/18]\tTime 0.078 (0.227)\tData 0.056 (0.203)\tLoss 1.0580 (0.7093)\tAcc 0.438 (0.688)\n",
      "Epoch: [97][3/18]\tTime 0.074 (0.176)\tData 0.052 (0.153)\tLoss 0.7682 (0.7289)\tAcc 0.750 (0.708)\n",
      "Epoch: [97][4/18]\tTime 0.076 (0.151)\tData 0.055 (0.128)\tLoss 0.6839 (0.7177)\tAcc 0.625 (0.688)\n",
      "Epoch: [97][5/18]\tTime 0.075 (0.136)\tData 0.053 (0.113)\tLoss 0.8637 (0.7469)\tAcc 0.688 (0.688)\n",
      "Epoch: [97][6/18]\tTime 0.076 (0.126)\tData 0.053 (0.103)\tLoss 0.4590 (0.6989)\tAcc 0.938 (0.729)\n",
      "Epoch: [97][7/18]\tTime 0.073 (0.118)\tData 0.051 (0.096)\tLoss 0.6773 (0.6958)\tAcc 0.688 (0.723)\n",
      "Epoch: [97][8/18]\tTime 0.074 (0.113)\tData 0.053 (0.090)\tLoss 1.1304 (0.7501)\tAcc 0.562 (0.703)\n",
      "Epoch: [97][9/18]\tTime 0.077 (0.109)\tData 0.055 (0.086)\tLoss 0.2185 (0.6911)\tAcc 1.000 (0.736)\n",
      "Epoch: [97][10/18]\tTime 0.076 (0.105)\tData 0.052 (0.083)\tLoss 1.5301 (0.7750)\tAcc 0.438 (0.706)\n",
      "Epoch: [97][11/18]\tTime 0.072 (0.102)\tData 0.052 (0.080)\tLoss 1.3628 (0.8284)\tAcc 0.375 (0.676)\n",
      "Epoch: [97][12/18]\tTime 0.076 (0.100)\tData 0.057 (0.078)\tLoss 0.9499 (0.8385)\tAcc 0.625 (0.672)\n",
      "Epoch: [97][13/18]\tTime 0.075 (0.098)\tData 0.054 (0.076)\tLoss 1.0157 (0.8522)\tAcc 0.688 (0.673)\n",
      "Epoch: [97][14/18]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.7419 (0.8443)\tAcc 0.625 (0.670)\n",
      "Epoch: [97][15/18]\tTime 0.074 (0.095)\tData 0.055 (0.073)\tLoss 0.8775 (0.8465)\tAcc 0.688 (0.671)\n",
      "Epoch: [97][16/18]\tTime 0.073 (0.093)\tData 0.055 (0.072)\tLoss 0.8842 (0.8489)\tAcc 0.562 (0.664)\n",
      "Epoch: [97][17/18]\tTime 0.075 (0.092)\tData 0.056 (0.071)\tLoss 0.8461 (0.8487)\tAcc 0.625 (0.662)\n",
      "Epoch: [97][18/18]\tTime 0.076 (0.091)\tData 0.057 (0.071)\tLoss 0.8469 (0.8486)\tAcc 0.625 (0.661)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/12]\tTime 0.342 (0.342)\tData 0.312 (0.312)\tLoss 0.9228 (0.9228)\tAcc 0.500 (0.500)\n",
      "Epoch: [98][2/12]\tTime 0.078 (0.210)\tData 0.052 (0.182)\tLoss 0.6810 (0.8019)\tAcc 0.625 (0.562)\n",
      "Epoch: [98][3/12]\tTime 0.080 (0.167)\tData 0.054 (0.139)\tLoss 0.8030 (0.8023)\tAcc 0.625 (0.583)\n",
      "Epoch: [98][4/12]\tTime 0.080 (0.145)\tData 0.053 (0.118)\tLoss 0.3782 (0.6963)\tAcc 0.938 (0.672)\n",
      "Epoch: [98][5/12]\tTime 0.081 (0.132)\tData 0.054 (0.105)\tLoss 0.9464 (0.7463)\tAcc 0.625 (0.663)\n",
      "Epoch: [98][6/12]\tTime 0.081 (0.124)\tData 0.054 (0.096)\tLoss 0.8232 (0.7591)\tAcc 0.688 (0.667)\n",
      "Epoch: [98][7/12]\tTime 0.081 (0.118)\tData 0.057 (0.091)\tLoss 0.5955 (0.7357)\tAcc 0.750 (0.679)\n",
      "Epoch: [98][8/12]\tTime 0.082 (0.113)\tData 0.058 (0.087)\tLoss 0.7901 (0.7425)\tAcc 0.688 (0.680)\n",
      "Epoch: [98][9/12]\tTime 0.078 (0.109)\tData 0.054 (0.083)\tLoss 0.7236 (0.7404)\tAcc 0.688 (0.681)\n",
      "Epoch: [98][10/12]\tTime 0.078 (0.106)\tData 0.055 (0.080)\tLoss 0.8125 (0.7476)\tAcc 0.750 (0.688)\n",
      "Epoch: [98][11/12]\tTime 0.080 (0.104)\tData 0.057 (0.078)\tLoss 0.8099 (0.7533)\tAcc 0.625 (0.682)\n",
      "Epoch: [98][12/12]\tTime 0.078 (0.102)\tData 0.055 (0.076)\tLoss 0.8505 (0.7609)\tAcc 0.733 (0.686)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/18]\tTime 0.298 (0.298)\tData 0.265 (0.265)\tLoss 0.3797 (0.3797)\tAcc 0.875 (0.875)\n",
      "Epoch: [98][2/18]\tTime 0.070 (0.184)\tData 0.048 (0.157)\tLoss 1.0049 (0.6923)\tAcc 0.438 (0.656)\n",
      "Epoch: [98][3/18]\tTime 0.074 (0.147)\tData 0.052 (0.122)\tLoss 0.6837 (0.6895)\tAcc 0.750 (0.688)\n",
      "Epoch: [98][4/18]\tTime 0.073 (0.129)\tData 0.053 (0.105)\tLoss 0.6313 (0.6749)\tAcc 0.688 (0.688)\n",
      "Epoch: [98][5/18]\tTime 0.080 (0.119)\tData 0.059 (0.095)\tLoss 0.8150 (0.7029)\tAcc 0.750 (0.700)\n",
      "Epoch: [98][6/18]\tTime 0.076 (0.112)\tData 0.055 (0.089)\tLoss 0.2545 (0.6282)\tAcc 1.000 (0.750)\n",
      "Epoch: [98][7/18]\tTime 0.074 (0.106)\tData 0.053 (0.084)\tLoss 0.5836 (0.6218)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][8/18]\tTime 0.080 (0.103)\tData 0.057 (0.080)\tLoss 1.0296 (0.6728)\tAcc 0.438 (0.711)\n",
      "Epoch: [98][9/18]\tTime 0.075 (0.100)\tData 0.053 (0.077)\tLoss 0.1487 (0.6146)\tAcc 1.000 (0.743)\n",
      "Epoch: [98][10/18]\tTime 0.076 (0.098)\tData 0.053 (0.075)\tLoss 1.1876 (0.6719)\tAcc 0.500 (0.719)\n",
      "Epoch: [98][11/18]\tTime 0.074 (0.095)\tData 0.052 (0.073)\tLoss 1.4292 (0.7407)\tAcc 0.438 (0.693)\n",
      "Epoch: [98][12/18]\tTime 0.071 (0.093)\tData 0.051 (0.071)\tLoss 0.8870 (0.7529)\tAcc 0.625 (0.688)\n",
      "Epoch: [98][13/18]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 1.0111 (0.7728)\tAcc 0.562 (0.678)\n",
      "Epoch: [98][14/18]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.8324 (0.7770)\tAcc 0.625 (0.674)\n",
      "Epoch: [98][15/18]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.7603 (0.7759)\tAcc 0.688 (0.675)\n",
      "Epoch: [98][16/18]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.8263 (0.7791)\tAcc 0.688 (0.676)\n",
      "Epoch: [98][17/18]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 0.7933 (0.7799)\tAcc 0.625 (0.673)\n",
      "Epoch: [98][18/18]\tTime 0.073 (0.087)\tData 0.054 (0.065)\tLoss 0.6851 (0.7772)\tAcc 0.875 (0.679)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/12]\tTime 0.299 (0.299)\tData 0.268 (0.268)\tLoss 0.4754 (0.4754)\tAcc 0.875 (0.875)\n",
      "Epoch: [99][2/12]\tTime 0.078 (0.189)\tData 0.049 (0.159)\tLoss 0.7661 (0.6207)\tAcc 0.750 (0.812)\n",
      "Epoch: [99][3/12]\tTime 0.077 (0.151)\tData 0.050 (0.123)\tLoss 0.8695 (0.7037)\tAcc 0.562 (0.729)\n",
      "Epoch: [99][4/12]\tTime 0.083 (0.134)\tData 0.052 (0.105)\tLoss 0.8274 (0.7346)\tAcc 0.562 (0.688)\n",
      "Epoch: [99][5/12]\tTime 0.079 (0.123)\tData 0.050 (0.094)\tLoss 0.8644 (0.7606)\tAcc 0.625 (0.675)\n",
      "Epoch: [99][6/12]\tTime 0.076 (0.115)\tData 0.050 (0.087)\tLoss 0.6392 (0.7403)\tAcc 0.812 (0.698)\n",
      "Epoch: [99][7/12]\tTime 0.079 (0.110)\tData 0.054 (0.082)\tLoss 0.5070 (0.7070)\tAcc 0.875 (0.723)\n",
      "Epoch: [99][8/12]\tTime 0.080 (0.106)\tData 0.055 (0.079)\tLoss 0.6798 (0.7036)\tAcc 0.875 (0.742)\n",
      "Epoch: [99][9/12]\tTime 0.077 (0.103)\tData 0.054 (0.076)\tLoss 0.5274 (0.6840)\tAcc 0.875 (0.757)\n",
      "Epoch: [99][10/12]\tTime 0.078 (0.101)\tData 0.055 (0.074)\tLoss 0.8554 (0.7012)\tAcc 0.625 (0.744)\n",
      "Epoch: [99][11/12]\tTime 0.080 (0.099)\tData 0.056 (0.072)\tLoss 0.7280 (0.7036)\tAcc 0.625 (0.733)\n",
      "Epoch: [99][12/12]\tTime 0.078 (0.097)\tData 0.055 (0.071)\tLoss 1.0012 (0.7270)\tAcc 0.600 (0.723)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/18]\tTime 0.309 (0.309)\tData 0.283 (0.283)\tLoss 0.3299 (0.3299)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/18]\tTime 0.074 (0.192)\tData 0.049 (0.166)\tLoss 1.1527 (0.7413)\tAcc 0.438 (0.688)\n",
      "Epoch: [99][3/18]\tTime 0.070 (0.151)\tData 0.049 (0.127)\tLoss 0.6005 (0.6943)\tAcc 0.875 (0.750)\n",
      "Epoch: [99][4/18]\tTime 0.075 (0.132)\tData 0.053 (0.109)\tLoss 0.6441 (0.6818)\tAcc 0.688 (0.734)\n",
      "Epoch: [99][5/18]\tTime 0.074 (0.120)\tData 0.054 (0.098)\tLoss 0.7794 (0.7013)\tAcc 0.812 (0.750)\n",
      "Epoch: [99][6/18]\tTime 0.074 (0.113)\tData 0.053 (0.090)\tLoss 0.3004 (0.6345)\tAcc 1.000 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [99][7/18]\tTime 0.077 (0.108)\tData 0.054 (0.085)\tLoss 0.7749 (0.6545)\tAcc 0.625 (0.768)\n",
      "Epoch: [99][8/18]\tTime 0.075 (0.103)\tData 0.053 (0.081)\tLoss 1.0156 (0.6997)\tAcc 0.625 (0.750)\n",
      "Epoch: [99][9/18]\tTime 0.075 (0.100)\tData 0.053 (0.078)\tLoss 0.2606 (0.6509)\tAcc 1.000 (0.778)\n",
      "Epoch: [99][10/18]\tTime 0.077 (0.098)\tData 0.054 (0.076)\tLoss 1.1257 (0.6984)\tAcc 0.562 (0.756)\n",
      "Epoch: [99][11/18]\tTime 0.072 (0.096)\tData 0.051 (0.073)\tLoss 1.4176 (0.7638)\tAcc 0.375 (0.722)\n",
      "Epoch: [99][12/18]\tTime 0.074 (0.094)\tData 0.053 (0.072)\tLoss 0.9314 (0.7777)\tAcc 0.750 (0.724)\n",
      "Epoch: [99][13/18]\tTime 0.072 (0.092)\tData 0.053 (0.070)\tLoss 1.1131 (0.8035)\tAcc 0.500 (0.707)\n",
      "Epoch: [99][14/18]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.7960 (0.8030)\tAcc 0.688 (0.705)\n",
      "Epoch: [99][15/18]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 0.8273 (0.8046)\tAcc 0.750 (0.708)\n",
      "Epoch: [99][16/18]\tTime 0.079 (0.089)\tData 0.056 (0.068)\tLoss 0.8639 (0.8083)\tAcc 0.750 (0.711)\n",
      "Epoch: [99][17/18]\tTime 0.081 (0.089)\tData 0.061 (0.067)\tLoss 0.7568 (0.8053)\tAcc 0.688 (0.710)\n",
      "Epoch: [99][18/18]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 0.8238 (0.8058)\tAcc 0.750 (0.711)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/12]\tTime 0.333 (0.333)\tData 0.288 (0.288)\tLoss 0.6805 (0.6805)\tAcc 0.625 (0.625)\n",
      "Epoch: [100][2/12]\tTime 0.077 (0.205)\tData 0.036 (0.162)\tLoss 0.6181 (0.6493)\tAcc 0.812 (0.719)\n",
      "Epoch: [100][3/12]\tTime 0.084 (0.165)\tData 0.040 (0.121)\tLoss 0.4103 (0.5696)\tAcc 0.938 (0.792)\n",
      "Epoch: [100][4/12]\tTime 0.064 (0.140)\tData 0.035 (0.100)\tLoss 0.5839 (0.5732)\tAcc 0.750 (0.781)\n",
      "Epoch: [100][5/12]\tTime 0.086 (0.129)\tData 0.052 (0.090)\tLoss 0.6999 (0.5986)\tAcc 0.750 (0.775)\n",
      "Epoch: [100][6/12]\tTime 0.089 (0.122)\tData 0.056 (0.084)\tLoss 0.6794 (0.6120)\tAcc 0.688 (0.760)\n",
      "Epoch: [100][7/12]\tTime 0.083 (0.117)\tData 0.055 (0.080)\tLoss 0.5749 (0.6067)\tAcc 0.750 (0.759)\n",
      "Epoch: [100][8/12]\tTime 0.090 (0.113)\tData 0.065 (0.078)\tLoss 0.5652 (0.6015)\tAcc 0.812 (0.766)\n",
      "Epoch: [100][9/12]\tTime 0.086 (0.110)\tData 0.062 (0.076)\tLoss 0.7040 (0.6129)\tAcc 0.750 (0.764)\n",
      "Epoch: [100][10/12]\tTime 0.087 (0.108)\tData 0.063 (0.075)\tLoss 0.7305 (0.6247)\tAcc 0.688 (0.756)\n",
      "Epoch: [100][11/12]\tTime 0.087 (0.106)\tData 0.062 (0.074)\tLoss 0.7072 (0.6322)\tAcc 0.688 (0.750)\n",
      "Epoch: [100][12/12]\tTime 0.081 (0.104)\tData 0.057 (0.072)\tLoss 0.7280 (0.6397)\tAcc 0.733 (0.749)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/18]\tTime 0.332 (0.332)\tData 0.305 (0.305)\tLoss 0.3074 (0.3074)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/18]\tTime 0.069 (0.201)\tData 0.048 (0.176)\tLoss 1.0289 (0.6682)\tAcc 0.438 (0.688)\n",
      "Epoch: [100][3/18]\tTime 0.084 (0.162)\tData 0.056 (0.136)\tLoss 0.5994 (0.6453)\tAcc 0.812 (0.729)\n",
      "Epoch: [100][4/18]\tTime 0.074 (0.140)\tData 0.052 (0.115)\tLoss 0.6179 (0.6384)\tAcc 0.625 (0.703)\n",
      "Epoch: [100][5/18]\tTime 0.085 (0.129)\tData 0.059 (0.104)\tLoss 0.8349 (0.6777)\tAcc 0.688 (0.700)\n",
      "Epoch: [100][6/18]\tTime 0.076 (0.120)\tData 0.054 (0.096)\tLoss 0.2963 (0.6141)\tAcc 1.000 (0.750)\n",
      "Epoch: [100][7/18]\tTime 0.080 (0.115)\tData 0.059 (0.090)\tLoss 0.6776 (0.6232)\tAcc 0.688 (0.741)\n",
      "Epoch: [100][8/18]\tTime 0.083 (0.111)\tData 0.059 (0.086)\tLoss 0.9610 (0.6654)\tAcc 0.688 (0.734)\n",
      "Epoch: [100][9/18]\tTime 0.088 (0.108)\tData 0.066 (0.084)\tLoss 0.2460 (0.6188)\tAcc 1.000 (0.764)\n",
      "Epoch: [100][10/18]\tTime 0.086 (0.106)\tData 0.060 (0.082)\tLoss 1.3530 (0.6922)\tAcc 0.375 (0.725)\n",
      "Epoch: [100][11/18]\tTime 0.076 (0.103)\tData 0.055 (0.079)\tLoss 1.2606 (0.7439)\tAcc 0.438 (0.699)\n",
      "Epoch: [100][12/18]\tTime 0.081 (0.101)\tData 0.061 (0.078)\tLoss 1.0776 (0.7717)\tAcc 0.562 (0.688)\n",
      "Epoch: [100][13/18]\tTime 0.082 (0.100)\tData 0.060 (0.076)\tLoss 0.9900 (0.7885)\tAcc 0.562 (0.678)\n",
      "Epoch: [100][14/18]\tTime 0.077 (0.098)\tData 0.057 (0.075)\tLoss 0.8953 (0.7961)\tAcc 0.625 (0.674)\n",
      "Epoch: [100][15/18]\tTime 0.081 (0.097)\tData 0.061 (0.074)\tLoss 0.8564 (0.8002)\tAcc 0.688 (0.675)\n",
      "Epoch: [100][16/18]\tTime 0.081 (0.096)\tData 0.060 (0.073)\tLoss 0.7566 (0.7974)\tAcc 0.750 (0.680)\n",
      "Epoch: [100][17/18]\tTime 0.080 (0.095)\tData 0.060 (0.072)\tLoss 0.8097 (0.7982)\tAcc 0.625 (0.676)\n",
      "Epoch: [100][18/18]\tTime 0.079 (0.094)\tData 0.060 (0.072)\tLoss 0.8437 (0.7995)\tAcc 0.750 (0.679)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:04:39.110420Z",
     "start_time": "2020-04-13T23:04:39.073744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/56]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/CSCE636-project-porta/videos/jpg_door3/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:04:41.547074Z",
     "start_time": "2020-04-13T23:04:41.531314Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:04:54.531169Z",
     "start_time": "2020-04-13T23:04:42.072491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 68 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:04:58.151658Z",
     "start_time": "2020-04-13T23:04:58.111047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 1.8549220561981201},\n",
       " {'label': 'none', 'score': 1.8549220561981201},\n",
       " {'label': 'none', 'score': 1.8549220561981201},\n",
       " {'label': 'none', 'score': 2.499387502670288},\n",
       " {'label': 'none', 'score': 2.499387502670288},\n",
       " {'label': 'none', 'score': 2.499387502670288},\n",
       " {'label': 'none', 'score': 1.2919776439666748},\n",
       " {'label': 'none', 'score': 1.2919776439666748},\n",
       " {'label': 'none', 'score': 1.2919776439666748},\n",
       " {'label': 'none', 'score': 1.7451896667480469},\n",
       " {'label': 'none', 'score': 1.7451896667480469},\n",
       " {'label': 'none', 'score': 1.7451896667480469},\n",
       " {'label': 'none', 'score': 1.383719801902771},\n",
       " {'label': 'none', 'score': 1.383719801902771},\n",
       " {'label': 'none', 'score': 1.383719801902771},\n",
       " {'label': 'none', 'score': 1.6983118057250977},\n",
       " {'label': 'none', 'score': 1.6983118057250977},\n",
       " {'label': 'none', 'score': 1.6983118057250977},\n",
       " {'label': 'none', 'score': 2.198748826980591},\n",
       " {'label': 'none', 'score': 2.198748826980591},\n",
       " {'label': 'none', 'score': 2.198748826980591},\n",
       " {'label': 'none', 'score': 2.5254311561584473},\n",
       " {'label': 'none', 'score': 2.5254311561584473},\n",
       " {'label': 'none', 'score': 2.5254311561584473},\n",
       " {'label': 'none', 'score': 1.4965360164642334},\n",
       " {'label': 'none', 'score': 1.4965360164642334},\n",
       " {'label': 'none', 'score': 1.4965360164642334},\n",
       " {'label': 'none', 'score': 1.8101470470428467},\n",
       " {'label': 'none', 'score': 1.8101470470428467},\n",
       " {'label': 'none', 'score': 1.8101470470428467},\n",
       " {'label': 'none', 'score': 2.224747896194458},\n",
       " {'label': 'none', 'score': 2.224747896194458},\n",
       " {'label': 'none', 'score': 2.224747896194458},\n",
       " {'label': 'none', 'score': 1.6858749389648438},\n",
       " {'label': 'none', 'score': 1.6858749389648438},\n",
       " {'label': 'none', 'score': 1.6858749389648438},\n",
       " {'label': 'none', 'score': 1.9189019203186035},\n",
       " {'label': 'none', 'score': 1.9189019203186035},\n",
       " {'label': 'none', 'score': 1.9189019203186035},\n",
       " {'label': 'none', 'score': 1.9213764667510986},\n",
       " {'label': 'none', 'score': 1.9213764667510986},\n",
       " {'label': 'none', 'score': 1.9213764667510986},\n",
       " {'label': 'none', 'score': 1.7693023681640625},\n",
       " {'label': 'none', 'score': 1.7693023681640625},\n",
       " {'label': 'none', 'score': 1.7693023681640625},\n",
       " {'label': 'none', 'score': 1.8538013696670532},\n",
       " {'label': 'none', 'score': 1.8538013696670532},\n",
       " {'label': 'none', 'score': 1.8538013696670532},\n",
       " {'label': 'none', 'score': 1.8608876466751099},\n",
       " {'label': 'none', 'score': 1.8608876466751099},\n",
       " {'label': 'none', 'score': 1.8608876466751099},\n",
       " {'label': 'none', 'score': 2.034414529800415},\n",
       " {'label': 'none', 'score': 2.034414529800415},\n",
       " {'label': 'none', 'score': 2.034414529800415},\n",
       " {'label': 'none', 'score': 1.566756248474121},\n",
       " {'label': 'none', 'score': 1.566756248474121},\n",
       " {'label': 'none', 'score': 1.566756248474121},\n",
       " {'label': 'none', 'score': 2.1452431678771973},\n",
       " {'label': 'none', 'score': 2.1452431678771973},\n",
       " {'label': 'none', 'score': 2.1452431678771973},\n",
       " {'label': 'none', 'score': 2.516040325164795},\n",
       " {'label': 'none', 'score': 2.516040325164795},\n",
       " {'label': 'none', 'score': 2.516040325164795},\n",
       " {'label': 'none', 'score': 1.262361764907837},\n",
       " {'label': 'none', 'score': 1.262361764907837},\n",
       " {'label': 'none', 'score': 1.262361764907837},\n",
       " {'label': 'returning', 'score': 0.775615930557251},\n",
       " {'label': 'returning', 'score': 0.775615930557251},\n",
       " {'label': 'returning', 'score': 0.775615930557251},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.5601652264595032},\n",
       " {'label': 'returning', 'score': 0.5601652264595032},\n",
       " {'label': 'returning', 'score': 0.5601652264595032},\n",
       " {'label': 'returning', 'score': 1.2816720008850098},\n",
       " {'label': 'returning', 'score': 1.2816720008850098},\n",
       " {'label': 'returning', 'score': 1.2816720008850098},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.3970968723297119},\n",
       " {'label': 'returning', 'score': 0.3970968723297119},\n",
       " {'label': 'returning', 'score': 0.3970968723297119},\n",
       " {'label': 'returning', 'score': 0.3424059748649597},\n",
       " {'label': 'returning', 'score': 0.3424059748649597},\n",
       " {'label': 'returning', 'score': 0.3424059748649597},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.3203265070915222},\n",
       " {'label': 'returning', 'score': 0.3203265070915222},\n",
       " {'label': 'returning', 'score': 0.3203265070915222},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.4003525972366333},\n",
       " {'label': 'none', 'score': 1.4003525972366333},\n",
       " {'label': 'none', 'score': 1.4003525972366333},\n",
       " {'label': 'none', 'score': 2.4829206466674805},\n",
       " {'label': 'none', 'score': 2.4829206466674805},\n",
       " {'label': 'none', 'score': 2.4829206466674805},\n",
       " {'label': 'none', 'score': 1.8923403024673462},\n",
       " {'label': 'none', 'score': 1.8923403024673462},\n",
       " {'label': 'none', 'score': 1.8923403024673462},\n",
       " {'label': 'none', 'score': 2.0633084774017334},\n",
       " {'label': 'none', 'score': 2.0633084774017334},\n",
       " {'label': 'none', 'score': 2.0633084774017334},\n",
       " {'label': 'none', 'score': 1.655352234840393},\n",
       " {'label': 'none', 'score': 1.655352234840393},\n",
       " {'label': 'none', 'score': 1.655352234840393},\n",
       " {'label': 'none', 'score': 2.167290687561035},\n",
       " {'label': 'none', 'score': 2.167290687561035},\n",
       " {'label': 'none', 'score': 2.167290687561035},\n",
       " {'label': 'none', 'score': 1.9161449670791626},\n",
       " {'label': 'none', 'score': 1.9161449670791626},\n",
       " {'label': 'none', 'score': 1.9161449670791626},\n",
       " {'label': 'none', 'score': 1.492110013961792},\n",
       " {'label': 'none', 'score': 1.492110013961792},\n",
       " {'label': 'none', 'score': 1.492110013961792},\n",
       " {'label': 'none', 'score': 1.422775387763977},\n",
       " {'label': 'none', 'score': 1.422775387763977},\n",
       " {'label': 'none', 'score': 1.422775387763977},\n",
       " {'label': 'none', 'score': 1.8721874952316284},\n",
       " {'label': 'none', 'score': 1.8721874952316284},\n",
       " {'label': 'none', 'score': 1.8721874952316284},\n",
       " {'label': 'none', 'score': 1.7556242942810059},\n",
       " {'label': 'none', 'score': 1.7556242942810059},\n",
       " {'label': 'none', 'score': 1.7556242942810059},\n",
       " {'label': 'none', 'score': 2.091203451156616},\n",
       " {'label': 'none', 'score': 2.091203451156616},\n",
       " {'label': 'none', 'score': 2.091203451156616},\n",
       " {'label': 'none', 'score': 1.9304677248001099},\n",
       " {'label': 'none', 'score': 1.9304677248001099},\n",
       " {'label': 'none', 'score': 1.9304677248001099},\n",
       " {'label': 'none', 'score': 1.5558161735534668},\n",
       " {'label': 'none', 'score': 1.5558161735534668},\n",
       " {'label': 'none', 'score': 1.5558161735534668},\n",
       " {'label': 'none', 'score': 1.9548624753952026},\n",
       " {'label': 'none', 'score': 1.9548624753952026},\n",
       " {'label': 'none', 'score': 1.9548624753952026},\n",
       " {'label': 'none', 'score': 2.2676262855529785},\n",
       " {'label': 'none', 'score': 2.2676262855529785},\n",
       " {'label': 'none', 'score': 2.2676262855529785},\n",
       " {'label': 'none', 'score': 2.12469482421875},\n",
       " {'label': 'none', 'score': 2.12469482421875},\n",
       " {'label': 'none', 'score': 2.12469482421875},\n",
       " {'label': 'none', 'score': 1.974600076675415},\n",
       " {'label': 'none', 'score': 1.974600076675415},\n",
       " {'label': 'none', 'score': 1.974600076675415},\n",
       " {'label': 'returning', 'score': 1.110700249671936},\n",
       " {'label': 'returning', 'score': 1.110700249671936},\n",
       " {'label': 'returning', 'score': 1.110700249671936},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.44982874393463135},\n",
       " {'label': 'returning', 'score': 0.44982874393463135},\n",
       " {'label': 'returning', 'score': 0.44982874393463135},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 1.139859914779663},\n",
       " {'label': 'returning', 'score': 1.139859914779663},\n",
       " {'label': 'returning', 'score': 1.139859914779663},\n",
       " {'label': 'none', 'score': 1.5491489171981812},\n",
       " {'label': 'none', 'score': 1.5491489171981812},\n",
       " {'label': 'none', 'score': 1.5491489171981812},\n",
       " {'label': 'none', 'score': 1.829342007637024},\n",
       " {'label': 'none', 'score': 1.829342007637024},\n",
       " {'label': 'none', 'score': 1.829342007637024},\n",
       " {'label': 'none', 'score': 1.4051291942596436},\n",
       " {'label': 'none', 'score': 1.4051291942596436},\n",
       " {'label': 'none', 'score': 1.4051291942596436},\n",
       " {'label': 'none', 'score': 1.7018746137619019},\n",
       " {'label': 'none', 'score': 1.7018746137619019},\n",
       " {'label': 'none', 'score': 1.7018746137619019},\n",
       " {'label': 'none', 'score': 1.6299957036972046},\n",
       " {'label': 'none', 'score': 1.6299957036972046},\n",
       " {'label': 'none', 'score': 1.6299957036972046},\n",
       " {'label': 'none', 'score': 1.766629934310913},\n",
       " {'label': 'none', 'score': 1.766629934310913},\n",
       " {'label': 'none', 'score': 1.766629934310913},\n",
       " {'label': 'none', 'score': 2.0585947036743164},\n",
       " {'label': 'none', 'score': 2.0585947036743164},\n",
       " {'label': 'none', 'score': 2.0585947036743164},\n",
       " {'label': 'none', 'score': 1.8590474128723145},\n",
       " {'label': 'none', 'score': 1.8590474128723145},\n",
       " {'label': 'none', 'score': 1.8590474128723145},\n",
       " {'label': 'none', 'score': 1.8593474626541138},\n",
       " {'label': 'none', 'score': 1.8593474626541138},\n",
       " {'label': 'none', 'score': 1.8593474626541138},\n",
       " {'label': 'none', 'score': 1.9769278764724731},\n",
       " {'label': 'none', 'score': 1.9769278764724731},\n",
       " {'label': 'none', 'score': 1.9769278764724731},\n",
       " {'label': 'none', 'score': 1.7569518089294434},\n",
       " {'label': 'none', 'score': 1.7569518089294434},\n",
       " {'label': 'none', 'score': 1.7569518089294434},\n",
       " {'label': 'none', 'score': 2.226677656173706},\n",
       " {'label': 'none', 'score': 2.226677656173706},\n",
       " {'label': 'none', 'score': 2.226677656173706},\n",
       " {'label': 'none', 'score': 1.8640576601028442},\n",
       " {'label': 'none', 'score': 1.8640576601028442},\n",
       " {'label': 'none', 'score': 1.8640576601028442},\n",
       " {'label': 'none', 'score': 1.6993695497512817},\n",
       " {'label': 'none', 'score': 1.6993695497512817},\n",
       " {'label': 'none', 'score': 1.6993695497512817},\n",
       " {'label': 'none', 'score': 1.7354694604873657},\n",
       " {'label': 'none', 'score': 1.7354694604873657},\n",
       " {'label': 'none', 'score': 1.7354694604873657},\n",
       " {'label': 'none', 'score': 1.3628963232040405},\n",
       " {'label': 'none', 'score': 1.3628963232040405},\n",
       " {'label': 'none', 'score': 1.3628963232040405},\n",
       " {'label': 'none', 'score': 1.7014409303665161},\n",
       " {'label': 'none', 'score': 1.7014409303665161},\n",
       " {'label': 'none', 'score': 1.7014409303665161},\n",
       " {'label': 'none', 'score': 2.167595624923706},\n",
       " {'label': 'none', 'score': 2.167595624923706},\n",
       " {'label': 'none', 'score': 2.167595624923706},\n",
       " {'label': 'none', 'score': 1.6518486738204956},\n",
       " {'label': 'none', 'score': 1.6518486738204956},\n",
       " {'label': 'none', 'score': 1.6518486738204956},\n",
       " {'label': 'none', 'score': 1.9302635192871094},\n",
       " {'label': 'none', 'score': 1.9302635192871094},\n",
       " {'label': 'none', 'score': 1.9302635192871094},\n",
       " {'label': 'none', 'score': 1.4668259620666504},\n",
       " {'label': 'none', 'score': 1.4668259620666504},\n",
       " {'label': 'none', 'score': 1.4668259620666504},\n",
       " {'label': 'returning', 'score': 0.15949979424476624},\n",
       " {'label': 'returning', 'score': 0.15949979424476624},\n",
       " {'label': 'returning', 'score': 0.15949979424476624},\n",
       " {'label': 'returning', 'score': 0.23444077372550964},\n",
       " {'label': 'returning', 'score': 0.23444077372550964},\n",
       " {'label': 'returning', 'score': 0.23444077372550964},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.27382516860961914},\n",
       " {'label': 'returning', 'score': 0.27382516860961914},\n",
       " {'label': 'returning', 'score': 0.27382516860961914},\n",
       " {'label': 'returning', 'score': 0.316015362739563},\n",
       " {'label': 'returning', 'score': 0.316015362739563},\n",
       " {'label': 'returning', 'score': 0.316015362739563},\n",
       " {'label': 'returning', 'score': 0.330112099647522},\n",
       " {'label': 'returning', 'score': 0.330112099647522},\n",
       " {'label': 'returning', 'score': 0.330112099647522},\n",
       " {'label': 'returning', 'score': 0.3668942451477051},\n",
       " {'label': 'returning', 'score': 0.3668942451477051},\n",
       " {'label': 'returning', 'score': 0.3668942451477051},\n",
       " {'label': 'returning', 'score': 1.1132582426071167},\n",
       " {'label': 'returning', 'score': 1.1132582426071167},\n",
       " {'label': 'returning', 'score': 1.1132582426071167},\n",
       " {'label': 'none', 'score': 1.5654577016830444},\n",
       " {'label': 'none', 'score': 1.5654577016830444},\n",
       " {'label': 'none', 'score': 1.5654577016830444},\n",
       " {'label': 'none', 'score': 1.5661386251449585},\n",
       " {'label': 'none', 'score': 1.5661386251449585},\n",
       " {'label': 'none', 'score': 1.5661386251449585},\n",
       " {'label': 'none', 'score': 1.4595602750778198},\n",
       " {'label': 'none', 'score': 1.4595602750778198},\n",
       " {'label': 'none', 'score': 1.4595602750778198},\n",
       " {'label': 'none', 'score': 2.222566604614258},\n",
       " {'label': 'none', 'score': 2.222566604614258},\n",
       " {'label': 'none', 'score': 2.222566604614258},\n",
       " {'label': 'none', 'score': 2.2882425785064697},\n",
       " {'label': 'none', 'score': 2.2882425785064697},\n",
       " {'label': 'none', 'score': 2.2882425785064697},\n",
       " {'label': 'none', 'score': 2.124490976333618},\n",
       " {'label': 'none', 'score': 2.124490976333618},\n",
       " {'label': 'none', 'score': 2.124490976333618},\n",
       " {'label': 'none', 'score': 1.5937857627868652},\n",
       " {'label': 'none', 'score': 1.5937857627868652},\n",
       " {'label': 'none', 'score': 1.5937857627868652},\n",
       " {'label': 'none', 'score': 1.8999419212341309},\n",
       " {'label': 'none', 'score': 1.8999419212341309},\n",
       " {'label': 'none', 'score': 1.8999419212341309},\n",
       " {'label': 'none', 'score': 1.7272869348526},\n",
       " {'label': 'none', 'score': 1.7272869348526},\n",
       " {'label': 'none', 'score': 1.7272869348526},\n",
       " {'label': 'none', 'score': 1.7147462368011475},\n",
       " {'label': 'none', 'score': 1.7147462368011475},\n",
       " {'label': 'none', 'score': 1.7147462368011475},\n",
       " {'label': 'none', 'score': 1.8759199380874634},\n",
       " {'label': 'none', 'score': 1.8759199380874634},\n",
       " {'label': 'none', 'score': 1.8759199380874634},\n",
       " {'label': 'none', 'score': 1.3466941118240356},\n",
       " {'label': 'none', 'score': 1.3466941118240356},\n",
       " {'label': 'none', 'score': 1.3466941118240356},\n",
       " {'label': 'none', 'score': 1.5712321996688843},\n",
       " {'label': 'none', 'score': 1.5712321996688843},\n",
       " {'label': 'none', 'score': 1.5712321996688843},\n",
       " {'label': 'none', 'score': 1.6295297145843506},\n",
       " {'label': 'none', 'score': 1.6295297145843506},\n",
       " {'label': 'none', 'score': 1.6295297145843506},\n",
       " {'label': 'none', 'score': 2.0547120571136475},\n",
       " {'label': 'none', 'score': 2.0547120571136475},\n",
       " {'label': 'none', 'score': 2.0547120571136475},\n",
       " {'label': 'none', 'score': 2.4445438385009766},\n",
       " {'label': 'none', 'score': 2.4445438385009766},\n",
       " {'label': 'none', 'score': 2.4445438385009766},\n",
       " {'label': 'none', 'score': 1.4001003503799438},\n",
       " {'label': 'none', 'score': 1.4001003503799438},\n",
       " {'label': 'none', 'score': 1.4001003503799438},\n",
       " {'label': 'none', 'score': 1.9948594570159912},\n",
       " {'label': 'none', 'score': 1.9948594570159912},\n",
       " {'label': 'none', 'score': 1.9948594570159912},\n",
       " {'label': 'none', 'score': 1.3399531841278076},\n",
       " {'label': 'none', 'score': 1.3399531841278076},\n",
       " {'label': 'none', 'score': 1.3399531841278076},\n",
       " {'label': 'returning', 'score': 1.4549592733383179},\n",
       " {'label': 'returning', 'score': 1.4549592733383179},\n",
       " {'label': 'returning', 'score': 1.4549592733383179},\n",
       " {'label': 'returning', 'score': 0.44156336784362793},\n",
       " {'label': 'returning', 'score': 0.44156336784362793},\n",
       " {'label': 'returning', 'score': 0.44156336784362793},\n",
       " {'label': 'returning', 'score': 0.29521527886390686},\n",
       " {'label': 'returning', 'score': 0.29521527886390686},\n",
       " {'label': 'returning', 'score': 0.29521527886390686},\n",
       " {'label': 'returning', 'score': 0.6040874719619751},\n",
       " {'label': 'returning', 'score': 0.6040874719619751},\n",
       " {'label': 'returning', 'score': 0.6040874719619751},\n",
       " {'label': 'returning', 'score': 0.13718470931053162},\n",
       " {'label': 'returning', 'score': 0.13718470931053162},\n",
       " {'label': 'returning', 'score': 0.13718470931053162},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.0666069984436035},\n",
       " {'label': 'none', 'score': 1.0666069984436035},\n",
       " {'label': 'none', 'score': 1.0666069984436035},\n",
       " {'label': 'returning', 'score': 1.9217910766601562},\n",
       " {'label': 'returning', 'score': 1.9217910766601562},\n",
       " {'label': 'returning', 'score': 1.9217910766601562},\n",
       " {'label': 'none', 'score': 2.005709409713745},\n",
       " {'label': 'none', 'score': 2.005709409713745},\n",
       " {'label': 'none', 'score': 2.005709409713745},\n",
       " {'label': 'none', 'score': 1.7318265438079834},\n",
       " {'label': 'none', 'score': 1.7318265438079834},\n",
       " {'label': 'none', 'score': 1.7318265438079834},\n",
       " {'label': 'none', 'score': 1.8869359493255615},\n",
       " {'label': 'none', 'score': 1.8869359493255615},\n",
       " {'label': 'none', 'score': 1.8869359493255615},\n",
       " {'label': 'none', 'score': 1.8150575160980225},\n",
       " {'label': 'none', 'score': 1.8150575160980225},\n",
       " {'label': 'none', 'score': 1.8150575160980225},\n",
       " {'label': 'none', 'score': 1.7016911506652832},\n",
       " {'label': 'none', 'score': 1.7016911506652832},\n",
       " {'label': 'none', 'score': 1.7016911506652832},\n",
       " {'label': 'none', 'score': 2.0744800567626953},\n",
       " {'label': 'none', 'score': 2.0744800567626953},\n",
       " {'label': 'none', 'score': 2.0744800567626953},\n",
       " {'label': 'none', 'score': 1.6165019273757935},\n",
       " {'label': 'none', 'score': 1.6165019273757935},\n",
       " {'label': 'none', 'score': 1.6165019273757935},\n",
       " {'label': 'none', 'score': 2.014963150024414},\n",
       " {'label': 'none', 'score': 2.014963150024414},\n",
       " {'label': 'none', 'score': 2.014963150024414},\n",
       " {'label': 'none', 'score': 1.5099928379058838},\n",
       " {'label': 'none', 'score': 1.5099928379058838},\n",
       " {'label': 'none', 'score': 1.5099928379058838},\n",
       " {'label': 'none', 'score': 1.8399375677108765},\n",
       " {'label': 'none', 'score': 1.8399375677108765},\n",
       " {'label': 'none', 'score': 1.8399375677108765},\n",
       " {'label': 'none', 'score': 2.207390546798706},\n",
       " {'label': 'none', 'score': 2.207390546798706},\n",
       " {'label': 'none', 'score': 2.207390546798706},\n",
       " {'label': 'none', 'score': 1.542690634727478},\n",
       " {'label': 'none', 'score': 1.542690634727478},\n",
       " {'label': 'none', 'score': 1.542690634727478},\n",
       " {'label': 'none', 'score': 1.7021760940551758},\n",
       " {'label': 'none', 'score': 1.7021760940551758},\n",
       " {'label': 'none', 'score': 1.7021760940551758},\n",
       " {'label': 'none', 'score': 1.8753732442855835},\n",
       " {'label': 'none', 'score': 1.8753732442855835},\n",
       " {'label': 'none', 'score': 1.8753732442855835},\n",
       " {'label': 'none', 'score': 1.6055011749267578},\n",
       " {'label': 'none', 'score': 1.6055011749267578},\n",
       " {'label': 'none', 'score': 1.6055011749267578},\n",
       " {'label': 'none', 'score': 2.8079006671905518},\n",
       " {'label': 'none', 'score': 2.8079006671905518},\n",
       " {'label': 'none', 'score': 2.8079006671905518},\n",
       " {'label': 'returning', 'score': 1.617978572845459},\n",
       " {'label': 'returning', 'score': 1.617978572845459},\n",
       " {'label': 'returning', 'score': 1.617978572845459},\n",
       " {'label': 'returning', 'score': 0.4732481837272644},\n",
       " {'label': 'returning', 'score': 0.4732481837272644},\n",
       " {'label': 'returning', 'score': 0.4732481837272644},\n",
       " {'label': 'returning', 'score': 1.178716778755188},\n",
       " {'label': 'returning', 'score': 1.178716778755188},\n",
       " {'label': 'returning', 'score': 1.178716778755188},\n",
       " {'label': 'none', 'score': 1.2673825025558472},\n",
       " {'label': 'none', 'score': 1.2673825025558472},\n",
       " {'label': 'none', 'score': 1.2673825025558472},\n",
       " {'label': 'none', 'score': 1.3418920040130615},\n",
       " {'label': 'none', 'score': 1.3418920040130615},\n",
       " {'label': 'none', 'score': 1.3418920040130615},\n",
       " {'label': 'none', 'score': 1.3660582304000854},\n",
       " {'label': 'none', 'score': 1.3660582304000854},\n",
       " {'label': 'none', 'score': 1.3660582304000854},\n",
       " {'label': 'none', 'score': 2.1817116737365723},\n",
       " {'label': 'none', 'score': 2.1817116737365723},\n",
       " {'label': 'none', 'score': 2.1817116737365723},\n",
       " {'label': 'none', 'score': 1.0700511932373047},\n",
       " {'label': 'none', 'score': 1.0700511932373047},\n",
       " {'label': 'none', 'score': 1.0700511932373047},\n",
       " {'label': 'none', 'score': 1.9528781175613403},\n",
       " {'label': 'none', 'score': 1.9528781175613403},\n",
       " {'label': 'none', 'score': 1.9528781175613403},\n",
       " {'label': 'none', 'score': 1.4773073196411133},\n",
       " {'label': 'none', 'score': 1.4773073196411133},\n",
       " {'label': 'none', 'score': 1.4773073196411133},\n",
       " {'label': 'none', 'score': 1.8207871913909912},\n",
       " {'label': 'none', 'score': 1.8207871913909912},\n",
       " {'label': 'none', 'score': 1.8207871913909912},\n",
       " {'label': 'none', 'score': 1.2563120126724243},\n",
       " {'label': 'none', 'score': 1.2563120126724243},\n",
       " {'label': 'none', 'score': 1.2563120126724243},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.5343137979507446},\n",
       " {'label': 'returning', 'score': 0.5343137979507446},\n",
       " {'label': 'returning', 'score': 0.5343137979507446},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.3446251153945923},\n",
       " {'label': 'returning', 'score': 0.3446251153945923},\n",
       " {'label': 'returning', 'score': 0.3446251153945923},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.9128245115280151},\n",
       " {'label': 'none', 'score': 1.9128245115280151},\n",
       " {'label': 'none', 'score': 1.9128245115280151},\n",
       " {'label': 'none', 'score': 1.1343168020248413},\n",
       " {'label': 'none', 'score': 1.1343168020248413},\n",
       " {'label': 'none', 'score': 1.1343168020248413},\n",
       " {'label': 'none', 'score': 1.8130816221237183},\n",
       " {'label': 'none', 'score': 1.8130816221237183},\n",
       " {'label': 'none', 'score': 1.8130816221237183},\n",
       " {'label': 'none', 'score': 2.458231210708618},\n",
       " {'label': 'none', 'score': 2.458231210708618},\n",
       " {'label': 'none', 'score': 2.458231210708618},\n",
       " {'label': 'none', 'score': 1.5659319162368774},\n",
       " {'label': 'none', 'score': 1.5659319162368774},\n",
       " {'label': 'none', 'score': 1.5659319162368774},\n",
       " {'label': 'none', 'score': 1.5929137468338013},\n",
       " {'label': 'none', 'score': 1.5929137468338013},\n",
       " {'label': 'none', 'score': 1.5929137468338013},\n",
       " {'label': 'none', 'score': 2.3923232555389404},\n",
       " {'label': 'none', 'score': 2.3923232555389404},\n",
       " {'label': 'none', 'score': 2.3923232555389404},\n",
       " {'label': 'none', 'score': 2.047157049179077},\n",
       " {'label': 'none', 'score': 2.047157049179077},\n",
       " {'label': 'none', 'score': 2.047157049179077},\n",
       " {'label': 'none', 'score': 1.8209388256072998},\n",
       " {'label': 'none', 'score': 1.8209388256072998},\n",
       " {'label': 'none', 'score': 1.8209388256072998},\n",
       " {'label': 'none', 'score': 2.3337392807006836},\n",
       " {'label': 'none', 'score': 2.3337392807006836},\n",
       " {'label': 'none', 'score': 2.3337392807006836},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.358613133430481},\n",
       " {'label': 'none', 'score': 1.358613133430481},\n",
       " {'label': 'none', 'score': 1.358613133430481},\n",
       " {'label': 'returning', 'score': 1.1649352312088013},\n",
       " {'label': 'returning', 'score': 1.1649352312088013},\n",
       " {'label': 'returning', 'score': 1.1649352312088013},\n",
       " {'label': 'returning', 'score': 0.49679791927337646},\n",
       " {'label': 'returning', 'score': 0.49679791927337646},\n",
       " {'label': 'returning', 'score': 0.49679791927337646},\n",
       " {'label': 'returning', 'score': 0.25348055362701416},\n",
       " {'label': 'returning', 'score': 0.25348055362701416},\n",
       " {'label': 'returning', 'score': 0.25348055362701416},\n",
       " {'label': 'returning', 'score': 0.3377719521522522},\n",
       " {'label': 'returning', 'score': 0.3377719521522522},\n",
       " {'label': 'returning', 'score': 0.3377719521522522},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.42834335565567017},\n",
       " {'label': 'returning', 'score': 0.42834335565567017},\n",
       " {'label': 'returning', 'score': 0.42834335565567017},\n",
       " {'label': 'returning', 'score': 1.289839506149292},\n",
       " {'label': 'returning', 'score': 1.289839506149292},\n",
       " {'label': 'returning', 'score': 1.289839506149292},\n",
       " {'label': 'none', 'score': 1.4020546674728394},\n",
       " {'label': 'none', 'score': 1.4020546674728394},\n",
       " {'label': 'none', 'score': 1.4020546674728394},\n",
       " {'label': 'none', 'score': 1.7802634239196777},\n",
       " {'label': 'none', 'score': 1.7802634239196777},\n",
       " {'label': 'none', 'score': 1.7802634239196777},\n",
       " {'label': 'none', 'score': 1.6661304235458374},\n",
       " {'label': 'none', 'score': 1.6661304235458374},\n",
       " {'label': 'none', 'score': 1.6661304235458374},\n",
       " {'label': 'none', 'score': 1.5693130493164062},\n",
       " {'label': 'none', 'score': 1.5693130493164062},\n",
       " {'label': 'none', 'score': 1.5693130493164062},\n",
       " {'label': 'none', 'score': 1.883497953414917},\n",
       " {'label': 'none', 'score': 1.883497953414917},\n",
       " {'label': 'none', 'score': 1.883497953414917},\n",
       " {'label': 'none', 'score': 1.9377926588058472},\n",
       " {'label': 'none', 'score': 1.9377926588058472},\n",
       " {'label': 'none', 'score': 1.9377926588058472},\n",
       " {'label': 'none', 'score': 2.2979989051818848},\n",
       " {'label': 'none', 'score': 2.2979989051818848},\n",
       " {'label': 'none', 'score': 2.2979989051818848},\n",
       " {'label': 'none', 'score': 1.9648076295852661},\n",
       " {'label': 'none', 'score': 1.9648076295852661},\n",
       " {'label': 'none', 'score': 1.9648076295852661},\n",
       " {'label': 'none', 'score': 2.118136405944824},\n",
       " {'label': 'none', 'score': 2.118136405944824},\n",
       " {'label': 'none', 'score': 2.118136405944824},\n",
       " {'label': 'none', 'score': 2.485809803009033},\n",
       " {'label': 'none', 'score': 2.485809803009033},\n",
       " {'label': 'none', 'score': 2.485809803009033},\n",
       " {'label': 'none', 'score': 1.8824299573898315},\n",
       " {'label': 'none', 'score': 1.8824299573898315},\n",
       " {'label': 'none', 'score': 1.8824299573898315},\n",
       " {'label': 'none', 'score': 1.6532245874404907},\n",
       " {'label': 'none', 'score': 1.6532245874404907},\n",
       " {'label': 'none', 'score': 1.6532245874404907},\n",
       " {'label': 'returning', 'score': 0.41593626141548157},\n",
       " {'label': 'returning', 'score': 0.41593626141548157},\n",
       " {'label': 'returning', 'score': 0.41593626141548157},\n",
       " {'label': 'returning', 'score': 0.4879179000854492},\n",
       " {'label': 'returning', 'score': 0.4879179000854492},\n",
       " {'label': 'returning', 'score': 0.4879179000854492},\n",
       " {'label': 'returning', 'score': 0.35476842522621155},\n",
       " {'label': 'returning', 'score': 0.35476842522621155},\n",
       " {'label': 'returning', 'score': 0.35476842522621155},\n",
       " {'label': 'returning', 'score': 0.36056897044181824},\n",
       " {'label': 'returning', 'score': 0.36056897044181824},\n",
       " {'label': 'returning', 'score': 0.36056897044181824},\n",
       " {'label': 'leaving', 'score': 0.44578784704208374},\n",
       " {'label': 'leaving', 'score': 0.44578784704208374},\n",
       " {'label': 'leaving', 'score': 0.44578784704208374},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.8859851956367493},\n",
       " {'label': 'returning', 'score': 0.8859851956367493},\n",
       " {'label': 'returning', 'score': 0.8859851956367493},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.2391462326049805},\n",
       " {'label': 'none', 'score': 1.2391462326049805},\n",
       " {'label': 'none', 'score': 1.2391462326049805},\n",
       " {'label': 'none', 'score': 2.13321590423584},\n",
       " {'label': 'none', 'score': 2.13321590423584},\n",
       " {'label': 'none', 'score': 2.13321590423584},\n",
       " {'label': 'none', 'score': 2.4642724990844727},\n",
       " {'label': 'none', 'score': 2.4642724990844727},\n",
       " {'label': 'none', 'score': 2.4642724990844727},\n",
       " {'label': 'none', 'score': 1.7881742715835571},\n",
       " {'label': 'none', 'score': 1.7881742715835571},\n",
       " {'label': 'none', 'score': 1.7881742715835571},\n",
       " {'label': 'none', 'score': 2.1159822940826416},\n",
       " {'label': 'none', 'score': 2.1159822940826416},\n",
       " {'label': 'none', 'score': 2.1159822940826416},\n",
       " {'label': 'none', 'score': 2.563842296600342},\n",
       " {'label': 'none', 'score': 2.563842296600342},\n",
       " {'label': 'none', 'score': 2.563842296600342},\n",
       " {'label': 'none', 'score': 2.034390687942505},\n",
       " {'label': 'none', 'score': 2.034390687942505},\n",
       " {'label': 'none', 'score': 2.034390687942505},\n",
       " {'label': 'none', 'score': 2.1531999111175537},\n",
       " {'label': 'none', 'score': 2.1531999111175537},\n",
       " {'label': 'none', 'score': 2.1531999111175537},\n",
       " {'label': 'none', 'score': 1.9263322353363037},\n",
       " {'label': 'none', 'score': 1.9263322353363037},\n",
       " {'label': 'none', 'score': 1.9263322353363037},\n",
       " {'label': 'none', 'score': 2.3681845664978027},\n",
       " {'label': 'none', 'score': 2.3681845664978027},\n",
       " {'label': 'none', 'score': 2.3681845664978027},\n",
       " {'label': 'none', 'score': 1.6950401067733765},\n",
       " {'label': 'none', 'score': 1.6950401067733765},\n",
       " {'label': 'none', 'score': 1.6950401067733765},\n",
       " {'label': 'none', 'score': 2.6120941638946533},\n",
       " {'label': 'none', 'score': 2.6120941638946533},\n",
       " {'label': 'none', 'score': 2.6120941638946533},\n",
       " {'label': 'none', 'score': 2.54034686088562},\n",
       " {'label': 'none', 'score': 2.54034686088562},\n",
       " {'label': 'none', 'score': 2.54034686088562},\n",
       " {'label': 'none', 'score': 2.1959290504455566},\n",
       " {'label': 'none', 'score': 2.1959290504455566},\n",
       " {'label': 'none', 'score': 2.1959290504455566},\n",
       " {'label': 'none', 'score': 2.0424532890319824},\n",
       " {'label': 'none', 'score': 2.0424532890319824},\n",
       " {'label': 'none', 'score': 2.0424532890319824},\n",
       " {'label': 'none', 'score': 2.2042133808135986},\n",
       " {'label': 'none', 'score': 2.2042133808135986},\n",
       " {'label': 'none', 'score': 2.2042133808135986},\n",
       " {'label': 'none', 'score': 2.0963897705078125},\n",
       " {'label': 'none', 'score': 2.0963897705078125},\n",
       " {'label': 'none', 'score': 2.0963897705078125},\n",
       " {'label': 'none', 'score': 2.5069751739501953},\n",
       " {'label': 'none', 'score': 2.5069751739501953},\n",
       " {'label': 'none', 'score': 2.5069751739501953},\n",
       " {'label': 'none', 'score': 2.0471489429473877},\n",
       " {'label': 'none', 'score': 2.0471489429473877},\n",
       " {'label': 'none', 'score': 2.0471489429473877},\n",
       " {'label': 'none', 'score': 2.0832197666168213},\n",
       " {'label': 'none', 'score': 2.0832197666168213},\n",
       " {'label': 'none', 'score': 2.0832197666168213},\n",
       " {'label': 'none', 'score': 2.312884569168091},\n",
       " {'label': 'none', 'score': 2.312884569168091},\n",
       " {'label': 'none', 'score': 2.312884569168091},\n",
       " {'label': 'none', 'score': 2.277247190475464},\n",
       " {'label': 'none', 'score': 2.277247190475464},\n",
       " {'label': 'none', 'score': 2.277247190475464},\n",
       " {'label': 'none', 'score': 1.9330683946609497},\n",
       " {'label': 'none', 'score': 1.9330683946609497},\n",
       " {'label': 'none', 'score': 1.9330683946609497},\n",
       " {'label': 'none', 'score': 1.7655974626541138},\n",
       " {'label': 'none', 'score': 1.7655974626541138},\n",
       " {'label': 'none', 'score': 1.7655974626541138},\n",
       " {'label': 'none', 'score': 2.2602615356445312},\n",
       " {'label': 'none', 'score': 2.2602615356445312},\n",
       " {'label': 'none', 'score': 2.2602615356445312},\n",
       " {'label': 'none', 'score': 1.9922822713851929},\n",
       " {'label': 'none', 'score': 1.9922822713851929},\n",
       " {'label': 'none', 'score': 1.9922822713851929},\n",
       " {'label': 'none', 'score': 2.1343181133270264},\n",
       " {'label': 'none', 'score': 2.1343181133270264},\n",
       " {'label': 'none', 'score': 2.1343181133270264},\n",
       " {'label': 'none', 'score': 2.426833152770996},\n",
       " {'label': 'none', 'score': 2.426833152770996},\n",
       " {'label': 'none', 'score': 2.426833152770996},\n",
       " {'label': 'none', 'score': 1.7585887908935547},\n",
       " {'label': 'none', 'score': 1.7585887908935547},\n",
       " {'label': 'none', 'score': 1.7585887908935547},\n",
       " {'label': 'none', 'score': 2.1012840270996094},\n",
       " {'label': 'none', 'score': 2.1012840270996094},\n",
       " {'label': 'none', 'score': 2.1012840270996094},\n",
       " {'label': 'none', 'score': 2.3487131595611572},\n",
       " {'label': 'none', 'score': 2.3487131595611572},\n",
       " {'label': 'none', 'score': 2.3487131595611572},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 1.1655992269515991},\n",
       " {'label': 'returning', 'score': 1.1655992269515991},\n",
       " {'label': 'returning', 'score': 1.1655992269515991},\n",
       " {'label': 'returning', 'score': 0.16762016713619232},\n",
       " {'label': 'returning', 'score': 0.16762016713619232},\n",
       " {'label': 'returning', 'score': 0.16762016713619232},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.3318098783493042},\n",
       " {'label': 'none', 'score': 1.3318098783493042},\n",
       " {'label': 'none', 'score': 1.3318098783493042},\n",
       " {'label': 'none', 'score': 1.807023525238037},\n",
       " {'label': 'none', 'score': 1.807023525238037},\n",
       " {'label': 'none', 'score': 1.807023525238037},\n",
       " {'label': 'none', 'score': 1.4233957529067993},\n",
       " {'label': 'none', 'score': 1.4233957529067993},\n",
       " {'label': 'none', 'score': 1.4233957529067993},\n",
       " {'label': 'none', 'score': 1.0223662853240967},\n",
       " {'label': 'none', 'score': 1.0223662853240967},\n",
       " {'label': 'none', 'score': 1.0223662853240967},\n",
       " {'label': 'none', 'score': 0.9906103014945984},\n",
       " {'label': 'none', 'score': 0.9906103014945984},\n",
       " {'label': 'none', 'score': 0.9906103014945984},\n",
       " {'label': 'none', 'score': 2.1538844108581543},\n",
       " {'label': 'none', 'score': 2.1538844108581543},\n",
       " {'label': 'none', 'score': 2.1538844108581543},\n",
       " {'label': 'none', 'score': 2.327404499053955},\n",
       " {'label': 'none', 'score': 2.327404499053955},\n",
       " {'label': 'none', 'score': 2.327404499053955},\n",
       " {'label': 'none', 'score': 2.411026954650879},\n",
       " {'label': 'none', 'score': 2.411026954650879},\n",
       " {'label': 'none', 'score': 2.411026954650879},\n",
       " {'label': 'none', 'score': 2.3724241256713867},\n",
       " {'label': 'none', 'score': 2.3724241256713867},\n",
       " {'label': 'none', 'score': 2.3724241256713867},\n",
       " {'label': 'none', 'score': 2.1597740650177},\n",
       " {'label': 'none', 'score': 2.1597740650177},\n",
       " {'label': 'none', 'score': 2.1597740650177},\n",
       " {'label': 'none', 'score': 2.19204044342041},\n",
       " {'label': 'none', 'score': 2.19204044342041},\n",
       " {'label': 'none', 'score': 2.19204044342041},\n",
       " {'label': 'none', 'score': 2.075023889541626},\n",
       " {'label': 'none', 'score': 2.075023889541626},\n",
       " {'label': 'none', 'score': 2.075023889541626},\n",
       " {'label': 'none', 'score': 2.323185682296753},\n",
       " {'label': 'none', 'score': 2.323185682296753},\n",
       " {'label': 'none', 'score': 2.323185682296753},\n",
       " {'label': 'none', 'score': 2.1457719802856445},\n",
       " {'label': 'none', 'score': 2.1457719802856445},\n",
       " {'label': 'none', 'score': 2.1457719802856445},\n",
       " {'label': 'none', 'score': 2.1363253593444824},\n",
       " {'label': 'none', 'score': 2.1363253593444824},\n",
       " {'label': 'none', 'score': 2.1363253593444824},\n",
       " {'label': 'none', 'score': 1.9866997003555298},\n",
       " {'label': 'none', 'score': 1.9866997003555298},\n",
       " {'label': 'none', 'score': 1.9866997003555298},\n",
       " {'label': 'none', 'score': 1.987662434577942},\n",
       " {'label': 'none', 'score': 1.987662434577942},\n",
       " {'label': 'none', 'score': 1.987662434577942},\n",
       " {'label': 'none', 'score': 2.074472188949585},\n",
       " {'label': 'none', 'score': 2.074472188949585},\n",
       " {'label': 'none', 'score': 2.074472188949585},\n",
       " {'label': 'none', 'score': 2.2579362392425537},\n",
       " {'label': 'none', 'score': 2.2579362392425537},\n",
       " {'label': 'none', 'score': 2.2579362392425537},\n",
       " {'label': 'none', 'score': 2.142099142074585},\n",
       " {'label': 'none', 'score': 2.142099142074585},\n",
       " {'label': 'none', 'score': 2.142099142074585},\n",
       " {'label': 'none', 'score': 1.554275631904602},\n",
       " {'label': 'none', 'score': 1.554275631904602},\n",
       " {'label': 'none', 'score': 1.554275631904602},\n",
       " {'label': 'none', 'score': 1.6381243467330933},\n",
       " {'label': 'none', 'score': 1.6381243467330933},\n",
       " {'label': 'none', 'score': 1.6381243467330933},\n",
       " {'label': 'none', 'score': 1.8317862749099731},\n",
       " {'label': 'none', 'score': 1.8317862749099731},\n",
       " {'label': 'none', 'score': 1.8317862749099731},\n",
       " {'label': 'none', 'score': 1.189041256904602},\n",
       " {'label': 'none', 'score': 1.189041256904602},\n",
       " {'label': 'none', 'score': 1.189041256904602},\n",
       " {'label': 'none', 'score': 1.4465378522872925},\n",
       " {'label': 'none', 'score': 1.4465378522872925},\n",
       " {'label': 'none', 'score': 1.4465378522872925},\n",
       " {'label': 'none', 'score': 1.6749908924102783},\n",
       " {'label': 'none', 'score': 1.6749908924102783},\n",
       " {'label': 'none', 'score': 1.6749908924102783},\n",
       " {'label': 'none', 'score': 0.9523921608924866},\n",
       " {'label': 'none', 'score': 0.9523921608924866},\n",
       " {'label': 'none', 'score': 0.9523921608924866},\n",
       " {'label': 'none', 'score': 0.5820525288581848},\n",
       " {'label': 'none', 'score': 0.5820525288581848},\n",
       " {'label': 'none', 'score': 0.5820525288581848},\n",
       " {'label': 'returning', 'score': 1.248225212097168},\n",
       " {'label': 'returning', 'score': 1.248225212097168},\n",
       " {'label': 'returning', 'score': 1.248225212097168},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.28013134002685547},\n",
       " {'label': 'none', 'score': 0.28013134002685547},\n",
       " {'label': 'none', 'score': 0.28013134002685547},\n",
       " {'label': 'none', 'score': 0.9592275619506836},\n",
       " {'label': 'none', 'score': 0.9592275619506836},\n",
       " {'label': 'none', 'score': 0.9592275619506836},\n",
       " {'label': 'none', 'score': 1.8086612224578857},\n",
       " {'label': 'none', 'score': 1.8086612224578857},\n",
       " {'label': 'none', 'score': 1.8086612224578857},\n",
       " {'label': 'none', 'score': 2.3390285968780518},\n",
       " {'label': 'none', 'score': 2.3390285968780518},\n",
       " {'label': 'none', 'score': 2.3390285968780518},\n",
       " {'label': 'none', 'score': 2.2664828300476074},\n",
       " {'label': 'none', 'score': 2.2664828300476074},\n",
       " {'label': 'none', 'score': 2.2664828300476074},\n",
       " {'label': 'none', 'score': 1.8880616426467896},\n",
       " {'label': 'none', 'score': 1.8880616426467896},\n",
       " {'label': 'none', 'score': 1.8880616426467896},\n",
       " {'label': 'none', 'score': 2.091005802154541},\n",
       " {'label': 'none', 'score': 2.091005802154541},\n",
       " {'label': 'none', 'score': 2.091005802154541},\n",
       " {'label': 'none', 'score': 1.8406563997268677},\n",
       " {'label': 'none', 'score': 1.8406563997268677},\n",
       " {'label': 'none', 'score': 1.8406563997268677},\n",
       " {'label': 'none', 'score': 2.516298532485962},\n",
       " {'label': 'none', 'score': 2.516298532485962},\n",
       " {'label': 'none', 'score': 2.516298532485962},\n",
       " {'label': 'none', 'score': 2.3869385719299316},\n",
       " {'label': 'none', 'score': 2.3869385719299316},\n",
       " {'label': 'none', 'score': 2.3869385719299316},\n",
       " {'label': 'none', 'score': 2.5593583583831787},\n",
       " {'label': 'none', 'score': 2.5593583583831787},\n",
       " {'label': 'none', 'score': 2.5593583583831787},\n",
       " {'label': 'none', 'score': 2.4459784030914307},\n",
       " {'label': 'none', 'score': 2.4459784030914307},\n",
       " {'label': 'none', 'score': 2.4459784030914307},\n",
       " {'label': 'none', 'score': 1.831934928894043},\n",
       " {'label': 'none', 'score': 1.831934928894043},\n",
       " {'label': 'none', 'score': 1.831934928894043},\n",
       " {'label': 'none', 'score': 2.7408156394958496},\n",
       " {'label': 'none', 'score': 2.7408156394958496},\n",
       " {'label': 'none', 'score': 2.7408156394958496},\n",
       " {'label': 'none', 'score': 1.538456678390503},\n",
       " {'label': 'none', 'score': 1.538456678390503},\n",
       " {'label': 'none', 'score': 1.538456678390503},\n",
       " {'label': 'none', 'score': 1.8817777633666992},\n",
       " {'label': 'none', 'score': 1.8817777633666992},\n",
       " {'label': 'none', 'score': 1.8817777633666992},\n",
       " {'label': 'none', 'score': 1.8983625173568726},\n",
       " {'label': 'none', 'score': 1.8983625173568726},\n",
       " {'label': 'none', 'score': 1.8983625173568726},\n",
       " {'label': 'none', 'score': 2.327181577682495},\n",
       " {'label': 'none', 'score': 2.327181577682495},\n",
       " {'label': 'none', 'score': 2.327181577682495},\n",
       " {'label': 'none', 'score': 2.2936184406280518},\n",
       " {'label': 'none', 'score': 2.2936184406280518},\n",
       " {'label': 'none', 'score': 2.2936184406280518},\n",
       " {'label': 'none', 'score': 2.0395660400390625},\n",
       " {'label': 'none', 'score': 2.0395660400390625},\n",
       " {'label': 'none', 'score': 2.0395660400390625},\n",
       " {'label': 'none', 'score': 2.4623451232910156},\n",
       " {'label': 'none', 'score': 2.4623451232910156},\n",
       " {'label': 'none', 'score': 2.4623451232910156},\n",
       " {'label': 'none', 'score': 1.756449818611145},\n",
       " {'label': 'none', 'score': 1.756449818611145},\n",
       " {'label': 'none', 'score': 1.756449818611145},\n",
       " {'label': 'none', 'score': 1.9221351146697998},\n",
       " {'label': 'none', 'score': 1.9221351146697998},\n",
       " {'label': 'none', 'score': 1.9221351146697998},\n",
       " {'label': 'none', 'score': 2.4267401695251465},\n",
       " {'label': 'none', 'score': 2.4267401695251465},\n",
       " {'label': 'none', 'score': 2.4267401695251465},\n",
       " {'label': 'none', 'score': 1.6936544179916382},\n",
       " {'label': 'none', 'score': 1.6936544179916382},\n",
       " {'label': 'none', 'score': 1.6936544179916382},\n",
       " {'label': 'none', 'score': 2.0282256603240967},\n",
       " {'label': 'none', 'score': 2.0282256603240967},\n",
       " {'label': 'none', 'score': 2.0282256603240967},\n",
       " {'label': 'none', 'score': 1.3871955871582031},\n",
       " {'label': 'none', 'score': 1.3871955871582031},\n",
       " {'label': 'none', 'score': 1.3871955871582031},\n",
       " {'label': 'returning', 'score': 0.785923957824707},\n",
       " {'label': 'returning', 'score': 0.785923957824707},\n",
       " {'label': 'returning', 'score': 0.785923957824707},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.6876339316368103},\n",
       " {'label': 'returning', 'score': 0.6876339316368103},\n",
       " {'label': 'returning', 'score': 0.6876339316368103},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 1.0578396320343018},\n",
       " {'label': 'returning', 'score': 1.0578396320343018},\n",
       " {'label': 'returning', 'score': 1.0578396320343018},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.3487521409988403},\n",
       " {'label': 'none', 'score': 1.3487521409988403},\n",
       " {'label': 'none', 'score': 1.3487521409988403},\n",
       " {'label': 'none', 'score': 1.5651752948760986},\n",
       " {'label': 'none', 'score': 1.5651752948760986},\n",
       " {'label': 'none', 'score': 1.5651752948760986},\n",
       " {'label': 'none', 'score': 2.372802972793579},\n",
       " {'label': 'none', 'score': 2.372802972793579},\n",
       " {'label': 'none', 'score': 2.372802972793579},\n",
       " {'label': 'none', 'score': 1.2428730726242065},\n",
       " {'label': 'none', 'score': 1.2428730726242065},\n",
       " {'label': 'none', 'score': 1.2428730726242065},\n",
       " {'label': 'none', 'score': 1.8079533576965332},\n",
       " {'label': 'none', 'score': 1.8079533576965332},\n",
       " {'label': 'none', 'score': 1.8079533576965332},\n",
       " {'label': 'none', 'score': 2.3576064109802246},\n",
       " {'label': 'none', 'score': 2.3576064109802246},\n",
       " {'label': 'none', 'score': 2.3576064109802246},\n",
       " {'label': 'none', 'score': 1.4423582553863525},\n",
       " {'label': 'none', 'score': 1.4423582553863525},\n",
       " {'label': 'none', 'score': 1.4423582553863525},\n",
       " {'label': 'none', 'score': 0.8688816428184509},\n",
       " {'label': 'none', 'score': 0.8688816428184509},\n",
       " {'label': 'none', 'score': 0.8688816428184509},\n",
       " {'label': 'none', 'score': 0.9064189195632935},\n",
       " {'label': 'none', 'score': 0.9064189195632935},\n",
       " {'label': 'none', 'score': 0.9064189195632935},\n",
       " {'label': 'none', 'score': 1.7482064962387085},\n",
       " {'label': 'none', 'score': 1.7482064962387085},\n",
       " {'label': 'none', 'score': 1.7482064962387085},\n",
       " {'label': 'none', 'score': 1.6618473529815674},\n",
       " {'label': 'none', 'score': 1.6618473529815674},\n",
       " {'label': 'none', 'score': 1.6618473529815674},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.7979629039764404},\n",
       " {'label': 'returning', 'score': 0.7979629039764404},\n",
       " {'label': 'returning', 'score': 0.7979629039764404},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.4949142336845398},\n",
       " {'label': 'returning', 'score': 0.4949142336845398},\n",
       " {'label': 'returning', 'score': 0.4949142336845398},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 0.852044403553009},\n",
       " {'label': 'none', 'score': 1.1646556854248047},\n",
       " {'label': 'none', 'score': 1.1646556854248047},\n",
       " {'label': 'none', 'score': 1.1646556854248047},\n",
       " {'label': 'none', 'score': 1.4218987226486206},\n",
       " {'label': 'none', 'score': 1.4218987226486206},\n",
       " {'label': 'none', 'score': 1.4218987226486206},\n",
       " {'label': 'none', 'score': 0.923671543598175},\n",
       " {'label': 'none', 'score': 0.923671543598175},\n",
       " {'label': 'none', 'score': 0.923671543598175},\n",
       " {'label': 'none', 'score': 1.2127043008804321},\n",
       " {'label': 'none', 'score': 1.2127043008804321},\n",
       " {'label': 'none', 'score': 1.2127043008804321},\n",
       " {'label': 'none', 'score': 1.784538745880127},\n",
       " {'label': 'none', 'score': 1.784538745880127},\n",
       " {'label': 'none', 'score': 1.784538745880127},\n",
       " {'label': 'none', 'score': 1.6288050413131714},\n",
       " {'label': 'none', 'score': 1.6288050413131714},\n",
       " {'label': 'none', 'score': 1.6288050413131714},\n",
       " {'label': 'none', 'score': 1.3428699970245361},\n",
       " {'label': 'none', 'score': 1.3428699970245361},\n",
       " {'label': 'none', 'score': 1.3428699970245361},\n",
       " {'label': 'none', 'score': 1.6185163259506226},\n",
       " {'label': 'none', 'score': 1.6185163259506226},\n",
       " {'label': 'none', 'score': 1.6185163259506226},\n",
       " {'label': 'none', 'score': 1.9541655778884888},\n",
       " {'label': 'none', 'score': 1.9541655778884888},\n",
       " {'label': 'none', 'score': 1.9541655778884888},\n",
       " {'label': 'none', 'score': 1.8593229055404663},\n",
       " {'label': 'none', 'score': 1.8593229055404663},\n",
       " {'label': 'none', 'score': 1.8593229055404663},\n",
       " {'label': 'none', 'score': 1.230277180671692},\n",
       " {'label': 'none', 'score': 1.230277180671692},\n",
       " {'label': 'none', 'score': 1.230277180671692},\n",
       " {'label': 'none', 'score': 1.6600993871688843},\n",
       " {'label': 'none', 'score': 1.6600993871688843},\n",
       " {'label': 'none', 'score': 1.6600993871688843},\n",
       " {'label': 'none', 'score': 1.11016845703125},\n",
       " {'label': 'none', 'score': 1.11016845703125},\n",
       " {'label': 'none', 'score': 1.11016845703125},\n",
       " {'label': 'none', 'score': 1.4982906579971313},\n",
       " {'label': 'none', 'score': 1.4982906579971313},\n",
       " {'label': 'none', 'score': 1.4982906579971313},\n",
       " {'label': 'none', 'score': 2.1030421257019043},\n",
       " {'label': 'none', 'score': 2.1030421257019043},\n",
       " {'label': 'none', 'score': 2.1030421257019043},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 1.4735603332519531},\n",
       " {'label': 'returning', 'score': 1.4735603332519531},\n",
       " {'label': 'returning', 'score': 1.4735603332519531},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.852044403553009},\n",
       " {'label': 'returning', 'score': 0.21993660926818848},\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:05:01.496341Z",
     "start_time": "2020-04-13T23:05:01.468106Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " with open(os.path.join(results_path,'validation_results3.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:05:02.996739Z",
     "start_time": "2020-04-13T23:05:02.986701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:05:04.316183Z",
     "start_time": "2020-04-13T23:05:04.018850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - ~~More diverse dataset~~ (2020-04-01)\n",
    "    - Hyperparameter tuning (some improvement 2020-04-04)\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T23:05:17.053364Z",
     "start_time": "2020-04-13T23:05:16.834717Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/porta3.pth')\n",
    "torch.save(my_model.state_dict(), weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
