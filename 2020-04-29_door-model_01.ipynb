{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:36.788051Z",
     "start_time": "2020-03-26T01:58:36.777172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T16:03:35.848209Z",
     "start_time": "2020-04-29T16:03:34.128626Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T16:03:42.738712Z",
     "start_time": "2020-04-29T16:03:36.634025Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.133335Z",
     "start_time": "2020-03-26T01:58:41.121009Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.176786Z",
     "start_time": "2020-03-26T01:58:41.134624Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.190090Z",
     "start_time": "2020-03-26T01:58:41.178036Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.201452Z",
     "start_time": "2020-03-26T01:58:41.191196Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.211301Z",
     "start_time": "2020-03-26T01:58:41.203178Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.343691Z",
     "start_time": "2020-03-26T01:58:41.212544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.362178Z",
     "start_time": "2020-03-26T01:58:43.348427Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.373621Z",
     "start_time": "2020-03-26T01:58:43.363275Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.863045Z",
     "start_time": "2020-03-26T01:58:43.374604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.883712Z",
     "start_time": "2020-03-26T01:58:43.867836Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:44.640836Z",
     "start_time": "2020-03-26T01:58:43.884708Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.580124Z",
     "start_time": "2020-03-26T01:58:44.641957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.590905Z",
     "start_time": "2020-03-26T01:58:54.581423Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.604647Z",
     "start_time": "2020-03-26T01:58:54.592134Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 256), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.621755Z",
     "start_time": "2020-03-26T01:58:54.605731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.633288Z",
     "start_time": "2020-03-26T01:58:54.623116Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-2,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.702462Z",
     "start_time": "2020-03-26T01:58:54.634312Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:50.971317Z",
     "start_time": "2020-03-26T01:58:54.704552Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 3.081 (3.081)\tData 1.470 (1.470)\tLoss 1.0648 (1.0648)\tAcc 0.562 (0.562)\n",
      "Epoch: [1][2/5]\tTime 0.148 (1.614)\tData 0.092 (0.781)\tLoss 1.0221 (1.0434)\tAcc 0.562 (0.562)\n",
      "Epoch: [1][3/5]\tTime 0.064 (1.098)\tData 0.041 (0.534)\tLoss 0.6768 (0.9212)\tAcc 0.875 (0.667)\n",
      "Epoch: [1][4/5]\tTime 0.092 (0.846)\tData 0.068 (0.418)\tLoss 1.3063 (1.0175)\tAcc 0.500 (0.625)\n",
      "Epoch: [1][5/5]\tTime 0.098 (0.697)\tData 0.075 (0.349)\tLoss 0.8448 (0.9962)\tAcc 0.778 (0.644)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.475 (0.475)\tData 0.452 (0.452)\tLoss 0.4223 (0.4223)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.072 (0.274)\tData 0.052 (0.252)\tLoss 1.2971 (0.8597)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.074 (0.207)\tData 0.054 (0.186)\tLoss 0.8845 (0.8680)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.075 (0.174)\tData 0.055 (0.153)\tLoss 0.8132 (0.8543)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.078 (0.155)\tData 0.058 (0.134)\tLoss 0.8660 (0.8566)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.072 (0.141)\tData 0.053 (0.121)\tLoss 0.3285 (0.7686)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.072 (0.131)\tData 0.053 (0.111)\tLoss 0.5457 (0.7368)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.074 (0.124)\tData 0.055 (0.104)\tLoss 1.1709 (0.7910)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.073 (0.118)\tData 0.055 (0.098)\tLoss 0.3022 (0.7835)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.634 (0.634)\tData 0.607 (0.607)\tLoss 1.1622 (1.1622)\tAcc 0.625 (0.625)\n",
      "Epoch: [2][2/5]\tTime 0.076 (0.355)\tData 0.052 (0.330)\tLoss 0.8539 (1.0081)\tAcc 0.688 (0.656)\n",
      "Epoch: [2][3/5]\tTime 0.077 (0.262)\tData 0.053 (0.238)\tLoss 0.7931 (0.9364)\tAcc 0.625 (0.646)\n",
      "Epoch: [2][4/5]\tTime 0.076 (0.216)\tData 0.053 (0.191)\tLoss 0.7807 (0.8975)\tAcc 0.875 (0.703)\n",
      "Epoch: [2][5/5]\tTime 0.079 (0.188)\tData 0.056 (0.164)\tLoss 0.9923 (0.9092)\tAcc 0.444 (0.671)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.416 (0.416)\tData 0.392 (0.392)\tLoss 0.5692 (0.5692)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.071 (0.244)\tData 0.050 (0.221)\tLoss 1.1401 (0.8547)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.074 (0.187)\tData 0.054 (0.165)\tLoss 0.8866 (0.8653)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.074 (0.159)\tData 0.055 (0.138)\tLoss 0.8524 (0.8621)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.073 (0.142)\tData 0.054 (0.121)\tLoss 0.8478 (0.8592)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.073 (0.130)\tData 0.054 (0.110)\tLoss 0.5150 (0.8019)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.073 (0.122)\tData 0.054 (0.102)\tLoss 0.6087 (0.7743)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.074 (0.116)\tData 0.055 (0.096)\tLoss 1.0784 (0.8123)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.072 (0.111)\tData 0.054 (0.091)\tLoss 0.4945 (0.8074)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.669 (0.669)\tData 0.640 (0.640)\tLoss 0.8909 (0.8909)\tAcc 0.625 (0.625)\n",
      "Epoch: [3][2/5]\tTime 0.072 (0.370)\tData 0.049 (0.345)\tLoss 0.9478 (0.9193)\tAcc 0.625 (0.625)\n",
      "Epoch: [3][3/5]\tTime 0.076 (0.272)\tData 0.053 (0.247)\tLoss 0.7721 (0.8703)\tAcc 0.625 (0.625)\n",
      "Epoch: [3][4/5]\tTime 0.076 (0.223)\tData 0.053 (0.199)\tLoss 0.6376 (0.8121)\tAcc 0.750 (0.656)\n",
      "Epoch: [3][5/5]\tTime 0.079 (0.194)\tData 0.056 (0.170)\tLoss 0.5236 (0.7765)\tAcc 0.778 (0.671)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.331 (0.331)\tData 0.305 (0.305)\tLoss 0.2884 (0.2884)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.069 (0.200)\tData 0.049 (0.177)\tLoss 1.4663 (0.8774)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.073 (0.158)\tData 0.053 (0.136)\tLoss 1.1734 (0.9760)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.075 (0.137)\tData 0.053 (0.115)\tLoss 0.8804 (0.9521)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.070 (0.124)\tData 0.051 (0.102)\tLoss 0.9917 (0.9600)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.1665 (0.8278)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.089)\tLoss 0.5147 (0.7830)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 1.5112 (0.8741)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.072 (0.101)\tData 0.054 (0.081)\tLoss 0.1895 (0.8635)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.680 (0.680)\tData 0.652 (0.652)\tLoss 0.6972 (0.6972)\tAcc 0.812 (0.812)\n",
      "Epoch: [4][2/5]\tTime 0.076 (0.378)\tData 0.051 (0.352)\tLoss 1.3616 (1.0294)\tAcc 0.500 (0.656)\n",
      "Epoch: [4][3/5]\tTime 0.075 (0.277)\tData 0.051 (0.252)\tLoss 0.6258 (0.8949)\tAcc 0.750 (0.688)\n",
      "Epoch: [4][4/5]\tTime 0.077 (0.227)\tData 0.052 (0.202)\tLoss 0.7816 (0.8666)\tAcc 0.625 (0.672)\n",
      "Epoch: [4][5/5]\tTime 0.078 (0.197)\tData 0.055 (0.172)\tLoss 0.6831 (0.8439)\tAcc 0.778 (0.685)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.333 (0.333)\tData 0.306 (0.306)\tLoss 0.4356 (0.4356)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.067 (0.200)\tData 0.046 (0.176)\tLoss 1.3280 (0.8818)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.073 (0.158)\tData 0.053 (0.135)\tLoss 0.8431 (0.8689)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/9]\tTime 0.074 (0.137)\tData 0.053 (0.115)\tLoss 0.9558 (0.8906)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/9]\tTime 0.071 (0.124)\tData 0.052 (0.102)\tLoss 0.8122 (0.8749)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/9]\tTime 0.072 (0.115)\tData 0.054 (0.094)\tLoss 0.2318 (0.7677)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.5569 (0.7376)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 1.2804 (0.8055)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.081)\tLoss 0.2756 (0.7973)\tAcc 1.000 (0.731)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.656 (0.656)\tData 0.629 (0.629)\tLoss 0.7590 (0.7590)\tAcc 0.625 (0.625)\n",
      "Epoch: [5][2/5]\tTime 0.074 (0.365)\tData 0.050 (0.340)\tLoss 0.7447 (0.7518)\tAcc 0.562 (0.594)\n",
      "Epoch: [5][3/5]\tTime 0.076 (0.269)\tData 0.053 (0.244)\tLoss 0.8189 (0.7742)\tAcc 0.750 (0.646)\n",
      "Epoch: [5][4/5]\tTime 0.076 (0.221)\tData 0.053 (0.196)\tLoss 1.5964 (0.9798)\tAcc 0.438 (0.594)\n",
      "Epoch: [5][5/5]\tTime 0.079 (0.192)\tData 0.056 (0.168)\tLoss 0.5324 (0.9246)\tAcc 0.667 (0.603)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.321 (0.321)\tData 0.292 (0.292)\tLoss 0.3433 (0.3433)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.066 (0.194)\tData 0.045 (0.169)\tLoss 1.7622 (1.0528)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.073 (0.153)\tData 0.052 (0.130)\tLoss 1.0206 (1.0421)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.073 (0.133)\tData 0.052 (0.110)\tLoss 0.9595 (1.0214)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.073 (0.121)\tData 0.052 (0.099)\tLoss 0.8305 (0.9832)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.076 (0.114)\tData 0.056 (0.092)\tLoss 0.1406 (0.8428)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.072 (0.108)\tData 0.053 (0.086)\tLoss 0.5292 (0.7980)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 1.4002 (0.8733)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.1522 (0.8622)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.632 (0.632)\tData 0.606 (0.606)\tLoss 0.6454 (0.6454)\tAcc 0.812 (0.812)\n",
      "Epoch: [6][2/5]\tTime 0.074 (0.353)\tData 0.051 (0.328)\tLoss 0.8990 (0.7722)\tAcc 0.625 (0.719)\n",
      "Epoch: [6][3/5]\tTime 0.076 (0.261)\tData 0.053 (0.237)\tLoss 0.4142 (0.6529)\tAcc 0.875 (0.771)\n",
      "Epoch: [6][4/5]\tTime 0.076 (0.215)\tData 0.053 (0.191)\tLoss 1.1796 (0.7846)\tAcc 0.500 (0.703)\n",
      "Epoch: [6][5/5]\tTime 0.079 (0.188)\tData 0.056 (0.164)\tLoss 0.9785 (0.8085)\tAcc 0.444 (0.671)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.296 (0.296)\tData 0.273 (0.273)\tLoss 0.5719 (0.5719)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.071 (0.184)\tData 0.050 (0.162)\tLoss 1.1207 (0.8463)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/9]\tTime 0.073 (0.147)\tData 0.052 (0.125)\tLoss 0.8655 (0.8527)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/9]\tTime 0.072 (0.128)\tData 0.052 (0.107)\tLoss 0.8577 (0.8540)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.8352 (0.8502)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.4870 (0.7897)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/9]\tTime 0.072 (0.104)\tData 0.054 (0.084)\tLoss 0.6065 (0.7635)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/9]\tTime 0.074 (0.101)\tData 0.054 (0.081)\tLoss 1.0566 (0.8001)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/9]\tTime 0.072 (0.097)\tData 0.054 (0.078)\tLoss 0.5498 (0.7963)\tAcc 1.000 (0.731)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.590 (0.590)\tData 0.563 (0.563)\tLoss 0.7431 (0.7431)\tAcc 0.625 (0.625)\n",
      "Epoch: [7][2/5]\tTime 0.075 (0.333)\tData 0.051 (0.307)\tLoss 0.7808 (0.7620)\tAcc 0.750 (0.688)\n",
      "Epoch: [7][3/5]\tTime 0.076 (0.247)\tData 0.053 (0.222)\tLoss 0.8840 (0.8027)\tAcc 0.688 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.078 (0.205)\tData 0.054 (0.180)\tLoss 0.9390 (0.8367)\tAcc 0.562 (0.656)\n",
      "Epoch: [7][5/5]\tTime 0.078 (0.179)\tData 0.055 (0.155)\tLoss 0.7909 (0.8311)\tAcc 0.556 (0.644)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.342 (0.342)\tData 0.316 (0.316)\tLoss 0.5595 (0.5595)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.070 (0.206)\tData 0.048 (0.182)\tLoss 1.2463 (0.9029)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.072 (0.161)\tData 0.052 (0.139)\tLoss 0.8913 (0.8991)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.075 (0.140)\tData 0.053 (0.117)\tLoss 0.8210 (0.8795)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.071 (0.126)\tData 0.051 (0.104)\tLoss 0.8320 (0.8700)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.072 (0.117)\tData 0.054 (0.096)\tLoss 0.4012 (0.7919)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.072 (0.111)\tData 0.054 (0.090)\tLoss 0.5167 (0.7526)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.074 (0.106)\tData 0.056 (0.086)\tLoss 1.1052 (0.7967)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.082)\tLoss 0.4032 (0.7906)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.583 (0.583)\tData 0.557 (0.557)\tLoss 0.6013 (0.6013)\tAcc 0.812 (0.812)\n",
      "Epoch: [8][2/5]\tTime 0.077 (0.330)\tData 0.052 (0.304)\tLoss 0.8321 (0.7167)\tAcc 0.688 (0.750)\n",
      "Epoch: [8][3/5]\tTime 0.074 (0.245)\tData 0.051 (0.220)\tLoss 0.7945 (0.7426)\tAcc 0.625 (0.708)\n",
      "Epoch: [8][4/5]\tTime 0.076 (0.203)\tData 0.053 (0.178)\tLoss 0.8337 (0.7654)\tAcc 0.750 (0.719)\n",
      "Epoch: [8][5/5]\tTime 0.077 (0.178)\tData 0.055 (0.154)\tLoss 1.2294 (0.8226)\tAcc 0.556 (0.699)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.306 (0.306)\tData 0.278 (0.278)\tLoss 0.5998 (0.5998)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.067 (0.186)\tData 0.046 (0.162)\tLoss 1.1426 (0.8712)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/9]\tTime 0.073 (0.149)\tData 0.053 (0.126)\tLoss 0.8801 (0.8742)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/9]\tTime 0.075 (0.130)\tData 0.052 (0.107)\tLoss 0.9792 (0.9004)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/9]\tTime 0.072 (0.119)\tData 0.051 (0.096)\tLoss 0.9740 (0.9151)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/9]\tTime 0.071 (0.111)\tData 0.052 (0.089)\tLoss 0.3825 (0.8264)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.7021 (0.8086)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/9]\tTime 0.074 (0.101)\tData 0.054 (0.080)\tLoss 1.0808 (0.8426)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/9]\tTime 0.072 (0.098)\tData 0.054 (0.077)\tLoss 0.6708 (0.8400)\tAcc 1.000 (0.731)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.637 (0.637)\tData 0.611 (0.611)\tLoss 0.9143 (0.9143)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][2/5]\tTime 0.075 (0.356)\tData 0.052 (0.332)\tLoss 0.8148 (0.8645)\tAcc 0.750 (0.719)\n",
      "Epoch: [9][3/5]\tTime 0.076 (0.263)\tData 0.053 (0.239)\tLoss 0.6035 (0.7775)\tAcc 0.875 (0.771)\n",
      "Epoch: [9][4/5]\tTime 0.076 (0.216)\tData 0.053 (0.193)\tLoss 1.0174 (0.8375)\tAcc 0.500 (0.703)\n",
      "Epoch: [9][5/5]\tTime 0.078 (0.188)\tData 0.055 (0.165)\tLoss 1.0329 (0.8616)\tAcc 0.556 (0.685)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.300 (0.300)\tData 0.274 (0.274)\tLoss 0.8842 (0.8842)\tAcc 0.875 (0.875)\n",
      "Epoch: [9][2/9]\tTime 0.069 (0.184)\tData 0.048 (0.161)\tLoss 1.0559 (0.9701)\tAcc 0.438 (0.656)\n",
      "Epoch: [9][3/9]\tTime 0.073 (0.147)\tData 0.052 (0.125)\tLoss 1.0058 (0.9820)\tAcc 0.688 (0.667)\n",
      "Epoch: [9][4/9]\tTime 0.074 (0.129)\tData 0.052 (0.107)\tLoss 0.9274 (0.9684)\tAcc 0.688 (0.672)\n",
      "Epoch: [9][5/9]\tTime 0.072 (0.118)\tData 0.052 (0.096)\tLoss 0.9851 (0.9717)\tAcc 0.688 (0.675)\n",
      "Epoch: [9][6/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.8596 (0.9530)\tAcc 0.938 (0.719)\n",
      "Epoch: [9][7/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.8730 (0.9416)\tAcc 0.875 (0.741)\n",
      "Epoch: [9][8/9]\tTime 0.074 (0.101)\tData 0.055 (0.080)\tLoss 1.0069 (0.9497)\tAcc 0.500 (0.711)\n",
      "Epoch: [9][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.9230 (0.9493)\tAcc 1.000 (0.715)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.539 (0.539)\tData 0.512 (0.512)\tLoss 0.9511 (0.9511)\tAcc 0.625 (0.625)\n",
      "Epoch: [10][2/5]\tTime 0.074 (0.306)\tData 0.050 (0.281)\tLoss 0.8477 (0.8994)\tAcc 0.688 (0.656)\n",
      "Epoch: [10][3/5]\tTime 0.077 (0.230)\tData 0.053 (0.205)\tLoss 0.7178 (0.8389)\tAcc 0.750 (0.688)\n",
      "Epoch: [10][4/5]\tTime 0.077 (0.192)\tData 0.053 (0.167)\tLoss 1.0030 (0.8799)\tAcc 0.500 (0.641)\n",
      "Epoch: [10][5/5]\tTime 0.076 (0.169)\tData 0.054 (0.144)\tLoss 0.5273 (0.8364)\tAcc 0.889 (0.671)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.392 (0.392)\tData 0.368 (0.368)\tLoss 0.6295 (0.6295)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.071 (0.231)\tData 0.050 (0.209)\tLoss 1.2039 (0.9167)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/9]\tTime 0.073 (0.178)\tData 0.053 (0.157)\tLoss 1.0311 (0.9548)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.073 (0.152)\tData 0.053 (0.131)\tLoss 0.9866 (0.9628)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.073 (0.136)\tData 0.054 (0.116)\tLoss 0.8576 (0.9417)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.072 (0.126)\tData 0.054 (0.105)\tLoss 0.5394 (0.8747)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.073 (0.118)\tData 0.054 (0.098)\tLoss 0.6076 (0.8365)\tAcc 0.875 (0.759)\n",
      "Epoch: [10][8/9]\tTime 0.074 (0.112)\tData 0.055 (0.093)\tLoss 1.0875 (0.8679)\tAcc 0.500 (0.727)\n",
      "Epoch: [10][9/9]\tTime 0.073 (0.108)\tData 0.055 (0.088)\tLoss 0.4902 (0.8621)\tAcc 1.000 (0.731)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.555 (0.555)\tData 0.526 (0.526)\tLoss 0.5448 (0.5448)\tAcc 0.750 (0.750)\n",
      "Epoch: [11][2/5]\tTime 0.072 (0.314)\tData 0.049 (0.287)\tLoss 0.6464 (0.5956)\tAcc 0.750 (0.750)\n",
      "Epoch: [11][3/5]\tTime 0.078 (0.235)\tData 0.055 (0.210)\tLoss 0.9138 (0.7017)\tAcc 0.562 (0.688)\n",
      "Epoch: [11][4/5]\tTime 0.081 (0.196)\tData 0.057 (0.172)\tLoss 1.2667 (0.8429)\tAcc 0.625 (0.672)\n",
      "Epoch: [11][5/5]\tTime 0.081 (0.173)\tData 0.058 (0.149)\tLoss 0.9145 (0.8517)\tAcc 0.778 (0.685)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.319 (0.319)\tData 0.292 (0.292)\tLoss 0.9340 (0.9340)\tAcc 0.500 (0.500)\n",
      "Epoch: [11][2/9]\tTime 0.068 (0.193)\tData 0.047 (0.170)\tLoss 1.2199 (1.0770)\tAcc 0.250 (0.375)\n",
      "Epoch: [11][3/9]\tTime 0.074 (0.154)\tData 0.052 (0.130)\tLoss 1.2303 (1.1281)\tAcc 0.375 (0.375)\n",
      "Epoch: [11][4/9]\tTime 0.071 (0.133)\tData 0.051 (0.111)\tLoss 1.1098 (1.1235)\tAcc 0.375 (0.375)\n",
      "Epoch: [11][5/9]\tTime 0.073 (0.121)\tData 0.053 (0.099)\tLoss 0.9215 (1.0831)\tAcc 0.688 (0.438)\n",
      "Epoch: [11][6/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 1.0197 (1.0725)\tAcc 0.438 (0.438)\n",
      "Epoch: [11][7/9]\tTime 0.072 (0.107)\tData 0.054 (0.086)\tLoss 0.7812 (1.0309)\tAcc 0.812 (0.491)\n",
      "Epoch: [11][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 1.0349 (1.0314)\tAcc 0.500 (0.492)\n",
      "Epoch: [11][9/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.5894 (1.0246)\tAcc 1.000 (0.500)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.571 (0.571)\tData 0.544 (0.544)\tLoss 0.9591 (0.9591)\tAcc 0.562 (0.562)\n",
      "Epoch: [12][2/5]\tTime 0.075 (0.323)\tData 0.051 (0.298)\tLoss 0.9084 (0.9338)\tAcc 0.812 (0.688)\n",
      "Epoch: [12][3/5]\tTime 0.076 (0.241)\tData 0.053 (0.216)\tLoss 0.6964 (0.8547)\tAcc 0.750 (0.708)\n",
      "Epoch: [12][4/5]\tTime 0.076 (0.199)\tData 0.053 (0.176)\tLoss 0.9278 (0.8729)\tAcc 0.625 (0.688)\n",
      "Epoch: [12][5/5]\tTime 0.078 (0.175)\tData 0.055 (0.151)\tLoss 0.9904 (0.8874)\tAcc 0.444 (0.658)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.306 (0.306)\tData 0.282 (0.282)\tLoss 0.8241 (0.8241)\tAcc 0.562 (0.562)\n",
      "Epoch: [12][2/9]\tTime 0.071 (0.188)\tData 0.050 (0.166)\tLoss 1.2054 (1.0147)\tAcc 0.438 (0.500)\n",
      "Epoch: [12][3/9]\tTime 0.073 (0.150)\tData 0.053 (0.128)\tLoss 0.7932 (0.9409)\tAcc 0.688 (0.562)\n",
      "Epoch: [12][4/9]\tTime 0.073 (0.131)\tData 0.053 (0.109)\tLoss 0.9094 (0.9330)\tAcc 0.688 (0.594)\n",
      "Epoch: [12][5/9]\tTime 0.072 (0.119)\tData 0.053 (0.098)\tLoss 0.7791 (0.9022)\tAcc 0.750 (0.625)\n",
      "Epoch: [12][6/9]\tTime 0.072 (0.111)\tData 0.054 (0.091)\tLoss 0.5893 (0.8501)\tAcc 0.875 (0.667)\n",
      "Epoch: [12][7/9]\tTime 0.072 (0.106)\tData 0.054 (0.085)\tLoss 0.7339 (0.8335)\tAcc 0.875 (0.696)\n",
      "Epoch: [12][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 0.9882 (0.8528)\tAcc 0.562 (0.680)\n",
      "Epoch: [12][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.079)\tLoss 0.7562 (0.8513)\tAcc 1.000 (0.685)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.517 (0.517)\tData 0.490 (0.490)\tLoss 0.7822 (0.7822)\tAcc 0.750 (0.750)\n",
      "Epoch: [13][2/5]\tTime 0.075 (0.296)\tData 0.051 (0.271)\tLoss 0.7649 (0.7735)\tAcc 0.688 (0.719)\n",
      "Epoch: [13][3/5]\tTime 0.076 (0.223)\tData 0.053 (0.198)\tLoss 0.5953 (0.7141)\tAcc 0.750 (0.729)\n",
      "Epoch: [13][4/5]\tTime 0.076 (0.186)\tData 0.053 (0.162)\tLoss 0.7106 (0.7132)\tAcc 0.688 (0.719)\n",
      "Epoch: [13][5/5]\tTime 0.077 (0.164)\tData 0.054 (0.140)\tLoss 0.5012 (0.6871)\tAcc 0.778 (0.726)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.291 (0.291)\tData 0.266 (0.266)\tLoss 0.6146 (0.6146)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/9]\tTime 0.071 (0.181)\tData 0.050 (0.158)\tLoss 1.2443 (0.9294)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/9]\tTime 0.073 (0.145)\tData 0.052 (0.123)\tLoss 0.8912 (0.9167)\tAcc 0.562 (0.646)\n",
      "Epoch: [13][4/9]\tTime 0.073 (0.127)\tData 0.052 (0.105)\tLoss 1.0003 (0.9376)\tAcc 0.562 (0.625)\n",
      "Epoch: [13][5/9]\tTime 0.073 (0.116)\tData 0.052 (0.095)\tLoss 0.7123 (0.8925)\tAcc 0.688 (0.637)\n",
      "Epoch: [13][6/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.5043 (0.8278)\tAcc 1.000 (0.698)\n",
      "Epoch: [13][7/9]\tTime 0.072 (0.104)\tData 0.054 (0.083)\tLoss 0.6310 (0.7997)\tAcc 0.875 (0.723)\n",
      "Epoch: [13][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 1.1875 (0.8482)\tAcc 0.375 (0.680)\n",
      "Epoch: [13][9/9]\tTime 0.072 (0.097)\tData 0.054 (0.076)\tLoss 0.5862 (0.8441)\tAcc 1.000 (0.685)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.960 (0.960)\tData 0.934 (0.934)\tLoss 0.5907 (0.5907)\tAcc 0.750 (0.750)\n",
      "Epoch: [14][2/5]\tTime 0.074 (0.517)\tData 0.051 (0.492)\tLoss 0.7886 (0.6896)\tAcc 0.625 (0.688)\n",
      "Epoch: [14][3/5]\tTime 0.077 (0.370)\tData 0.053 (0.346)\tLoss 0.6993 (0.6929)\tAcc 0.750 (0.708)\n",
      "Epoch: [14][4/5]\tTime 0.076 (0.297)\tData 0.053 (0.273)\tLoss 1.0469 (0.7814)\tAcc 0.500 (0.656)\n",
      "Epoch: [14][5/5]\tTime 0.077 (0.253)\tData 0.055 (0.229)\tLoss 0.3775 (0.7316)\tAcc 0.889 (0.685)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.289 (0.289)\tData 0.266 (0.266)\tLoss 0.4777 (0.4777)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.072 (0.181)\tData 0.051 (0.158)\tLoss 1.2793 (0.8785)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/9]\tTime 0.073 (0.145)\tData 0.052 (0.123)\tLoss 0.7478 (0.8349)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][4/9]\tTime 0.075 (0.127)\tData 0.053 (0.105)\tLoss 0.7675 (0.8181)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][5/9]\tTime 0.071 (0.116)\tData 0.052 (0.095)\tLoss 0.7750 (0.8094)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][6/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 0.4940 (0.7569)\tAcc 1.000 (0.740)\n",
      "Epoch: [14][7/9]\tTime 0.072 (0.104)\tData 0.054 (0.083)\tLoss 0.6096 (0.7358)\tAcc 0.875 (0.759)\n",
      "Epoch: [14][8/9]\tTime 0.074 (0.100)\tData 0.055 (0.080)\tLoss 1.0461 (0.7746)\tAcc 0.500 (0.727)\n",
      "Epoch: [14][9/9]\tTime 0.072 (0.097)\tData 0.054 (0.077)\tLoss 0.4045 (0.7689)\tAcc 1.000 (0.731)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.534 (0.534)\tData 0.507 (0.507)\tLoss 0.8236 (0.8236)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][2/5]\tTime 0.074 (0.304)\tData 0.050 (0.279)\tLoss 0.8228 (0.8232)\tAcc 0.625 (0.656)\n",
      "Epoch: [15][3/5]\tTime 0.078 (0.229)\tData 0.053 (0.203)\tLoss 0.7190 (0.7885)\tAcc 0.750 (0.688)\n",
      "Epoch: [15][4/5]\tTime 0.075 (0.190)\tData 0.052 (0.165)\tLoss 0.8036 (0.7922)\tAcc 0.750 (0.703)\n",
      "Epoch: [15][5/5]\tTime 0.077 (0.168)\tData 0.055 (0.143)\tLoss 0.4908 (0.7551)\tAcc 0.889 (0.726)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.370 (0.370)\tData 0.346 (0.346)\tLoss 0.4624 (0.4624)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/9]\tTime 0.071 (0.220)\tData 0.050 (0.198)\tLoss 1.3598 (0.9111)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/9]\tTime 0.072 (0.171)\tData 0.053 (0.150)\tLoss 0.7029 (0.8417)\tAcc 0.750 (0.708)\n",
      "Epoch: [15][4/9]\tTime 0.074 (0.147)\tData 0.053 (0.126)\tLoss 0.8752 (0.8501)\tAcc 0.688 (0.703)\n",
      "Epoch: [15][5/9]\tTime 0.073 (0.132)\tData 0.054 (0.111)\tLoss 0.7515 (0.8303)\tAcc 0.750 (0.713)\n",
      "Epoch: [15][6/9]\tTime 0.072 (0.122)\tData 0.054 (0.102)\tLoss 0.3529 (0.7508)\tAcc 1.000 (0.760)\n",
      "Epoch: [15][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.095)\tLoss 0.6055 (0.7300)\tAcc 0.875 (0.777)\n",
      "Epoch: [15][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.090)\tLoss 1.1735 (0.7855)\tAcc 0.438 (0.734)\n",
      "Epoch: [15][9/9]\tTime 0.072 (0.106)\tData 0.054 (0.086)\tLoss 0.3515 (0.7788)\tAcc 1.000 (0.738)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.522 (0.522)\tData 0.495 (0.495)\tLoss 0.6160 (0.6160)\tAcc 0.812 (0.812)\n",
      "Epoch: [16][2/5]\tTime 0.074 (0.298)\tData 0.051 (0.273)\tLoss 0.7301 (0.6731)\tAcc 0.750 (0.781)\n",
      "Epoch: [16][3/5]\tTime 0.077 (0.224)\tData 0.053 (0.200)\tLoss 0.6441 (0.6634)\tAcc 0.750 (0.771)\n",
      "Epoch: [16][4/5]\tTime 0.076 (0.187)\tData 0.053 (0.163)\tLoss 0.8963 (0.7216)\tAcc 0.562 (0.719)\n",
      "Epoch: [16][5/5]\tTime 0.077 (0.165)\tData 0.055 (0.141)\tLoss 0.9786 (0.7533)\tAcc 0.444 (0.685)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.322 (0.322)\tData 0.296 (0.296)\tLoss 0.5041 (0.5041)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.069 (0.195)\tData 0.048 (0.172)\tLoss 1.2426 (0.8734)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.132)\tLoss 0.6623 (0.8030)\tAcc 0.875 (0.750)\n",
      "Epoch: [16][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.112)\tLoss 0.8134 (0.8056)\tAcc 0.688 (0.734)\n",
      "Epoch: [16][5/9]\tTime 0.072 (0.122)\tData 0.052 (0.100)\tLoss 0.8370 (0.8119)\tAcc 0.688 (0.725)\n",
      "Epoch: [16][6/9]\tTime 0.073 (0.114)\tData 0.053 (0.092)\tLoss 0.3573 (0.7361)\tAcc 1.000 (0.771)\n",
      "Epoch: [16][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.6388 (0.7222)\tAcc 0.750 (0.768)\n",
      "Epoch: [16][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 1.0375 (0.7616)\tAcc 0.500 (0.734)\n",
      "Epoch: [16][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.080)\tLoss 0.3048 (0.7546)\tAcc 1.000 (0.738)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.570 (0.570)\tData 0.541 (0.541)\tLoss 0.6288 (0.6288)\tAcc 0.812 (0.812)\n",
      "Epoch: [17][2/5]\tTime 0.073 (0.321)\tData 0.049 (0.295)\tLoss 0.5631 (0.5959)\tAcc 0.750 (0.781)\n",
      "Epoch: [17][3/5]\tTime 0.077 (0.240)\tData 0.053 (0.214)\tLoss 0.7101 (0.6340)\tAcc 0.688 (0.750)\n",
      "Epoch: [17][4/5]\tTime 0.075 (0.199)\tData 0.052 (0.174)\tLoss 0.7781 (0.6700)\tAcc 0.688 (0.734)\n",
      "Epoch: [17][5/5]\tTime 0.079 (0.175)\tData 0.055 (0.150)\tLoss 0.9910 (0.7096)\tAcc 0.667 (0.726)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.285 (0.285)\tData 0.261 (0.261)\tLoss 0.5745 (0.5745)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/9]\tTime 0.071 (0.178)\tData 0.050 (0.156)\tLoss 1.0787 (0.8266)\tAcc 0.438 (0.688)\n",
      "Epoch: [17][3/9]\tTime 0.073 (0.143)\tData 0.053 (0.121)\tLoss 0.7616 (0.8050)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][4/9]\tTime 0.076 (0.126)\tData 0.052 (0.104)\tLoss 0.8133 (0.8070)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][5/9]\tTime 0.070 (0.115)\tData 0.051 (0.094)\tLoss 0.7434 (0.7943)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][6/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.2819 (0.7089)\tAcc 1.000 (0.740)\n",
      "Epoch: [17][7/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.6163 (0.6957)\tAcc 0.875 (0.759)\n",
      "Epoch: [17][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.079)\tLoss 0.9586 (0.7285)\tAcc 0.562 (0.734)\n",
      "Epoch: [17][9/9]\tTime 0.072 (0.096)\tData 0.055 (0.076)\tLoss 0.5544 (0.7259)\tAcc 1.000 (0.738)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.475 (0.475)\tData 0.448 (0.448)\tLoss 0.7202 (0.7202)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][2/5]\tTime 0.075 (0.275)\tData 0.051 (0.250)\tLoss 0.8170 (0.7686)\tAcc 0.625 (0.656)\n",
      "Epoch: [18][3/5]\tTime 0.076 (0.208)\tData 0.053 (0.184)\tLoss 0.8077 (0.7816)\tAcc 0.562 (0.625)\n",
      "Epoch: [18][4/5]\tTime 0.076 (0.175)\tData 0.054 (0.151)\tLoss 0.5797 (0.7312)\tAcc 0.812 (0.672)\n",
      "Epoch: [18][5/5]\tTime 0.078 (0.156)\tData 0.056 (0.132)\tLoss 0.7871 (0.7381)\tAcc 0.667 (0.671)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.284 (0.284)\tData 0.260 (0.260)\tLoss 0.4593 (0.4593)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/9]\tTime 0.072 (0.178)\tData 0.050 (0.155)\tLoss 0.9886 (0.7240)\tAcc 0.438 (0.688)\n",
      "Epoch: [18][3/9]\tTime 0.072 (0.143)\tData 0.052 (0.121)\tLoss 0.6021 (0.6833)\tAcc 0.750 (0.708)\n",
      "Epoch: [18][4/9]\tTime 0.072 (0.125)\tData 0.052 (0.104)\tLoss 0.7764 (0.7066)\tAcc 0.625 (0.688)\n",
      "Epoch: [18][5/9]\tTime 0.075 (0.115)\tData 0.054 (0.094)\tLoss 0.8087 (0.7270)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][6/9]\tTime 0.072 (0.108)\tData 0.052 (0.087)\tLoss 0.2824 (0.6529)\tAcc 1.000 (0.740)\n",
      "Epoch: [18][7/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.7489 (0.6666)\tAcc 0.625 (0.723)\n",
      "Epoch: [18][8/9]\tTime 0.075 (0.099)\tData 0.055 (0.079)\tLoss 1.0726 (0.7174)\tAcc 0.562 (0.703)\n",
      "Epoch: [18][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.076)\tLoss 0.3789 (0.7122)\tAcc 1.000 (0.708)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.563 (0.563)\tData 0.536 (0.536)\tLoss 0.6343 (0.6343)\tAcc 0.750 (0.750)\n",
      "Epoch: [19][2/5]\tTime 0.075 (0.319)\tData 0.051 (0.294)\tLoss 0.7257 (0.6800)\tAcc 0.750 (0.750)\n",
      "Epoch: [19][3/5]\tTime 0.076 (0.238)\tData 0.053 (0.213)\tLoss 0.6916 (0.6839)\tAcc 0.812 (0.771)\n",
      "Epoch: [19][4/5]\tTime 0.077 (0.198)\tData 0.053 (0.173)\tLoss 0.9545 (0.7515)\tAcc 0.562 (0.719)\n",
      "Epoch: [19][5/5]\tTime 0.084 (0.175)\tData 0.061 (0.151)\tLoss 0.7648 (0.7532)\tAcc 0.778 (0.726)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.343 (0.343)\tData 0.313 (0.313)\tLoss 0.4646 (0.4646)\tAcc 0.875 (0.875)\n",
      "Epoch: [19][2/9]\tTime 0.065 (0.204)\tData 0.044 (0.179)\tLoss 0.9903 (0.7274)\tAcc 0.500 (0.688)\n",
      "Epoch: [19][3/9]\tTime 0.073 (0.161)\tData 0.052 (0.137)\tLoss 0.6740 (0.7096)\tAcc 0.812 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.073 (0.139)\tData 0.052 (0.115)\tLoss 0.7274 (0.7141)\tAcc 0.625 (0.703)\n",
      "Epoch: [19][5/9]\tTime 0.072 (0.126)\tData 0.053 (0.103)\tLoss 0.8161 (0.7345)\tAcc 0.750 (0.713)\n",
      "Epoch: [19][6/9]\tTime 0.073 (0.117)\tData 0.053 (0.095)\tLoss 0.3178 (0.6650)\tAcc 1.000 (0.760)\n",
      "Epoch: [19][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.8583 (0.6926)\tAcc 0.500 (0.723)\n",
      "Epoch: [19][8/9]\tTime 0.074 (0.106)\tData 0.055 (0.085)\tLoss 1.1555 (0.7505)\tAcc 0.500 (0.695)\n",
      "Epoch: [19][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.081)\tLoss 0.1667 (0.7415)\tAcc 1.000 (0.700)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.517 (0.517)\tData 0.490 (0.490)\tLoss 0.6004 (0.6004)\tAcc 0.750 (0.750)\n",
      "Epoch: [20][2/5]\tTime 0.074 (0.296)\tData 0.050 (0.270)\tLoss 0.8551 (0.7277)\tAcc 0.625 (0.688)\n",
      "Epoch: [20][3/5]\tTime 0.077 (0.223)\tData 0.053 (0.198)\tLoss 1.0281 (0.8279)\tAcc 0.562 (0.646)\n",
      "Epoch: [20][4/5]\tTime 0.075 (0.186)\tData 0.052 (0.161)\tLoss 0.6855 (0.7923)\tAcc 0.750 (0.672)\n",
      "Epoch: [20][5/5]\tTime 0.078 (0.164)\tData 0.055 (0.140)\tLoss 0.4662 (0.7521)\tAcc 0.889 (0.699)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.388 (0.388)\tData 0.365 (0.365)\tLoss 0.3147 (0.3147)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][2/9]\tTime 0.071 (0.230)\tData 0.051 (0.208)\tLoss 0.9305 (0.6226)\tAcc 0.438 (0.656)\n",
      "Epoch: [20][3/9]\tTime 0.073 (0.177)\tData 0.053 (0.156)\tLoss 0.5926 (0.6126)\tAcc 0.812 (0.708)\n",
      "Epoch: [20][4/9]\tTime 0.072 (0.151)\tData 0.053 (0.130)\tLoss 0.6494 (0.6218)\tAcc 0.625 (0.688)\n",
      "Epoch: [20][5/9]\tTime 0.074 (0.136)\tData 0.054 (0.115)\tLoss 0.9209 (0.6816)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][6/9]\tTime 0.073 (0.125)\tData 0.054 (0.105)\tLoss 0.2766 (0.6141)\tAcc 1.000 (0.740)\n",
      "Epoch: [20][7/9]\tTime 0.073 (0.118)\tData 0.054 (0.098)\tLoss 0.7453 (0.6328)\tAcc 0.688 (0.732)\n",
      "Epoch: [20][8/9]\tTime 0.074 (0.112)\tData 0.056 (0.092)\tLoss 1.0866 (0.6896)\tAcc 0.500 (0.703)\n",
      "Epoch: [20][9/9]\tTime 0.072 (0.108)\tData 0.054 (0.088)\tLoss 0.3211 (0.6839)\tAcc 1.000 (0.708)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.419 (0.419)\tData 0.390 (0.390)\tLoss 0.8433 (0.8433)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][2/5]\tTime 0.073 (0.246)\tData 0.050 (0.220)\tLoss 0.6961 (0.7697)\tAcc 0.750 (0.719)\n",
      "Epoch: [21][3/5]\tTime 0.077 (0.190)\tData 0.054 (0.164)\tLoss 0.7328 (0.7574)\tAcc 0.750 (0.729)\n",
      "Epoch: [21][4/5]\tTime 0.076 (0.161)\tData 0.053 (0.137)\tLoss 0.6896 (0.7405)\tAcc 0.750 (0.734)\n",
      "Epoch: [21][5/5]\tTime 0.077 (0.144)\tData 0.055 (0.120)\tLoss 0.5839 (0.7211)\tAcc 0.667 (0.726)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.324 (0.324)\tData 0.299 (0.299)\tLoss 0.2450 (0.2450)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.070 (0.197)\tData 0.049 (0.174)\tLoss 1.0767 (0.6609)\tAcc 0.438 (0.688)\n",
      "Epoch: [21][3/9]\tTime 0.075 (0.157)\tData 0.052 (0.134)\tLoss 0.6870 (0.6696)\tAcc 0.750 (0.708)\n",
      "Epoch: [21][4/9]\tTime 0.070 (0.135)\tData 0.050 (0.113)\tLoss 0.6451 (0.6634)\tAcc 0.688 (0.703)\n",
      "Epoch: [21][5/9]\tTime 0.074 (0.123)\tData 0.054 (0.101)\tLoss 0.6427 (0.6593)\tAcc 0.812 (0.725)\n",
      "Epoch: [21][6/9]\tTime 0.074 (0.115)\tData 0.055 (0.093)\tLoss 0.2559 (0.5921)\tAcc 1.000 (0.771)\n",
      "Epoch: [21][7/9]\tTime 0.072 (0.109)\tData 0.054 (0.088)\tLoss 0.6824 (0.6050)\tAcc 0.688 (0.759)\n",
      "Epoch: [21][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.084)\tLoss 1.1473 (0.6728)\tAcc 0.500 (0.727)\n",
      "Epoch: [21][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.1379 (0.6645)\tAcc 1.000 (0.731)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.398 (0.398)\tData 0.371 (0.371)\tLoss 0.5880 (0.5880)\tAcc 0.812 (0.812)\n",
      "Epoch: [22][2/5]\tTime 0.097 (0.248)\tData 0.073 (0.222)\tLoss 1.0746 (0.8313)\tAcc 0.500 (0.656)\n",
      "Epoch: [22][3/5]\tTime 0.077 (0.191)\tData 0.053 (0.166)\tLoss 0.6004 (0.7543)\tAcc 0.750 (0.688)\n",
      "Epoch: [22][4/5]\tTime 0.075 (0.162)\tData 0.052 (0.137)\tLoss 0.4334 (0.6741)\tAcc 0.812 (0.719)\n",
      "Epoch: [22][5/5]\tTime 0.078 (0.145)\tData 0.055 (0.121)\tLoss 0.5210 (0.6552)\tAcc 0.778 (0.726)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.282 (0.282)\tData 0.256 (0.256)\tLoss 0.2757 (0.2757)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.070 (0.176)\tData 0.049 (0.153)\tLoss 1.0236 (0.6496)\tAcc 0.438 (0.688)\n",
      "Epoch: [22][3/9]\tTime 0.073 (0.142)\tData 0.052 (0.119)\tLoss 0.4390 (0.5794)\tAcc 0.938 (0.771)\n",
      "Epoch: [22][4/9]\tTime 0.074 (0.125)\tData 0.052 (0.102)\tLoss 0.5706 (0.5772)\tAcc 0.688 (0.750)\n",
      "Epoch: [22][5/9]\tTime 0.072 (0.114)\tData 0.052 (0.092)\tLoss 0.9075 (0.6433)\tAcc 0.625 (0.725)\n",
      "Epoch: [22][6/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.2290 (0.5742)\tAcc 1.000 (0.771)\n",
      "Epoch: [22][7/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.7578 (0.6005)\tAcc 0.562 (0.741)\n",
      "Epoch: [22][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 1.0514 (0.6568)\tAcc 0.500 (0.711)\n",
      "Epoch: [22][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.075)\tLoss 0.1371 (0.6488)\tAcc 1.000 (0.715)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.526 (0.526)\tData 0.499 (0.499)\tLoss 0.7811 (0.7811)\tAcc 0.688 (0.688)\n",
      "Epoch: [23][2/5]\tTime 0.075 (0.300)\tData 0.051 (0.275)\tLoss 0.5528 (0.6669)\tAcc 0.875 (0.781)\n",
      "Epoch: [23][3/5]\tTime 0.078 (0.226)\tData 0.053 (0.201)\tLoss 0.5934 (0.6424)\tAcc 0.750 (0.771)\n",
      "Epoch: [23][4/5]\tTime 0.075 (0.188)\tData 0.052 (0.164)\tLoss 0.9136 (0.7102)\tAcc 0.625 (0.734)\n",
      "Epoch: [23][5/5]\tTime 0.078 (0.166)\tData 0.055 (0.142)\tLoss 0.6528 (0.7031)\tAcc 0.667 (0.726)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.298 (0.298)\tData 0.274 (0.274)\tLoss 0.2976 (0.2976)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.073 (0.185)\tData 0.050 (0.162)\tLoss 1.1264 (0.7120)\tAcc 0.438 (0.688)\n",
      "Epoch: [23][3/9]\tTime 0.073 (0.148)\tData 0.052 (0.125)\tLoss 0.5507 (0.6582)\tAcc 0.750 (0.708)\n",
      "Epoch: [23][4/9]\tTime 0.074 (0.129)\tData 0.052 (0.107)\tLoss 0.8471 (0.7055)\tAcc 0.625 (0.688)\n",
      "Epoch: [23][5/9]\tTime 0.074 (0.118)\tData 0.053 (0.096)\tLoss 0.9642 (0.7572)\tAcc 0.688 (0.688)\n",
      "Epoch: [23][6/9]\tTime 0.073 (0.111)\tData 0.053 (0.089)\tLoss 0.3271 (0.6855)\tAcc 0.938 (0.729)\n",
      "Epoch: [23][7/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.8180 (0.7044)\tAcc 0.562 (0.705)\n",
      "Epoch: [23][8/9]\tTime 0.075 (0.101)\tData 0.056 (0.080)\tLoss 1.1676 (0.7623)\tAcc 0.500 (0.680)\n",
      "Epoch: [23][9/9]\tTime 0.072 (0.098)\tData 0.054 (0.077)\tLoss 0.2082 (0.7538)\tAcc 1.000 (0.685)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.395 (0.395)\tData 0.367 (0.367)\tLoss 0.5053 (0.5053)\tAcc 0.812 (0.812)\n",
      "Epoch: [24][2/5]\tTime 0.079 (0.237)\tData 0.055 (0.211)\tLoss 0.8978 (0.7016)\tAcc 0.688 (0.750)\n",
      "Epoch: [24][3/5]\tTime 0.077 (0.184)\tData 0.054 (0.159)\tLoss 1.2850 (0.8960)\tAcc 0.438 (0.646)\n",
      "Epoch: [24][4/5]\tTime 0.076 (0.157)\tData 0.053 (0.132)\tLoss 0.7324 (0.8551)\tAcc 0.688 (0.656)\n",
      "Epoch: [24][5/5]\tTime 0.078 (0.141)\tData 0.055 (0.117)\tLoss 0.7653 (0.8441)\tAcc 0.778 (0.671)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.353 (0.353)\tData 0.329 (0.329)\tLoss 0.2938 (0.2938)\tAcc 0.875 (0.875)\n",
      "Epoch: [24][2/9]\tTime 0.071 (0.212)\tData 0.050 (0.189)\tLoss 1.1276 (0.7107)\tAcc 0.438 (0.656)\n",
      "Epoch: [24][3/9]\tTime 0.074 (0.166)\tData 0.052 (0.144)\tLoss 0.5569 (0.6595)\tAcc 0.938 (0.750)\n",
      "Epoch: [24][4/9]\tTime 0.071 (0.142)\tData 0.051 (0.121)\tLoss 0.7879 (0.6916)\tAcc 0.625 (0.719)\n",
      "Epoch: [24][5/9]\tTime 0.073 (0.129)\tData 0.054 (0.107)\tLoss 0.8759 (0.7284)\tAcc 0.562 (0.688)\n",
      "Epoch: [24][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.2949 (0.6562)\tAcc 1.000 (0.740)\n",
      "Epoch: [24][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.6188 (0.6508)\tAcc 0.625 (0.723)\n",
      "Epoch: [24][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.087)\tLoss 1.1114 (0.7084)\tAcc 0.562 (0.703)\n",
      "Epoch: [24][9/9]\tTime 0.072 (0.104)\tData 0.054 (0.084)\tLoss 0.1725 (0.7002)\tAcc 1.000 (0.708)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.405 (0.405)\tData 0.376 (0.376)\tLoss 0.4255 (0.4255)\tAcc 0.875 (0.875)\n",
      "Epoch: [25][2/5]\tTime 0.074 (0.240)\tData 0.049 (0.213)\tLoss 0.8634 (0.6445)\tAcc 0.688 (0.781)\n",
      "Epoch: [25][3/5]\tTime 0.076 (0.185)\tData 0.052 (0.159)\tLoss 1.0811 (0.7900)\tAcc 0.562 (0.708)\n",
      "Epoch: [25][4/5]\tTime 0.078 (0.158)\tData 0.053 (0.132)\tLoss 0.6489 (0.7547)\tAcc 0.750 (0.719)\n",
      "Epoch: [25][5/5]\tTime 0.076 (0.142)\tData 0.053 (0.117)\tLoss 0.7980 (0.7601)\tAcc 0.667 (0.712)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.311 (0.311)\tData 0.285 (0.285)\tLoss 0.3421 (0.3421)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.070 (0.190)\tData 0.049 (0.167)\tLoss 1.0259 (0.6840)\tAcc 0.438 (0.688)\n",
      "Epoch: [25][3/9]\tTime 0.073 (0.151)\tData 0.052 (0.129)\tLoss 0.6510 (0.6730)\tAcc 0.875 (0.750)\n",
      "Epoch: [25][4/9]\tTime 0.074 (0.132)\tData 0.052 (0.110)\tLoss 0.6630 (0.6705)\tAcc 0.625 (0.719)\n",
      "Epoch: [25][5/9]\tTime 0.072 (0.120)\tData 0.053 (0.098)\tLoss 0.9715 (0.7307)\tAcc 0.625 (0.700)\n",
      "Epoch: [25][6/9]\tTime 0.072 (0.112)\tData 0.054 (0.091)\tLoss 0.1972 (0.6418)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.6649 (0.6451)\tAcc 0.750 (0.750)\n",
      "Epoch: [25][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.082)\tLoss 1.0408 (0.6945)\tAcc 0.500 (0.719)\n",
      "Epoch: [25][9/9]\tTime 0.072 (0.099)\tData 0.054 (0.079)\tLoss 0.1611 (0.6863)\tAcc 1.000 (0.723)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.542 (0.542)\tData 0.515 (0.515)\tLoss 0.7589 (0.7589)\tAcc 0.562 (0.562)\n",
      "Epoch: [26][2/5]\tTime 0.074 (0.308)\tData 0.050 (0.283)\tLoss 1.0664 (0.9127)\tAcc 0.562 (0.562)\n",
      "Epoch: [26][3/5]\tTime 0.077 (0.231)\tData 0.053 (0.206)\tLoss 0.8013 (0.8755)\tAcc 0.688 (0.604)\n",
      "Epoch: [26][4/5]\tTime 0.076 (0.192)\tData 0.053 (0.168)\tLoss 0.5214 (0.7870)\tAcc 0.875 (0.672)\n",
      "Epoch: [26][5/5]\tTime 0.078 (0.169)\tData 0.055 (0.145)\tLoss 0.3680 (0.7353)\tAcc 1.000 (0.712)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.335 (0.335)\tData 0.310 (0.310)\tLoss 0.2845 (0.2845)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/9]\tTime 0.070 (0.202)\tData 0.049 (0.180)\tLoss 1.0951 (0.6898)\tAcc 0.438 (0.688)\n",
      "Epoch: [26][3/9]\tTime 0.074 (0.160)\tData 0.053 (0.137)\tLoss 0.5922 (0.6573)\tAcc 0.875 (0.750)\n",
      "Epoch: [26][4/9]\tTime 0.074 (0.138)\tData 0.052 (0.116)\tLoss 0.6855 (0.6643)\tAcc 0.625 (0.719)\n",
      "Epoch: [26][5/9]\tTime 0.072 (0.125)\tData 0.053 (0.104)\tLoss 0.7096 (0.6734)\tAcc 0.750 (0.725)\n",
      "Epoch: [26][6/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.2575 (0.6041)\tAcc 1.000 (0.771)\n",
      "Epoch: [26][7/9]\tTime 0.072 (0.110)\tData 0.054 (0.089)\tLoss 0.8304 (0.6364)\tAcc 0.438 (0.723)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.106)\tData 0.055 (0.085)\tLoss 1.0784 (0.6917)\tAcc 0.625 (0.711)\n",
      "Epoch: [26][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.082)\tLoss 0.1983 (0.6841)\tAcc 1.000 (0.715)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.393 (0.393)\tData 0.365 (0.365)\tLoss 0.4437 (0.4437)\tAcc 0.875 (0.875)\n",
      "Epoch: [27][2/5]\tTime 0.104 (0.249)\tData 0.080 (0.223)\tLoss 0.6958 (0.5697)\tAcc 0.688 (0.781)\n",
      "Epoch: [27][3/5]\tTime 0.076 (0.191)\tData 0.053 (0.166)\tLoss 0.8913 (0.6769)\tAcc 0.688 (0.750)\n",
      "Epoch: [27][4/5]\tTime 0.077 (0.163)\tData 0.053 (0.138)\tLoss 0.8734 (0.7260)\tAcc 0.688 (0.734)\n",
      "Epoch: [27][5/5]\tTime 0.077 (0.146)\tData 0.054 (0.121)\tLoss 0.8646 (0.7431)\tAcc 0.667 (0.726)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.275 (0.275)\tData 0.247 (0.247)\tLoss 0.3522 (0.3522)\tAcc 0.875 (0.875)\n",
      "Epoch: [27][2/9]\tTime 0.068 (0.171)\tData 0.046 (0.146)\tLoss 1.0260 (0.6891)\tAcc 0.438 (0.656)\n",
      "Epoch: [27][3/9]\tTime 0.073 (0.139)\tData 0.052 (0.115)\tLoss 0.6548 (0.6777)\tAcc 0.750 (0.688)\n",
      "Epoch: [27][4/9]\tTime 0.077 (0.123)\tData 0.052 (0.099)\tLoss 0.7502 (0.6958)\tAcc 0.625 (0.672)\n",
      "Epoch: [27][5/9]\tTime 0.074 (0.113)\tData 0.054 (0.090)\tLoss 0.9222 (0.7411)\tAcc 0.562 (0.650)\n",
      "Epoch: [27][6/9]\tTime 0.073 (0.107)\tData 0.054 (0.084)\tLoss 0.2752 (0.6634)\tAcc 1.000 (0.708)\n",
      "Epoch: [27][7/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.7864 (0.6810)\tAcc 0.562 (0.688)\n",
      "Epoch: [27][8/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 1.0322 (0.7249)\tAcc 0.562 (0.672)\n",
      "Epoch: [27][9/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.2371 (0.7174)\tAcc 1.000 (0.677)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.428 (0.428)\tData 0.397 (0.397)\tLoss 1.1583 (1.1583)\tAcc 0.562 (0.562)\n",
      "Epoch: [28][2/5]\tTime 0.071 (0.250)\tData 0.047 (0.222)\tLoss 0.5340 (0.8462)\tAcc 0.812 (0.688)\n",
      "Epoch: [28][3/5]\tTime 0.076 (0.192)\tData 0.053 (0.166)\tLoss 0.5560 (0.7495)\tAcc 0.750 (0.708)\n",
      "Epoch: [28][4/5]\tTime 0.076 (0.163)\tData 0.054 (0.138)\tLoss 0.9087 (0.7893)\tAcc 0.625 (0.688)\n",
      "Epoch: [28][5/5]\tTime 0.078 (0.146)\tData 0.055 (0.121)\tLoss 1.2017 (0.8401)\tAcc 0.444 (0.658)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.266 (0.266)\tData 0.242 (0.242)\tLoss 0.3400 (0.3400)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/9]\tTime 0.073 (0.170)\tData 0.050 (0.146)\tLoss 0.8625 (0.6012)\tAcc 0.562 (0.750)\n",
      "Epoch: [28][3/9]\tTime 0.071 (0.137)\tData 0.050 (0.114)\tLoss 0.5451 (0.5825)\tAcc 0.875 (0.792)\n",
      "Epoch: [28][4/9]\tTime 0.074 (0.121)\tData 0.053 (0.099)\tLoss 0.6676 (0.6038)\tAcc 0.625 (0.750)\n",
      "Epoch: [28][5/9]\tTime 0.075 (0.112)\tData 0.054 (0.090)\tLoss 0.8929 (0.6616)\tAcc 0.688 (0.738)\n",
      "Epoch: [28][6/9]\tTime 0.072 (0.105)\tData 0.052 (0.084)\tLoss 0.2162 (0.5874)\tAcc 1.000 (0.781)\n",
      "Epoch: [28][7/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.8486 (0.6247)\tAcc 0.500 (0.741)\n",
      "Epoch: [28][8/9]\tTime 0.075 (0.097)\tData 0.056 (0.076)\tLoss 1.0425 (0.6769)\tAcc 0.625 (0.727)\n",
      "Epoch: [28][9/9]\tTime 0.073 (0.094)\tData 0.054 (0.074)\tLoss 0.1597 (0.6690)\tAcc 1.000 (0.731)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.471 (0.471)\tData 0.443 (0.443)\tLoss 0.6234 (0.6234)\tAcc 0.750 (0.750)\n",
      "Epoch: [29][2/5]\tTime 0.075 (0.273)\tData 0.050 (0.247)\tLoss 0.8651 (0.7442)\tAcc 0.562 (0.656)\n",
      "Epoch: [29][3/5]\tTime 0.081 (0.209)\tData 0.055 (0.183)\tLoss 0.7600 (0.7495)\tAcc 0.625 (0.646)\n",
      "Epoch: [29][4/5]\tTime 0.083 (0.177)\tData 0.058 (0.152)\tLoss 0.8387 (0.7718)\tAcc 0.625 (0.641)\n",
      "Epoch: [29][5/5]\tTime 0.086 (0.159)\tData 0.060 (0.133)\tLoss 0.7586 (0.7701)\tAcc 0.667 (0.644)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.343 (0.343)\tData 0.320 (0.320)\tLoss 0.3894 (0.3894)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.105 (0.224)\tData 0.070 (0.195)\tLoss 0.9446 (0.6670)\tAcc 0.438 (0.688)\n",
      "Epoch: [29][3/9]\tTime 0.072 (0.173)\tData 0.049 (0.146)\tLoss 0.6783 (0.6708)\tAcc 0.750 (0.708)\n",
      "Epoch: [29][4/9]\tTime 0.077 (0.149)\tData 0.056 (0.123)\tLoss 0.7203 (0.6831)\tAcc 0.688 (0.703)\n",
      "Epoch: [29][5/9]\tTime 0.080 (0.135)\tData 0.058 (0.110)\tLoss 0.8297 (0.7125)\tAcc 0.812 (0.725)\n",
      "Epoch: [29][6/9]\tTime 0.078 (0.126)\tData 0.059 (0.102)\tLoss 0.2607 (0.6372)\tAcc 1.000 (0.771)\n",
      "Epoch: [29][7/9]\tTime 0.075 (0.119)\tData 0.055 (0.095)\tLoss 0.8841 (0.6724)\tAcc 0.500 (0.732)\n",
      "Epoch: [29][8/9]\tTime 0.075 (0.113)\tData 0.055 (0.090)\tLoss 1.0312 (0.7173)\tAcc 0.625 (0.719)\n",
      "Epoch: [29][9/9]\tTime 0.073 (0.109)\tData 0.054 (0.086)\tLoss 0.3349 (0.7114)\tAcc 1.000 (0.723)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.526 (0.526)\tData 0.499 (0.499)\tLoss 0.6980 (0.6980)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][2/5]\tTime 0.076 (0.301)\tData 0.050 (0.275)\tLoss 0.8399 (0.7690)\tAcc 0.625 (0.656)\n",
      "Epoch: [30][3/5]\tTime 0.080 (0.228)\tData 0.056 (0.202)\tLoss 0.8196 (0.7858)\tAcc 0.688 (0.667)\n",
      "Epoch: [30][4/5]\tTime 0.084 (0.192)\tData 0.061 (0.167)\tLoss 0.5360 (0.7234)\tAcc 0.750 (0.688)\n",
      "Epoch: [30][5/5]\tTime 0.085 (0.170)\tData 0.061 (0.145)\tLoss 0.7642 (0.7284)\tAcc 0.667 (0.685)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.399 (0.399)\tData 0.364 (0.364)\tLoss 0.3784 (0.3784)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/9]\tTime 0.074 (0.237)\tData 0.047 (0.206)\tLoss 0.9152 (0.6468)\tAcc 0.562 (0.750)\n",
      "Epoch: [30][3/9]\tTime 0.074 (0.182)\tData 0.052 (0.154)\tLoss 0.6302 (0.6413)\tAcc 0.875 (0.792)\n",
      "Epoch: [30][4/9]\tTime 0.076 (0.156)\tData 0.057 (0.130)\tLoss 0.6601 (0.6460)\tAcc 0.812 (0.797)\n",
      "Epoch: [30][5/9]\tTime 0.078 (0.140)\tData 0.058 (0.116)\tLoss 0.7878 (0.6743)\tAcc 0.688 (0.775)\n",
      "Epoch: [30][6/9]\tTime 0.080 (0.130)\tData 0.060 (0.106)\tLoss 0.3248 (0.6161)\tAcc 0.938 (0.802)\n",
      "Epoch: [30][7/9]\tTime 0.080 (0.123)\tData 0.060 (0.100)\tLoss 0.7947 (0.6416)\tAcc 0.625 (0.777)\n",
      "Epoch: [30][8/9]\tTime 0.080 (0.118)\tData 0.060 (0.095)\tLoss 1.0454 (0.6921)\tAcc 0.562 (0.750)\n",
      "Epoch: [30][9/9]\tTime 0.080 (0.113)\tData 0.060 (0.091)\tLoss 0.3401 (0.6867)\tAcc 1.000 (0.754)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.375 (0.375)\tData 0.345 (0.345)\tLoss 0.6978 (0.6978)\tAcc 0.625 (0.625)\n",
      "Epoch: [31][2/5]\tTime 0.082 (0.228)\tData 0.057 (0.201)\tLoss 0.7323 (0.7150)\tAcc 0.625 (0.625)\n",
      "Epoch: [31][3/5]\tTime 0.085 (0.181)\tData 0.059 (0.154)\tLoss 0.5890 (0.6730)\tAcc 0.875 (0.708)\n",
      "Epoch: [31][4/5]\tTime 0.086 (0.157)\tData 0.062 (0.131)\tLoss 0.4515 (0.6176)\tAcc 0.875 (0.750)\n",
      "Epoch: [31][5/5]\tTime 0.085 (0.143)\tData 0.061 (0.117)\tLoss 1.0191 (0.6671)\tAcc 0.444 (0.712)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.286 (0.286)\tData 0.260 (0.260)\tLoss 0.4290 (0.4290)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.080 (0.183)\tData 0.055 (0.157)\tLoss 0.9136 (0.6713)\tAcc 0.438 (0.688)\n",
      "Epoch: [31][3/9]\tTime 0.076 (0.147)\tData 0.051 (0.122)\tLoss 0.7289 (0.6905)\tAcc 0.750 (0.708)\n",
      "Epoch: [31][4/9]\tTime 0.076 (0.130)\tData 0.054 (0.105)\tLoss 0.6777 (0.6873)\tAcc 0.750 (0.719)\n",
      "Epoch: [31][5/9]\tTime 0.081 (0.120)\tData 0.059 (0.096)\tLoss 0.7900 (0.7079)\tAcc 0.688 (0.713)\n",
      "Epoch: [31][6/9]\tTime 0.079 (0.113)\tData 0.058 (0.089)\tLoss 0.2652 (0.6341)\tAcc 1.000 (0.760)\n",
      "Epoch: [31][7/9]\tTime 0.079 (0.108)\tData 0.059 (0.085)\tLoss 0.7989 (0.6576)\tAcc 0.688 (0.750)\n",
      "Epoch: [31][8/9]\tTime 0.080 (0.105)\tData 0.060 (0.082)\tLoss 1.1533 (0.7196)\tAcc 0.500 (0.719)\n",
      "Epoch: [31][9/9]\tTime 0.077 (0.102)\tData 0.058 (0.079)\tLoss 0.1535 (0.7109)\tAcc 1.000 (0.723)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.469 (0.469)\tData 0.439 (0.439)\tLoss 0.8935 (0.8935)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][2/5]\tTime 0.080 (0.275)\tData 0.055 (0.247)\tLoss 0.7576 (0.8256)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][3/5]\tTime 0.085 (0.211)\tData 0.060 (0.185)\tLoss 0.5098 (0.7203)\tAcc 0.812 (0.771)\n",
      "Epoch: [32][4/5]\tTime 0.085 (0.180)\tData 0.061 (0.154)\tLoss 0.8731 (0.7585)\tAcc 0.562 (0.719)\n",
      "Epoch: [32][5/5]\tTime 0.084 (0.160)\tData 0.060 (0.135)\tLoss 0.5018 (0.7269)\tAcc 0.889 (0.740)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.355 (0.355)\tData 0.329 (0.329)\tLoss 0.3587 (0.3587)\tAcc 0.938 (0.938)\n",
      "Epoch: [32][2/9]\tTime 0.078 (0.216)\tData 0.055 (0.192)\tLoss 0.9656 (0.6622)\tAcc 0.438 (0.688)\n",
      "Epoch: [32][3/9]\tTime 0.081 (0.171)\tData 0.057 (0.147)\tLoss 0.5338 (0.6194)\tAcc 0.812 (0.729)\n",
      "Epoch: [32][4/9]\tTime 0.079 (0.148)\tData 0.058 (0.125)\tLoss 0.5530 (0.6028)\tAcc 0.812 (0.750)\n",
      "Epoch: [32][5/9]\tTime 0.079 (0.134)\tData 0.059 (0.111)\tLoss 0.7404 (0.6303)\tAcc 0.688 (0.738)\n",
      "Epoch: [32][6/9]\tTime 0.080 (0.125)\tData 0.061 (0.103)\tLoss 0.3326 (0.5807)\tAcc 1.000 (0.781)\n",
      "Epoch: [32][7/9]\tTime 0.080 (0.119)\tData 0.060 (0.097)\tLoss 0.9089 (0.6276)\tAcc 0.500 (0.741)\n",
      "Epoch: [32][8/9]\tTime 0.080 (0.114)\tData 0.060 (0.092)\tLoss 0.9606 (0.6692)\tAcc 0.562 (0.719)\n",
      "Epoch: [32][9/9]\tTime 0.080 (0.110)\tData 0.060 (0.089)\tLoss 0.1721 (0.6616)\tAcc 1.000 (0.723)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.410 (0.410)\tData 0.381 (0.381)\tLoss 0.9106 (0.9106)\tAcc 0.562 (0.562)\n",
      "Epoch: [33][2/5]\tTime 0.073 (0.241)\tData 0.049 (0.215)\tLoss 0.4728 (0.6917)\tAcc 0.875 (0.719)\n",
      "Epoch: [33][3/5]\tTime 0.079 (0.187)\tData 0.055 (0.162)\tLoss 0.5607 (0.6480)\tAcc 0.812 (0.750)\n",
      "Epoch: [33][4/5]\tTime 0.084 (0.161)\tData 0.060 (0.136)\tLoss 1.0844 (0.7571)\tAcc 0.500 (0.688)\n",
      "Epoch: [33][5/5]\tTime 0.085 (0.146)\tData 0.061 (0.121)\tLoss 0.5963 (0.7373)\tAcc 0.667 (0.685)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.2442 (0.2442)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.076 (0.221)\tData 0.049 (0.194)\tLoss 1.0632 (0.6537)\tAcc 0.500 (0.719)\n",
      "Epoch: [33][3/9]\tTime 0.072 (0.171)\tData 0.047 (0.145)\tLoss 0.7588 (0.6888)\tAcc 0.562 (0.667)\n",
      "Epoch: [33][4/9]\tTime 0.069 (0.146)\tData 0.049 (0.121)\tLoss 0.6176 (0.6710)\tAcc 0.812 (0.703)\n",
      "Epoch: [33][5/9]\tTime 0.073 (0.131)\tData 0.053 (0.107)\tLoss 0.8884 (0.7145)\tAcc 0.625 (0.688)\n",
      "Epoch: [33][6/9]\tTime 0.079 (0.122)\tData 0.059 (0.099)\tLoss 0.1868 (0.6265)\tAcc 1.000 (0.740)\n",
      "Epoch: [33][7/9]\tTime 0.080 (0.116)\tData 0.060 (0.094)\tLoss 0.9432 (0.6718)\tAcc 0.500 (0.705)\n",
      "Epoch: [33][8/9]\tTime 0.085 (0.112)\tData 0.060 (0.090)\tLoss 1.0534 (0.7195)\tAcc 0.500 (0.680)\n",
      "Epoch: [33][9/9]\tTime 0.074 (0.108)\tData 0.055 (0.086)\tLoss 0.1316 (0.7104)\tAcc 1.000 (0.685)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.556 (0.556)\tData 0.529 (0.529)\tLoss 0.6287 (0.6287)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][2/5]\tTime 0.197 (0.376)\tData 0.173 (0.351)\tLoss 0.5690 (0.5988)\tAcc 0.812 (0.781)\n",
      "Epoch: [34][3/5]\tTime 0.078 (0.277)\tData 0.053 (0.252)\tLoss 0.6931 (0.6303)\tAcc 0.688 (0.750)\n",
      "Epoch: [34][4/5]\tTime 0.082 (0.228)\tData 0.059 (0.204)\tLoss 1.2258 (0.7792)\tAcc 0.562 (0.703)\n",
      "Epoch: [34][5/5]\tTime 0.077 (0.198)\tData 0.054 (0.174)\tLoss 0.5139 (0.7465)\tAcc 0.889 (0.726)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.358 (0.358)\tData 0.332 (0.332)\tLoss 0.3403 (0.3403)\tAcc 0.875 (0.875)\n",
      "Epoch: [34][2/9]\tTime 0.069 (0.214)\tData 0.048 (0.190)\tLoss 1.0758 (0.7080)\tAcc 0.438 (0.656)\n",
      "Epoch: [34][3/9]\tTime 0.074 (0.167)\tData 0.052 (0.144)\tLoss 0.7226 (0.7129)\tAcc 0.688 (0.667)\n",
      "Epoch: [34][4/9]\tTime 0.071 (0.143)\tData 0.052 (0.121)\tLoss 0.6844 (0.7058)\tAcc 0.625 (0.656)\n",
      "Epoch: [34][5/9]\tTime 0.074 (0.129)\tData 0.055 (0.108)\tLoss 0.8030 (0.7252)\tAcc 0.688 (0.663)\n",
      "Epoch: [34][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.2182 (0.6407)\tAcc 1.000 (0.719)\n",
      "Epoch: [34][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.7613 (0.6579)\tAcc 0.688 (0.714)\n",
      "Epoch: [34][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.088)\tLoss 1.1073 (0.7141)\tAcc 0.625 (0.703)\n",
      "Epoch: [34][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.084)\tLoss 0.1020 (0.7047)\tAcc 1.000 (0.708)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.353 (0.353)\tData 0.324 (0.324)\tLoss 0.8798 (0.8798)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][2/5]\tTime 0.073 (0.213)\tData 0.049 (0.186)\tLoss 0.4846 (0.6822)\tAcc 0.812 (0.781)\n",
      "Epoch: [35][3/5]\tTime 0.078 (0.168)\tData 0.053 (0.142)\tLoss 0.8303 (0.7315)\tAcc 0.500 (0.688)\n",
      "Epoch: [35][4/5]\tTime 0.075 (0.144)\tData 0.052 (0.119)\tLoss 0.7186 (0.7283)\tAcc 0.688 (0.688)\n",
      "Epoch: [35][5/5]\tTime 0.080 (0.132)\tData 0.057 (0.107)\tLoss 0.5151 (0.7020)\tAcc 0.889 (0.712)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.262 (0.262)\tData 0.238 (0.238)\tLoss 0.3959 (0.3959)\tAcc 0.875 (0.875)\n",
      "Epoch: [35][2/9]\tTime 0.073 (0.167)\tData 0.051 (0.145)\tLoss 1.0147 (0.7053)\tAcc 0.500 (0.688)\n",
      "Epoch: [35][3/9]\tTime 0.073 (0.136)\tData 0.052 (0.114)\tLoss 0.5620 (0.6575)\tAcc 0.625 (0.667)\n",
      "Epoch: [35][4/9]\tTime 0.073 (0.120)\tData 0.052 (0.099)\tLoss 0.6410 (0.6534)\tAcc 0.750 (0.688)\n",
      "Epoch: [35][5/9]\tTime 0.077 (0.112)\tData 0.054 (0.090)\tLoss 0.8237 (0.6875)\tAcc 0.688 (0.688)\n",
      "Epoch: [35][6/9]\tTime 0.070 (0.105)\tData 0.051 (0.083)\tLoss 0.2519 (0.6149)\tAcc 1.000 (0.740)\n",
      "Epoch: [35][7/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.6567 (0.6208)\tAcc 0.625 (0.723)\n",
      "Epoch: [35][8/9]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 1.1629 (0.6886)\tAcc 0.500 (0.695)\n",
      "Epoch: [35][9/9]\tTime 0.078 (0.095)\tData 0.059 (0.074)\tLoss 0.2696 (0.6821)\tAcc 1.000 (0.700)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.349 (0.349)\tData 0.321 (0.321)\tLoss 0.8493 (0.8493)\tAcc 0.688 (0.688)\n",
      "Epoch: [36][2/5]\tTime 0.076 (0.213)\tData 0.051 (0.186)\tLoss 0.6858 (0.7676)\tAcc 0.625 (0.656)\n",
      "Epoch: [36][3/5]\tTime 0.075 (0.167)\tData 0.052 (0.141)\tLoss 0.9238 (0.8197)\tAcc 0.562 (0.625)\n",
      "Epoch: [36][4/5]\tTime 0.076 (0.144)\tData 0.053 (0.119)\tLoss 0.6616 (0.7801)\tAcc 0.750 (0.656)\n",
      "Epoch: [36][5/5]\tTime 0.079 (0.131)\tData 0.056 (0.107)\tLoss 0.8826 (0.7928)\tAcc 0.778 (0.671)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.323 (0.323)\tData 0.287 (0.287)\tLoss 0.2814 (0.2814)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/9]\tTime 0.069 (0.196)\tData 0.047 (0.167)\tLoss 1.0462 (0.6638)\tAcc 0.500 (0.719)\n",
      "Epoch: [36][3/9]\tTime 0.076 (0.156)\tData 0.052 (0.129)\tLoss 0.5427 (0.6235)\tAcc 0.812 (0.750)\n",
      "Epoch: [36][4/9]\tTime 0.071 (0.135)\tData 0.050 (0.109)\tLoss 0.7219 (0.6481)\tAcc 0.688 (0.734)\n",
      "Epoch: [36][5/9]\tTime 0.073 (0.122)\tData 0.053 (0.098)\tLoss 0.8303 (0.6845)\tAcc 0.688 (0.725)\n",
      "Epoch: [36][6/9]\tTime 0.072 (0.114)\tData 0.053 (0.090)\tLoss 0.1670 (0.5982)\tAcc 1.000 (0.771)\n",
      "Epoch: [36][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.085)\tLoss 0.6734 (0.6090)\tAcc 0.688 (0.759)\n",
      "Epoch: [36][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.082)\tLoss 1.1247 (0.6734)\tAcc 0.562 (0.734)\n",
      "Epoch: [36][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.1154 (0.6649)\tAcc 1.000 (0.738)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.392 (0.392)\tData 0.363 (0.363)\tLoss 0.6466 (0.6466)\tAcc 0.688 (0.688)\n",
      "Epoch: [37][2/5]\tTime 0.073 (0.232)\tData 0.049 (0.206)\tLoss 0.8423 (0.7445)\tAcc 0.562 (0.625)\n",
      "Epoch: [37][3/5]\tTime 0.078 (0.181)\tData 0.054 (0.156)\tLoss 0.5257 (0.6716)\tAcc 0.875 (0.708)\n",
      "Epoch: [37][4/5]\tTime 0.076 (0.155)\tData 0.053 (0.130)\tLoss 0.4454 (0.6150)\tAcc 0.875 (0.750)\n",
      "Epoch: [37][5/5]\tTime 0.080 (0.140)\tData 0.057 (0.115)\tLoss 0.9475 (0.6560)\tAcc 0.556 (0.726)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.238 (0.238)\tData 0.214 (0.214)\tLoss 0.3427 (0.3427)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/9]\tTime 0.118 (0.178)\tData 0.096 (0.155)\tLoss 0.9223 (0.6325)\tAcc 0.500 (0.719)\n",
      "Epoch: [37][3/9]\tTime 0.072 (0.143)\tData 0.051 (0.120)\tLoss 0.7150 (0.6600)\tAcc 0.688 (0.708)\n",
      "Epoch: [37][4/9]\tTime 0.074 (0.126)\tData 0.053 (0.103)\tLoss 0.5576 (0.6344)\tAcc 0.812 (0.734)\n",
      "Epoch: [37][5/9]\tTime 0.077 (0.116)\tData 0.056 (0.094)\tLoss 0.9112 (0.6898)\tAcc 0.688 (0.725)\n",
      "Epoch: [37][6/9]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.2062 (0.6092)\tAcc 1.000 (0.771)\n",
      "Epoch: [37][7/9]\tTime 0.073 (0.104)\tData 0.053 (0.082)\tLoss 0.5654 (0.6029)\tAcc 0.812 (0.777)\n",
      "Epoch: [37][8/9]\tTime 0.077 (0.100)\tData 0.058 (0.079)\tLoss 1.0708 (0.6614)\tAcc 0.625 (0.758)\n",
      "Epoch: [37][9/9]\tTime 0.074 (0.097)\tData 0.055 (0.077)\tLoss 0.1991 (0.6543)\tAcc 1.000 (0.762)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.407 (0.407)\tData 0.377 (0.377)\tLoss 0.4100 (0.4100)\tAcc 0.875 (0.875)\n",
      "Epoch: [38][2/5]\tTime 0.072 (0.240)\tData 0.048 (0.213)\tLoss 0.9784 (0.6942)\tAcc 0.625 (0.750)\n",
      "Epoch: [38][3/5]\tTime 0.076 (0.185)\tData 0.053 (0.159)\tLoss 1.1790 (0.8558)\tAcc 0.562 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.076 (0.158)\tData 0.053 (0.133)\tLoss 0.7302 (0.8244)\tAcc 0.750 (0.703)\n",
      "Epoch: [38][5/5]\tTime 0.079 (0.142)\tData 0.056 (0.117)\tLoss 0.4731 (0.7811)\tAcc 0.778 (0.712)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.327 (0.327)\tData 0.303 (0.303)\tLoss 0.2894 (0.2894)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.071 (0.199)\tData 0.050 (0.177)\tLoss 1.0002 (0.6448)\tAcc 0.562 (0.750)\n",
      "Epoch: [38][3/9]\tTime 0.073 (0.157)\tData 0.053 (0.136)\tLoss 0.6302 (0.6399)\tAcc 0.625 (0.708)\n",
      "Epoch: [38][4/9]\tTime 0.074 (0.136)\tData 0.053 (0.115)\tLoss 0.7101 (0.6575)\tAcc 0.688 (0.703)\n",
      "Epoch: [38][5/9]\tTime 0.074 (0.124)\tData 0.054 (0.103)\tLoss 0.7438 (0.6747)\tAcc 0.812 (0.725)\n",
      "Epoch: [38][6/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.2229 (0.5994)\tAcc 1.000 (0.771)\n",
      "Epoch: [38][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.089)\tLoss 0.5938 (0.5986)\tAcc 0.812 (0.777)\n",
      "Epoch: [38][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 1.1079 (0.6623)\tAcc 0.438 (0.734)\n",
      "Epoch: [38][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.081)\tLoss 0.1328 (0.6541)\tAcc 1.000 (0.738)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.386 (0.386)\tData 0.358 (0.358)\tLoss 1.0754 (1.0754)\tAcc 0.438 (0.438)\n",
      "Epoch: [39][2/5]\tTime 0.074 (0.230)\tData 0.050 (0.204)\tLoss 0.7811 (0.9282)\tAcc 0.625 (0.531)\n",
      "Epoch: [39][3/5]\tTime 0.076 (0.178)\tData 0.053 (0.154)\tLoss 0.5389 (0.7985)\tAcc 0.875 (0.646)\n",
      "Epoch: [39][4/5]\tTime 0.076 (0.153)\tData 0.053 (0.128)\tLoss 0.5850 (0.7451)\tAcc 0.812 (0.688)\n",
      "Epoch: [39][5/5]\tTime 0.078 (0.138)\tData 0.055 (0.114)\tLoss 1.0771 (0.7860)\tAcc 0.556 (0.671)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.354 (0.354)\tData 0.330 (0.330)\tLoss 0.3580 (0.3580)\tAcc 0.875 (0.875)\n",
      "Epoch: [39][2/9]\tTime 0.071 (0.212)\tData 0.050 (0.190)\tLoss 0.9904 (0.6742)\tAcc 0.500 (0.688)\n",
      "Epoch: [39][3/9]\tTime 0.074 (0.166)\tData 0.052 (0.144)\tLoss 0.4127 (0.5870)\tAcc 0.875 (0.750)\n",
      "Epoch: [39][4/9]\tTime 0.072 (0.142)\tData 0.052 (0.121)\tLoss 0.6121 (0.5933)\tAcc 0.625 (0.719)\n",
      "Epoch: [39][5/9]\tTime 0.089 (0.132)\tData 0.070 (0.111)\tLoss 0.9767 (0.6700)\tAcc 0.562 (0.688)\n",
      "Epoch: [39][6/9]\tTime 0.073 (0.122)\tData 0.054 (0.101)\tLoss 0.2575 (0.6012)\tAcc 1.000 (0.740)\n",
      "Epoch: [39][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.095)\tLoss 0.6756 (0.6119)\tAcc 0.625 (0.723)\n",
      "Epoch: [39][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.090)\tLoss 1.0696 (0.6691)\tAcc 0.500 (0.695)\n",
      "Epoch: [39][9/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.1703 (0.6614)\tAcc 1.000 (0.700)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.481 (0.481)\tData 0.454 (0.454)\tLoss 0.6595 (0.6595)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][2/5]\tTime 0.075 (0.278)\tData 0.051 (0.253)\tLoss 0.8110 (0.7352)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][3/5]\tTime 0.077 (0.211)\tData 0.054 (0.186)\tLoss 0.8035 (0.7580)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][4/5]\tTime 0.076 (0.177)\tData 0.053 (0.153)\tLoss 0.7785 (0.7631)\tAcc 0.625 (0.672)\n",
      "Epoch: [40][5/5]\tTime 0.078 (0.157)\tData 0.056 (0.134)\tLoss 0.4416 (0.7235)\tAcc 0.889 (0.699)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.309 (0.309)\tData 0.281 (0.281)\tLoss 0.3107 (0.3107)\tAcc 0.875 (0.875)\n",
      "Epoch: [40][2/9]\tTime 0.067 (0.188)\tData 0.046 (0.164)\tLoss 1.0609 (0.6858)\tAcc 0.500 (0.688)\n",
      "Epoch: [40][3/9]\tTime 0.074 (0.150)\tData 0.053 (0.127)\tLoss 0.6348 (0.6688)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][4/9]\tTime 0.072 (0.130)\tData 0.052 (0.108)\tLoss 0.7548 (0.6903)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][5/9]\tTime 0.073 (0.119)\tData 0.054 (0.097)\tLoss 0.8237 (0.7170)\tAcc 0.625 (0.675)\n",
      "Epoch: [40][6/9]\tTime 0.073 (0.111)\tData 0.054 (0.090)\tLoss 0.1945 (0.6299)\tAcc 1.000 (0.729)\n",
      "Epoch: [40][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.085)\tLoss 0.7901 (0.6528)\tAcc 0.750 (0.732)\n",
      "Epoch: [40][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.081)\tLoss 1.0331 (0.7003)\tAcc 0.625 (0.719)\n",
      "Epoch: [40][9/9]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.1661 (0.6921)\tAcc 1.000 (0.723)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.490 (0.490)\tData 0.462 (0.462)\tLoss 0.9106 (0.9106)\tAcc 0.500 (0.500)\n",
      "Epoch: [41][2/5]\tTime 0.073 (0.282)\tData 0.049 (0.255)\tLoss 0.8262 (0.8684)\tAcc 0.562 (0.531)\n",
      "Epoch: [41][3/5]\tTime 0.077 (0.214)\tData 0.053 (0.188)\tLoss 0.6960 (0.8109)\tAcc 0.750 (0.604)\n",
      "Epoch: [41][4/5]\tTime 0.076 (0.179)\tData 0.053 (0.154)\tLoss 0.9771 (0.8525)\tAcc 0.688 (0.625)\n",
      "Epoch: [41][5/5]\tTime 0.078 (0.159)\tData 0.055 (0.134)\tLoss 0.5782 (0.8187)\tAcc 0.778 (0.644)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.324 (0.324)\tData 0.301 (0.301)\tLoss 0.3536 (0.3536)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/9]\tTime 0.074 (0.199)\tData 0.051 (0.176)\tLoss 0.9093 (0.6314)\tAcc 0.625 (0.781)\n",
      "Epoch: [41][3/9]\tTime 0.073 (0.157)\tData 0.051 (0.134)\tLoss 0.6552 (0.6393)\tAcc 0.688 (0.750)\n",
      "Epoch: [41][4/9]\tTime 0.072 (0.136)\tData 0.051 (0.114)\tLoss 0.6203 (0.6346)\tAcc 0.625 (0.719)\n",
      "Epoch: [41][5/9]\tTime 0.074 (0.123)\tData 0.053 (0.101)\tLoss 0.9200 (0.6917)\tAcc 0.688 (0.713)\n",
      "Epoch: [41][6/9]\tTime 0.075 (0.115)\tData 0.053 (0.093)\tLoss 0.2523 (0.6184)\tAcc 1.000 (0.760)\n",
      "Epoch: [41][7/9]\tTime 0.071 (0.109)\tData 0.052 (0.087)\tLoss 0.7296 (0.6343)\tAcc 0.625 (0.741)\n",
      "Epoch: [41][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.083)\tLoss 1.2774 (0.7147)\tAcc 0.500 (0.711)\n",
      "Epoch: [41][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.3101 (0.7085)\tAcc 1.000 (0.715)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.420 (0.420)\tData 0.392 (0.392)\tLoss 0.9813 (0.9813)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][2/5]\tTime 0.075 (0.247)\tData 0.051 (0.222)\tLoss 0.6225 (0.8019)\tAcc 0.812 (0.750)\n",
      "Epoch: [42][3/5]\tTime 0.077 (0.191)\tData 0.054 (0.166)\tLoss 0.7038 (0.7692)\tAcc 0.688 (0.729)\n",
      "Epoch: [42][4/5]\tTime 0.077 (0.162)\tData 0.053 (0.138)\tLoss 0.5658 (0.7183)\tAcc 0.750 (0.734)\n",
      "Epoch: [42][5/5]\tTime 0.078 (0.145)\tData 0.055 (0.121)\tLoss 0.5848 (0.7019)\tAcc 0.778 (0.740)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.262 (0.262)\tData 0.238 (0.238)\tLoss 0.3091 (0.3091)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/9]\tTime 0.073 (0.167)\tData 0.052 (0.145)\tLoss 0.9917 (0.6504)\tAcc 0.625 (0.781)\n",
      "Epoch: [42][3/9]\tTime 0.074 (0.136)\tData 0.052 (0.114)\tLoss 0.6029 (0.6346)\tAcc 0.750 (0.771)\n",
      "Epoch: [42][4/9]\tTime 0.073 (0.120)\tData 0.052 (0.099)\tLoss 0.5982 (0.6255)\tAcc 0.812 (0.781)\n",
      "Epoch: [42][5/9]\tTime 0.074 (0.111)\tData 0.054 (0.090)\tLoss 0.8752 (0.6754)\tAcc 0.562 (0.738)\n",
      "Epoch: [42][6/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.2760 (0.6088)\tAcc 1.000 (0.781)\n",
      "Epoch: [42][7/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.7011 (0.6220)\tAcc 0.688 (0.768)\n",
      "Epoch: [42][8/9]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 1.0005 (0.6693)\tAcc 0.688 (0.758)\n",
      "Epoch: [42][9/9]\tTime 0.073 (0.094)\tData 0.055 (0.074)\tLoss 0.1865 (0.6619)\tAcc 1.000 (0.762)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.352 (0.352)\tData 0.324 (0.324)\tLoss 0.8330 (0.8330)\tAcc 0.625 (0.625)\n",
      "Epoch: [43][2/5]\tTime 0.074 (0.213)\tData 0.050 (0.187)\tLoss 0.4832 (0.6581)\tAcc 0.875 (0.750)\n",
      "Epoch: [43][3/5]\tTime 0.077 (0.168)\tData 0.052 (0.142)\tLoss 0.5799 (0.6320)\tAcc 0.812 (0.771)\n",
      "Epoch: [43][4/5]\tTime 0.075 (0.145)\tData 0.053 (0.120)\tLoss 0.9204 (0.7041)\tAcc 0.625 (0.734)\n",
      "Epoch: [43][5/5]\tTime 0.078 (0.131)\tData 0.056 (0.107)\tLoss 0.6626 (0.6990)\tAcc 0.667 (0.726)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.296 (0.296)\tData 0.270 (0.270)\tLoss 0.2915 (0.2915)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/9]\tTime 0.072 (0.184)\tData 0.049 (0.160)\tLoss 1.0442 (0.6678)\tAcc 0.625 (0.781)\n",
      "Epoch: [43][3/9]\tTime 0.071 (0.147)\tData 0.050 (0.123)\tLoss 0.5738 (0.6365)\tAcc 0.875 (0.812)\n",
      "Epoch: [43][4/9]\tTime 0.073 (0.128)\tData 0.052 (0.105)\tLoss 0.8322 (0.6854)\tAcc 0.625 (0.766)\n",
      "Epoch: [43][5/9]\tTime 0.077 (0.118)\tData 0.054 (0.095)\tLoss 0.8637 (0.7211)\tAcc 0.750 (0.762)\n",
      "Epoch: [43][6/9]\tTime 0.070 (0.110)\tData 0.050 (0.088)\tLoss 0.2359 (0.6402)\tAcc 1.000 (0.802)\n",
      "Epoch: [43][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.5401 (0.6259)\tAcc 0.812 (0.804)\n",
      "Epoch: [43][8/9]\tTime 0.075 (0.101)\tData 0.055 (0.079)\tLoss 1.2020 (0.6979)\tAcc 0.562 (0.773)\n",
      "Epoch: [43][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.1314 (0.6892)\tAcc 1.000 (0.777)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.340 (0.340)\tData 0.309 (0.309)\tLoss 0.7002 (0.7002)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][2/5]\tTime 0.072 (0.206)\tData 0.048 (0.179)\tLoss 0.3862 (0.5432)\tAcc 0.938 (0.812)\n",
      "Epoch: [44][3/5]\tTime 0.076 (0.163)\tData 0.053 (0.137)\tLoss 0.9291 (0.6718)\tAcc 0.750 (0.792)\n",
      "Epoch: [44][4/5]\tTime 0.076 (0.141)\tData 0.054 (0.116)\tLoss 0.5875 (0.6507)\tAcc 0.875 (0.812)\n",
      "Epoch: [44][5/5]\tTime 0.078 (0.128)\tData 0.055 (0.104)\tLoss 1.0160 (0.6958)\tAcc 0.444 (0.767)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.321 (0.321)\tData 0.296 (0.296)\tLoss 0.3111 (0.3111)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.072 (0.196)\tData 0.050 (0.173)\tLoss 0.9460 (0.6285)\tAcc 0.562 (0.750)\n",
      "Epoch: [44][3/9]\tTime 0.074 (0.155)\tData 0.052 (0.133)\tLoss 0.5586 (0.6052)\tAcc 0.812 (0.771)\n",
      "Epoch: [44][4/9]\tTime 0.073 (0.135)\tData 0.052 (0.113)\tLoss 0.6300 (0.6114)\tAcc 0.688 (0.750)\n",
      "Epoch: [44][5/9]\tTime 0.083 (0.124)\tData 0.054 (0.101)\tLoss 0.7805 (0.6452)\tAcc 0.750 (0.750)\n",
      "Epoch: [44][6/9]\tTime 0.064 (0.114)\tData 0.044 (0.091)\tLoss 0.2351 (0.5769)\tAcc 1.000 (0.792)\n",
      "Epoch: [44][7/9]\tTime 0.073 (0.108)\tData 0.053 (0.086)\tLoss 0.7837 (0.6064)\tAcc 0.500 (0.750)\n",
      "Epoch: [44][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.082)\tLoss 1.0873 (0.6665)\tAcc 0.562 (0.727)\n",
      "Epoch: [44][9/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.2156 (0.6596)\tAcc 1.000 (0.731)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.500 (0.500)\tData 0.472 (0.472)\tLoss 0.5917 (0.5917)\tAcc 0.625 (0.625)\n",
      "Epoch: [45][2/5]\tTime 0.074 (0.287)\tData 0.050 (0.261)\tLoss 0.9670 (0.7794)\tAcc 0.500 (0.562)\n",
      "Epoch: [45][3/5]\tTime 0.076 (0.217)\tData 0.053 (0.192)\tLoss 0.6022 (0.7203)\tAcc 0.750 (0.625)\n",
      "Epoch: [45][4/5]\tTime 0.076 (0.182)\tData 0.054 (0.157)\tLoss 0.6834 (0.7111)\tAcc 0.688 (0.641)\n",
      "Epoch: [45][5/5]\tTime 0.078 (0.161)\tData 0.056 (0.137)\tLoss 0.6217 (0.7000)\tAcc 0.667 (0.644)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.299 (0.299)\tData 0.275 (0.275)\tLoss 0.3360 (0.3360)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/9]\tTime 0.072 (0.185)\tData 0.050 (0.163)\tLoss 0.9334 (0.6347)\tAcc 0.562 (0.750)\n",
      "Epoch: [45][3/9]\tTime 0.074 (0.148)\tData 0.052 (0.126)\tLoss 0.6373 (0.6356)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][4/9]\tTime 0.073 (0.129)\tData 0.051 (0.107)\tLoss 0.6538 (0.6401)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][5/9]\tTime 0.073 (0.118)\tData 0.053 (0.096)\tLoss 0.8602 (0.6841)\tAcc 0.625 (0.725)\n",
      "Epoch: [45][6/9]\tTime 0.073 (0.111)\tData 0.053 (0.089)\tLoss 0.2671 (0.6146)\tAcc 1.000 (0.771)\n",
      "Epoch: [45][7/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.6681 (0.6223)\tAcc 0.688 (0.759)\n",
      "Epoch: [45][8/9]\tTime 0.075 (0.101)\tData 0.055 (0.081)\tLoss 1.0636 (0.6774)\tAcc 0.500 (0.727)\n",
      "Epoch: [45][9/9]\tTime 0.072 (0.098)\tData 0.054 (0.078)\tLoss 0.1289 (0.6690)\tAcc 1.000 (0.731)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.368 (0.368)\tData 0.340 (0.340)\tLoss 0.6866 (0.6866)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][2/5]\tTime 0.076 (0.222)\tData 0.051 (0.195)\tLoss 0.6183 (0.6525)\tAcc 0.875 (0.812)\n",
      "Epoch: [46][3/5]\tTime 0.075 (0.173)\tData 0.052 (0.148)\tLoss 1.1877 (0.8309)\tAcc 0.500 (0.708)\n",
      "Epoch: [46][4/5]\tTime 0.076 (0.149)\tData 0.053 (0.124)\tLoss 0.7069 (0.7999)\tAcc 0.812 (0.734)\n",
      "Epoch: [46][5/5]\tTime 0.078 (0.135)\tData 0.056 (0.110)\tLoss 0.3902 (0.7494)\tAcc 0.889 (0.753)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.322 (0.322)\tData 0.298 (0.298)\tLoss 0.3429 (0.3429)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/9]\tTime 0.071 (0.197)\tData 0.050 (0.174)\tLoss 0.8797 (0.6113)\tAcc 0.500 (0.719)\n",
      "Epoch: [46][3/9]\tTime 0.074 (0.156)\tData 0.053 (0.134)\tLoss 0.6114 (0.6113)\tAcc 0.875 (0.771)\n",
      "Epoch: [46][4/9]\tTime 0.073 (0.135)\tData 0.052 (0.113)\tLoss 0.6336 (0.6169)\tAcc 0.688 (0.750)\n",
      "Epoch: [46][5/9]\tTime 0.073 (0.123)\tData 0.053 (0.101)\tLoss 0.8727 (0.6680)\tAcc 0.625 (0.725)\n",
      "Epoch: [46][6/9]\tTime 0.072 (0.114)\tData 0.053 (0.093)\tLoss 0.2970 (0.6062)\tAcc 1.000 (0.771)\n",
      "Epoch: [46][7/9]\tTime 0.072 (0.108)\tData 0.054 (0.087)\tLoss 0.7422 (0.6256)\tAcc 0.562 (0.741)\n",
      "Epoch: [46][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 1.0720 (0.6814)\tAcc 0.500 (0.711)\n",
      "Epoch: [46][9/9]\tTime 0.072 (0.100)\tData 0.054 (0.080)\tLoss 0.2631 (0.6750)\tAcc 1.000 (0.715)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.422 (0.422)\tData 0.393 (0.393)\tLoss 0.9362 (0.9362)\tAcc 0.625 (0.625)\n",
      "Epoch: [47][2/5]\tTime 0.073 (0.248)\tData 0.049 (0.221)\tLoss 0.7612 (0.8487)\tAcc 0.688 (0.656)\n",
      "Epoch: [47][3/5]\tTime 0.076 (0.190)\tData 0.053 (0.165)\tLoss 0.6745 (0.7906)\tAcc 0.812 (0.708)\n",
      "Epoch: [47][4/5]\tTime 0.077 (0.162)\tData 0.054 (0.137)\tLoss 0.5758 (0.7369)\tAcc 0.812 (0.734)\n",
      "Epoch: [47][5/5]\tTime 0.078 (0.145)\tData 0.055 (0.121)\tLoss 1.0515 (0.7757)\tAcc 0.444 (0.699)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.340 (0.340)\tData 0.315 (0.315)\tLoss 0.2328 (0.2328)\tAcc 1.000 (1.000)\n",
      "Epoch: [47][2/9]\tTime 0.070 (0.205)\tData 0.049 (0.182)\tLoss 1.0818 (0.6573)\tAcc 0.438 (0.719)\n",
      "Epoch: [47][3/9]\tTime 0.073 (0.161)\tData 0.053 (0.139)\tLoss 0.5521 (0.6222)\tAcc 0.875 (0.771)\n",
      "Epoch: [47][4/9]\tTime 0.073 (0.139)\tData 0.054 (0.118)\tLoss 0.6053 (0.6180)\tAcc 0.750 (0.766)\n",
      "Epoch: [47][5/9]\tTime 0.073 (0.126)\tData 0.054 (0.105)\tLoss 1.0233 (0.6991)\tAcc 0.625 (0.738)\n",
      "Epoch: [47][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.097)\tLoss 0.2046 (0.6166)\tAcc 1.000 (0.781)\n",
      "Epoch: [47][7/9]\tTime 0.073 (0.111)\tData 0.054 (0.090)\tLoss 0.7775 (0.6396)\tAcc 0.625 (0.759)\n",
      "Epoch: [47][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.086)\tLoss 0.9645 (0.6802)\tAcc 0.562 (0.734)\n",
      "Epoch: [47][9/9]\tTime 0.073 (0.103)\tData 0.055 (0.083)\tLoss 0.1353 (0.6718)\tAcc 1.000 (0.738)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.399 (0.399)\tData 0.370 (0.370)\tLoss 0.5614 (0.5614)\tAcc 0.812 (0.812)\n",
      "Epoch: [48][2/5]\tTime 0.074 (0.236)\tData 0.050 (0.210)\tLoss 0.9499 (0.7557)\tAcc 0.562 (0.688)\n",
      "Epoch: [48][3/5]\tTime 0.076 (0.183)\tData 0.053 (0.158)\tLoss 0.5702 (0.6938)\tAcc 0.750 (0.708)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.156)\tData 0.054 (0.132)\tLoss 0.7181 (0.6999)\tAcc 0.688 (0.703)\n",
      "Epoch: [48][5/5]\tTime 0.078 (0.141)\tData 0.055 (0.116)\tLoss 0.6646 (0.6955)\tAcc 0.667 (0.699)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.375 (0.375)\tData 0.351 (0.351)\tLoss 0.2829 (0.2829)\tAcc 0.938 (0.938)\n",
      "Epoch: [48][2/9]\tTime 0.072 (0.223)\tData 0.050 (0.201)\tLoss 1.0717 (0.6773)\tAcc 0.562 (0.750)\n",
      "Epoch: [48][3/9]\tTime 0.075 (0.174)\tData 0.052 (0.151)\tLoss 0.5462 (0.6336)\tAcc 0.875 (0.792)\n",
      "Epoch: [48][4/9]\tTime 0.073 (0.149)\tData 0.050 (0.126)\tLoss 0.6490 (0.6374)\tAcc 0.688 (0.766)\n",
      "Epoch: [48][5/9]\tTime 0.072 (0.133)\tData 0.052 (0.111)\tLoss 0.9365 (0.6973)\tAcc 0.688 (0.750)\n",
      "Epoch: [48][6/9]\tTime 0.072 (0.123)\tData 0.054 (0.102)\tLoss 0.2376 (0.6206)\tAcc 1.000 (0.792)\n",
      "Epoch: [48][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.7277 (0.6359)\tAcc 0.688 (0.777)\n",
      "Epoch: [48][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 1.0728 (0.6905)\tAcc 0.438 (0.734)\n",
      "Epoch: [48][9/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.2112 (0.6832)\tAcc 1.000 (0.738)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.354 (0.354)\tData 0.326 (0.326)\tLoss 0.9395 (0.9395)\tAcc 0.688 (0.688)\n",
      "Epoch: [49][2/5]\tTime 0.074 (0.214)\tData 0.050 (0.188)\tLoss 0.8176 (0.8785)\tAcc 0.812 (0.750)\n",
      "Epoch: [49][3/5]\tTime 0.076 (0.168)\tData 0.054 (0.143)\tLoss 0.9338 (0.8969)\tAcc 0.562 (0.688)\n",
      "Epoch: [49][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.121)\tLoss 0.5852 (0.8190)\tAcc 0.812 (0.719)\n",
      "Epoch: [49][5/5]\tTime 0.078 (0.132)\tData 0.056 (0.108)\tLoss 0.4480 (0.7733)\tAcc 0.889 (0.740)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.390 (0.390)\tData 0.366 (0.366)\tLoss 0.2542 (0.2542)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.072 (0.231)\tData 0.050 (0.208)\tLoss 0.8699 (0.5620)\tAcc 0.500 (0.719)\n",
      "Epoch: [49][3/9]\tTime 0.073 (0.178)\tData 0.052 (0.156)\tLoss 0.4825 (0.5355)\tAcc 0.812 (0.750)\n",
      "Epoch: [49][4/9]\tTime 0.073 (0.152)\tData 0.052 (0.130)\tLoss 0.6725 (0.5698)\tAcc 0.688 (0.734)\n",
      "Epoch: [49][5/9]\tTime 0.075 (0.137)\tData 0.053 (0.115)\tLoss 0.8140 (0.6186)\tAcc 0.688 (0.725)\n",
      "Epoch: [49][6/9]\tTime 0.071 (0.126)\tData 0.052 (0.104)\tLoss 0.2273 (0.5534)\tAcc 1.000 (0.771)\n",
      "Epoch: [49][7/9]\tTime 0.073 (0.118)\tData 0.054 (0.097)\tLoss 0.6109 (0.5616)\tAcc 0.750 (0.768)\n",
      "Epoch: [49][8/9]\tTime 0.074 (0.113)\tData 0.055 (0.092)\tLoss 1.0319 (0.6204)\tAcc 0.500 (0.734)\n",
      "Epoch: [49][9/9]\tTime 0.073 (0.108)\tData 0.054 (0.088)\tLoss 0.2513 (0.6147)\tAcc 1.000 (0.738)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.409 (0.409)\tData 0.382 (0.382)\tLoss 0.5021 (0.5021)\tAcc 0.812 (0.812)\n",
      "Epoch: [50][2/5]\tTime 0.074 (0.242)\tData 0.051 (0.216)\tLoss 0.8566 (0.6794)\tAcc 0.625 (0.719)\n",
      "Epoch: [50][3/5]\tTime 0.078 (0.187)\tData 0.053 (0.162)\tLoss 0.6060 (0.6549)\tAcc 0.750 (0.729)\n",
      "Epoch: [50][4/5]\tTime 0.076 (0.159)\tData 0.053 (0.135)\tLoss 0.8581 (0.7057)\tAcc 0.625 (0.703)\n",
      "Epoch: [50][5/5]\tTime 0.082 (0.144)\tData 0.059 (0.119)\tLoss 1.1595 (0.7616)\tAcc 0.444 (0.671)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.330 (0.330)\tData 0.304 (0.304)\tLoss 0.2742 (0.2742)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/9]\tTime 0.071 (0.200)\tData 0.048 (0.176)\tLoss 1.0379 (0.6560)\tAcc 0.500 (0.719)\n",
      "Epoch: [50][3/9]\tTime 0.071 (0.157)\tData 0.051 (0.134)\tLoss 0.5581 (0.6234)\tAcc 0.750 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.074 (0.137)\tData 0.054 (0.114)\tLoss 0.5823 (0.6131)\tAcc 0.750 (0.734)\n",
      "Epoch: [50][5/9]\tTime 0.074 (0.124)\tData 0.055 (0.102)\tLoss 0.8289 (0.6563)\tAcc 0.750 (0.738)\n",
      "Epoch: [50][6/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.2306 (0.5853)\tAcc 1.000 (0.781)\n",
      "Epoch: [50][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.089)\tLoss 0.6904 (0.6003)\tAcc 0.812 (0.786)\n",
      "Epoch: [50][8/9]\tTime 0.074 (0.105)\tData 0.056 (0.084)\tLoss 1.0036 (0.6507)\tAcc 0.500 (0.750)\n",
      "Epoch: [50][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.081)\tLoss 0.2887 (0.6452)\tAcc 1.000 (0.754)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.394 (0.394)\tData 0.365 (0.365)\tLoss 1.0032 (1.0032)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][2/5]\tTime 0.073 (0.233)\tData 0.049 (0.207)\tLoss 0.4052 (0.7042)\tAcc 0.875 (0.781)\n",
      "Epoch: [51][3/5]\tTime 0.078 (0.182)\tData 0.054 (0.156)\tLoss 0.6369 (0.6818)\tAcc 0.812 (0.792)\n",
      "Epoch: [51][4/5]\tTime 0.075 (0.155)\tData 0.052 (0.130)\tLoss 0.8504 (0.7239)\tAcc 0.625 (0.750)\n",
      "Epoch: [51][5/5]\tTime 0.078 (0.140)\tData 0.055 (0.115)\tLoss 0.7158 (0.7229)\tAcc 0.667 (0.740)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.325 (0.325)\tData 0.300 (0.300)\tLoss 0.3124 (0.3124)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/9]\tTime 0.070 (0.197)\tData 0.049 (0.174)\tLoss 1.1274 (0.7199)\tAcc 0.438 (0.688)\n",
      "Epoch: [51][3/9]\tTime 0.073 (0.156)\tData 0.053 (0.134)\tLoss 0.6726 (0.7041)\tAcc 0.625 (0.667)\n",
      "Epoch: [51][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.114)\tLoss 0.7621 (0.7186)\tAcc 0.625 (0.656)\n",
      "Epoch: [51][5/9]\tTime 0.073 (0.123)\tData 0.054 (0.102)\tLoss 1.0442 (0.7837)\tAcc 0.562 (0.637)\n",
      "Epoch: [51][6/9]\tTime 0.072 (0.115)\tData 0.054 (0.094)\tLoss 0.2837 (0.7004)\tAcc 1.000 (0.698)\n",
      "Epoch: [51][7/9]\tTime 0.073 (0.109)\tData 0.055 (0.088)\tLoss 0.8131 (0.7165)\tAcc 0.625 (0.688)\n",
      "Epoch: [51][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.084)\tLoss 0.9487 (0.7455)\tAcc 0.562 (0.672)\n",
      "Epoch: [51][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.081)\tLoss 0.3681 (0.7397)\tAcc 1.000 (0.677)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.344 (0.344)\tData 0.315 (0.315)\tLoss 0.9712 (0.9712)\tAcc 0.562 (0.562)\n",
      "Epoch: [52][2/5]\tTime 0.073 (0.209)\tData 0.049 (0.182)\tLoss 0.5486 (0.7599)\tAcc 0.812 (0.688)\n",
      "Epoch: [52][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.139)\tLoss 0.5081 (0.6759)\tAcc 0.875 (0.750)\n",
      "Epoch: [52][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.118)\tLoss 1.0029 (0.7577)\tAcc 0.625 (0.719)\n",
      "Epoch: [52][5/5]\tTime 0.078 (0.130)\tData 0.056 (0.105)\tLoss 0.5201 (0.7284)\tAcc 0.778 (0.726)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.372 (0.372)\tData 0.348 (0.348)\tLoss 0.3128 (0.3128)\tAcc 0.938 (0.938)\n",
      "Epoch: [52][2/9]\tTime 0.072 (0.222)\tData 0.051 (0.199)\tLoss 0.9764 (0.6446)\tAcc 0.500 (0.719)\n",
      "Epoch: [52][3/9]\tTime 0.075 (0.173)\tData 0.052 (0.150)\tLoss 0.6307 (0.6400)\tAcc 0.812 (0.750)\n",
      "Epoch: [52][4/9]\tTime 0.072 (0.148)\tData 0.051 (0.125)\tLoss 0.6852 (0.6513)\tAcc 0.688 (0.734)\n",
      "Epoch: [52][5/9]\tTime 0.073 (0.133)\tData 0.053 (0.111)\tLoss 0.8185 (0.6847)\tAcc 0.688 (0.725)\n",
      "Epoch: [52][6/9]\tTime 0.073 (0.123)\tData 0.054 (0.102)\tLoss 0.2148 (0.6064)\tAcc 1.000 (0.771)\n",
      "Epoch: [52][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.6158 (0.6077)\tAcc 0.750 (0.768)\n",
      "Epoch: [52][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.090)\tLoss 1.0337 (0.6610)\tAcc 0.562 (0.742)\n",
      "Epoch: [52][9/9]\tTime 0.072 (0.106)\tData 0.054 (0.086)\tLoss 0.2945 (0.6553)\tAcc 1.000 (0.746)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.454 (0.454)\tData 0.426 (0.426)\tLoss 0.6927 (0.6927)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][2/5]\tTime 0.074 (0.264)\tData 0.050 (0.238)\tLoss 0.7140 (0.7033)\tAcc 0.688 (0.719)\n",
      "Epoch: [53][3/5]\tTime 0.076 (0.201)\tData 0.053 (0.176)\tLoss 0.7530 (0.7199)\tAcc 0.688 (0.708)\n",
      "Epoch: [53][4/5]\tTime 0.077 (0.170)\tData 0.054 (0.146)\tLoss 0.6416 (0.7003)\tAcc 0.875 (0.750)\n",
      "Epoch: [53][5/5]\tTime 0.078 (0.152)\tData 0.055 (0.128)\tLoss 0.6766 (0.6974)\tAcc 0.667 (0.740)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.292 (0.292)\tData 0.266 (0.266)\tLoss 0.2990 (0.2990)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/9]\tTime 0.070 (0.181)\tData 0.048 (0.157)\tLoss 0.9932 (0.6461)\tAcc 0.500 (0.719)\n",
      "Epoch: [53][3/9]\tTime 0.075 (0.145)\tData 0.052 (0.122)\tLoss 0.6274 (0.6399)\tAcc 0.688 (0.708)\n",
      "Epoch: [53][4/9]\tTime 0.071 (0.127)\tData 0.051 (0.104)\tLoss 0.5980 (0.6294)\tAcc 0.750 (0.719)\n",
      "Epoch: [53][5/9]\tTime 0.074 (0.116)\tData 0.054 (0.094)\tLoss 0.7441 (0.6523)\tAcc 0.750 (0.725)\n",
      "Epoch: [53][6/9]\tTime 0.072 (0.109)\tData 0.053 (0.087)\tLoss 0.2743 (0.5893)\tAcc 1.000 (0.771)\n",
      "Epoch: [53][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.6691 (0.6007)\tAcc 0.750 (0.768)\n",
      "Epoch: [53][8/9]\tTime 0.075 (0.100)\tData 0.056 (0.079)\tLoss 1.0667 (0.6590)\tAcc 0.562 (0.742)\n",
      "Epoch: [53][9/9]\tTime 0.073 (0.097)\tData 0.054 (0.076)\tLoss 0.2290 (0.6524)\tAcc 1.000 (0.746)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.333 (0.333)\tData 0.305 (0.305)\tLoss 1.0710 (1.0710)\tAcc 0.625 (0.625)\n",
      "Epoch: [54][2/5]\tTime 0.073 (0.203)\tData 0.049 (0.177)\tLoss 0.5771 (0.8241)\tAcc 0.812 (0.719)\n",
      "Epoch: [54][3/5]\tTime 0.077 (0.161)\tData 0.054 (0.136)\tLoss 0.5917 (0.7466)\tAcc 0.750 (0.729)\n",
      "Epoch: [54][4/5]\tTime 0.077 (0.140)\tData 0.054 (0.115)\tLoss 0.6146 (0.7136)\tAcc 0.875 (0.766)\n",
      "Epoch: [54][5/5]\tTime 0.078 (0.128)\tData 0.056 (0.103)\tLoss 0.8353 (0.7286)\tAcc 0.556 (0.740)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.352 (0.352)\tData 0.326 (0.326)\tLoss 0.3288 (0.3288)\tAcc 0.875 (0.875)\n",
      "Epoch: [54][2/9]\tTime 0.070 (0.211)\tData 0.049 (0.188)\tLoss 0.8734 (0.6011)\tAcc 0.562 (0.719)\n",
      "Epoch: [54][3/9]\tTime 0.073 (0.165)\tData 0.053 (0.143)\tLoss 0.6298 (0.6107)\tAcc 0.688 (0.708)\n",
      "Epoch: [54][4/9]\tTime 0.073 (0.142)\tData 0.053 (0.120)\tLoss 0.6453 (0.6193)\tAcc 0.688 (0.703)\n",
      "Epoch: [54][5/9]\tTime 0.073 (0.128)\tData 0.054 (0.107)\tLoss 0.8310 (0.6617)\tAcc 0.625 (0.688)\n",
      "Epoch: [54][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.2145 (0.5872)\tAcc 1.000 (0.740)\n",
      "Epoch: [54][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.092)\tLoss 0.6871 (0.6014)\tAcc 0.688 (0.732)\n",
      "Epoch: [54][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.087)\tLoss 0.9977 (0.6510)\tAcc 0.625 (0.719)\n",
      "Epoch: [54][9/9]\tTime 0.072 (0.104)\tData 0.054 (0.084)\tLoss 0.0971 (0.6424)\tAcc 1.000 (0.723)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.342 (0.342)\tData 0.315 (0.315)\tLoss 0.8760 (0.8760)\tAcc 0.562 (0.562)\n",
      "Epoch: [55][2/5]\tTime 0.075 (0.209)\tData 0.051 (0.183)\tLoss 0.4048 (0.6404)\tAcc 0.812 (0.688)\n",
      "Epoch: [55][3/5]\tTime 0.076 (0.165)\tData 0.053 (0.140)\tLoss 0.8243 (0.7017)\tAcc 0.750 (0.708)\n",
      "Epoch: [55][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.7464 (0.7129)\tAcc 0.750 (0.719)\n",
      "Epoch: [55][5/5]\tTime 0.078 (0.130)\tData 0.055 (0.106)\tLoss 0.9050 (0.7366)\tAcc 0.667 (0.712)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.307 (0.307)\tData 0.282 (0.282)\tLoss 0.2848 (0.2848)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/9]\tTime 0.070 (0.189)\tData 0.050 (0.166)\tLoss 0.9561 (0.6205)\tAcc 0.500 (0.719)\n",
      "Epoch: [55][3/9]\tTime 0.073 (0.150)\tData 0.053 (0.128)\tLoss 0.6450 (0.6287)\tAcc 0.812 (0.750)\n",
      "Epoch: [55][4/9]\tTime 0.072 (0.131)\tData 0.053 (0.109)\tLoss 0.6548 (0.6352)\tAcc 0.688 (0.734)\n",
      "Epoch: [55][5/9]\tTime 0.074 (0.120)\tData 0.055 (0.098)\tLoss 0.8997 (0.6881)\tAcc 0.625 (0.713)\n",
      "Epoch: [55][6/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.1786 (0.6032)\tAcc 1.000 (0.760)\n",
      "Epoch: [55][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.6894 (0.6155)\tAcc 0.750 (0.759)\n",
      "Epoch: [55][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 1.0127 (0.6651)\tAcc 0.625 (0.742)\n",
      "Epoch: [55][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.079)\tLoss 0.1497 (0.6572)\tAcc 1.000 (0.746)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.369 (0.369)\tData 0.341 (0.341)\tLoss 0.7493 (0.7493)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][2/5]\tTime 0.073 (0.221)\tData 0.049 (0.195)\tLoss 0.6605 (0.7049)\tAcc 0.812 (0.750)\n",
      "Epoch: [56][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.9890 (0.7996)\tAcc 0.562 (0.688)\n",
      "Epoch: [56][4/5]\tTime 0.077 (0.149)\tData 0.053 (0.124)\tLoss 0.7545 (0.7883)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][5/5]\tTime 0.078 (0.135)\tData 0.055 (0.110)\tLoss 0.8586 (0.7970)\tAcc 0.667 (0.685)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.378 (0.378)\tData 0.354 (0.354)\tLoss 0.3232 (0.3232)\tAcc 0.875 (0.875)\n",
      "Epoch: [56][2/9]\tTime 0.072 (0.225)\tData 0.050 (0.202)\tLoss 0.9794 (0.6513)\tAcc 0.500 (0.688)\n",
      "Epoch: [56][3/9]\tTime 0.073 (0.174)\tData 0.052 (0.152)\tLoss 0.5444 (0.6157)\tAcc 0.750 (0.708)\n",
      "Epoch: [56][4/9]\tTime 0.074 (0.149)\tData 0.053 (0.127)\tLoss 0.5144 (0.5904)\tAcc 0.750 (0.719)\n",
      "Epoch: [56][5/9]\tTime 0.073 (0.134)\tData 0.053 (0.112)\tLoss 0.8292 (0.6381)\tAcc 0.688 (0.713)\n",
      "Epoch: [56][6/9]\tTime 0.072 (0.123)\tData 0.053 (0.103)\tLoss 0.2185 (0.5682)\tAcc 1.000 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.074 (0.116)\tData 0.055 (0.096)\tLoss 0.8078 (0.6024)\tAcc 0.562 (0.732)\n",
      "Epoch: [56][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.091)\tLoss 1.1381 (0.6694)\tAcc 0.500 (0.703)\n",
      "Epoch: [56][9/9]\tTime 0.073 (0.107)\tData 0.055 (0.087)\tLoss 0.0910 (0.6605)\tAcc 1.000 (0.708)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.304 (0.304)\tData 0.275 (0.275)\tLoss 0.8406 (0.8406)\tAcc 0.688 (0.688)\n",
      "Epoch: [57][2/5]\tTime 0.073 (0.188)\tData 0.050 (0.162)\tLoss 0.5814 (0.7110)\tAcc 0.625 (0.656)\n",
      "Epoch: [57][3/5]\tTime 0.077 (0.151)\tData 0.053 (0.126)\tLoss 0.4923 (0.6381)\tAcc 0.875 (0.729)\n",
      "Epoch: [57][4/5]\tTime 0.076 (0.132)\tData 0.054 (0.108)\tLoss 0.8278 (0.6855)\tAcc 0.688 (0.719)\n",
      "Epoch: [57][5/5]\tTime 0.078 (0.121)\tData 0.055 (0.097)\tLoss 1.1923 (0.7480)\tAcc 0.556 (0.699)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.303 (0.303)\tData 0.279 (0.279)\tLoss 0.2495 (0.2495)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/9]\tTime 0.074 (0.188)\tData 0.050 (0.165)\tLoss 1.0121 (0.6308)\tAcc 0.625 (0.781)\n",
      "Epoch: [57][3/9]\tTime 0.071 (0.149)\tData 0.050 (0.126)\tLoss 0.6716 (0.6444)\tAcc 0.750 (0.771)\n",
      "Epoch: [57][4/9]\tTime 0.075 (0.131)\tData 0.052 (0.108)\tLoss 0.6540 (0.6468)\tAcc 0.688 (0.750)\n",
      "Epoch: [57][5/9]\tTime 0.073 (0.119)\tData 0.051 (0.097)\tLoss 0.7900 (0.6754)\tAcc 0.688 (0.738)\n",
      "Epoch: [57][6/9]\tTime 0.071 (0.111)\tData 0.052 (0.089)\tLoss 0.2666 (0.6073)\tAcc 1.000 (0.781)\n",
      "Epoch: [57][7/9]\tTime 0.073 (0.106)\tData 0.055 (0.084)\tLoss 0.6171 (0.6087)\tAcc 0.812 (0.786)\n",
      "Epoch: [57][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.081)\tLoss 1.2905 (0.6939)\tAcc 0.562 (0.758)\n",
      "Epoch: [57][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.078)\tLoss 0.1743 (0.6859)\tAcc 1.000 (0.762)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.419 (0.419)\tData 0.392 (0.392)\tLoss 0.5372 (0.5372)\tAcc 0.812 (0.812)\n",
      "Epoch: [58][2/5]\tTime 0.074 (0.247)\tData 0.051 (0.221)\tLoss 0.5241 (0.5306)\tAcc 0.812 (0.812)\n",
      "Epoch: [58][3/5]\tTime 0.076 (0.190)\tData 0.054 (0.165)\tLoss 1.0492 (0.7035)\tAcc 0.562 (0.729)\n",
      "Epoch: [58][4/5]\tTime 0.077 (0.162)\tData 0.054 (0.138)\tLoss 1.0218 (0.7831)\tAcc 0.438 (0.656)\n",
      "Epoch: [58][5/5]\tTime 0.078 (0.145)\tData 0.055 (0.121)\tLoss 0.6870 (0.7712)\tAcc 0.778 (0.671)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.371 (0.371)\tData 0.347 (0.347)\tLoss 0.3415 (0.3415)\tAcc 0.875 (0.875)\n",
      "Epoch: [58][2/9]\tTime 0.072 (0.221)\tData 0.050 (0.199)\tLoss 1.0955 (0.7185)\tAcc 0.438 (0.656)\n",
      "Epoch: [58][3/9]\tTime 0.073 (0.172)\tData 0.052 (0.150)\tLoss 0.6732 (0.7034)\tAcc 0.688 (0.667)\n",
      "Epoch: [58][4/9]\tTime 0.075 (0.147)\tData 0.053 (0.126)\tLoss 0.6306 (0.6852)\tAcc 0.750 (0.688)\n",
      "Epoch: [58][5/9]\tTime 0.072 (0.132)\tData 0.053 (0.111)\tLoss 1.0941 (0.7670)\tAcc 0.500 (0.650)\n",
      "Epoch: [58][6/9]\tTime 0.073 (0.122)\tData 0.054 (0.102)\tLoss 0.2550 (0.6817)\tAcc 1.000 (0.708)\n",
      "Epoch: [58][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.095)\tLoss 0.7637 (0.6934)\tAcc 0.625 (0.696)\n",
      "Epoch: [58][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.090)\tLoss 1.1268 (0.7476)\tAcc 0.562 (0.680)\n",
      "Epoch: [58][9/9]\tTime 0.072 (0.106)\tData 0.054 (0.086)\tLoss 0.0705 (0.7371)\tAcc 1.000 (0.685)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.324 (0.324)\tData 0.296 (0.296)\tLoss 0.7269 (0.7269)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][2/5]\tTime 0.073 (0.199)\tData 0.049 (0.172)\tLoss 0.4698 (0.5983)\tAcc 0.938 (0.812)\n",
      "Epoch: [59][3/5]\tTime 0.078 (0.158)\tData 0.053 (0.133)\tLoss 0.6802 (0.6256)\tAcc 0.625 (0.750)\n",
      "Epoch: [59][4/5]\tTime 0.075 (0.137)\tData 0.052 (0.113)\tLoss 0.6734 (0.6376)\tAcc 0.750 (0.750)\n",
      "Epoch: [59][5/5]\tTime 0.078 (0.126)\tData 0.056 (0.101)\tLoss 1.2731 (0.7159)\tAcc 0.444 (0.712)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.365 (0.365)\tData 0.342 (0.342)\tLoss 0.3072 (0.3072)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/9]\tTime 0.072 (0.218)\tData 0.051 (0.196)\tLoss 0.9769 (0.6420)\tAcc 0.438 (0.688)\n",
      "Epoch: [59][3/9]\tTime 0.074 (0.170)\tData 0.054 (0.149)\tLoss 0.6787 (0.6542)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][4/9]\tTime 0.073 (0.146)\tData 0.054 (0.125)\tLoss 0.6371 (0.6499)\tAcc 0.750 (0.703)\n",
      "Epoch: [59][5/9]\tTime 0.074 (0.131)\tData 0.055 (0.111)\tLoss 0.6449 (0.6489)\tAcc 0.812 (0.725)\n",
      "Epoch: [59][6/9]\tTime 0.072 (0.122)\tData 0.054 (0.101)\tLoss 0.2662 (0.5851)\tAcc 1.000 (0.771)\n",
      "Epoch: [59][7/9]\tTime 0.073 (0.115)\tData 0.055 (0.095)\tLoss 0.6726 (0.5976)\tAcc 0.625 (0.750)\n",
      "Epoch: [59][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.090)\tLoss 0.9508 (0.6418)\tAcc 0.688 (0.742)\n",
      "Epoch: [59][9/9]\tTime 0.072 (0.105)\tData 0.054 (0.086)\tLoss 0.1439 (0.6341)\tAcc 1.000 (0.746)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.336 (0.336)\tData 0.305 (0.305)\tLoss 0.7971 (0.7971)\tAcc 0.812 (0.812)\n",
      "Epoch: [60][2/5]\tTime 0.072 (0.204)\tData 0.047 (0.176)\tLoss 0.5283 (0.6627)\tAcc 0.938 (0.875)\n",
      "Epoch: [60][3/5]\tTime 0.075 (0.161)\tData 0.051 (0.134)\tLoss 0.6357 (0.6537)\tAcc 0.812 (0.854)\n",
      "Epoch: [60][4/5]\tTime 0.076 (0.140)\tData 0.053 (0.114)\tLoss 1.0192 (0.7451)\tAcc 0.625 (0.797)\n",
      "Epoch: [60][5/5]\tTime 0.077 (0.127)\tData 0.054 (0.102)\tLoss 0.6206 (0.7297)\tAcc 0.778 (0.795)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.337 (0.337)\tData 0.314 (0.314)\tLoss 0.2435 (0.2435)\tAcc 0.938 (0.938)\n",
      "Epoch: [60][2/9]\tTime 0.072 (0.205)\tData 0.051 (0.182)\tLoss 1.0817 (0.6626)\tAcc 0.438 (0.688)\n",
      "Epoch: [60][3/9]\tTime 0.073 (0.161)\tData 0.052 (0.139)\tLoss 0.5756 (0.6336)\tAcc 0.750 (0.708)\n",
      "Epoch: [60][4/9]\tTime 0.074 (0.139)\tData 0.053 (0.117)\tLoss 0.7188 (0.6549)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][5/9]\tTime 0.073 (0.126)\tData 0.054 (0.105)\tLoss 0.7556 (0.6750)\tAcc 0.750 (0.700)\n",
      "Epoch: [60][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.2917 (0.6112)\tAcc 1.000 (0.750)\n",
      "Epoch: [60][7/9]\tTime 0.073 (0.111)\tData 0.054 (0.090)\tLoss 0.8141 (0.6401)\tAcc 0.625 (0.732)\n",
      "Epoch: [60][8/9]\tTime 0.074 (0.106)\tData 0.055 (0.086)\tLoss 0.9682 (0.6812)\tAcc 0.688 (0.727)\n",
      "Epoch: [60][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.082)\tLoss 0.2193 (0.6740)\tAcc 1.000 (0.731)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.365 (0.365)\tData 0.338 (0.338)\tLoss 1.1989 (1.1989)\tAcc 0.500 (0.500)\n",
      "Epoch: [61][2/5]\tTime 0.075 (0.220)\tData 0.051 (0.194)\tLoss 0.6869 (0.9429)\tAcc 0.625 (0.562)\n",
      "Epoch: [61][3/5]\tTime 0.077 (0.172)\tData 0.053 (0.147)\tLoss 0.4084 (0.7647)\tAcc 1.000 (0.708)\n",
      "Epoch: [61][4/5]\tTime 0.077 (0.148)\tData 0.053 (0.124)\tLoss 0.8197 (0.7785)\tAcc 0.562 (0.672)\n",
      "Epoch: [61][5/5]\tTime 0.078 (0.134)\tData 0.055 (0.110)\tLoss 0.9510 (0.7997)\tAcc 0.667 (0.671)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.305 (0.305)\tData 0.277 (0.277)\tLoss 0.3251 (0.3251)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.068 (0.186)\tData 0.047 (0.162)\tLoss 1.0036 (0.6644)\tAcc 0.438 (0.688)\n",
      "Epoch: [61][3/9]\tTime 0.073 (0.149)\tData 0.053 (0.126)\tLoss 0.5993 (0.6427)\tAcc 0.875 (0.750)\n",
      "Epoch: [61][4/9]\tTime 0.076 (0.130)\tData 0.053 (0.108)\tLoss 0.7135 (0.6604)\tAcc 0.688 (0.734)\n",
      "Epoch: [61][5/9]\tTime 0.071 (0.118)\tData 0.052 (0.096)\tLoss 0.7918 (0.6867)\tAcc 0.688 (0.725)\n",
      "Epoch: [61][6/9]\tTime 0.073 (0.111)\tData 0.055 (0.089)\tLoss 0.3291 (0.6271)\tAcc 1.000 (0.771)\n",
      "Epoch: [61][7/9]\tTime 0.073 (0.105)\tData 0.055 (0.084)\tLoss 0.5508 (0.6162)\tAcc 0.750 (0.768)\n",
      "Epoch: [61][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.081)\tLoss 0.9731 (0.6608)\tAcc 0.625 (0.750)\n",
      "Epoch: [61][9/9]\tTime 0.072 (0.098)\tData 0.055 (0.078)\tLoss 0.1117 (0.6523)\tAcc 1.000 (0.754)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.443 (0.443)\tData 0.417 (0.417)\tLoss 0.6949 (0.6949)\tAcc 0.688 (0.688)\n",
      "Epoch: [62][2/5]\tTime 0.076 (0.259)\tData 0.051 (0.234)\tLoss 0.7322 (0.7135)\tAcc 0.750 (0.719)\n",
      "Epoch: [62][3/5]\tTime 0.075 (0.198)\tData 0.052 (0.173)\tLoss 0.6316 (0.6862)\tAcc 0.812 (0.750)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.168)\tData 0.054 (0.144)\tLoss 0.7065 (0.6913)\tAcc 0.625 (0.719)\n",
      "Epoch: [62][5/5]\tTime 0.078 (0.150)\tData 0.056 (0.126)\tLoss 0.8919 (0.7160)\tAcc 0.667 (0.712)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.338 (0.338)\tData 0.312 (0.312)\tLoss 0.3253 (0.3253)\tAcc 0.875 (0.875)\n",
      "Epoch: [62][2/9]\tTime 0.070 (0.204)\tData 0.049 (0.180)\tLoss 1.0066 (0.6659)\tAcc 0.500 (0.688)\n",
      "Epoch: [62][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.138)\tLoss 0.6120 (0.6480)\tAcc 0.750 (0.708)\n",
      "Epoch: [62][4/9]\tTime 0.073 (0.138)\tData 0.053 (0.116)\tLoss 0.6602 (0.6510)\tAcc 0.625 (0.688)\n",
      "Epoch: [62][5/9]\tTime 0.074 (0.126)\tData 0.054 (0.104)\tLoss 0.8975 (0.7003)\tAcc 0.625 (0.675)\n",
      "Epoch: [62][6/9]\tTime 0.072 (0.117)\tData 0.053 (0.095)\tLoss 0.2643 (0.6276)\tAcc 1.000 (0.729)\n",
      "Epoch: [62][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6204 (0.6266)\tAcc 0.750 (0.732)\n",
      "Epoch: [62][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 1.2054 (0.6990)\tAcc 0.500 (0.703)\n",
      "Epoch: [62][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.082)\tLoss 0.1569 (0.6906)\tAcc 1.000 (0.708)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.325 (0.325)\tData 0.296 (0.296)\tLoss 0.7655 (0.7655)\tAcc 0.688 (0.688)\n",
      "Epoch: [63][2/5]\tTime 0.073 (0.199)\tData 0.049 (0.172)\tLoss 0.6101 (0.6878)\tAcc 0.750 (0.719)\n",
      "Epoch: [63][3/5]\tTime 0.076 (0.158)\tData 0.053 (0.133)\tLoss 0.5858 (0.6538)\tAcc 0.812 (0.750)\n",
      "Epoch: [63][4/5]\tTime 0.077 (0.138)\tData 0.054 (0.113)\tLoss 0.7931 (0.6886)\tAcc 0.750 (0.750)\n",
      "Epoch: [63][5/5]\tTime 0.078 (0.126)\tData 0.055 (0.101)\tLoss 1.4372 (0.7809)\tAcc 0.333 (0.699)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.339 (0.339)\tData 0.315 (0.315)\tLoss 0.3290 (0.3290)\tAcc 0.875 (0.875)\n",
      "Epoch: [63][2/9]\tTime 0.073 (0.206)\tData 0.050 (0.182)\tLoss 0.9797 (0.6543)\tAcc 0.625 (0.750)\n",
      "Epoch: [63][3/9]\tTime 0.071 (0.161)\tData 0.050 (0.138)\tLoss 0.5364 (0.6150)\tAcc 0.812 (0.771)\n",
      "Epoch: [63][4/9]\tTime 0.075 (0.139)\tData 0.053 (0.117)\tLoss 0.6132 (0.6146)\tAcc 0.750 (0.766)\n",
      "Epoch: [63][5/9]\tTime 0.077 (0.127)\tData 0.058 (0.105)\tLoss 0.7672 (0.6451)\tAcc 0.625 (0.738)\n",
      "Epoch: [63][6/9]\tTime 0.073 (0.118)\tData 0.054 (0.096)\tLoss 0.2187 (0.5740)\tAcc 1.000 (0.781)\n",
      "Epoch: [63][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.090)\tLoss 0.9510 (0.6279)\tAcc 0.500 (0.741)\n",
      "Epoch: [63][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 1.1224 (0.6897)\tAcc 0.500 (0.711)\n",
      "Epoch: [63][9/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.1923 (0.6820)\tAcc 1.000 (0.715)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.312 (0.312)\tData 0.283 (0.283)\tLoss 0.7783 (0.7783)\tAcc 0.688 (0.688)\n",
      "Epoch: [64][2/5]\tTime 0.074 (0.193)\tData 0.050 (0.166)\tLoss 0.6265 (0.7024)\tAcc 0.750 (0.719)\n",
      "Epoch: [64][3/5]\tTime 0.078 (0.155)\tData 0.053 (0.128)\tLoss 0.7687 (0.7245)\tAcc 0.688 (0.708)\n",
      "Epoch: [64][4/5]\tTime 0.075 (0.135)\tData 0.052 (0.109)\tLoss 0.9099 (0.7709)\tAcc 0.625 (0.688)\n",
      "Epoch: [64][5/5]\tTime 0.080 (0.124)\tData 0.057 (0.099)\tLoss 0.4632 (0.7330)\tAcc 0.889 (0.712)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.333 (0.333)\tData 0.308 (0.308)\tLoss 0.3254 (0.3254)\tAcc 0.875 (0.875)\n",
      "Epoch: [64][2/9]\tTime 0.070 (0.201)\tData 0.049 (0.178)\tLoss 0.9310 (0.6282)\tAcc 0.438 (0.656)\n",
      "Epoch: [64][3/9]\tTime 0.073 (0.159)\tData 0.053 (0.136)\tLoss 0.6747 (0.6437)\tAcc 0.750 (0.688)\n",
      "Epoch: [64][4/9]\tTime 0.073 (0.137)\tData 0.053 (0.116)\tLoss 0.7139 (0.6613)\tAcc 0.625 (0.672)\n",
      "Epoch: [64][5/9]\tTime 0.074 (0.125)\tData 0.055 (0.103)\tLoss 0.7939 (0.6878)\tAcc 0.625 (0.663)\n",
      "Epoch: [64][6/9]\tTime 0.072 (0.116)\tData 0.054 (0.095)\tLoss 0.2210 (0.6100)\tAcc 1.000 (0.719)\n",
      "Epoch: [64][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.7508 (0.6301)\tAcc 0.688 (0.714)\n",
      "Epoch: [64][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.085)\tLoss 1.2469 (0.7072)\tAcc 0.438 (0.680)\n",
      "Epoch: [64][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.082)\tLoss 0.2143 (0.6996)\tAcc 1.000 (0.685)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.336 (0.336)\tData 0.307 (0.307)\tLoss 0.6795 (0.6795)\tAcc 0.750 (0.750)\n",
      "Epoch: [65][2/5]\tTime 0.073 (0.205)\tData 0.049 (0.178)\tLoss 0.5997 (0.6396)\tAcc 0.688 (0.719)\n",
      "Epoch: [65][3/5]\tTime 0.076 (0.162)\tData 0.053 (0.137)\tLoss 0.7246 (0.6679)\tAcc 0.750 (0.729)\n",
      "Epoch: [65][4/5]\tTime 0.076 (0.140)\tData 0.054 (0.116)\tLoss 0.8514 (0.7138)\tAcc 0.688 (0.719)\n",
      "Epoch: [65][5/5]\tTime 0.078 (0.128)\tData 0.056 (0.104)\tLoss 0.8412 (0.7295)\tAcc 0.556 (0.699)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.303 (0.303)\tData 0.276 (0.276)\tLoss 0.3077 (0.3077)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][2/9]\tTime 0.076 (0.190)\tData 0.055 (0.165)\tLoss 0.9057 (0.6067)\tAcc 0.500 (0.688)\n",
      "Epoch: [65][3/9]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 0.8177 (0.6771)\tAcc 0.750 (0.708)\n",
      "Epoch: [65][4/9]\tTime 0.073 (0.132)\tData 0.053 (0.109)\tLoss 0.6846 (0.6789)\tAcc 0.625 (0.688)\n",
      "Epoch: [65][5/9]\tTime 0.075 (0.120)\tData 0.054 (0.098)\tLoss 0.7873 (0.7006)\tAcc 0.625 (0.675)\n",
      "Epoch: [65][6/9]\tTime 0.071 (0.112)\tData 0.052 (0.090)\tLoss 0.2440 (0.6245)\tAcc 1.000 (0.729)\n",
      "Epoch: [65][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.5822 (0.6185)\tAcc 0.750 (0.732)\n",
      "Epoch: [65][8/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 1.0538 (0.6729)\tAcc 0.500 (0.703)\n",
      "Epoch: [65][9/9]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.1758 (0.6652)\tAcc 1.000 (0.708)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.372 (0.372)\tData 0.344 (0.344)\tLoss 0.8459 (0.8459)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][2/5]\tTime 0.074 (0.223)\tData 0.050 (0.197)\tLoss 1.0505 (0.9482)\tAcc 0.500 (0.625)\n",
      "Epoch: [66][3/5]\tTime 0.077 (0.174)\tData 0.054 (0.149)\tLoss 0.5478 (0.8147)\tAcc 0.812 (0.688)\n",
      "Epoch: [66][4/5]\tTime 0.076 (0.150)\tData 0.054 (0.125)\tLoss 0.7665 (0.8027)\tAcc 0.688 (0.688)\n",
      "Epoch: [66][5/5]\tTime 0.078 (0.135)\tData 0.056 (0.111)\tLoss 0.3601 (0.7481)\tAcc 0.889 (0.712)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.278 (0.278)\tData 0.254 (0.254)\tLoss 0.3363 (0.3363)\tAcc 0.938 (0.938)\n",
      "Epoch: [66][2/9]\tTime 0.074 (0.176)\tData 0.051 (0.152)\tLoss 1.0188 (0.6775)\tAcc 0.500 (0.719)\n",
      "Epoch: [66][3/9]\tTime 0.071 (0.141)\tData 0.050 (0.118)\tLoss 0.6128 (0.6560)\tAcc 0.750 (0.729)\n",
      "Epoch: [66][4/9]\tTime 0.073 (0.124)\tData 0.053 (0.102)\tLoss 0.6461 (0.6535)\tAcc 0.625 (0.703)\n",
      "Epoch: [66][5/9]\tTime 0.076 (0.114)\tData 0.054 (0.092)\tLoss 0.8703 (0.6969)\tAcc 0.562 (0.675)\n",
      "Epoch: [66][6/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.2536 (0.6230)\tAcc 1.000 (0.729)\n",
      "Epoch: [66][7/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.5809 (0.6170)\tAcc 0.812 (0.741)\n",
      "Epoch: [66][8/9]\tTime 0.074 (0.099)\tData 0.056 (0.078)\tLoss 1.0915 (0.6763)\tAcc 0.562 (0.719)\n",
      "Epoch: [66][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.075)\tLoss 0.2152 (0.6692)\tAcc 1.000 (0.723)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.342 (0.342)\tData 0.314 (0.314)\tLoss 0.4340 (0.4340)\tAcc 0.875 (0.875)\n",
      "Epoch: [67][2/5]\tTime 0.073 (0.208)\tData 0.049 (0.181)\tLoss 0.6403 (0.5372)\tAcc 0.750 (0.812)\n",
      "Epoch: [67][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.139)\tLoss 0.7159 (0.5967)\tAcc 0.625 (0.750)\n",
      "Epoch: [67][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.117)\tLoss 0.8244 (0.6537)\tAcc 0.625 (0.719)\n",
      "Epoch: [67][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.105)\tLoss 0.7226 (0.6622)\tAcc 0.778 (0.726)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.357 (0.357)\tData 0.333 (0.333)\tLoss 0.3504 (0.3504)\tAcc 0.875 (0.875)\n",
      "Epoch: [67][2/9]\tTime 0.072 (0.215)\tData 0.051 (0.192)\tLoss 1.1119 (0.7312)\tAcc 0.438 (0.656)\n",
      "Epoch: [67][3/9]\tTime 0.073 (0.167)\tData 0.053 (0.146)\tLoss 0.5153 (0.6592)\tAcc 0.875 (0.729)\n",
      "Epoch: [67][4/9]\tTime 0.073 (0.144)\tData 0.053 (0.123)\tLoss 0.7205 (0.6745)\tAcc 0.625 (0.703)\n",
      "Epoch: [67][5/9]\tTime 0.074 (0.130)\tData 0.055 (0.109)\tLoss 0.8524 (0.7101)\tAcc 0.688 (0.700)\n",
      "Epoch: [67][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.100)\tLoss 0.2119 (0.6271)\tAcc 1.000 (0.750)\n",
      "Epoch: [67][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.093)\tLoss 0.6996 (0.6374)\tAcc 0.688 (0.741)\n",
      "Epoch: [67][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.089)\tLoss 1.0970 (0.6949)\tAcc 0.562 (0.719)\n",
      "Epoch: [67][9/9]\tTime 0.073 (0.105)\tData 0.055 (0.085)\tLoss 0.0945 (0.6856)\tAcc 1.000 (0.723)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.329 (0.329)\tData 0.301 (0.301)\tLoss 0.4492 (0.4492)\tAcc 0.812 (0.812)\n",
      "Epoch: [68][2/5]\tTime 0.074 (0.201)\tData 0.050 (0.176)\tLoss 0.9505 (0.6999)\tAcc 0.625 (0.719)\n",
      "Epoch: [68][3/5]\tTime 0.077 (0.160)\tData 0.054 (0.135)\tLoss 0.9383 (0.7794)\tAcc 0.625 (0.688)\n",
      "Epoch: [68][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.115)\tLoss 0.7540 (0.7730)\tAcc 0.750 (0.703)\n",
      "Epoch: [68][5/5]\tTime 0.078 (0.127)\tData 0.055 (0.103)\tLoss 0.6630 (0.7595)\tAcc 0.778 (0.712)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.327 (0.327)\tData 0.302 (0.302)\tLoss 0.3220 (0.3220)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.070 (0.199)\tData 0.049 (0.175)\tLoss 0.9595 (0.6408)\tAcc 0.438 (0.688)\n",
      "Epoch: [68][3/9]\tTime 0.073 (0.157)\tData 0.052 (0.134)\tLoss 0.5168 (0.5994)\tAcc 0.875 (0.750)\n",
      "Epoch: [68][4/9]\tTime 0.074 (0.136)\tData 0.052 (0.114)\tLoss 0.6650 (0.6158)\tAcc 0.750 (0.750)\n",
      "Epoch: [68][5/9]\tTime 0.073 (0.124)\tData 0.053 (0.102)\tLoss 0.7264 (0.6379)\tAcc 0.750 (0.750)\n",
      "Epoch: [68][6/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.2580 (0.5746)\tAcc 1.000 (0.792)\n",
      "Epoch: [68][7/9]\tTime 0.072 (0.109)\tData 0.054 (0.088)\tLoss 0.7411 (0.5984)\tAcc 0.625 (0.768)\n",
      "Epoch: [68][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.084)\tLoss 1.1115 (0.6625)\tAcc 0.562 (0.742)\n",
      "Epoch: [68][9/9]\tTime 0.072 (0.101)\tData 0.054 (0.081)\tLoss 0.1993 (0.6554)\tAcc 1.000 (0.746)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.308 (0.308)\tData 0.280 (0.280)\tLoss 0.8248 (0.8248)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][2/5]\tTime 0.075 (0.192)\tData 0.050 (0.165)\tLoss 0.9688 (0.8968)\tAcc 0.625 (0.656)\n",
      "Epoch: [69][3/5]\tTime 0.075 (0.153)\tData 0.051 (0.127)\tLoss 0.5145 (0.7694)\tAcc 0.750 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.076 (0.134)\tData 0.053 (0.108)\tLoss 0.5979 (0.7265)\tAcc 0.812 (0.719)\n",
      "Epoch: [69][5/5]\tTime 0.078 (0.123)\tData 0.055 (0.098)\tLoss 0.6403 (0.7159)\tAcc 0.667 (0.712)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.353 (0.353)\tData 0.330 (0.330)\tLoss 0.2764 (0.2764)\tAcc 0.938 (0.938)\n",
      "Epoch: [69][2/9]\tTime 0.072 (0.213)\tData 0.051 (0.191)\tLoss 1.0188 (0.6476)\tAcc 0.438 (0.688)\n",
      "Epoch: [69][3/9]\tTime 0.074 (0.166)\tData 0.053 (0.145)\tLoss 0.5528 (0.6160)\tAcc 0.812 (0.729)\n",
      "Epoch: [69][4/9]\tTime 0.072 (0.143)\tData 0.052 (0.122)\tLoss 0.5674 (0.6039)\tAcc 0.688 (0.719)\n",
      "Epoch: [69][5/9]\tTime 0.074 (0.129)\tData 0.054 (0.108)\tLoss 0.9446 (0.6720)\tAcc 0.562 (0.688)\n",
      "Epoch: [69][6/9]\tTime 0.073 (0.120)\tData 0.053 (0.099)\tLoss 0.2331 (0.5989)\tAcc 1.000 (0.740)\n",
      "Epoch: [69][7/9]\tTime 0.072 (0.113)\tData 0.054 (0.093)\tLoss 0.8068 (0.6286)\tAcc 0.500 (0.705)\n",
      "Epoch: [69][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.088)\tLoss 1.0216 (0.6777)\tAcc 0.500 (0.680)\n",
      "Epoch: [69][9/9]\tTime 0.072 (0.104)\tData 0.054 (0.084)\tLoss 0.2724 (0.6715)\tAcc 1.000 (0.685)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.364 (0.364)\tData 0.337 (0.337)\tLoss 0.9917 (0.9917)\tAcc 0.625 (0.625)\n",
      "Epoch: [70][2/5]\tTime 0.075 (0.219)\tData 0.051 (0.194)\tLoss 0.5555 (0.7736)\tAcc 0.812 (0.719)\n",
      "Epoch: [70][3/5]\tTime 0.077 (0.172)\tData 0.055 (0.147)\tLoss 0.8654 (0.8042)\tAcc 0.688 (0.708)\n",
      "Epoch: [70][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.124)\tLoss 0.5244 (0.7343)\tAcc 0.812 (0.734)\n",
      "Epoch: [70][5/5]\tTime 0.078 (0.134)\tData 0.055 (0.110)\tLoss 1.0478 (0.7729)\tAcc 0.667 (0.726)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.370 (0.370)\tData 0.347 (0.347)\tLoss 0.2996 (0.2996)\tAcc 0.875 (0.875)\n",
      "Epoch: [70][2/9]\tTime 0.072 (0.221)\tData 0.051 (0.199)\tLoss 1.0214 (0.6605)\tAcc 0.500 (0.688)\n",
      "Epoch: [70][3/9]\tTime 0.074 (0.172)\tData 0.052 (0.150)\tLoss 0.5563 (0.6258)\tAcc 0.812 (0.729)\n",
      "Epoch: [70][4/9]\tTime 0.072 (0.147)\tData 0.051 (0.125)\tLoss 0.6764 (0.6384)\tAcc 0.625 (0.703)\n",
      "Epoch: [70][5/9]\tTime 0.073 (0.132)\tData 0.054 (0.111)\tLoss 1.0732 (0.7254)\tAcc 0.750 (0.713)\n",
      "Epoch: [70][6/9]\tTime 0.073 (0.122)\tData 0.053 (0.101)\tLoss 0.2499 (0.6461)\tAcc 1.000 (0.760)\n",
      "Epoch: [70][7/9]\tTime 0.072 (0.115)\tData 0.054 (0.095)\tLoss 0.7849 (0.6659)\tAcc 0.562 (0.732)\n",
      "Epoch: [70][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.090)\tLoss 1.1406 (0.7253)\tAcc 0.500 (0.703)\n",
      "Epoch: [70][9/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.2559 (0.7181)\tAcc 1.000 (0.708)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.312 (0.312)\tData 0.283 (0.283)\tLoss 0.8276 (0.8276)\tAcc 0.688 (0.688)\n",
      "Epoch: [71][2/5]\tTime 0.075 (0.194)\tData 0.050 (0.167)\tLoss 0.6726 (0.7501)\tAcc 0.688 (0.688)\n",
      "Epoch: [71][3/5]\tTime 0.075 (0.154)\tData 0.052 (0.128)\tLoss 0.8402 (0.7801)\tAcc 0.625 (0.667)\n",
      "Epoch: [71][4/5]\tTime 0.076 (0.135)\tData 0.054 (0.110)\tLoss 0.5770 (0.7293)\tAcc 0.875 (0.719)\n",
      "Epoch: [71][5/5]\tTime 0.084 (0.124)\tData 0.062 (0.100)\tLoss 0.4733 (0.6978)\tAcc 0.778 (0.726)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.260 (0.260)\tData 0.236 (0.236)\tLoss 0.3003 (0.3003)\tAcc 0.875 (0.875)\n",
      "Epoch: [71][2/9]\tTime 0.073 (0.166)\tData 0.052 (0.144)\tLoss 0.9642 (0.6322)\tAcc 0.438 (0.656)\n",
      "Epoch: [71][3/9]\tTime 0.074 (0.136)\tData 0.053 (0.114)\tLoss 0.5546 (0.6064)\tAcc 0.812 (0.708)\n",
      "Epoch: [71][4/9]\tTime 0.074 (0.120)\tData 0.053 (0.099)\tLoss 0.6369 (0.6140)\tAcc 0.688 (0.703)\n",
      "Epoch: [71][5/9]\tTime 0.073 (0.111)\tData 0.053 (0.089)\tLoss 0.8147 (0.6541)\tAcc 0.750 (0.713)\n",
      "Epoch: [71][6/9]\tTime 0.073 (0.104)\tData 0.054 (0.084)\tLoss 0.2602 (0.5885)\tAcc 1.000 (0.760)\n",
      "Epoch: [71][7/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.6515 (0.5975)\tAcc 0.812 (0.768)\n",
      "Epoch: [71][8/9]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 1.0660 (0.6560)\tAcc 0.438 (0.727)\n",
      "Epoch: [71][9/9]\tTime 0.073 (0.094)\tData 0.055 (0.074)\tLoss 0.3422 (0.6512)\tAcc 1.000 (0.731)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.370 (0.370)\tData 0.342 (0.342)\tLoss 0.4106 (0.4106)\tAcc 0.812 (0.812)\n",
      "Epoch: [72][2/5]\tTime 0.074 (0.222)\tData 0.050 (0.196)\tLoss 0.7641 (0.5873)\tAcc 0.688 (0.750)\n",
      "Epoch: [72][3/5]\tTime 0.077 (0.174)\tData 0.053 (0.149)\tLoss 0.8783 (0.6843)\tAcc 0.562 (0.688)\n",
      "Epoch: [72][4/5]\tTime 0.076 (0.149)\tData 0.053 (0.125)\tLoss 0.8059 (0.7147)\tAcc 0.750 (0.703)\n",
      "Epoch: [72][5/5]\tTime 0.077 (0.135)\tData 0.055 (0.111)\tLoss 0.8791 (0.7350)\tAcc 0.667 (0.699)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.341 (0.341)\tData 0.315 (0.315)\tLoss 0.2590 (0.2590)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.069 (0.205)\tData 0.048 (0.181)\tLoss 1.0607 (0.6598)\tAcc 0.500 (0.719)\n",
      "Epoch: [72][3/9]\tTime 0.073 (0.161)\tData 0.052 (0.138)\tLoss 0.4828 (0.6008)\tAcc 0.812 (0.750)\n",
      "Epoch: [72][4/9]\tTime 0.074 (0.140)\tData 0.053 (0.117)\tLoss 0.6219 (0.6061)\tAcc 0.688 (0.734)\n",
      "Epoch: [72][5/9]\tTime 0.072 (0.126)\tData 0.052 (0.104)\tLoss 0.8864 (0.6622)\tAcc 0.625 (0.713)\n",
      "Epoch: [72][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.1818 (0.5821)\tAcc 1.000 (0.760)\n",
      "Epoch: [72][7/9]\tTime 0.073 (0.111)\tData 0.054 (0.090)\tLoss 0.5991 (0.5845)\tAcc 0.750 (0.759)\n",
      "Epoch: [72][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.9884 (0.6350)\tAcc 0.625 (0.742)\n",
      "Epoch: [72][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.082)\tLoss 0.1160 (0.6270)\tAcc 1.000 (0.746)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.328 (0.328)\tData 0.297 (0.297)\tLoss 1.0486 (1.0486)\tAcc 0.562 (0.562)\n",
      "Epoch: [73][2/5]\tTime 0.073 (0.200)\tData 0.047 (0.172)\tLoss 1.1004 (1.0745)\tAcc 0.500 (0.531)\n",
      "Epoch: [73][3/5]\tTime 0.076 (0.159)\tData 0.052 (0.132)\tLoss 0.6656 (0.9382)\tAcc 0.812 (0.625)\n",
      "Epoch: [73][4/5]\tTime 0.076 (0.138)\tData 0.053 (0.112)\tLoss 0.4233 (0.8095)\tAcc 0.875 (0.688)\n",
      "Epoch: [73][5/5]\tTime 0.078 (0.126)\tData 0.055 (0.101)\tLoss 0.9889 (0.8316)\tAcc 0.444 (0.658)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.293 (0.293)\tData 0.268 (0.268)\tLoss 0.2589 (0.2589)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.071 (0.182)\tData 0.050 (0.159)\tLoss 0.9651 (0.6120)\tAcc 0.500 (0.719)\n",
      "Epoch: [73][3/9]\tTime 0.074 (0.146)\tData 0.052 (0.123)\tLoss 0.5550 (0.5930)\tAcc 0.875 (0.771)\n",
      "Epoch: [73][4/9]\tTime 0.074 (0.128)\tData 0.053 (0.106)\tLoss 0.6736 (0.6132)\tAcc 0.688 (0.750)\n",
      "Epoch: [73][5/9]\tTime 0.076 (0.117)\tData 0.055 (0.096)\tLoss 0.8155 (0.6536)\tAcc 0.688 (0.738)\n",
      "Epoch: [73][6/9]\tTime 0.072 (0.110)\tData 0.053 (0.088)\tLoss 0.2672 (0.5892)\tAcc 0.938 (0.771)\n",
      "Epoch: [73][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.8151 (0.6215)\tAcc 0.625 (0.750)\n",
      "Epoch: [73][8/9]\tTime 0.074 (0.101)\tData 0.055 (0.080)\tLoss 0.9425 (0.6616)\tAcc 0.438 (0.711)\n",
      "Epoch: [73][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.1180 (0.6533)\tAcc 1.000 (0.715)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.360 (0.360)\tData 0.326 (0.326)\tLoss 1.0655 (1.0655)\tAcc 0.625 (0.625)\n",
      "Epoch: [74][2/5]\tTime 0.068 (0.214)\tData 0.044 (0.185)\tLoss 0.8328 (0.9491)\tAcc 0.625 (0.625)\n",
      "Epoch: [74][3/5]\tTime 0.077 (0.168)\tData 0.053 (0.141)\tLoss 0.8238 (0.9073)\tAcc 0.750 (0.667)\n",
      "Epoch: [74][4/5]\tTime 0.076 (0.145)\tData 0.053 (0.119)\tLoss 0.4644 (0.7966)\tAcc 0.875 (0.719)\n",
      "Epoch: [74][5/5]\tTime 0.078 (0.132)\tData 0.055 (0.106)\tLoss 0.7120 (0.7862)\tAcc 0.667 (0.712)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.358 (0.358)\tData 0.335 (0.335)\tLoss 0.3066 (0.3066)\tAcc 0.875 (0.875)\n",
      "Epoch: [74][2/9]\tTime 0.072 (0.215)\tData 0.051 (0.193)\tLoss 0.9853 (0.6460)\tAcc 0.438 (0.656)\n",
      "Epoch: [74][3/9]\tTime 0.073 (0.168)\tData 0.052 (0.146)\tLoss 0.5089 (0.6003)\tAcc 0.875 (0.729)\n",
      "Epoch: [74][4/9]\tTime 0.071 (0.144)\tData 0.052 (0.122)\tLoss 0.5271 (0.5820)\tAcc 0.750 (0.734)\n",
      "Epoch: [74][5/9]\tTime 0.074 (0.130)\tData 0.055 (0.109)\tLoss 0.8872 (0.6430)\tAcc 0.688 (0.725)\n",
      "Epoch: [74][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.100)\tLoss 0.2228 (0.5730)\tAcc 1.000 (0.771)\n",
      "Epoch: [74][7/9]\tTime 0.073 (0.114)\tData 0.054 (0.093)\tLoss 0.6853 (0.5890)\tAcc 0.688 (0.759)\n",
      "Epoch: [74][8/9]\tTime 0.075 (0.109)\tData 0.056 (0.089)\tLoss 1.0947 (0.6522)\tAcc 0.500 (0.727)\n",
      "Epoch: [74][9/9]\tTime 0.072 (0.105)\tData 0.054 (0.085)\tLoss 0.1504 (0.6445)\tAcc 1.000 (0.731)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.349 (0.349)\tData 0.322 (0.322)\tLoss 0.5569 (0.5569)\tAcc 0.875 (0.875)\n",
      "Epoch: [75][2/5]\tTime 0.076 (0.212)\tData 0.051 (0.187)\tLoss 0.7098 (0.6333)\tAcc 0.625 (0.750)\n",
      "Epoch: [75][3/5]\tTime 0.075 (0.167)\tData 0.052 (0.142)\tLoss 0.5514 (0.6060)\tAcc 0.750 (0.750)\n",
      "Epoch: [75][4/5]\tTime 0.077 (0.144)\tData 0.054 (0.120)\tLoss 0.7500 (0.6420)\tAcc 0.750 (0.750)\n",
      "Epoch: [75][5/5]\tTime 0.078 (0.131)\tData 0.055 (0.107)\tLoss 0.6294 (0.6405)\tAcc 0.667 (0.740)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.327 (0.327)\tData 0.304 (0.304)\tLoss 0.3291 (0.3291)\tAcc 0.938 (0.938)\n",
      "Epoch: [75][2/9]\tTime 0.072 (0.200)\tData 0.051 (0.177)\tLoss 0.9611 (0.6451)\tAcc 0.438 (0.688)\n",
      "Epoch: [75][3/9]\tTime 0.074 (0.158)\tData 0.053 (0.136)\tLoss 0.6581 (0.6494)\tAcc 0.750 (0.708)\n",
      "Epoch: [75][4/9]\tTime 0.072 (0.136)\tData 0.053 (0.115)\tLoss 0.5202 (0.6171)\tAcc 0.688 (0.703)\n",
      "Epoch: [75][5/9]\tTime 0.076 (0.124)\tData 0.056 (0.103)\tLoss 0.8714 (0.6680)\tAcc 0.688 (0.700)\n",
      "Epoch: [75][6/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.2284 (0.5947)\tAcc 1.000 (0.750)\n",
      "Epoch: [75][7/9]\tTime 0.072 (0.110)\tData 0.054 (0.089)\tLoss 0.5914 (0.5943)\tAcc 0.750 (0.750)\n",
      "Epoch: [75][8/9]\tTime 0.074 (0.105)\tData 0.056 (0.085)\tLoss 1.1235 (0.6604)\tAcc 0.438 (0.711)\n",
      "Epoch: [75][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.082)\tLoss 0.2118 (0.6535)\tAcc 1.000 (0.715)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.309 (0.309)\tData 0.279 (0.279)\tLoss 0.8096 (0.8096)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][2/5]\tTime 0.072 (0.191)\tData 0.049 (0.164)\tLoss 0.5105 (0.6600)\tAcc 0.812 (0.750)\n",
      "Epoch: [76][3/5]\tTime 0.076 (0.153)\tData 0.053 (0.127)\tLoss 0.9160 (0.7454)\tAcc 0.625 (0.708)\n",
      "Epoch: [76][4/5]\tTime 0.077 (0.134)\tData 0.054 (0.109)\tLoss 0.7876 (0.7559)\tAcc 0.688 (0.703)\n",
      "Epoch: [76][5/5]\tTime 0.078 (0.122)\tData 0.055 (0.098)\tLoss 0.6176 (0.7389)\tAcc 0.667 (0.699)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.340 (0.340)\tData 0.316 (0.316)\tLoss 0.2951 (0.2951)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/9]\tTime 0.073 (0.206)\tData 0.050 (0.183)\tLoss 0.9994 (0.6473)\tAcc 0.500 (0.719)\n",
      "Epoch: [76][3/9]\tTime 0.071 (0.161)\tData 0.051 (0.139)\tLoss 0.6616 (0.6521)\tAcc 0.750 (0.729)\n",
      "Epoch: [76][4/9]\tTime 0.074 (0.139)\tData 0.053 (0.118)\tLoss 0.6348 (0.6478)\tAcc 0.625 (0.703)\n",
      "Epoch: [76][5/9]\tTime 0.074 (0.126)\tData 0.055 (0.105)\tLoss 0.9182 (0.7018)\tAcc 0.750 (0.713)\n",
      "Epoch: [76][6/9]\tTime 0.073 (0.118)\tData 0.055 (0.097)\tLoss 0.2238 (0.6222)\tAcc 1.000 (0.760)\n",
      "Epoch: [76][7/9]\tTime 0.073 (0.111)\tData 0.055 (0.091)\tLoss 0.5536 (0.6124)\tAcc 0.812 (0.768)\n",
      "Epoch: [76][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 1.0355 (0.6653)\tAcc 0.500 (0.734)\n",
      "Epoch: [76][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.083)\tLoss 0.2135 (0.6583)\tAcc 1.000 (0.738)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.489 (0.489)\tData 0.462 (0.462)\tLoss 0.5885 (0.5885)\tAcc 0.750 (0.750)\n",
      "Epoch: [77][2/5]\tTime 0.076 (0.282)\tData 0.052 (0.257)\tLoss 0.6831 (0.6358)\tAcc 0.688 (0.719)\n",
      "Epoch: [77][3/5]\tTime 0.077 (0.214)\tData 0.053 (0.189)\tLoss 0.7755 (0.6824)\tAcc 0.625 (0.688)\n",
      "Epoch: [77][4/5]\tTime 0.076 (0.179)\tData 0.053 (0.155)\tLoss 0.6319 (0.6698)\tAcc 0.750 (0.703)\n",
      "Epoch: [77][5/5]\tTime 0.078 (0.159)\tData 0.055 (0.135)\tLoss 0.8213 (0.6884)\tAcc 0.667 (0.699)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.350 (0.350)\tData 0.323 (0.323)\tLoss 0.3187 (0.3187)\tAcc 0.938 (0.938)\n",
      "Epoch: [77][2/9]\tTime 0.070 (0.210)\tData 0.048 (0.186)\tLoss 0.8965 (0.6076)\tAcc 0.500 (0.719)\n",
      "Epoch: [77][3/9]\tTime 0.073 (0.164)\tData 0.052 (0.141)\tLoss 0.4914 (0.5688)\tAcc 0.750 (0.729)\n",
      "Epoch: [77][4/9]\tTime 0.072 (0.141)\tData 0.052 (0.119)\tLoss 0.6413 (0.5870)\tAcc 0.750 (0.734)\n",
      "Epoch: [77][5/9]\tTime 0.074 (0.128)\tData 0.054 (0.106)\tLoss 0.8449 (0.6385)\tAcc 0.688 (0.725)\n",
      "Epoch: [77][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.097)\tLoss 0.1982 (0.5651)\tAcc 1.000 (0.771)\n",
      "Epoch: [77][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6959 (0.5838)\tAcc 0.688 (0.759)\n",
      "Epoch: [77][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.087)\tLoss 0.8970 (0.6230)\tAcc 0.750 (0.758)\n",
      "Epoch: [77][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.083)\tLoss 0.0847 (0.6147)\tAcc 1.000 (0.762)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.367 (0.367)\tData 0.340 (0.340)\tLoss 0.8766 (0.8766)\tAcc 0.688 (0.688)\n",
      "Epoch: [78][2/5]\tTime 0.075 (0.221)\tData 0.052 (0.196)\tLoss 0.6938 (0.7852)\tAcc 0.625 (0.656)\n",
      "Epoch: [78][3/5]\tTime 0.076 (0.173)\tData 0.054 (0.149)\tLoss 0.8038 (0.7914)\tAcc 0.688 (0.667)\n",
      "Epoch: [78][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.125)\tLoss 0.6964 (0.7676)\tAcc 0.750 (0.688)\n",
      "Epoch: [78][5/5]\tTime 0.078 (0.135)\tData 0.056 (0.111)\tLoss 1.1150 (0.8105)\tAcc 0.556 (0.671)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.245 (0.245)\tData 0.221 (0.221)\tLoss 0.2852 (0.2852)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/9]\tTime 0.080 (0.163)\tData 0.060 (0.141)\tLoss 1.0102 (0.6477)\tAcc 0.438 (0.688)\n",
      "Epoch: [78][3/9]\tTime 0.074 (0.133)\tData 0.053 (0.111)\tLoss 0.6519 (0.6491)\tAcc 0.750 (0.708)\n",
      "Epoch: [78][4/9]\tTime 0.076 (0.119)\tData 0.053 (0.097)\tLoss 0.6490 (0.6491)\tAcc 0.750 (0.719)\n",
      "Epoch: [78][5/9]\tTime 0.071 (0.109)\tData 0.052 (0.088)\tLoss 0.8335 (0.6860)\tAcc 0.562 (0.688)\n",
      "Epoch: [78][6/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.1985 (0.6047)\tAcc 1.000 (0.740)\n",
      "Epoch: [78][7/9]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.5477 (0.5966)\tAcc 0.812 (0.750)\n",
      "Epoch: [78][8/9]\tTime 0.075 (0.096)\tData 0.056 (0.075)\tLoss 1.1796 (0.6695)\tAcc 0.438 (0.711)\n",
      "Epoch: [78][9/9]\tTime 0.072 (0.093)\tData 0.054 (0.073)\tLoss 0.2060 (0.6623)\tAcc 1.000 (0.715)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.316 (0.316)\tData 0.288 (0.288)\tLoss 0.7815 (0.7815)\tAcc 0.688 (0.688)\n",
      "Epoch: [79][2/5]\tTime 0.086 (0.201)\tData 0.062 (0.175)\tLoss 0.9262 (0.8538)\tAcc 0.688 (0.688)\n",
      "Epoch: [79][3/5]\tTime 0.077 (0.160)\tData 0.053 (0.134)\tLoss 0.6992 (0.8023)\tAcc 0.688 (0.688)\n",
      "Epoch: [79][4/5]\tTime 0.076 (0.139)\tData 0.052 (0.114)\tLoss 0.8988 (0.8264)\tAcc 0.500 (0.641)\n",
      "Epoch: [79][5/5]\tTime 0.078 (0.127)\tData 0.055 (0.102)\tLoss 0.9010 (0.8356)\tAcc 0.667 (0.644)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.284 (0.284)\tData 0.261 (0.261)\tLoss 0.3049 (0.3049)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.074 (0.179)\tData 0.051 (0.156)\tLoss 1.0256 (0.6652)\tAcc 0.500 (0.719)\n",
      "Epoch: [79][3/9]\tTime 0.071 (0.143)\tData 0.051 (0.121)\tLoss 0.5910 (0.6405)\tAcc 0.688 (0.708)\n",
      "Epoch: [79][4/9]\tTime 0.077 (0.126)\tData 0.053 (0.104)\tLoss 0.7877 (0.6773)\tAcc 0.625 (0.688)\n",
      "Epoch: [79][5/9]\tTime 0.071 (0.115)\tData 0.051 (0.093)\tLoss 0.7663 (0.6951)\tAcc 0.750 (0.700)\n",
      "Epoch: [79][6/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.2756 (0.6252)\tAcc 0.938 (0.740)\n",
      "Epoch: [79][7/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.6395 (0.6272)\tAcc 0.750 (0.741)\n",
      "Epoch: [79][8/9]\tTime 0.074 (0.100)\tData 0.055 (0.079)\tLoss 1.0884 (0.6849)\tAcc 0.625 (0.727)\n",
      "Epoch: [79][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.076)\tLoss 0.1649 (0.6769)\tAcc 1.000 (0.731)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.309 (0.309)\tData 0.278 (0.278)\tLoss 0.4816 (0.4816)\tAcc 0.812 (0.812)\n",
      "Epoch: [80][2/5]\tTime 0.071 (0.190)\tData 0.047 (0.163)\tLoss 0.9315 (0.7066)\tAcc 0.625 (0.719)\n",
      "Epoch: [80][3/5]\tTime 0.077 (0.152)\tData 0.053 (0.126)\tLoss 0.6773 (0.6968)\tAcc 0.688 (0.708)\n",
      "Epoch: [80][4/5]\tTime 0.076 (0.133)\tData 0.053 (0.108)\tLoss 0.8106 (0.7252)\tAcc 0.625 (0.688)\n",
      "Epoch: [80][5/5]\tTime 0.078 (0.122)\tData 0.055 (0.097)\tLoss 0.3135 (0.6745)\tAcc 0.889 (0.712)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.289 (0.289)\tData 0.266 (0.266)\tLoss 0.3483 (0.3483)\tAcc 0.875 (0.875)\n",
      "Epoch: [80][2/9]\tTime 0.082 (0.185)\tData 0.061 (0.164)\tLoss 0.9912 (0.6697)\tAcc 0.562 (0.719)\n",
      "Epoch: [80][3/9]\tTime 0.075 (0.149)\tData 0.053 (0.127)\tLoss 0.5562 (0.6319)\tAcc 0.750 (0.729)\n",
      "Epoch: [80][4/9]\tTime 0.072 (0.130)\tData 0.051 (0.108)\tLoss 0.6526 (0.6371)\tAcc 0.625 (0.703)\n",
      "Epoch: [80][5/9]\tTime 0.073 (0.118)\tData 0.053 (0.097)\tLoss 0.9963 (0.7089)\tAcc 0.625 (0.688)\n",
      "Epoch: [80][6/9]\tTime 0.075 (0.111)\tData 0.055 (0.090)\tLoss 0.2672 (0.6353)\tAcc 1.000 (0.740)\n",
      "Epoch: [80][7/9]\tTime 0.076 (0.106)\tData 0.056 (0.085)\tLoss 0.7034 (0.6450)\tAcc 0.688 (0.732)\n",
      "Epoch: [80][8/9]\tTime 0.078 (0.102)\tData 0.059 (0.082)\tLoss 1.1256 (0.7051)\tAcc 0.500 (0.703)\n",
      "Epoch: [80][9/9]\tTime 0.078 (0.100)\tData 0.060 (0.079)\tLoss 0.1095 (0.6959)\tAcc 1.000 (0.708)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.359 (0.359)\tData 0.329 (0.329)\tLoss 0.5424 (0.5424)\tAcc 0.688 (0.688)\n",
      "Epoch: [81][2/5]\tTime 0.072 (0.215)\tData 0.048 (0.188)\tLoss 0.5404 (0.5414)\tAcc 0.750 (0.719)\n",
      "Epoch: [81][3/5]\tTime 0.076 (0.169)\tData 0.053 (0.143)\tLoss 0.6463 (0.5764)\tAcc 0.812 (0.750)\n",
      "Epoch: [81][4/5]\tTime 0.076 (0.146)\tData 0.053 (0.121)\tLoss 1.1574 (0.7216)\tAcc 0.625 (0.719)\n",
      "Epoch: [81][5/5]\tTime 0.078 (0.132)\tData 0.055 (0.108)\tLoss 0.8857 (0.7419)\tAcc 0.778 (0.726)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.271 (0.271)\tData 0.245 (0.245)\tLoss 0.2774 (0.2774)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/9]\tTime 0.071 (0.171)\tData 0.048 (0.147)\tLoss 1.0617 (0.6696)\tAcc 0.500 (0.719)\n",
      "Epoch: [81][3/9]\tTime 0.074 (0.139)\tData 0.051 (0.115)\tLoss 0.6065 (0.6485)\tAcc 0.688 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.073 (0.122)\tData 0.051 (0.099)\tLoss 0.5330 (0.6197)\tAcc 0.812 (0.734)\n",
      "Epoch: [81][5/9]\tTime 0.072 (0.112)\tData 0.052 (0.089)\tLoss 0.8005 (0.6558)\tAcc 0.750 (0.738)\n",
      "Epoch: [81][6/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.2041 (0.5805)\tAcc 1.000 (0.781)\n",
      "Epoch: [81][7/9]\tTime 0.072 (0.101)\tData 0.054 (0.079)\tLoss 0.8325 (0.6165)\tAcc 0.625 (0.759)\n",
      "Epoch: [81][8/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 1.1380 (0.6817)\tAcc 0.438 (0.719)\n",
      "Epoch: [81][9/9]\tTime 0.072 (0.095)\tData 0.054 (0.074)\tLoss 0.2515 (0.6751)\tAcc 1.000 (0.723)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.320 (0.320)\tData 0.289 (0.289)\tLoss 0.8520 (0.8520)\tAcc 0.625 (0.625)\n",
      "Epoch: [82][2/5]\tTime 0.072 (0.196)\tData 0.048 (0.169)\tLoss 0.6217 (0.7369)\tAcc 0.812 (0.719)\n",
      "Epoch: [82][3/5]\tTime 0.077 (0.156)\tData 0.053 (0.130)\tLoss 0.8954 (0.7897)\tAcc 0.625 (0.688)\n",
      "Epoch: [82][4/5]\tTime 0.076 (0.136)\tData 0.053 (0.111)\tLoss 0.5167 (0.7215)\tAcc 0.812 (0.719)\n",
      "Epoch: [82][5/5]\tTime 0.079 (0.125)\tData 0.055 (0.100)\tLoss 2.0063 (0.8799)\tAcc 0.111 (0.644)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.314 (0.314)\tData 0.288 (0.288)\tLoss 0.3300 (0.3300)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/9]\tTime 0.070 (0.192)\tData 0.049 (0.168)\tLoss 0.9090 (0.6195)\tAcc 0.500 (0.719)\n",
      "Epoch: [82][3/9]\tTime 0.074 (0.153)\tData 0.052 (0.130)\tLoss 0.6097 (0.6162)\tAcc 0.750 (0.729)\n",
      "Epoch: [82][4/9]\tTime 0.072 (0.132)\tData 0.052 (0.110)\tLoss 0.6456 (0.6236)\tAcc 0.812 (0.750)\n",
      "Epoch: [82][5/9]\tTime 0.073 (0.121)\tData 0.054 (0.099)\tLoss 0.8156 (0.6620)\tAcc 0.688 (0.738)\n",
      "Epoch: [82][6/9]\tTime 0.073 (0.113)\tData 0.054 (0.091)\tLoss 0.3052 (0.6025)\tAcc 1.000 (0.781)\n",
      "Epoch: [82][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.6980 (0.6162)\tAcc 0.750 (0.777)\n",
      "Epoch: [82][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 1.0532 (0.6708)\tAcc 0.562 (0.750)\n",
      "Epoch: [82][9/9]\tTime 0.072 (0.099)\tData 0.054 (0.079)\tLoss 0.1712 (0.6631)\tAcc 1.000 (0.754)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.386 (0.386)\tData 0.359 (0.359)\tLoss 0.9399 (0.9399)\tAcc 0.625 (0.625)\n",
      "Epoch: [83][2/5]\tTime 0.075 (0.230)\tData 0.051 (0.205)\tLoss 0.6897 (0.8148)\tAcc 0.750 (0.688)\n",
      "Epoch: [83][3/5]\tTime 0.077 (0.179)\tData 0.054 (0.154)\tLoss 0.5200 (0.7165)\tAcc 0.875 (0.750)\n",
      "Epoch: [83][4/5]\tTime 0.077 (0.154)\tData 0.053 (0.129)\tLoss 0.7429 (0.7231)\tAcc 0.625 (0.719)\n",
      "Epoch: [83][5/5]\tTime 0.078 (0.139)\tData 0.055 (0.114)\tLoss 0.6424 (0.7132)\tAcc 0.889 (0.740)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.406 (0.406)\tData 0.383 (0.383)\tLoss 0.3013 (0.3013)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.071 (0.239)\tData 0.051 (0.217)\tLoss 0.9694 (0.6354)\tAcc 0.562 (0.750)\n",
      "Epoch: [83][3/9]\tTime 0.073 (0.183)\tData 0.053 (0.162)\tLoss 0.6571 (0.6426)\tAcc 0.812 (0.771)\n",
      "Epoch: [83][4/9]\tTime 0.074 (0.156)\tData 0.054 (0.135)\tLoss 0.6186 (0.6366)\tAcc 0.625 (0.734)\n",
      "Epoch: [83][5/9]\tTime 0.074 (0.139)\tData 0.054 (0.119)\tLoss 0.9852 (0.7063)\tAcc 0.562 (0.700)\n",
      "Epoch: [83][6/9]\tTime 0.072 (0.128)\tData 0.054 (0.108)\tLoss 0.1902 (0.6203)\tAcc 1.000 (0.750)\n",
      "Epoch: [83][7/9]\tTime 0.073 (0.120)\tData 0.055 (0.100)\tLoss 0.7308 (0.6361)\tAcc 0.688 (0.741)\n",
      "Epoch: [83][8/9]\tTime 0.074 (0.115)\tData 0.056 (0.095)\tLoss 1.0937 (0.6933)\tAcc 0.562 (0.719)\n",
      "Epoch: [83][9/9]\tTime 0.072 (0.110)\tData 0.054 (0.090)\tLoss 0.1741 (0.6853)\tAcc 1.000 (0.723)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.350 (0.350)\tData 0.323 (0.323)\tLoss 0.4180 (0.4180)\tAcc 0.812 (0.812)\n",
      "Epoch: [84][2/5]\tTime 0.075 (0.212)\tData 0.051 (0.187)\tLoss 0.8583 (0.6381)\tAcc 0.625 (0.719)\n",
      "Epoch: [84][3/5]\tTime 0.076 (0.167)\tData 0.053 (0.143)\tLoss 1.1520 (0.8094)\tAcc 0.562 (0.667)\n",
      "Epoch: [84][4/5]\tTime 0.076 (0.144)\tData 0.054 (0.121)\tLoss 0.6649 (0.7733)\tAcc 0.750 (0.688)\n",
      "Epoch: [84][5/5]\tTime 0.078 (0.131)\tData 0.056 (0.108)\tLoss 0.4462 (0.7330)\tAcc 0.889 (0.712)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.310 (0.310)\tData 0.287 (0.287)\tLoss 0.3418 (0.3418)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/9]\tTime 0.072 (0.191)\tData 0.051 (0.169)\tLoss 1.1251 (0.7335)\tAcc 0.500 (0.719)\n",
      "Epoch: [84][3/9]\tTime 0.073 (0.152)\tData 0.053 (0.130)\tLoss 0.5710 (0.6793)\tAcc 0.875 (0.771)\n",
      "Epoch: [84][4/9]\tTime 0.076 (0.133)\tData 0.053 (0.111)\tLoss 0.6350 (0.6682)\tAcc 0.688 (0.750)\n",
      "Epoch: [84][5/9]\tTime 0.071 (0.120)\tData 0.052 (0.099)\tLoss 0.7758 (0.6897)\tAcc 0.625 (0.725)\n",
      "Epoch: [84][6/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.1970 (0.6076)\tAcc 1.000 (0.771)\n",
      "Epoch: [84][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.8263 (0.6389)\tAcc 0.625 (0.750)\n",
      "Epoch: [84][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 1.1151 (0.6984)\tAcc 0.438 (0.711)\n",
      "Epoch: [84][9/9]\tTime 0.072 (0.099)\tData 0.054 (0.079)\tLoss 0.1204 (0.6895)\tAcc 1.000 (0.715)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.346 (0.346)\tData 0.317 (0.317)\tLoss 0.7179 (0.7179)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/5]\tTime 0.073 (0.210)\tData 0.049 (0.183)\tLoss 0.6528 (0.6853)\tAcc 0.750 (0.719)\n",
      "Epoch: [85][3/5]\tTime 0.075 (0.165)\tData 0.052 (0.139)\tLoss 0.7650 (0.7119)\tAcc 0.688 (0.708)\n",
      "Epoch: [85][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.7683 (0.7260)\tAcc 0.625 (0.688)\n",
      "Epoch: [85][5/5]\tTime 0.078 (0.130)\tData 0.055 (0.105)\tLoss 0.4185 (0.6881)\tAcc 0.889 (0.712)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.332 (0.332)\tData 0.308 (0.308)\tLoss 0.2809 (0.2809)\tAcc 0.938 (0.938)\n",
      "Epoch: [85][2/9]\tTime 0.071 (0.202)\tData 0.050 (0.179)\tLoss 0.9665 (0.6237)\tAcc 0.438 (0.688)\n",
      "Epoch: [85][3/9]\tTime 0.074 (0.159)\tData 0.053 (0.137)\tLoss 0.8053 (0.6842)\tAcc 0.625 (0.667)\n",
      "Epoch: [85][4/9]\tTime 0.072 (0.137)\tData 0.052 (0.116)\tLoss 0.5894 (0.6605)\tAcc 0.812 (0.703)\n",
      "Epoch: [85][5/9]\tTime 0.074 (0.125)\tData 0.054 (0.104)\tLoss 0.9916 (0.7267)\tAcc 0.562 (0.675)\n",
      "Epoch: [85][6/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.2303 (0.6440)\tAcc 1.000 (0.729)\n",
      "Epoch: [85][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6276 (0.6416)\tAcc 0.750 (0.732)\n",
      "Epoch: [85][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.085)\tLoss 1.1700 (0.7077)\tAcc 0.562 (0.711)\n",
      "Epoch: [85][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.082)\tLoss 0.1783 (0.6995)\tAcc 1.000 (0.715)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.360 (0.360)\tData 0.334 (0.334)\tLoss 0.7159 (0.7159)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][2/5]\tTime 0.075 (0.218)\tData 0.051 (0.193)\tLoss 1.2414 (0.9787)\tAcc 0.500 (0.625)\n",
      "Epoch: [86][3/5]\tTime 0.076 (0.171)\tData 0.053 (0.146)\tLoss 0.8776 (0.9450)\tAcc 0.688 (0.646)\n",
      "Epoch: [86][4/5]\tTime 0.076 (0.147)\tData 0.054 (0.123)\tLoss 0.5438 (0.8447)\tAcc 0.875 (0.703)\n",
      "Epoch: [86][5/5]\tTime 0.078 (0.133)\tData 0.056 (0.110)\tLoss 1.1538 (0.8828)\tAcc 0.556 (0.685)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.284 (0.284)\tData 0.261 (0.261)\tLoss 0.2677 (0.2677)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.074 (0.179)\tData 0.051 (0.156)\tLoss 0.9019 (0.5848)\tAcc 0.625 (0.781)\n",
      "Epoch: [86][3/9]\tTime 0.073 (0.144)\tData 0.051 (0.121)\tLoss 0.5890 (0.5862)\tAcc 0.812 (0.792)\n",
      "Epoch: [86][4/9]\tTime 0.072 (0.126)\tData 0.052 (0.104)\tLoss 0.7375 (0.6240)\tAcc 0.688 (0.766)\n",
      "Epoch: [86][5/9]\tTime 0.075 (0.116)\tData 0.055 (0.094)\tLoss 0.7927 (0.6577)\tAcc 0.812 (0.775)\n",
      "Epoch: [86][6/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.2842 (0.5955)\tAcc 1.000 (0.812)\n",
      "Epoch: [86][7/9]\tTime 0.072 (0.103)\tData 0.054 (0.083)\tLoss 0.6186 (0.5988)\tAcc 0.812 (0.813)\n",
      "Epoch: [86][8/9]\tTime 0.074 (0.100)\tData 0.055 (0.079)\tLoss 1.1048 (0.6620)\tAcc 0.562 (0.781)\n",
      "Epoch: [86][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.076)\tLoss 0.2300 (0.6554)\tAcc 1.000 (0.785)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.315 (0.315)\tData 0.286 (0.286)\tLoss 0.6431 (0.6431)\tAcc 0.812 (0.812)\n",
      "Epoch: [87][2/5]\tTime 0.073 (0.194)\tData 0.048 (0.167)\tLoss 0.7506 (0.6968)\tAcc 0.750 (0.781)\n",
      "Epoch: [87][3/5]\tTime 0.075 (0.154)\tData 0.053 (0.129)\tLoss 0.6182 (0.6706)\tAcc 0.750 (0.771)\n",
      "Epoch: [87][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.110)\tLoss 0.6922 (0.6760)\tAcc 0.625 (0.734)\n",
      "Epoch: [87][5/5]\tTime 0.078 (0.124)\tData 0.056 (0.099)\tLoss 1.2724 (0.7496)\tAcc 0.556 (0.712)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.307 (0.307)\tData 0.281 (0.281)\tLoss 0.3977 (0.3977)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][2/9]\tTime 0.070 (0.189)\tData 0.049 (0.165)\tLoss 1.0307 (0.7142)\tAcc 0.438 (0.656)\n",
      "Epoch: [87][3/9]\tTime 0.073 (0.150)\tData 0.053 (0.127)\tLoss 0.6836 (0.7040)\tAcc 0.688 (0.667)\n",
      "Epoch: [87][4/9]\tTime 0.074 (0.131)\tData 0.053 (0.109)\tLoss 0.5102 (0.6556)\tAcc 0.750 (0.688)\n",
      "Epoch: [87][5/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.9384 (0.7121)\tAcc 0.750 (0.700)\n",
      "Epoch: [87][6/9]\tTime 0.073 (0.112)\tData 0.054 (0.090)\tLoss 0.3156 (0.6460)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.072 (0.106)\tData 0.054 (0.085)\tLoss 0.5750 (0.6359)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 1.1039 (0.6944)\tAcc 0.562 (0.727)\n",
      "Epoch: [87][9/9]\tTime 0.072 (0.099)\tData 0.054 (0.078)\tLoss 0.1819 (0.6865)\tAcc 1.000 (0.731)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.220 (0.220)\tData 0.192 (0.192)\tLoss 0.6420 (0.6420)\tAcc 0.688 (0.688)\n",
      "Epoch: [88][2/5]\tTime 0.101 (0.161)\tData 0.077 (0.135)\tLoss 0.7851 (0.7135)\tAcc 0.688 (0.688)\n",
      "Epoch: [88][3/5]\tTime 0.077 (0.133)\tData 0.054 (0.108)\tLoss 0.8708 (0.7660)\tAcc 0.562 (0.646)\n",
      "Epoch: [88][4/5]\tTime 0.077 (0.119)\tData 0.054 (0.094)\tLoss 1.0046 (0.8256)\tAcc 0.562 (0.625)\n",
      "Epoch: [88][5/5]\tTime 0.077 (0.110)\tData 0.054 (0.086)\tLoss 0.4314 (0.7770)\tAcc 0.889 (0.658)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.347 (0.347)\tData 0.323 (0.323)\tLoss 0.2838 (0.2838)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/9]\tTime 0.072 (0.209)\tData 0.050 (0.187)\tLoss 0.8934 (0.5886)\tAcc 0.500 (0.719)\n",
      "Epoch: [88][3/9]\tTime 0.075 (0.164)\tData 0.053 (0.142)\tLoss 0.6769 (0.6180)\tAcc 0.750 (0.729)\n",
      "Epoch: [88][4/9]\tTime 0.077 (0.143)\tData 0.052 (0.119)\tLoss 0.7776 (0.6579)\tAcc 0.625 (0.703)\n",
      "Epoch: [88][5/9]\tTime 0.069 (0.128)\tData 0.049 (0.105)\tLoss 0.8299 (0.6923)\tAcc 0.688 (0.700)\n",
      "Epoch: [88][6/9]\tTime 0.073 (0.119)\tData 0.053 (0.097)\tLoss 0.2371 (0.6165)\tAcc 0.938 (0.740)\n",
      "Epoch: [88][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6640 (0.6232)\tAcc 0.688 (0.732)\n",
      "Epoch: [88][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 0.9810 (0.6680)\tAcc 0.750 (0.734)\n",
      "Epoch: [88][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.083)\tLoss 0.0580 (0.6586)\tAcc 1.000 (0.738)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.305 (0.305)\tData 0.277 (0.277)\tLoss 0.8578 (0.8578)\tAcc 0.562 (0.562)\n",
      "Epoch: [89][2/5]\tTime 0.073 (0.189)\tData 0.050 (0.163)\tLoss 0.3916 (0.6247)\tAcc 0.938 (0.750)\n",
      "Epoch: [89][3/5]\tTime 0.076 (0.152)\tData 0.053 (0.127)\tLoss 0.6479 (0.6324)\tAcc 0.812 (0.771)\n",
      "Epoch: [89][4/5]\tTime 0.076 (0.133)\tData 0.054 (0.108)\tLoss 0.5693 (0.6166)\tAcc 0.750 (0.766)\n",
      "Epoch: [89][5/5]\tTime 0.078 (0.122)\tData 0.055 (0.098)\tLoss 1.1090 (0.6773)\tAcc 0.556 (0.740)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.327 (0.327)\tData 0.304 (0.304)\tLoss 0.2928 (0.2928)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.071 (0.199)\tData 0.051 (0.177)\tLoss 0.9100 (0.6014)\tAcc 0.562 (0.750)\n",
      "Epoch: [89][3/9]\tTime 0.075 (0.158)\tData 0.053 (0.136)\tLoss 0.7442 (0.6490)\tAcc 0.688 (0.729)\n",
      "Epoch: [89][4/9]\tTime 0.070 (0.136)\tData 0.051 (0.115)\tLoss 0.5101 (0.6143)\tAcc 0.812 (0.750)\n",
      "Epoch: [89][5/9]\tTime 0.074 (0.124)\tData 0.055 (0.103)\tLoss 0.8593 (0.6633)\tAcc 0.688 (0.738)\n",
      "Epoch: [89][6/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.2332 (0.5916)\tAcc 1.000 (0.781)\n",
      "Epoch: [89][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.089)\tLoss 0.7505 (0.6143)\tAcc 0.688 (0.768)\n",
      "Epoch: [89][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.085)\tLoss 0.9196 (0.6525)\tAcc 0.500 (0.734)\n",
      "Epoch: [89][9/9]\tTime 0.072 (0.101)\tData 0.054 (0.081)\tLoss 0.0892 (0.6438)\tAcc 1.000 (0.738)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.385 (0.385)\tData 0.358 (0.358)\tLoss 0.7831 (0.7831)\tAcc 0.688 (0.688)\n",
      "Epoch: [90][2/5]\tTime 0.075 (0.230)\tData 0.051 (0.205)\tLoss 0.9498 (0.8665)\tAcc 0.688 (0.688)\n",
      "Epoch: [90][3/5]\tTime 0.076 (0.179)\tData 0.054 (0.154)\tLoss 0.7018 (0.8116)\tAcc 0.812 (0.729)\n",
      "Epoch: [90][4/5]\tTime 0.076 (0.153)\tData 0.054 (0.129)\tLoss 0.7786 (0.8033)\tAcc 0.812 (0.750)\n",
      "Epoch: [90][5/5]\tTime 0.078 (0.138)\tData 0.056 (0.114)\tLoss 0.6901 (0.7894)\tAcc 0.778 (0.753)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.269 (0.269)\tData 0.243 (0.243)\tLoss 0.3431 (0.3431)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/9]\tTime 0.071 (0.170)\tData 0.049 (0.146)\tLoss 0.9386 (0.6409)\tAcc 0.562 (0.750)\n",
      "Epoch: [90][3/9]\tTime 0.072 (0.137)\tData 0.051 (0.114)\tLoss 0.5121 (0.5980)\tAcc 0.875 (0.792)\n",
      "Epoch: [90][4/9]\tTime 0.074 (0.121)\tData 0.053 (0.099)\tLoss 0.6965 (0.6226)\tAcc 0.688 (0.766)\n",
      "Epoch: [90][5/9]\tTime 0.073 (0.112)\tData 0.054 (0.090)\tLoss 0.9717 (0.6924)\tAcc 0.625 (0.738)\n",
      "Epoch: [90][6/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.2177 (0.6133)\tAcc 1.000 (0.781)\n",
      "Epoch: [90][7/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.4573 (0.5910)\tAcc 0.875 (0.795)\n",
      "Epoch: [90][8/9]\tTime 0.075 (0.097)\tData 0.056 (0.077)\tLoss 0.9183 (0.6319)\tAcc 0.500 (0.758)\n",
      "Epoch: [90][9/9]\tTime 0.072 (0.095)\tData 0.054 (0.074)\tLoss 0.3591 (0.6277)\tAcc 1.000 (0.762)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.354 (0.354)\tData 0.323 (0.323)\tLoss 0.9705 (0.9705)\tAcc 0.500 (0.500)\n",
      "Epoch: [91][2/5]\tTime 0.071 (0.213)\tData 0.047 (0.185)\tLoss 0.7380 (0.8543)\tAcc 0.688 (0.594)\n",
      "Epoch: [91][3/5]\tTime 0.076 (0.167)\tData 0.053 (0.141)\tLoss 0.8454 (0.8513)\tAcc 0.750 (0.646)\n",
      "Epoch: [91][4/5]\tTime 0.077 (0.144)\tData 0.054 (0.119)\tLoss 0.6409 (0.7987)\tAcc 0.688 (0.656)\n",
      "Epoch: [91][5/5]\tTime 0.078 (0.131)\tData 0.055 (0.107)\tLoss 0.9720 (0.8201)\tAcc 0.667 (0.658)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.294 (0.294)\tData 0.271 (0.271)\tLoss 0.3657 (0.3657)\tAcc 0.875 (0.875)\n",
      "Epoch: [91][2/9]\tTime 0.075 (0.185)\tData 0.051 (0.161)\tLoss 0.9380 (0.6518)\tAcc 0.500 (0.688)\n",
      "Epoch: [91][3/9]\tTime 0.071 (0.147)\tData 0.051 (0.124)\tLoss 0.6460 (0.6499)\tAcc 0.625 (0.667)\n",
      "Epoch: [91][4/9]\tTime 0.074 (0.128)\tData 0.053 (0.107)\tLoss 0.6357 (0.6463)\tAcc 0.688 (0.672)\n",
      "Epoch: [91][5/9]\tTime 0.078 (0.118)\tData 0.056 (0.096)\tLoss 0.9593 (0.7089)\tAcc 0.562 (0.650)\n",
      "Epoch: [91][6/9]\tTime 0.071 (0.110)\tData 0.051 (0.089)\tLoss 0.2772 (0.6370)\tAcc 1.000 (0.708)\n",
      "Epoch: [91][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.9695 (0.6845)\tAcc 0.438 (0.670)\n",
      "Epoch: [91][8/9]\tTime 0.074 (0.101)\tData 0.056 (0.080)\tLoss 1.1065 (0.7372)\tAcc 0.500 (0.648)\n",
      "Epoch: [91][9/9]\tTime 0.072 (0.098)\tData 0.054 (0.078)\tLoss 0.1504 (0.7282)\tAcc 1.000 (0.654)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.380 (0.380)\tData 0.353 (0.353)\tLoss 0.6423 (0.6423)\tAcc 0.812 (0.812)\n",
      "Epoch: [92][2/5]\tTime 0.074 (0.227)\tData 0.051 (0.202)\tLoss 1.1846 (0.9134)\tAcc 0.625 (0.719)\n",
      "Epoch: [92][3/5]\tTime 0.077 (0.177)\tData 0.054 (0.153)\tLoss 0.5081 (0.7783)\tAcc 0.812 (0.750)\n",
      "Epoch: [92][4/5]\tTime 0.077 (0.152)\tData 0.054 (0.128)\tLoss 0.7140 (0.7623)\tAcc 0.812 (0.766)\n",
      "Epoch: [92][5/5]\tTime 0.078 (0.137)\tData 0.055 (0.114)\tLoss 0.8453 (0.7725)\tAcc 0.556 (0.740)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.271 (0.271)\tData 0.247 (0.247)\tLoss 0.3066 (0.3066)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/9]\tTime 0.078 (0.175)\tData 0.056 (0.152)\tLoss 0.9066 (0.6066)\tAcc 0.562 (0.750)\n",
      "Epoch: [92][3/9]\tTime 0.072 (0.141)\tData 0.051 (0.118)\tLoss 0.6834 (0.6322)\tAcc 0.625 (0.708)\n",
      "Epoch: [92][4/9]\tTime 0.073 (0.124)\tData 0.052 (0.102)\tLoss 0.6861 (0.6456)\tAcc 0.688 (0.703)\n",
      "Epoch: [92][5/9]\tTime 0.074 (0.114)\tData 0.053 (0.092)\tLoss 0.8340 (0.6833)\tAcc 0.562 (0.675)\n",
      "Epoch: [92][6/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.2319 (0.6081)\tAcc 1.000 (0.729)\n",
      "Epoch: [92][7/9]\tTime 0.072 (0.102)\tData 0.054 (0.081)\tLoss 0.7761 (0.6321)\tAcc 0.625 (0.714)\n",
      "Epoch: [92][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 1.0308 (0.6819)\tAcc 0.500 (0.688)\n",
      "Epoch: [92][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.075)\tLoss 0.0669 (0.6725)\tAcc 1.000 (0.692)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.354 (0.354)\tData 0.327 (0.327)\tLoss 0.8418 (0.8418)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][2/5]\tTime 0.075 (0.214)\tData 0.051 (0.189)\tLoss 0.9458 (0.8938)\tAcc 0.500 (0.625)\n",
      "Epoch: [93][3/5]\tTime 0.076 (0.168)\tData 0.053 (0.144)\tLoss 0.6412 (0.8096)\tAcc 0.750 (0.667)\n",
      "Epoch: [93][4/5]\tTime 0.076 (0.145)\tData 0.054 (0.121)\tLoss 0.6459 (0.7687)\tAcc 0.688 (0.672)\n",
      "Epoch: [93][5/5]\tTime 0.078 (0.132)\tData 0.055 (0.108)\tLoss 0.4193 (0.7256)\tAcc 0.889 (0.699)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.317 (0.317)\tData 0.293 (0.293)\tLoss 0.2472 (0.2472)\tAcc 1.000 (1.000)\n",
      "Epoch: [93][2/9]\tTime 0.074 (0.195)\tData 0.051 (0.172)\tLoss 1.0029 (0.6251)\tAcc 0.438 (0.719)\n",
      "Epoch: [93][3/9]\tTime 0.072 (0.154)\tData 0.051 (0.131)\tLoss 0.6060 (0.6187)\tAcc 0.750 (0.729)\n",
      "Epoch: [93][4/9]\tTime 0.073 (0.134)\tData 0.052 (0.112)\tLoss 0.5793 (0.6089)\tAcc 0.688 (0.719)\n",
      "Epoch: [93][5/9]\tTime 0.073 (0.122)\tData 0.054 (0.100)\tLoss 0.8485 (0.6568)\tAcc 0.688 (0.713)\n",
      "Epoch: [93][6/9]\tTime 0.073 (0.114)\tData 0.053 (0.092)\tLoss 0.2419 (0.5877)\tAcc 1.000 (0.760)\n",
      "Epoch: [93][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.6981 (0.6034)\tAcc 0.625 (0.741)\n",
      "Epoch: [93][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 1.0553 (0.6599)\tAcc 0.500 (0.711)\n",
      "Epoch: [93][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.080)\tLoss 0.1930 (0.6527)\tAcc 1.000 (0.715)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.366 (0.366)\tData 0.339 (0.339)\tLoss 0.8663 (0.8663)\tAcc 0.500 (0.500)\n",
      "Epoch: [94][2/5]\tTime 0.074 (0.220)\tData 0.051 (0.195)\tLoss 0.8380 (0.8522)\tAcc 0.750 (0.625)\n",
      "Epoch: [94][3/5]\tTime 0.077 (0.172)\tData 0.054 (0.148)\tLoss 0.6837 (0.7960)\tAcc 0.688 (0.646)\n",
      "Epoch: [94][4/5]\tTime 0.076 (0.148)\tData 0.053 (0.124)\tLoss 0.5424 (0.7326)\tAcc 0.875 (0.703)\n",
      "Epoch: [94][5/5]\tTime 0.078 (0.134)\tData 0.055 (0.110)\tLoss 0.7103 (0.7298)\tAcc 0.667 (0.699)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.340 (0.340)\tData 0.315 (0.315)\tLoss 0.2643 (0.2643)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/9]\tTime 0.071 (0.205)\tData 0.049 (0.182)\tLoss 0.9761 (0.6202)\tAcc 0.438 (0.688)\n",
      "Epoch: [94][3/9]\tTime 0.074 (0.161)\tData 0.052 (0.139)\tLoss 0.3931 (0.5445)\tAcc 0.938 (0.771)\n",
      "Epoch: [94][4/9]\tTime 0.079 (0.141)\tData 0.052 (0.117)\tLoss 0.7166 (0.5875)\tAcc 0.688 (0.750)\n",
      "Epoch: [94][5/9]\tTime 0.067 (0.126)\tData 0.047 (0.103)\tLoss 0.9024 (0.6505)\tAcc 0.750 (0.750)\n",
      "Epoch: [94][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.095)\tLoss 0.2523 (0.5841)\tAcc 1.000 (0.792)\n",
      "Epoch: [94][7/9]\tTime 0.073 (0.111)\tData 0.054 (0.089)\tLoss 0.6690 (0.5963)\tAcc 0.688 (0.777)\n",
      "Epoch: [94][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 1.1373 (0.6639)\tAcc 0.625 (0.758)\n",
      "Epoch: [94][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.081)\tLoss 0.3067 (0.6584)\tAcc 1.000 (0.762)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.348 (0.348)\tData 0.320 (0.320)\tLoss 0.5516 (0.5516)\tAcc 0.688 (0.688)\n",
      "Epoch: [95][2/5]\tTime 0.075 (0.211)\tData 0.051 (0.186)\tLoss 0.6747 (0.6131)\tAcc 0.812 (0.750)\n",
      "Epoch: [95][3/5]\tTime 0.075 (0.166)\tData 0.052 (0.141)\tLoss 0.9194 (0.7152)\tAcc 0.688 (0.729)\n",
      "Epoch: [95][4/5]\tTime 0.076 (0.144)\tData 0.054 (0.119)\tLoss 0.9594 (0.7763)\tAcc 0.750 (0.734)\n",
      "Epoch: [95][5/5]\tTime 0.078 (0.130)\tData 0.056 (0.107)\tLoss 0.8398 (0.7841)\tAcc 0.667 (0.726)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.397 (0.397)\tData 0.373 (0.373)\tLoss 0.2660 (0.2660)\tAcc 1.000 (1.000)\n",
      "Epoch: [95][2/9]\tTime 0.072 (0.234)\tData 0.050 (0.212)\tLoss 0.9162 (0.5911)\tAcc 0.500 (0.750)\n",
      "Epoch: [95][3/9]\tTime 0.074 (0.181)\tData 0.053 (0.159)\tLoss 0.5546 (0.5789)\tAcc 0.750 (0.750)\n",
      "Epoch: [95][4/9]\tTime 0.075 (0.154)\tData 0.053 (0.132)\tLoss 0.6382 (0.5938)\tAcc 0.812 (0.766)\n",
      "Epoch: [95][5/9]\tTime 0.072 (0.138)\tData 0.052 (0.116)\tLoss 0.7371 (0.6224)\tAcc 0.688 (0.750)\n",
      "Epoch: [95][6/9]\tTime 0.072 (0.127)\tData 0.053 (0.106)\tLoss 0.2070 (0.5532)\tAcc 1.000 (0.792)\n",
      "Epoch: [95][7/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.6148 (0.5620)\tAcc 0.688 (0.777)\n",
      "Epoch: [95][8/9]\tTime 0.074 (0.114)\tData 0.055 (0.093)\tLoss 0.9574 (0.6114)\tAcc 0.625 (0.758)\n",
      "Epoch: [95][9/9]\tTime 0.072 (0.109)\tData 0.054 (0.089)\tLoss 0.1234 (0.6039)\tAcc 1.000 (0.762)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.370 (0.370)\tData 0.342 (0.342)\tLoss 0.6662 (0.6662)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][2/5]\tTime 0.073 (0.221)\tData 0.050 (0.196)\tLoss 0.8964 (0.7813)\tAcc 0.438 (0.562)\n",
      "Epoch: [96][3/5]\tTime 0.076 (0.173)\tData 0.054 (0.148)\tLoss 0.6189 (0.7272)\tAcc 0.688 (0.604)\n",
      "Epoch: [96][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.125)\tLoss 0.4996 (0.6703)\tAcc 0.812 (0.656)\n",
      "Epoch: [96][5/5]\tTime 0.078 (0.135)\tData 0.056 (0.111)\tLoss 0.9214 (0.7012)\tAcc 0.667 (0.658)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.354 (0.354)\tData 0.328 (0.328)\tLoss 0.3709 (0.3709)\tAcc 0.875 (0.875)\n",
      "Epoch: [96][2/9]\tTime 0.069 (0.211)\tData 0.048 (0.188)\tLoss 0.8718 (0.6213)\tAcc 0.688 (0.781)\n",
      "Epoch: [96][3/9]\tTime 0.073 (0.165)\tData 0.053 (0.143)\tLoss 0.7189 (0.6539)\tAcc 0.750 (0.771)\n",
      "Epoch: [96][4/9]\tTime 0.074 (0.143)\tData 0.053 (0.120)\tLoss 0.7322 (0.6735)\tAcc 0.688 (0.750)\n",
      "Epoch: [96][5/9]\tTime 0.072 (0.128)\tData 0.052 (0.107)\tLoss 0.8066 (0.7001)\tAcc 0.688 (0.738)\n",
      "Epoch: [96][6/9]\tTime 0.074 (0.119)\tData 0.055 (0.098)\tLoss 0.2779 (0.6297)\tAcc 1.000 (0.781)\n",
      "Epoch: [96][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.7457 (0.6463)\tAcc 0.750 (0.777)\n",
      "Epoch: [96][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.087)\tLoss 1.1415 (0.7082)\tAcc 0.500 (0.742)\n",
      "Epoch: [96][9/9]\tTime 0.072 (0.104)\tData 0.054 (0.084)\tLoss 0.3904 (0.7033)\tAcc 1.000 (0.746)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.394 (0.394)\tData 0.366 (0.366)\tLoss 0.7232 (0.7232)\tAcc 0.625 (0.625)\n",
      "Epoch: [97][2/5]\tTime 0.074 (0.234)\tData 0.050 (0.208)\tLoss 0.5545 (0.6388)\tAcc 0.750 (0.688)\n",
      "Epoch: [97][3/5]\tTime 0.077 (0.181)\tData 0.053 (0.156)\tLoss 0.7253 (0.6676)\tAcc 0.688 (0.688)\n",
      "Epoch: [97][4/5]\tTime 0.077 (0.155)\tData 0.053 (0.131)\tLoss 0.9687 (0.7429)\tAcc 0.625 (0.672)\n",
      "Epoch: [97][5/5]\tTime 0.078 (0.140)\tData 0.054 (0.115)\tLoss 0.5139 (0.7147)\tAcc 0.889 (0.699)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.352 (0.352)\tData 0.326 (0.326)\tLoss 0.2427 (0.2427)\tAcc 1.000 (1.000)\n",
      "Epoch: [97][2/9]\tTime 0.069 (0.210)\tData 0.048 (0.187)\tLoss 0.9379 (0.5903)\tAcc 0.438 (0.719)\n",
      "Epoch: [97][3/9]\tTime 0.075 (0.165)\tData 0.053 (0.142)\tLoss 0.7884 (0.6563)\tAcc 0.750 (0.729)\n",
      "Epoch: [97][4/9]\tTime 0.071 (0.142)\tData 0.052 (0.120)\tLoss 0.5960 (0.6412)\tAcc 0.750 (0.734)\n",
      "Epoch: [97][5/9]\tTime 0.074 (0.128)\tData 0.055 (0.107)\tLoss 0.8788 (0.6887)\tAcc 0.625 (0.713)\n",
      "Epoch: [97][6/9]\tTime 0.072 (0.119)\tData 0.054 (0.098)\tLoss 0.3141 (0.6263)\tAcc 1.000 (0.760)\n",
      "Epoch: [97][7/9]\tTime 0.073 (0.112)\tData 0.055 (0.092)\tLoss 0.7110 (0.6384)\tAcc 0.625 (0.741)\n",
      "Epoch: [97][8/9]\tTime 0.074 (0.108)\tData 0.056 (0.087)\tLoss 1.1795 (0.7060)\tAcc 0.438 (0.703)\n",
      "Epoch: [97][9/9]\tTime 0.073 (0.104)\tData 0.055 (0.084)\tLoss 0.2573 (0.6991)\tAcc 1.000 (0.708)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.397 (0.397)\tData 0.370 (0.370)\tLoss 0.8016 (0.8016)\tAcc 0.688 (0.688)\n",
      "Epoch: [98][2/5]\tTime 0.075 (0.236)\tData 0.051 (0.211)\tLoss 0.8561 (0.8288)\tAcc 0.750 (0.719)\n",
      "Epoch: [98][3/5]\tTime 0.077 (0.183)\tData 0.054 (0.158)\tLoss 0.6730 (0.7769)\tAcc 0.750 (0.729)\n",
      "Epoch: [98][4/5]\tTime 0.076 (0.156)\tData 0.054 (0.132)\tLoss 0.6209 (0.7379)\tAcc 0.750 (0.734)\n",
      "Epoch: [98][5/5]\tTime 0.078 (0.141)\tData 0.056 (0.117)\tLoss 0.5664 (0.7167)\tAcc 0.778 (0.740)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.354 (0.354)\tData 0.331 (0.331)\tLoss 0.2945 (0.2945)\tAcc 0.875 (0.875)\n",
      "Epoch: [98][2/9]\tTime 0.072 (0.213)\tData 0.051 (0.191)\tLoss 1.0510 (0.6728)\tAcc 0.438 (0.656)\n",
      "Epoch: [98][3/9]\tTime 0.074 (0.167)\tData 0.052 (0.145)\tLoss 0.6162 (0.6539)\tAcc 0.812 (0.708)\n",
      "Epoch: [98][4/9]\tTime 0.072 (0.143)\tData 0.051 (0.121)\tLoss 0.7102 (0.6680)\tAcc 0.688 (0.703)\n",
      "Epoch: [98][5/9]\tTime 0.073 (0.129)\tData 0.054 (0.108)\tLoss 0.7315 (0.6807)\tAcc 0.688 (0.700)\n",
      "Epoch: [98][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.2505 (0.6090)\tAcc 1.000 (0.750)\n",
      "Epoch: [98][7/9]\tTime 0.072 (0.113)\tData 0.054 (0.092)\tLoss 0.5411 (0.5993)\tAcc 0.812 (0.759)\n",
      "Epoch: [98][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.088)\tLoss 1.1919 (0.6734)\tAcc 0.500 (0.727)\n",
      "Epoch: [98][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.084)\tLoss 0.1047 (0.6646)\tAcc 1.000 (0.731)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.320 (0.320)\tData 0.293 (0.293)\tLoss 0.7727 (0.7727)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][2/5]\tTime 0.075 (0.198)\tData 0.051 (0.172)\tLoss 0.7103 (0.7415)\tAcc 0.812 (0.750)\n",
      "Epoch: [99][3/5]\tTime 0.077 (0.157)\tData 0.053 (0.132)\tLoss 0.7314 (0.7382)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][4/5]\tTime 0.077 (0.137)\tData 0.054 (0.113)\tLoss 0.7946 (0.7523)\tAcc 0.688 (0.734)\n",
      "Epoch: [99][5/5]\tTime 0.078 (0.125)\tData 0.055 (0.101)\tLoss 0.4842 (0.7192)\tAcc 0.889 (0.753)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.375 (0.375)\tData 0.350 (0.350)\tLoss 0.2145 (0.2145)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.071 (0.223)\tData 0.050 (0.200)\tLoss 1.0398 (0.6271)\tAcc 0.500 (0.719)\n",
      "Epoch: [99][3/9]\tTime 0.075 (0.173)\tData 0.053 (0.151)\tLoss 0.6584 (0.6376)\tAcc 0.688 (0.708)\n",
      "Epoch: [99][4/9]\tTime 0.071 (0.148)\tData 0.052 (0.126)\tLoss 0.6778 (0.6476)\tAcc 0.625 (0.688)\n",
      "Epoch: [99][5/9]\tTime 0.074 (0.133)\tData 0.054 (0.112)\tLoss 0.9648 (0.7110)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][6/9]\tTime 0.073 (0.123)\tData 0.054 (0.102)\tLoss 0.1814 (0.6228)\tAcc 1.000 (0.740)\n",
      "Epoch: [99][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.6592 (0.6280)\tAcc 0.625 (0.723)\n",
      "Epoch: [99][8/9]\tTime 0.075 (0.111)\tData 0.056 (0.090)\tLoss 1.2422 (0.7047)\tAcc 0.500 (0.695)\n",
      "Epoch: [99][9/9]\tTime 0.072 (0.106)\tData 0.054 (0.086)\tLoss 0.2224 (0.6973)\tAcc 1.000 (0.700)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.374 (0.374)\tData 0.345 (0.345)\tLoss 0.5726 (0.5726)\tAcc 0.875 (0.875)\n",
      "Epoch: [100][2/5]\tTime 0.074 (0.224)\tData 0.049 (0.197)\tLoss 0.5826 (0.5776)\tAcc 0.875 (0.875)\n",
      "Epoch: [100][3/5]\tTime 0.075 (0.174)\tData 0.052 (0.149)\tLoss 0.9590 (0.7047)\tAcc 0.688 (0.812)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.077 (0.150)\tData 0.054 (0.125)\tLoss 0.7274 (0.7104)\tAcc 0.812 (0.812)\n",
      "Epoch: [100][5/5]\tTime 0.078 (0.136)\tData 0.055 (0.111)\tLoss 1.2628 (0.7785)\tAcc 0.444 (0.767)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.377 (0.377)\tData 0.353 (0.353)\tLoss 0.2381 (0.2381)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.072 (0.224)\tData 0.050 (0.202)\tLoss 1.1047 (0.6714)\tAcc 0.562 (0.750)\n",
      "Epoch: [100][3/9]\tTime 0.075 (0.174)\tData 0.052 (0.152)\tLoss 0.5354 (0.6261)\tAcc 0.812 (0.771)\n",
      "Epoch: [100][4/9]\tTime 0.071 (0.148)\tData 0.051 (0.127)\tLoss 0.6652 (0.6358)\tAcc 0.688 (0.750)\n",
      "Epoch: [100][5/9]\tTime 0.075 (0.134)\tData 0.055 (0.112)\tLoss 0.8218 (0.6730)\tAcc 0.688 (0.738)\n",
      "Epoch: [100][6/9]\tTime 0.073 (0.124)\tData 0.054 (0.103)\tLoss 0.2166 (0.5970)\tAcc 1.000 (0.781)\n",
      "Epoch: [100][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.096)\tLoss 0.6918 (0.6105)\tAcc 0.625 (0.759)\n",
      "Epoch: [100][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.091)\tLoss 1.0715 (0.6681)\tAcc 0.500 (0.727)\n",
      "Epoch: [100][9/9]\tTime 0.073 (0.107)\tData 0.054 (0.087)\tLoss 0.1456 (0.6601)\tAcc 1.000 (0.731)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:51.004268Z",
     "start_time": "2020-03-26T02:01:50.972567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:51.015046Z",
     "start_time": "2020-03-26T02:01:51.006363Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.882108Z",
     "start_time": "2020-03-26T02:01:51.016268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.911612Z",
     "start_time": "2020-03-26T02:01:56.883245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 1.9097319841384888},\n",
       " {'label': 'none', 'score': 1.9097319841384888},\n",
       " {'label': 'none', 'score': 1.9097319841384888},\n",
       " {'label': 'none', 'score': 2.112319231033325},\n",
       " {'label': 'none', 'score': 2.112319231033325},\n",
       " {'label': 'none', 'score': 2.112319231033325},\n",
       " {'label': 'none', 'score': 1.9766334295272827},\n",
       " {'label': 'none', 'score': 1.9766334295272827},\n",
       " {'label': 'none', 'score': 1.9766334295272827},\n",
       " {'label': 'none', 'score': 1.9380890130996704},\n",
       " {'label': 'none', 'score': 1.9380890130996704},\n",
       " {'label': 'none', 'score': 1.9380890130996704},\n",
       " {'label': 'none', 'score': 2.0319652557373047},\n",
       " {'label': 'none', 'score': 2.0319652557373047},\n",
       " {'label': 'none', 'score': 2.0319652557373047},\n",
       " {'label': 'none', 'score': 2.014137029647827},\n",
       " {'label': 'none', 'score': 2.014137029647827},\n",
       " {'label': 'none', 'score': 2.014137029647827},\n",
       " {'label': 'none', 'score': 2.0617408752441406},\n",
       " {'label': 'none', 'score': 2.0617408752441406},\n",
       " {'label': 'none', 'score': 2.0617408752441406},\n",
       " {'label': 'none', 'score': 1.996951699256897},\n",
       " {'label': 'none', 'score': 1.996951699256897},\n",
       " {'label': 'none', 'score': 1.996951699256897},\n",
       " {'label': 'none', 'score': 1.7878860235214233},\n",
       " {'label': 'none', 'score': 1.7878860235214233},\n",
       " {'label': 'none', 'score': 1.7878860235214233},\n",
       " {'label': 'none', 'score': 1.9469271898269653},\n",
       " {'label': 'none', 'score': 1.9469271898269653},\n",
       " {'label': 'none', 'score': 1.9469271898269653},\n",
       " {'label': 'none', 'score': 1.77041494846344},\n",
       " {'label': 'none', 'score': 1.77041494846344},\n",
       " {'label': 'none', 'score': 1.77041494846344},\n",
       " {'label': 'none', 'score': 1.6724140644073486},\n",
       " {'label': 'none', 'score': 1.6724140644073486},\n",
       " {'label': 'none', 'score': 1.6724140644073486},\n",
       " {'label': 'none', 'score': 2.056701183319092},\n",
       " {'label': 'none', 'score': 2.056701183319092},\n",
       " {'label': 'none', 'score': 2.056701183319092},\n",
       " {'label': 'none', 'score': 1.7125946283340454},\n",
       " {'label': 'none', 'score': 1.7125946283340454},\n",
       " {'label': 'none', 'score': 1.7125946283340454},\n",
       " {'label': 'none', 'score': 1.3978856801986694},\n",
       " {'label': 'none', 'score': 1.3978856801986694},\n",
       " {'label': 'none', 'score': 1.3978856801986694},\n",
       " {'label': 'none', 'score': 1.6564680337905884},\n",
       " {'label': 'none', 'score': 1.6564680337905884},\n",
       " {'label': 'none', 'score': 1.6564680337905884},\n",
       " {'label': 'none', 'score': 2.0530755519866943},\n",
       " {'label': 'none', 'score': 2.0530755519866943},\n",
       " {'label': 'none', 'score': 2.0530755519866943},\n",
       " {'label': 'none', 'score': 1.6779136657714844},\n",
       " {'label': 'none', 'score': 1.6779136657714844},\n",
       " {'label': 'none', 'score': 1.6779136657714844},\n",
       " {'label': 'none', 'score': 2.564612865447998},\n",
       " {'label': 'none', 'score': 2.564612865447998},\n",
       " {'label': 'none', 'score': 2.564612865447998},\n",
       " {'label': 'none', 'score': 1.916752815246582},\n",
       " {'label': 'none', 'score': 1.916752815246582},\n",
       " {'label': 'none', 'score': 1.916752815246582},\n",
       " {'label': 'none', 'score': 2.087873697280884},\n",
       " {'label': 'none', 'score': 2.087873697280884},\n",
       " {'label': 'none', 'score': 2.087873697280884},\n",
       " {'label': 'none', 'score': 1.7991769313812256},\n",
       " {'label': 'none', 'score': 1.7991769313812256},\n",
       " {'label': 'none', 'score': 1.7991769313812256},\n",
       " {'label': 'returning', 'score': 1.368032455444336},\n",
       " {'label': 'returning', 'score': 1.368032455444336},\n",
       " {'label': 'returning', 'score': 1.368032455444336},\n",
       " {'label': 'returning', 'score': 0.5302795767784119},\n",
       " {'label': 'returning', 'score': 0.5302795767784119},\n",
       " {'label': 'returning', 'score': 0.5302795767784119},\n",
       " {'label': 'returning', 'score': 0.7260876893997192},\n",
       " {'label': 'returning', 'score': 0.7260876893997192},\n",
       " {'label': 'returning', 'score': 0.7260876893997192},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.3917143642902374},\n",
       " {'label': 'returning', 'score': 0.3917143642902374},\n",
       " {'label': 'returning', 'score': 0.3917143642902374},\n",
       " {'label': 'returning', 'score': 0.3738313317298889},\n",
       " {'label': 'returning', 'score': 0.3738313317298889},\n",
       " {'label': 'returning', 'score': 0.3738313317298889},\n",
       " {'label': 'returning', 'score': 0.9047914147377014},\n",
       " {'label': 'returning', 'score': 0.9047914147377014},\n",
       " {'label': 'returning', 'score': 0.9047914147377014},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.2477730512619019},\n",
       " {'label': 'none', 'score': 1.2477730512619019},\n",
       " {'label': 'none', 'score': 1.2477730512619019},\n",
       " {'label': 'none', 'score': 2.007840871810913},\n",
       " {'label': 'none', 'score': 2.007840871810913},\n",
       " {'label': 'none', 'score': 2.007840871810913},\n",
       " {'label': 'none', 'score': 2.180107593536377},\n",
       " {'label': 'none', 'score': 2.180107593536377},\n",
       " {'label': 'none', 'score': 2.180107593536377},\n",
       " {'label': 'none', 'score': 2.148731231689453},\n",
       " {'label': 'none', 'score': 2.148731231689453},\n",
       " {'label': 'none', 'score': 2.148731231689453},\n",
       " {'label': 'none', 'score': 1.657326340675354},\n",
       " {'label': 'none', 'score': 1.657326340675354},\n",
       " {'label': 'none', 'score': 1.657326340675354},\n",
       " {'label': 'none', 'score': 1.5916391611099243},\n",
       " {'label': 'none', 'score': 1.5916391611099243},\n",
       " {'label': 'none', 'score': 1.5916391611099243},\n",
       " {'label': 'none', 'score': 1.926905870437622},\n",
       " {'label': 'none', 'score': 1.926905870437622},\n",
       " {'label': 'none', 'score': 1.926905870437622},\n",
       " {'label': 'none', 'score': 2.149308919906616},\n",
       " {'label': 'none', 'score': 2.149308919906616},\n",
       " {'label': 'none', 'score': 2.149308919906616},\n",
       " {'label': 'none', 'score': 2.010338544845581},\n",
       " {'label': 'none', 'score': 2.010338544845581},\n",
       " {'label': 'none', 'score': 2.010338544845581},\n",
       " {'label': 'none', 'score': 2.8376879692077637},\n",
       " {'label': 'none', 'score': 2.8376879692077637},\n",
       " {'label': 'none', 'score': 2.8376879692077637},\n",
       " {'label': 'none', 'score': 2.324779510498047},\n",
       " {'label': 'none', 'score': 2.324779510498047},\n",
       " {'label': 'none', 'score': 2.324779510498047},\n",
       " {'label': 'none', 'score': 2.342946767807007},\n",
       " {'label': 'none', 'score': 2.342946767807007},\n",
       " {'label': 'none', 'score': 2.342946767807007},\n",
       " {'label': 'none', 'score': 1.9594385623931885},\n",
       " {'label': 'none', 'score': 1.9594385623931885},\n",
       " {'label': 'none', 'score': 1.9594385623931885},\n",
       " {'label': 'none', 'score': 1.7527642250061035},\n",
       " {'label': 'none', 'score': 1.7527642250061035},\n",
       " {'label': 'none', 'score': 1.7527642250061035},\n",
       " {'label': 'none', 'score': 2.0283727645874023},\n",
       " {'label': 'none', 'score': 2.0283727645874023},\n",
       " {'label': 'none', 'score': 2.0283727645874023},\n",
       " {'label': 'none', 'score': 2.3431613445281982},\n",
       " {'label': 'none', 'score': 2.3431613445281982},\n",
       " {'label': 'none', 'score': 2.3431613445281982},\n",
       " {'label': 'none', 'score': 2.1342270374298096},\n",
       " {'label': 'none', 'score': 2.1342270374298096},\n",
       " {'label': 'none', 'score': 2.1342270374298096},\n",
       " {'label': 'none', 'score': 2.135063409805298},\n",
       " {'label': 'none', 'score': 2.135063409805298},\n",
       " {'label': 'none', 'score': 2.135063409805298},\n",
       " {'label': 'returning', 'score': 0.7844434976577759},\n",
       " {'label': 'returning', 'score': 0.7844434976577759},\n",
       " {'label': 'returning', 'score': 0.7844434976577759},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.2745773196220398},\n",
       " {'label': 'returning', 'score': 0.2745773196220398},\n",
       " {'label': 'returning', 'score': 0.2745773196220398},\n",
       " {'label': 'returning', 'score': 0.6294155120849609},\n",
       " {'label': 'returning', 'score': 0.6294155120849609},\n",
       " {'label': 'returning', 'score': 0.6294155120849609},\n",
       " {'label': 'returning', 'score': 0.6465010643005371},\n",
       " {'label': 'returning', 'score': 0.6465010643005371},\n",
       " {'label': 'returning', 'score': 0.6465010643005371},\n",
       " {'label': 'returning', 'score': 0.35210567712783813},\n",
       " {'label': 'returning', 'score': 0.35210567712783813},\n",
       " {'label': 'returning', 'score': 0.35210567712783813},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 0.4723212718963623},\n",
       " {'label': 'leaving', 'score': 0.4723212718963623},\n",
       " {'label': 'leaving', 'score': 0.4723212718963623},\n",
       " {'label': 'returning', 'score': 0.9852021932601929},\n",
       " {'label': 'returning', 'score': 0.9852021932601929},\n",
       " {'label': 'returning', 'score': 0.9852021932601929},\n",
       " {'label': 'returning', 'score': 1.4157716035842896},\n",
       " {'label': 'returning', 'score': 1.4157716035842896},\n",
       " {'label': 'returning', 'score': 1.4157716035842896},\n",
       " {'label': 'none', 'score': 1.6932176351547241},\n",
       " {'label': 'none', 'score': 1.6932176351547241},\n",
       " {'label': 'none', 'score': 1.6932176351547241},\n",
       " {'label': 'none', 'score': 1.5598224401474},\n",
       " {'label': 'none', 'score': 1.5598224401474},\n",
       " {'label': 'none', 'score': 1.5598224401474},\n",
       " {'label': 'none', 'score': 2.1889960765838623},\n",
       " {'label': 'none', 'score': 2.1889960765838623},\n",
       " {'label': 'none', 'score': 2.1889960765838623},\n",
       " {'label': 'none', 'score': 2.333204984664917},\n",
       " {'label': 'none', 'score': 2.333204984664917},\n",
       " {'label': 'none', 'score': 2.333204984664917},\n",
       " {'label': 'none', 'score': 1.2708044052124023},\n",
       " {'label': 'none', 'score': 1.2708044052124023},\n",
       " {'label': 'none', 'score': 1.2708044052124023},\n",
       " {'label': 'none', 'score': 1.7820996046066284},\n",
       " {'label': 'none', 'score': 1.7820996046066284},\n",
       " {'label': 'none', 'score': 1.7820996046066284},\n",
       " {'label': 'none', 'score': 2.1311697959899902},\n",
       " {'label': 'none', 'score': 2.1311697959899902},\n",
       " {'label': 'none', 'score': 2.1311697959899902},\n",
       " {'label': 'none', 'score': 1.9328993558883667},\n",
       " {'label': 'none', 'score': 1.9328993558883667},\n",
       " {'label': 'none', 'score': 1.9328993558883667},\n",
       " {'label': 'none', 'score': 1.854978322982788},\n",
       " {'label': 'none', 'score': 1.854978322982788},\n",
       " {'label': 'none', 'score': 1.854978322982788},\n",
       " {'label': 'none', 'score': 1.7480648756027222},\n",
       " {'label': 'none', 'score': 1.7480648756027222},\n",
       " {'label': 'none', 'score': 1.7480648756027222},\n",
       " {'label': 'none', 'score': 1.9386334419250488},\n",
       " {'label': 'none', 'score': 1.9386334419250488},\n",
       " {'label': 'none', 'score': 1.9386334419250488},\n",
       " {'label': 'none', 'score': 2.311129331588745},\n",
       " {'label': 'none', 'score': 2.311129331588745},\n",
       " {'label': 'none', 'score': 2.311129331588745},\n",
       " {'label': 'none', 'score': 2.167341470718384},\n",
       " {'label': 'none', 'score': 2.167341470718384},\n",
       " {'label': 'none', 'score': 2.167341470718384},\n",
       " {'label': 'none', 'score': 2.1786649227142334},\n",
       " {'label': 'none', 'score': 2.1786649227142334},\n",
       " {'label': 'none', 'score': 2.1786649227142334},\n",
       " {'label': 'none', 'score': 1.535245656967163},\n",
       " {'label': 'none', 'score': 1.535245656967163},\n",
       " {'label': 'none', 'score': 1.535245656967163},\n",
       " {'label': 'none', 'score': 2.1977741718292236},\n",
       " {'label': 'none', 'score': 2.1977741718292236},\n",
       " {'label': 'none', 'score': 2.1977741718292236},\n",
       " {'label': 'none', 'score': 2.1438043117523193},\n",
       " {'label': 'none', 'score': 2.1438043117523193},\n",
       " {'label': 'none', 'score': 2.1438043117523193},\n",
       " {'label': 'none', 'score': 1.7931758165359497},\n",
       " {'label': 'none', 'score': 1.7931758165359497},\n",
       " {'label': 'none', 'score': 1.7931758165359497},\n",
       " {'label': 'none', 'score': 2.0770843029022217},\n",
       " {'label': 'none', 'score': 2.0770843029022217},\n",
       " {'label': 'none', 'score': 2.0770843029022217},\n",
       " {'label': 'returning', 'score': 2.1861352920532227},\n",
       " {'label': 'returning', 'score': 2.1861352920532227},\n",
       " {'label': 'returning', 'score': 2.1861352920532227},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.6157917976379395},\n",
       " {'label': 'returning', 'score': 0.6157917976379395},\n",
       " {'label': 'returning', 'score': 0.6157917976379395},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.42211031913757324},\n",
       " {'label': 'returning', 'score': 0.42211031913757324},\n",
       " {'label': 'returning', 'score': 0.42211031913757324},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.2515283823013306},\n",
       " {'label': 'none', 'score': 1.2515283823013306},\n",
       " {'label': 'none', 'score': 1.2515283823013306},\n",
       " {'label': 'none', 'score': 1.6756309270858765},\n",
       " {'label': 'none', 'score': 1.6756309270858765},\n",
       " {'label': 'none', 'score': 1.6756309270858765},\n",
       " {'label': 'none', 'score': 1.7643380165100098},\n",
       " {'label': 'none', 'score': 1.7643380165100098},\n",
       " {'label': 'none', 'score': 1.7643380165100098},\n",
       " {'label': 'none', 'score': 2.0875978469848633},\n",
       " {'label': 'none', 'score': 2.0875978469848633},\n",
       " {'label': 'none', 'score': 2.0875978469848633},\n",
       " {'label': 'none', 'score': 2.1030218601226807},\n",
       " {'label': 'none', 'score': 2.1030218601226807},\n",
       " {'label': 'none', 'score': 2.1030218601226807},\n",
       " {'label': 'none', 'score': 2.0539543628692627},\n",
       " {'label': 'none', 'score': 2.0539543628692627},\n",
       " {'label': 'none', 'score': 2.0539543628692627},\n",
       " {'label': 'none', 'score': 2.606565475463867},\n",
       " {'label': 'none', 'score': 2.606565475463867},\n",
       " {'label': 'none', 'score': 2.606565475463867},\n",
       " {'label': 'none', 'score': 2.055335283279419},\n",
       " {'label': 'none', 'score': 2.055335283279419},\n",
       " {'label': 'none', 'score': 2.055335283279419},\n",
       " {'label': 'none', 'score': 1.86920964717865},\n",
       " {'label': 'none', 'score': 1.86920964717865},\n",
       " {'label': 'none', 'score': 1.86920964717865},\n",
       " {'label': 'none', 'score': 1.843523621559143},\n",
       " {'label': 'none', 'score': 1.843523621559143},\n",
       " {'label': 'none', 'score': 1.843523621559143},\n",
       " {'label': 'none', 'score': 2.080383062362671},\n",
       " {'label': 'none', 'score': 2.080383062362671},\n",
       " {'label': 'none', 'score': 2.080383062362671},\n",
       " {'label': 'none', 'score': 1.9775809049606323},\n",
       " {'label': 'none', 'score': 1.9775809049606323},\n",
       " {'label': 'none', 'score': 1.9775809049606323},\n",
       " {'label': 'none', 'score': 1.8155103921890259},\n",
       " {'label': 'none', 'score': 1.8155103921890259},\n",
       " {'label': 'none', 'score': 1.8155103921890259},\n",
       " {'label': 'none', 'score': 2.4065394401550293},\n",
       " {'label': 'none', 'score': 2.4065394401550293},\n",
       " {'label': 'none', 'score': 2.4065394401550293},\n",
       " {'label': 'none', 'score': 1.779424786567688},\n",
       " {'label': 'none', 'score': 1.779424786567688},\n",
       " {'label': 'none', 'score': 1.779424786567688},\n",
       " {'label': 'none', 'score': 1.6999332904815674},\n",
       " {'label': 'none', 'score': 1.6999332904815674},\n",
       " {'label': 'none', 'score': 1.6999332904815674},\n",
       " {'label': 'none', 'score': 2.4682092666625977},\n",
       " {'label': 'none', 'score': 2.4682092666625977},\n",
       " {'label': 'none', 'score': 2.4682092666625977},\n",
       " {'label': 'none', 'score': 2.010570764541626},\n",
       " {'label': 'none', 'score': 2.010570764541626},\n",
       " {'label': 'none', 'score': 2.010570764541626},\n",
       " {'label': 'none', 'score': 1.2322533130645752},\n",
       " {'label': 'none', 'score': 1.2322533130645752},\n",
       " {'label': 'none', 'score': 1.2322533130645752},\n",
       " {'label': 'none', 'score': 1.612047553062439},\n",
       " {'label': 'none', 'score': 1.612047553062439},\n",
       " {'label': 'none', 'score': 1.612047553062439},\n",
       " {'label': 'returning', 'score': 0.30619531869888306},\n",
       " {'label': 'returning', 'score': 0.30619531869888306},\n",
       " {'label': 'returning', 'score': 0.30619531869888306},\n",
       " {'label': 'returning', 'score': 0.5462360978126526},\n",
       " {'label': 'returning', 'score': 0.5462360978126526},\n",
       " {'label': 'returning', 'score': 0.5462360978126526},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.40117430686950684},\n",
       " {'label': 'returning', 'score': 0.40117430686950684},\n",
       " {'label': 'returning', 'score': 0.40117430686950684},\n",
       " {'label': 'returning', 'score': 0.7641315460205078},\n",
       " {'label': 'returning', 'score': 0.7641315460205078},\n",
       " {'label': 'returning', 'score': 0.7641315460205078},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.2869981527328491},\n",
       " {'label': 'returning', 'score': 1.2869981527328491},\n",
       " {'label': 'returning', 'score': 1.2869981527328491},\n",
       " {'label': 'none', 'score': 2.305610179901123},\n",
       " {'label': 'none', 'score': 2.305610179901123},\n",
       " {'label': 'none', 'score': 2.305610179901123},\n",
       " {'label': 'none', 'score': 1.9996501207351685},\n",
       " {'label': 'none', 'score': 1.9996501207351685},\n",
       " {'label': 'none', 'score': 1.9996501207351685},\n",
       " {'label': 'none', 'score': 2.8792948722839355},\n",
       " {'label': 'none', 'score': 2.8792948722839355},\n",
       " {'label': 'none', 'score': 2.8792948722839355},\n",
       " {'label': 'none', 'score': 1.6884486675262451},\n",
       " {'label': 'none', 'score': 1.6884486675262451},\n",
       " {'label': 'none', 'score': 1.6884486675262451},\n",
       " {'label': 'none', 'score': 1.5687357187271118},\n",
       " {'label': 'none', 'score': 1.5687357187271118},\n",
       " {'label': 'none', 'score': 1.5687357187271118},\n",
       " {'label': 'none', 'score': 1.9417873620986938},\n",
       " {'label': 'none', 'score': 1.9417873620986938},\n",
       " {'label': 'none', 'score': 1.9417873620986938},\n",
       " {'label': 'none', 'score': 2.11727237701416},\n",
       " {'label': 'none', 'score': 2.11727237701416},\n",
       " {'label': 'none', 'score': 2.11727237701416},\n",
       " {'label': 'none', 'score': 2.198655128479004},\n",
       " {'label': 'none', 'score': 2.198655128479004},\n",
       " {'label': 'none', 'score': 2.198655128479004},\n",
       " {'label': 'none', 'score': 1.7533061504364014},\n",
       " {'label': 'none', 'score': 1.7533061504364014},\n",
       " {'label': 'none', 'score': 1.7533061504364014},\n",
       " {'label': 'none', 'score': 2.1142876148223877},\n",
       " {'label': 'none', 'score': 2.1142876148223877},\n",
       " {'label': 'none', 'score': 2.1142876148223877},\n",
       " {'label': 'none', 'score': 2.236494779586792},\n",
       " {'label': 'none', 'score': 2.236494779586792},\n",
       " {'label': 'none', 'score': 2.236494779586792},\n",
       " {'label': 'none', 'score': 2.3443143367767334},\n",
       " {'label': 'none', 'score': 2.3443143367767334},\n",
       " {'label': 'none', 'score': 2.3443143367767334},\n",
       " {'label': 'none', 'score': 2.371044158935547},\n",
       " {'label': 'none', 'score': 2.371044158935547},\n",
       " {'label': 'none', 'score': 2.371044158935547},\n",
       " {'label': 'none', 'score': 1.798768401145935},\n",
       " {'label': 'none', 'score': 1.798768401145935},\n",
       " {'label': 'none', 'score': 1.798768401145935},\n",
       " {'label': 'none', 'score': 2.227527141571045},\n",
       " {'label': 'none', 'score': 2.227527141571045},\n",
       " {'label': 'none', 'score': 2.227527141571045},\n",
       " {'label': 'none', 'score': 1.8035515546798706},\n",
       " {'label': 'none', 'score': 1.8035515546798706},\n",
       " {'label': 'none', 'score': 1.8035515546798706},\n",
       " {'label': 'none', 'score': 1.8368452787399292},\n",
       " {'label': 'none', 'score': 1.8368452787399292},\n",
       " {'label': 'none', 'score': 1.8368452787399292},\n",
       " {'label': 'none', 'score': 2.0528032779693604},\n",
       " {'label': 'none', 'score': 2.0528032779693604},\n",
       " {'label': 'none', 'score': 2.0528032779693604},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 1.0005487203598022},\n",
       " {'label': 'none', 'score': 0.9589710235595703},\n",
       " {'label': 'none', 'score': 0.9589710235595703},\n",
       " {'label': 'none', 'score': 0.9589710235595703},\n",
       " {'label': 'none', 'score': 1.8561509847640991},\n",
       " {'label': 'none', 'score': 1.8561509847640991},\n",
       " {'label': 'none', 'score': 1.8561509847640991},\n",
       " {'label': 'none', 'score': 2.0528252124786377},\n",
       " {'label': 'none', 'score': 2.0528252124786377},\n",
       " {'label': 'none', 'score': 2.0528252124786377},\n",
       " {'label': 'none', 'score': 2.2433316707611084},\n",
       " {'label': 'none', 'score': 2.2433316707611084},\n",
       " {'label': 'none', 'score': 2.2433316707611084},\n",
       " {'label': 'none', 'score': 2.2453083992004395},\n",
       " {'label': 'none', 'score': 2.2453083992004395},\n",
       " {'label': 'none', 'score': 2.2453083992004395},\n",
       " {'label': 'none', 'score': 1.656292200088501},\n",
       " {'label': 'none', 'score': 1.656292200088501},\n",
       " {'label': 'none', 'score': 1.656292200088501},\n",
       " {'label': 'none', 'score': 2.305608034133911},\n",
       " {'label': 'none', 'score': 2.305608034133911},\n",
       " {'label': 'none', 'score': 2.305608034133911},\n",
       " {'label': 'none', 'score': 1.4581083059310913},\n",
       " {'label': 'none', 'score': 1.4581083059310913},\n",
       " {'label': 'none', 'score': 1.4581083059310913},\n",
       " {'label': 'none', 'score': 2.264552593231201},\n",
       " {'label': 'none', 'score': 2.264552593231201},\n",
       " {'label': 'none', 'score': 2.264552593231201},\n",
       " {'label': 'returning', 'score': 0.9703460931777954},\n",
       " {'label': 'returning', 'score': 0.9703460931777954},\n",
       " {'label': 'returning', 'score': 0.9703460931777954},\n",
       " {'label': 'none', 'score': 1.0815683603286743},\n",
       " {'label': 'none', 'score': 1.0815683603286743},\n",
       " {'label': 'none', 'score': 1.0815683603286743},\n",
       " {'label': 'returning', 'score': 1.2621663808822632},\n",
       " {'label': 'returning', 'score': 1.2621663808822632},\n",
       " {'label': 'returning', 'score': 1.2621663808822632},\n",
       " {'label': 'returning', 'score': 0.40265220403671265},\n",
       " {'label': 'returning', 'score': 0.40265220403671265},\n",
       " {'label': 'returning', 'score': 0.40265220403671265},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.6775474548339844},\n",
       " {'label': 'leaving', 'score': 1.6775474548339844},\n",
       " {'label': 'leaving', 'score': 1.6775474548339844},\n",
       " {'label': 'none', 'score': 1.9942203760147095},\n",
       " {'label': 'none', 'score': 1.9942203760147095},\n",
       " {'label': 'none', 'score': 1.9942203760147095},\n",
       " {'label': 'none', 'score': 2.104264736175537},\n",
       " {'label': 'none', 'score': 2.104264736175537},\n",
       " {'label': 'none', 'score': 2.104264736175537},\n",
       " {'label': 'none', 'score': 1.9761945009231567},\n",
       " {'label': 'none', 'score': 1.9761945009231567},\n",
       " {'label': 'none', 'score': 1.9761945009231567},\n",
       " {'label': 'none', 'score': 2.1751515865325928},\n",
       " {'label': 'none', 'score': 2.1751515865325928},\n",
       " {'label': 'none', 'score': 2.1751515865325928},\n",
       " {'label': 'none', 'score': 2.2555742263793945},\n",
       " {'label': 'none', 'score': 2.2555742263793945},\n",
       " {'label': 'none', 'score': 2.2555742263793945},\n",
       " {'label': 'none', 'score': 1.9533501863479614},\n",
       " {'label': 'none', 'score': 1.9533501863479614},\n",
       " {'label': 'none', 'score': 1.9533501863479614},\n",
       " {'label': 'none', 'score': 2.286816120147705},\n",
       " {'label': 'none', 'score': 2.286816120147705},\n",
       " {'label': 'none', 'score': 2.286816120147705},\n",
       " {'label': 'none', 'score': 1.743895411491394},\n",
       " {'label': 'none', 'score': 1.743895411491394},\n",
       " {'label': 'none', 'score': 1.743895411491394},\n",
       " {'label': 'none', 'score': 1.8934638500213623},\n",
       " {'label': 'none', 'score': 1.8934638500213623},\n",
       " {'label': 'none', 'score': 1.8934638500213623},\n",
       " {'label': 'none', 'score': 1.8601138591766357},\n",
       " {'label': 'none', 'score': 1.8601138591766357},\n",
       " {'label': 'none', 'score': 1.8601138591766357},\n",
       " {'label': 'returning', 'score': 0.5401248335838318},\n",
       " {'label': 'returning', 'score': 0.5401248335838318},\n",
       " {'label': 'returning', 'score': 0.5401248335838318},\n",
       " {'label': 'returning', 'score': 1.1322635412216187},\n",
       " {'label': 'returning', 'score': 1.1322635412216187},\n",
       " {'label': 'returning', 'score': 1.1322635412216187},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'leaving', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.49750518798828125},\n",
       " {'label': 'returning', 'score': 0.49750518798828125},\n",
       " {'label': 'returning', 'score': 0.49750518798828125},\n",
       " {'label': 'returning', 'score': 0.4815993309020996},\n",
       " {'label': 'returning', 'score': 0.4815993309020996},\n",
       " {'label': 'returning', 'score': 0.4815993309020996},\n",
       " {'label': 'returning', 'score': 0.6744791269302368},\n",
       " {'label': 'returning', 'score': 0.6744791269302368},\n",
       " {'label': 'returning', 'score': 0.6744791269302368},\n",
       " {'label': 'returning', 'score': 0.49008801579475403},\n",
       " {'label': 'returning', 'score': 0.49008801579475403},\n",
       " {'label': 'returning', 'score': 0.49008801579475403},\n",
       " {'label': 'none', 'score': 1.8575663566589355},\n",
       " {'label': 'none', 'score': 1.8575663566589355},\n",
       " {'label': 'none', 'score': 1.8575663566589355},\n",
       " {'label': 'none', 'score': 1.786882758140564},\n",
       " {'label': 'none', 'score': 1.786882758140564},\n",
       " {'label': 'none', 'score': 1.786882758140564},\n",
       " {'label': 'none', 'score': 2.1053056716918945},\n",
       " {'label': 'none', 'score': 2.1053056716918945},\n",
       " {'label': 'none', 'score': 2.1053056716918945},\n",
       " {'label': 'none', 'score': 1.5294791460037231},\n",
       " {'label': 'none', 'score': 1.5294791460037231},\n",
       " {'label': 'none', 'score': 1.5294791460037231},\n",
       " {'label': 'none', 'score': 2.1636834144592285},\n",
       " {'label': 'none', 'score': 2.1636834144592285},\n",
       " {'label': 'none', 'score': 2.1636834144592285},\n",
       " {'label': 'none', 'score': 1.9849145412445068},\n",
       " {'label': 'none', 'score': 1.9849145412445068},\n",
       " {'label': 'none', 'score': 1.9849145412445068},\n",
       " {'label': 'none', 'score': 2.124459981918335},\n",
       " {'label': 'none', 'score': 2.124459981918335},\n",
       " {'label': 'none', 'score': 2.124459981918335},\n",
       " {'label': 'none', 'score': 1.9802504777908325},\n",
       " {'label': 'none', 'score': 1.9802504777908325},\n",
       " {'label': 'none', 'score': 1.9802504777908325},\n",
       " {'label': 'none', 'score': 2.293849468231201},\n",
       " {'label': 'none', 'score': 2.293849468231201},\n",
       " {'label': 'none', 'score': 2.293849468231201},\n",
       " {'label': 'none', 'score': 2.7213268280029297},\n",
       " {'label': 'none', 'score': 2.7213268280029297},\n",
       " {'label': 'none', 'score': 2.7213268280029297},\n",
       " {'label': 'none', 'score': 2.08058500289917},\n",
       " {'label': 'none', 'score': 2.08058500289917},\n",
       " {'label': 'none', 'score': 2.08058500289917},\n",
       " {'label': 'none', 'score': 1.8700450658798218},\n",
       " {'label': 'none', 'score': 1.8700450658798218},\n",
       " {'label': 'none', 'score': 1.8700450658798218},\n",
       " {'label': 'leaving', 'score': 1.4154880046844482},\n",
       " {'label': 'leaving', 'score': 1.4154880046844482},\n",
       " {'label': 'leaving', 'score': 1.4154880046844482},\n",
       " {'label': 'returning', 'score': 0.51637202501297},\n",
       " {'label': 'returning', 'score': 0.51637202501297},\n",
       " {'label': 'returning', 'score': 0.51637202501297},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.4498096704483032},\n",
       " {'label': 'returning', 'score': 0.4498096704483032},\n",
       " {'label': 'returning', 'score': 0.4498096704483032},\n",
       " {'label': 'returning', 'score': 0.36959487199783325},\n",
       " {'label': 'returning', 'score': 0.36959487199783325},\n",
       " {'label': 'returning', 'score': 0.36959487199783325},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 1.0005487203598022},\n",
       " {'label': 'returning', 'score': 0.27752918004989624},\n",
       " {'label': 'returning', 'score': 0.27752918004989624},\n",
       " {'label': 'returning', 'score': 0.27752918004989624},\n",
       " {'label': 'returning', 'score': 0.42818641662597656},\n",
       " {'label': 'returning', 'score': 0.42818641662597656},\n",
       " {'label': 'returning', 'score': 0.42818641662597656},\n",
       " {'label': 'returning', 'score': 1.0499128103256226},\n",
       " {'label': 'returning', 'score': 1.0499128103256226},\n",
       " {'label': 'returning', 'score': 1.0499128103256226},\n",
       " {'label': 'returning', 'score': 1.4914761781692505},\n",
       " {'label': 'returning', 'score': 1.4914761781692505},\n",
       " {'label': 'returning', 'score': 1.4914761781692505},\n",
       " {'label': 'none', 'score': 1.746036410331726},\n",
       " {'label': 'none', 'score': 1.746036410331726},\n",
       " {'label': 'none', 'score': 1.746036410331726},\n",
       " {'label': 'none', 'score': 2.0582034587860107},\n",
       " {'label': 'none', 'score': 2.0582034587860107},\n",
       " {'label': 'none', 'score': 2.0582034587860107},\n",
       " {'label': 'none', 'score': 2.383660078048706},\n",
       " {'label': 'none', 'score': 2.383660078048706},\n",
       " {'label': 'none', 'score': 2.383660078048706},\n",
       " {'label': 'none', 'score': 2.1806423664093018},\n",
       " {'label': 'none', 'score': 2.1806423664093018},\n",
       " {'label': 'none', 'score': 2.1806423664093018}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.923895Z",
     "start_time": "2020-03-26T02:01:56.912588Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " with open(os.path.join(results_path,'validation_results.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.933954Z",
     "start_time": "2020-03-26T02:01:56.924957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:57.304040Z",
     "start_time": "2020-03-26T02:01:56.935345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - ~~More diverse dataset~~ (2020-04-10)\n",
    "    - ~~Hyperparameter tuning~~ (2020-04-29)\n",
    "    - ~~Make video window overlapping~~ (2020-04-10)\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:03:56.668377Z",
     "start_time": "2020-03-26T02:03:56.516791Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/CSCE636-project-porta/porta.pth')\n",
    "torch.save(my_model.state_dict(), weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
