{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:36.788051Z",
     "start_time": "2020-03-26T01:58:36.777172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:38.327064Z",
     "start_time": "2020-03-26T01:58:36.789480Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.115192Z",
     "start_time": "2020-03-26T01:58:38.329032Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.133335Z",
     "start_time": "2020-03-26T01:58:41.121009Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.176786Z",
     "start_time": "2020-03-26T01:58:41.134624Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.190090Z",
     "start_time": "2020-03-26T01:58:41.178036Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.201452Z",
     "start_time": "2020-03-26T01:58:41.191196Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:41.211301Z",
     "start_time": "2020-03-26T01:58:41.203178Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.343691Z",
     "start_time": "2020-03-26T01:58:41.212544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.362178Z",
     "start_time": "2020-03-26T01:58:43.348427Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.373621Z",
     "start_time": "2020-03-26T01:58:43.363275Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.863045Z",
     "start_time": "2020-03-26T01:58:43.374604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:43.883712Z",
     "start_time": "2020-03-26T01:58:43.867836Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:44.640836Z",
     "start_time": "2020-03-26T01:58:43.884708Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.580124Z",
     "start_time": "2020-03-26T01:58:44.641957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.590905Z",
     "start_time": "2020-03-26T01:58:54.581423Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.604647Z",
     "start_time": "2020-03-26T01:58:54.592134Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 256), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.621755Z",
     "start_time": "2020-03-26T01:58:54.605731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.633288Z",
     "start_time": "2020-03-26T01:58:54.623116Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-2,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T01:58:54.702462Z",
     "start_time": "2020-03-26T01:58:54.634312Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:50.971317Z",
     "start_time": "2020-03-26T01:58:54.704552Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 3.061 (3.061)\tData 1.531 (1.531)\tLoss 1.0598 (1.0598)\tAcc 0.562 (0.562)\n",
      "Epoch: [1][2/5]\tTime 0.106 (1.583)\tData 0.075 (0.803)\tLoss 0.8903 (0.9750)\tAcc 0.812 (0.688)\n",
      "Epoch: [1][3/5]\tTime 0.091 (1.086)\tData 0.062 (0.556)\tLoss 1.1280 (1.0260)\tAcc 0.500 (0.625)\n",
      "Epoch: [1][4/5]\tTime 0.092 (0.837)\tData 0.062 (0.432)\tLoss 0.9989 (1.0192)\tAcc 0.625 (0.625)\n",
      "Epoch: [1][5/5]\tTime 0.085 (0.687)\tData 0.059 (0.358)\tLoss 0.5144 (0.9570)\tAcc 0.889 (0.658)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.471 (0.471)\tData 0.360 (0.360)\tLoss 0.5384 (0.5384)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.142 (0.307)\tData 0.109 (0.234)\tLoss 1.3248 (0.9316)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.085 (0.233)\tData 0.044 (0.171)\tLoss 0.9076 (0.9236)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.072 (0.193)\tData 0.039 (0.138)\tLoss 0.9280 (0.9247)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.081 (0.170)\tData 0.047 (0.120)\tLoss 0.8539 (0.9105)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.068 (0.153)\tData 0.044 (0.107)\tLoss 0.4322 (0.8308)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.072 (0.142)\tData 0.052 (0.099)\tLoss 0.5899 (0.7964)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.074 (0.133)\tData 0.054 (0.094)\tLoss 1.1681 (0.8428)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.073 (0.126)\tData 0.053 (0.089)\tLoss 0.4418 (0.8367)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.667 (0.667)\tData 0.604 (0.604)\tLoss 0.9414 (0.9414)\tAcc 0.625 (0.625)\n",
      "Epoch: [2][2/5]\tTime 0.078 (0.373)\tData 0.048 (0.326)\tLoss 1.1321 (1.0368)\tAcc 0.500 (0.562)\n",
      "Epoch: [2][3/5]\tTime 0.077 (0.274)\tData 0.048 (0.233)\tLoss 0.6749 (0.9162)\tAcc 0.750 (0.625)\n",
      "Epoch: [2][4/5]\tTime 0.084 (0.227)\tData 0.054 (0.189)\tLoss 0.7114 (0.8650)\tAcc 0.812 (0.672)\n",
      "Epoch: [2][5/5]\tTime 0.083 (0.198)\tData 0.056 (0.162)\tLoss 0.6604 (0.8397)\tAcc 0.778 (0.685)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.426 (0.426)\tData 0.355 (0.355)\tLoss 0.7338 (0.7338)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.078 (0.252)\tData 0.002 (0.178)\tLoss 1.1643 (0.9490)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.057 (0.187)\tData 0.002 (0.120)\tLoss 0.9030 (0.9337)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.050 (0.153)\tData 0.024 (0.096)\tLoss 0.9474 (0.9371)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.076 (0.138)\tData 0.051 (0.087)\tLoss 0.8878 (0.9273)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.076 (0.127)\tData 0.054 (0.081)\tLoss 0.6697 (0.8843)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.079 (0.120)\tData 0.057 (0.078)\tLoss 0.7430 (0.8641)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.079 (0.115)\tData 0.058 (0.075)\tLoss 1.0598 (0.8886)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.080 (0.111)\tData 0.058 (0.073)\tLoss 0.6451 (0.8848)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.799 (0.799)\tData 0.758 (0.758)\tLoss 0.7423 (0.7423)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][2/5]\tTime 0.082 (0.441)\tData 0.047 (0.403)\tLoss 0.6260 (0.6842)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][3/5]\tTime 0.082 (0.321)\tData 0.053 (0.286)\tLoss 0.6813 (0.6832)\tAcc 0.750 (0.708)\n",
      "Epoch: [3][4/5]\tTime 0.081 (0.261)\tData 0.055 (0.228)\tLoss 0.5016 (0.6378)\tAcc 0.875 (0.750)\n",
      "Epoch: [3][5/5]\tTime 0.084 (0.226)\tData 0.059 (0.195)\tLoss 1.2735 (0.7162)\tAcc 0.556 (0.726)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.371 (0.371)\tData 0.305 (0.305)\tLoss 0.6221 (0.6221)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.070 (0.221)\tData 0.019 (0.162)\tLoss 1.1141 (0.8681)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.084 (0.175)\tData 0.028 (0.117)\tLoss 0.9580 (0.8980)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.062 (0.147)\tData 0.022 (0.094)\tLoss 0.8480 (0.8855)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.081 (0.134)\tData 0.041 (0.083)\tLoss 0.9207 (0.8926)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.071 (0.123)\tData 0.041 (0.076)\tLoss 0.5640 (0.8378)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.073 (0.116)\tData 0.049 (0.072)\tLoss 0.6844 (0.8159)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.078 (0.111)\tData 0.056 (0.070)\tLoss 1.0955 (0.8508)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.079 (0.108)\tData 0.059 (0.069)\tLoss 0.5507 (0.8462)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.788 (0.788)\tData 0.723 (0.723)\tLoss 0.4717 (0.4717)\tAcc 0.812 (0.812)\n",
      "Epoch: [4][2/5]\tTime 0.069 (0.429)\tData 0.026 (0.375)\tLoss 0.8488 (0.6602)\tAcc 0.688 (0.750)\n",
      "Epoch: [4][3/5]\tTime 0.070 (0.309)\tData 0.042 (0.264)\tLoss 0.5188 (0.6131)\tAcc 0.750 (0.750)\n",
      "Epoch: [4][4/5]\tTime 0.084 (0.253)\tData 0.058 (0.212)\tLoss 0.4776 (0.5792)\tAcc 0.812 (0.766)\n",
      "Epoch: [4][5/5]\tTime 0.085 (0.219)\tData 0.058 (0.181)\tLoss 0.9902 (0.6299)\tAcc 0.556 (0.740)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.449 (0.449)\tData 0.379 (0.379)\tLoss 0.8842 (0.8842)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.045 (0.247)\tData 0.012 (0.195)\tLoss 1.2325 (1.0583)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.077 (0.190)\tData 0.043 (0.145)\tLoss 0.9286 (1.0151)\tAcc 0.750 (0.708)\n",
      "Epoch: [4][4/9]\tTime 0.070 (0.160)\tData 0.040 (0.118)\tLoss 1.0955 (1.0352)\tAcc 0.688 (0.703)\n",
      "Epoch: [4][5/9]\tTime 0.063 (0.141)\tData 0.042 (0.103)\tLoss 0.8814 (1.0044)\tAcc 0.750 (0.713)\n",
      "Epoch: [4][6/9]\tTime 0.075 (0.130)\tData 0.053 (0.095)\tLoss 0.8776 (0.9833)\tAcc 0.938 (0.750)\n",
      "Epoch: [4][7/9]\tTime 0.073 (0.122)\tData 0.052 (0.089)\tLoss 0.9976 (0.9853)\tAcc 0.688 (0.741)\n",
      "Epoch: [4][8/9]\tTime 0.074 (0.116)\tData 0.053 (0.084)\tLoss 1.0340 (0.9914)\tAcc 0.500 (0.711)\n",
      "Epoch: [4][9/9]\tTime 0.074 (0.111)\tData 0.052 (0.081)\tLoss 0.8553 (0.9893)\tAcc 1.000 (0.715)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.604 (0.604)\tData 0.541 (0.541)\tLoss 0.8341 (0.8341)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][2/5]\tTime 0.109 (0.356)\tData 0.029 (0.285)\tLoss 1.0116 (0.9229)\tAcc 0.625 (0.656)\n",
      "Epoch: [5][3/5]\tTime 0.047 (0.253)\tData 0.009 (0.193)\tLoss 1.0091 (0.9516)\tAcc 0.750 (0.688)\n",
      "Epoch: [5][4/5]\tTime 0.068 (0.207)\tData 0.042 (0.156)\tLoss 0.4987 (0.8384)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/5]\tTime 0.078 (0.181)\tData 0.053 (0.135)\tLoss 0.4561 (0.7913)\tAcc 0.778 (0.699)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.441 (0.441)\tData 0.381 (0.381)\tLoss 0.5848 (0.5848)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.084 (0.263)\tData 0.020 (0.201)\tLoss 1.2084 (0.8966)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.055 (0.193)\tData 0.016 (0.139)\tLoss 0.8892 (0.8941)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.074 (0.164)\tData 0.034 (0.113)\tLoss 0.9241 (0.9016)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.071 (0.145)\tData 0.036 (0.097)\tLoss 0.9104 (0.9034)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.061 (0.131)\tData 0.039 (0.088)\tLoss 0.5159 (0.8388)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.073 (0.123)\tData 0.051 (0.083)\tLoss 0.6746 (0.8153)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.077 (0.117)\tData 0.056 (0.079)\tLoss 1.1515 (0.8574)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.079 (0.113)\tData 0.058 (0.077)\tLoss 0.6104 (0.8536)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.529 (0.529)\tData 0.472 (0.472)\tLoss 0.8611 (0.8611)\tAcc 0.625 (0.625)\n",
      "Epoch: [6][2/5]\tTime 0.072 (0.300)\tData 0.022 (0.247)\tLoss 0.4112 (0.6362)\tAcc 0.750 (0.688)\n",
      "Epoch: [6][3/5]\tTime 0.067 (0.223)\tData 0.032 (0.175)\tLoss 0.8200 (0.6974)\tAcc 0.812 (0.729)\n",
      "Epoch: [6][4/5]\tTime 0.070 (0.185)\tData 0.044 (0.143)\tLoss 0.8841 (0.7441)\tAcc 0.688 (0.719)\n",
      "Epoch: [6][5/5]\tTime 0.078 (0.163)\tData 0.052 (0.125)\tLoss 0.9733 (0.7724)\tAcc 0.556 (0.699)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.402 (0.402)\tData 0.346 (0.346)\tLoss 0.8679 (0.8679)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.073 (0.237)\tData 0.025 (0.185)\tLoss 0.9726 (0.9203)\tAcc 0.812 (0.875)\n",
      "Epoch: [6][3/9]\tTime 0.052 (0.176)\tData 0.025 (0.132)\tLoss 1.0210 (0.9538)\tAcc 0.625 (0.792)\n",
      "Epoch: [6][4/9]\tTime 0.068 (0.149)\tData 0.046 (0.110)\tLoss 0.9341 (0.9489)\tAcc 0.812 (0.797)\n",
      "Epoch: [6][5/9]\tTime 0.073 (0.133)\tData 0.051 (0.098)\tLoss 1.0151 (0.9621)\tAcc 0.688 (0.775)\n",
      "Epoch: [6][6/9]\tTime 0.075 (0.124)\tData 0.053 (0.091)\tLoss 0.8722 (0.9472)\tAcc 0.938 (0.802)\n",
      "Epoch: [6][7/9]\tTime 0.074 (0.117)\tData 0.052 (0.085)\tLoss 0.8995 (0.9404)\tAcc 0.875 (0.813)\n",
      "Epoch: [6][8/9]\tTime 0.080 (0.112)\tData 0.054 (0.081)\tLoss 1.0819 (0.9580)\tAcc 0.500 (0.773)\n",
      "Epoch: [6][9/9]\tTime 0.077 (0.108)\tData 0.055 (0.078)\tLoss 0.8485 (0.9564)\tAcc 1.000 (0.777)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.633 (0.633)\tData 0.582 (0.582)\tLoss 0.9283 (0.9283)\tAcc 0.562 (0.562)\n",
      "Epoch: [7][2/5]\tTime 0.061 (0.347)\tData 0.027 (0.305)\tLoss 0.7798 (0.8541)\tAcc 0.688 (0.625)\n",
      "Epoch: [7][3/5]\tTime 0.075 (0.257)\tData 0.042 (0.217)\tLoss 0.7384 (0.8155)\tAcc 0.875 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.071 (0.210)\tData 0.045 (0.174)\tLoss 0.9350 (0.8454)\tAcc 0.562 (0.672)\n",
      "Epoch: [7][5/5]\tTime 0.079 (0.184)\tData 0.053 (0.150)\tLoss 1.1786 (0.8865)\tAcc 0.444 (0.644)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.485 (0.485)\tData 0.445 (0.445)\tLoss 0.6790 (0.6790)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.064 (0.275)\tData 0.035 (0.240)\tLoss 1.1203 (0.8997)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.074 (0.208)\tData 0.045 (0.175)\tLoss 0.8312 (0.8768)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.077 (0.175)\tData 0.046 (0.143)\tLoss 0.8931 (0.8809)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.066 (0.153)\tData 0.044 (0.123)\tLoss 0.9072 (0.8862)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.073 (0.140)\tData 0.052 (0.111)\tLoss 0.6066 (0.8396)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.073 (0.130)\tData 0.052 (0.103)\tLoss 0.7520 (0.8271)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.077 (0.124)\tData 0.055 (0.097)\tLoss 1.0242 (0.8517)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.079 (0.119)\tData 0.058 (0.092)\tLoss 0.5582 (0.8472)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.812 (0.812)\tData 0.737 (0.737)\tLoss 0.5255 (0.5255)\tAcc 0.875 (0.875)\n",
      "Epoch: [8][2/5]\tTime 0.049 (0.431)\tData 0.009 (0.373)\tLoss 0.9863 (0.7559)\tAcc 0.500 (0.688)\n",
      "Epoch: [8][3/5]\tTime 0.077 (0.313)\tData 0.039 (0.262)\tLoss 0.6219 (0.7112)\tAcc 0.812 (0.729)\n",
      "Epoch: [8][4/5]\tTime 0.069 (0.252)\tData 0.041 (0.207)\tLoss 0.7151 (0.7122)\tAcc 0.625 (0.703)\n",
      "Epoch: [8][5/5]\tTime 0.078 (0.217)\tData 0.051 (0.175)\tLoss 0.7452 (0.7163)\tAcc 0.667 (0.699)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.429 (0.429)\tData 0.368 (0.368)\tLoss 0.6594 (0.6594)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.067 (0.248)\tData 0.017 (0.193)\tLoss 1.0396 (0.8495)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/9]\tTime 0.072 (0.189)\tData 0.026 (0.137)\tLoss 0.8631 (0.8541)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/9]\tTime 0.064 (0.158)\tData 0.034 (0.112)\tLoss 0.8586 (0.8552)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/9]\tTime 0.068 (0.140)\tData 0.047 (0.099)\tLoss 0.8801 (0.8602)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/9]\tTime 0.073 (0.129)\tData 0.052 (0.091)\tLoss 0.6350 (0.8226)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/9]\tTime 0.073 (0.121)\tData 0.052 (0.085)\tLoss 0.7479 (0.8120)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/9]\tTime 0.074 (0.115)\tData 0.053 (0.081)\tLoss 1.0125 (0.8370)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/9]\tTime 0.073 (0.110)\tData 0.052 (0.078)\tLoss 0.5862 (0.8332)\tAcc 1.000 (0.731)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.640 (0.640)\tData 0.592 (0.592)\tLoss 0.8418 (0.8418)\tAcc 0.750 (0.750)\n",
      "Epoch: [9][2/5]\tTime 0.089 (0.364)\tData 0.031 (0.312)\tLoss 0.7170 (0.7794)\tAcc 0.812 (0.781)\n",
      "Epoch: [9][3/5]\tTime 0.058 (0.262)\tData 0.022 (0.215)\tLoss 0.5126 (0.6905)\tAcc 0.812 (0.792)\n",
      "Epoch: [9][4/5]\tTime 0.070 (0.214)\tData 0.044 (0.172)\tLoss 0.8011 (0.7181)\tAcc 0.625 (0.750)\n",
      "Epoch: [9][5/5]\tTime 0.079 (0.187)\tData 0.053 (0.149)\tLoss 0.7237 (0.7188)\tAcc 0.778 (0.753)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.454 (0.454)\tData 0.393 (0.393)\tLoss 0.4585 (0.4585)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/9]\tTime 0.051 (0.252)\tData 0.017 (0.205)\tLoss 0.9328 (0.6957)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/9]\tTime 0.080 (0.195)\tData 0.039 (0.150)\tLoss 0.7679 (0.7197)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/9]\tTime 0.056 (0.160)\tData 0.032 (0.120)\tLoss 0.7407 (0.7250)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/9]\tTime 0.077 (0.143)\tData 0.051 (0.106)\tLoss 0.8353 (0.7470)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/9]\tTime 0.069 (0.131)\tData 0.048 (0.097)\tLoss 0.4499 (0.6975)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/9]\tTime 0.074 (0.123)\tData 0.052 (0.090)\tLoss 0.6475 (0.6904)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/9]\tTime 0.074 (0.117)\tData 0.053 (0.086)\tLoss 1.0639 (0.7371)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/9]\tTime 0.075 (0.112)\tData 0.054 (0.082)\tLoss 0.3750 (0.7315)\tAcc 1.000 (0.731)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.684 (0.684)\tData 0.630 (0.630)\tLoss 0.8179 (0.8179)\tAcc 0.625 (0.625)\n",
      "Epoch: [10][2/5]\tTime 0.060 (0.372)\tData 0.025 (0.327)\tLoss 0.4088 (0.6133)\tAcc 0.938 (0.781)\n",
      "Epoch: [10][3/5]\tTime 0.071 (0.272)\tData 0.041 (0.232)\tLoss 0.5344 (0.5870)\tAcc 0.875 (0.812)\n",
      "Epoch: [10][4/5]\tTime 0.074 (0.222)\tData 0.048 (0.186)\tLoss 1.0752 (0.7091)\tAcc 0.562 (0.750)\n",
      "Epoch: [10][5/5]\tTime 0.079 (0.194)\tData 0.052 (0.159)\tLoss 0.8936 (0.7318)\tAcc 0.778 (0.753)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.394 (0.394)\tData 0.338 (0.338)\tLoss 0.3354 (0.3354)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.155 (0.275)\tData 0.112 (0.225)\tLoss 1.0217 (0.6786)\tAcc 0.500 (0.719)\n",
      "Epoch: [10][3/9]\tTime 0.064 (0.204)\tData 0.030 (0.160)\tLoss 0.7261 (0.6944)\tAcc 0.625 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.067 (0.170)\tData 0.044 (0.131)\tLoss 0.6786 (0.6905)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.074 (0.151)\tData 0.053 (0.115)\tLoss 0.7989 (0.7121)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.073 (0.138)\tData 0.052 (0.105)\tLoss 0.3321 (0.6488)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.074 (0.129)\tData 0.053 (0.097)\tLoss 0.6374 (0.6472)\tAcc 0.688 (0.732)\n",
      "Epoch: [10][8/9]\tTime 0.074 (0.122)\tData 0.052 (0.092)\tLoss 1.0386 (0.6961)\tAcc 0.625 (0.719)\n",
      "Epoch: [10][9/9]\tTime 0.073 (0.117)\tData 0.052 (0.087)\tLoss 0.2096 (0.6886)\tAcc 1.000 (0.723)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.480 (0.480)\tData 0.430 (0.430)\tLoss 0.9484 (0.9484)\tAcc 0.625 (0.625)\n",
      "Epoch: [11][2/5]\tTime 0.144 (0.312)\tData 0.098 (0.264)\tLoss 0.4540 (0.7012)\tAcc 0.875 (0.750)\n",
      "Epoch: [11][3/5]\tTime 0.079 (0.234)\tData 0.041 (0.190)\tLoss 0.6726 (0.6917)\tAcc 0.688 (0.729)\n",
      "Epoch: [11][4/5]\tTime 0.066 (0.192)\tData 0.040 (0.152)\tLoss 1.1107 (0.7964)\tAcc 0.562 (0.688)\n",
      "Epoch: [11][5/5]\tTime 0.090 (0.172)\tData 0.064 (0.135)\tLoss 0.5398 (0.7648)\tAcc 0.778 (0.699)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.357 (0.357)\tData 0.305 (0.305)\tLoss 0.3530 (0.3530)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/9]\tTime 0.070 (0.213)\tData 0.027 (0.166)\tLoss 1.0606 (0.7068)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/9]\tTime 0.069 (0.165)\tData 0.039 (0.124)\tLoss 0.7196 (0.7111)\tAcc 0.625 (0.667)\n",
      "Epoch: [11][4/9]\tTime 0.093 (0.147)\tData 0.044 (0.104)\tLoss 0.6947 (0.7070)\tAcc 0.688 (0.672)\n",
      "Epoch: [11][5/9]\tTime 0.053 (0.128)\tData 0.027 (0.089)\tLoss 0.7548 (0.7165)\tAcc 0.688 (0.675)\n",
      "Epoch: [11][6/9]\tTime 0.071 (0.119)\tData 0.047 (0.082)\tLoss 0.4106 (0.6656)\tAcc 1.000 (0.729)\n",
      "Epoch: [11][7/9]\tTime 0.077 (0.113)\tData 0.055 (0.078)\tLoss 0.6413 (0.6621)\tAcc 0.812 (0.741)\n",
      "Epoch: [11][8/9]\tTime 0.075 (0.108)\tData 0.053 (0.075)\tLoss 0.9253 (0.6950)\tAcc 0.562 (0.719)\n",
      "Epoch: [11][9/9]\tTime 0.075 (0.104)\tData 0.053 (0.072)\tLoss 0.2208 (0.6877)\tAcc 1.000 (0.723)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.456 (0.456)\tData 0.417 (0.417)\tLoss 0.5101 (0.5101)\tAcc 0.812 (0.812)\n",
      "Epoch: [12][2/5]\tTime 0.075 (0.266)\tData 0.039 (0.228)\tLoss 0.7044 (0.6072)\tAcc 0.625 (0.719)\n",
      "Epoch: [12][3/5]\tTime 0.075 (0.202)\tData 0.041 (0.166)\tLoss 0.7480 (0.6542)\tAcc 0.625 (0.688)\n",
      "Epoch: [12][4/5]\tTime 0.070 (0.169)\tData 0.044 (0.135)\tLoss 0.8426 (0.7013)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/5]\tTime 0.079 (0.151)\tData 0.054 (0.119)\tLoss 0.5633 (0.6843)\tAcc 0.889 (0.712)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.455 (0.455)\tData 0.397 (0.397)\tLoss 0.4224 (0.4224)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/9]\tTime 0.051 (0.253)\tData 0.022 (0.209)\tLoss 0.9924 (0.7074)\tAcc 0.500 (0.719)\n",
      "Epoch: [12][3/9]\tTime 0.075 (0.194)\tData 0.048 (0.156)\tLoss 0.7412 (0.7187)\tAcc 0.688 (0.708)\n",
      "Epoch: [12][4/9]\tTime 0.071 (0.163)\tData 0.050 (0.129)\tLoss 0.6579 (0.7035)\tAcc 0.750 (0.719)\n",
      "Epoch: [12][5/9]\tTime 0.077 (0.146)\tData 0.053 (0.114)\tLoss 0.8539 (0.7336)\tAcc 0.625 (0.700)\n",
      "Epoch: [12][6/9]\tTime 0.075 (0.134)\tData 0.052 (0.104)\tLoss 0.3310 (0.6665)\tAcc 1.000 (0.750)\n",
      "Epoch: [12][7/9]\tTime 0.073 (0.125)\tData 0.052 (0.096)\tLoss 0.5611 (0.6514)\tAcc 0.812 (0.759)\n",
      "Epoch: [12][8/9]\tTime 0.076 (0.119)\tData 0.053 (0.091)\tLoss 0.9303 (0.6863)\tAcc 0.500 (0.727)\n",
      "Epoch: [12][9/9]\tTime 0.073 (0.114)\tData 0.052 (0.087)\tLoss 0.3027 (0.6804)\tAcc 1.000 (0.731)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.487 (0.487)\tData 0.409 (0.409)\tLoss 0.4709 (0.4709)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/5]\tTime 0.056 (0.271)\tData 0.002 (0.206)\tLoss 0.9709 (0.7209)\tAcc 0.562 (0.750)\n",
      "Epoch: [13][3/5]\tTime 0.052 (0.198)\tData 0.025 (0.145)\tLoss 0.7077 (0.7165)\tAcc 0.688 (0.729)\n",
      "Epoch: [13][4/5]\tTime 0.078 (0.168)\tData 0.051 (0.122)\tLoss 1.2991 (0.8622)\tAcc 0.562 (0.688)\n",
      "Epoch: [13][5/5]\tTime 0.078 (0.150)\tData 0.053 (0.108)\tLoss 0.7110 (0.8435)\tAcc 0.778 (0.699)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.275 (0.275)\tData 0.219 (0.219)\tLoss 0.3596 (0.3596)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/9]\tTime 0.104 (0.189)\tData 0.045 (0.132)\tLoss 0.9922 (0.6759)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/9]\tTime 0.065 (0.148)\tData 0.022 (0.095)\tLoss 0.6639 (0.6719)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/9]\tTime 0.067 (0.128)\tData 0.037 (0.081)\tLoss 0.6370 (0.6632)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][5/9]\tTime 0.065 (0.115)\tData 0.044 (0.073)\tLoss 0.7062 (0.6718)\tAcc 0.812 (0.713)\n",
      "Epoch: [13][6/9]\tTime 0.075 (0.108)\tData 0.052 (0.070)\tLoss 0.3627 (0.6203)\tAcc 1.000 (0.760)\n",
      "Epoch: [13][7/9]\tTime 0.074 (0.104)\tData 0.052 (0.067)\tLoss 0.6061 (0.6183)\tAcc 0.750 (0.759)\n",
      "Epoch: [13][8/9]\tTime 0.076 (0.100)\tData 0.053 (0.065)\tLoss 0.8680 (0.6495)\tAcc 0.750 (0.758)\n",
      "Epoch: [13][9/9]\tTime 0.076 (0.097)\tData 0.052 (0.064)\tLoss 0.2738 (0.6437)\tAcc 1.000 (0.762)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.482 (0.482)\tData 0.447 (0.447)\tLoss 0.7089 (0.7089)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][2/5]\tTime 0.069 (0.275)\tData 0.043 (0.245)\tLoss 0.9714 (0.8402)\tAcc 0.562 (0.625)\n",
      "Epoch: [14][3/5]\tTime 0.077 (0.209)\tData 0.052 (0.180)\tLoss 0.8138 (0.8314)\tAcc 0.688 (0.646)\n",
      "Epoch: [14][4/5]\tTime 0.077 (0.176)\tData 0.052 (0.148)\tLoss 0.7575 (0.8129)\tAcc 0.562 (0.625)\n",
      "Epoch: [14][5/5]\tTime 0.078 (0.157)\tData 0.054 (0.129)\tLoss 0.8292 (0.8149)\tAcc 0.667 (0.630)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.218 (0.218)\tData 0.189 (0.189)\tLoss 0.3894 (0.3894)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.084 (0.151)\tData 0.055 (0.122)\tLoss 0.7894 (0.5894)\tAcc 0.750 (0.844)\n",
      "Epoch: [14][3/9]\tTime 0.065 (0.122)\tData 0.045 (0.097)\tLoss 0.7218 (0.6335)\tAcc 0.625 (0.771)\n",
      "Epoch: [14][4/9]\tTime 0.073 (0.110)\tData 0.054 (0.086)\tLoss 0.6301 (0.6326)\tAcc 0.875 (0.797)\n",
      "Epoch: [14][5/9]\tTime 0.074 (0.103)\tData 0.055 (0.080)\tLoss 0.8418 (0.6745)\tAcc 0.625 (0.762)\n",
      "Epoch: [14][6/9]\tTime 0.073 (0.098)\tData 0.054 (0.075)\tLoss 0.3931 (0.6276)\tAcc 1.000 (0.802)\n",
      "Epoch: [14][7/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.6043 (0.6242)\tAcc 0.938 (0.821)\n",
      "Epoch: [14][8/9]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.9342 (0.6630)\tAcc 0.562 (0.789)\n",
      "Epoch: [14][9/9]\tTime 0.072 (0.090)\tData 0.054 (0.068)\tLoss 0.3363 (0.6580)\tAcc 1.000 (0.792)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.559 (0.559)\tData 0.532 (0.532)\tLoss 0.7277 (0.7277)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][2/5]\tTime 0.076 (0.318)\tData 0.052 (0.292)\tLoss 0.8065 (0.7671)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][3/5]\tTime 0.076 (0.237)\tData 0.053 (0.212)\tLoss 0.5584 (0.6975)\tAcc 0.750 (0.708)\n",
      "Epoch: [15][4/5]\tTime 0.077 (0.197)\tData 0.053 (0.173)\tLoss 0.7063 (0.6997)\tAcc 0.688 (0.703)\n",
      "Epoch: [15][5/5]\tTime 0.078 (0.173)\tData 0.055 (0.149)\tLoss 0.3670 (0.6587)\tAcc 0.778 (0.712)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.196 (0.196)\tData 0.171 (0.171)\tLoss 0.1570 (0.1570)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/9]\tTime 0.074 (0.135)\tData 0.050 (0.110)\tLoss 1.1991 (0.6780)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/9]\tTime 0.069 (0.113)\tData 0.049 (0.090)\tLoss 0.6320 (0.6627)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][4/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.5788 (0.6417)\tAcc 0.750 (0.703)\n",
      "Epoch: [15][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 1.0715 (0.7277)\tAcc 0.625 (0.688)\n",
      "Epoch: [15][6/9]\tTime 0.073 (0.093)\tData 0.053 (0.072)\tLoss 0.0923 (0.6218)\tAcc 1.000 (0.740)\n",
      "Epoch: [15][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.3673 (0.5854)\tAcc 0.875 (0.759)\n",
      "Epoch: [15][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 1.4034 (0.6877)\tAcc 0.562 (0.734)\n",
      "Epoch: [15][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.066)\tLoss 0.0385 (0.6777)\tAcc 1.000 (0.738)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.513 (0.513)\tData 0.480 (0.480)\tLoss 0.9045 (0.9045)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][2/5]\tTime 0.081 (0.297)\tData 0.056 (0.268)\tLoss 1.2190 (1.0617)\tAcc 0.500 (0.594)\n",
      "Epoch: [16][3/5]\tTime 0.082 (0.225)\tData 0.058 (0.198)\tLoss 0.3319 (0.8185)\tAcc 0.938 (0.708)\n",
      "Epoch: [16][4/5]\tTime 0.077 (0.188)\tData 0.054 (0.162)\tLoss 0.9880 (0.8609)\tAcc 0.625 (0.688)\n",
      "Epoch: [16][5/5]\tTime 0.078 (0.166)\tData 0.056 (0.141)\tLoss 0.7562 (0.8480)\tAcc 0.444 (0.658)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.196 (0.196)\tData 0.170 (0.170)\tLoss 0.4705 (0.4705)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.070 (0.133)\tData 0.048 (0.109)\tLoss 0.8844 (0.6774)\tAcc 0.562 (0.750)\n",
      "Epoch: [16][3/9]\tTime 0.074 (0.113)\tData 0.055 (0.091)\tLoss 0.6629 (0.6726)\tAcc 0.812 (0.771)\n",
      "Epoch: [16][4/9]\tTime 0.075 (0.104)\tData 0.055 (0.082)\tLoss 0.6392 (0.6642)\tAcc 0.625 (0.734)\n",
      "Epoch: [16][5/9]\tTime 0.077 (0.098)\tData 0.057 (0.077)\tLoss 0.7737 (0.6861)\tAcc 0.688 (0.725)\n",
      "Epoch: [16][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.4197 (0.6417)\tAcc 1.000 (0.771)\n",
      "Epoch: [16][7/9]\tTime 0.072 (0.091)\tData 0.054 (0.071)\tLoss 0.8200 (0.6672)\tAcc 0.625 (0.750)\n",
      "Epoch: [16][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 0.9589 (0.7037)\tAcc 0.562 (0.727)\n",
      "Epoch: [16][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.067)\tLoss 0.3044 (0.6975)\tAcc 1.000 (0.731)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.441 (0.441)\tData 0.412 (0.412)\tLoss 0.7682 (0.7682)\tAcc 0.750 (0.750)\n",
      "Epoch: [17][2/5]\tTime 0.073 (0.257)\tData 0.049 (0.230)\tLoss 0.6783 (0.7232)\tAcc 0.750 (0.750)\n",
      "Epoch: [17][3/5]\tTime 0.081 (0.199)\tData 0.058 (0.173)\tLoss 0.5581 (0.6682)\tAcc 0.875 (0.792)\n",
      "Epoch: [17][4/5]\tTime 0.078 (0.168)\tData 0.054 (0.143)\tLoss 0.5088 (0.6283)\tAcc 0.812 (0.797)\n",
      "Epoch: [17][5/5]\tTime 0.080 (0.151)\tData 0.056 (0.126)\tLoss 0.7186 (0.6395)\tAcc 0.778 (0.795)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.214 (0.214)\tData 0.178 (0.178)\tLoss 0.1926 (0.1926)\tAcc 1.000 (1.000)\n",
      "Epoch: [17][2/9]\tTime 0.060 (0.137)\tData 0.038 (0.108)\tLoss 0.8128 (0.5027)\tAcc 0.688 (0.844)\n",
      "Epoch: [17][3/9]\tTime 0.073 (0.116)\tData 0.053 (0.090)\tLoss 0.6288 (0.5447)\tAcc 0.812 (0.833)\n",
      "Epoch: [17][4/9]\tTime 0.073 (0.105)\tData 0.053 (0.081)\tLoss 0.5682 (0.5506)\tAcc 0.750 (0.812)\n",
      "Epoch: [17][5/9]\tTime 0.077 (0.099)\tData 0.057 (0.076)\tLoss 0.7439 (0.5893)\tAcc 0.750 (0.800)\n",
      "Epoch: [17][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.072)\tLoss 0.2596 (0.5343)\tAcc 1.000 (0.833)\n",
      "Epoch: [17][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.7312 (0.5624)\tAcc 0.625 (0.804)\n",
      "Epoch: [17][8/9]\tTime 0.075 (0.090)\tData 0.054 (0.068)\tLoss 1.0321 (0.6212)\tAcc 0.688 (0.789)\n",
      "Epoch: [17][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.0789 (0.6128)\tAcc 1.000 (0.792)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.406 (0.406)\tData 0.377 (0.377)\tLoss 0.4534 (0.4534)\tAcc 0.812 (0.812)\n",
      "Epoch: [18][2/5]\tTime 0.086 (0.246)\tData 0.061 (0.219)\tLoss 0.7891 (0.6213)\tAcc 0.750 (0.781)\n",
      "Epoch: [18][3/5]\tTime 0.085 (0.192)\tData 0.060 (0.166)\tLoss 0.9655 (0.7360)\tAcc 0.625 (0.729)\n",
      "Epoch: [18][4/5]\tTime 0.084 (0.165)\tData 0.060 (0.140)\tLoss 0.8645 (0.7681)\tAcc 0.688 (0.719)\n",
      "Epoch: [18][5/5]\tTime 0.085 (0.149)\tData 0.061 (0.124)\tLoss 0.6702 (0.7561)\tAcc 0.667 (0.712)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.206 (0.206)\tData 0.176 (0.176)\tLoss 0.2129 (0.2129)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/9]\tTime 0.079 (0.142)\tData 0.051 (0.114)\tLoss 0.7844 (0.4986)\tAcc 0.750 (0.844)\n",
      "Epoch: [18][3/9]\tTime 0.073 (0.119)\tData 0.053 (0.093)\tLoss 0.6773 (0.5582)\tAcc 0.625 (0.771)\n",
      "Epoch: [18][4/9]\tTime 0.080 (0.109)\tData 0.060 (0.085)\tLoss 0.6307 (0.5763)\tAcc 0.750 (0.766)\n",
      "Epoch: [18][5/9]\tTime 0.080 (0.103)\tData 0.059 (0.080)\tLoss 0.8758 (0.6362)\tAcc 0.625 (0.738)\n",
      "Epoch: [18][6/9]\tTime 0.079 (0.099)\tData 0.059 (0.076)\tLoss 0.1988 (0.5633)\tAcc 1.000 (0.781)\n",
      "Epoch: [18][7/9]\tTime 0.076 (0.096)\tData 0.056 (0.074)\tLoss 0.4958 (0.5537)\tAcc 0.938 (0.804)\n",
      "Epoch: [18][8/9]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 0.9625 (0.6048)\tAcc 0.500 (0.766)\n",
      "Epoch: [18][9/9]\tTime 0.072 (0.091)\tData 0.054 (0.069)\tLoss 0.1251 (0.5974)\tAcc 1.000 (0.769)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.347 (0.347)\tData 0.320 (0.320)\tLoss 0.5300 (0.5300)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][2/5]\tTime 0.076 (0.211)\tData 0.051 (0.185)\tLoss 0.6877 (0.6088)\tAcc 0.750 (0.719)\n",
      "Epoch: [19][3/5]\tTime 0.075 (0.166)\tData 0.052 (0.141)\tLoss 0.6231 (0.6136)\tAcc 0.750 (0.729)\n",
      "Epoch: [19][4/5]\tTime 0.076 (0.144)\tData 0.053 (0.119)\tLoss 0.7450 (0.6464)\tAcc 0.688 (0.719)\n",
      "Epoch: [19][5/5]\tTime 0.079 (0.131)\tData 0.055 (0.106)\tLoss 0.8911 (0.6766)\tAcc 0.778 (0.726)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.191 (0.191)\tData 0.162 (0.162)\tLoss 0.3954 (0.3954)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/9]\tTime 0.066 (0.129)\tData 0.045 (0.104)\tLoss 0.7513 (0.5733)\tAcc 0.562 (0.750)\n",
      "Epoch: [19][3/9]\tTime 0.072 (0.110)\tData 0.052 (0.087)\tLoss 0.7494 (0.6320)\tAcc 0.688 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.073 (0.101)\tData 0.054 (0.078)\tLoss 0.6227 (0.6297)\tAcc 0.875 (0.766)\n",
      "Epoch: [19][5/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.7977 (0.6633)\tAcc 0.750 (0.762)\n",
      "Epoch: [19][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.3414 (0.6096)\tAcc 1.000 (0.802)\n",
      "Epoch: [19][7/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.8795 (0.6482)\tAcc 0.625 (0.777)\n",
      "Epoch: [19][8/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.9360 (0.6842)\tAcc 0.625 (0.758)\n",
      "Epoch: [19][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.3033 (0.6783)\tAcc 1.000 (0.762)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.431 (0.431)\tData 0.399 (0.399)\tLoss 0.7319 (0.7319)\tAcc 0.812 (0.812)\n",
      "Epoch: [20][2/5]\tTime 0.072 (0.251)\tData 0.047 (0.223)\tLoss 0.8251 (0.7785)\tAcc 0.625 (0.719)\n",
      "Epoch: [20][3/5]\tTime 0.077 (0.193)\tData 0.052 (0.166)\tLoss 0.5448 (0.7006)\tAcc 0.812 (0.750)\n",
      "Epoch: [20][4/5]\tTime 0.076 (0.164)\tData 0.052 (0.138)\tLoss 0.8701 (0.7430)\tAcc 0.625 (0.719)\n",
      "Epoch: [20][5/5]\tTime 0.078 (0.147)\tData 0.055 (0.121)\tLoss 1.2883 (0.8102)\tAcc 0.444 (0.685)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.198 (0.198)\tData 0.174 (0.174)\tLoss 0.2937 (0.2937)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/9]\tTime 0.077 (0.137)\tData 0.050 (0.112)\tLoss 1.0692 (0.6815)\tAcc 0.438 (0.688)\n",
      "Epoch: [20][3/9]\tTime 0.066 (0.113)\tData 0.047 (0.090)\tLoss 0.5857 (0.6496)\tAcc 0.750 (0.708)\n",
      "Epoch: [20][4/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.6830 (0.6579)\tAcc 0.625 (0.688)\n",
      "Epoch: [20][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.076)\tLoss 0.7795 (0.6822)\tAcc 0.812 (0.713)\n",
      "Epoch: [20][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2938 (0.6175)\tAcc 1.000 (0.760)\n",
      "Epoch: [20][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 0.5608 (0.6094)\tAcc 0.812 (0.768)\n",
      "Epoch: [20][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.068)\tLoss 0.8821 (0.6435)\tAcc 0.625 (0.750)\n",
      "Epoch: [20][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.066)\tLoss 0.2075 (0.6368)\tAcc 1.000 (0.754)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.358 (0.358)\tData 0.330 (0.330)\tLoss 0.6335 (0.6335)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][2/5]\tTime 0.079 (0.218)\tData 0.054 (0.192)\tLoss 0.7423 (0.6879)\tAcc 0.562 (0.656)\n",
      "Epoch: [21][3/5]\tTime 0.077 (0.171)\tData 0.052 (0.146)\tLoss 0.5370 (0.6376)\tAcc 0.875 (0.729)\n",
      "Epoch: [21][4/5]\tTime 0.078 (0.148)\tData 0.054 (0.123)\tLoss 0.8475 (0.6901)\tAcc 0.750 (0.734)\n",
      "Epoch: [21][5/5]\tTime 0.078 (0.134)\tData 0.054 (0.109)\tLoss 0.8081 (0.7047)\tAcc 0.667 (0.726)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.197 (0.197)\tData 0.171 (0.171)\tLoss 0.5034 (0.5034)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.074 (0.136)\tData 0.048 (0.110)\tLoss 0.7641 (0.6337)\tAcc 0.688 (0.812)\n",
      "Epoch: [21][3/9]\tTime 0.068 (0.113)\tData 0.048 (0.089)\tLoss 0.7745 (0.6806)\tAcc 0.688 (0.771)\n",
      "Epoch: [21][4/9]\tTime 0.075 (0.104)\tData 0.055 (0.081)\tLoss 0.7221 (0.6910)\tAcc 0.688 (0.750)\n",
      "Epoch: [21][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.075)\tLoss 0.8831 (0.7294)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][6/9]\tTime 0.076 (0.094)\tData 0.057 (0.072)\tLoss 0.4267 (0.6790)\tAcc 1.000 (0.792)\n",
      "Epoch: [21][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.6909 (0.6807)\tAcc 0.812 (0.795)\n",
      "Epoch: [21][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 1.1497 (0.7393)\tAcc 0.562 (0.766)\n",
      "Epoch: [21][9/9]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 0.3918 (0.7340)\tAcc 1.000 (0.769)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.379 (0.379)\tData 0.350 (0.350)\tLoss 0.6107 (0.6107)\tAcc 0.750 (0.750)\n",
      "Epoch: [22][2/5]\tTime 0.084 (0.231)\tData 0.057 (0.203)\tLoss 0.7851 (0.6979)\tAcc 0.688 (0.719)\n",
      "Epoch: [22][3/5]\tTime 0.081 (0.181)\tData 0.057 (0.155)\tLoss 1.4153 (0.9371)\tAcc 0.438 (0.625)\n",
      "Epoch: [22][4/5]\tTime 0.086 (0.157)\tData 0.061 (0.131)\tLoss 0.4623 (0.8184)\tAcc 0.938 (0.703)\n",
      "Epoch: [22][5/5]\tTime 0.083 (0.143)\tData 0.060 (0.117)\tLoss 0.5151 (0.7810)\tAcc 0.778 (0.712)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.211 (0.211)\tData 0.185 (0.185)\tLoss 0.3450 (0.3450)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.076 (0.143)\tData 0.049 (0.117)\tLoss 0.8751 (0.6100)\tAcc 0.625 (0.781)\n",
      "Epoch: [22][3/9]\tTime 0.066 (0.118)\tData 0.047 (0.094)\tLoss 0.6243 (0.6148)\tAcc 0.750 (0.771)\n",
      "Epoch: [22][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.084)\tLoss 0.5615 (0.6015)\tAcc 0.750 (0.766)\n",
      "Epoch: [22][5/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.8079 (0.6428)\tAcc 0.750 (0.762)\n",
      "Epoch: [22][6/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.3021 (0.5860)\tAcc 1.000 (0.802)\n",
      "Epoch: [22][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.5297 (0.5779)\tAcc 0.875 (0.813)\n",
      "Epoch: [22][8/9]\tTime 0.076 (0.091)\tData 0.055 (0.069)\tLoss 0.9228 (0.6211)\tAcc 0.688 (0.797)\n",
      "Epoch: [22][9/9]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.1818 (0.6143)\tAcc 1.000 (0.800)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.471 (0.471)\tData 0.439 (0.439)\tLoss 0.3287 (0.3287)\tAcc 0.875 (0.875)\n",
      "Epoch: [23][2/5]\tTime 0.071 (0.271)\tData 0.046 (0.242)\tLoss 0.5683 (0.4485)\tAcc 0.750 (0.812)\n",
      "Epoch: [23][3/5]\tTime 0.078 (0.206)\tData 0.052 (0.179)\tLoss 0.6384 (0.5118)\tAcc 0.812 (0.812)\n",
      "Epoch: [23][4/5]\tTime 0.086 (0.176)\tData 0.063 (0.150)\tLoss 1.4740 (0.7524)\tAcc 0.562 (0.750)\n",
      "Epoch: [23][5/5]\tTime 0.079 (0.157)\tData 0.056 (0.131)\tLoss 1.0782 (0.7925)\tAcc 0.667 (0.740)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.200 (0.200)\tData 0.170 (0.170)\tLoss 0.4197 (0.4197)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.099 (0.149)\tData 0.057 (0.114)\tLoss 1.0857 (0.7527)\tAcc 0.438 (0.688)\n",
      "Epoch: [23][3/9]\tTime 0.060 (0.119)\tData 0.039 (0.089)\tLoss 0.6243 (0.7099)\tAcc 0.812 (0.729)\n",
      "Epoch: [23][4/9]\tTime 0.072 (0.108)\tData 0.053 (0.080)\tLoss 0.7126 (0.7106)\tAcc 0.688 (0.719)\n",
      "Epoch: [23][5/9]\tTime 0.075 (0.101)\tData 0.055 (0.075)\tLoss 0.7278 (0.7140)\tAcc 0.812 (0.738)\n",
      "Epoch: [23][6/9]\tTime 0.075 (0.097)\tData 0.054 (0.071)\tLoss 0.4126 (0.6638)\tAcc 1.000 (0.781)\n",
      "Epoch: [23][7/9]\tTime 0.072 (0.093)\tData 0.052 (0.069)\tLoss 0.7217 (0.6721)\tAcc 0.750 (0.777)\n",
      "Epoch: [23][8/9]\tTime 0.074 (0.091)\tData 0.055 (0.067)\tLoss 0.9689 (0.7092)\tAcc 0.625 (0.758)\n",
      "Epoch: [23][9/9]\tTime 0.073 (0.089)\tData 0.054 (0.065)\tLoss 0.6708 (0.7086)\tAcc 1.000 (0.762)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.290 (0.290)\tData 0.262 (0.262)\tLoss 0.8210 (0.8210)\tAcc 0.688 (0.688)\n",
      "Epoch: [24][2/5]\tTime 0.084 (0.187)\tData 0.056 (0.159)\tLoss 0.7641 (0.7925)\tAcc 0.750 (0.719)\n",
      "Epoch: [24][3/5]\tTime 0.079 (0.151)\tData 0.055 (0.124)\tLoss 0.7608 (0.7819)\tAcc 0.688 (0.708)\n",
      "Epoch: [24][4/5]\tTime 0.082 (0.134)\tData 0.058 (0.108)\tLoss 0.8138 (0.7899)\tAcc 0.688 (0.703)\n",
      "Epoch: [24][5/5]\tTime 0.083 (0.124)\tData 0.059 (0.098)\tLoss 0.9192 (0.8058)\tAcc 0.556 (0.685)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.219 (0.219)\tData 0.186 (0.186)\tLoss 0.6508 (0.6508)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/9]\tTime 0.074 (0.146)\tData 0.046 (0.116)\tLoss 0.9139 (0.7824)\tAcc 0.438 (0.688)\n",
      "Epoch: [24][3/9]\tTime 0.070 (0.121)\tData 0.050 (0.094)\tLoss 0.8980 (0.8209)\tAcc 0.812 (0.729)\n",
      "Epoch: [24][4/9]\tTime 0.076 (0.110)\tData 0.057 (0.085)\tLoss 0.8592 (0.8305)\tAcc 0.625 (0.703)\n",
      "Epoch: [24][5/9]\tTime 0.075 (0.103)\tData 0.056 (0.079)\tLoss 0.8020 (0.8248)\tAcc 0.875 (0.738)\n",
      "Epoch: [24][6/9]\tTime 0.076 (0.098)\tData 0.057 (0.075)\tLoss 0.6107 (0.7891)\tAcc 1.000 (0.781)\n",
      "Epoch: [24][7/9]\tTime 0.076 (0.095)\tData 0.056 (0.073)\tLoss 0.8471 (0.7974)\tAcc 0.812 (0.786)\n",
      "Epoch: [24][8/9]\tTime 0.075 (0.093)\tData 0.056 (0.070)\tLoss 0.9859 (0.8210)\tAcc 0.625 (0.766)\n",
      "Epoch: [24][9/9]\tTime 0.077 (0.091)\tData 0.058 (0.069)\tLoss 0.6446 (0.8182)\tAcc 1.000 (0.769)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.285 (0.285)\tData 0.251 (0.251)\tLoss 0.9064 (0.9064)\tAcc 0.625 (0.625)\n",
      "Epoch: [25][2/5]\tTime 0.134 (0.209)\tData 0.110 (0.181)\tLoss 0.7508 (0.8286)\tAcc 0.812 (0.719)\n",
      "Epoch: [25][3/5]\tTime 0.082 (0.167)\tData 0.057 (0.139)\tLoss 0.5469 (0.7347)\tAcc 0.938 (0.792)\n",
      "Epoch: [25][4/5]\tTime 0.078 (0.145)\tData 0.054 (0.118)\tLoss 0.6442 (0.7121)\tAcc 0.750 (0.781)\n",
      "Epoch: [25][5/5]\tTime 0.077 (0.131)\tData 0.054 (0.105)\tLoss 0.7517 (0.7170)\tAcc 0.778 (0.781)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.206 (0.206)\tData 0.182 (0.182)\tLoss 0.3421 (0.3421)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.080 (0.143)\tData 0.054 (0.118)\tLoss 0.8408 (0.5914)\tAcc 0.688 (0.812)\n",
      "Epoch: [25][3/9]\tTime 0.069 (0.118)\tData 0.050 (0.095)\tLoss 0.7238 (0.6356)\tAcc 0.625 (0.750)\n",
      "Epoch: [25][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.6305 (0.6343)\tAcc 0.750 (0.750)\n",
      "Epoch: [25][5/9]\tTime 0.075 (0.101)\tData 0.056 (0.079)\tLoss 0.9312 (0.6937)\tAcc 0.562 (0.713)\n",
      "Epoch: [25][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.2947 (0.6272)\tAcc 1.000 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.073 (0.093)\tData 0.055 (0.072)\tLoss 0.5849 (0.6212)\tAcc 0.875 (0.777)\n",
      "Epoch: [25][8/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.9780 (0.6658)\tAcc 0.562 (0.750)\n",
      "Epoch: [25][9/9]\tTime 0.073 (0.089)\tData 0.055 (0.069)\tLoss 0.3164 (0.6604)\tAcc 1.000 (0.754)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.221 (0.221)\tData 0.193 (0.193)\tLoss 0.6962 (0.6962)\tAcc 0.625 (0.625)\n",
      "Epoch: [26][2/5]\tTime 0.080 (0.151)\tData 0.054 (0.124)\tLoss 0.7482 (0.7222)\tAcc 0.688 (0.656)\n",
      "Epoch: [26][3/5]\tTime 0.084 (0.128)\tData 0.058 (0.102)\tLoss 0.4708 (0.6384)\tAcc 0.812 (0.708)\n",
      "Epoch: [26][4/5]\tTime 0.084 (0.117)\tData 0.059 (0.091)\tLoss 0.6246 (0.6350)\tAcc 0.750 (0.719)\n",
      "Epoch: [26][5/5]\tTime 0.083 (0.110)\tData 0.058 (0.084)\tLoss 0.2762 (0.5908)\tAcc 0.889 (0.740)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.195 (0.195)\tData 0.170 (0.170)\tLoss 0.3462 (0.3462)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/9]\tTime 0.073 (0.134)\tData 0.050 (0.110)\tLoss 0.9598 (0.6530)\tAcc 0.438 (0.688)\n",
      "Epoch: [26][3/9]\tTime 0.071 (0.113)\tData 0.051 (0.090)\tLoss 0.4582 (0.5881)\tAcc 0.750 (0.708)\n",
      "Epoch: [26][4/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.5420 (0.5766)\tAcc 0.625 (0.688)\n",
      "Epoch: [26][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 0.8730 (0.6358)\tAcc 0.750 (0.700)\n",
      "Epoch: [26][6/9]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.1617 (0.5568)\tAcc 1.000 (0.750)\n",
      "Epoch: [26][7/9]\tTime 0.074 (0.090)\tData 0.055 (0.070)\tLoss 0.5133 (0.5506)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.068)\tLoss 1.1893 (0.6304)\tAcc 0.562 (0.727)\n",
      "Epoch: [26][9/9]\tTime 0.075 (0.087)\tData 0.055 (0.066)\tLoss 0.0575 (0.6216)\tAcc 1.000 (0.731)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.239 (0.239)\tData 0.207 (0.207)\tLoss 0.8385 (0.8385)\tAcc 0.625 (0.625)\n",
      "Epoch: [27][2/5]\tTime 0.073 (0.156)\tData 0.048 (0.127)\tLoss 0.7527 (0.7956)\tAcc 0.688 (0.656)\n",
      "Epoch: [27][3/5]\tTime 0.075 (0.129)\tData 0.052 (0.102)\tLoss 0.3744 (0.6552)\tAcc 0.875 (0.729)\n",
      "Epoch: [27][4/5]\tTime 0.079 (0.117)\tData 0.055 (0.090)\tLoss 0.5451 (0.6277)\tAcc 0.875 (0.766)\n",
      "Epoch: [27][5/5]\tTime 0.079 (0.109)\tData 0.056 (0.084)\tLoss 0.9884 (0.6721)\tAcc 0.556 (0.740)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.205 (0.205)\tData 0.181 (0.181)\tLoss 0.3144 (0.3144)\tAcc 1.000 (1.000)\n",
      "Epoch: [27][2/9]\tTime 0.077 (0.141)\tData 0.051 (0.116)\tLoss 0.7019 (0.5081)\tAcc 0.750 (0.875)\n",
      "Epoch: [27][3/9]\tTime 0.066 (0.116)\tData 0.047 (0.093)\tLoss 0.8209 (0.6124)\tAcc 0.625 (0.792)\n",
      "Epoch: [27][4/9]\tTime 0.077 (0.106)\tData 0.056 (0.083)\tLoss 0.6154 (0.6131)\tAcc 0.875 (0.812)\n",
      "Epoch: [27][5/9]\tTime 0.081 (0.101)\tData 0.060 (0.079)\tLoss 0.9504 (0.6806)\tAcc 0.625 (0.775)\n",
      "Epoch: [27][6/9]\tTime 0.086 (0.098)\tData 0.065 (0.076)\tLoss 0.4219 (0.6375)\tAcc 0.938 (0.802)\n",
      "Epoch: [27][7/9]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 0.9404 (0.6807)\tAcc 0.688 (0.786)\n",
      "Epoch: [27][8/9]\tTime 0.079 (0.094)\tData 0.059 (0.072)\tLoss 1.0693 (0.7293)\tAcc 0.625 (0.766)\n",
      "Epoch: [27][9/9]\tTime 0.080 (0.092)\tData 0.060 (0.071)\tLoss 0.2551 (0.7220)\tAcc 1.000 (0.769)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.336 (0.336)\tData 0.304 (0.304)\tLoss 0.4869 (0.4869)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/5]\tTime 0.080 (0.208)\tData 0.054 (0.179)\tLoss 0.3991 (0.4430)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][3/5]\tTime 0.084 (0.167)\tData 0.059 (0.139)\tLoss 0.7277 (0.5379)\tAcc 0.750 (0.875)\n",
      "Epoch: [28][4/5]\tTime 0.084 (0.146)\tData 0.059 (0.119)\tLoss 1.4781 (0.7730)\tAcc 0.562 (0.797)\n",
      "Epoch: [28][5/5]\tTime 0.085 (0.134)\tData 0.060 (0.107)\tLoss 0.8769 (0.7858)\tAcc 0.444 (0.753)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.202 (0.202)\tData 0.178 (0.178)\tLoss 0.4247 (0.4247)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/9]\tTime 0.082 (0.142)\tData 0.056 (0.117)\tLoss 0.9211 (0.6729)\tAcc 0.500 (0.719)\n",
      "Epoch: [28][3/9]\tTime 0.073 (0.119)\tData 0.053 (0.096)\tLoss 0.7019 (0.6826)\tAcc 0.688 (0.708)\n",
      "Epoch: [28][4/9]\tTime 0.079 (0.109)\tData 0.059 (0.086)\tLoss 0.7981 (0.7115)\tAcc 0.625 (0.688)\n",
      "Epoch: [28][5/9]\tTime 0.080 (0.103)\tData 0.059 (0.081)\tLoss 0.7787 (0.7249)\tAcc 0.688 (0.688)\n",
      "Epoch: [28][6/9]\tTime 0.078 (0.099)\tData 0.058 (0.077)\tLoss 0.3851 (0.6683)\tAcc 1.000 (0.740)\n",
      "Epoch: [28][7/9]\tTime 0.078 (0.096)\tData 0.058 (0.074)\tLoss 0.7274 (0.6767)\tAcc 0.750 (0.741)\n",
      "Epoch: [28][8/9]\tTime 0.078 (0.094)\tData 0.059 (0.072)\tLoss 0.9284 (0.7082)\tAcc 0.688 (0.734)\n",
      "Epoch: [28][9/9]\tTime 0.079 (0.092)\tData 0.059 (0.071)\tLoss 0.4049 (0.7035)\tAcc 1.000 (0.738)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.376 (0.376)\tData 0.348 (0.348)\tLoss 0.5685 (0.5685)\tAcc 0.812 (0.812)\n",
      "Epoch: [29][2/5]\tTime 0.082 (0.229)\tData 0.055 (0.201)\tLoss 0.6549 (0.6117)\tAcc 0.750 (0.781)\n",
      "Epoch: [29][3/5]\tTime 0.084 (0.181)\tData 0.057 (0.153)\tLoss 0.7320 (0.6518)\tAcc 0.812 (0.792)\n",
      "Epoch: [29][4/5]\tTime 0.083 (0.156)\tData 0.057 (0.129)\tLoss 0.7672 (0.6806)\tAcc 0.688 (0.766)\n",
      "Epoch: [29][5/5]\tTime 0.086 (0.142)\tData 0.060 (0.116)\tLoss 0.7225 (0.6858)\tAcc 0.667 (0.753)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.235 (0.235)\tData 0.206 (0.206)\tLoss 0.5367 (0.5367)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.075 (0.155)\tData 0.051 (0.128)\tLoss 0.9547 (0.7457)\tAcc 0.562 (0.750)\n",
      "Epoch: [29][3/9]\tTime 0.076 (0.129)\tData 0.055 (0.104)\tLoss 0.9263 (0.8059)\tAcc 0.750 (0.750)\n",
      "Epoch: [29][4/9]\tTime 0.081 (0.117)\tData 0.059 (0.093)\tLoss 0.7870 (0.8012)\tAcc 0.625 (0.719)\n",
      "Epoch: [29][5/9]\tTime 0.078 (0.109)\tData 0.057 (0.086)\tLoss 0.7254 (0.7860)\tAcc 0.750 (0.725)\n",
      "Epoch: [29][6/9]\tTime 0.079 (0.104)\tData 0.058 (0.081)\tLoss 0.4843 (0.7357)\tAcc 1.000 (0.771)\n",
      "Epoch: [29][7/9]\tTime 0.077 (0.100)\tData 0.057 (0.078)\tLoss 0.8124 (0.7467)\tAcc 0.688 (0.759)\n",
      "Epoch: [29][8/9]\tTime 0.080 (0.098)\tData 0.059 (0.075)\tLoss 1.2014 (0.8035)\tAcc 0.500 (0.727)\n",
      "Epoch: [29][9/9]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.5575 (0.7997)\tAcc 1.000 (0.731)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.357 (0.357)\tData 0.316 (0.316)\tLoss 0.8016 (0.8016)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][2/5]\tTime 0.073 (0.215)\tData 0.043 (0.179)\tLoss 0.6032 (0.7024)\tAcc 0.875 (0.781)\n",
      "Epoch: [30][3/5]\tTime 0.078 (0.170)\tData 0.052 (0.137)\tLoss 0.7497 (0.7182)\tAcc 0.625 (0.729)\n",
      "Epoch: [30][4/5]\tTime 0.080 (0.147)\tData 0.054 (0.116)\tLoss 0.9666 (0.7803)\tAcc 0.500 (0.672)\n",
      "Epoch: [30][5/5]\tTime 0.085 (0.135)\tData 0.059 (0.105)\tLoss 0.7246 (0.7734)\tAcc 0.778 (0.685)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.243 (0.243)\tData 0.214 (0.214)\tLoss 0.5816 (0.5816)\tAcc 0.875 (0.875)\n",
      "Epoch: [30][2/9]\tTime 0.087 (0.165)\tData 0.058 (0.136)\tLoss 0.8000 (0.6908)\tAcc 0.625 (0.750)\n",
      "Epoch: [30][3/9]\tTime 0.069 (0.133)\tData 0.049 (0.107)\tLoss 0.8830 (0.7549)\tAcc 0.750 (0.750)\n",
      "Epoch: [30][4/9]\tTime 0.079 (0.120)\tData 0.058 (0.095)\tLoss 0.7791 (0.7609)\tAcc 0.750 (0.750)\n",
      "Epoch: [30][5/9]\tTime 0.080 (0.112)\tData 0.058 (0.088)\tLoss 0.8083 (0.7704)\tAcc 0.688 (0.738)\n",
      "Epoch: [30][6/9]\tTime 0.080 (0.106)\tData 0.059 (0.083)\tLoss 0.4895 (0.7236)\tAcc 1.000 (0.781)\n",
      "Epoch: [30][7/9]\tTime 0.079 (0.103)\tData 0.059 (0.079)\tLoss 0.8271 (0.7384)\tAcc 0.688 (0.768)\n",
      "Epoch: [30][8/9]\tTime 0.075 (0.099)\tData 0.055 (0.076)\tLoss 0.8854 (0.7568)\tAcc 0.688 (0.758)\n",
      "Epoch: [30][9/9]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.5422 (0.7535)\tAcc 1.000 (0.762)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.264 (0.264)\tData 0.233 (0.233)\tLoss 0.7184 (0.7184)\tAcc 0.875 (0.875)\n",
      "Epoch: [31][2/5]\tTime 0.073 (0.169)\tData 0.048 (0.141)\tLoss 0.7595 (0.7390)\tAcc 0.625 (0.750)\n",
      "Epoch: [31][3/5]\tTime 0.077 (0.138)\tData 0.053 (0.111)\tLoss 0.8309 (0.7696)\tAcc 0.688 (0.729)\n",
      "Epoch: [31][4/5]\tTime 0.077 (0.123)\tData 0.053 (0.097)\tLoss 0.6910 (0.7499)\tAcc 0.688 (0.719)\n",
      "Epoch: [31][5/5]\tTime 0.076 (0.114)\tData 0.052 (0.088)\tLoss 0.5486 (0.7251)\tAcc 0.778 (0.726)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.212 (0.212)\tData 0.174 (0.174)\tLoss 0.4606 (0.4606)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.065 (0.139)\tData 0.043 (0.108)\tLoss 0.9630 (0.7118)\tAcc 0.500 (0.719)\n",
      "Epoch: [31][3/9]\tTime 0.077 (0.118)\tData 0.057 (0.091)\tLoss 0.7573 (0.7270)\tAcc 0.750 (0.729)\n",
      "Epoch: [31][4/9]\tTime 0.073 (0.107)\tData 0.053 (0.082)\tLoss 0.7089 (0.7225)\tAcc 0.688 (0.719)\n",
      "Epoch: [31][5/9]\tTime 0.075 (0.101)\tData 0.054 (0.076)\tLoss 0.7869 (0.7354)\tAcc 0.688 (0.713)\n",
      "Epoch: [31][6/9]\tTime 0.079 (0.097)\tData 0.058 (0.073)\tLoss 0.3845 (0.6769)\tAcc 1.000 (0.760)\n",
      "Epoch: [31][7/9]\tTime 0.079 (0.094)\tData 0.059 (0.071)\tLoss 0.5597 (0.6601)\tAcc 0.875 (0.777)\n",
      "Epoch: [31][8/9]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.7346 (0.6695)\tAcc 0.688 (0.766)\n",
      "Epoch: [31][9/9]\tTime 0.079 (0.091)\tData 0.059 (0.068)\tLoss 0.3890 (0.6651)\tAcc 1.000 (0.769)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.294 (0.294)\tData 0.261 (0.261)\tLoss 0.6673 (0.6673)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][2/5]\tTime 0.076 (0.185)\tData 0.049 (0.155)\tLoss 0.9785 (0.8229)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][3/5]\tTime 0.079 (0.150)\tData 0.054 (0.122)\tLoss 0.6312 (0.7590)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][4/5]\tTime 0.085 (0.134)\tData 0.060 (0.106)\tLoss 0.8502 (0.7818)\tAcc 0.625 (0.719)\n",
      "Epoch: [32][5/5]\tTime 0.086 (0.124)\tData 0.060 (0.097)\tLoss 0.4072 (0.7356)\tAcc 1.000 (0.753)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.238 (0.238)\tData 0.205 (0.205)\tLoss 0.4111 (0.4111)\tAcc 0.938 (0.938)\n",
      "Epoch: [32][2/9]\tTime 0.074 (0.156)\tData 0.048 (0.126)\tLoss 0.9376 (0.6743)\tAcc 0.562 (0.750)\n",
      "Epoch: [32][3/9]\tTime 0.074 (0.129)\tData 0.054 (0.102)\tLoss 0.7620 (0.7035)\tAcc 0.812 (0.771)\n",
      "Epoch: [32][4/9]\tTime 0.079 (0.116)\tData 0.059 (0.091)\tLoss 0.6948 (0.7014)\tAcc 0.750 (0.766)\n",
      "Epoch: [32][5/9]\tTime 0.080 (0.109)\tData 0.059 (0.085)\tLoss 0.8141 (0.7239)\tAcc 0.688 (0.750)\n",
      "Epoch: [32][6/9]\tTime 0.080 (0.104)\tData 0.060 (0.081)\tLoss 0.3650 (0.6641)\tAcc 1.000 (0.792)\n",
      "Epoch: [32][7/9]\tTime 0.080 (0.101)\tData 0.060 (0.078)\tLoss 0.6949 (0.6685)\tAcc 0.812 (0.795)\n",
      "Epoch: [32][8/9]\tTime 0.079 (0.098)\tData 0.059 (0.075)\tLoss 0.9966 (0.7095)\tAcc 0.562 (0.766)\n",
      "Epoch: [32][9/9]\tTime 0.079 (0.096)\tData 0.060 (0.074)\tLoss 0.4095 (0.7049)\tAcc 1.000 (0.769)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.276 (0.276)\tData 0.243 (0.243)\tLoss 0.7589 (0.7589)\tAcc 0.750 (0.750)\n",
      "Epoch: [33][2/5]\tTime 0.078 (0.177)\tData 0.052 (0.147)\tLoss 0.8761 (0.8175)\tAcc 0.688 (0.719)\n",
      "Epoch: [33][3/5]\tTime 0.079 (0.144)\tData 0.054 (0.116)\tLoss 0.6396 (0.7582)\tAcc 0.812 (0.750)\n",
      "Epoch: [33][4/5]\tTime 0.080 (0.128)\tData 0.056 (0.101)\tLoss 0.6732 (0.7369)\tAcc 0.812 (0.766)\n",
      "Epoch: [33][5/5]\tTime 0.080 (0.118)\tData 0.056 (0.092)\tLoss 0.7613 (0.7399)\tAcc 0.778 (0.767)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.227 (0.227)\tData 0.200 (0.200)\tLoss 0.3684 (0.3684)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.091 (0.159)\tData 0.051 (0.125)\tLoss 1.0933 (0.7308)\tAcc 0.500 (0.719)\n",
      "Epoch: [33][3/9]\tTime 0.059 (0.126)\tData 0.038 (0.096)\tLoss 0.6724 (0.7114)\tAcc 0.750 (0.729)\n",
      "Epoch: [33][4/9]\tTime 0.077 (0.114)\tData 0.057 (0.086)\tLoss 0.5679 (0.6755)\tAcc 0.812 (0.750)\n",
      "Epoch: [33][5/9]\tTime 0.079 (0.107)\tData 0.059 (0.081)\tLoss 0.7562 (0.6916)\tAcc 0.750 (0.750)\n",
      "Epoch: [33][6/9]\tTime 0.079 (0.102)\tData 0.058 (0.077)\tLoss 0.2913 (0.6249)\tAcc 1.000 (0.792)\n",
      "Epoch: [33][7/9]\tTime 0.079 (0.099)\tData 0.058 (0.074)\tLoss 0.6118 (0.6230)\tAcc 0.812 (0.795)\n",
      "Epoch: [33][8/9]\tTime 0.079 (0.096)\tData 0.057 (0.072)\tLoss 0.8091 (0.6463)\tAcc 0.688 (0.781)\n",
      "Epoch: [33][9/9]\tTime 0.078 (0.094)\tData 0.058 (0.071)\tLoss 0.3013 (0.6410)\tAcc 1.000 (0.785)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.314 (0.314)\tData 0.283 (0.283)\tLoss 0.5713 (0.5713)\tAcc 0.812 (0.812)\n",
      "Epoch: [34][2/5]\tTime 0.078 (0.196)\tData 0.052 (0.167)\tLoss 0.5344 (0.5528)\tAcc 0.875 (0.844)\n",
      "Epoch: [34][3/5]\tTime 0.080 (0.157)\tData 0.055 (0.130)\tLoss 1.0858 (0.7305)\tAcc 0.438 (0.708)\n",
      "Epoch: [34][4/5]\tTime 0.083 (0.139)\tData 0.058 (0.112)\tLoss 0.8503 (0.7604)\tAcc 0.625 (0.688)\n",
      "Epoch: [34][5/5]\tTime 0.083 (0.128)\tData 0.058 (0.101)\tLoss 0.3156 (0.7056)\tAcc 1.000 (0.726)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.244 (0.244)\tData 0.216 (0.216)\tLoss 0.3667 (0.3667)\tAcc 0.938 (0.938)\n",
      "Epoch: [34][2/9]\tTime 0.072 (0.158)\tData 0.051 (0.133)\tLoss 0.9017 (0.6342)\tAcc 0.562 (0.750)\n",
      "Epoch: [34][3/9]\tTime 0.074 (0.130)\tData 0.054 (0.107)\tLoss 0.7779 (0.6821)\tAcc 0.625 (0.708)\n",
      "Epoch: [34][4/9]\tTime 0.074 (0.116)\tData 0.053 (0.094)\tLoss 0.6703 (0.6791)\tAcc 0.688 (0.703)\n",
      "Epoch: [34][5/9]\tTime 0.076 (0.108)\tData 0.056 (0.086)\tLoss 0.6710 (0.6775)\tAcc 0.750 (0.713)\n",
      "Epoch: [34][6/9]\tTime 0.079 (0.103)\tData 0.058 (0.081)\tLoss 0.2839 (0.6119)\tAcc 1.000 (0.760)\n",
      "Epoch: [34][7/9]\tTime 0.076 (0.099)\tData 0.057 (0.078)\tLoss 0.6725 (0.6206)\tAcc 0.688 (0.750)\n",
      "Epoch: [34][8/9]\tTime 0.076 (0.096)\tData 0.056 (0.075)\tLoss 0.8416 (0.6482)\tAcc 0.688 (0.742)\n",
      "Epoch: [34][9/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.2993 (0.6428)\tAcc 1.000 (0.746)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.344 (0.344)\tData 0.316 (0.316)\tLoss 0.6962 (0.6962)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][2/5]\tTime 0.082 (0.213)\tData 0.057 (0.186)\tLoss 0.4742 (0.5852)\tAcc 0.875 (0.812)\n",
      "Epoch: [35][3/5]\tTime 0.081 (0.169)\tData 0.057 (0.143)\tLoss 0.6580 (0.6095)\tAcc 0.812 (0.812)\n",
      "Epoch: [35][4/5]\tTime 0.082 (0.147)\tData 0.058 (0.122)\tLoss 0.5276 (0.5890)\tAcc 0.812 (0.812)\n",
      "Epoch: [35][5/5]\tTime 0.081 (0.134)\tData 0.058 (0.109)\tLoss 0.8994 (0.6273)\tAcc 0.667 (0.795)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.227 (0.227)\tData 0.188 (0.188)\tLoss 0.3824 (0.3824)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/9]\tTime 0.078 (0.153)\tData 0.040 (0.114)\tLoss 0.7571 (0.5698)\tAcc 0.688 (0.812)\n",
      "Epoch: [35][3/9]\tTime 0.059 (0.121)\tData 0.038 (0.089)\tLoss 0.7698 (0.6364)\tAcc 0.688 (0.771)\n",
      "Epoch: [35][4/9]\tTime 0.077 (0.110)\tData 0.057 (0.081)\tLoss 0.5403 (0.6124)\tAcc 0.812 (0.781)\n",
      "Epoch: [35][5/9]\tTime 0.073 (0.103)\tData 0.053 (0.075)\tLoss 0.6807 (0.6261)\tAcc 0.750 (0.775)\n",
      "Epoch: [35][6/9]\tTime 0.079 (0.099)\tData 0.059 (0.073)\tLoss 0.2536 (0.5640)\tAcc 1.000 (0.812)\n",
      "Epoch: [35][7/9]\tTime 0.080 (0.096)\tData 0.059 (0.071)\tLoss 0.4984 (0.5546)\tAcc 0.812 (0.813)\n",
      "Epoch: [35][8/9]\tTime 0.080 (0.094)\tData 0.059 (0.069)\tLoss 0.8143 (0.5871)\tAcc 0.688 (0.797)\n",
      "Epoch: [35][9/9]\tTime 0.075 (0.092)\tData 0.055 (0.068)\tLoss 0.2854 (0.5824)\tAcc 1.000 (0.800)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.308 (0.308)\tData 0.271 (0.271)\tLoss 0.5882 (0.5882)\tAcc 0.812 (0.812)\n",
      "Epoch: [36][2/5]\tTime 0.073 (0.190)\tData 0.047 (0.159)\tLoss 0.8993 (0.7437)\tAcc 0.562 (0.688)\n",
      "Epoch: [36][3/5]\tTime 0.079 (0.153)\tData 0.054 (0.124)\tLoss 0.4859 (0.6578)\tAcc 0.875 (0.750)\n",
      "Epoch: [36][4/5]\tTime 0.078 (0.134)\tData 0.053 (0.107)\tLoss 0.8395 (0.7032)\tAcc 0.625 (0.719)\n",
      "Epoch: [36][5/5]\tTime 0.078 (0.123)\tData 0.054 (0.096)\tLoss 0.2507 (0.6474)\tAcc 1.000 (0.753)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.293 (0.293)\tData 0.222 (0.222)\tLoss 0.3165 (0.3165)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/9]\tTime 0.034 (0.164)\tData 0.007 (0.114)\tLoss 1.0397 (0.6781)\tAcc 0.562 (0.750)\n",
      "Epoch: [36][3/9]\tTime 0.067 (0.131)\tData 0.047 (0.092)\tLoss 0.8026 (0.7196)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][4/9]\tTime 0.075 (0.117)\tData 0.055 (0.083)\tLoss 0.5771 (0.6840)\tAcc 0.812 (0.766)\n",
      "Epoch: [36][5/9]\tTime 0.074 (0.109)\tData 0.054 (0.077)\tLoss 0.6601 (0.6792)\tAcc 0.750 (0.762)\n",
      "Epoch: [36][6/9]\tTime 0.074 (0.103)\tData 0.054 (0.073)\tLoss 0.2585 (0.6091)\tAcc 1.000 (0.802)\n",
      "Epoch: [36][7/9]\tTime 0.072 (0.098)\tData 0.053 (0.070)\tLoss 0.6123 (0.6095)\tAcc 0.812 (0.804)\n",
      "Epoch: [36][8/9]\tTime 0.077 (0.096)\tData 0.056 (0.068)\tLoss 0.9291 (0.6495)\tAcc 0.625 (0.781)\n",
      "Epoch: [36][9/9]\tTime 0.077 (0.094)\tData 0.056 (0.067)\tLoss 0.2402 (0.6432)\tAcc 1.000 (0.785)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.326 (0.326)\tData 0.299 (0.299)\tLoss 0.3724 (0.3724)\tAcc 0.875 (0.875)\n",
      "Epoch: [37][2/5]\tTime 0.075 (0.201)\tData 0.050 (0.175)\tLoss 0.6241 (0.4982)\tAcc 0.688 (0.781)\n",
      "Epoch: [37][3/5]\tTime 0.076 (0.159)\tData 0.052 (0.134)\tLoss 0.5925 (0.5296)\tAcc 0.812 (0.792)\n",
      "Epoch: [37][4/5]\tTime 0.079 (0.139)\tData 0.054 (0.114)\tLoss 0.9416 (0.6326)\tAcc 0.562 (0.734)\n",
      "Epoch: [37][5/5]\tTime 0.077 (0.127)\tData 0.053 (0.102)\tLoss 0.4947 (0.6156)\tAcc 0.889 (0.753)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.201 (0.201)\tData 0.171 (0.171)\tLoss 0.2774 (0.2774)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/9]\tTime 0.068 (0.134)\tData 0.045 (0.108)\tLoss 1.0413 (0.6593)\tAcc 0.562 (0.750)\n",
      "Epoch: [37][3/9]\tTime 0.076 (0.115)\tData 0.056 (0.091)\tLoss 0.8281 (0.7156)\tAcc 0.812 (0.771)\n",
      "Epoch: [37][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 0.7133 (0.7150)\tAcc 0.688 (0.750)\n",
      "Epoch: [37][5/9]\tTime 0.074 (0.098)\tData 0.053 (0.076)\tLoss 0.7264 (0.7173)\tAcc 0.750 (0.750)\n",
      "Epoch: [37][6/9]\tTime 0.073 (0.094)\tData 0.052 (0.072)\tLoss 0.2261 (0.6355)\tAcc 1.000 (0.792)\n",
      "Epoch: [37][7/9]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.6347 (0.6353)\tAcc 0.875 (0.804)\n",
      "Epoch: [37][8/9]\tTime 0.073 (0.089)\tData 0.053 (0.067)\tLoss 0.8471 (0.6618)\tAcc 0.625 (0.781)\n",
      "Epoch: [37][9/9]\tTime 0.072 (0.087)\tData 0.053 (0.066)\tLoss 0.2811 (0.6559)\tAcc 1.000 (0.785)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.278 (0.278)\tData 0.251 (0.251)\tLoss 0.7403 (0.7403)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][2/5]\tTime 0.075 (0.177)\tData 0.050 (0.150)\tLoss 0.4132 (0.5767)\tAcc 0.938 (0.844)\n",
      "Epoch: [38][3/5]\tTime 0.075 (0.143)\tData 0.052 (0.118)\tLoss 1.0427 (0.7321)\tAcc 0.562 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.078 (0.127)\tData 0.054 (0.102)\tLoss 0.6507 (0.7117)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][5/5]\tTime 0.076 (0.117)\tData 0.053 (0.092)\tLoss 0.8985 (0.7348)\tAcc 0.667 (0.740)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.209 (0.209)\tData 0.176 (0.176)\tLoss 0.3850 (0.3850)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.081 (0.145)\tData 0.045 (0.110)\tLoss 0.8337 (0.6093)\tAcc 0.562 (0.750)\n",
      "Epoch: [38][3/9]\tTime 0.056 (0.115)\tData 0.037 (0.086)\tLoss 0.5744 (0.5977)\tAcc 0.688 (0.729)\n",
      "Epoch: [38][4/9]\tTime 0.075 (0.105)\tData 0.055 (0.078)\tLoss 0.7180 (0.6277)\tAcc 0.688 (0.719)\n",
      "Epoch: [38][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.073)\tLoss 0.6148 (0.6252)\tAcc 0.812 (0.738)\n",
      "Epoch: [38][6/9]\tTime 0.073 (0.095)\tData 0.053 (0.070)\tLoss 0.2764 (0.5670)\tAcc 1.000 (0.781)\n",
      "Epoch: [38][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.068)\tLoss 0.5898 (0.5703)\tAcc 0.812 (0.786)\n",
      "Epoch: [38][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.066)\tLoss 0.9099 (0.6127)\tAcc 0.625 (0.766)\n",
      "Epoch: [38][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.065)\tLoss 0.3171 (0.6082)\tAcc 1.000 (0.769)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.326 (0.326)\tData 0.300 (0.300)\tLoss 0.5862 (0.5862)\tAcc 0.812 (0.812)\n",
      "Epoch: [39][2/5]\tTime 0.074 (0.200)\tData 0.051 (0.175)\tLoss 0.5485 (0.5673)\tAcc 0.812 (0.812)\n",
      "Epoch: [39][3/5]\tTime 0.077 (0.159)\tData 0.054 (0.135)\tLoss 0.7740 (0.6362)\tAcc 0.625 (0.750)\n",
      "Epoch: [39][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.115)\tLoss 0.5357 (0.6111)\tAcc 0.812 (0.766)\n",
      "Epoch: [39][5/5]\tTime 0.077 (0.126)\tData 0.054 (0.103)\tLoss 0.2834 (0.5707)\tAcc 1.000 (0.795)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.200 (0.200)\tData 0.175 (0.175)\tLoss 0.3957 (0.3957)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/9]\tTime 0.073 (0.137)\tData 0.049 (0.112)\tLoss 0.8559 (0.6258)\tAcc 0.688 (0.812)\n",
      "Epoch: [39][3/9]\tTime 0.069 (0.114)\tData 0.049 (0.091)\tLoss 0.7600 (0.6705)\tAcc 0.750 (0.792)\n",
      "Epoch: [39][4/9]\tTime 0.073 (0.104)\tData 0.053 (0.082)\tLoss 0.6994 (0.6778)\tAcc 0.750 (0.781)\n",
      "Epoch: [39][5/9]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.7888 (0.7000)\tAcc 0.750 (0.775)\n",
      "Epoch: [39][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2916 (0.6319)\tAcc 1.000 (0.812)\n",
      "Epoch: [39][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6235 (0.6307)\tAcc 0.750 (0.804)\n",
      "Epoch: [39][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 1.0719 (0.6859)\tAcc 0.562 (0.773)\n",
      "Epoch: [39][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2358 (0.6789)\tAcc 1.000 (0.777)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.270 (0.270)\tData 0.241 (0.241)\tLoss 0.5065 (0.5065)\tAcc 0.750 (0.750)\n",
      "Epoch: [40][2/5]\tTime 0.074 (0.172)\tData 0.049 (0.145)\tLoss 0.5576 (0.5320)\tAcc 0.812 (0.781)\n",
      "Epoch: [40][3/5]\tTime 0.076 (0.140)\tData 0.052 (0.114)\tLoss 0.6678 (0.5773)\tAcc 0.750 (0.771)\n",
      "Epoch: [40][4/5]\tTime 0.081 (0.125)\tData 0.057 (0.100)\tLoss 0.7677 (0.6249)\tAcc 0.750 (0.766)\n",
      "Epoch: [40][5/5]\tTime 0.077 (0.116)\tData 0.054 (0.091)\tLoss 0.5729 (0.6185)\tAcc 0.667 (0.753)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.213 (0.213)\tData 0.186 (0.186)\tLoss 0.3152 (0.3152)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/9]\tTime 0.073 (0.143)\tData 0.048 (0.117)\tLoss 0.9124 (0.6138)\tAcc 0.688 (0.812)\n",
      "Epoch: [40][3/9]\tTime 0.067 (0.118)\tData 0.048 (0.094)\tLoss 0.8456 (0.6910)\tAcc 0.750 (0.792)\n",
      "Epoch: [40][4/9]\tTime 0.072 (0.106)\tData 0.053 (0.084)\tLoss 0.4745 (0.6369)\tAcc 0.812 (0.797)\n",
      "Epoch: [40][5/9]\tTime 0.075 (0.100)\tData 0.054 (0.078)\tLoss 0.7123 (0.6520)\tAcc 0.750 (0.788)\n",
      "Epoch: [40][6/9]\tTime 0.075 (0.096)\tData 0.054 (0.074)\tLoss 0.2123 (0.5787)\tAcc 1.000 (0.823)\n",
      "Epoch: [40][7/9]\tTime 0.072 (0.093)\tData 0.052 (0.071)\tLoss 0.7896 (0.6088)\tAcc 0.688 (0.804)\n",
      "Epoch: [40][8/9]\tTime 0.077 (0.091)\tData 0.057 (0.069)\tLoss 0.8449 (0.6383)\tAcc 0.688 (0.789)\n",
      "Epoch: [40][9/9]\tTime 0.078 (0.089)\tData 0.059 (0.068)\tLoss 0.2290 (0.6320)\tAcc 1.000 (0.792)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.338 (0.338)\tData 0.306 (0.306)\tLoss 0.6491 (0.6491)\tAcc 0.750 (0.750)\n",
      "Epoch: [41][2/5]\tTime 0.071 (0.204)\tData 0.046 (0.176)\tLoss 0.6244 (0.6367)\tAcc 0.812 (0.781)\n",
      "Epoch: [41][3/5]\tTime 0.077 (0.162)\tData 0.052 (0.135)\tLoss 0.5675 (0.6137)\tAcc 0.812 (0.792)\n",
      "Epoch: [41][4/5]\tTime 0.077 (0.141)\tData 0.053 (0.114)\tLoss 0.7015 (0.6356)\tAcc 0.812 (0.797)\n",
      "Epoch: [41][5/5]\tTime 0.077 (0.128)\tData 0.053 (0.102)\tLoss 0.7962 (0.6554)\tAcc 0.778 (0.795)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.206 (0.206)\tData 0.178 (0.178)\tLoss 0.3041 (0.3041)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/9]\tTime 0.073 (0.140)\tData 0.046 (0.112)\tLoss 0.8382 (0.5712)\tAcc 0.562 (0.750)\n",
      "Epoch: [41][3/9]\tTime 0.066 (0.115)\tData 0.046 (0.090)\tLoss 0.7849 (0.6424)\tAcc 0.688 (0.729)\n",
      "Epoch: [41][4/9]\tTime 0.073 (0.105)\tData 0.053 (0.081)\tLoss 0.6485 (0.6439)\tAcc 0.812 (0.750)\n",
      "Epoch: [41][5/9]\tTime 0.073 (0.098)\tData 0.053 (0.075)\tLoss 0.7042 (0.6560)\tAcc 0.688 (0.738)\n",
      "Epoch: [41][6/9]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.2524 (0.5887)\tAcc 1.000 (0.781)\n",
      "Epoch: [41][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.7848 (0.6167)\tAcc 0.688 (0.768)\n",
      "Epoch: [41][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.9937 (0.6638)\tAcc 0.625 (0.750)\n",
      "Epoch: [41][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2591 (0.6576)\tAcc 1.000 (0.754)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.375 (0.375)\tData 0.345 (0.345)\tLoss 0.8576 (0.8576)\tAcc 0.562 (0.562)\n",
      "Epoch: [42][2/5]\tTime 0.081 (0.228)\tData 0.056 (0.201)\tLoss 0.5653 (0.7114)\tAcc 0.812 (0.688)\n",
      "Epoch: [42][3/5]\tTime 0.086 (0.181)\tData 0.061 (0.154)\tLoss 0.7060 (0.7096)\tAcc 0.750 (0.708)\n",
      "Epoch: [42][4/5]\tTime 0.084 (0.156)\tData 0.060 (0.130)\tLoss 0.7328 (0.7154)\tAcc 0.812 (0.734)\n",
      "Epoch: [42][5/5]\tTime 0.084 (0.142)\tData 0.059 (0.116)\tLoss 0.6410 (0.7063)\tAcc 0.889 (0.753)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.226 (0.226)\tData 0.176 (0.176)\tLoss 0.3246 (0.3246)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/9]\tTime 0.059 (0.143)\tData 0.033 (0.105)\tLoss 0.9266 (0.6256)\tAcc 0.562 (0.750)\n",
      "Epoch: [42][3/9]\tTime 0.073 (0.119)\tData 0.053 (0.087)\tLoss 0.9323 (0.7279)\tAcc 0.688 (0.729)\n",
      "Epoch: [42][4/9]\tTime 0.079 (0.109)\tData 0.059 (0.080)\tLoss 0.4642 (0.6620)\tAcc 0.750 (0.734)\n",
      "Epoch: [42][5/9]\tTime 0.081 (0.104)\tData 0.060 (0.076)\tLoss 0.9074 (0.7110)\tAcc 0.688 (0.725)\n",
      "Epoch: [42][6/9]\tTime 0.079 (0.100)\tData 0.059 (0.073)\tLoss 0.2625 (0.6363)\tAcc 1.000 (0.771)\n",
      "Epoch: [42][7/9]\tTime 0.079 (0.097)\tData 0.059 (0.071)\tLoss 0.7038 (0.6459)\tAcc 0.688 (0.759)\n",
      "Epoch: [42][8/9]\tTime 0.078 (0.094)\tData 0.059 (0.070)\tLoss 1.1013 (0.7028)\tAcc 0.625 (0.742)\n",
      "Epoch: [42][9/9]\tTime 0.079 (0.093)\tData 0.059 (0.069)\tLoss 0.3017 (0.6967)\tAcc 1.000 (0.746)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.256 (0.256)\tData 0.223 (0.223)\tLoss 0.7976 (0.7976)\tAcc 0.812 (0.812)\n",
      "Epoch: [43][2/5]\tTime 0.074 (0.165)\tData 0.049 (0.136)\tLoss 0.8157 (0.8067)\tAcc 0.750 (0.781)\n",
      "Epoch: [43][3/5]\tTime 0.079 (0.136)\tData 0.054 (0.109)\tLoss 0.7194 (0.7776)\tAcc 0.688 (0.750)\n",
      "Epoch: [43][4/5]\tTime 0.080 (0.122)\tData 0.056 (0.096)\tLoss 0.6410 (0.7434)\tAcc 0.812 (0.766)\n",
      "Epoch: [43][5/5]\tTime 0.080 (0.114)\tData 0.056 (0.088)\tLoss 0.3821 (0.6989)\tAcc 0.889 (0.781)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.207 (0.207)\tData 0.175 (0.175)\tLoss 0.2771 (0.2771)\tAcc 1.000 (1.000)\n",
      "Epoch: [43][2/9]\tTime 0.075 (0.141)\tData 0.046 (0.110)\tLoss 0.9860 (0.6315)\tAcc 0.438 (0.719)\n",
      "Epoch: [43][3/9]\tTime 0.069 (0.117)\tData 0.048 (0.090)\tLoss 0.7522 (0.6718)\tAcc 0.750 (0.729)\n",
      "Epoch: [43][4/9]\tTime 0.077 (0.107)\tData 0.056 (0.081)\tLoss 0.6178 (0.6583)\tAcc 0.750 (0.734)\n",
      "Epoch: [43][5/9]\tTime 0.075 (0.100)\tData 0.055 (0.076)\tLoss 0.6704 (0.6607)\tAcc 0.750 (0.738)\n",
      "Epoch: [43][6/9]\tTime 0.079 (0.097)\tData 0.059 (0.073)\tLoss 0.3146 (0.6030)\tAcc 1.000 (0.781)\n",
      "Epoch: [43][7/9]\tTime 0.076 (0.094)\tData 0.056 (0.071)\tLoss 0.5067 (0.5893)\tAcc 0.875 (0.795)\n",
      "Epoch: [43][8/9]\tTime 0.078 (0.092)\tData 0.058 (0.069)\tLoss 0.8363 (0.6201)\tAcc 0.625 (0.773)\n",
      "Epoch: [43][9/9]\tTime 0.076 (0.090)\tData 0.057 (0.068)\tLoss 0.3314 (0.6157)\tAcc 1.000 (0.777)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.314 (0.314)\tData 0.284 (0.284)\tLoss 0.6280 (0.6280)\tAcc 0.812 (0.812)\n",
      "Epoch: [44][2/5]\tTime 0.076 (0.195)\tData 0.050 (0.167)\tLoss 0.5776 (0.6028)\tAcc 0.875 (0.844)\n",
      "Epoch: [44][3/5]\tTime 0.079 (0.156)\tData 0.055 (0.130)\tLoss 0.4782 (0.5612)\tAcc 0.875 (0.854)\n",
      "Epoch: [44][4/5]\tTime 0.081 (0.137)\tData 0.057 (0.111)\tLoss 0.6016 (0.5713)\tAcc 0.750 (0.828)\n",
      "Epoch: [44][5/5]\tTime 0.082 (0.126)\tData 0.057 (0.101)\tLoss 0.8274 (0.6029)\tAcc 0.667 (0.808)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.209 (0.209)\tData 0.170 (0.170)\tLoss 0.3321 (0.3321)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.074 (0.142)\tData 0.041 (0.106)\tLoss 0.8558 (0.5940)\tAcc 0.625 (0.781)\n",
      "Epoch: [44][3/9]\tTime 0.067 (0.117)\tData 0.045 (0.085)\tLoss 0.7456 (0.6445)\tAcc 0.812 (0.792)\n",
      "Epoch: [44][4/9]\tTime 0.077 (0.107)\tData 0.057 (0.078)\tLoss 0.6942 (0.6569)\tAcc 0.812 (0.797)\n",
      "Epoch: [44][5/9]\tTime 0.078 (0.101)\tData 0.057 (0.074)\tLoss 0.7228 (0.6701)\tAcc 0.750 (0.788)\n",
      "Epoch: [44][6/9]\tTime 0.077 (0.097)\tData 0.057 (0.071)\tLoss 0.2212 (0.5953)\tAcc 1.000 (0.823)\n",
      "Epoch: [44][7/9]\tTime 0.078 (0.094)\tData 0.057 (0.069)\tLoss 0.5035 (0.5822)\tAcc 0.750 (0.813)\n",
      "Epoch: [44][8/9]\tTime 0.076 (0.092)\tData 0.055 (0.067)\tLoss 0.9781 (0.6317)\tAcc 0.562 (0.781)\n",
      "Epoch: [44][9/9]\tTime 0.077 (0.090)\tData 0.055 (0.066)\tLoss 0.1587 (0.6244)\tAcc 1.000 (0.785)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.229 (0.229)\tData 0.202 (0.202)\tLoss 0.3520 (0.3520)\tAcc 0.875 (0.875)\n",
      "Epoch: [45][2/5]\tTime 0.087 (0.158)\tData 0.061 (0.132)\tLoss 0.4735 (0.4127)\tAcc 0.812 (0.844)\n",
      "Epoch: [45][3/5]\tTime 0.076 (0.131)\tData 0.052 (0.105)\tLoss 1.0438 (0.6231)\tAcc 0.500 (0.729)\n",
      "Epoch: [45][4/5]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 0.6390 (0.6271)\tAcc 0.812 (0.750)\n",
      "Epoch: [45][5/5]\tTime 0.077 (0.109)\tData 0.054 (0.085)\tLoss 1.1361 (0.6898)\tAcc 0.667 (0.740)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.196 (0.196)\tData 0.173 (0.173)\tLoss 0.3178 (0.3178)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/9]\tTime 0.076 (0.136)\tData 0.051 (0.112)\tLoss 1.0040 (0.6609)\tAcc 0.500 (0.719)\n",
      "Epoch: [45][3/9]\tTime 0.068 (0.113)\tData 0.049 (0.091)\tLoss 0.6911 (0.6710)\tAcc 0.750 (0.729)\n",
      "Epoch: [45][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 0.5870 (0.6500)\tAcc 0.750 (0.734)\n",
      "Epoch: [45][5/9]\tTime 0.073 (0.097)\tData 0.054 (0.076)\tLoss 0.7340 (0.6668)\tAcc 0.750 (0.738)\n",
      "Epoch: [45][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2452 (0.5965)\tAcc 1.000 (0.781)\n",
      "Epoch: [45][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 0.7089 (0.6126)\tAcc 0.750 (0.777)\n",
      "Epoch: [45][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 1.0147 (0.6628)\tAcc 0.500 (0.742)\n",
      "Epoch: [45][9/9]\tTime 0.072 (0.086)\tData 0.054 (0.066)\tLoss 0.2335 (0.6562)\tAcc 1.000 (0.746)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.288 (0.288)\tData 0.261 (0.261)\tLoss 0.8549 (0.8549)\tAcc 0.688 (0.688)\n",
      "Epoch: [46][2/5]\tTime 0.077 (0.183)\tData 0.053 (0.157)\tLoss 0.5691 (0.7120)\tAcc 0.750 (0.719)\n",
      "Epoch: [46][3/5]\tTime 0.077 (0.147)\tData 0.053 (0.122)\tLoss 0.6408 (0.6883)\tAcc 0.812 (0.750)\n",
      "Epoch: [46][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.105)\tLoss 0.5528 (0.6544)\tAcc 0.812 (0.766)\n",
      "Epoch: [46][5/5]\tTime 0.077 (0.119)\tData 0.054 (0.095)\tLoss 0.6025 (0.6480)\tAcc 0.889 (0.781)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.197 (0.197)\tData 0.173 (0.173)\tLoss 0.2995 (0.2995)\tAcc 1.000 (1.000)\n",
      "Epoch: [46][2/9]\tTime 0.077 (0.137)\tData 0.050 (0.112)\tLoss 0.8591 (0.5793)\tAcc 0.688 (0.844)\n",
      "Epoch: [46][3/9]\tTime 0.067 (0.113)\tData 0.047 (0.090)\tLoss 0.8061 (0.6549)\tAcc 0.688 (0.792)\n",
      "Epoch: [46][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.081)\tLoss 0.6230 (0.6469)\tAcc 0.750 (0.781)\n",
      "Epoch: [46][5/9]\tTime 0.075 (0.098)\tData 0.053 (0.076)\tLoss 0.6857 (0.6547)\tAcc 0.750 (0.775)\n",
      "Epoch: [46][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.2536 (0.5878)\tAcc 1.000 (0.812)\n",
      "Epoch: [46][7/9]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.5858 (0.5875)\tAcc 0.812 (0.813)\n",
      "Epoch: [46][8/9]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.8226 (0.6169)\tAcc 0.688 (0.797)\n",
      "Epoch: [46][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.3073 (0.6121)\tAcc 1.000 (0.800)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.261 (0.261)\tData 0.232 (0.232)\tLoss 0.5459 (0.5459)\tAcc 0.875 (0.875)\n",
      "Epoch: [47][2/5]\tTime 0.074 (0.167)\tData 0.049 (0.140)\tLoss 0.6210 (0.5835)\tAcc 0.625 (0.750)\n",
      "Epoch: [47][3/5]\tTime 0.080 (0.138)\tData 0.057 (0.112)\tLoss 1.1209 (0.7626)\tAcc 0.562 (0.688)\n",
      "Epoch: [47][4/5]\tTime 0.077 (0.123)\tData 0.054 (0.098)\tLoss 0.6975 (0.7463)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][5/5]\tTime 0.077 (0.114)\tData 0.054 (0.089)\tLoss 0.9121 (0.7668)\tAcc 0.556 (0.671)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.207 (0.207)\tData 0.177 (0.177)\tLoss 0.3400 (0.3400)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/9]\tTime 0.074 (0.141)\tData 0.050 (0.114)\tLoss 0.8892 (0.6146)\tAcc 0.500 (0.719)\n",
      "Epoch: [47][3/9]\tTime 0.069 (0.117)\tData 0.050 (0.092)\tLoss 0.8073 (0.6788)\tAcc 0.750 (0.729)\n",
      "Epoch: [47][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.7259 (0.6906)\tAcc 0.625 (0.703)\n",
      "Epoch: [47][5/9]\tTime 0.073 (0.099)\tData 0.053 (0.077)\tLoss 0.7564 (0.7038)\tAcc 0.750 (0.713)\n",
      "Epoch: [47][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.2526 (0.6286)\tAcc 1.000 (0.760)\n",
      "Epoch: [47][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.5727 (0.6206)\tAcc 0.875 (0.777)\n",
      "Epoch: [47][8/9]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.9518 (0.6620)\tAcc 0.562 (0.750)\n",
      "Epoch: [47][9/9]\tTime 0.072 (0.088)\tData 0.054 (0.067)\tLoss 0.2552 (0.6557)\tAcc 1.000 (0.754)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.220 (0.220)\tData 0.192 (0.192)\tLoss 0.5662 (0.5662)\tAcc 0.750 (0.750)\n",
      "Epoch: [48][2/5]\tTime 0.074 (0.147)\tData 0.049 (0.120)\tLoss 0.8943 (0.7303)\tAcc 0.500 (0.625)\n",
      "Epoch: [48][3/5]\tTime 0.076 (0.123)\tData 0.053 (0.098)\tLoss 0.5627 (0.6744)\tAcc 0.750 (0.667)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.112)\tData 0.054 (0.087)\tLoss 0.9199 (0.7358)\tAcc 0.625 (0.656)\n",
      "Epoch: [48][5/5]\tTime 0.077 (0.105)\tData 0.054 (0.080)\tLoss 0.3526 (0.6885)\tAcc 1.000 (0.699)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.240 (0.240)\tData 0.207 (0.207)\tLoss 0.3757 (0.3757)\tAcc 0.875 (0.875)\n",
      "Epoch: [48][2/9]\tTime 0.071 (0.155)\tData 0.047 (0.127)\tLoss 0.7579 (0.5668)\tAcc 0.688 (0.781)\n",
      "Epoch: [48][3/9]\tTime 0.076 (0.129)\tData 0.056 (0.103)\tLoss 0.9560 (0.6965)\tAcc 0.625 (0.729)\n",
      "Epoch: [48][4/9]\tTime 0.081 (0.117)\tData 0.059 (0.092)\tLoss 0.5344 (0.6560)\tAcc 0.812 (0.750)\n",
      "Epoch: [48][5/9]\tTime 0.079 (0.109)\tData 0.059 (0.086)\tLoss 0.8855 (0.7019)\tAcc 0.688 (0.738)\n",
      "Epoch: [48][6/9]\tTime 0.076 (0.104)\tData 0.056 (0.081)\tLoss 0.2805 (0.6317)\tAcc 1.000 (0.781)\n",
      "Epoch: [48][7/9]\tTime 0.073 (0.099)\tData 0.053 (0.077)\tLoss 0.8129 (0.6576)\tAcc 0.688 (0.768)\n",
      "Epoch: [48][8/9]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.7469 (0.6687)\tAcc 0.688 (0.758)\n",
      "Epoch: [48][9/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.4705 (0.6657)\tAcc 1.000 (0.762)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.341 (0.341)\tData 0.312 (0.312)\tLoss 0.5837 (0.5837)\tAcc 0.812 (0.812)\n",
      "Epoch: [49][2/5]\tTime 0.076 (0.208)\tData 0.051 (0.182)\tLoss 0.6469 (0.6153)\tAcc 0.750 (0.781)\n",
      "Epoch: [49][3/5]\tTime 0.077 (0.164)\tData 0.053 (0.139)\tLoss 0.5051 (0.5786)\tAcc 0.875 (0.812)\n",
      "Epoch: [49][4/5]\tTime 0.077 (0.143)\tData 0.053 (0.117)\tLoss 0.5665 (0.5756)\tAcc 0.875 (0.828)\n",
      "Epoch: [49][5/5]\tTime 0.077 (0.129)\tData 0.053 (0.104)\tLoss 0.6646 (0.5865)\tAcc 0.778 (0.822)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.201 (0.201)\tData 0.177 (0.177)\tLoss 0.3618 (0.3618)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.076 (0.138)\tData 0.051 (0.114)\tLoss 0.8534 (0.6076)\tAcc 0.625 (0.781)\n",
      "Epoch: [49][3/9]\tTime 0.067 (0.115)\tData 0.048 (0.092)\tLoss 0.8023 (0.6725)\tAcc 0.750 (0.771)\n",
      "Epoch: [49][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.7784 (0.6990)\tAcc 0.688 (0.750)\n",
      "Epoch: [49][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.6953 (0.6982)\tAcc 0.688 (0.738)\n",
      "Epoch: [49][6/9]\tTime 0.072 (0.094)\tData 0.054 (0.073)\tLoss 0.3140 (0.6342)\tAcc 1.000 (0.781)\n",
      "Epoch: [49][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.7775 (0.6547)\tAcc 0.688 (0.768)\n",
      "Epoch: [49][8/9]\tTime 0.076 (0.089)\tData 0.056 (0.069)\tLoss 0.8621 (0.6806)\tAcc 0.688 (0.758)\n",
      "Epoch: [49][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.067)\tLoss 0.2807 (0.6744)\tAcc 1.000 (0.762)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.275 (0.275)\tData 0.248 (0.248)\tLoss 0.6161 (0.6161)\tAcc 0.750 (0.750)\n",
      "Epoch: [50][2/5]\tTime 0.078 (0.177)\tData 0.054 (0.151)\tLoss 0.5687 (0.5924)\tAcc 0.750 (0.750)\n",
      "Epoch: [50][3/5]\tTime 0.084 (0.146)\tData 0.060 (0.121)\tLoss 0.8180 (0.6676)\tAcc 0.688 (0.729)\n",
      "Epoch: [50][4/5]\tTime 0.082 (0.130)\tData 0.057 (0.105)\tLoss 0.5873 (0.6475)\tAcc 0.750 (0.734)\n",
      "Epoch: [50][5/5]\tTime 0.080 (0.120)\tData 0.056 (0.095)\tLoss 0.5429 (0.6346)\tAcc 0.889 (0.753)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.238 (0.238)\tData 0.206 (0.206)\tLoss 0.3365 (0.3365)\tAcc 1.000 (1.000)\n",
      "Epoch: [50][2/9]\tTime 0.076 (0.157)\tData 0.047 (0.127)\tLoss 0.8189 (0.5777)\tAcc 0.500 (0.750)\n",
      "Epoch: [50][3/9]\tTime 0.071 (0.128)\tData 0.050 (0.101)\tLoss 0.6842 (0.6132)\tAcc 0.750 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.076 (0.115)\tData 0.057 (0.090)\tLoss 0.5937 (0.6083)\tAcc 0.750 (0.750)\n",
      "Epoch: [50][5/9]\tTime 0.078 (0.108)\tData 0.058 (0.084)\tLoss 0.6385 (0.6144)\tAcc 0.812 (0.762)\n",
      "Epoch: [50][6/9]\tTime 0.077 (0.103)\tData 0.058 (0.079)\tLoss 0.2820 (0.5590)\tAcc 1.000 (0.802)\n",
      "Epoch: [50][7/9]\tTime 0.076 (0.099)\tData 0.056 (0.076)\tLoss 0.7488 (0.5861)\tAcc 0.812 (0.804)\n",
      "Epoch: [50][8/9]\tTime 0.077 (0.096)\tData 0.057 (0.074)\tLoss 0.8389 (0.6177)\tAcc 0.688 (0.789)\n",
      "Epoch: [50][9/9]\tTime 0.077 (0.094)\tData 0.058 (0.072)\tLoss 0.2286 (0.6117)\tAcc 1.000 (0.792)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.280 (0.280)\tData 0.237 (0.237)\tLoss 0.5232 (0.5232)\tAcc 0.812 (0.812)\n",
      "Epoch: [51][2/5]\tTime 0.071 (0.176)\tData 0.043 (0.140)\tLoss 0.5366 (0.5299)\tAcc 0.875 (0.844)\n",
      "Epoch: [51][3/5]\tTime 0.083 (0.145)\tData 0.058 (0.113)\tLoss 0.6315 (0.5638)\tAcc 0.688 (0.792)\n",
      "Epoch: [51][4/5]\tTime 0.086 (0.130)\tData 0.060 (0.100)\tLoss 0.5575 (0.5622)\tAcc 0.812 (0.797)\n",
      "Epoch: [51][5/5]\tTime 0.084 (0.121)\tData 0.060 (0.092)\tLoss 0.4792 (0.5520)\tAcc 0.778 (0.795)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.287 (0.287)\tData 0.240 (0.240)\tLoss 0.4815 (0.4815)\tAcc 0.875 (0.875)\n",
      "Epoch: [51][2/9]\tTime 0.056 (0.172)\tData 0.031 (0.136)\tLoss 0.9330 (0.7073)\tAcc 0.562 (0.719)\n",
      "Epoch: [51][3/9]\tTime 0.074 (0.139)\tData 0.054 (0.108)\tLoss 0.7586 (0.7244)\tAcc 0.750 (0.729)\n",
      "Epoch: [51][4/9]\tTime 0.079 (0.124)\tData 0.059 (0.096)\tLoss 0.5586 (0.6829)\tAcc 0.750 (0.734)\n",
      "Epoch: [51][5/9]\tTime 0.080 (0.116)\tData 0.059 (0.089)\tLoss 0.6712 (0.6806)\tAcc 0.750 (0.738)\n",
      "Epoch: [51][6/9]\tTime 0.080 (0.110)\tData 0.059 (0.084)\tLoss 0.2604 (0.6105)\tAcc 1.000 (0.781)\n",
      "Epoch: [51][7/9]\tTime 0.080 (0.105)\tData 0.059 (0.080)\tLoss 0.7413 (0.6292)\tAcc 0.750 (0.777)\n",
      "Epoch: [51][8/9]\tTime 0.076 (0.102)\tData 0.056 (0.077)\tLoss 0.9070 (0.6639)\tAcc 0.625 (0.758)\n",
      "Epoch: [51][9/9]\tTime 0.073 (0.098)\tData 0.053 (0.074)\tLoss 0.2031 (0.6569)\tAcc 1.000 (0.762)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.265 (0.265)\tData 0.236 (0.236)\tLoss 0.3942 (0.3942)\tAcc 0.812 (0.812)\n",
      "Epoch: [52][2/5]\tTime 0.082 (0.173)\tData 0.057 (0.146)\tLoss 0.5998 (0.4970)\tAcc 0.750 (0.781)\n",
      "Epoch: [52][3/5]\tTime 0.085 (0.144)\tData 0.060 (0.117)\tLoss 0.6773 (0.5571)\tAcc 0.688 (0.750)\n",
      "Epoch: [52][4/5]\tTime 0.084 (0.129)\tData 0.060 (0.103)\tLoss 0.7995 (0.6177)\tAcc 0.625 (0.719)\n",
      "Epoch: [52][5/5]\tTime 0.085 (0.120)\tData 0.061 (0.095)\tLoss 0.8675 (0.6485)\tAcc 0.667 (0.712)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.272 (0.272)\tData 0.237 (0.237)\tLoss 0.3650 (0.3650)\tAcc 0.938 (0.938)\n",
      "Epoch: [52][2/9]\tTime 0.064 (0.168)\tData 0.043 (0.140)\tLoss 0.7726 (0.5688)\tAcc 0.688 (0.812)\n",
      "Epoch: [52][3/9]\tTime 0.077 (0.138)\tData 0.057 (0.113)\tLoss 0.6384 (0.5920)\tAcc 0.750 (0.792)\n",
      "Epoch: [52][4/9]\tTime 0.077 (0.123)\tData 0.057 (0.099)\tLoss 0.5548 (0.5827)\tAcc 0.750 (0.781)\n",
      "Epoch: [52][5/9]\tTime 0.076 (0.113)\tData 0.055 (0.090)\tLoss 0.6902 (0.6042)\tAcc 0.750 (0.775)\n",
      "Epoch: [52][6/9]\tTime 0.078 (0.107)\tData 0.058 (0.085)\tLoss 0.2359 (0.5428)\tAcc 1.000 (0.812)\n",
      "Epoch: [52][7/9]\tTime 0.079 (0.103)\tData 0.059 (0.081)\tLoss 0.7002 (0.5653)\tAcc 0.750 (0.804)\n",
      "Epoch: [52][8/9]\tTime 0.079 (0.100)\tData 0.059 (0.078)\tLoss 0.9635 (0.6151)\tAcc 0.625 (0.781)\n",
      "Epoch: [52][9/9]\tTime 0.079 (0.098)\tData 0.059 (0.076)\tLoss 0.2230 (0.6090)\tAcc 1.000 (0.785)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.225 (0.225)\tData 0.181 (0.181)\tLoss 0.6132 (0.6132)\tAcc 0.812 (0.812)\n",
      "Epoch: [53][2/5]\tTime 0.062 (0.144)\tData 0.037 (0.109)\tLoss 0.8871 (0.7502)\tAcc 0.625 (0.719)\n",
      "Epoch: [53][3/5]\tTime 0.080 (0.122)\tData 0.055 (0.091)\tLoss 0.4564 (0.6523)\tAcc 0.812 (0.750)\n",
      "Epoch: [53][4/5]\tTime 0.078 (0.111)\tData 0.054 (0.082)\tLoss 0.5277 (0.6211)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][5/5]\tTime 0.077 (0.104)\tData 0.054 (0.076)\tLoss 0.5718 (0.6150)\tAcc 0.778 (0.753)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.206 (0.206)\tData 0.177 (0.177)\tLoss 0.3354 (0.3354)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/9]\tTime 0.076 (0.141)\tData 0.050 (0.113)\tLoss 0.8523 (0.5938)\tAcc 0.562 (0.750)\n",
      "Epoch: [53][3/9]\tTime 0.072 (0.118)\tData 0.052 (0.093)\tLoss 0.7728 (0.6535)\tAcc 0.625 (0.708)\n",
      "Epoch: [53][4/9]\tTime 0.078 (0.108)\tData 0.058 (0.084)\tLoss 0.6038 (0.6411)\tAcc 0.750 (0.719)\n",
      "Epoch: [53][5/9]\tTime 0.079 (0.102)\tData 0.058 (0.079)\tLoss 0.7211 (0.6571)\tAcc 0.688 (0.713)\n",
      "Epoch: [53][6/9]\tTime 0.078 (0.098)\tData 0.058 (0.076)\tLoss 0.2797 (0.5942)\tAcc 1.000 (0.760)\n",
      "Epoch: [53][7/9]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.7251 (0.6129)\tAcc 0.750 (0.759)\n",
      "Epoch: [53][8/9]\tTime 0.078 (0.093)\tData 0.058 (0.071)\tLoss 1.0488 (0.6674)\tAcc 0.562 (0.734)\n",
      "Epoch: [53][9/9]\tTime 0.079 (0.091)\tData 0.059 (0.070)\tLoss 0.2465 (0.6609)\tAcc 1.000 (0.738)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.226 (0.226)\tData 0.197 (0.197)\tLoss 0.6854 (0.6854)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][2/5]\tTime 0.077 (0.152)\tData 0.052 (0.124)\tLoss 0.8686 (0.7770)\tAcc 0.625 (0.688)\n",
      "Epoch: [54][3/5]\tTime 0.081 (0.128)\tData 0.057 (0.102)\tLoss 0.6363 (0.7301)\tAcc 0.812 (0.729)\n",
      "Epoch: [54][4/5]\tTime 0.086 (0.118)\tData 0.060 (0.091)\tLoss 0.3934 (0.6459)\tAcc 0.938 (0.781)\n",
      "Epoch: [54][5/5]\tTime 0.081 (0.110)\tData 0.057 (0.085)\tLoss 0.4505 (0.6219)\tAcc 0.778 (0.781)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.197 (0.197)\tData 0.169 (0.169)\tLoss 0.3437 (0.3437)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/9]\tTime 0.072 (0.135)\tData 0.048 (0.109)\tLoss 0.8842 (0.6140)\tAcc 0.562 (0.750)\n",
      "Epoch: [54][3/9]\tTime 0.077 (0.116)\tData 0.056 (0.091)\tLoss 0.7915 (0.6731)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][4/9]\tTime 0.078 (0.106)\tData 0.057 (0.083)\tLoss 0.6215 (0.6602)\tAcc 0.688 (0.734)\n",
      "Epoch: [54][5/9]\tTime 0.080 (0.101)\tData 0.059 (0.078)\tLoss 0.6320 (0.6546)\tAcc 0.750 (0.738)\n",
      "Epoch: [54][6/9]\tTime 0.077 (0.097)\tData 0.056 (0.074)\tLoss 0.2334 (0.5844)\tAcc 1.000 (0.781)\n",
      "Epoch: [54][7/9]\tTime 0.075 (0.094)\tData 0.054 (0.072)\tLoss 0.6818 (0.5983)\tAcc 0.688 (0.768)\n",
      "Epoch: [54][8/9]\tTime 0.076 (0.092)\tData 0.056 (0.070)\tLoss 1.0116 (0.6500)\tAcc 0.562 (0.742)\n",
      "Epoch: [54][9/9]\tTime 0.079 (0.090)\tData 0.058 (0.068)\tLoss 0.3182 (0.6449)\tAcc 1.000 (0.746)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.228 (0.228)\tData 0.189 (0.189)\tLoss 0.7153 (0.7153)\tAcc 0.688 (0.688)\n",
      "Epoch: [55][2/5]\tTime 0.070 (0.149)\tData 0.045 (0.117)\tLoss 0.5557 (0.6355)\tAcc 0.875 (0.781)\n",
      "Epoch: [55][3/5]\tTime 0.085 (0.128)\tData 0.060 (0.098)\tLoss 1.1246 (0.7985)\tAcc 0.500 (0.688)\n",
      "Epoch: [55][4/5]\tTime 0.084 (0.117)\tData 0.059 (0.088)\tLoss 0.2940 (0.6724)\tAcc 0.875 (0.734)\n",
      "Epoch: [55][5/5]\tTime 0.085 (0.111)\tData 0.060 (0.083)\tLoss 0.5443 (0.6566)\tAcc 0.889 (0.753)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.213 (0.213)\tData 0.185 (0.185)\tLoss 0.3713 (0.3713)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/9]\tTime 0.079 (0.146)\tData 0.046 (0.116)\tLoss 0.8707 (0.6210)\tAcc 0.625 (0.781)\n",
      "Epoch: [55][3/9]\tTime 0.065 (0.119)\tData 0.045 (0.092)\tLoss 0.8155 (0.6859)\tAcc 0.688 (0.750)\n",
      "Epoch: [55][4/9]\tTime 0.073 (0.107)\tData 0.053 (0.082)\tLoss 0.5787 (0.6591)\tAcc 0.812 (0.766)\n",
      "Epoch: [55][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.077)\tLoss 0.7942 (0.6861)\tAcc 0.688 (0.750)\n",
      "Epoch: [55][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.073)\tLoss 0.3006 (0.6218)\tAcc 0.938 (0.781)\n",
      "Epoch: [55][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.070)\tLoss 0.5158 (0.6067)\tAcc 0.812 (0.786)\n",
      "Epoch: [55][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.7774 (0.6280)\tAcc 0.625 (0.766)\n",
      "Epoch: [55][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.2481 (0.6222)\tAcc 1.000 (0.769)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.251 (0.251)\tData 0.223 (0.223)\tLoss 0.6987 (0.6987)\tAcc 0.750 (0.750)\n",
      "Epoch: [56][2/5]\tTime 0.077 (0.164)\tData 0.054 (0.138)\tLoss 0.6890 (0.6939)\tAcc 0.688 (0.719)\n",
      "Epoch: [56][3/5]\tTime 0.078 (0.136)\tData 0.054 (0.110)\tLoss 0.4181 (0.6019)\tAcc 0.875 (0.771)\n",
      "Epoch: [56][4/5]\tTime 0.081 (0.122)\tData 0.057 (0.097)\tLoss 0.5811 (0.5967)\tAcc 0.812 (0.781)\n",
      "Epoch: [56][5/5]\tTime 0.078 (0.113)\tData 0.055 (0.088)\tLoss 0.6319 (0.6011)\tAcc 0.667 (0.767)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.200 (0.200)\tData 0.173 (0.173)\tLoss 0.3673 (0.3673)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/9]\tTime 0.075 (0.138)\tData 0.049 (0.111)\tLoss 0.9809 (0.6741)\tAcc 0.500 (0.719)\n",
      "Epoch: [56][3/9]\tTime 0.067 (0.114)\tData 0.048 (0.090)\tLoss 0.6982 (0.6821)\tAcc 0.750 (0.729)\n",
      "Epoch: [56][4/9]\tTime 0.073 (0.104)\tData 0.053 (0.081)\tLoss 0.5249 (0.6428)\tAcc 0.750 (0.734)\n",
      "Epoch: [56][5/9]\tTime 0.073 (0.098)\tData 0.054 (0.075)\tLoss 0.7098 (0.6562)\tAcc 0.688 (0.725)\n",
      "Epoch: [56][6/9]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.2523 (0.5889)\tAcc 1.000 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 0.7694 (0.6147)\tAcc 0.688 (0.759)\n",
      "Epoch: [56][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.9898 (0.6616)\tAcc 0.562 (0.734)\n",
      "Epoch: [56][9/9]\tTime 0.075 (0.087)\tData 0.055 (0.066)\tLoss 0.2226 (0.6548)\tAcc 1.000 (0.738)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.252 (0.252)\tData 0.223 (0.223)\tLoss 0.6194 (0.6194)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][2/5]\tTime 0.079 (0.165)\tData 0.055 (0.139)\tLoss 0.3102 (0.4648)\tAcc 0.938 (0.844)\n",
      "Epoch: [57][3/5]\tTime 0.077 (0.136)\tData 0.053 (0.110)\tLoss 0.7156 (0.5484)\tAcc 0.750 (0.812)\n",
      "Epoch: [57][4/5]\tTime 0.077 (0.121)\tData 0.053 (0.096)\tLoss 1.0505 (0.6739)\tAcc 0.688 (0.781)\n",
      "Epoch: [57][5/5]\tTime 0.078 (0.112)\tData 0.053 (0.087)\tLoss 0.7086 (0.6782)\tAcc 0.778 (0.781)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.199 (0.199)\tData 0.174 (0.174)\tLoss 0.2984 (0.2984)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/9]\tTime 0.078 (0.139)\tData 0.051 (0.113)\tLoss 0.8489 (0.5737)\tAcc 0.562 (0.750)\n",
      "Epoch: [57][3/9]\tTime 0.074 (0.117)\tData 0.054 (0.093)\tLoss 0.8369 (0.6614)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.6436 (0.6570)\tAcc 0.688 (0.734)\n",
      "Epoch: [57][5/9]\tTime 0.073 (0.100)\tData 0.053 (0.077)\tLoss 0.7936 (0.6843)\tAcc 0.688 (0.725)\n",
      "Epoch: [57][6/9]\tTime 0.073 (0.095)\tData 0.053 (0.073)\tLoss 0.2540 (0.6126)\tAcc 1.000 (0.771)\n",
      "Epoch: [57][7/9]\tTime 0.073 (0.092)\tData 0.053 (0.070)\tLoss 0.7248 (0.6286)\tAcc 0.750 (0.768)\n",
      "Epoch: [57][8/9]\tTime 0.073 (0.090)\tData 0.053 (0.068)\tLoss 0.9417 (0.6677)\tAcc 0.625 (0.750)\n",
      "Epoch: [57][9/9]\tTime 0.073 (0.088)\tData 0.053 (0.067)\tLoss 0.2126 (0.6607)\tAcc 1.000 (0.754)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.310 (0.310)\tData 0.280 (0.280)\tLoss 0.8209 (0.8209)\tAcc 0.688 (0.688)\n",
      "Epoch: [58][2/5]\tTime 0.073 (0.192)\tData 0.048 (0.164)\tLoss 0.6544 (0.7377)\tAcc 0.812 (0.750)\n",
      "Epoch: [58][3/5]\tTime 0.076 (0.153)\tData 0.052 (0.127)\tLoss 0.4511 (0.6421)\tAcc 0.938 (0.812)\n",
      "Epoch: [58][4/5]\tTime 0.078 (0.134)\tData 0.053 (0.108)\tLoss 0.5351 (0.6154)\tAcc 0.875 (0.828)\n",
      "Epoch: [58][5/5]\tTime 0.082 (0.124)\tData 0.057 (0.098)\tLoss 0.5141 (0.6029)\tAcc 0.778 (0.822)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.224 (0.224)\tData 0.194 (0.194)\tLoss 0.3329 (0.3329)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/9]\tTime 0.075 (0.149)\tData 0.044 (0.119)\tLoss 0.7478 (0.5403)\tAcc 0.688 (0.812)\n",
      "Epoch: [58][3/9]\tTime 0.063 (0.121)\tData 0.043 (0.094)\tLoss 0.8194 (0.6333)\tAcc 0.688 (0.771)\n",
      "Epoch: [58][4/9]\tTime 0.073 (0.109)\tData 0.053 (0.084)\tLoss 0.6145 (0.6286)\tAcc 0.812 (0.781)\n",
      "Epoch: [58][5/9]\tTime 0.073 (0.102)\tData 0.053 (0.078)\tLoss 0.6387 (0.6306)\tAcc 0.812 (0.788)\n",
      "Epoch: [58][6/9]\tTime 0.073 (0.097)\tData 0.054 (0.074)\tLoss 0.2149 (0.5613)\tAcc 1.000 (0.823)\n",
      "Epoch: [58][7/9]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.6668 (0.5764)\tAcc 0.812 (0.821)\n",
      "Epoch: [58][8/9]\tTime 0.073 (0.091)\tData 0.053 (0.069)\tLoss 1.0324 (0.6334)\tAcc 0.688 (0.805)\n",
      "Epoch: [58][9/9]\tTime 0.072 (0.089)\tData 0.053 (0.067)\tLoss 0.2031 (0.6268)\tAcc 1.000 (0.808)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.236 (0.236)\tData 0.209 (0.209)\tLoss 0.8401 (0.8401)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][2/5]\tTime 0.075 (0.155)\tData 0.051 (0.130)\tLoss 0.7491 (0.7946)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][3/5]\tTime 0.077 (0.129)\tData 0.053 (0.104)\tLoss 0.9602 (0.8498)\tAcc 0.688 (0.688)\n",
      "Epoch: [59][4/5]\tTime 0.079 (0.117)\tData 0.056 (0.092)\tLoss 0.5246 (0.7685)\tAcc 0.875 (0.734)\n",
      "Epoch: [59][5/5]\tTime 0.077 (0.109)\tData 0.054 (0.084)\tLoss 0.6118 (0.7492)\tAcc 0.889 (0.753)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.202 (0.202)\tData 0.166 (0.166)\tLoss 0.4417 (0.4417)\tAcc 0.875 (0.875)\n",
      "Epoch: [59][2/9]\tTime 0.060 (0.131)\tData 0.039 (0.103)\tLoss 0.9002 (0.6709)\tAcc 0.500 (0.688)\n",
      "Epoch: [59][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.086)\tLoss 0.9486 (0.7635)\tAcc 0.750 (0.708)\n",
      "Epoch: [59][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.078)\tLoss 0.6064 (0.7242)\tAcc 0.812 (0.734)\n",
      "Epoch: [59][5/9]\tTime 0.073 (0.096)\tData 0.054 (0.073)\tLoss 0.9154 (0.7624)\tAcc 0.750 (0.738)\n",
      "Epoch: [59][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.3124 (0.6874)\tAcc 1.000 (0.781)\n",
      "Epoch: [59][7/9]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.5158 (0.6629)\tAcc 0.875 (0.795)\n",
      "Epoch: [59][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.066)\tLoss 0.8271 (0.6834)\tAcc 0.750 (0.789)\n",
      "Epoch: [59][9/9]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.2087 (0.6761)\tAcc 1.000 (0.792)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.300 (0.300)\tData 0.271 (0.271)\tLoss 0.6519 (0.6519)\tAcc 0.812 (0.812)\n",
      "Epoch: [60][2/5]\tTime 0.074 (0.187)\tData 0.049 (0.160)\tLoss 0.6903 (0.6711)\tAcc 0.750 (0.781)\n",
      "Epoch: [60][3/5]\tTime 0.084 (0.153)\tData 0.059 (0.126)\tLoss 0.5893 (0.6438)\tAcc 0.750 (0.771)\n",
      "Epoch: [60][4/5]\tTime 0.081 (0.135)\tData 0.057 (0.109)\tLoss 0.6116 (0.6358)\tAcc 0.812 (0.781)\n",
      "Epoch: [60][5/5]\tTime 0.078 (0.123)\tData 0.055 (0.098)\tLoss 0.2881 (0.5929)\tAcc 1.000 (0.808)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.3131 (0.3131)\tAcc 0.938 (0.938)\n",
      "Epoch: [60][2/9]\tTime 0.072 (0.137)\tData 0.046 (0.110)\tLoss 0.9110 (0.6120)\tAcc 0.500 (0.719)\n",
      "Epoch: [60][3/9]\tTime 0.070 (0.114)\tData 0.050 (0.090)\tLoss 0.8655 (0.6965)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][4/9]\tTime 0.073 (0.104)\tData 0.053 (0.081)\tLoss 0.5823 (0.6680)\tAcc 0.812 (0.719)\n",
      "Epoch: [60][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.075)\tLoss 0.8145 (0.6973)\tAcc 0.750 (0.725)\n",
      "Epoch: [60][6/9]\tTime 0.072 (0.094)\tData 0.053 (0.072)\tLoss 0.2797 (0.6277)\tAcc 1.000 (0.771)\n",
      "Epoch: [60][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.7167 (0.6404)\tAcc 0.812 (0.777)\n",
      "Epoch: [60][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.9760 (0.6823)\tAcc 0.625 (0.758)\n",
      "Epoch: [60][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.066)\tLoss 0.1980 (0.6749)\tAcc 1.000 (0.762)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.216 (0.216)\tData 0.189 (0.189)\tLoss 0.4970 (0.4970)\tAcc 0.812 (0.812)\n",
      "Epoch: [61][2/5]\tTime 0.075 (0.145)\tData 0.051 (0.120)\tLoss 1.0804 (0.7887)\tAcc 0.500 (0.656)\n",
      "Epoch: [61][3/5]\tTime 0.077 (0.122)\tData 0.054 (0.098)\tLoss 0.7600 (0.7791)\tAcc 0.750 (0.688)\n",
      "Epoch: [61][4/5]\tTime 0.077 (0.111)\tData 0.054 (0.087)\tLoss 0.5859 (0.7308)\tAcc 0.812 (0.719)\n",
      "Epoch: [61][5/5]\tTime 0.076 (0.104)\tData 0.054 (0.080)\tLoss 0.3435 (0.6831)\tAcc 0.889 (0.740)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.249 (0.249)\tData 0.197 (0.197)\tLoss 0.3806 (0.3806)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.054 (0.151)\tData 0.026 (0.111)\tLoss 0.7820 (0.5813)\tAcc 0.688 (0.812)\n",
      "Epoch: [61][3/9]\tTime 0.069 (0.124)\tData 0.050 (0.091)\tLoss 0.7609 (0.6412)\tAcc 0.688 (0.771)\n",
      "Epoch: [61][4/9]\tTime 0.073 (0.111)\tData 0.054 (0.082)\tLoss 0.6280 (0.6379)\tAcc 0.812 (0.781)\n",
      "Epoch: [61][5/9]\tTime 0.073 (0.104)\tData 0.053 (0.076)\tLoss 0.7449 (0.6593)\tAcc 0.750 (0.775)\n",
      "Epoch: [61][6/9]\tTime 0.074 (0.099)\tData 0.053 (0.072)\tLoss 0.2595 (0.5927)\tAcc 1.000 (0.812)\n",
      "Epoch: [61][7/9]\tTime 0.078 (0.096)\tData 0.057 (0.070)\tLoss 0.6540 (0.6014)\tAcc 0.875 (0.821)\n",
      "Epoch: [61][8/9]\tTime 0.076 (0.093)\tData 0.056 (0.068)\tLoss 0.8045 (0.6268)\tAcc 0.750 (0.812)\n",
      "Epoch: [61][9/9]\tTime 0.074 (0.091)\tData 0.055 (0.067)\tLoss 0.2719 (0.6214)\tAcc 1.000 (0.815)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.239 (0.239)\tData 0.211 (0.211)\tLoss 0.9315 (0.9315)\tAcc 0.688 (0.688)\n",
      "Epoch: [62][2/5]\tTime 0.075 (0.157)\tData 0.050 (0.131)\tLoss 0.4042 (0.6678)\tAcc 0.812 (0.750)\n",
      "Epoch: [62][3/5]\tTime 0.076 (0.130)\tData 0.052 (0.105)\tLoss 0.8110 (0.7156)\tAcc 0.688 (0.729)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 0.6533 (0.7000)\tAcc 0.750 (0.734)\n",
      "Epoch: [62][5/5]\tTime 0.079 (0.109)\tData 0.054 (0.084)\tLoss 0.4114 (0.6644)\tAcc 0.778 (0.740)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.215 (0.215)\tData 0.178 (0.178)\tLoss 0.3359 (0.3359)\tAcc 0.938 (0.938)\n",
      "Epoch: [62][2/9]\tTime 0.065 (0.140)\tData 0.038 (0.108)\tLoss 0.7932 (0.5645)\tAcc 0.625 (0.781)\n",
      "Epoch: [62][3/9]\tTime 0.068 (0.116)\tData 0.048 (0.088)\tLoss 0.7640 (0.6310)\tAcc 0.750 (0.771)\n",
      "Epoch: [62][4/9]\tTime 0.076 (0.106)\tData 0.056 (0.080)\tLoss 0.6097 (0.6257)\tAcc 0.750 (0.766)\n",
      "Epoch: [62][5/9]\tTime 0.075 (0.100)\tData 0.056 (0.075)\tLoss 0.6649 (0.6336)\tAcc 0.812 (0.775)\n",
      "Epoch: [62][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.072)\tLoss 0.2330 (0.5668)\tAcc 1.000 (0.812)\n",
      "Epoch: [62][7/9]\tTime 0.075 (0.092)\tData 0.054 (0.069)\tLoss 0.7274 (0.5897)\tAcc 0.750 (0.804)\n",
      "Epoch: [62][8/9]\tTime 0.076 (0.090)\tData 0.056 (0.067)\tLoss 0.8060 (0.6168)\tAcc 0.562 (0.773)\n",
      "Epoch: [62][9/9]\tTime 0.077 (0.089)\tData 0.058 (0.066)\tLoss 0.2210 (0.6107)\tAcc 1.000 (0.777)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.223 (0.223)\tData 0.194 (0.194)\tLoss 0.6125 (0.6125)\tAcc 0.750 (0.750)\n",
      "Epoch: [63][2/5]\tTime 0.073 (0.148)\tData 0.049 (0.121)\tLoss 0.7245 (0.6685)\tAcc 0.750 (0.750)\n",
      "Epoch: [63][3/5]\tTime 0.077 (0.124)\tData 0.053 (0.098)\tLoss 0.5109 (0.6160)\tAcc 0.812 (0.771)\n",
      "Epoch: [63][4/5]\tTime 0.081 (0.114)\tData 0.056 (0.088)\tLoss 0.5311 (0.5948)\tAcc 0.812 (0.781)\n",
      "Epoch: [63][5/5]\tTime 0.077 (0.106)\tData 0.053 (0.081)\tLoss 1.0738 (0.6538)\tAcc 0.667 (0.767)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.194 (0.194)\tData 0.165 (0.165)\tLoss 0.3222 (0.3222)\tAcc 0.938 (0.938)\n",
      "Epoch: [63][2/9]\tTime 0.077 (0.136)\tData 0.048 (0.106)\tLoss 0.7045 (0.5133)\tAcc 0.750 (0.844)\n",
      "Epoch: [63][3/9]\tTime 0.068 (0.113)\tData 0.049 (0.087)\tLoss 0.7704 (0.5990)\tAcc 0.750 (0.812)\n",
      "Epoch: [63][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.079)\tLoss 0.6779 (0.6187)\tAcc 0.688 (0.781)\n",
      "Epoch: [63][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.074)\tLoss 1.0979 (0.7146)\tAcc 0.625 (0.750)\n",
      "Epoch: [63][6/9]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.3071 (0.6466)\tAcc 1.000 (0.792)\n",
      "Epoch: [63][7/9]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 0.7102 (0.6557)\tAcc 0.688 (0.777)\n",
      "Epoch: [63][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 0.8769 (0.6834)\tAcc 0.625 (0.758)\n",
      "Epoch: [63][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.1932 (0.6758)\tAcc 1.000 (0.762)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.256 (0.256)\tData 0.228 (0.228)\tLoss 1.0844 (1.0844)\tAcc 0.500 (0.500)\n",
      "Epoch: [64][2/5]\tTime 0.077 (0.166)\tData 0.051 (0.140)\tLoss 0.5333 (0.8089)\tAcc 0.750 (0.625)\n",
      "Epoch: [64][3/5]\tTime 0.077 (0.137)\tData 0.053 (0.111)\tLoss 0.5221 (0.7133)\tAcc 0.812 (0.688)\n",
      "Epoch: [64][4/5]\tTime 0.084 (0.123)\tData 0.060 (0.098)\tLoss 0.4381 (0.6445)\tAcc 0.938 (0.750)\n",
      "Epoch: [64][5/5]\tTime 0.080 (0.115)\tData 0.056 (0.090)\tLoss 0.3340 (0.6062)\tAcc 1.000 (0.781)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.216 (0.216)\tData 0.175 (0.175)\tLoss 0.4111 (0.4111)\tAcc 0.875 (0.875)\n",
      "Epoch: [64][2/9]\tTime 0.079 (0.147)\tData 0.038 (0.107)\tLoss 0.9086 (0.6598)\tAcc 0.562 (0.719)\n",
      "Epoch: [64][3/9]\tTime 0.058 (0.118)\tData 0.037 (0.083)\tLoss 0.9810 (0.7669)\tAcc 0.688 (0.708)\n",
      "Epoch: [64][4/9]\tTime 0.077 (0.107)\tData 0.057 (0.077)\tLoss 0.5143 (0.7038)\tAcc 0.812 (0.734)\n",
      "Epoch: [64][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.072)\tLoss 0.6795 (0.6989)\tAcc 0.812 (0.750)\n",
      "Epoch: [64][6/9]\tTime 0.075 (0.096)\tData 0.055 (0.069)\tLoss 0.2822 (0.6295)\tAcc 1.000 (0.792)\n",
      "Epoch: [64][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.067)\tLoss 0.8343 (0.6587)\tAcc 0.688 (0.777)\n",
      "Epoch: [64][8/9]\tTime 0.073 (0.091)\tData 0.054 (0.065)\tLoss 0.9904 (0.7002)\tAcc 0.625 (0.758)\n",
      "Epoch: [64][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.064)\tLoss 0.1941 (0.6924)\tAcc 1.000 (0.762)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.252 (0.252)\tData 0.222 (0.222)\tLoss 0.7218 (0.7218)\tAcc 0.625 (0.625)\n",
      "Epoch: [65][2/5]\tTime 0.074 (0.163)\tData 0.049 (0.135)\tLoss 0.5599 (0.6409)\tAcc 0.812 (0.719)\n",
      "Epoch: [65][3/5]\tTime 0.076 (0.134)\tData 0.052 (0.108)\tLoss 0.5700 (0.6172)\tAcc 0.875 (0.771)\n",
      "Epoch: [65][4/5]\tTime 0.077 (0.120)\tData 0.053 (0.094)\tLoss 0.5650 (0.6042)\tAcc 0.812 (0.781)\n",
      "Epoch: [65][5/5]\tTime 0.079 (0.111)\tData 0.055 (0.086)\tLoss 0.6101 (0.6049)\tAcc 0.778 (0.781)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.226 (0.226)\tData 0.183 (0.183)\tLoss 0.3585 (0.3585)\tAcc 0.938 (0.938)\n",
      "Epoch: [65][2/9]\tTime 0.061 (0.144)\tData 0.034 (0.109)\tLoss 0.8218 (0.5902)\tAcc 0.688 (0.812)\n",
      "Epoch: [65][3/9]\tTime 0.067 (0.118)\tData 0.047 (0.088)\tLoss 0.8131 (0.6645)\tAcc 0.750 (0.792)\n",
      "Epoch: [65][4/9]\tTime 0.075 (0.107)\tData 0.055 (0.080)\tLoss 0.6283 (0.6554)\tAcc 0.688 (0.766)\n",
      "Epoch: [65][5/9]\tTime 0.079 (0.102)\tData 0.059 (0.076)\tLoss 0.7860 (0.6815)\tAcc 0.812 (0.775)\n",
      "Epoch: [65][6/9]\tTime 0.073 (0.097)\tData 0.054 (0.072)\tLoss 0.2806 (0.6147)\tAcc 1.000 (0.812)\n",
      "Epoch: [65][7/9]\tTime 0.073 (0.094)\tData 0.054 (0.070)\tLoss 0.6366 (0.6179)\tAcc 0.750 (0.804)\n",
      "Epoch: [65][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.068)\tLoss 0.8637 (0.6486)\tAcc 0.625 (0.781)\n",
      "Epoch: [65][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.066)\tLoss 1.1427 (0.6562)\tAcc 0.500 (0.777)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.230 (0.230)\tData 0.198 (0.198)\tLoss 0.6290 (0.6290)\tAcc 0.688 (0.688)\n",
      "Epoch: [66][2/5]\tTime 0.077 (0.154)\tData 0.053 (0.126)\tLoss 0.5140 (0.5715)\tAcc 0.812 (0.750)\n",
      "Epoch: [66][3/5]\tTime 0.083 (0.130)\tData 0.059 (0.103)\tLoss 1.1713 (0.7714)\tAcc 0.500 (0.667)\n",
      "Epoch: [66][4/5]\tTime 0.082 (0.118)\tData 0.058 (0.092)\tLoss 0.6950 (0.7523)\tAcc 0.750 (0.688)\n",
      "Epoch: [66][5/5]\tTime 0.082 (0.111)\tData 0.058 (0.085)\tLoss 0.7401 (0.7508)\tAcc 0.667 (0.685)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.200 (0.200)\tData 0.176 (0.176)\tLoss 0.3766 (0.3766)\tAcc 0.938 (0.938)\n",
      "Epoch: [66][2/9]\tTime 0.076 (0.138)\tData 0.050 (0.113)\tLoss 0.9320 (0.6543)\tAcc 0.562 (0.750)\n",
      "Epoch: [66][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.091)\tLoss 0.8565 (0.7217)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][4/9]\tTime 0.079 (0.106)\tData 0.058 (0.083)\tLoss 0.5792 (0.6861)\tAcc 0.875 (0.781)\n",
      "Epoch: [66][5/9]\tTime 0.079 (0.100)\tData 0.058 (0.078)\tLoss 0.6259 (0.6740)\tAcc 0.750 (0.775)\n",
      "Epoch: [66][6/9]\tTime 0.078 (0.096)\tData 0.058 (0.075)\tLoss 0.2883 (0.6097)\tAcc 1.000 (0.812)\n",
      "Epoch: [66][7/9]\tTime 0.078 (0.094)\tData 0.058 (0.072)\tLoss 0.6419 (0.6143)\tAcc 0.812 (0.813)\n",
      "Epoch: [66][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 1.2180 (0.6898)\tAcc 0.500 (0.773)\n",
      "Epoch: [66][9/9]\tTime 0.075 (0.090)\tData 0.056 (0.068)\tLoss 0.2782 (0.6835)\tAcc 1.000 (0.777)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.218 (0.218)\tData 0.191 (0.191)\tLoss 0.9575 (0.9575)\tAcc 0.625 (0.625)\n",
      "Epoch: [67][2/5]\tTime 0.075 (0.147)\tData 0.051 (0.121)\tLoss 0.6050 (0.7813)\tAcc 0.812 (0.719)\n",
      "Epoch: [67][3/5]\tTime 0.077 (0.123)\tData 0.053 (0.098)\tLoss 0.5599 (0.7075)\tAcc 0.875 (0.771)\n",
      "Epoch: [67][4/5]\tTime 0.078 (0.112)\tData 0.054 (0.087)\tLoss 0.3630 (0.6214)\tAcc 0.875 (0.797)\n",
      "Epoch: [67][5/5]\tTime 0.077 (0.105)\tData 0.053 (0.080)\tLoss 0.9811 (0.6657)\tAcc 0.444 (0.753)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.221 (0.221)\tData 0.184 (0.184)\tLoss 0.3810 (0.3810)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/9]\tTime 0.065 (0.143)\tData 0.040 (0.112)\tLoss 0.8853 (0.6331)\tAcc 0.500 (0.719)\n",
      "Epoch: [67][3/9]\tTime 0.075 (0.120)\tData 0.055 (0.093)\tLoss 0.7936 (0.6866)\tAcc 0.750 (0.729)\n",
      "Epoch: [67][4/9]\tTime 0.079 (0.110)\tData 0.059 (0.084)\tLoss 0.5526 (0.6531)\tAcc 0.750 (0.734)\n",
      "Epoch: [67][5/9]\tTime 0.081 (0.104)\tData 0.060 (0.079)\tLoss 0.6572 (0.6539)\tAcc 0.750 (0.738)\n",
      "Epoch: [67][6/9]\tTime 0.079 (0.100)\tData 0.059 (0.076)\tLoss 0.2422 (0.5853)\tAcc 1.000 (0.781)\n",
      "Epoch: [67][7/9]\tTime 0.080 (0.097)\tData 0.060 (0.074)\tLoss 0.7794 (0.6130)\tAcc 0.750 (0.777)\n",
      "Epoch: [67][8/9]\tTime 0.076 (0.095)\tData 0.056 (0.072)\tLoss 1.0023 (0.6617)\tAcc 0.562 (0.750)\n",
      "Epoch: [67][9/9]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.2075 (0.6547)\tAcc 1.000 (0.754)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.221 (0.221)\tData 0.191 (0.191)\tLoss 0.4736 (0.4736)\tAcc 0.812 (0.812)\n",
      "Epoch: [68][2/5]\tTime 0.076 (0.148)\tData 0.052 (0.122)\tLoss 0.5737 (0.5237)\tAcc 0.750 (0.781)\n",
      "Epoch: [68][3/5]\tTime 0.080 (0.126)\tData 0.056 (0.100)\tLoss 0.9295 (0.6589)\tAcc 0.562 (0.708)\n",
      "Epoch: [68][4/5]\tTime 0.084 (0.115)\tData 0.059 (0.089)\tLoss 0.6393 (0.6540)\tAcc 0.750 (0.719)\n",
      "Epoch: [68][5/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.4972 (0.6347)\tAcc 0.889 (0.740)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.195 (0.195)\tData 0.167 (0.167)\tLoss 0.3695 (0.3695)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.070 (0.132)\tData 0.047 (0.107)\tLoss 0.8944 (0.6320)\tAcc 0.500 (0.719)\n",
      "Epoch: [68][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.089)\tLoss 0.6994 (0.6544)\tAcc 0.688 (0.708)\n",
      "Epoch: [68][4/9]\tTime 0.079 (0.104)\tData 0.058 (0.081)\tLoss 0.5854 (0.6372)\tAcc 0.812 (0.734)\n",
      "Epoch: [68][5/9]\tTime 0.081 (0.099)\tData 0.061 (0.077)\tLoss 0.7813 (0.6660)\tAcc 0.750 (0.738)\n",
      "Epoch: [68][6/9]\tTime 0.078 (0.096)\tData 0.058 (0.074)\tLoss 0.3083 (0.6064)\tAcc 0.938 (0.771)\n",
      "Epoch: [68][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.7389 (0.6253)\tAcc 0.750 (0.768)\n",
      "Epoch: [68][8/9]\tTime 0.077 (0.091)\tData 0.057 (0.069)\tLoss 0.9794 (0.6696)\tAcc 0.562 (0.742)\n",
      "Epoch: [68][9/9]\tTime 0.079 (0.089)\tData 0.059 (0.068)\tLoss 0.2542 (0.6632)\tAcc 1.000 (0.746)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.243 (0.243)\tData 0.210 (0.210)\tLoss 0.5253 (0.5253)\tAcc 0.812 (0.812)\n",
      "Epoch: [69][2/5]\tTime 0.074 (0.159)\tData 0.051 (0.131)\tLoss 0.7363 (0.6308)\tAcc 0.750 (0.781)\n",
      "Epoch: [69][3/5]\tTime 0.084 (0.134)\tData 0.060 (0.107)\tLoss 0.4706 (0.5774)\tAcc 0.875 (0.812)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.085 (0.122)\tData 0.061 (0.096)\tLoss 0.8050 (0.6343)\tAcc 0.688 (0.781)\n",
      "Epoch: [69][5/5]\tTime 0.086 (0.114)\tData 0.062 (0.089)\tLoss 0.7303 (0.6461)\tAcc 0.778 (0.781)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.198 (0.198)\tData 0.172 (0.172)\tLoss 0.3208 (0.3208)\tAcc 1.000 (1.000)\n",
      "Epoch: [69][2/9]\tTime 0.076 (0.137)\tData 0.050 (0.111)\tLoss 1.0099 (0.6653)\tAcc 0.500 (0.750)\n",
      "Epoch: [69][3/9]\tTime 0.068 (0.114)\tData 0.049 (0.090)\tLoss 0.6896 (0.6734)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][4/9]\tTime 0.074 (0.104)\tData 0.055 (0.081)\tLoss 0.5829 (0.6508)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.076)\tLoss 0.6439 (0.6494)\tAcc 0.812 (0.762)\n",
      "Epoch: [69][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.2440 (0.5818)\tAcc 1.000 (0.802)\n",
      "Epoch: [69][7/9]\tTime 0.076 (0.091)\tData 0.056 (0.070)\tLoss 0.6598 (0.5930)\tAcc 0.750 (0.795)\n",
      "Epoch: [69][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.7560 (0.6133)\tAcc 0.750 (0.789)\n",
      "Epoch: [69][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.067)\tLoss 0.4851 (0.6114)\tAcc 1.000 (0.792)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.214 (0.214)\tData 0.186 (0.186)\tLoss 0.5003 (0.5003)\tAcc 0.812 (0.812)\n",
      "Epoch: [70][2/5]\tTime 0.075 (0.145)\tData 0.051 (0.118)\tLoss 0.9230 (0.7117)\tAcc 0.688 (0.750)\n",
      "Epoch: [70][3/5]\tTime 0.080 (0.123)\tData 0.055 (0.097)\tLoss 0.6161 (0.6798)\tAcc 0.812 (0.771)\n",
      "Epoch: [70][4/5]\tTime 0.079 (0.112)\tData 0.054 (0.087)\tLoss 0.6913 (0.6827)\tAcc 0.750 (0.766)\n",
      "Epoch: [70][5/5]\tTime 0.082 (0.106)\tData 0.058 (0.081)\tLoss 0.8630 (0.7049)\tAcc 0.667 (0.753)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.217 (0.217)\tData 0.191 (0.191)\tLoss 0.3936 (0.3936)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/9]\tTime 0.079 (0.148)\tData 0.053 (0.122)\tLoss 0.8613 (0.6275)\tAcc 0.562 (0.750)\n",
      "Epoch: [70][3/9]\tTime 0.067 (0.121)\tData 0.048 (0.097)\tLoss 0.8273 (0.6941)\tAcc 0.688 (0.729)\n",
      "Epoch: [70][4/9]\tTime 0.074 (0.109)\tData 0.055 (0.087)\tLoss 0.7398 (0.7055)\tAcc 0.688 (0.719)\n",
      "Epoch: [70][5/9]\tTime 0.076 (0.103)\tData 0.057 (0.081)\tLoss 0.7810 (0.7206)\tAcc 0.688 (0.713)\n",
      "Epoch: [70][6/9]\tTime 0.076 (0.098)\tData 0.057 (0.077)\tLoss 0.2829 (0.6476)\tAcc 1.000 (0.760)\n",
      "Epoch: [70][7/9]\tTime 0.077 (0.095)\tData 0.057 (0.074)\tLoss 0.8068 (0.6704)\tAcc 0.750 (0.759)\n",
      "Epoch: [70][8/9]\tTime 0.079 (0.093)\tData 0.059 (0.072)\tLoss 0.8464 (0.6924)\tAcc 0.688 (0.750)\n",
      "Epoch: [70][9/9]\tTime 0.076 (0.091)\tData 0.056 (0.070)\tLoss 0.2114 (0.6850)\tAcc 1.000 (0.754)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.222 (0.222)\tData 0.194 (0.194)\tLoss 0.7125 (0.7125)\tAcc 0.750 (0.750)\n",
      "Epoch: [71][2/5]\tTime 0.075 (0.149)\tData 0.051 (0.123)\tLoss 0.5553 (0.6339)\tAcc 0.812 (0.781)\n",
      "Epoch: [71][3/5]\tTime 0.079 (0.126)\tData 0.056 (0.100)\tLoss 0.7586 (0.6755)\tAcc 0.750 (0.771)\n",
      "Epoch: [71][4/5]\tTime 0.077 (0.114)\tData 0.053 (0.089)\tLoss 0.9354 (0.7404)\tAcc 0.625 (0.734)\n",
      "Epoch: [71][5/5]\tTime 0.076 (0.106)\tData 0.053 (0.082)\tLoss 0.4023 (0.6988)\tAcc 0.778 (0.740)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.202 (0.202)\tData 0.173 (0.173)\tLoss 0.2774 (0.2774)\tAcc 1.000 (1.000)\n",
      "Epoch: [71][2/9]\tTime 0.087 (0.144)\tData 0.057 (0.115)\tLoss 0.8497 (0.5636)\tAcc 0.562 (0.781)\n",
      "Epoch: [71][3/9]\tTime 0.069 (0.119)\tData 0.048 (0.092)\tLoss 0.8207 (0.6493)\tAcc 0.688 (0.750)\n",
      "Epoch: [71][4/9]\tTime 0.080 (0.109)\tData 0.060 (0.084)\tLoss 0.6275 (0.6438)\tAcc 0.688 (0.734)\n",
      "Epoch: [71][5/9]\tTime 0.080 (0.103)\tData 0.059 (0.079)\tLoss 0.7810 (0.6713)\tAcc 0.688 (0.725)\n",
      "Epoch: [71][6/9]\tTime 0.081 (0.100)\tData 0.060 (0.076)\tLoss 0.3185 (0.6125)\tAcc 1.000 (0.771)\n",
      "Epoch: [71][7/9]\tTime 0.080 (0.097)\tData 0.060 (0.074)\tLoss 0.6229 (0.6140)\tAcc 0.812 (0.777)\n",
      "Epoch: [71][8/9]\tTime 0.081 (0.095)\tData 0.061 (0.072)\tLoss 0.8832 (0.6476)\tAcc 0.688 (0.766)\n",
      "Epoch: [71][9/9]\tTime 0.079 (0.093)\tData 0.060 (0.071)\tLoss 0.2634 (0.6417)\tAcc 1.000 (0.769)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.210 (0.210)\tData 0.182 (0.182)\tLoss 0.9135 (0.9135)\tAcc 0.625 (0.625)\n",
      "Epoch: [72][2/5]\tTime 0.074 (0.142)\tData 0.051 (0.116)\tLoss 0.5479 (0.7307)\tAcc 0.875 (0.750)\n",
      "Epoch: [72][3/5]\tTime 0.077 (0.121)\tData 0.054 (0.095)\tLoss 0.3754 (0.6122)\tAcc 0.875 (0.792)\n",
      "Epoch: [72][4/5]\tTime 0.080 (0.110)\tData 0.056 (0.086)\tLoss 0.5233 (0.5900)\tAcc 0.875 (0.812)\n",
      "Epoch: [72][5/5]\tTime 0.079 (0.104)\tData 0.055 (0.079)\tLoss 0.2982 (0.5540)\tAcc 1.000 (0.836)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.254 (0.254)\tData 0.189 (0.189)\tLoss 0.3463 (0.3463)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.057 (0.156)\tData 0.018 (0.104)\tLoss 0.9685 (0.6574)\tAcc 0.500 (0.719)\n",
      "Epoch: [72][3/9]\tTime 0.061 (0.124)\tData 0.040 (0.082)\tLoss 0.8192 (0.7113)\tAcc 0.688 (0.708)\n",
      "Epoch: [72][4/9]\tTime 0.075 (0.112)\tData 0.055 (0.075)\tLoss 0.5180 (0.6630)\tAcc 0.812 (0.734)\n",
      "Epoch: [72][5/9]\tTime 0.073 (0.104)\tData 0.053 (0.071)\tLoss 0.7643 (0.6833)\tAcc 0.688 (0.725)\n",
      "Epoch: [72][6/9]\tTime 0.075 (0.099)\tData 0.055 (0.068)\tLoss 0.2167 (0.6055)\tAcc 1.000 (0.771)\n",
      "Epoch: [72][7/9]\tTime 0.074 (0.095)\tData 0.054 (0.066)\tLoss 0.5026 (0.5908)\tAcc 0.875 (0.786)\n",
      "Epoch: [72][8/9]\tTime 0.074 (0.093)\tData 0.054 (0.065)\tLoss 0.8935 (0.6286)\tAcc 0.688 (0.773)\n",
      "Epoch: [72][9/9]\tTime 0.074 (0.091)\tData 0.054 (0.064)\tLoss 0.2199 (0.6224)\tAcc 1.000 (0.777)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.220 (0.220)\tData 0.178 (0.178)\tLoss 0.5253 (0.5253)\tAcc 0.812 (0.812)\n",
      "Epoch: [73][2/5]\tTime 0.061 (0.141)\tData 0.037 (0.107)\tLoss 0.5774 (0.5513)\tAcc 0.750 (0.781)\n",
      "Epoch: [73][3/5]\tTime 0.081 (0.121)\tData 0.057 (0.090)\tLoss 0.5777 (0.5601)\tAcc 0.875 (0.812)\n",
      "Epoch: [73][4/5]\tTime 0.078 (0.110)\tData 0.055 (0.082)\tLoss 0.8564 (0.6342)\tAcc 0.688 (0.781)\n",
      "Epoch: [73][5/5]\tTime 0.085 (0.105)\tData 0.061 (0.077)\tLoss 0.8273 (0.6580)\tAcc 0.667 (0.767)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.202 (0.202)\tData 0.168 (0.168)\tLoss 0.3149 (0.3149)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.063 (0.133)\tData 0.041 (0.105)\tLoss 0.9210 (0.6179)\tAcc 0.562 (0.750)\n",
      "Epoch: [73][3/9]\tTime 0.075 (0.114)\tData 0.055 (0.088)\tLoss 0.7902 (0.6754)\tAcc 0.688 (0.729)\n",
      "Epoch: [73][4/9]\tTime 0.079 (0.105)\tData 0.059 (0.081)\tLoss 0.6026 (0.6572)\tAcc 0.750 (0.734)\n",
      "Epoch: [73][5/9]\tTime 0.078 (0.100)\tData 0.057 (0.076)\tLoss 0.6243 (0.6506)\tAcc 0.750 (0.738)\n",
      "Epoch: [73][6/9]\tTime 0.073 (0.095)\tData 0.053 (0.072)\tLoss 0.2706 (0.5873)\tAcc 1.000 (0.781)\n",
      "Epoch: [73][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.7894 (0.6161)\tAcc 0.688 (0.768)\n",
      "Epoch: [73][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.7910 (0.6380)\tAcc 0.688 (0.758)\n",
      "Epoch: [73][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.2727 (0.6324)\tAcc 1.000 (0.762)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.232 (0.232)\tData 0.203 (0.203)\tLoss 0.5169 (0.5169)\tAcc 0.875 (0.875)\n",
      "Epoch: [74][2/5]\tTime 0.073 (0.153)\tData 0.049 (0.126)\tLoss 0.6654 (0.5911)\tAcc 0.750 (0.812)\n",
      "Epoch: [74][3/5]\tTime 0.077 (0.127)\tData 0.053 (0.102)\tLoss 0.7229 (0.6350)\tAcc 0.750 (0.792)\n",
      "Epoch: [74][4/5]\tTime 0.079 (0.115)\tData 0.055 (0.090)\tLoss 0.3476 (0.5632)\tAcc 0.812 (0.797)\n",
      "Epoch: [74][5/5]\tTime 0.077 (0.107)\tData 0.054 (0.083)\tLoss 1.4014 (0.6665)\tAcc 0.556 (0.767)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.3943 (0.3943)\tAcc 0.875 (0.875)\n",
      "Epoch: [74][2/9]\tTime 0.074 (0.139)\tData 0.048 (0.111)\tLoss 0.9142 (0.6543)\tAcc 0.500 (0.688)\n",
      "Epoch: [74][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.090)\tLoss 0.8082 (0.7056)\tAcc 0.688 (0.688)\n",
      "Epoch: [74][4/9]\tTime 0.073 (0.105)\tData 0.053 (0.081)\tLoss 0.7467 (0.7159)\tAcc 0.750 (0.703)\n",
      "Epoch: [74][5/9]\tTime 0.075 (0.099)\tData 0.055 (0.076)\tLoss 0.7733 (0.7273)\tAcc 0.750 (0.713)\n",
      "Epoch: [74][6/9]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.2268 (0.6439)\tAcc 1.000 (0.760)\n",
      "Epoch: [74][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.5825 (0.6351)\tAcc 0.750 (0.759)\n",
      "Epoch: [74][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.9441 (0.6738)\tAcc 0.562 (0.734)\n",
      "Epoch: [74][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.3977 (0.6695)\tAcc 1.000 (0.738)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.220 (0.220)\tData 0.193 (0.193)\tLoss 0.5773 (0.5773)\tAcc 0.875 (0.875)\n",
      "Epoch: [75][2/5]\tTime 0.077 (0.149)\tData 0.052 (0.123)\tLoss 0.8598 (0.7185)\tAcc 0.625 (0.750)\n",
      "Epoch: [75][3/5]\tTime 0.082 (0.126)\tData 0.058 (0.101)\tLoss 0.6682 (0.7018)\tAcc 0.688 (0.729)\n",
      "Epoch: [75][4/5]\tTime 0.082 (0.115)\tData 0.058 (0.090)\tLoss 0.5306 (0.6590)\tAcc 0.812 (0.750)\n",
      "Epoch: [75][5/5]\tTime 0.079 (0.108)\tData 0.056 (0.083)\tLoss 0.5480 (0.6453)\tAcc 0.889 (0.767)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.213 (0.213)\tData 0.180 (0.180)\tLoss 0.3579 (0.3579)\tAcc 0.938 (0.938)\n",
      "Epoch: [75][2/9]\tTime 0.073 (0.143)\tData 0.045 (0.112)\tLoss 0.8420 (0.6000)\tAcc 0.625 (0.781)\n",
      "Epoch: [75][3/9]\tTime 0.065 (0.117)\tData 0.045 (0.090)\tLoss 0.8340 (0.6780)\tAcc 0.750 (0.771)\n",
      "Epoch: [75][4/9]\tTime 0.075 (0.107)\tData 0.056 (0.081)\tLoss 0.5821 (0.6540)\tAcc 0.812 (0.781)\n",
      "Epoch: [75][5/9]\tTime 0.076 (0.100)\tData 0.056 (0.076)\tLoss 0.6858 (0.6604)\tAcc 0.750 (0.775)\n",
      "Epoch: [75][6/9]\tTime 0.075 (0.096)\tData 0.056 (0.073)\tLoss 0.2555 (0.5929)\tAcc 1.000 (0.812)\n",
      "Epoch: [75][7/9]\tTime 0.075 (0.093)\tData 0.055 (0.070)\tLoss 0.6369 (0.5992)\tAcc 0.812 (0.813)\n",
      "Epoch: [75][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.068)\tLoss 0.7846 (0.6224)\tAcc 0.688 (0.797)\n",
      "Epoch: [75][9/9]\tTime 0.076 (0.089)\tData 0.057 (0.067)\tLoss 0.2456 (0.6166)\tAcc 1.000 (0.800)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.249 (0.249)\tData 0.218 (0.218)\tLoss 0.4074 (0.4074)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/5]\tTime 0.075 (0.162)\tData 0.050 (0.134)\tLoss 0.9714 (0.6894)\tAcc 0.625 (0.781)\n",
      "Epoch: [76][3/5]\tTime 0.077 (0.134)\tData 0.053 (0.107)\tLoss 0.5205 (0.6331)\tAcc 0.812 (0.792)\n",
      "Epoch: [76][4/5]\tTime 0.078 (0.120)\tData 0.054 (0.094)\tLoss 0.4931 (0.5981)\tAcc 0.875 (0.812)\n",
      "Epoch: [76][5/5]\tTime 0.081 (0.112)\tData 0.056 (0.086)\tLoss 0.5691 (0.5945)\tAcc 0.778 (0.808)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.221 (0.221)\tData 0.184 (0.184)\tLoss 0.3929 (0.3929)\tAcc 0.875 (0.875)\n",
      "Epoch: [76][2/9]\tTime 0.068 (0.145)\tData 0.041 (0.113)\tLoss 0.9211 (0.6570)\tAcc 0.562 (0.719)\n",
      "Epoch: [76][3/9]\tTime 0.069 (0.119)\tData 0.047 (0.091)\tLoss 0.7182 (0.6774)\tAcc 0.812 (0.750)\n",
      "Epoch: [76][4/9]\tTime 0.073 (0.108)\tData 0.053 (0.081)\tLoss 0.5926 (0.6562)\tAcc 0.875 (0.781)\n",
      "Epoch: [76][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.076)\tLoss 0.7813 (0.6812)\tAcc 0.750 (0.775)\n",
      "Epoch: [76][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.072)\tLoss 0.2372 (0.6072)\tAcc 1.000 (0.812)\n",
      "Epoch: [76][7/9]\tTime 0.076 (0.093)\tData 0.056 (0.070)\tLoss 0.7286 (0.6246)\tAcc 0.750 (0.804)\n",
      "Epoch: [76][8/9]\tTime 0.082 (0.092)\tData 0.061 (0.069)\tLoss 0.8333 (0.6507)\tAcc 0.625 (0.781)\n",
      "Epoch: [76][9/9]\tTime 0.085 (0.091)\tData 0.066 (0.068)\tLoss 0.2591 (0.6446)\tAcc 1.000 (0.785)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.196 (0.196)\tData 0.169 (0.169)\tLoss 0.6902 (0.6902)\tAcc 0.750 (0.750)\n",
      "Epoch: [77][2/5]\tTime 0.441 (0.318)\tData 0.408 (0.289)\tLoss 0.5303 (0.6102)\tAcc 0.750 (0.750)\n",
      "Epoch: [77][3/5]\tTime 0.071 (0.236)\tData 0.047 (0.208)\tLoss 0.8608 (0.6938)\tAcc 0.625 (0.708)\n",
      "Epoch: [77][4/5]\tTime 0.077 (0.196)\tData 0.053 (0.169)\tLoss 0.9800 (0.7653)\tAcc 0.625 (0.688)\n",
      "Epoch: [77][5/5]\tTime 0.077 (0.172)\tData 0.054 (0.146)\tLoss 0.3889 (0.7189)\tAcc 0.889 (0.712)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.215 (0.215)\tData 0.184 (0.184)\tLoss 0.3389 (0.3389)\tAcc 0.938 (0.938)\n",
      "Epoch: [77][2/9]\tTime 0.075 (0.145)\tData 0.047 (0.116)\tLoss 1.0204 (0.6796)\tAcc 0.500 (0.719)\n",
      "Epoch: [77][3/9]\tTime 0.066 (0.119)\tData 0.047 (0.093)\tLoss 0.7269 (0.6954)\tAcc 0.875 (0.771)\n",
      "Epoch: [77][4/9]\tTime 0.074 (0.108)\tData 0.055 (0.083)\tLoss 0.5238 (0.6525)\tAcc 0.812 (0.781)\n",
      "Epoch: [77][5/9]\tTime 0.077 (0.102)\tData 0.058 (0.078)\tLoss 0.7569 (0.6734)\tAcc 0.688 (0.762)\n",
      "Epoch: [77][6/9]\tTime 0.079 (0.098)\tData 0.060 (0.075)\tLoss 0.2083 (0.5959)\tAcc 1.000 (0.802)\n",
      "Epoch: [77][7/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.5431 (0.5883)\tAcc 0.875 (0.813)\n",
      "Epoch: [77][8/9]\tTime 0.075 (0.092)\tData 0.055 (0.070)\tLoss 0.9474 (0.6332)\tAcc 0.562 (0.781)\n",
      "Epoch: [77][9/9]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.3463 (0.6288)\tAcc 1.000 (0.785)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.229 (0.229)\tData 0.196 (0.196)\tLoss 0.8406 (0.8406)\tAcc 0.625 (0.625)\n",
      "Epoch: [78][2/5]\tTime 0.071 (0.150)\tData 0.047 (0.122)\tLoss 0.5687 (0.7047)\tAcc 0.750 (0.688)\n",
      "Epoch: [78][3/5]\tTime 0.079 (0.126)\tData 0.054 (0.099)\tLoss 0.5254 (0.6449)\tAcc 0.875 (0.750)\n",
      "Epoch: [78][4/5]\tTime 0.077 (0.114)\tData 0.053 (0.088)\tLoss 0.4682 (0.6007)\tAcc 0.812 (0.766)\n",
      "Epoch: [78][5/5]\tTime 0.080 (0.107)\tData 0.053 (0.081)\tLoss 0.5097 (0.5895)\tAcc 0.889 (0.781)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.202 (0.202)\tData 0.171 (0.171)\tLoss 0.3283 (0.3283)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/9]\tTime 0.071 (0.137)\tData 0.046 (0.109)\tLoss 0.9099 (0.6191)\tAcc 0.562 (0.750)\n",
      "Epoch: [78][3/9]\tTime 0.070 (0.114)\tData 0.051 (0.089)\tLoss 0.8425 (0.6936)\tAcc 0.812 (0.771)\n",
      "Epoch: [78][4/9]\tTime 0.077 (0.105)\tData 0.057 (0.081)\tLoss 0.7529 (0.7084)\tAcc 0.688 (0.750)\n",
      "Epoch: [78][5/9]\tTime 0.077 (0.099)\tData 0.057 (0.076)\tLoss 0.7417 (0.7151)\tAcc 0.688 (0.738)\n",
      "Epoch: [78][6/9]\tTime 0.078 (0.096)\tData 0.058 (0.073)\tLoss 0.2198 (0.6325)\tAcc 1.000 (0.781)\n",
      "Epoch: [78][7/9]\tTime 0.078 (0.093)\tData 0.058 (0.071)\tLoss 0.6910 (0.6409)\tAcc 0.688 (0.768)\n",
      "Epoch: [78][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.8471 (0.6667)\tAcc 0.625 (0.750)\n",
      "Epoch: [78][9/9]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.2221 (0.6598)\tAcc 1.000 (0.754)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.202 (0.202)\tData 0.164 (0.164)\tLoss 0.5809 (0.5809)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][2/5]\tTime 0.067 (0.134)\tData 0.042 (0.103)\tLoss 0.7806 (0.6808)\tAcc 0.625 (0.719)\n",
      "Epoch: [79][3/5]\tTime 0.077 (0.115)\tData 0.053 (0.087)\tLoss 0.7857 (0.7158)\tAcc 0.750 (0.729)\n",
      "Epoch: [79][4/5]\tTime 0.081 (0.107)\tData 0.056 (0.079)\tLoss 0.6146 (0.6905)\tAcc 0.750 (0.734)\n",
      "Epoch: [79][5/5]\tTime 0.079 (0.101)\tData 0.055 (0.074)\tLoss 0.6222 (0.6821)\tAcc 0.778 (0.740)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.200 (0.200)\tData 0.176 (0.176)\tLoss 0.3298 (0.3298)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.076 (0.138)\tData 0.051 (0.114)\tLoss 0.7957 (0.5628)\tAcc 0.688 (0.812)\n",
      "Epoch: [79][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.092)\tLoss 0.7733 (0.6329)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][4/9]\tTime 0.074 (0.105)\tData 0.053 (0.082)\tLoss 0.5983 (0.6243)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][5/9]\tTime 0.077 (0.099)\tData 0.057 (0.077)\tLoss 0.6577 (0.6310)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][6/9]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.2451 (0.5667)\tAcc 1.000 (0.844)\n",
      "Epoch: [79][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.5481 (0.5640)\tAcc 0.875 (0.848)\n",
      "Epoch: [79][8/9]\tTime 0.080 (0.091)\tData 0.059 (0.069)\tLoss 0.8103 (0.5948)\tAcc 0.625 (0.820)\n",
      "Epoch: [79][9/9]\tTime 0.080 (0.089)\tData 0.060 (0.068)\tLoss 0.1697 (0.5883)\tAcc 1.000 (0.823)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.220 (0.220)\tData 0.191 (0.191)\tLoss 0.8082 (0.8082)\tAcc 0.750 (0.750)\n",
      "Epoch: [80][2/5]\tTime 0.075 (0.148)\tData 0.051 (0.121)\tLoss 0.7357 (0.7719)\tAcc 0.625 (0.688)\n",
      "Epoch: [80][3/5]\tTime 0.079 (0.125)\tData 0.055 (0.099)\tLoss 0.4560 (0.6666)\tAcc 0.875 (0.750)\n",
      "Epoch: [80][4/5]\tTime 0.080 (0.113)\tData 0.056 (0.088)\tLoss 0.5492 (0.6373)\tAcc 0.875 (0.781)\n",
      "Epoch: [80][5/5]\tTime 0.077 (0.106)\tData 0.054 (0.081)\tLoss 0.2982 (0.5955)\tAcc 0.889 (0.795)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.194 (0.194)\tData 0.165 (0.165)\tLoss 0.3526 (0.3526)\tAcc 0.938 (0.938)\n",
      "Epoch: [80][2/9]\tTime 0.069 (0.131)\tData 0.047 (0.106)\tLoss 0.8202 (0.5864)\tAcc 0.500 (0.719)\n",
      "Epoch: [80][3/9]\tTime 0.073 (0.112)\tData 0.053 (0.089)\tLoss 0.9491 (0.7073)\tAcc 0.688 (0.708)\n",
      "Epoch: [80][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.6187 (0.6852)\tAcc 0.688 (0.703)\n",
      "Epoch: [80][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.6027 (0.6687)\tAcc 0.812 (0.725)\n",
      "Epoch: [80][6/9]\tTime 0.077 (0.093)\tData 0.055 (0.072)\tLoss 0.2296 (0.5955)\tAcc 1.000 (0.771)\n",
      "Epoch: [80][7/9]\tTime 0.081 (0.092)\tData 0.061 (0.070)\tLoss 0.4953 (0.5812)\tAcc 0.812 (0.777)\n",
      "Epoch: [80][8/9]\tTime 0.078 (0.090)\tData 0.058 (0.068)\tLoss 0.8534 (0.6152)\tAcc 0.688 (0.766)\n",
      "Epoch: [80][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2581 (0.6097)\tAcc 1.000 (0.769)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.209 (0.209)\tData 0.181 (0.181)\tLoss 0.5108 (0.5108)\tAcc 0.875 (0.875)\n",
      "Epoch: [81][2/5]\tTime 0.080 (0.144)\tData 0.054 (0.118)\tLoss 0.6678 (0.5893)\tAcc 0.625 (0.750)\n",
      "Epoch: [81][3/5]\tTime 0.083 (0.124)\tData 0.058 (0.098)\tLoss 0.7189 (0.6325)\tAcc 0.812 (0.771)\n",
      "Epoch: [81][4/5]\tTime 0.083 (0.114)\tData 0.058 (0.088)\tLoss 0.7232 (0.6552)\tAcc 0.750 (0.766)\n",
      "Epoch: [81][5/5]\tTime 0.082 (0.107)\tData 0.058 (0.082)\tLoss 0.3436 (0.6168)\tAcc 1.000 (0.795)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.213 (0.213)\tData 0.178 (0.178)\tLoss 0.3167 (0.3167)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/9]\tTime 0.072 (0.142)\tData 0.045 (0.111)\tLoss 0.8438 (0.5802)\tAcc 0.688 (0.812)\n",
      "Epoch: [81][3/9]\tTime 0.073 (0.119)\tData 0.052 (0.092)\tLoss 0.6756 (0.6120)\tAcc 0.812 (0.812)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.079 (0.109)\tData 0.059 (0.083)\tLoss 0.4813 (0.5794)\tAcc 0.875 (0.828)\n",
      "Epoch: [81][5/9]\tTime 0.079 (0.103)\tData 0.059 (0.079)\tLoss 0.6455 (0.5926)\tAcc 0.750 (0.812)\n",
      "Epoch: [81][6/9]\tTime 0.079 (0.099)\tData 0.058 (0.075)\tLoss 0.2183 (0.5302)\tAcc 1.000 (0.844)\n",
      "Epoch: [81][7/9]\tTime 0.079 (0.096)\tData 0.058 (0.073)\tLoss 0.7087 (0.5557)\tAcc 0.750 (0.830)\n",
      "Epoch: [81][8/9]\tTime 0.080 (0.094)\tData 0.059 (0.071)\tLoss 0.9257 (0.6020)\tAcc 0.562 (0.797)\n",
      "Epoch: [81][9/9]\tTime 0.080 (0.092)\tData 0.060 (0.070)\tLoss 0.2694 (0.5968)\tAcc 1.000 (0.800)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.235 (0.235)\tData 0.205 (0.205)\tLoss 0.5446 (0.5446)\tAcc 0.812 (0.812)\n",
      "Epoch: [82][2/5]\tTime 0.091 (0.163)\tData 0.067 (0.136)\tLoss 0.6641 (0.6043)\tAcc 0.625 (0.719)\n",
      "Epoch: [82][3/5]\tTime 0.083 (0.136)\tData 0.056 (0.109)\tLoss 0.7073 (0.6387)\tAcc 0.688 (0.708)\n",
      "Epoch: [82][4/5]\tTime 0.081 (0.122)\tData 0.056 (0.096)\tLoss 0.5721 (0.6220)\tAcc 0.750 (0.719)\n",
      "Epoch: [82][5/5]\tTime 0.084 (0.115)\tData 0.061 (0.089)\tLoss 0.8536 (0.6506)\tAcc 0.556 (0.699)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.201 (0.201)\tData 0.169 (0.169)\tLoss 0.3701 (0.3701)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/9]\tTime 0.084 (0.142)\tData 0.056 (0.113)\tLoss 0.7075 (0.5388)\tAcc 0.625 (0.781)\n",
      "Epoch: [82][3/9]\tTime 0.066 (0.117)\tData 0.046 (0.091)\tLoss 0.7735 (0.6170)\tAcc 0.688 (0.750)\n",
      "Epoch: [82][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.081)\tLoss 0.5256 (0.5942)\tAcc 0.875 (0.781)\n",
      "Epoch: [82][5/9]\tTime 0.075 (0.100)\tData 0.055 (0.076)\tLoss 0.7950 (0.6343)\tAcc 0.750 (0.775)\n",
      "Epoch: [82][6/9]\tTime 0.076 (0.096)\tData 0.057 (0.073)\tLoss 0.2290 (0.5668)\tAcc 1.000 (0.812)\n",
      "Epoch: [82][7/9]\tTime 0.075 (0.093)\tData 0.055 (0.070)\tLoss 0.6391 (0.5771)\tAcc 0.812 (0.813)\n",
      "Epoch: [82][8/9]\tTime 0.080 (0.091)\tData 0.060 (0.069)\tLoss 0.8477 (0.6109)\tAcc 0.688 (0.797)\n",
      "Epoch: [82][9/9]\tTime 0.081 (0.090)\tData 0.061 (0.068)\tLoss 0.2094 (0.6048)\tAcc 1.000 (0.800)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.194 (0.194)\tData 0.162 (0.162)\tLoss 0.8366 (0.8366)\tAcc 0.562 (0.562)\n",
      "Epoch: [83][2/5]\tTime 0.071 (0.132)\tData 0.047 (0.104)\tLoss 0.7344 (0.7855)\tAcc 0.688 (0.625)\n",
      "Epoch: [83][3/5]\tTime 0.078 (0.114)\tData 0.053 (0.087)\tLoss 0.6472 (0.7394)\tAcc 0.750 (0.667)\n",
      "Epoch: [83][4/5]\tTime 0.076 (0.105)\tData 0.053 (0.079)\tLoss 0.4356 (0.6634)\tAcc 0.875 (0.719)\n",
      "Epoch: [83][5/5]\tTime 0.078 (0.099)\tData 0.054 (0.074)\tLoss 0.5189 (0.6456)\tAcc 0.889 (0.740)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.196 (0.196)\tData 0.170 (0.170)\tLoss 0.3264 (0.3264)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.072 (0.134)\tData 0.049 (0.109)\tLoss 0.8237 (0.5750)\tAcc 0.562 (0.750)\n",
      "Epoch: [83][3/9]\tTime 0.070 (0.113)\tData 0.051 (0.090)\tLoss 0.8268 (0.6590)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][4/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 0.6121 (0.6472)\tAcc 0.625 (0.719)\n",
      "Epoch: [83][5/9]\tTime 0.076 (0.098)\tData 0.057 (0.076)\tLoss 0.6839 (0.6546)\tAcc 0.812 (0.738)\n",
      "Epoch: [83][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.2914 (0.5941)\tAcc 0.938 (0.771)\n",
      "Epoch: [83][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5306 (0.5850)\tAcc 0.812 (0.777)\n",
      "Epoch: [83][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.8898 (0.6231)\tAcc 0.562 (0.750)\n",
      "Epoch: [83][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2493 (0.6173)\tAcc 1.000 (0.754)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.226 (0.226)\tData 0.198 (0.198)\tLoss 0.6493 (0.6493)\tAcc 0.875 (0.875)\n",
      "Epoch: [84][2/5]\tTime 0.083 (0.155)\tData 0.059 (0.129)\tLoss 0.9474 (0.7983)\tAcc 0.562 (0.719)\n",
      "Epoch: [84][3/5]\tTime 0.077 (0.129)\tData 0.054 (0.104)\tLoss 0.8714 (0.8227)\tAcc 0.688 (0.708)\n",
      "Epoch: [84][4/5]\tTime 0.077 (0.116)\tData 0.053 (0.091)\tLoss 0.3897 (0.7144)\tAcc 0.875 (0.750)\n",
      "Epoch: [84][5/5]\tTime 0.077 (0.108)\tData 0.054 (0.084)\tLoss 1.2192 (0.7767)\tAcc 0.556 (0.726)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.196 (0.196)\tData 0.169 (0.169)\tLoss 0.3117 (0.3117)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/9]\tTime 0.069 (0.133)\tData 0.048 (0.108)\tLoss 0.9327 (0.6222)\tAcc 0.625 (0.781)\n",
      "Epoch: [84][3/9]\tTime 0.071 (0.112)\tData 0.052 (0.090)\tLoss 0.8409 (0.6951)\tAcc 0.625 (0.729)\n",
      "Epoch: [84][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.5294 (0.6537)\tAcc 0.875 (0.766)\n",
      "Epoch: [84][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.9509 (0.7131)\tAcc 0.625 (0.738)\n",
      "Epoch: [84][6/9]\tTime 0.073 (0.093)\tData 0.055 (0.072)\tLoss 0.2555 (0.6369)\tAcc 1.000 (0.781)\n",
      "Epoch: [84][7/9]\tTime 0.073 (0.090)\tData 0.055 (0.070)\tLoss 0.4592 (0.6115)\tAcc 0.938 (0.804)\n",
      "Epoch: [84][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.068)\tLoss 1.2306 (0.6889)\tAcc 0.500 (0.766)\n",
      "Epoch: [84][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.066)\tLoss 0.2153 (0.6816)\tAcc 1.000 (0.769)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.201 (0.201)\tData 0.172 (0.172)\tLoss 0.7948 (0.7948)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/5]\tTime 0.072 (0.137)\tData 0.048 (0.110)\tLoss 0.5709 (0.6828)\tAcc 0.750 (0.719)\n",
      "Epoch: [85][3/5]\tTime 0.077 (0.117)\tData 0.053 (0.091)\tLoss 0.2889 (0.5515)\tAcc 0.938 (0.792)\n",
      "Epoch: [85][4/5]\tTime 0.077 (0.107)\tData 0.054 (0.082)\tLoss 0.5788 (0.5583)\tAcc 0.812 (0.797)\n",
      "Epoch: [85][5/5]\tTime 0.082 (0.102)\tData 0.058 (0.077)\tLoss 0.2670 (0.5224)\tAcc 1.000 (0.822)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.213 (0.213)\tData 0.168 (0.168)\tLoss 0.4190 (0.4190)\tAcc 0.875 (0.875)\n",
      "Epoch: [85][2/9]\tTime 0.051 (0.132)\tData 0.029 (0.098)\tLoss 0.8559 (0.6374)\tAcc 0.688 (0.781)\n",
      "Epoch: [85][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.083)\tLoss 0.6884 (0.6544)\tAcc 0.750 (0.771)\n",
      "Epoch: [85][4/9]\tTime 0.076 (0.103)\tData 0.056 (0.076)\tLoss 0.7730 (0.6841)\tAcc 0.625 (0.734)\n",
      "Epoch: [85][5/9]\tTime 0.080 (0.098)\tData 0.060 (0.073)\tLoss 0.5557 (0.6584)\tAcc 0.812 (0.750)\n",
      "Epoch: [85][6/9]\tTime 0.081 (0.095)\tData 0.061 (0.071)\tLoss 0.2380 (0.5883)\tAcc 1.000 (0.792)\n",
      "Epoch: [85][7/9]\tTime 0.081 (0.093)\tData 0.060 (0.069)\tLoss 0.5016 (0.5759)\tAcc 0.875 (0.804)\n",
      "Epoch: [85][8/9]\tTime 0.080 (0.092)\tData 0.060 (0.068)\tLoss 0.9441 (0.6220)\tAcc 0.625 (0.781)\n",
      "Epoch: [85][9/9]\tTime 0.080 (0.090)\tData 0.060 (0.067)\tLoss 0.3849 (0.6183)\tAcc 1.000 (0.785)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.192 (0.192)\tData 0.162 (0.162)\tLoss 0.6793 (0.6793)\tAcc 0.812 (0.812)\n",
      "Epoch: [86][2/5]\tTime 0.072 (0.132)\tData 0.048 (0.105)\tLoss 0.4542 (0.5668)\tAcc 0.875 (0.844)\n",
      "Epoch: [86][3/5]\tTime 0.077 (0.114)\tData 0.053 (0.088)\tLoss 0.6559 (0.5965)\tAcc 0.750 (0.812)\n",
      "Epoch: [86][4/5]\tTime 0.077 (0.105)\tData 0.053 (0.079)\tLoss 0.4604 (0.5624)\tAcc 0.875 (0.828)\n",
      "Epoch: [86][5/5]\tTime 0.081 (0.100)\tData 0.057 (0.075)\tLoss 0.6614 (0.5746)\tAcc 0.778 (0.822)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.197 (0.197)\tData 0.171 (0.171)\tLoss 0.3707 (0.3707)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.074 (0.136)\tData 0.049 (0.110)\tLoss 0.9035 (0.6371)\tAcc 0.625 (0.781)\n",
      "Epoch: [86][3/9]\tTime 0.068 (0.113)\tData 0.049 (0.090)\tLoss 0.6593 (0.6445)\tAcc 0.688 (0.750)\n",
      "Epoch: [86][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.5990 (0.6331)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][5/9]\tTime 0.073 (0.097)\tData 0.054 (0.075)\tLoss 0.6422 (0.6349)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][6/9]\tTime 0.077 (0.094)\tData 0.057 (0.072)\tLoss 0.2310 (0.5676)\tAcc 1.000 (0.792)\n",
      "Epoch: [86][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5703 (0.5680)\tAcc 0.750 (0.786)\n",
      "Epoch: [86][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.9621 (0.6173)\tAcc 0.625 (0.766)\n",
      "Epoch: [86][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2220 (0.6112)\tAcc 1.000 (0.769)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.198 (0.198)\tData 0.167 (0.167)\tLoss 0.4944 (0.4944)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][2/5]\tTime 0.071 (0.135)\tData 0.047 (0.107)\tLoss 0.3518 (0.4231)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.089)\tLoss 0.8363 (0.5608)\tAcc 0.688 (0.812)\n",
      "Epoch: [87][4/5]\tTime 0.079 (0.106)\tData 0.054 (0.081)\tLoss 0.7464 (0.6072)\tAcc 0.812 (0.812)\n",
      "Epoch: [87][5/5]\tTime 0.080 (0.101)\tData 0.057 (0.076)\tLoss 1.2182 (0.6826)\tAcc 0.444 (0.767)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.208 (0.208)\tData 0.185 (0.185)\tLoss 0.2925 (0.2925)\tAcc 0.938 (0.938)\n",
      "Epoch: [87][2/9]\tTime 0.079 (0.144)\tData 0.053 (0.119)\tLoss 0.9174 (0.6050)\tAcc 0.625 (0.781)\n",
      "Epoch: [87][3/9]\tTime 0.068 (0.119)\tData 0.049 (0.095)\tLoss 0.8750 (0.6950)\tAcc 0.750 (0.771)\n",
      "Epoch: [87][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.5588 (0.6609)\tAcc 0.688 (0.750)\n",
      "Epoch: [87][5/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.8078 (0.6903)\tAcc 0.688 (0.738)\n",
      "Epoch: [87][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.2885 (0.6233)\tAcc 1.000 (0.781)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.073 (0.093)\tData 0.055 (0.072)\tLoss 0.5510 (0.6130)\tAcc 0.938 (0.804)\n",
      "Epoch: [87][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 1.1690 (0.6825)\tAcc 0.562 (0.773)\n",
      "Epoch: [87][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.068)\tLoss 0.2693 (0.6761)\tAcc 1.000 (0.777)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.241 (0.241)\tData 0.214 (0.214)\tLoss 0.7097 (0.7097)\tAcc 0.688 (0.688)\n",
      "Epoch: [88][2/5]\tTime 0.078 (0.160)\tData 0.054 (0.134)\tLoss 0.4230 (0.5664)\tAcc 0.875 (0.781)\n",
      "Epoch: [88][3/5]\tTime 0.078 (0.132)\tData 0.054 (0.107)\tLoss 0.5332 (0.5553)\tAcc 0.750 (0.771)\n",
      "Epoch: [88][4/5]\tTime 0.081 (0.120)\tData 0.056 (0.095)\tLoss 1.1298 (0.6989)\tAcc 0.562 (0.719)\n",
      "Epoch: [88][5/5]\tTime 0.080 (0.112)\tData 0.057 (0.087)\tLoss 0.9311 (0.7276)\tAcc 0.556 (0.699)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.200 (0.200)\tData 0.170 (0.170)\tLoss 0.3421 (0.3421)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/9]\tTime 0.068 (0.134)\tData 0.046 (0.108)\tLoss 0.9581 (0.6501)\tAcc 0.562 (0.750)\n",
      "Epoch: [88][3/9]\tTime 0.072 (0.113)\tData 0.052 (0.089)\tLoss 0.8525 (0.7176)\tAcc 0.688 (0.729)\n",
      "Epoch: [88][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.080)\tLoss 0.6469 (0.6999)\tAcc 0.688 (0.719)\n",
      "Epoch: [88][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.8400 (0.7279)\tAcc 0.688 (0.713)\n",
      "Epoch: [88][6/9]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.2652 (0.6508)\tAcc 1.000 (0.760)\n",
      "Epoch: [88][7/9]\tTime 0.076 (0.091)\tData 0.055 (0.069)\tLoss 0.4635 (0.6241)\tAcc 0.938 (0.786)\n",
      "Epoch: [88][8/9]\tTime 0.080 (0.090)\tData 0.060 (0.068)\tLoss 0.8612 (0.6537)\tAcc 0.688 (0.773)\n",
      "Epoch: [88][9/9]\tTime 0.080 (0.089)\tData 0.060 (0.067)\tLoss 0.1493 (0.6459)\tAcc 1.000 (0.777)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.208 (0.208)\tData 0.176 (0.176)\tLoss 0.4307 (0.4307)\tAcc 0.875 (0.875)\n",
      "Epoch: [89][2/5]\tTime 0.076 (0.142)\tData 0.051 (0.114)\tLoss 0.7002 (0.5654)\tAcc 0.688 (0.781)\n",
      "Epoch: [89][3/5]\tTime 0.082 (0.122)\tData 0.058 (0.095)\tLoss 0.7414 (0.6241)\tAcc 0.688 (0.750)\n",
      "Epoch: [89][4/5]\tTime 0.082 (0.112)\tData 0.058 (0.086)\tLoss 0.4859 (0.5896)\tAcc 0.875 (0.781)\n",
      "Epoch: [89][5/5]\tTime 0.085 (0.106)\tData 0.061 (0.081)\tLoss 0.7577 (0.6103)\tAcc 0.667 (0.767)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.216 (0.216)\tData 0.187 (0.187)\tLoss 0.3208 (0.3208)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.080 (0.148)\tData 0.052 (0.119)\tLoss 0.8714 (0.5961)\tAcc 0.562 (0.750)\n",
      "Epoch: [89][3/9]\tTime 0.066 (0.121)\tData 0.046 (0.095)\tLoss 0.8372 (0.6764)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][4/9]\tTime 0.073 (0.109)\tData 0.053 (0.085)\tLoss 0.6480 (0.6693)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][5/9]\tTime 0.074 (0.102)\tData 0.054 (0.079)\tLoss 0.8259 (0.7006)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][6/9]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.2435 (0.6244)\tAcc 1.000 (0.792)\n",
      "Epoch: [89][7/9]\tTime 0.073 (0.094)\tData 0.054 (0.071)\tLoss 0.5118 (0.6084)\tAcc 0.812 (0.795)\n",
      "Epoch: [89][8/9]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.7423 (0.6251)\tAcc 0.750 (0.789)\n",
      "Epoch: [89][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.2245 (0.6189)\tAcc 1.000 (0.792)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.208 (0.208)\tData 0.175 (0.175)\tLoss 0.6645 (0.6645)\tAcc 0.625 (0.625)\n",
      "Epoch: [90][2/5]\tTime 0.087 (0.148)\tData 0.062 (0.119)\tLoss 0.6167 (0.6406)\tAcc 0.812 (0.719)\n",
      "Epoch: [90][3/5]\tTime 0.084 (0.126)\tData 0.059 (0.099)\tLoss 0.6866 (0.6559)\tAcc 0.688 (0.708)\n",
      "Epoch: [90][4/5]\tTime 0.084 (0.116)\tData 0.058 (0.088)\tLoss 0.7048 (0.6682)\tAcc 0.750 (0.719)\n",
      "Epoch: [90][5/5]\tTime 0.083 (0.109)\tData 0.058 (0.082)\tLoss 0.3318 (0.6267)\tAcc 0.889 (0.740)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.213 (0.213)\tData 0.186 (0.186)\tLoss 0.2929 (0.2929)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/9]\tTime 0.090 (0.151)\tData 0.061 (0.124)\tLoss 0.8635 (0.5782)\tAcc 0.625 (0.781)\n",
      "Epoch: [90][3/9]\tTime 0.069 (0.124)\tData 0.049 (0.099)\tLoss 0.6279 (0.5948)\tAcc 0.750 (0.771)\n",
      "Epoch: [90][4/9]\tTime 0.084 (0.114)\tData 0.054 (0.088)\tLoss 0.6782 (0.6156)\tAcc 0.750 (0.766)\n",
      "Epoch: [90][5/9]\tTime 0.074 (0.106)\tData 0.054 (0.081)\tLoss 0.7312 (0.6387)\tAcc 0.750 (0.762)\n",
      "Epoch: [90][6/9]\tTime 0.074 (0.101)\tData 0.055 (0.077)\tLoss 0.2417 (0.5726)\tAcc 1.000 (0.802)\n",
      "Epoch: [90][7/9]\tTime 0.075 (0.097)\tData 0.055 (0.074)\tLoss 0.4569 (0.5560)\tAcc 0.812 (0.804)\n",
      "Epoch: [90][8/9]\tTime 0.074 (0.094)\tData 0.055 (0.071)\tLoss 0.9486 (0.6051)\tAcc 0.562 (0.773)\n",
      "Epoch: [90][9/9]\tTime 0.073 (0.092)\tData 0.055 (0.069)\tLoss 0.2381 (0.5995)\tAcc 1.000 (0.777)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.201 (0.201)\tData 0.173 (0.173)\tLoss 0.5021 (0.5021)\tAcc 0.812 (0.812)\n",
      "Epoch: [91][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.112)\tLoss 0.7685 (0.6353)\tAcc 0.625 (0.719)\n",
      "Epoch: [91][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.093)\tLoss 0.6892 (0.6533)\tAcc 0.750 (0.729)\n",
      "Epoch: [91][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.7331 (0.6732)\tAcc 0.750 (0.734)\n",
      "Epoch: [91][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 0.2804 (0.6248)\tAcc 1.000 (0.767)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.3347 (0.3347)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/9]\tTime 0.069 (0.134)\tData 0.045 (0.108)\tLoss 0.8059 (0.5703)\tAcc 0.688 (0.812)\n",
      "Epoch: [91][3/9]\tTime 0.070 (0.113)\tData 0.050 (0.088)\tLoss 0.7777 (0.6394)\tAcc 0.750 (0.792)\n",
      "Epoch: [91][4/9]\tTime 0.075 (0.103)\tData 0.055 (0.080)\tLoss 0.5985 (0.6292)\tAcc 0.750 (0.781)\n",
      "Epoch: [91][5/9]\tTime 0.073 (0.097)\tData 0.053 (0.075)\tLoss 0.6611 (0.6356)\tAcc 0.812 (0.788)\n",
      "Epoch: [91][6/9]\tTime 0.074 (0.093)\tData 0.054 (0.071)\tLoss 0.2724 (0.5751)\tAcc 1.000 (0.823)\n",
      "Epoch: [91][7/9]\tTime 0.077 (0.091)\tData 0.057 (0.069)\tLoss 0.5546 (0.5721)\tAcc 0.875 (0.830)\n",
      "Epoch: [91][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 0.9213 (0.6158)\tAcc 0.625 (0.805)\n",
      "Epoch: [91][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2215 (0.6097)\tAcc 1.000 (0.808)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.227 (0.227)\tData 0.200 (0.200)\tLoss 0.7210 (0.7210)\tAcc 0.750 (0.750)\n",
      "Epoch: [92][2/5]\tTime 0.076 (0.152)\tData 0.053 (0.126)\tLoss 0.4924 (0.6067)\tAcc 0.812 (0.781)\n",
      "Epoch: [92][3/5]\tTime 0.077 (0.127)\tData 0.053 (0.102)\tLoss 0.6700 (0.6278)\tAcc 0.750 (0.771)\n",
      "Epoch: [92][4/5]\tTime 0.078 (0.115)\tData 0.055 (0.090)\tLoss 1.0294 (0.7282)\tAcc 0.562 (0.719)\n",
      "Epoch: [92][5/5]\tTime 0.082 (0.108)\tData 0.058 (0.084)\tLoss 0.2847 (0.6735)\tAcc 1.000 (0.753)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.206 (0.206)\tData 0.178 (0.178)\tLoss 0.5169 (0.5169)\tAcc 0.812 (0.812)\n",
      "Epoch: [92][2/9]\tTime 0.073 (0.139)\tData 0.048 (0.113)\tLoss 0.9121 (0.7145)\tAcc 0.500 (0.656)\n",
      "Epoch: [92][3/9]\tTime 0.068 (0.116)\tData 0.049 (0.092)\tLoss 0.8690 (0.7660)\tAcc 0.750 (0.688)\n",
      "Epoch: [92][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.082)\tLoss 0.6002 (0.7246)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][5/9]\tTime 0.073 (0.099)\tData 0.053 (0.076)\tLoss 0.9004 (0.7597)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][6/9]\tTime 0.074 (0.095)\tData 0.055 (0.073)\tLoss 0.3785 (0.6962)\tAcc 0.938 (0.729)\n",
      "Epoch: [92][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.7156 (0.6990)\tAcc 0.688 (0.723)\n",
      "Epoch: [92][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 1.0641 (0.7446)\tAcc 0.625 (0.711)\n",
      "Epoch: [92][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2260 (0.7366)\tAcc 1.000 (0.715)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.195 (0.195)\tData 0.162 (0.162)\tLoss 0.7460 (0.7460)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][2/5]\tTime 0.071 (0.133)\tData 0.046 (0.104)\tLoss 0.8024 (0.7742)\tAcc 0.688 (0.719)\n",
      "Epoch: [93][3/5]\tTime 0.078 (0.114)\tData 0.054 (0.087)\tLoss 0.7188 (0.7558)\tAcc 0.812 (0.750)\n",
      "Epoch: [93][4/5]\tTime 0.076 (0.105)\tData 0.053 (0.079)\tLoss 0.7425 (0.7524)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][5/5]\tTime 0.078 (0.099)\tData 0.054 (0.074)\tLoss 0.5962 (0.7332)\tAcc 0.778 (0.753)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.201 (0.201)\tData 0.176 (0.176)\tLoss 0.3731 (0.3731)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/9]\tTime 0.077 (0.139)\tData 0.050 (0.113)\tLoss 0.8835 (0.6283)\tAcc 0.500 (0.719)\n",
      "Epoch: [93][3/9]\tTime 0.069 (0.115)\tData 0.049 (0.092)\tLoss 0.6480 (0.6349)\tAcc 0.688 (0.708)\n",
      "Epoch: [93][4/9]\tTime 0.075 (0.105)\tData 0.055 (0.083)\tLoss 0.5644 (0.6173)\tAcc 0.812 (0.734)\n",
      "Epoch: [93][5/9]\tTime 0.075 (0.099)\tData 0.055 (0.077)\tLoss 0.8184 (0.6575)\tAcc 0.750 (0.738)\n",
      "Epoch: [93][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.2723 (0.5933)\tAcc 1.000 (0.781)\n",
      "Epoch: [93][7/9]\tTime 0.075 (0.092)\tData 0.056 (0.071)\tLoss 0.5382 (0.5854)\tAcc 0.750 (0.777)\n",
      "Epoch: [93][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.8405 (0.6173)\tAcc 0.625 (0.758)\n",
      "Epoch: [93][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2417 (0.6115)\tAcc 1.000 (0.762)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.206 (0.206)\tData 0.176 (0.176)\tLoss 0.4636 (0.4636)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][2/5]\tTime 0.073 (0.139)\tData 0.049 (0.112)\tLoss 0.5174 (0.4905)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][3/5]\tTime 0.076 (0.118)\tData 0.053 (0.093)\tLoss 0.6601 (0.5470)\tAcc 0.750 (0.833)\n",
      "Epoch: [94][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.5440 (0.5463)\tAcc 0.875 (0.844)\n",
      "Epoch: [94][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.8293 (0.5812)\tAcc 0.778 (0.836)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.196 (0.196)\tData 0.168 (0.168)\tLoss 0.3951 (0.3951)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/9]\tTime 0.069 (0.132)\tData 0.047 (0.108)\tLoss 0.9281 (0.6616)\tAcc 0.562 (0.750)\n",
      "Epoch: [94][3/9]\tTime 0.073 (0.112)\tData 0.053 (0.089)\tLoss 0.6735 (0.6656)\tAcc 0.812 (0.771)\n",
      "Epoch: [94][4/9]\tTime 0.074 (0.103)\tData 0.055 (0.081)\tLoss 0.6592 (0.6640)\tAcc 0.625 (0.734)\n",
      "Epoch: [94][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.8650 (0.7042)\tAcc 0.688 (0.725)\n",
      "Epoch: [94][6/9]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.2402 (0.6269)\tAcc 1.000 (0.771)\n",
      "Epoch: [94][7/9]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 0.7627 (0.6463)\tAcc 0.812 (0.777)\n",
      "Epoch: [94][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8178 (0.6677)\tAcc 0.688 (0.766)\n",
      "Epoch: [94][9/9]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 0.1842 (0.6603)\tAcc 1.000 (0.769)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.195 (0.195)\tData 0.165 (0.165)\tLoss 0.6504 (0.6504)\tAcc 0.750 (0.750)\n",
      "Epoch: [95][2/5]\tTime 0.073 (0.134)\tData 0.049 (0.107)\tLoss 1.1448 (0.8976)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][3/5]\tTime 0.077 (0.115)\tData 0.053 (0.089)\tLoss 0.4891 (0.7614)\tAcc 0.812 (0.729)\n",
      "Epoch: [95][4/5]\tTime 0.077 (0.106)\tData 0.054 (0.080)\tLoss 0.3189 (0.6508)\tAcc 0.938 (0.781)\n",
      "Epoch: [95][5/5]\tTime 0.077 (0.100)\tData 0.054 (0.075)\tLoss 0.7095 (0.6580)\tAcc 0.778 (0.781)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.195 (0.195)\tData 0.166 (0.166)\tLoss 0.3518 (0.3518)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/9]\tTime 0.069 (0.132)\tData 0.047 (0.106)\tLoss 0.9163 (0.6340)\tAcc 0.688 (0.812)\n",
      "Epoch: [95][3/9]\tTime 0.071 (0.112)\tData 0.051 (0.088)\tLoss 0.8246 (0.6976)\tAcc 0.688 (0.771)\n",
      "Epoch: [95][4/9]\tTime 0.074 (0.102)\tData 0.054 (0.079)\tLoss 0.5672 (0.6650)\tAcc 0.812 (0.781)\n",
      "Epoch: [95][5/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.7972 (0.6914)\tAcc 0.625 (0.750)\n",
      "Epoch: [95][6/9]\tTime 0.075 (0.093)\tData 0.056 (0.071)\tLoss 0.2544 (0.6186)\tAcc 1.000 (0.792)\n",
      "Epoch: [95][7/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.7316 (0.6347)\tAcc 0.750 (0.786)\n",
      "Epoch: [95][8/9]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.0838 (0.6909)\tAcc 0.562 (0.758)\n",
      "Epoch: [95][9/9]\tTime 0.074 (0.086)\tData 0.054 (0.065)\tLoss 0.2282 (0.6837)\tAcc 1.000 (0.762)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.210 (0.210)\tData 0.179 (0.179)\tLoss 0.8269 (0.8269)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][2/5]\tTime 0.072 (0.141)\tData 0.048 (0.113)\tLoss 0.6952 (0.7610)\tAcc 0.688 (0.688)\n",
      "Epoch: [96][3/5]\tTime 0.079 (0.120)\tData 0.055 (0.094)\tLoss 0.2774 (0.5998)\tAcc 0.938 (0.771)\n",
      "Epoch: [96][4/5]\tTime 0.078 (0.109)\tData 0.055 (0.084)\tLoss 0.7031 (0.6257)\tAcc 0.688 (0.750)\n",
      "Epoch: [96][5/5]\tTime 0.077 (0.103)\tData 0.054 (0.078)\tLoss 1.2336 (0.7006)\tAcc 0.444 (0.712)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.4191 (0.4191)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/9]\tTime 0.072 (0.135)\tData 0.048 (0.109)\tLoss 0.8512 (0.6351)\tAcc 0.562 (0.750)\n",
      "Epoch: [96][3/9]\tTime 0.069 (0.113)\tData 0.050 (0.089)\tLoss 0.6883 (0.6528)\tAcc 0.812 (0.771)\n",
      "Epoch: [96][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.080)\tLoss 0.6337 (0.6480)\tAcc 0.688 (0.750)\n",
      "Epoch: [96][5/9]\tTime 0.073 (0.097)\tData 0.054 (0.075)\tLoss 0.6275 (0.6439)\tAcc 0.812 (0.762)\n",
      "Epoch: [96][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2244 (0.5740)\tAcc 1.000 (0.802)\n",
      "Epoch: [96][7/9]\tTime 0.075 (0.090)\tData 0.056 (0.069)\tLoss 0.5756 (0.5742)\tAcc 0.750 (0.795)\n",
      "Epoch: [96][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8373 (0.6071)\tAcc 0.625 (0.773)\n",
      "Epoch: [96][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.066)\tLoss 0.3345 (0.6029)\tAcc 1.000 (0.777)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.201 (0.201)\tData 0.172 (0.172)\tLoss 0.7272 (0.7272)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][2/5]\tTime 0.074 (0.138)\tData 0.050 (0.111)\tLoss 0.9645 (0.8458)\tAcc 0.562 (0.656)\n",
      "Epoch: [97][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.092)\tLoss 0.3903 (0.6940)\tAcc 0.875 (0.729)\n",
      "Epoch: [97][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.4126 (0.6237)\tAcc 0.875 (0.766)\n",
      "Epoch: [97][5/5]\tTime 0.077 (0.102)\tData 0.053 (0.077)\tLoss 0.8002 (0.6454)\tAcc 0.667 (0.753)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.200 (0.200)\tData 0.166 (0.166)\tLoss 0.3318 (0.3318)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/9]\tTime 0.062 (0.131)\tData 0.041 (0.104)\tLoss 0.8826 (0.6072)\tAcc 0.625 (0.781)\n",
      "Epoch: [97][3/9]\tTime 0.072 (0.111)\tData 0.053 (0.087)\tLoss 0.6846 (0.6330)\tAcc 0.750 (0.771)\n",
      "Epoch: [97][4/9]\tTime 0.073 (0.102)\tData 0.053 (0.078)\tLoss 0.5729 (0.6180)\tAcc 0.688 (0.750)\n",
      "Epoch: [97][5/9]\tTime 0.074 (0.096)\tData 0.055 (0.074)\tLoss 0.7776 (0.6499)\tAcc 0.688 (0.738)\n",
      "Epoch: [97][6/9]\tTime 0.074 (0.093)\tData 0.055 (0.071)\tLoss 0.2543 (0.5840)\tAcc 1.000 (0.781)\n",
      "Epoch: [97][7/9]\tTime 0.073 (0.090)\tData 0.055 (0.068)\tLoss 0.7335 (0.6053)\tAcc 0.688 (0.768)\n",
      "Epoch: [97][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.9065 (0.6430)\tAcc 0.688 (0.758)\n",
      "Epoch: [97][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.065)\tLoss 0.1900 (0.6360)\tAcc 1.000 (0.762)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.200 (0.200)\tData 0.170 (0.170)\tLoss 0.8690 (0.8690)\tAcc 0.625 (0.625)\n",
      "Epoch: [98][2/5]\tTime 0.073 (0.137)\tData 0.049 (0.110)\tLoss 0.5447 (0.7068)\tAcc 0.812 (0.719)\n",
      "Epoch: [98][3/5]\tTime 0.076 (0.117)\tData 0.053 (0.091)\tLoss 0.6324 (0.6820)\tAcc 0.625 (0.688)\n",
      "Epoch: [98][4/5]\tTime 0.077 (0.107)\tData 0.054 (0.082)\tLoss 0.4025 (0.6122)\tAcc 0.812 (0.719)\n",
      "Epoch: [98][5/5]\tTime 0.077 (0.101)\tData 0.054 (0.076)\tLoss 0.8130 (0.6369)\tAcc 0.667 (0.712)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.194 (0.194)\tData 0.167 (0.167)\tLoss 0.2952 (0.2952)\tAcc 0.938 (0.938)\n",
      "Epoch: [98][2/9]\tTime 0.086 (0.140)\tData 0.059 (0.113)\tLoss 0.9413 (0.6182)\tAcc 0.500 (0.719)\n",
      "Epoch: [98][3/9]\tTime 0.066 (0.115)\tData 0.046 (0.091)\tLoss 0.8364 (0.6910)\tAcc 0.750 (0.729)\n",
      "Epoch: [98][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.081)\tLoss 0.5741 (0.6617)\tAcc 0.875 (0.766)\n",
      "Epoch: [98][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.076)\tLoss 0.9380 (0.7170)\tAcc 0.688 (0.750)\n",
      "Epoch: [98][6/9]\tTime 0.072 (0.094)\tData 0.054 (0.072)\tLoss 0.2579 (0.6405)\tAcc 1.000 (0.792)\n",
      "Epoch: [98][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.5408 (0.6262)\tAcc 0.750 (0.786)\n",
      "Epoch: [98][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8251 (0.6511)\tAcc 0.688 (0.773)\n",
      "Epoch: [98][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2289 (0.6446)\tAcc 1.000 (0.777)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.195 (0.195)\tData 0.164 (0.164)\tLoss 0.5230 (0.5230)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][2/5]\tTime 0.071 (0.133)\tData 0.048 (0.106)\tLoss 0.8410 (0.6820)\tAcc 0.625 (0.688)\n",
      "Epoch: [99][3/5]\tTime 0.077 (0.114)\tData 0.053 (0.089)\tLoss 1.0055 (0.7898)\tAcc 0.500 (0.625)\n",
      "Epoch: [99][4/5]\tTime 0.076 (0.105)\tData 0.054 (0.080)\tLoss 0.7162 (0.7714)\tAcc 0.750 (0.656)\n",
      "Epoch: [99][5/5]\tTime 0.077 (0.099)\tData 0.054 (0.075)\tLoss 0.4995 (0.7379)\tAcc 0.889 (0.685)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.191 (0.191)\tData 0.163 (0.163)\tLoss 0.3510 (0.3510)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.068 (0.129)\tData 0.047 (0.105)\tLoss 0.8892 (0.6201)\tAcc 0.500 (0.719)\n",
      "Epoch: [99][3/9]\tTime 0.072 (0.110)\tData 0.053 (0.087)\tLoss 0.9453 (0.7285)\tAcc 0.750 (0.729)\n",
      "Epoch: [99][4/9]\tTime 0.073 (0.101)\tData 0.054 (0.079)\tLoss 0.4909 (0.6691)\tAcc 0.812 (0.750)\n",
      "Epoch: [99][5/9]\tTime 0.074 (0.095)\tData 0.055 (0.074)\tLoss 0.7405 (0.6834)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.2575 (0.6124)\tAcc 1.000 (0.792)\n",
      "Epoch: [99][7/9]\tTime 0.073 (0.089)\tData 0.055 (0.069)\tLoss 0.6294 (0.6148)\tAcc 0.812 (0.795)\n",
      "Epoch: [99][8/9]\tTime 0.075 (0.087)\tData 0.056 (0.067)\tLoss 1.1509 (0.6819)\tAcc 0.500 (0.758)\n",
      "Epoch: [99][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.066)\tLoss 0.2949 (0.6759)\tAcc 1.000 (0.762)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.221 (0.221)\tData 0.194 (0.194)\tLoss 0.7034 (0.7034)\tAcc 0.812 (0.812)\n",
      "Epoch: [100][2/5]\tTime 0.075 (0.148)\tData 0.051 (0.123)\tLoss 0.2982 (0.5008)\tAcc 0.938 (0.875)\n",
      "Epoch: [100][3/5]\tTime 0.077 (0.124)\tData 0.054 (0.100)\tLoss 0.5742 (0.5253)\tAcc 0.812 (0.854)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.078 (0.112)\tData 0.054 (0.088)\tLoss 0.7958 (0.5929)\tAcc 0.688 (0.812)\n",
      "Epoch: [100][5/5]\tTime 0.078 (0.106)\tData 0.055 (0.082)\tLoss 0.5117 (0.5829)\tAcc 0.778 (0.808)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.191 (0.191)\tData 0.162 (0.162)\tLoss 0.3389 (0.3389)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.067 (0.129)\tData 0.046 (0.104)\tLoss 0.7904 (0.5646)\tAcc 0.625 (0.781)\n",
      "Epoch: [100][3/9]\tTime 0.072 (0.110)\tData 0.053 (0.087)\tLoss 0.7296 (0.6196)\tAcc 0.750 (0.771)\n",
      "Epoch: [100][4/9]\tTime 0.073 (0.101)\tData 0.054 (0.079)\tLoss 0.6283 (0.6218)\tAcc 0.750 (0.766)\n",
      "Epoch: [100][5/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.7747 (0.6524)\tAcc 0.750 (0.762)\n",
      "Epoch: [100][6/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.2718 (0.5890)\tAcc 1.000 (0.802)\n",
      "Epoch: [100][7/9]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 0.7674 (0.6144)\tAcc 0.812 (0.804)\n",
      "Epoch: [100][8/9]\tTime 0.075 (0.087)\tData 0.055 (0.067)\tLoss 0.7555 (0.6321)\tAcc 0.688 (0.789)\n",
      "Epoch: [100][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.066)\tLoss 0.5443 (0.6307)\tAcc 1.000 (0.792)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:51.004268Z",
     "start_time": "2020-03-26T02:01:50.972567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:51.015046Z",
     "start_time": "2020-03-26T02:01:51.006363Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.882108Z",
     "start_time": "2020-03-26T02:01:51.016268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T02:01:56.911612Z",
     "start_time": "2020-03-26T02:01:56.883245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 1.3451223373413086},\n",
       " {'label': 'none', 'score': 1.3451223373413086},\n",
       " {'label': 'none', 'score': 1.3451223373413086},\n",
       " {'label': 'none', 'score': 1.6161491870880127},\n",
       " {'label': 'none', 'score': 1.6161491870880127},\n",
       " {'label': 'none', 'score': 1.6161491870880127},\n",
       " {'label': 'none', 'score': 1.6952850818634033},\n",
       " {'label': 'none', 'score': 1.6952850818634033},\n",
       " {'label': 'none', 'score': 1.6952850818634033},\n",
       " {'label': 'none', 'score': 1.3718663454055786},\n",
       " {'label': 'none', 'score': 1.3718663454055786},\n",
       " {'label': 'none', 'score': 1.3718663454055786},\n",
       " {'label': 'none', 'score': 1.505290150642395},\n",
       " {'label': 'none', 'score': 1.505290150642395},\n",
       " {'label': 'none', 'score': 1.505290150642395},\n",
       " {'label': 'none', 'score': 1.5103569030761719},\n",
       " {'label': 'none', 'score': 1.5103569030761719},\n",
       " {'label': 'none', 'score': 1.5103569030761719},\n",
       " {'label': 'none', 'score': 1.6606383323669434},\n",
       " {'label': 'none', 'score': 1.6606383323669434},\n",
       " {'label': 'none', 'score': 1.6606383323669434},\n",
       " {'label': 'none', 'score': 1.5266547203063965},\n",
       " {'label': 'none', 'score': 1.5266547203063965},\n",
       " {'label': 'none', 'score': 1.5266547203063965},\n",
       " {'label': 'none', 'score': 1.3095229864120483},\n",
       " {'label': 'none', 'score': 1.3095229864120483},\n",
       " {'label': 'none', 'score': 1.3095229864120483},\n",
       " {'label': 'none', 'score': 1.311072826385498},\n",
       " {'label': 'none', 'score': 1.311072826385498},\n",
       " {'label': 'none', 'score': 1.311072826385498},\n",
       " {'label': 'none', 'score': 1.3215495347976685},\n",
       " {'label': 'none', 'score': 1.3215495347976685},\n",
       " {'label': 'none', 'score': 1.3215495347976685},\n",
       " {'label': 'none', 'score': 1.6114389896392822},\n",
       " {'label': 'none', 'score': 1.6114389896392822},\n",
       " {'label': 'none', 'score': 1.6114389896392822},\n",
       " {'label': 'none', 'score': 1.4832630157470703},\n",
       " {'label': 'none', 'score': 1.4832630157470703},\n",
       " {'label': 'none', 'score': 1.4832630157470703},\n",
       " {'label': 'none', 'score': 1.4967708587646484},\n",
       " {'label': 'none', 'score': 1.4967708587646484},\n",
       " {'label': 'none', 'score': 1.4967708587646484},\n",
       " {'label': 'none', 'score': 2.1990017890930176},\n",
       " {'label': 'none', 'score': 2.1990017890930176},\n",
       " {'label': 'none', 'score': 2.1990017890930176},\n",
       " {'label': 'none', 'score': 1.521087646484375},\n",
       " {'label': 'none', 'score': 1.521087646484375},\n",
       " {'label': 'none', 'score': 1.521087646484375},\n",
       " {'label': 'none', 'score': 1.459716558456421},\n",
       " {'label': 'none', 'score': 1.459716558456421},\n",
       " {'label': 'none', 'score': 1.459716558456421},\n",
       " {'label': 'none', 'score': 1.3309694528579712},\n",
       " {'label': 'none', 'score': 1.3309694528579712},\n",
       " {'label': 'none', 'score': 1.3309694528579712},\n",
       " {'label': 'none', 'score': 1.644124984741211},\n",
       " {'label': 'none', 'score': 1.644124984741211},\n",
       " {'label': 'none', 'score': 1.644124984741211},\n",
       " {'label': 'none', 'score': 1.498095989227295},\n",
       " {'label': 'none', 'score': 1.498095989227295},\n",
       " {'label': 'none', 'score': 1.498095989227295},\n",
       " {'label': 'none', 'score': 1.5775718688964844},\n",
       " {'label': 'none', 'score': 1.5775718688964844},\n",
       " {'label': 'none', 'score': 1.5775718688964844},\n",
       " {'label': 'none', 'score': 1.4624539613723755},\n",
       " {'label': 'none', 'score': 1.4624539613723755},\n",
       " {'label': 'none', 'score': 1.4624539613723755},\n",
       " {'label': 'none', 'score': 1.5068411827087402},\n",
       " {'label': 'none', 'score': 1.5068411827087402},\n",
       " {'label': 'none', 'score': 1.5068411827087402},\n",
       " {'label': 'returning', 'score': 1.5211424827575684},\n",
       " {'label': 'returning', 'score': 1.5211424827575684},\n",
       " {'label': 'returning', 'score': 1.5211424827575684},\n",
       " {'label': 'returning', 'score': 1.0687246322631836},\n",
       " {'label': 'returning', 'score': 1.0687246322631836},\n",
       " {'label': 'returning', 'score': 1.0687246322631836},\n",
       " {'label': 'leaving', 'score': 1.2090668678283691},\n",
       " {'label': 'leaving', 'score': 1.2090668678283691},\n",
       " {'label': 'leaving', 'score': 1.2090668678283691},\n",
       " {'label': 'leaving', 'score': 0.7963203191757202},\n",
       " {'label': 'leaving', 'score': 0.7963203191757202},\n",
       " {'label': 'leaving', 'score': 0.7963203191757202},\n",
       " {'label': 'leaving', 'score': 0.9263057112693787},\n",
       " {'label': 'leaving', 'score': 0.9263057112693787},\n",
       " {'label': 'leaving', 'score': 0.9263057112693787},\n",
       " {'label': 'returning', 'score': 0.8840054869651794},\n",
       " {'label': 'returning', 'score': 0.8840054869651794},\n",
       " {'label': 'returning', 'score': 0.8840054869651794},\n",
       " {'label': 'returning', 'score': 1.430472731590271},\n",
       " {'label': 'returning', 'score': 1.430472731590271},\n",
       " {'label': 'returning', 'score': 1.430472731590271},\n",
       " {'label': 'returning', 'score': 1.229871392250061},\n",
       " {'label': 'returning', 'score': 1.229871392250061},\n",
       " {'label': 'returning', 'score': 1.229871392250061},\n",
       " {'label': 'returning', 'score': 0.9139504432678223},\n",
       " {'label': 'returning', 'score': 0.9139504432678223},\n",
       " {'label': 'returning', 'score': 0.9139504432678223},\n",
       " {'label': 'leaving', 'score': 0.7314876914024353},\n",
       " {'label': 'leaving', 'score': 0.7314876914024353},\n",
       " {'label': 'leaving', 'score': 0.7314876914024353},\n",
       " {'label': 'leaving', 'score': 1.2050172090530396},\n",
       " {'label': 'leaving', 'score': 1.2050172090530396},\n",
       " {'label': 'leaving', 'score': 1.2050172090530396},\n",
       " {'label': 'none', 'score': 1.5778963565826416},\n",
       " {'label': 'none', 'score': 1.5778963565826416},\n",
       " {'label': 'none', 'score': 1.5778963565826416},\n",
       " {'label': 'none', 'score': 1.4201219081878662},\n",
       " {'label': 'none', 'score': 1.4201219081878662},\n",
       " {'label': 'none', 'score': 1.4201219081878662},\n",
       " {'label': 'none', 'score': 1.36574387550354},\n",
       " {'label': 'none', 'score': 1.36574387550354},\n",
       " {'label': 'none', 'score': 1.36574387550354},\n",
       " {'label': 'none', 'score': 1.673855185508728},\n",
       " {'label': 'none', 'score': 1.673855185508728},\n",
       " {'label': 'none', 'score': 1.673855185508728},\n",
       " {'label': 'none', 'score': 1.4044041633605957},\n",
       " {'label': 'none', 'score': 1.4044041633605957},\n",
       " {'label': 'none', 'score': 1.4044041633605957},\n",
       " {'label': 'none', 'score': 1.5096782445907593},\n",
       " {'label': 'none', 'score': 1.5096782445907593},\n",
       " {'label': 'none', 'score': 1.5096782445907593},\n",
       " {'label': 'none', 'score': 1.5565600395202637},\n",
       " {'label': 'none', 'score': 1.5565600395202637},\n",
       " {'label': 'none', 'score': 1.5565600395202637},\n",
       " {'label': 'none', 'score': 1.818432331085205},\n",
       " {'label': 'none', 'score': 1.818432331085205},\n",
       " {'label': 'none', 'score': 1.818432331085205},\n",
       " {'label': 'none', 'score': 1.7386910915374756},\n",
       " {'label': 'none', 'score': 1.7386910915374756},\n",
       " {'label': 'none', 'score': 1.7386910915374756},\n",
       " {'label': 'none', 'score': 1.5542110204696655},\n",
       " {'label': 'none', 'score': 1.5542110204696655},\n",
       " {'label': 'none', 'score': 1.5542110204696655},\n",
       " {'label': 'none', 'score': 1.41153883934021},\n",
       " {'label': 'none', 'score': 1.41153883934021},\n",
       " {'label': 'none', 'score': 1.41153883934021},\n",
       " {'label': 'none', 'score': 1.5992143154144287},\n",
       " {'label': 'none', 'score': 1.5992143154144287},\n",
       " {'label': 'none', 'score': 1.5992143154144287},\n",
       " {'label': 'none', 'score': 1.5314240455627441},\n",
       " {'label': 'none', 'score': 1.5314240455627441},\n",
       " {'label': 'none', 'score': 1.5314240455627441},\n",
       " {'label': 'none', 'score': 1.4761347770690918},\n",
       " {'label': 'none', 'score': 1.4761347770690918},\n",
       " {'label': 'none', 'score': 1.4761347770690918},\n",
       " {'label': 'none', 'score': 1.8701484203338623},\n",
       " {'label': 'none', 'score': 1.8701484203338623},\n",
       " {'label': 'none', 'score': 1.8701484203338623},\n",
       " {'label': 'none', 'score': 1.4264566898345947},\n",
       " {'label': 'none', 'score': 1.4264566898345947},\n",
       " {'label': 'none', 'score': 1.4264566898345947},\n",
       " {'label': 'none', 'score': 1.4148175716400146},\n",
       " {'label': 'none', 'score': 1.4148175716400146},\n",
       " {'label': 'none', 'score': 1.4148175716400146},\n",
       " {'label': 'returning', 'score': 1.3834075927734375},\n",
       " {'label': 'returning', 'score': 1.3834075927734375},\n",
       " {'label': 'returning', 'score': 1.3834075927734375},\n",
       " {'label': 'returning', 'score': 2.0929481983184814},\n",
       " {'label': 'returning', 'score': 2.0929481983184814},\n",
       " {'label': 'returning', 'score': 2.0929481983184814},\n",
       " {'label': 'returning', 'score': 0.9182902574539185},\n",
       " {'label': 'returning', 'score': 0.9182902574539185},\n",
       " {'label': 'returning', 'score': 0.9182902574539185},\n",
       " {'label': 'returning', 'score': 1.3086740970611572},\n",
       " {'label': 'returning', 'score': 1.3086740970611572},\n",
       " {'label': 'returning', 'score': 1.3086740970611572},\n",
       " {'label': 'returning', 'score': 1.8257097005844116},\n",
       " {'label': 'returning', 'score': 1.8257097005844116},\n",
       " {'label': 'returning', 'score': 1.8257097005844116},\n",
       " {'label': 'returning', 'score': 1.182157039642334},\n",
       " {'label': 'returning', 'score': 1.182157039642334},\n",
       " {'label': 'returning', 'score': 1.182157039642334},\n",
       " {'label': 'returning', 'score': 1.8150334358215332},\n",
       " {'label': 'returning', 'score': 1.8150334358215332},\n",
       " {'label': 'returning', 'score': 1.8150334358215332},\n",
       " {'label': 'leaving', 'score': 0.7868815064430237},\n",
       " {'label': 'leaving', 'score': 0.7868815064430237},\n",
       " {'label': 'leaving', 'score': 0.7868815064430237},\n",
       " {'label': 'none', 'score': 1.2002129554748535},\n",
       " {'label': 'none', 'score': 1.2002129554748535},\n",
       " {'label': 'none', 'score': 1.2002129554748535},\n",
       " {'label': 'none', 'score': 1.3953487873077393},\n",
       " {'label': 'none', 'score': 1.3953487873077393},\n",
       " {'label': 'none', 'score': 1.3953487873077393},\n",
       " {'label': 'none', 'score': 1.2995164394378662},\n",
       " {'label': 'none', 'score': 1.2995164394378662},\n",
       " {'label': 'none', 'score': 1.2995164394378662},\n",
       " {'label': 'none', 'score': 1.4520788192749023},\n",
       " {'label': 'none', 'score': 1.4520788192749023},\n",
       " {'label': 'none', 'score': 1.4520788192749023},\n",
       " {'label': 'none', 'score': 1.278006672859192},\n",
       " {'label': 'none', 'score': 1.278006672859192},\n",
       " {'label': 'none', 'score': 1.278006672859192},\n",
       " {'label': 'none', 'score': 1.3409587144851685},\n",
       " {'label': 'none', 'score': 1.3409587144851685},\n",
       " {'label': 'none', 'score': 1.3409587144851685},\n",
       " {'label': 'none', 'score': 1.2178585529327393},\n",
       " {'label': 'none', 'score': 1.2178585529327393},\n",
       " {'label': 'none', 'score': 1.2178585529327393},\n",
       " {'label': 'none', 'score': 1.7648764848709106},\n",
       " {'label': 'none', 'score': 1.7648764848709106},\n",
       " {'label': 'none', 'score': 1.7648764848709106},\n",
       " {'label': 'none', 'score': 1.772452473640442},\n",
       " {'label': 'none', 'score': 1.772452473640442},\n",
       " {'label': 'none', 'score': 1.772452473640442},\n",
       " {'label': 'none', 'score': 1.734604001045227},\n",
       " {'label': 'none', 'score': 1.734604001045227},\n",
       " {'label': 'none', 'score': 1.734604001045227},\n",
       " {'label': 'none', 'score': 1.5000579357147217},\n",
       " {'label': 'none', 'score': 1.5000579357147217},\n",
       " {'label': 'none', 'score': 1.5000579357147217},\n",
       " {'label': 'none', 'score': 1.6548694372177124},\n",
       " {'label': 'none', 'score': 1.6548694372177124},\n",
       " {'label': 'none', 'score': 1.6548694372177124},\n",
       " {'label': 'none', 'score': 1.5329625606536865},\n",
       " {'label': 'none', 'score': 1.5329625606536865},\n",
       " {'label': 'none', 'score': 1.5329625606536865},\n",
       " {'label': 'none', 'score': 1.7234678268432617},\n",
       " {'label': 'none', 'score': 1.7234678268432617},\n",
       " {'label': 'none', 'score': 1.7234678268432617},\n",
       " {'label': 'leaving', 'score': 1.3980467319488525},\n",
       " {'label': 'leaving', 'score': 1.3980467319488525},\n",
       " {'label': 'leaving', 'score': 1.3980467319488525},\n",
       " {'label': 'none', 'score': 1.5356957912445068},\n",
       " {'label': 'none', 'score': 1.5356957912445068},\n",
       " {'label': 'none', 'score': 1.5356957912445068},\n",
       " {'label': 'none', 'score': 1.9700366258621216},\n",
       " {'label': 'none', 'score': 1.9700366258621216},\n",
       " {'label': 'none', 'score': 1.9700366258621216},\n",
       " {'label': 'none', 'score': 1.3796262741088867},\n",
       " {'label': 'none', 'score': 1.3796262741088867},\n",
       " {'label': 'none', 'score': 1.3796262741088867},\n",
       " {'label': 'none', 'score': 1.6576132774353027},\n",
       " {'label': 'none', 'score': 1.6576132774353027},\n",
       " {'label': 'none', 'score': 1.6576132774353027},\n",
       " {'label': 'none', 'score': 1.7159297466278076},\n",
       " {'label': 'none', 'score': 1.7159297466278076},\n",
       " {'label': 'none', 'score': 1.7159297466278076},\n",
       " {'label': 'none', 'score': 1.4866124391555786},\n",
       " {'label': 'none', 'score': 1.4866124391555786},\n",
       " {'label': 'none', 'score': 1.4866124391555786},\n",
       " {'label': 'none', 'score': 1.4419703483581543},\n",
       " {'label': 'none', 'score': 1.4419703483581543},\n",
       " {'label': 'none', 'score': 1.4419703483581543},\n",
       " {'label': 'returning', 'score': 0.7172972559928894},\n",
       " {'label': 'returning', 'score': 0.7172972559928894},\n",
       " {'label': 'returning', 'score': 0.7172972559928894},\n",
       " {'label': 'returning', 'score': 1.0401716232299805},\n",
       " {'label': 'returning', 'score': 1.0401716232299805},\n",
       " {'label': 'returning', 'score': 1.0401716232299805},\n",
       " {'label': 'leaving', 'score': 1.2489838600158691},\n",
       " {'label': 'leaving', 'score': 1.2489838600158691},\n",
       " {'label': 'leaving', 'score': 1.2489838600158691},\n",
       " {'label': 'returning', 'score': 1.2281088829040527},\n",
       " {'label': 'returning', 'score': 1.2281088829040527},\n",
       " {'label': 'returning', 'score': 1.2281088829040527},\n",
       " {'label': 'returning', 'score': 1.464781641960144},\n",
       " {'label': 'returning', 'score': 1.464781641960144},\n",
       " {'label': 'returning', 'score': 1.464781641960144},\n",
       " {'label': 'returning', 'score': 1.238935947418213},\n",
       " {'label': 'returning', 'score': 1.238935947418213},\n",
       " {'label': 'returning', 'score': 1.238935947418213},\n",
       " {'label': 'returning', 'score': 0.6395009160041809},\n",
       " {'label': 'returning', 'score': 0.6395009160041809},\n",
       " {'label': 'returning', 'score': 0.6395009160041809},\n",
       " {'label': 'leaving', 'score': 0.8345755934715271},\n",
       " {'label': 'leaving', 'score': 0.8345755934715271},\n",
       " {'label': 'leaving', 'score': 0.8345755934715271},\n",
       " {'label': 'leaving', 'score': 0.6660084128379822},\n",
       " {'label': 'leaving', 'score': 0.6660084128379822},\n",
       " {'label': 'leaving', 'score': 0.6660084128379822},\n",
       " {'label': 'leaving', 'score': 1.097916841506958},\n",
       " {'label': 'leaving', 'score': 1.097916841506958},\n",
       " {'label': 'leaving', 'score': 1.097916841506958},\n",
       " {'label': 'none', 'score': 1.435520052909851},\n",
       " {'label': 'none', 'score': 1.435520052909851},\n",
       " {'label': 'none', 'score': 1.435520052909851},\n",
       " {'label': 'none', 'score': 1.1526083946228027},\n",
       " {'label': 'none', 'score': 1.1526083946228027},\n",
       " {'label': 'none', 'score': 1.1526083946228027},\n",
       " {'label': 'none', 'score': 1.3626348972320557},\n",
       " {'label': 'none', 'score': 1.3626348972320557},\n",
       " {'label': 'none', 'score': 1.3626348972320557},\n",
       " {'label': 'none', 'score': 1.3012678623199463},\n",
       " {'label': 'none', 'score': 1.3012678623199463},\n",
       " {'label': 'none', 'score': 1.3012678623199463},\n",
       " {'label': 'none', 'score': 1.4240517616271973},\n",
       " {'label': 'none', 'score': 1.4240517616271973},\n",
       " {'label': 'none', 'score': 1.4240517616271973},\n",
       " {'label': 'none', 'score': 1.5694806575775146},\n",
       " {'label': 'none', 'score': 1.5694806575775146},\n",
       " {'label': 'none', 'score': 1.5694806575775146},\n",
       " {'label': 'none', 'score': 1.768094539642334},\n",
       " {'label': 'none', 'score': 1.768094539642334},\n",
       " {'label': 'none', 'score': 1.768094539642334},\n",
       " {'label': 'none', 'score': 1.3649760484695435},\n",
       " {'label': 'none', 'score': 1.3649760484695435},\n",
       " {'label': 'none', 'score': 1.3649760484695435},\n",
       " {'label': 'none', 'score': 1.479313850402832},\n",
       " {'label': 'none', 'score': 1.479313850402832},\n",
       " {'label': 'none', 'score': 1.479313850402832},\n",
       " {'label': 'none', 'score': 1.8225030899047852},\n",
       " {'label': 'none', 'score': 1.8225030899047852},\n",
       " {'label': 'none', 'score': 1.8225030899047852},\n",
       " {'label': 'none', 'score': 1.6360255479812622},\n",
       " {'label': 'none', 'score': 1.6360255479812622},\n",
       " {'label': 'none', 'score': 1.6360255479812622},\n",
       " {'label': 'none', 'score': 1.4128224849700928},\n",
       " {'label': 'none', 'score': 1.4128224849700928},\n",
       " {'label': 'none', 'score': 1.4128224849700928},\n",
       " {'label': 'none', 'score': 1.4423937797546387},\n",
       " {'label': 'none', 'score': 1.4423937797546387},\n",
       " {'label': 'none', 'score': 1.4423937797546387},\n",
       " {'label': 'none', 'score': 1.868587851524353},\n",
       " {'label': 'none', 'score': 1.868587851524353},\n",
       " {'label': 'none', 'score': 1.868587851524353},\n",
       " {'label': 'none', 'score': 1.7312417030334473},\n",
       " {'label': 'none', 'score': 1.7312417030334473},\n",
       " {'label': 'none', 'score': 1.7312417030334473},\n",
       " {'label': 'none', 'score': 1.4967039823532104},\n",
       " {'label': 'none', 'score': 1.4967039823532104},\n",
       " {'label': 'none', 'score': 1.4967039823532104},\n",
       " {'label': 'none', 'score': 1.5653833150863647},\n",
       " {'label': 'none', 'score': 1.5653833150863647},\n",
       " {'label': 'none', 'score': 1.5653833150863647},\n",
       " {'label': 'returning', 'score': 1.5742950439453125},\n",
       " {'label': 'returning', 'score': 1.5742950439453125},\n",
       " {'label': 'returning', 'score': 1.5742950439453125},\n",
       " {'label': 'returning', 'score': 1.6615198850631714},\n",
       " {'label': 'returning', 'score': 1.6615198850631714},\n",
       " {'label': 'returning', 'score': 1.6615198850631714},\n",
       " {'label': 'returning', 'score': 1.1480010747909546},\n",
       " {'label': 'returning', 'score': 1.1480010747909546},\n",
       " {'label': 'returning', 'score': 1.1480010747909546},\n",
       " {'label': 'returning', 'score': 1.168383240699768},\n",
       " {'label': 'returning', 'score': 1.168383240699768},\n",
       " {'label': 'returning', 'score': 1.168383240699768},\n",
       " {'label': 'returning', 'score': 1.880128264427185},\n",
       " {'label': 'returning', 'score': 1.880128264427185},\n",
       " {'label': 'returning', 'score': 1.880128264427185},\n",
       " {'label': 'returning', 'score': 1.3095653057098389},\n",
       " {'label': 'returning', 'score': 1.3095653057098389},\n",
       " {'label': 'returning', 'score': 1.3095653057098389},\n",
       " {'label': 'returning', 'score': 0.82124924659729},\n",
       " {'label': 'returning', 'score': 0.82124924659729},\n",
       " {'label': 'returning', 'score': 0.82124924659729},\n",
       " {'label': 'leaving', 'score': 1.0352327823638916},\n",
       " {'label': 'leaving', 'score': 1.0352327823638916},\n",
       " {'label': 'leaving', 'score': 1.0352327823638916},\n",
       " {'label': 'none', 'score': 1.4509830474853516},\n",
       " {'label': 'none', 'score': 1.4509830474853516},\n",
       " {'label': 'none', 'score': 1.4509830474853516},\n",
       " {'label': 'none', 'score': 1.4028666019439697},\n",
       " {'label': 'none', 'score': 1.4028666019439697},\n",
       " {'label': 'none', 'score': 1.4028666019439697},\n",
       " {'label': 'none', 'score': 1.4480407238006592},\n",
       " {'label': 'none', 'score': 1.4480407238006592},\n",
       " {'label': 'none', 'score': 1.4480407238006592},\n",
       " {'label': 'none', 'score': 1.5612499713897705},\n",
       " {'label': 'none', 'score': 1.5612499713897705},\n",
       " {'label': 'none', 'score': 1.5612499713897705},\n",
       " {'label': 'none', 'score': 1.6334645748138428},\n",
       " {'label': 'none', 'score': 1.6334645748138428},\n",
       " {'label': 'none', 'score': 1.6334645748138428},\n",
       " {'label': 'none', 'score': 1.410799264907837},\n",
       " {'label': 'none', 'score': 1.410799264907837},\n",
       " {'label': 'none', 'score': 1.410799264907837},\n",
       " {'label': 'none', 'score': 1.4971708059310913},\n",
       " {'label': 'none', 'score': 1.4971708059310913},\n",
       " {'label': 'none', 'score': 1.4971708059310913},\n",
       " {'label': 'none', 'score': 1.4809458255767822},\n",
       " {'label': 'none', 'score': 1.4809458255767822},\n",
       " {'label': 'none', 'score': 1.4809458255767822},\n",
       " {'label': 'none', 'score': 1.762193202972412},\n",
       " {'label': 'none', 'score': 1.762193202972412},\n",
       " {'label': 'none', 'score': 1.762193202972412},\n",
       " {'label': 'none', 'score': 1.455444097518921},\n",
       " {'label': 'none', 'score': 1.455444097518921},\n",
       " {'label': 'none', 'score': 1.455444097518921},\n",
       " {'label': 'none', 'score': 1.688114881515503},\n",
       " {'label': 'none', 'score': 1.688114881515503},\n",
       " {'label': 'none', 'score': 1.688114881515503},\n",
       " {'label': 'leaving', 'score': 1.4309418201446533},\n",
       " {'label': 'leaving', 'score': 1.4309418201446533},\n",
       " {'label': 'leaving', 'score': 1.4309418201446533},\n",
       " {'label': 'none', 'score': 1.7113947868347168},\n",
       " {'label': 'none', 'score': 1.7113947868347168},\n",
       " {'label': 'none', 'score': 1.7113947868347168},\n",
       " {'label': 'none', 'score': 1.4247956275939941},\n",
       " {'label': 'none', 'score': 1.4247956275939941},\n",
       " {'label': 'none', 'score': 1.4247956275939941},\n",
       " {'label': 'none', 'score': 1.5986952781677246},\n",
       " {'label': 'none', 'score': 1.5986952781677246},\n",
       " {'label': 'none', 'score': 1.5986952781677246},\n",
       " {'label': 'none', 'score': 1.4030423164367676},\n",
       " {'label': 'none', 'score': 1.4030423164367676},\n",
       " {'label': 'none', 'score': 1.4030423164367676},\n",
       " {'label': 'none', 'score': 1.5809035301208496},\n",
       " {'label': 'none', 'score': 1.5809035301208496},\n",
       " {'label': 'none', 'score': 1.5809035301208496},\n",
       " {'label': 'none', 'score': 1.341529130935669},\n",
       " {'label': 'none', 'score': 1.341529130935669},\n",
       " {'label': 'none', 'score': 1.341529130935669},\n",
       " {'label': 'none', 'score': 1.1097532510757446},\n",
       " {'label': 'none', 'score': 1.1097532510757446},\n",
       " {'label': 'none', 'score': 1.1097532510757446},\n",
       " {'label': 'returning', 'score': 1.3117647171020508},\n",
       " {'label': 'returning', 'score': 1.3117647171020508},\n",
       " {'label': 'returning', 'score': 1.3117647171020508},\n",
       " {'label': 'leaving', 'score': 1.344666600227356},\n",
       " {'label': 'leaving', 'score': 1.344666600227356},\n",
       " {'label': 'leaving', 'score': 1.344666600227356},\n",
       " {'label': 'none', 'score': 1.4598500728607178},\n",
       " {'label': 'none', 'score': 1.4598500728607178},\n",
       " {'label': 'none', 'score': 1.4598500728607178},\n",
       " {'label': 'none', 'score': 1.444300651550293},\n",
       " {'label': 'none', 'score': 1.444300651550293},\n",
       " {'label': 'none', 'score': 1.444300651550293},\n",
       " {'label': 'none', 'score': 1.6007556915283203},\n",
       " {'label': 'none', 'score': 1.6007556915283203},\n",
       " {'label': 'none', 'score': 1.6007556915283203},\n",
       " {'label': 'none', 'score': 1.4667887687683105},\n",
       " {'label': 'none', 'score': 1.4667887687683105},\n",
       " {'label': 'none', 'score': 1.4667887687683105},\n",
       " {'label': 'none', 'score': 1.3743290901184082},\n",
       " {'label': 'none', 'score': 1.3743290901184082},\n",
       " {'label': 'none', 'score': 1.3743290901184082},\n",
       " {'label': 'none', 'score': 1.3387126922607422},\n",
       " {'label': 'none', 'score': 1.3387126922607422},\n",
       " {'label': 'none', 'score': 1.3387126922607422},\n",
       " {'label': 'none', 'score': 1.2464196681976318},\n",
       " {'label': 'none', 'score': 1.2464196681976318},\n",
       " {'label': 'none', 'score': 1.2464196681976318},\n",
       " {'label': 'none', 'score': 1.4916367530822754},\n",
       " {'label': 'none', 'score': 1.4916367530822754},\n",
       " {'label': 'none', 'score': 1.4916367530822754},\n",
       " {'label': 'leaving', 'score': 1.081674337387085},\n",
       " {'label': 'leaving', 'score': 1.081674337387085},\n",
       " {'label': 'leaving', 'score': 1.081674337387085},\n",
       " {'label': 'none', 'score': 0.9338403940200806},\n",
       " {'label': 'none', 'score': 0.9338403940200806},\n",
       " {'label': 'none', 'score': 0.9338403940200806},\n",
       " {'label': 'leaving', 'score': 0.90531325340271},\n",
       " {'label': 'leaving', 'score': 0.90531325340271},\n",
       " {'label': 'leaving', 'score': 0.90531325340271},\n",
       " {'label': 'returning', 'score': 2.088660478591919},\n",
       " {'label': 'returning', 'score': 2.088660478591919},\n",
       " {'label': 'returning', 'score': 2.088660478591919},\n",
       " {'label': 'returning', 'score': 1.1062167882919312},\n",
       " {'label': 'returning', 'score': 1.1062167882919312},\n",
       " {'label': 'returning', 'score': 1.1062167882919312},\n",
       " {'label': 'none', 'score': 1.6355754137039185},\n",
       " {'label': 'none', 'score': 1.6355754137039185},\n",
       " {'label': 'none', 'score': 1.6355754137039185},\n",
       " {'label': 'none', 'score': 1.5015301704406738},\n",
       " {'label': 'none', 'score': 1.5015301704406738},\n",
       " {'label': 'none', 'score': 1.5015301704406738},\n",
       " {'label': 'none', 'score': 1.591766357421875},\n",
       " {'label': 'none', 'score': 1.591766357421875},\n",
       " {'label': 'none', 'score': 1.591766357421875},\n",
       " {'label': 'none', 'score': 1.300779104232788},\n",
       " {'label': 'none', 'score': 1.300779104232788},\n",
       " {'label': 'none', 'score': 1.300779104232788},\n",
       " {'label': 'none', 'score': 1.422729253768921},\n",
       " {'label': 'none', 'score': 1.422729253768921},\n",
       " {'label': 'none', 'score': 1.422729253768921},\n",
       " {'label': 'none', 'score': 1.438378095626831},\n",
       " {'label': 'none', 'score': 1.438378095626831},\n",
       " {'label': 'none', 'score': 1.438378095626831},\n",
       " {'label': 'none', 'score': 1.8205381631851196},\n",
       " {'label': 'none', 'score': 1.8205381631851196},\n",
       " {'label': 'none', 'score': 1.8205381631851196},\n",
       " {'label': 'none', 'score': 1.703136682510376},\n",
       " {'label': 'none', 'score': 1.703136682510376},\n",
       " {'label': 'none', 'score': 1.703136682510376},\n",
       " {'label': 'none', 'score': 1.322129487991333},\n",
       " {'label': 'none', 'score': 1.322129487991333},\n",
       " {'label': 'none', 'score': 1.322129487991333},\n",
       " {'label': 'none', 'score': 1.3439197540283203},\n",
       " {'label': 'none', 'score': 1.3439197540283203},\n",
       " {'label': 'none', 'score': 1.3439197540283203},\n",
       " {'label': 'none', 'score': 1.4050345420837402},\n",
       " {'label': 'none', 'score': 1.4050345420837402},\n",
       " {'label': 'none', 'score': 1.4050345420837402},\n",
       " {'label': 'leaving', 'score': 1.3582532405853271},\n",
       " {'label': 'leaving', 'score': 1.3582532405853271},\n",
       " {'label': 'leaving', 'score': 1.3582532405853271},\n",
       " {'label': 'returning', 'score': 0.727716326713562},\n",
       " {'label': 'returning', 'score': 0.727716326713562},\n",
       " {'label': 'returning', 'score': 0.727716326713562},\n",
       " {'label': 'returning', 'score': 0.8052963614463806},\n",
       " {'label': 'returning', 'score': 0.8052963614463806},\n",
       " {'label': 'returning', 'score': 0.8052963614463806},\n",
       " {'label': 'leaving', 'score': 1.1285409927368164},\n",
       " {'label': 'leaving', 'score': 1.1285409927368164},\n",
       " {'label': 'leaving', 'score': 1.1285409927368164},\n",
       " {'label': 'returning', 'score': 1.3479485511779785},\n",
       " {'label': 'returning', 'score': 1.3479485511779785},\n",
       " {'label': 'returning', 'score': 1.3479485511779785},\n",
       " {'label': 'returning', 'score': 1.5172066688537598},\n",
       " {'label': 'returning', 'score': 1.5172066688537598},\n",
       " {'label': 'returning', 'score': 1.5172066688537598},\n",
       " {'label': 'returning', 'score': 0.9323405027389526},\n",
       " {'label': 'returning', 'score': 0.9323405027389526},\n",
       " {'label': 'returning', 'score': 0.9323405027389526},\n",
       " {'label': 'leaving', 'score': 0.7745737433433533},\n",
       " {'label': 'leaving', 'score': 0.7745737433433533},\n",
       " {'label': 'leaving', 'score': 0.7745737433433533},\n",
       " {'label': 'leaving', 'score': 1.1805195808410645},\n",
       " {'label': 'leaving', 'score': 1.1805195808410645},\n",
       " {'label': 'leaving', 'score': 1.1805195808410645},\n",
       " {'label': 'none', 'score': 1.3536174297332764},\n",
       " {'label': 'none', 'score': 1.3536174297332764},\n",
       " {'label': 'none', 'score': 1.3536174297332764},\n",
       " {'label': 'none', 'score': 1.4065423011779785},\n",
       " {'label': 'none', 'score': 1.4065423011779785},\n",
       " {'label': 'none', 'score': 1.4065423011779785},\n",
       " {'label': 'none', 'score': 1.4947916269302368},\n",
       " {'label': 'none', 'score': 1.4947916269302368},\n",
       " {'label': 'none', 'score': 1.4947916269302368},\n",
       " {'label': 'none', 'score': 1.45395028591156},\n",
       " {'label': 'none', 'score': 1.45395028591156},\n",
       " {'label': 'none', 'score': 1.45395028591156},\n",
       " {'label': 'none', 'score': 1.3152395486831665},\n",
       " {'label': 'none', 'score': 1.3152395486831665},\n",
       " {'label': 'none', 'score': 1.3152395486831665},\n",
       " {'label': 'none', 'score': 1.776485562324524},\n",
       " {'label': 'none', 'score': 1.776485562324524},\n",
       " {'label': 'none', 'score': 1.776485562324524},\n",
       " {'label': 'none', 'score': 1.5326913595199585},\n",
       " {'label': 'none', 'score': 1.5326913595199585},\n",
       " {'label': 'none', 'score': 1.5326913595199585},\n",
       " {'label': 'none', 'score': 1.484606146812439},\n",
       " {'label': 'none', 'score': 1.484606146812439},\n",
       " {'label': 'none', 'score': 1.484606146812439},\n",
       " {'label': 'none', 'score': 1.357497215270996},\n",
       " {'label': 'none', 'score': 1.357497215270996},\n",
       " {'label': 'none', 'score': 1.357497215270996},\n",
       " {'label': 'none', 'score': 1.4367319345474243},\n",
       " {'label': 'none', 'score': 1.4367319345474243},\n",
       " {'label': 'none', 'score': 1.4367319345474243},\n",
       " {'label': 'none', 'score': 1.7940194606781006},\n",
       " {'label': 'none', 'score': 1.7940194606781006},\n",
       " {'label': 'none', 'score': 1.7940194606781006},\n",
       " {'label': 'returning', 'score': 1.2043302059173584},\n",
       " {'label': 'returning', 'score': 1.2043302059173584},\n",
       " {'label': 'returning', 'score': 1.2043302059173584},\n",
       " {'label': 'returning', 'score': 1.0555158853530884},\n",
       " {'label': 'returning', 'score': 1.0555158853530884},\n",
       " {'label': 'returning', 'score': 1.0555158853530884},\n",
       " {'label': 'returning', 'score': 2.349623918533325},\n",
       " {'label': 'returning', 'score': 2.349623918533325},\n",
       " {'label': 'returning', 'score': 2.349623918533325},\n",
       " {'label': 'returning', 'score': 1.3089021444320679},\n",
       " {'label': 'returning', 'score': 1.3089021444320679},\n",
       " {'label': 'returning', 'score': 1.3089021444320679},\n",
       " {'label': 'returning', 'score': 1.4807113409042358},\n",
       " {'label': 'returning', 'score': 1.4807113409042358},\n",
       " {'label': 'returning', 'score': 1.4807113409042358},\n",
       " {'label': 'returning', 'score': 1.359357237815857},\n",
       " {'label': 'returning', 'score': 1.359357237815857},\n",
       " {'label': 'returning', 'score': 1.359357237815857},\n",
       " {'label': 'returning', 'score': 1.1403155326843262},\n",
       " {'label': 'returning', 'score': 1.1403155326843262},\n",
       " {'label': 'returning', 'score': 1.1403155326843262},\n",
       " {'label': 'returning', 'score': 1.1054706573486328},\n",
       " {'label': 'returning', 'score': 1.1054706573486328},\n",
       " {'label': 'returning', 'score': 1.1054706573486328},\n",
       " {'label': 'returning', 'score': 0.8806390762329102},\n",
       " {'label': 'returning', 'score': 0.8806390762329102},\n",
       " {'label': 'returning', 'score': 0.8806390762329102},\n",
       " {'label': 'leaving', 'score': 1.3107246160507202},\n",
       " {'label': 'leaving', 'score': 1.3107246160507202},\n",
       " {'label': 'leaving', 'score': 1.3107246160507202},\n",
       " {'label': 'none', 'score': 1.9098448753356934},\n",
       " {'label': 'none', 'score': 1.9098448753356934},\n",
       " {'label': 'none', 'score': 1.9098448753356934},\n",
       " {'label': 'none', 'score': 1.4014028310775757},\n",
       " {'label': 'none', 'score': 1.4014028310775757},\n",
       " {'label': 'none', 'score': 1.4014028310775757},\n",
       " {'label': 'none', 'score': 1.6251885890960693},\n",
       " {'label': 'none', 'score': 1.6251885890960693},\n",
       " {'label': 'none', 'score': 1.6251885890960693},\n",
       " {'label': 'none', 'score': 1.6506670713424683},\n",
       " {'label': 'none', 'score': 1.6506670713424683},\n",
       " {'label': 'none', 'score': 1.6506670713424683}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:16:30.653379Z",
     "start_time": "2020-05-01T02:16:30.638933Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(results_path,'validation_results.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:16:31.859802Z",
     "start_time": "2020-05-01T02:16:31.848418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:16:33.090671Z",
     "start_time": "2020-05-01T02:16:32.768291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - More diverse dataset \n",
    "    - Hyperparameter tuning\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:16:36.988109Z",
     "start_time": "2020-05-01T02:16:36.661055Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/CSCE636-project-porta/porta1.pth')\n",
    "torch.save(my_model, weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
