{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:19.833976Z",
     "start_time": "2020-03-16T18:46:19.823466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.015144Z",
     "start_time": "2020-03-16T18:46:19.835049Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.245253Z",
     "start_time": "2020-03-16T18:46:20.016393Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.254886Z",
     "start_time": "2020-03-16T18:46:20.246626Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.268088Z",
     "start_time": "2020-03-16T18:46:20.255882Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.279802Z",
     "start_time": "2020-03-16T18:46:20.269019Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.291723Z",
     "start_time": "2020-03-16T18:46:20.280986Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.301647Z",
     "start_time": "2020-03-16T18:46:20.293537Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.400067Z",
     "start_time": "2020-03-16T18:46:20.303011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.410340Z",
     "start_time": "2020-03-16T18:46:20.401186Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.423307Z",
     "start_time": "2020-03-16T18:46:20.411423Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.437020Z",
     "start_time": "2020-03-16T18:46:20.424436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.448665Z",
     "start_time": "2020-03-16T18:46:20.438022Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:20.963731Z",
     "start_time": "2020-03-16T18:46:20.449631Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:23.236254Z",
     "start_time": "2020-03-16T18:46:20.964856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:46:23.246952Z",
     "start_time": "2020-03-16T18:46:23.237506Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:47:55.551209Z",
     "start_time": "2020-03-16T18:47:55.540217Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 256), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:47:56.559816Z",
     "start_time": "2020-03-16T18:47:56.529549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:47:58.173059Z",
     "start_time": "2020-03-16T18:47:58.162505Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-2,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:51:36.220907Z",
     "start_time": "2020-03-16T18:51:36.210887Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:54:30.769630Z",
     "start_time": "2020-03-16T18:51:38.823370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 0.614 (0.614)\tData 0.306 (0.306)\tLoss 1.0536 (1.0536)\tAcc 0.625 (0.625)\n",
      "Epoch: [1][2/5]\tTime 0.026 (0.320)\tData 0.002 (0.154)\tLoss 0.9107 (0.9821)\tAcc 0.812 (0.719)\n",
      "Epoch: [1][3/5]\tTime 0.092 (0.244)\tData 0.068 (0.125)\tLoss 1.1753 (1.0465)\tAcc 0.438 (0.625)\n",
      "Epoch: [1][4/5]\tTime 0.084 (0.204)\tData 0.061 (0.109)\tLoss 0.8390 (0.9947)\tAcc 0.688 (0.641)\n",
      "Epoch: [1][5/5]\tTime 0.080 (0.179)\tData 0.057 (0.099)\tLoss 0.5839 (0.9440)\tAcc 0.889 (0.671)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.356 (0.356)\tData 0.331 (0.331)\tLoss 0.4382 (0.4382)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.075 (0.216)\tData 0.053 (0.192)\tLoss 1.2449 (0.8416)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.077 (0.169)\tData 0.057 (0.147)\tLoss 0.8602 (0.8478)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.079 (0.147)\tData 0.057 (0.124)\tLoss 0.8178 (0.8403)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.085 (0.135)\tData 0.063 (0.112)\tLoss 0.9192 (0.8561)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.073 (0.124)\tData 0.053 (0.102)\tLoss 0.3087 (0.7649)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.072 (0.117)\tData 0.052 (0.095)\tLoss 0.5167 (0.7294)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.074 (0.111)\tData 0.054 (0.090)\tLoss 1.2125 (0.7898)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.074 (0.107)\tData 0.054 (0.086)\tLoss 0.3389 (0.7829)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.421 (0.421)\tData 0.394 (0.394)\tLoss 0.7668 (0.7668)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][2/5]\tTime 0.075 (0.248)\tData 0.050 (0.222)\tLoss 1.1465 (0.9566)\tAcc 0.562 (0.625)\n",
      "Epoch: [2][3/5]\tTime 0.075 (0.190)\tData 0.052 (0.165)\tLoss 0.9272 (0.9468)\tAcc 0.625 (0.625)\n",
      "Epoch: [2][4/5]\tTime 0.076 (0.162)\tData 0.053 (0.137)\tLoss 0.7695 (0.9025)\tAcc 0.750 (0.656)\n",
      "Epoch: [2][5/5]\tTime 0.080 (0.145)\tData 0.056 (0.121)\tLoss 0.7042 (0.8781)\tAcc 0.778 (0.671)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.5410 (0.5410)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.069 (0.218)\tData 0.048 (0.194)\tLoss 1.2036 (0.8723)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.072 (0.169)\tData 0.052 (0.147)\tLoss 0.8846 (0.8764)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.075 (0.146)\tData 0.055 (0.124)\tLoss 0.8605 (0.8724)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.073 (0.131)\tData 0.054 (0.110)\tLoss 0.8437 (0.8667)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.101)\tLoss 0.4361 (0.7949)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.5725 (0.7631)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 1.1023 (0.8055)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.074 (0.106)\tData 0.055 (0.085)\tLoss 0.4578 (0.8002)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.302 (0.302)\tData 0.271 (0.271)\tLoss 0.7649 (0.7649)\tAcc 0.625 (0.625)\n",
      "Epoch: [3][2/5]\tTime 0.071 (0.186)\tData 0.047 (0.159)\tLoss 0.9858 (0.8754)\tAcc 0.438 (0.531)\n",
      "Epoch: [3][3/5]\tTime 0.076 (0.150)\tData 0.053 (0.124)\tLoss 0.8260 (0.8589)\tAcc 0.750 (0.604)\n",
      "Epoch: [3][4/5]\tTime 0.076 (0.131)\tData 0.053 (0.106)\tLoss 0.8204 (0.8493)\tAcc 0.688 (0.625)\n",
      "Epoch: [3][5/5]\tTime 0.079 (0.121)\tData 0.056 (0.096)\tLoss 0.4549 (0.8007)\tAcc 0.889 (0.658)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.351 (0.351)\tData 0.326 (0.326)\tLoss 0.2726 (0.2726)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.069 (0.210)\tData 0.048 (0.187)\tLoss 1.5585 (0.9155)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.074 (0.165)\tData 0.052 (0.142)\tLoss 1.0817 (0.9709)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.073 (0.142)\tData 0.053 (0.120)\tLoss 0.9634 (0.9691)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.092 (0.132)\tData 0.072 (0.110)\tLoss 1.0748 (0.9902)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.079 (0.123)\tData 0.059 (0.102)\tLoss 0.1268 (0.8463)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.079 (0.117)\tData 0.059 (0.096)\tLoss 0.5254 (0.8005)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.079 (0.112)\tData 0.060 (0.091)\tLoss 1.6090 (0.9015)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.078 (0.108)\tData 0.059 (0.087)\tLoss 0.1151 (0.8894)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.286 (0.286)\tData 0.257 (0.257)\tLoss 1.2476 (1.2476)\tAcc 0.500 (0.500)\n",
      "Epoch: [4][2/5]\tTime 0.073 (0.180)\tData 0.049 (0.153)\tLoss 0.6903 (0.9690)\tAcc 0.812 (0.656)\n",
      "Epoch: [4][3/5]\tTime 0.076 (0.145)\tData 0.053 (0.120)\tLoss 0.4712 (0.8030)\tAcc 0.750 (0.688)\n",
      "Epoch: [4][4/5]\tTime 0.076 (0.128)\tData 0.053 (0.103)\tLoss 1.2840 (0.9233)\tAcc 0.562 (0.656)\n",
      "Epoch: [4][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.094)\tLoss 0.6837 (0.8937)\tAcc 0.778 (0.671)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.360 (0.360)\tData 0.337 (0.337)\tLoss 0.3861 (0.3861)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.071 (0.216)\tData 0.050 (0.193)\tLoss 1.3567 (0.8714)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.073 (0.168)\tData 0.052 (0.146)\tLoss 0.8490 (0.8639)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/9]\tTime 0.074 (0.145)\tData 0.055 (0.123)\tLoss 0.8983 (0.8725)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/9]\tTime 0.075 (0.131)\tData 0.054 (0.110)\tLoss 0.8785 (0.8737)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/9]\tTime 0.077 (0.122)\tData 0.058 (0.101)\tLoss 0.2978 (0.7777)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/9]\tTime 0.077 (0.115)\tData 0.057 (0.095)\tLoss 0.4983 (0.7378)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/9]\tTime 0.074 (0.110)\tData 0.054 (0.090)\tLoss 1.1526 (0.7897)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.086)\tLoss 0.2616 (0.7815)\tAcc 1.000 (0.731)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.309 (0.309)\tData 0.280 (0.280)\tLoss 0.6913 (0.6913)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][2/5]\tTime 0.072 (0.191)\tData 0.048 (0.164)\tLoss 0.7841 (0.7377)\tAcc 0.562 (0.625)\n",
      "Epoch: [5][3/5]\tTime 0.076 (0.152)\tData 0.053 (0.127)\tLoss 0.7691 (0.7482)\tAcc 0.750 (0.667)\n",
      "Epoch: [5][4/5]\tTime 0.076 (0.133)\tData 0.053 (0.109)\tLoss 0.7513 (0.7489)\tAcc 0.812 (0.703)\n",
      "Epoch: [5][5/5]\tTime 0.080 (0.123)\tData 0.057 (0.098)\tLoss 0.8318 (0.7591)\tAcc 0.667 (0.699)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.369 (0.369)\tData 0.345 (0.345)\tLoss 0.3755 (0.3755)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.071 (0.220)\tData 0.050 (0.197)\tLoss 1.2053 (0.7904)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.073 (0.171)\tData 0.052 (0.149)\tLoss 0.9422 (0.8410)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.074 (0.147)\tData 0.052 (0.125)\tLoss 0.8491 (0.8430)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.087 (0.135)\tData 0.067 (0.113)\tLoss 0.9407 (0.8626)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.073 (0.125)\tData 0.053 (0.103)\tLoss 0.2695 (0.7637)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.073 (0.117)\tData 0.053 (0.096)\tLoss 0.5193 (0.7288)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.073 (0.112)\tData 0.053 (0.091)\tLoss 1.2851 (0.7983)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.074 (0.107)\tData 0.054 (0.087)\tLoss 0.2335 (0.7896)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.288 (0.288)\tData 0.259 (0.259)\tLoss 1.0217 (1.0217)\tAcc 0.562 (0.562)\n",
      "Epoch: [6][2/5]\tTime 0.073 (0.181)\tData 0.049 (0.154)\tLoss 0.9029 (0.9623)\tAcc 0.750 (0.656)\n",
      "Epoch: [6][3/5]\tTime 0.075 (0.145)\tData 0.052 (0.120)\tLoss 0.9800 (0.9682)\tAcc 0.500 (0.604)\n",
      "Epoch: [6][4/5]\tTime 0.077 (0.128)\tData 0.054 (0.103)\tLoss 0.6433 (0.8870)\tAcc 0.875 (0.672)\n",
      "Epoch: [6][5/5]\tTime 0.080 (0.119)\tData 0.057 (0.094)\tLoss 0.5314 (0.8431)\tAcc 0.778 (0.685)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.363 (0.363)\tData 0.339 (0.339)\tLoss 0.3703 (0.3703)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.071 (0.217)\tData 0.050 (0.195)\tLoss 1.3188 (0.8446)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/9]\tTime 0.075 (0.170)\tData 0.052 (0.147)\tLoss 0.9398 (0.8763)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/9]\tTime 0.072 (0.145)\tData 0.051 (0.123)\tLoss 0.8589 (0.8719)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/9]\tTime 0.072 (0.131)\tData 0.052 (0.109)\tLoss 0.8680 (0.8712)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/9]\tTime 0.074 (0.121)\tData 0.054 (0.100)\tLoss 0.2925 (0.7747)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/9]\tTime 0.072 (0.114)\tData 0.053 (0.093)\tLoss 0.5170 (0.7379)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 1.2453 (0.8013)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 0.3000 (0.7936)\tAcc 1.000 (0.731)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.333 (0.333)\tData 0.304 (0.304)\tLoss 0.6061 (0.6061)\tAcc 0.750 (0.750)\n",
      "Epoch: [7][2/5]\tTime 0.073 (0.203)\tData 0.049 (0.177)\tLoss 0.7790 (0.6926)\tAcc 0.625 (0.688)\n",
      "Epoch: [7][3/5]\tTime 0.076 (0.161)\tData 0.053 (0.135)\tLoss 0.7215 (0.7022)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.076 (0.140)\tData 0.053 (0.115)\tLoss 1.4424 (0.8872)\tAcc 0.625 (0.688)\n",
      "Epoch: [7][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 0.8663 (0.8847)\tAcc 0.667 (0.685)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.249 (0.249)\tData 0.225 (0.225)\tLoss 0.3884 (0.3884)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.088 (0.169)\tData 0.065 (0.145)\tLoss 1.2485 (0.8185)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.084 (0.140)\tData 0.063 (0.118)\tLoss 0.9470 (0.8613)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.073 (0.123)\tData 0.052 (0.102)\tLoss 0.8525 (0.8591)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.076 (0.114)\tData 0.054 (0.092)\tLoss 0.8771 (0.8627)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.071 (0.107)\tData 0.052 (0.085)\tLoss 0.2721 (0.7643)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.073 (0.102)\tData 0.053 (0.081)\tLoss 0.5043 (0.7271)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.074 (0.098)\tData 0.055 (0.078)\tLoss 1.1581 (0.7810)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.074 (0.096)\tData 0.054 (0.075)\tLoss 0.2613 (0.7730)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.305 (0.305)\tData 0.276 (0.276)\tLoss 0.7359 (0.7359)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][2/5]\tTime 0.074 (0.189)\tData 0.050 (0.163)\tLoss 0.6404 (0.6881)\tAcc 0.812 (0.781)\n",
      "Epoch: [8][3/5]\tTime 0.076 (0.152)\tData 0.052 (0.126)\tLoss 0.6231 (0.6664)\tAcc 0.875 (0.812)\n",
      "Epoch: [8][4/5]\tTime 0.076 (0.133)\tData 0.053 (0.108)\tLoss 0.9317 (0.7328)\tAcc 0.625 (0.766)\n",
      "Epoch: [8][5/5]\tTime 0.079 (0.122)\tData 0.055 (0.097)\tLoss 1.0639 (0.7736)\tAcc 0.444 (0.726)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.351 (0.351)\tData 0.310 (0.310)\tLoss 0.6125 (0.6125)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.060 (0.205)\tData 0.036 (0.173)\tLoss 1.3112 (0.9619)\tAcc 0.375 (0.656)\n",
      "Epoch: [8][3/9]\tTime 0.082 (0.164)\tData 0.057 (0.134)\tLoss 0.8653 (0.9297)\tAcc 0.688 (0.667)\n",
      "Epoch: [8][4/9]\tTime 0.076 (0.142)\tData 0.055 (0.115)\tLoss 0.9059 (0.9237)\tAcc 0.688 (0.672)\n",
      "Epoch: [8][5/9]\tTime 0.079 (0.130)\tData 0.059 (0.103)\tLoss 0.8215 (0.9033)\tAcc 0.688 (0.675)\n",
      "Epoch: [8][6/9]\tTime 0.079 (0.121)\tData 0.059 (0.096)\tLoss 0.4251 (0.8236)\tAcc 1.000 (0.729)\n",
      "Epoch: [8][7/9]\tTime 0.080 (0.115)\tData 0.060 (0.091)\tLoss 0.5878 (0.7899)\tAcc 0.875 (0.750)\n",
      "Epoch: [8][8/9]\tTime 0.079 (0.111)\tData 0.059 (0.087)\tLoss 1.0721 (0.8252)\tAcc 0.500 (0.719)\n",
      "Epoch: [8][9/9]\tTime 0.079 (0.107)\tData 0.059 (0.084)\tLoss 0.6719 (0.8228)\tAcc 1.000 (0.723)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.399 (0.399)\tData 0.373 (0.373)\tLoss 0.9576 (0.9576)\tAcc 0.562 (0.562)\n",
      "Epoch: [9][2/5]\tTime 0.075 (0.237)\tData 0.051 (0.212)\tLoss 0.6451 (0.8013)\tAcc 0.812 (0.688)\n",
      "Epoch: [9][3/5]\tTime 0.077 (0.184)\tData 0.053 (0.159)\tLoss 0.7180 (0.7736)\tAcc 0.812 (0.729)\n",
      "Epoch: [9][4/5]\tTime 0.077 (0.157)\tData 0.053 (0.132)\tLoss 0.9042 (0.8062)\tAcc 0.625 (0.703)\n",
      "Epoch: [9][5/5]\tTime 0.080 (0.142)\tData 0.055 (0.117)\tLoss 0.6273 (0.7841)\tAcc 0.889 (0.726)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.307 (0.307)\tData 0.280 (0.280)\tLoss 0.4115 (0.4115)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/9]\tTime 0.077 (0.192)\tData 0.054 (0.167)\tLoss 1.3219 (0.8667)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/9]\tTime 0.079 (0.154)\tData 0.056 (0.130)\tLoss 0.8917 (0.8750)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/9]\tTime 0.084 (0.136)\tData 0.057 (0.112)\tLoss 0.9242 (0.8873)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/9]\tTime 0.075 (0.124)\tData 0.053 (0.100)\tLoss 0.9229 (0.8944)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/9]\tTime 0.078 (0.116)\tData 0.057 (0.093)\tLoss 0.3678 (0.8067)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/9]\tTime 0.079 (0.111)\tData 0.059 (0.088)\tLoss 0.5203 (0.7658)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/9]\tTime 0.075 (0.107)\tData 0.053 (0.084)\tLoss 1.2682 (0.8286)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.2987 (0.8204)\tAcc 1.000 (0.731)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.358 (0.358)\tData 0.322 (0.322)\tLoss 0.7569 (0.7569)\tAcc 0.625 (0.625)\n",
      "Epoch: [10][2/5]\tTime 0.080 (0.219)\tData 0.054 (0.188)\tLoss 0.6698 (0.7134)\tAcc 0.750 (0.688)\n",
      "Epoch: [10][3/5]\tTime 0.084 (0.174)\tData 0.059 (0.145)\tLoss 0.7822 (0.7363)\tAcc 0.750 (0.708)\n",
      "Epoch: [10][4/5]\tTime 0.084 (0.151)\tData 0.060 (0.124)\tLoss 0.6773 (0.7216)\tAcc 0.688 (0.703)\n",
      "Epoch: [10][5/5]\tTime 0.086 (0.138)\tData 0.061 (0.111)\tLoss 1.7618 (0.8498)\tAcc 0.333 (0.658)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.342 (0.342)\tData 0.317 (0.317)\tLoss 0.5982 (0.5982)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.072 (0.207)\tData 0.049 (0.183)\tLoss 1.2436 (0.9209)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/9]\tTime 0.097 (0.171)\tData 0.067 (0.145)\tLoss 0.8249 (0.8889)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.082 (0.148)\tData 0.051 (0.121)\tLoss 0.8615 (0.8821)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.074 (0.134)\tData 0.054 (0.108)\tLoss 0.8387 (0.8734)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.078 (0.124)\tData 0.057 (0.099)\tLoss 0.4721 (0.8065)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.079 (0.118)\tData 0.059 (0.093)\tLoss 0.5894 (0.7755)\tAcc 0.875 (0.759)\n",
      "Epoch: [10][8/9]\tTime 0.076 (0.113)\tData 0.055 (0.089)\tLoss 1.1059 (0.8168)\tAcc 0.500 (0.727)\n",
      "Epoch: [10][9/9]\tTime 0.079 (0.109)\tData 0.059 (0.085)\tLoss 0.5115 (0.8121)\tAcc 1.000 (0.731)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.339 (0.339)\tData 0.311 (0.311)\tLoss 0.8686 (0.8686)\tAcc 0.625 (0.625)\n",
      "Epoch: [11][2/5]\tTime 0.084 (0.211)\tData 0.060 (0.186)\tLoss 0.6840 (0.7763)\tAcc 0.875 (0.750)\n",
      "Epoch: [11][3/5]\tTime 0.081 (0.168)\tData 0.057 (0.143)\tLoss 0.9241 (0.8256)\tAcc 0.562 (0.688)\n",
      "Epoch: [11][4/5]\tTime 0.085 (0.147)\tData 0.061 (0.122)\tLoss 0.8848 (0.8404)\tAcc 0.750 (0.703)\n",
      "Epoch: [11][5/5]\tTime 0.083 (0.134)\tData 0.058 (0.109)\tLoss 0.8851 (0.8459)\tAcc 0.667 (0.699)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.365 (0.365)\tData 0.341 (0.341)\tLoss 0.7633 (0.7633)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/9]\tTime 0.076 (0.220)\tData 0.053 (0.197)\tLoss 1.2660 (1.0147)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/9]\tTime 0.079 (0.173)\tData 0.056 (0.150)\tLoss 0.8585 (0.9626)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][4/9]\tTime 0.081 (0.150)\tData 0.059 (0.127)\tLoss 0.9847 (0.9681)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][5/9]\tTime 0.073 (0.135)\tData 0.053 (0.112)\tLoss 0.8868 (0.9519)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][6/9]\tTime 0.079 (0.126)\tData 0.059 (0.103)\tLoss 0.6970 (0.9094)\tAcc 1.000 (0.740)\n",
      "Epoch: [11][7/9]\tTime 0.074 (0.118)\tData 0.054 (0.096)\tLoss 0.8270 (0.8976)\tAcc 0.875 (0.759)\n",
      "Epoch: [11][8/9]\tTime 0.076 (0.113)\tData 0.055 (0.091)\tLoss 0.9928 (0.9095)\tAcc 0.500 (0.727)\n",
      "Epoch: [11][9/9]\tTime 0.074 (0.109)\tData 0.054 (0.087)\tLoss 0.6257 (0.9051)\tAcc 1.000 (0.731)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.341 (0.341)\tData 0.310 (0.310)\tLoss 0.8790 (0.8790)\tAcc 0.812 (0.812)\n",
      "Epoch: [12][2/5]\tTime 0.076 (0.208)\tData 0.049 (0.179)\tLoss 0.6150 (0.7470)\tAcc 0.750 (0.781)\n",
      "Epoch: [12][3/5]\tTime 0.083 (0.167)\tData 0.058 (0.139)\tLoss 0.7147 (0.7362)\tAcc 0.688 (0.750)\n",
      "Epoch: [12][4/5]\tTime 0.083 (0.146)\tData 0.057 (0.119)\tLoss 0.7364 (0.7362)\tAcc 0.688 (0.734)\n",
      "Epoch: [12][5/5]\tTime 0.086 (0.134)\tData 0.060 (0.107)\tLoss 1.4598 (0.8254)\tAcc 0.333 (0.685)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.371 (0.371)\tData 0.345 (0.345)\tLoss 0.4530 (0.4530)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/9]\tTime 0.069 (0.220)\tData 0.048 (0.196)\tLoss 1.4491 (0.9510)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/9]\tTime 0.073 (0.171)\tData 0.052 (0.148)\tLoss 0.8763 (0.9261)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][4/9]\tTime 0.075 (0.147)\tData 0.052 (0.124)\tLoss 1.0640 (0.9606)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/9]\tTime 0.071 (0.132)\tData 0.051 (0.110)\tLoss 0.7824 (0.9249)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][6/9]\tTime 0.079 (0.123)\tData 0.059 (0.101)\tLoss 0.2631 (0.8146)\tAcc 1.000 (0.740)\n",
      "Epoch: [12][7/9]\tTime 0.080 (0.117)\tData 0.060 (0.095)\tLoss 0.5976 (0.7836)\tAcc 0.875 (0.759)\n",
      "Epoch: [12][8/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 1.1947 (0.8350)\tAcc 0.500 (0.727)\n",
      "Epoch: [12][9/9]\tTime 0.079 (0.108)\tData 0.060 (0.087)\tLoss 0.1578 (0.8246)\tAcc 1.000 (0.731)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.398 (0.398)\tData 0.369 (0.369)\tLoss 0.4302 (0.4302)\tAcc 0.812 (0.812)\n",
      "Epoch: [13][2/5]\tTime 0.074 (0.236)\tData 0.050 (0.210)\tLoss 1.0782 (0.7542)\tAcc 0.562 (0.688)\n",
      "Epoch: [13][3/5]\tTime 0.076 (0.183)\tData 0.053 (0.157)\tLoss 0.8071 (0.7718)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/5]\tTime 0.077 (0.156)\tData 0.053 (0.131)\tLoss 0.9024 (0.8045)\tAcc 0.625 (0.672)\n",
      "Epoch: [13][5/5]\tTime 0.079 (0.141)\tData 0.056 (0.116)\tLoss 1.2634 (0.8611)\tAcc 0.444 (0.644)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.405 (0.405)\tData 0.369 (0.369)\tLoss 0.8972 (0.8972)\tAcc 0.812 (0.812)\n",
      "Epoch: [13][2/9]\tTime 0.092 (0.248)\tData 0.066 (0.217)\tLoss 1.0061 (0.9517)\tAcc 0.375 (0.594)\n",
      "Epoch: [13][3/9]\tTime 0.071 (0.189)\tData 0.048 (0.161)\tLoss 0.8980 (0.9338)\tAcc 0.812 (0.667)\n",
      "Epoch: [13][4/9]\tTime 0.081 (0.162)\tData 0.057 (0.135)\tLoss 1.0446 (0.9615)\tAcc 0.688 (0.672)\n",
      "Epoch: [13][5/9]\tTime 0.076 (0.145)\tData 0.056 (0.119)\tLoss 0.9930 (0.9678)\tAcc 0.750 (0.688)\n",
      "Epoch: [13][6/9]\tTime 0.079 (0.134)\tData 0.059 (0.109)\tLoss 0.7805 (0.9366)\tAcc 1.000 (0.740)\n",
      "Epoch: [13][7/9]\tTime 0.081 (0.127)\tData 0.059 (0.102)\tLoss 0.8284 (0.9211)\tAcc 0.875 (0.759)\n",
      "Epoch: [13][8/9]\tTime 0.082 (0.121)\tData 0.061 (0.097)\tLoss 1.1228 (0.9463)\tAcc 0.438 (0.719)\n",
      "Epoch: [13][9/9]\tTime 0.079 (0.116)\tData 0.060 (0.093)\tLoss 0.6488 (0.9418)\tAcc 1.000 (0.723)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.435 (0.435)\tData 0.404 (0.404)\tLoss 0.6360 (0.6360)\tAcc 0.812 (0.812)\n",
      "Epoch: [14][2/5]\tTime 0.080 (0.258)\tData 0.054 (0.229)\tLoss 0.9575 (0.7968)\tAcc 0.562 (0.688)\n",
      "Epoch: [14][3/5]\tTime 0.084 (0.200)\tData 0.059 (0.173)\tLoss 0.7569 (0.7835)\tAcc 0.625 (0.667)\n",
      "Epoch: [14][4/5]\tTime 0.085 (0.171)\tData 0.060 (0.144)\tLoss 0.7089 (0.7648)\tAcc 0.812 (0.703)\n",
      "Epoch: [14][5/5]\tTime 0.084 (0.154)\tData 0.060 (0.128)\tLoss 0.6516 (0.7509)\tAcc 0.778 (0.712)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.367 (0.367)\tData 0.341 (0.341)\tLoss 0.3550 (0.3550)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.070 (0.219)\tData 0.049 (0.195)\tLoss 1.3235 (0.8392)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/9]\tTime 0.075 (0.171)\tData 0.052 (0.147)\tLoss 0.7804 (0.8196)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][4/9]\tTime 0.074 (0.147)\tData 0.052 (0.123)\tLoss 0.9365 (0.8488)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][5/9]\tTime 0.072 (0.132)\tData 0.052 (0.109)\tLoss 0.8574 (0.8506)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.100)\tLoss 0.2059 (0.7431)\tAcc 1.000 (0.740)\n",
      "Epoch: [14][7/9]\tTime 0.074 (0.115)\tData 0.055 (0.094)\tLoss 0.4332 (0.6988)\tAcc 0.875 (0.759)\n",
      "Epoch: [14][8/9]\tTime 0.080 (0.111)\tData 0.060 (0.089)\tLoss 1.2760 (0.7710)\tAcc 0.500 (0.727)\n",
      "Epoch: [14][9/9]\tTime 0.077 (0.107)\tData 0.057 (0.086)\tLoss 0.1608 (0.7616)\tAcc 1.000 (0.731)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.347 (0.347)\tData 0.310 (0.310)\tLoss 1.0518 (1.0518)\tAcc 0.625 (0.625)\n",
      "Epoch: [15][2/5]\tTime 0.074 (0.211)\tData 0.049 (0.179)\tLoss 0.8518 (0.9518)\tAcc 0.625 (0.625)\n",
      "Epoch: [15][3/5]\tTime 0.084 (0.168)\tData 0.060 (0.140)\tLoss 0.5412 (0.8149)\tAcc 0.750 (0.667)\n",
      "Epoch: [15][4/5]\tTime 0.079 (0.146)\tData 0.054 (0.118)\tLoss 0.8900 (0.8337)\tAcc 0.688 (0.672)\n",
      "Epoch: [15][5/5]\tTime 0.086 (0.134)\tData 0.061 (0.107)\tLoss 0.3729 (0.7769)\tAcc 0.889 (0.699)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.377 (0.377)\tData 0.351 (0.351)\tLoss 0.3914 (0.3914)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/9]\tTime 0.073 (0.225)\tData 0.049 (0.200)\tLoss 1.2083 (0.7998)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/9]\tTime 0.085 (0.178)\tData 0.058 (0.153)\tLoss 0.6815 (0.7604)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][4/9]\tTime 0.072 (0.152)\tData 0.050 (0.127)\tLoss 0.8562 (0.7844)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][5/9]\tTime 0.074 (0.136)\tData 0.053 (0.112)\tLoss 0.7977 (0.7870)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][6/9]\tTime 0.080 (0.127)\tData 0.060 (0.104)\tLoss 0.2776 (0.7021)\tAcc 1.000 (0.740)\n",
      "Epoch: [15][7/9]\tTime 0.080 (0.120)\tData 0.060 (0.097)\tLoss 0.5336 (0.6780)\tAcc 0.938 (0.768)\n",
      "Epoch: [15][8/9]\tTime 0.079 (0.115)\tData 0.059 (0.093)\tLoss 1.2038 (0.7438)\tAcc 0.500 (0.734)\n",
      "Epoch: [15][9/9]\tTime 0.078 (0.111)\tData 0.060 (0.089)\tLoss 0.3544 (0.7378)\tAcc 1.000 (0.738)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.417 (0.417)\tData 0.389 (0.389)\tLoss 0.6723 (0.6723)\tAcc 0.625 (0.625)\n",
      "Epoch: [16][2/5]\tTime 0.076 (0.246)\tData 0.050 (0.220)\tLoss 0.5051 (0.5887)\tAcc 0.875 (0.750)\n",
      "Epoch: [16][3/5]\tTime 0.078 (0.190)\tData 0.053 (0.164)\tLoss 0.4866 (0.5547)\tAcc 0.812 (0.771)\n",
      "Epoch: [16][4/5]\tTime 0.084 (0.164)\tData 0.059 (0.138)\tLoss 1.2234 (0.7219)\tAcc 0.625 (0.734)\n",
      "Epoch: [16][5/5]\tTime 0.084 (0.148)\tData 0.060 (0.123)\tLoss 1.2244 (0.7838)\tAcc 0.556 (0.712)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.434 (0.434)\tData 0.409 (0.409)\tLoss 0.3737 (0.3737)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.076 (0.255)\tData 0.053 (0.231)\tLoss 1.1667 (0.7702)\tAcc 0.500 (0.719)\n",
      "Epoch: [16][3/9]\tTime 0.079 (0.196)\tData 0.057 (0.173)\tLoss 0.6062 (0.7155)\tAcc 0.688 (0.708)\n",
      "Epoch: [16][4/9]\tTime 0.081 (0.168)\tData 0.058 (0.144)\tLoss 0.7972 (0.7359)\tAcc 0.688 (0.703)\n",
      "Epoch: [16][5/9]\tTime 0.078 (0.150)\tData 0.057 (0.127)\tLoss 0.7984 (0.7484)\tAcc 0.688 (0.700)\n",
      "Epoch: [16][6/9]\tTime 0.080 (0.138)\tData 0.060 (0.116)\tLoss 0.2036 (0.6576)\tAcc 1.000 (0.750)\n",
      "Epoch: [16][7/9]\tTime 0.075 (0.129)\tData 0.054 (0.107)\tLoss 0.7218 (0.6668)\tAcc 0.812 (0.759)\n",
      "Epoch: [16][8/9]\tTime 0.074 (0.122)\tData 0.053 (0.100)\tLoss 1.1332 (0.7251)\tAcc 0.500 (0.727)\n",
      "Epoch: [16][9/9]\tTime 0.079 (0.117)\tData 0.059 (0.096)\tLoss 0.4070 (0.7202)\tAcc 1.000 (0.731)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.342 (0.342)\tData 0.313 (0.313)\tLoss 0.6683 (0.6683)\tAcc 0.625 (0.625)\n",
      "Epoch: [17][2/5]\tTime 0.073 (0.207)\tData 0.049 (0.181)\tLoss 0.8919 (0.7801)\tAcc 0.750 (0.688)\n",
      "Epoch: [17][3/5]\tTime 0.079 (0.164)\tData 0.053 (0.138)\tLoss 0.6027 (0.7210)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][4/5]\tTime 0.081 (0.144)\tData 0.056 (0.118)\tLoss 0.5968 (0.6899)\tAcc 0.750 (0.703)\n",
      "Epoch: [17][5/5]\tTime 0.099 (0.135)\tData 0.060 (0.106)\tLoss 0.9567 (0.7228)\tAcc 0.444 (0.671)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.281 (0.281)\tData 0.250 (0.250)\tLoss 0.3971 (0.3971)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/9]\tTime 0.112 (0.197)\tData 0.091 (0.171)\tLoss 1.1648 (0.7810)\tAcc 0.438 (0.688)\n",
      "Epoch: [17][3/9]\tTime 0.075 (0.156)\tData 0.054 (0.132)\tLoss 0.6816 (0.7478)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.112)\tLoss 0.7971 (0.7601)\tAcc 0.625 (0.672)\n",
      "Epoch: [17][5/9]\tTime 0.076 (0.124)\tData 0.056 (0.101)\tLoss 0.8360 (0.7753)\tAcc 0.625 (0.663)\n",
      "Epoch: [17][6/9]\tTime 0.074 (0.115)\tData 0.054 (0.093)\tLoss 0.3479 (0.7041)\tAcc 1.000 (0.719)\n",
      "Epoch: [17][7/9]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.6910 (0.7022)\tAcc 0.688 (0.714)\n",
      "Epoch: [17][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.083)\tLoss 0.9305 (0.7307)\tAcc 0.562 (0.695)\n",
      "Epoch: [17][9/9]\tTime 0.080 (0.102)\tData 0.060 (0.081)\tLoss 0.2708 (0.7237)\tAcc 1.000 (0.700)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.427 (0.427)\tData 0.400 (0.400)\tLoss 1.0415 (1.0415)\tAcc 0.500 (0.500)\n",
      "Epoch: [18][2/5]\tTime 0.075 (0.251)\tData 0.050 (0.225)\tLoss 0.4334 (0.7374)\tAcc 0.875 (0.688)\n",
      "Epoch: [18][3/5]\tTime 0.076 (0.193)\tData 0.052 (0.167)\tLoss 0.6422 (0.7057)\tAcc 0.750 (0.708)\n",
      "Epoch: [18][4/5]\tTime 0.077 (0.164)\tData 0.053 (0.139)\tLoss 0.5539 (0.6677)\tAcc 0.688 (0.703)\n",
      "Epoch: [18][5/5]\tTime 0.082 (0.147)\tData 0.057 (0.123)\tLoss 1.1663 (0.7292)\tAcc 0.556 (0.685)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.370 (0.370)\tData 0.346 (0.346)\tLoss 0.2294 (0.2294)\tAcc 1.000 (1.000)\n",
      "Epoch: [18][2/9]\tTime 0.070 (0.220)\tData 0.050 (0.198)\tLoss 1.1090 (0.6692)\tAcc 0.438 (0.719)\n",
      "Epoch: [18][3/9]\tTime 0.073 (0.171)\tData 0.052 (0.149)\tLoss 0.6825 (0.6736)\tAcc 0.625 (0.688)\n",
      "Epoch: [18][4/9]\tTime 0.075 (0.147)\tData 0.052 (0.125)\tLoss 0.6399 (0.6652)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][5/9]\tTime 0.072 (0.132)\tData 0.052 (0.110)\tLoss 0.9596 (0.7241)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][6/9]\tTime 0.080 (0.123)\tData 0.060 (0.102)\tLoss 0.1294 (0.6250)\tAcc 1.000 (0.740)\n",
      "Epoch: [18][7/9]\tTime 0.077 (0.117)\tData 0.057 (0.096)\tLoss 0.3999 (0.5928)\tAcc 0.875 (0.759)\n",
      "Epoch: [18][8/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 1.1490 (0.6623)\tAcc 0.500 (0.727)\n",
      "Epoch: [18][9/9]\tTime 0.074 (0.108)\tData 0.055 (0.087)\tLoss 0.2765 (0.6564)\tAcc 1.000 (0.731)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.412 (0.412)\tData 0.380 (0.380)\tLoss 0.9833 (0.9833)\tAcc 0.625 (0.625)\n",
      "Epoch: [19][2/5]\tTime 0.075 (0.243)\tData 0.049 (0.215)\tLoss 0.6500 (0.8167)\tAcc 0.812 (0.719)\n",
      "Epoch: [19][3/5]\tTime 0.080 (0.189)\tData 0.056 (0.162)\tLoss 0.7234 (0.7856)\tAcc 0.562 (0.667)\n",
      "Epoch: [19][4/5]\tTime 0.085 (0.163)\tData 0.061 (0.136)\tLoss 0.7626 (0.7798)\tAcc 0.688 (0.672)\n",
      "Epoch: [19][5/5]\tTime 0.082 (0.147)\tData 0.057 (0.120)\tLoss 0.7705 (0.7787)\tAcc 0.778 (0.685)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.323 (0.323)\tData 0.286 (0.286)\tLoss 0.4693 (0.4693)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/9]\tTime 0.061 (0.192)\tData 0.039 (0.162)\tLoss 1.0181 (0.7437)\tAcc 0.438 (0.688)\n",
      "Epoch: [19][3/9]\tTime 0.075 (0.153)\tData 0.052 (0.126)\tLoss 0.6678 (0.7184)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.073 (0.133)\tData 0.052 (0.107)\tLoss 0.6788 (0.7085)\tAcc 0.688 (0.703)\n",
      "Epoch: [19][5/9]\tTime 0.077 (0.122)\tData 0.056 (0.097)\tLoss 0.7362 (0.7140)\tAcc 0.750 (0.713)\n",
      "Epoch: [19][6/9]\tTime 0.081 (0.115)\tData 0.061 (0.091)\tLoss 0.2538 (0.6373)\tAcc 1.000 (0.760)\n",
      "Epoch: [19][7/9]\tTime 0.077 (0.110)\tData 0.056 (0.086)\tLoss 0.5395 (0.6234)\tAcc 0.875 (0.777)\n",
      "Epoch: [19][8/9]\tTime 0.081 (0.106)\tData 0.060 (0.083)\tLoss 1.0518 (0.6769)\tAcc 0.500 (0.742)\n",
      "Epoch: [19][9/9]\tTime 0.076 (0.103)\tData 0.056 (0.080)\tLoss 0.4150 (0.6729)\tAcc 1.000 (0.746)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.273 (0.273)\tData 0.244 (0.244)\tLoss 0.6749 (0.6749)\tAcc 0.750 (0.750)\n",
      "Epoch: [20][2/5]\tTime 0.074 (0.174)\tData 0.049 (0.147)\tLoss 0.7980 (0.7365)\tAcc 0.625 (0.688)\n",
      "Epoch: [20][3/5]\tTime 0.076 (0.141)\tData 0.053 (0.116)\tLoss 0.9062 (0.7930)\tAcc 0.562 (0.646)\n",
      "Epoch: [20][4/5]\tTime 0.077 (0.125)\tData 0.054 (0.100)\tLoss 0.3834 (0.6906)\tAcc 1.000 (0.734)\n",
      "Epoch: [20][5/5]\tTime 0.082 (0.117)\tData 0.058 (0.092)\tLoss 0.9007 (0.7165)\tAcc 0.667 (0.726)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.379 (0.379)\tData 0.355 (0.355)\tLoss 0.3650 (0.3650)\tAcc 0.875 (0.875)\n",
      "Epoch: [20][2/9]\tTime 0.072 (0.225)\tData 0.050 (0.202)\tLoss 1.2238 (0.7944)\tAcc 0.438 (0.656)\n",
      "Epoch: [20][3/9]\tTime 0.075 (0.175)\tData 0.052 (0.152)\tLoss 0.7150 (0.7679)\tAcc 0.750 (0.688)\n",
      "Epoch: [20][4/9]\tTime 0.075 (0.150)\tData 0.053 (0.128)\tLoss 0.7317 (0.7589)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][5/9]\tTime 0.078 (0.136)\tData 0.058 (0.114)\tLoss 0.7249 (0.7521)\tAcc 0.750 (0.700)\n",
      "Epoch: [20][6/9]\tTime 0.074 (0.125)\tData 0.054 (0.104)\tLoss 0.2364 (0.6661)\tAcc 1.000 (0.750)\n",
      "Epoch: [20][7/9]\tTime 0.081 (0.119)\tData 0.060 (0.097)\tLoss 0.7103 (0.6724)\tAcc 0.750 (0.750)\n",
      "Epoch: [20][8/9]\tTime 0.079 (0.114)\tData 0.059 (0.093)\tLoss 1.1066 (0.7267)\tAcc 0.500 (0.719)\n",
      "Epoch: [20][9/9]\tTime 0.075 (0.110)\tData 0.054 (0.088)\tLoss 0.0989 (0.7171)\tAcc 1.000 (0.723)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.334 (0.334)\tData 0.302 (0.302)\tLoss 0.6664 (0.6664)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][2/5]\tTime 0.070 (0.202)\tData 0.047 (0.174)\tLoss 0.7918 (0.7291)\tAcc 0.625 (0.688)\n",
      "Epoch: [21][3/5]\tTime 0.077 (0.160)\tData 0.053 (0.134)\tLoss 0.8348 (0.7643)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][4/5]\tTime 0.076 (0.139)\tData 0.053 (0.114)\tLoss 0.8470 (0.7850)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][5/5]\tTime 0.080 (0.127)\tData 0.057 (0.102)\tLoss 0.7930 (0.7860)\tAcc 0.556 (0.671)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.295 (0.295)\tData 0.264 (0.264)\tLoss 0.4908 (0.4908)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.079 (0.187)\tData 0.056 (0.160)\tLoss 0.8381 (0.6645)\tAcc 0.500 (0.719)\n",
      "Epoch: [21][3/9]\tTime 0.083 (0.152)\tData 0.062 (0.127)\tLoss 0.6759 (0.6683)\tAcc 0.750 (0.729)\n",
      "Epoch: [21][4/9]\tTime 0.073 (0.132)\tData 0.052 (0.108)\tLoss 0.5961 (0.6502)\tAcc 0.812 (0.750)\n",
      "Epoch: [21][5/9]\tTime 0.075 (0.121)\tData 0.055 (0.098)\tLoss 0.9441 (0.7090)\tAcc 0.625 (0.725)\n",
      "Epoch: [21][6/9]\tTime 0.074 (0.113)\tData 0.053 (0.090)\tLoss 0.2255 (0.6284)\tAcc 1.000 (0.771)\n",
      "Epoch: [21][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.085)\tLoss 0.6464 (0.6310)\tAcc 0.750 (0.768)\n",
      "Epoch: [21][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 1.0783 (0.6869)\tAcc 0.500 (0.734)\n",
      "Epoch: [21][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.1482 (0.6786)\tAcc 1.000 (0.738)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.326 (0.326)\tData 0.297 (0.297)\tLoss 0.7358 (0.7358)\tAcc 0.812 (0.812)\n",
      "Epoch: [22][2/5]\tTime 0.077 (0.202)\tData 0.052 (0.175)\tLoss 0.9471 (0.8415)\tAcc 0.562 (0.688)\n",
      "Epoch: [22][3/5]\tTime 0.078 (0.160)\tData 0.053 (0.134)\tLoss 0.7258 (0.8029)\tAcc 0.562 (0.646)\n",
      "Epoch: [22][4/5]\tTime 0.081 (0.141)\tData 0.056 (0.115)\tLoss 0.8111 (0.8050)\tAcc 0.750 (0.672)\n",
      "Epoch: [22][5/5]\tTime 0.080 (0.128)\tData 0.055 (0.103)\tLoss 0.7298 (0.7957)\tAcc 0.667 (0.671)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.386 (0.386)\tData 0.361 (0.361)\tLoss 0.4415 (0.4415)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.070 (0.228)\tData 0.049 (0.205)\tLoss 0.8493 (0.6454)\tAcc 0.562 (0.750)\n",
      "Epoch: [22][3/9]\tTime 0.073 (0.176)\tData 0.052 (0.154)\tLoss 0.6885 (0.6598)\tAcc 0.688 (0.729)\n",
      "Epoch: [22][4/9]\tTime 0.074 (0.151)\tData 0.053 (0.129)\tLoss 0.6836 (0.6657)\tAcc 0.875 (0.766)\n",
      "Epoch: [22][5/9]\tTime 0.072 (0.135)\tData 0.053 (0.113)\tLoss 0.8987 (0.7123)\tAcc 0.625 (0.738)\n",
      "Epoch: [22][6/9]\tTime 0.075 (0.125)\tData 0.055 (0.104)\tLoss 0.4520 (0.6689)\tAcc 1.000 (0.781)\n",
      "Epoch: [22][7/9]\tTime 0.073 (0.118)\tData 0.053 (0.096)\tLoss 0.8768 (0.6986)\tAcc 0.688 (0.768)\n",
      "Epoch: [22][8/9]\tTime 0.074 (0.112)\tData 0.055 (0.091)\tLoss 1.0852 (0.7469)\tAcc 0.438 (0.727)\n",
      "Epoch: [22][9/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 0.4409 (0.7422)\tAcc 1.000 (0.731)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.350 (0.350)\tData 0.319 (0.319)\tLoss 1.1331 (1.1331)\tAcc 0.500 (0.500)\n",
      "Epoch: [23][2/5]\tTime 0.071 (0.211)\tData 0.047 (0.183)\tLoss 0.7707 (0.9519)\tAcc 0.625 (0.562)\n",
      "Epoch: [23][3/5]\tTime 0.078 (0.166)\tData 0.053 (0.139)\tLoss 0.8264 (0.9101)\tAcc 0.625 (0.583)\n",
      "Epoch: [23][4/5]\tTime 0.076 (0.144)\tData 0.052 (0.118)\tLoss 0.5119 (0.8105)\tAcc 0.812 (0.641)\n",
      "Epoch: [23][5/5]\tTime 0.080 (0.131)\tData 0.056 (0.105)\tLoss 0.4489 (0.7659)\tAcc 0.889 (0.671)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.372 (0.372)\tData 0.348 (0.348)\tLoss 0.2736 (0.2736)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.071 (0.222)\tData 0.050 (0.199)\tLoss 0.9546 (0.6141)\tAcc 0.438 (0.688)\n",
      "Epoch: [23][3/9]\tTime 0.074 (0.172)\tData 0.052 (0.150)\tLoss 0.6237 (0.6173)\tAcc 0.625 (0.667)\n",
      "Epoch: [23][4/9]\tTime 0.071 (0.147)\tData 0.051 (0.125)\tLoss 0.7159 (0.6420)\tAcc 0.688 (0.672)\n",
      "Epoch: [23][5/9]\tTime 0.073 (0.132)\tData 0.053 (0.111)\tLoss 0.7685 (0.6673)\tAcc 0.750 (0.688)\n",
      "Epoch: [23][6/9]\tTime 0.079 (0.123)\tData 0.059 (0.102)\tLoss 0.2733 (0.6016)\tAcc 1.000 (0.740)\n",
      "Epoch: [23][7/9]\tTime 0.075 (0.117)\tData 0.054 (0.095)\tLoss 0.5471 (0.5938)\tAcc 0.938 (0.768)\n",
      "Epoch: [23][8/9]\tTime 0.073 (0.111)\tData 0.053 (0.090)\tLoss 1.1112 (0.6585)\tAcc 0.500 (0.734)\n",
      "Epoch: [23][9/9]\tTime 0.075 (0.107)\tData 0.054 (0.086)\tLoss 0.1225 (0.6503)\tAcc 1.000 (0.738)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.299 (0.299)\tData 0.269 (0.269)\tLoss 0.8727 (0.8727)\tAcc 0.625 (0.625)\n",
      "Epoch: [24][2/5]\tTime 0.073 (0.186)\tData 0.049 (0.159)\tLoss 0.9976 (0.9351)\tAcc 0.625 (0.625)\n",
      "Epoch: [24][3/5]\tTime 0.077 (0.149)\tData 0.053 (0.124)\tLoss 0.5375 (0.8026)\tAcc 0.750 (0.667)\n",
      "Epoch: [24][4/5]\tTime 0.076 (0.131)\tData 0.053 (0.106)\tLoss 0.6795 (0.7718)\tAcc 0.688 (0.672)\n",
      "Epoch: [24][5/5]\tTime 0.079 (0.121)\tData 0.056 (0.096)\tLoss 1.1219 (0.8150)\tAcc 0.778 (0.685)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.323 (0.323)\tData 0.294 (0.294)\tLoss 0.3274 (0.3274)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/9]\tTime 0.071 (0.197)\tData 0.048 (0.171)\tLoss 1.0564 (0.6919)\tAcc 0.438 (0.688)\n",
      "Epoch: [24][3/9]\tTime 0.080 (0.158)\tData 0.058 (0.133)\tLoss 0.5988 (0.6609)\tAcc 0.625 (0.667)\n",
      "Epoch: [24][4/9]\tTime 0.077 (0.138)\tData 0.053 (0.113)\tLoss 0.5894 (0.6430)\tAcc 0.625 (0.656)\n",
      "Epoch: [24][5/9]\tTime 0.075 (0.125)\tData 0.054 (0.101)\tLoss 0.9012 (0.6947)\tAcc 0.750 (0.675)\n",
      "Epoch: [24][6/9]\tTime 0.079 (0.118)\tData 0.059 (0.094)\tLoss 0.2739 (0.6245)\tAcc 1.000 (0.729)\n",
      "Epoch: [24][7/9]\tTime 0.078 (0.112)\tData 0.057 (0.089)\tLoss 0.5674 (0.6164)\tAcc 0.750 (0.732)\n",
      "Epoch: [24][8/9]\tTime 0.075 (0.107)\tData 0.055 (0.085)\tLoss 1.0885 (0.6754)\tAcc 0.625 (0.719)\n",
      "Epoch: [24][9/9]\tTime 0.080 (0.104)\tData 0.060 (0.082)\tLoss 0.2454 (0.6688)\tAcc 1.000 (0.723)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.358 (0.358)\tData 0.330 (0.330)\tLoss 0.8921 (0.8921)\tAcc 0.625 (0.625)\n",
      "Epoch: [25][2/5]\tTime 0.074 (0.216)\tData 0.050 (0.190)\tLoss 0.9233 (0.9077)\tAcc 0.688 (0.656)\n",
      "Epoch: [25][3/5]\tTime 0.079 (0.170)\tData 0.055 (0.145)\tLoss 0.7922 (0.8692)\tAcc 0.688 (0.667)\n",
      "Epoch: [25][4/5]\tTime 0.076 (0.147)\tData 0.053 (0.122)\tLoss 0.5601 (0.7919)\tAcc 0.812 (0.703)\n",
      "Epoch: [25][5/5]\tTime 0.080 (0.133)\tData 0.057 (0.109)\tLoss 0.7064 (0.7814)\tAcc 0.667 (0.699)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.324 (0.324)\tData 0.300 (0.300)\tLoss 0.4511 (0.4511)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.071 (0.198)\tData 0.050 (0.175)\tLoss 0.9663 (0.7087)\tAcc 0.438 (0.688)\n",
      "Epoch: [25][3/9]\tTime 0.073 (0.156)\tData 0.052 (0.134)\tLoss 0.7977 (0.7384)\tAcc 0.812 (0.729)\n",
      "Epoch: [25][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.114)\tLoss 0.7587 (0.7435)\tAcc 0.625 (0.703)\n",
      "Epoch: [25][5/9]\tTime 0.073 (0.123)\tData 0.053 (0.102)\tLoss 0.8650 (0.7678)\tAcc 0.688 (0.700)\n",
      "Epoch: [25][6/9]\tTime 0.075 (0.115)\tData 0.055 (0.094)\tLoss 0.4568 (0.7159)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.073 (0.109)\tData 0.053 (0.088)\tLoss 0.6539 (0.7071)\tAcc 0.812 (0.759)\n",
      "Epoch: [25][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.084)\tLoss 0.8822 (0.7290)\tAcc 0.625 (0.742)\n",
      "Epoch: [25][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.081)\tLoss 0.3508 (0.7232)\tAcc 1.000 (0.746)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.327 (0.327)\tData 0.300 (0.300)\tLoss 0.8665 (0.8665)\tAcc 0.625 (0.625)\n",
      "Epoch: [26][2/5]\tTime 0.074 (0.201)\tData 0.050 (0.175)\tLoss 0.7991 (0.8328)\tAcc 0.625 (0.625)\n",
      "Epoch: [26][3/5]\tTime 0.077 (0.160)\tData 0.053 (0.134)\tLoss 0.6181 (0.7612)\tAcc 0.750 (0.667)\n",
      "Epoch: [26][4/5]\tTime 0.075 (0.138)\tData 0.052 (0.114)\tLoss 0.8528 (0.7841)\tAcc 0.688 (0.672)\n",
      "Epoch: [26][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.102)\tLoss 0.9936 (0.8099)\tAcc 0.556 (0.658)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.356 (0.356)\tData 0.333 (0.333)\tLoss 0.2318 (0.2318)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/9]\tTime 0.071 (0.214)\tData 0.050 (0.192)\tLoss 1.0428 (0.6373)\tAcc 0.500 (0.719)\n",
      "Epoch: [26][3/9]\tTime 0.073 (0.167)\tData 0.053 (0.145)\tLoss 0.4934 (0.5893)\tAcc 0.688 (0.708)\n",
      "Epoch: [26][4/9]\tTime 0.075 (0.144)\tData 0.053 (0.122)\tLoss 0.6520 (0.6050)\tAcc 0.750 (0.719)\n",
      "Epoch: [26][5/9]\tTime 0.071 (0.129)\tData 0.052 (0.108)\tLoss 0.8469 (0.6534)\tAcc 0.688 (0.713)\n",
      "Epoch: [26][6/9]\tTime 0.074 (0.120)\tData 0.054 (0.099)\tLoss 0.2469 (0.5856)\tAcc 1.000 (0.760)\n",
      "Epoch: [26][7/9]\tTime 0.072 (0.113)\tData 0.053 (0.092)\tLoss 0.5844 (0.5855)\tAcc 0.812 (0.768)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.088)\tLoss 1.2313 (0.6662)\tAcc 0.500 (0.734)\n",
      "Epoch: [26][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 0.2529 (0.6598)\tAcc 1.000 (0.738)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.383 (0.383)\tData 0.356 (0.356)\tLoss 0.5548 (0.5548)\tAcc 0.812 (0.812)\n",
      "Epoch: [27][2/5]\tTime 0.074 (0.229)\tData 0.051 (0.204)\tLoss 0.4856 (0.5202)\tAcc 0.812 (0.812)\n",
      "Epoch: [27][3/5]\tTime 0.076 (0.178)\tData 0.053 (0.154)\tLoss 0.8784 (0.6396)\tAcc 0.625 (0.750)\n",
      "Epoch: [27][4/5]\tTime 0.076 (0.153)\tData 0.054 (0.129)\tLoss 0.9907 (0.7274)\tAcc 0.562 (0.703)\n",
      "Epoch: [27][5/5]\tTime 0.080 (0.138)\tData 0.056 (0.114)\tLoss 1.0290 (0.7645)\tAcc 0.556 (0.685)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.340 (0.340)\tData 0.317 (0.317)\tLoss 0.3091 (0.3091)\tAcc 0.938 (0.938)\n",
      "Epoch: [27][2/9]\tTime 0.071 (0.206)\tData 0.051 (0.184)\tLoss 0.9801 (0.6446)\tAcc 0.438 (0.688)\n",
      "Epoch: [27][3/9]\tTime 0.073 (0.162)\tData 0.053 (0.140)\tLoss 0.6896 (0.6596)\tAcc 0.625 (0.667)\n",
      "Epoch: [27][4/9]\tTime 0.072 (0.139)\tData 0.052 (0.118)\tLoss 0.7029 (0.6704)\tAcc 0.750 (0.688)\n",
      "Epoch: [27][5/9]\tTime 0.074 (0.126)\tData 0.054 (0.105)\tLoss 0.8550 (0.7073)\tAcc 0.688 (0.688)\n",
      "Epoch: [27][6/9]\tTime 0.074 (0.118)\tData 0.054 (0.097)\tLoss 0.1928 (0.6216)\tAcc 1.000 (0.740)\n",
      "Epoch: [27][7/9]\tTime 0.073 (0.111)\tData 0.053 (0.091)\tLoss 0.4418 (0.5959)\tAcc 0.875 (0.759)\n",
      "Epoch: [27][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.086)\tLoss 1.2289 (0.6750)\tAcc 0.438 (0.719)\n",
      "Epoch: [27][9/9]\tTime 0.074 (0.103)\tData 0.054 (0.083)\tLoss 0.1934 (0.6676)\tAcc 1.000 (0.723)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.277 (0.277)\tData 0.247 (0.247)\tLoss 1.2340 (1.2340)\tAcc 0.438 (0.438)\n",
      "Epoch: [28][2/5]\tTime 0.104 (0.191)\tData 0.078 (0.163)\tLoss 0.5511 (0.8926)\tAcc 0.812 (0.625)\n",
      "Epoch: [28][3/5]\tTime 0.075 (0.152)\tData 0.052 (0.126)\tLoss 0.8402 (0.8751)\tAcc 0.688 (0.646)\n",
      "Epoch: [28][4/5]\tTime 0.077 (0.133)\tData 0.053 (0.108)\tLoss 0.7178 (0.8358)\tAcc 0.750 (0.672)\n",
      "Epoch: [28][5/5]\tTime 0.079 (0.123)\tData 0.055 (0.097)\tLoss 0.9593 (0.8510)\tAcc 0.556 (0.658)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.403 (0.403)\tData 0.380 (0.380)\tLoss 0.5717 (0.5717)\tAcc 0.875 (0.875)\n",
      "Epoch: [28][2/9]\tTime 0.071 (0.237)\tData 0.050 (0.215)\tLoss 0.8383 (0.7050)\tAcc 0.750 (0.812)\n",
      "Epoch: [28][3/9]\tTime 0.074 (0.183)\tData 0.053 (0.161)\tLoss 0.7964 (0.7355)\tAcc 0.625 (0.750)\n",
      "Epoch: [28][4/9]\tTime 0.071 (0.155)\tData 0.052 (0.134)\tLoss 0.6947 (0.7253)\tAcc 0.875 (0.781)\n",
      "Epoch: [28][5/9]\tTime 0.074 (0.139)\tData 0.054 (0.118)\tLoss 0.8459 (0.7494)\tAcc 0.688 (0.762)\n",
      "Epoch: [28][6/9]\tTime 0.075 (0.128)\tData 0.054 (0.107)\tLoss 0.4762 (0.7039)\tAcc 1.000 (0.802)\n",
      "Epoch: [28][7/9]\tTime 0.075 (0.120)\tData 0.055 (0.100)\tLoss 0.6576 (0.6973)\tAcc 0.875 (0.813)\n",
      "Epoch: [28][8/9]\tTime 0.075 (0.115)\tData 0.055 (0.094)\tLoss 0.9403 (0.7277)\tAcc 0.562 (0.781)\n",
      "Epoch: [28][9/9]\tTime 0.074 (0.110)\tData 0.054 (0.090)\tLoss 0.4463 (0.7233)\tAcc 1.000 (0.785)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.309 (0.309)\tData 0.280 (0.280)\tLoss 0.7846 (0.7846)\tAcc 0.812 (0.812)\n",
      "Epoch: [29][2/5]\tTime 0.073 (0.191)\tData 0.049 (0.164)\tLoss 0.7882 (0.7864)\tAcc 0.750 (0.781)\n",
      "Epoch: [29][3/5]\tTime 0.076 (0.152)\tData 0.052 (0.127)\tLoss 0.7914 (0.7881)\tAcc 0.688 (0.750)\n",
      "Epoch: [29][4/5]\tTime 0.076 (0.133)\tData 0.053 (0.108)\tLoss 0.9549 (0.8298)\tAcc 0.562 (0.703)\n",
      "Epoch: [29][5/5]\tTime 0.078 (0.122)\tData 0.055 (0.098)\tLoss 0.6070 (0.8023)\tAcc 0.778 (0.712)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.342 (0.342)\tData 0.317 (0.317)\tLoss 0.3704 (0.3704)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.071 (0.206)\tData 0.050 (0.183)\tLoss 0.9769 (0.6737)\tAcc 0.500 (0.719)\n",
      "Epoch: [29][3/9]\tTime 0.073 (0.162)\tData 0.052 (0.140)\tLoss 0.6356 (0.6610)\tAcc 0.688 (0.708)\n",
      "Epoch: [29][4/9]\tTime 0.074 (0.140)\tData 0.053 (0.118)\tLoss 0.6761 (0.6648)\tAcc 0.688 (0.703)\n",
      "Epoch: [29][5/9]\tTime 0.073 (0.127)\tData 0.053 (0.105)\tLoss 0.8608 (0.7040)\tAcc 0.688 (0.700)\n",
      "Epoch: [29][6/9]\tTime 0.074 (0.118)\tData 0.053 (0.096)\tLoss 0.3131 (0.6388)\tAcc 1.000 (0.750)\n",
      "Epoch: [29][7/9]\tTime 0.072 (0.111)\tData 0.053 (0.090)\tLoss 0.5352 (0.6240)\tAcc 0.938 (0.777)\n",
      "Epoch: [29][8/9]\tTime 0.075 (0.107)\tData 0.055 (0.086)\tLoss 1.0009 (0.6711)\tAcc 0.500 (0.742)\n",
      "Epoch: [29][9/9]\tTime 0.074 (0.103)\tData 0.054 (0.082)\tLoss 0.2735 (0.6650)\tAcc 1.000 (0.746)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.318 (0.318)\tData 0.279 (0.279)\tLoss 0.8261 (0.8261)\tAcc 0.625 (0.625)\n",
      "Epoch: [30][2/5]\tTime 0.064 (0.191)\tData 0.039 (0.159)\tLoss 0.6725 (0.7493)\tAcc 0.750 (0.688)\n",
      "Epoch: [30][3/5]\tTime 0.075 (0.152)\tData 0.052 (0.123)\tLoss 0.7092 (0.7360)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][4/5]\tTime 0.077 (0.133)\tData 0.053 (0.106)\tLoss 0.7855 (0.7483)\tAcc 0.625 (0.672)\n",
      "Epoch: [30][5/5]\tTime 0.080 (0.123)\tData 0.056 (0.096)\tLoss 0.3552 (0.6999)\tAcc 0.889 (0.699)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.319 (0.319)\tData 0.295 (0.295)\tLoss 0.2626 (0.2626)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/9]\tTime 0.077 (0.198)\tData 0.055 (0.175)\tLoss 1.0437 (0.6531)\tAcc 0.750 (0.844)\n",
      "Epoch: [30][3/9]\tTime 0.075 (0.157)\tData 0.053 (0.134)\tLoss 0.4106 (0.5723)\tAcc 0.688 (0.792)\n",
      "Epoch: [30][4/9]\tTime 0.074 (0.136)\tData 0.052 (0.113)\tLoss 0.5489 (0.5664)\tAcc 0.812 (0.797)\n",
      "Epoch: [30][5/9]\tTime 0.073 (0.123)\tData 0.053 (0.101)\tLoss 0.9024 (0.6336)\tAcc 0.625 (0.762)\n",
      "Epoch: [30][6/9]\tTime 0.074 (0.115)\tData 0.054 (0.093)\tLoss 0.1388 (0.5512)\tAcc 1.000 (0.802)\n",
      "Epoch: [30][7/9]\tTime 0.072 (0.109)\tData 0.053 (0.088)\tLoss 0.6434 (0.5643)\tAcc 0.750 (0.795)\n",
      "Epoch: [30][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 1.0971 (0.6309)\tAcc 0.500 (0.758)\n",
      "Epoch: [30][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.0690 (0.6223)\tAcc 1.000 (0.762)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.341 (0.341)\tData 0.312 (0.312)\tLoss 0.3061 (0.3061)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/5]\tTime 0.073 (0.207)\tData 0.049 (0.181)\tLoss 0.7207 (0.5134)\tAcc 0.750 (0.844)\n",
      "Epoch: [31][3/5]\tTime 0.077 (0.163)\tData 0.053 (0.138)\tLoss 1.1763 (0.7344)\tAcc 0.562 (0.750)\n",
      "Epoch: [31][4/5]\tTime 0.076 (0.142)\tData 0.054 (0.117)\tLoss 1.3103 (0.8784)\tAcc 0.562 (0.703)\n",
      "Epoch: [31][5/5]\tTime 0.078 (0.129)\tData 0.055 (0.105)\tLoss 0.8387 (0.8735)\tAcc 0.556 (0.685)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.330 (0.330)\tData 0.306 (0.306)\tLoss 0.4655 (0.4655)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.072 (0.201)\tData 0.051 (0.178)\tLoss 0.9803 (0.7229)\tAcc 0.688 (0.812)\n",
      "Epoch: [31][3/9]\tTime 0.074 (0.158)\tData 0.053 (0.137)\tLoss 0.7388 (0.7282)\tAcc 0.562 (0.729)\n",
      "Epoch: [31][4/9]\tTime 0.075 (0.137)\tData 0.053 (0.116)\tLoss 0.6598 (0.7111)\tAcc 0.812 (0.750)\n",
      "Epoch: [31][5/9]\tTime 0.071 (0.124)\tData 0.051 (0.103)\tLoss 1.2554 (0.8200)\tAcc 0.500 (0.700)\n",
      "Epoch: [31][6/9]\tTime 0.075 (0.116)\tData 0.055 (0.095)\tLoss 0.5197 (0.7699)\tAcc 0.875 (0.729)\n",
      "Epoch: [31][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.9943 (0.8020)\tAcc 0.688 (0.723)\n",
      "Epoch: [31][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.085)\tLoss 1.2138 (0.8535)\tAcc 0.375 (0.680)\n",
      "Epoch: [31][9/9]\tTime 0.074 (0.102)\tData 0.054 (0.081)\tLoss 0.5687 (0.8491)\tAcc 1.000 (0.685)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.349 (0.349)\tData 0.316 (0.316)\tLoss 0.8371 (0.8371)\tAcc 0.625 (0.625)\n",
      "Epoch: [32][2/5]\tTime 0.069 (0.209)\tData 0.046 (0.181)\tLoss 0.7866 (0.8118)\tAcc 0.750 (0.688)\n",
      "Epoch: [32][3/5]\tTime 0.076 (0.165)\tData 0.054 (0.139)\tLoss 0.6945 (0.7727)\tAcc 0.750 (0.708)\n",
      "Epoch: [32][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.117)\tLoss 0.7824 (0.7751)\tAcc 0.688 (0.703)\n",
      "Epoch: [32][5/5]\tTime 0.080 (0.130)\tData 0.057 (0.105)\tLoss 1.1956 (0.8270)\tAcc 0.444 (0.671)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.374 (0.374)\tData 0.344 (0.344)\tLoss 0.2593 (0.2593)\tAcc 0.938 (0.938)\n",
      "Epoch: [32][2/9]\tTime 0.066 (0.220)\tData 0.045 (0.195)\tLoss 1.2817 (0.7705)\tAcc 0.438 (0.688)\n",
      "Epoch: [32][3/9]\tTime 0.074 (0.171)\tData 0.053 (0.147)\tLoss 0.6835 (0.7415)\tAcc 0.688 (0.688)\n",
      "Epoch: [32][4/9]\tTime 0.071 (0.146)\tData 0.052 (0.123)\tLoss 0.7519 (0.7441)\tAcc 0.625 (0.672)\n",
      "Epoch: [32][5/9]\tTime 0.074 (0.132)\tData 0.055 (0.110)\tLoss 0.9591 (0.7871)\tAcc 0.750 (0.688)\n",
      "Epoch: [32][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.101)\tLoss 0.1226 (0.6764)\tAcc 1.000 (0.740)\n",
      "Epoch: [32][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.4019 (0.6371)\tAcc 0.875 (0.759)\n",
      "Epoch: [32][8/9]\tTime 0.075 (0.110)\tData 0.056 (0.089)\tLoss 1.3171 (0.7221)\tAcc 0.562 (0.734)\n",
      "Epoch: [32][9/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 0.0707 (0.7121)\tAcc 1.000 (0.738)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.294 (0.294)\tData 0.266 (0.266)\tLoss 1.0500 (1.0500)\tAcc 0.562 (0.562)\n",
      "Epoch: [33][2/5]\tTime 0.074 (0.184)\tData 0.050 (0.158)\tLoss 0.6124 (0.8312)\tAcc 0.812 (0.688)\n",
      "Epoch: [33][3/5]\tTime 0.077 (0.148)\tData 0.053 (0.123)\tLoss 0.6398 (0.7674)\tAcc 0.750 (0.708)\n",
      "Epoch: [33][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.105)\tLoss 0.8742 (0.7941)\tAcc 0.625 (0.688)\n",
      "Epoch: [33][5/5]\tTime 0.078 (0.120)\tData 0.055 (0.095)\tLoss 0.4848 (0.7559)\tAcc 1.000 (0.726)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.345 (0.345)\tData 0.321 (0.321)\tLoss 0.4898 (0.4898)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.072 (0.208)\tData 0.050 (0.186)\tLoss 1.1896 (0.8397)\tAcc 0.438 (0.688)\n",
      "Epoch: [33][3/9]\tTime 0.074 (0.164)\tData 0.053 (0.142)\tLoss 0.6026 (0.7607)\tAcc 0.875 (0.750)\n",
      "Epoch: [33][4/9]\tTime 0.074 (0.141)\tData 0.053 (0.120)\tLoss 0.8366 (0.7797)\tAcc 0.688 (0.734)\n",
      "Epoch: [33][5/9]\tTime 0.074 (0.128)\tData 0.054 (0.106)\tLoss 0.7469 (0.7731)\tAcc 0.750 (0.738)\n",
      "Epoch: [33][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.098)\tLoss 0.4108 (0.7127)\tAcc 1.000 (0.781)\n",
      "Epoch: [33][7/9]\tTime 0.072 (0.112)\tData 0.053 (0.091)\tLoss 0.7180 (0.7135)\tAcc 0.812 (0.786)\n",
      "Epoch: [33][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.087)\tLoss 1.0036 (0.7497)\tAcc 0.438 (0.742)\n",
      "Epoch: [33][9/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 0.2124 (0.7415)\tAcc 1.000 (0.746)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.313 (0.313)\tData 0.281 (0.281)\tLoss 0.8411 (0.8411)\tAcc 0.688 (0.688)\n",
      "Epoch: [34][2/5]\tTime 0.070 (0.192)\tData 0.046 (0.164)\tLoss 0.7552 (0.7981)\tAcc 0.750 (0.719)\n",
      "Epoch: [34][3/5]\tTime 0.077 (0.153)\tData 0.053 (0.127)\tLoss 0.9297 (0.8420)\tAcc 0.562 (0.667)\n",
      "Epoch: [34][4/5]\tTime 0.077 (0.134)\tData 0.054 (0.109)\tLoss 0.5859 (0.7780)\tAcc 0.875 (0.719)\n",
      "Epoch: [34][5/5]\tTime 0.078 (0.123)\tData 0.056 (0.098)\tLoss 0.6980 (0.7681)\tAcc 0.778 (0.726)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.346 (0.346)\tData 0.323 (0.323)\tLoss 0.3511 (0.3511)\tAcc 0.938 (0.938)\n",
      "Epoch: [34][2/9]\tTime 0.072 (0.209)\tData 0.051 (0.187)\tLoss 1.1273 (0.7392)\tAcc 0.438 (0.688)\n",
      "Epoch: [34][3/9]\tTime 0.073 (0.164)\tData 0.053 (0.142)\tLoss 0.5363 (0.6715)\tAcc 0.812 (0.729)\n",
      "Epoch: [34][4/9]\tTime 0.076 (0.142)\tData 0.053 (0.120)\tLoss 0.7080 (0.6806)\tAcc 0.688 (0.719)\n",
      "Epoch: [34][5/9]\tTime 0.071 (0.128)\tData 0.051 (0.106)\tLoss 0.9003 (0.7246)\tAcc 0.625 (0.700)\n",
      "Epoch: [34][6/9]\tTime 0.074 (0.119)\tData 0.054 (0.097)\tLoss 0.3016 (0.6541)\tAcc 1.000 (0.750)\n",
      "Epoch: [34][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6102 (0.6478)\tAcc 0.875 (0.768)\n",
      "Epoch: [34][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.087)\tLoss 1.0680 (0.7003)\tAcc 0.500 (0.734)\n",
      "Epoch: [34][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.1149 (0.6913)\tAcc 1.000 (0.738)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.403 (0.403)\tData 0.376 (0.376)\tLoss 0.6972 (0.6972)\tAcc 0.812 (0.812)\n",
      "Epoch: [35][2/5]\tTime 0.075 (0.239)\tData 0.051 (0.213)\tLoss 0.8720 (0.7846)\tAcc 0.625 (0.719)\n",
      "Epoch: [35][3/5]\tTime 0.077 (0.185)\tData 0.054 (0.160)\tLoss 0.6070 (0.7254)\tAcc 0.812 (0.750)\n",
      "Epoch: [35][4/5]\tTime 0.077 (0.158)\tData 0.054 (0.134)\tLoss 0.8010 (0.7443)\tAcc 0.750 (0.750)\n",
      "Epoch: [35][5/5]\tTime 0.080 (0.142)\tData 0.056 (0.118)\tLoss 0.7984 (0.7510)\tAcc 0.667 (0.740)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.294 (0.294)\tData 0.270 (0.270)\tLoss 0.3312 (0.3312)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/9]\tTime 0.110 (0.202)\tData 0.089 (0.180)\tLoss 1.0122 (0.6717)\tAcc 0.438 (0.688)\n",
      "Epoch: [35][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.137)\tLoss 0.6993 (0.6809)\tAcc 0.625 (0.667)\n",
      "Epoch: [35][4/9]\tTime 0.076 (0.138)\tData 0.053 (0.116)\tLoss 0.5955 (0.6596)\tAcc 0.688 (0.672)\n",
      "Epoch: [35][5/9]\tTime 0.072 (0.125)\tData 0.052 (0.103)\tLoss 0.8416 (0.6960)\tAcc 0.750 (0.688)\n",
      "Epoch: [35][6/9]\tTime 0.072 (0.116)\tData 0.053 (0.095)\tLoss 0.2512 (0.6218)\tAcc 1.000 (0.740)\n",
      "Epoch: [35][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.4851 (0.6023)\tAcc 0.875 (0.759)\n",
      "Epoch: [35][8/9]\tTime 0.076 (0.106)\tData 0.055 (0.085)\tLoss 1.1407 (0.6696)\tAcc 0.562 (0.734)\n",
      "Epoch: [35][9/9]\tTime 0.072 (0.102)\tData 0.053 (0.081)\tLoss 0.1134 (0.6611)\tAcc 1.000 (0.738)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.344 (0.344)\tData 0.315 (0.315)\tLoss 0.6874 (0.6874)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][2/5]\tTime 0.073 (0.208)\tData 0.049 (0.182)\tLoss 0.5360 (0.6117)\tAcc 0.875 (0.812)\n",
      "Epoch: [36][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.139)\tLoss 0.8728 (0.6987)\tAcc 0.562 (0.729)\n",
      "Epoch: [36][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.6764 (0.6931)\tAcc 0.750 (0.734)\n",
      "Epoch: [36][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.105)\tLoss 0.5291 (0.6729)\tAcc 0.667 (0.726)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.376 (0.376)\tData 0.352 (0.352)\tLoss 0.3640 (0.3640)\tAcc 1.000 (1.000)\n",
      "Epoch: [36][2/9]\tTime 0.072 (0.224)\tData 0.051 (0.201)\tLoss 0.8606 (0.6123)\tAcc 0.688 (0.844)\n",
      "Epoch: [36][3/9]\tTime 0.073 (0.174)\tData 0.053 (0.152)\tLoss 0.7762 (0.6669)\tAcc 0.625 (0.771)\n",
      "Epoch: [36][4/9]\tTime 0.073 (0.149)\tData 0.053 (0.127)\tLoss 0.6033 (0.6510)\tAcc 0.688 (0.750)\n",
      "Epoch: [36][5/9]\tTime 0.075 (0.134)\tData 0.054 (0.112)\tLoss 0.7222 (0.6653)\tAcc 0.812 (0.762)\n",
      "Epoch: [36][6/9]\tTime 0.074 (0.124)\tData 0.054 (0.103)\tLoss 0.2956 (0.6037)\tAcc 0.938 (0.792)\n",
      "Epoch: [36][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.096)\tLoss 0.8699 (0.6417)\tAcc 0.625 (0.768)\n",
      "Epoch: [36][8/9]\tTime 0.075 (0.111)\tData 0.056 (0.091)\tLoss 1.1209 (0.7016)\tAcc 0.500 (0.734)\n",
      "Epoch: [36][9/9]\tTime 0.074 (0.107)\tData 0.054 (0.087)\tLoss 0.1031 (0.6924)\tAcc 1.000 (0.738)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.314 (0.314)\tData 0.285 (0.285)\tLoss 1.1603 (1.1603)\tAcc 0.438 (0.438)\n",
      "Epoch: [37][2/5]\tTime 0.073 (0.194)\tData 0.049 (0.167)\tLoss 0.6593 (0.9098)\tAcc 0.625 (0.531)\n",
      "Epoch: [37][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.129)\tLoss 0.7083 (0.8426)\tAcc 0.812 (0.625)\n",
      "Epoch: [37][4/5]\tTime 0.076 (0.135)\tData 0.054 (0.110)\tLoss 0.7555 (0.8208)\tAcc 0.750 (0.656)\n",
      "Epoch: [37][5/5]\tTime 0.081 (0.124)\tData 0.056 (0.099)\tLoss 0.5406 (0.7863)\tAcc 0.889 (0.685)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.295 (0.295)\tData 0.271 (0.271)\tLoss 0.2209 (0.2209)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/9]\tTime 0.072 (0.183)\tData 0.051 (0.161)\tLoss 1.0022 (0.6115)\tAcc 0.625 (0.781)\n",
      "Epoch: [37][3/9]\tTime 0.073 (0.147)\tData 0.052 (0.124)\tLoss 0.6366 (0.6199)\tAcc 0.688 (0.750)\n",
      "Epoch: [37][4/9]\tTime 0.076 (0.129)\tData 0.052 (0.106)\tLoss 0.7230 (0.6457)\tAcc 0.750 (0.750)\n",
      "Epoch: [37][5/9]\tTime 0.072 (0.117)\tData 0.051 (0.095)\tLoss 0.8891 (0.6944)\tAcc 0.625 (0.725)\n",
      "Epoch: [37][6/9]\tTime 0.074 (0.110)\tData 0.053 (0.088)\tLoss 0.1451 (0.6028)\tAcc 1.000 (0.771)\n",
      "Epoch: [37][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.5319 (0.5927)\tAcc 0.812 (0.777)\n",
      "Epoch: [37][8/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 1.4426 (0.6989)\tAcc 0.500 (0.742)\n",
      "Epoch: [37][9/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.1099 (0.6899)\tAcc 1.000 (0.746)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.304 (0.304)\tData 0.274 (0.274)\tLoss 0.3129 (0.3129)\tAcc 0.875 (0.875)\n",
      "Epoch: [38][2/5]\tTime 0.071 (0.188)\tData 0.047 (0.161)\tLoss 0.4946 (0.4038)\tAcc 0.688 (0.781)\n",
      "Epoch: [38][3/5]\tTime 0.076 (0.151)\tData 0.053 (0.125)\tLoss 1.2723 (0.6933)\tAcc 0.562 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.107)\tLoss 1.2018 (0.8204)\tAcc 0.562 (0.672)\n",
      "Epoch: [38][5/5]\tTime 0.080 (0.122)\tData 0.056 (0.097)\tLoss 0.8194 (0.8203)\tAcc 0.778 (0.685)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.337 (0.337)\tData 0.307 (0.307)\tLoss 0.4579 (0.4579)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.066 (0.202)\tData 0.045 (0.176)\tLoss 0.8851 (0.6715)\tAcc 0.438 (0.688)\n",
      "Epoch: [38][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.135)\tLoss 0.7012 (0.6814)\tAcc 0.875 (0.750)\n",
      "Epoch: [38][4/9]\tTime 0.074 (0.138)\tData 0.052 (0.114)\tLoss 0.9971 (0.7603)\tAcc 0.562 (0.703)\n",
      "Epoch: [38][5/9]\tTime 0.072 (0.125)\tData 0.053 (0.102)\tLoss 0.8968 (0.7876)\tAcc 0.750 (0.713)\n",
      "Epoch: [38][6/9]\tTime 0.074 (0.116)\tData 0.054 (0.094)\tLoss 0.4141 (0.7254)\tAcc 1.000 (0.760)\n",
      "Epoch: [38][7/9]\tTime 0.072 (0.110)\tData 0.053 (0.088)\tLoss 1.3487 (0.8144)\tAcc 0.625 (0.741)\n",
      "Epoch: [38][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.084)\tLoss 1.2185 (0.8649)\tAcc 0.500 (0.711)\n",
      "Epoch: [38][9/9]\tTime 0.074 (0.102)\tData 0.054 (0.081)\tLoss 0.5741 (0.8605)\tAcc 1.000 (0.715)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.341 (0.341)\tData 0.314 (0.314)\tLoss 0.7331 (0.7331)\tAcc 0.750 (0.750)\n",
      "Epoch: [39][2/5]\tTime 0.074 (0.207)\tData 0.051 (0.182)\tLoss 0.7644 (0.7487)\tAcc 0.688 (0.719)\n",
      "Epoch: [39][3/5]\tTime 0.077 (0.164)\tData 0.054 (0.140)\tLoss 0.8016 (0.7664)\tAcc 0.625 (0.688)\n",
      "Epoch: [39][4/5]\tTime 0.077 (0.142)\tData 0.055 (0.118)\tLoss 0.7731 (0.7681)\tAcc 0.562 (0.656)\n",
      "Epoch: [39][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.106)\tLoss 0.7872 (0.7704)\tAcc 0.667 (0.658)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.276 (0.276)\tData 0.251 (0.251)\tLoss 0.4134 (0.4134)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/9]\tTime 0.070 (0.173)\tData 0.049 (0.150)\tLoss 0.9568 (0.6851)\tAcc 0.500 (0.719)\n",
      "Epoch: [39][3/9]\tTime 0.073 (0.140)\tData 0.052 (0.117)\tLoss 0.6214 (0.6639)\tAcc 0.750 (0.729)\n",
      "Epoch: [39][4/9]\tTime 0.074 (0.123)\tData 0.053 (0.101)\tLoss 0.7019 (0.6734)\tAcc 0.688 (0.719)\n",
      "Epoch: [39][5/9]\tTime 0.076 (0.114)\tData 0.053 (0.091)\tLoss 0.8691 (0.7125)\tAcc 0.688 (0.713)\n",
      "Epoch: [39][6/9]\tTime 0.072 (0.107)\tData 0.051 (0.085)\tLoss 0.2450 (0.6346)\tAcc 1.000 (0.760)\n",
      "Epoch: [39][7/9]\tTime 0.072 (0.102)\tData 0.053 (0.080)\tLoss 0.6506 (0.6369)\tAcc 0.812 (0.768)\n",
      "Epoch: [39][8/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 0.9659 (0.6780)\tAcc 0.562 (0.742)\n",
      "Epoch: [39][9/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.1815 (0.6704)\tAcc 1.000 (0.746)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.396 (0.396)\tData 0.368 (0.368)\tLoss 0.5113 (0.5113)\tAcc 0.875 (0.875)\n",
      "Epoch: [40][2/5]\tTime 0.077 (0.237)\tData 0.053 (0.210)\tLoss 0.9975 (0.7544)\tAcc 0.500 (0.688)\n",
      "Epoch: [40][3/5]\tTime 0.077 (0.184)\tData 0.053 (0.158)\tLoss 0.6549 (0.7212)\tAcc 0.812 (0.729)\n",
      "Epoch: [40][4/5]\tTime 0.076 (0.157)\tData 0.053 (0.132)\tLoss 0.8691 (0.7582)\tAcc 0.625 (0.703)\n",
      "Epoch: [40][5/5]\tTime 0.080 (0.141)\tData 0.056 (0.116)\tLoss 0.6710 (0.7474)\tAcc 0.778 (0.712)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.365 (0.365)\tData 0.342 (0.342)\tLoss 0.3997 (0.3997)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/9]\tTime 0.072 (0.218)\tData 0.050 (0.196)\tLoss 0.9154 (0.6576)\tAcc 0.500 (0.719)\n",
      "Epoch: [40][3/9]\tTime 0.073 (0.170)\tData 0.052 (0.148)\tLoss 0.5862 (0.6338)\tAcc 0.875 (0.771)\n",
      "Epoch: [40][4/9]\tTime 0.074 (0.146)\tData 0.053 (0.124)\tLoss 0.6271 (0.6321)\tAcc 0.750 (0.766)\n",
      "Epoch: [40][5/9]\tTime 0.073 (0.131)\tData 0.053 (0.110)\tLoss 0.8618 (0.6780)\tAcc 0.750 (0.762)\n",
      "Epoch: [40][6/9]\tTime 0.074 (0.122)\tData 0.054 (0.101)\tLoss 0.2678 (0.6097)\tAcc 1.000 (0.802)\n",
      "Epoch: [40][7/9]\tTime 0.073 (0.115)\tData 0.053 (0.094)\tLoss 0.6771 (0.6193)\tAcc 0.750 (0.795)\n",
      "Epoch: [40][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 0.8907 (0.6532)\tAcc 0.562 (0.766)\n",
      "Epoch: [40][9/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 0.2440 (0.6469)\tAcc 1.000 (0.769)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.302 (0.302)\tData 0.270 (0.270)\tLoss 0.9870 (0.9870)\tAcc 0.562 (0.562)\n",
      "Epoch: [41][2/5]\tTime 0.071 (0.186)\tData 0.047 (0.158)\tLoss 0.5924 (0.7897)\tAcc 0.750 (0.656)\n",
      "Epoch: [41][3/5]\tTime 0.076 (0.150)\tData 0.053 (0.123)\tLoss 1.0828 (0.8874)\tAcc 0.562 (0.625)\n",
      "Epoch: [41][4/5]\tTime 0.076 (0.131)\tData 0.053 (0.106)\tLoss 0.5364 (0.7997)\tAcc 0.875 (0.688)\n",
      "Epoch: [41][5/5]\tTime 0.080 (0.121)\tData 0.056 (0.096)\tLoss 0.9950 (0.8237)\tAcc 0.444 (0.658)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.314 (0.314)\tData 0.288 (0.288)\tLoss 0.3678 (0.3678)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/9]\tTime 0.070 (0.192)\tData 0.048 (0.168)\tLoss 0.9058 (0.6368)\tAcc 0.438 (0.688)\n",
      "Epoch: [41][3/9]\tTime 0.073 (0.152)\tData 0.052 (0.129)\tLoss 0.6968 (0.6568)\tAcc 0.812 (0.729)\n",
      "Epoch: [41][4/9]\tTime 0.075 (0.133)\tData 0.053 (0.110)\tLoss 0.7518 (0.6806)\tAcc 0.688 (0.719)\n",
      "Epoch: [41][5/9]\tTime 0.072 (0.121)\tData 0.052 (0.099)\tLoss 0.7329 (0.6910)\tAcc 0.750 (0.725)\n",
      "Epoch: [41][6/9]\tTime 0.075 (0.113)\tData 0.054 (0.091)\tLoss 0.3295 (0.6308)\tAcc 1.000 (0.771)\n",
      "Epoch: [41][7/9]\tTime 0.075 (0.108)\tData 0.055 (0.086)\tLoss 0.8183 (0.6575)\tAcc 0.625 (0.750)\n",
      "Epoch: [41][8/9]\tTime 0.080 (0.104)\tData 0.060 (0.083)\tLoss 1.0423 (0.7056)\tAcc 0.500 (0.719)\n",
      "Epoch: [41][9/9]\tTime 0.079 (0.101)\tData 0.059 (0.080)\tLoss 0.2586 (0.6988)\tAcc 1.000 (0.723)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.348 (0.348)\tData 0.308 (0.308)\tLoss 0.6247 (0.6247)\tAcc 0.812 (0.812)\n",
      "Epoch: [42][2/5]\tTime 0.074 (0.211)\tData 0.050 (0.179)\tLoss 0.6592 (0.6420)\tAcc 0.688 (0.750)\n",
      "Epoch: [42][3/5]\tTime 0.084 (0.169)\tData 0.061 (0.139)\tLoss 0.7271 (0.6704)\tAcc 0.688 (0.729)\n",
      "Epoch: [42][4/5]\tTime 0.085 (0.148)\tData 0.061 (0.120)\tLoss 0.8144 (0.7064)\tAcc 0.688 (0.719)\n",
      "Epoch: [42][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.107)\tLoss 0.6783 (0.7029)\tAcc 0.778 (0.726)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.416 (0.416)\tData 0.377 (0.377)\tLoss 0.4066 (0.4066)\tAcc 0.875 (0.875)\n",
      "Epoch: [42][2/9]\tTime 0.064 (0.240)\tData 0.040 (0.209)\tLoss 0.9072 (0.6569)\tAcc 0.438 (0.656)\n",
      "Epoch: [42][3/9]\tTime 0.085 (0.188)\tData 0.057 (0.158)\tLoss 0.5950 (0.6363)\tAcc 0.875 (0.729)\n",
      "Epoch: [42][4/9]\tTime 0.070 (0.159)\tData 0.049 (0.131)\tLoss 0.7835 (0.6731)\tAcc 0.625 (0.703)\n",
      "Epoch: [42][5/9]\tTime 0.075 (0.142)\tData 0.054 (0.115)\tLoss 0.9702 (0.7325)\tAcc 0.688 (0.700)\n",
      "Epoch: [42][6/9]\tTime 0.072 (0.130)\tData 0.053 (0.105)\tLoss 0.2707 (0.6555)\tAcc 1.000 (0.750)\n",
      "Epoch: [42][7/9]\tTime 0.073 (0.122)\tData 0.054 (0.098)\tLoss 0.7510 (0.6692)\tAcc 0.688 (0.741)\n",
      "Epoch: [42][8/9]\tTime 0.074 (0.116)\tData 0.054 (0.092)\tLoss 1.0409 (0.7156)\tAcc 0.500 (0.711)\n",
      "Epoch: [42][9/9]\tTime 0.075 (0.112)\tData 0.054 (0.088)\tLoss 0.2718 (0.7088)\tAcc 1.000 (0.715)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.399 (0.399)\tData 0.371 (0.371)\tLoss 0.7381 (0.7381)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][2/5]\tTime 0.077 (0.238)\tData 0.051 (0.211)\tLoss 0.8100 (0.7740)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][3/5]\tTime 0.080 (0.185)\tData 0.055 (0.159)\tLoss 0.6000 (0.7160)\tAcc 0.750 (0.708)\n",
      "Epoch: [43][4/5]\tTime 0.078 (0.158)\tData 0.053 (0.132)\tLoss 0.7558 (0.7260)\tAcc 0.750 (0.719)\n",
      "Epoch: [43][5/5]\tTime 0.079 (0.142)\tData 0.054 (0.117)\tLoss 0.5038 (0.6986)\tAcc 0.889 (0.740)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.346 (0.346)\tData 0.319 (0.319)\tLoss 0.3305 (0.3305)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/9]\tTime 0.074 (0.210)\tData 0.052 (0.185)\tLoss 0.9778 (0.6542)\tAcc 0.438 (0.688)\n",
      "Epoch: [43][3/9]\tTime 0.078 (0.166)\tData 0.057 (0.142)\tLoss 0.6699 (0.6594)\tAcc 0.812 (0.729)\n",
      "Epoch: [43][4/9]\tTime 0.080 (0.144)\tData 0.060 (0.122)\tLoss 0.7999 (0.6945)\tAcc 0.625 (0.703)\n",
      "Epoch: [43][5/9]\tTime 0.080 (0.131)\tData 0.060 (0.109)\tLoss 1.0039 (0.7564)\tAcc 0.688 (0.700)\n",
      "Epoch: [43][6/9]\tTime 0.080 (0.123)\tData 0.060 (0.101)\tLoss 0.2426 (0.6708)\tAcc 1.000 (0.750)\n",
      "Epoch: [43][7/9]\tTime 0.076 (0.116)\tData 0.056 (0.095)\tLoss 0.7416 (0.6809)\tAcc 0.750 (0.750)\n",
      "Epoch: [43][8/9]\tTime 0.080 (0.112)\tData 0.060 (0.090)\tLoss 1.0060 (0.7215)\tAcc 0.562 (0.727)\n",
      "Epoch: [43][9/9]\tTime 0.079 (0.108)\tData 0.060 (0.087)\tLoss 0.1913 (0.7134)\tAcc 1.000 (0.731)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.414 (0.414)\tData 0.385 (0.385)\tLoss 0.5927 (0.5927)\tAcc 0.812 (0.812)\n",
      "Epoch: [44][2/5]\tTime 0.084 (0.249)\tData 0.058 (0.222)\tLoss 0.9134 (0.7531)\tAcc 0.625 (0.719)\n",
      "Epoch: [44][3/5]\tTime 0.078 (0.192)\tData 0.054 (0.166)\tLoss 0.9040 (0.8034)\tAcc 0.562 (0.667)\n",
      "Epoch: [44][4/5]\tTime 0.085 (0.165)\tData 0.061 (0.140)\tLoss 0.6572 (0.7668)\tAcc 0.812 (0.703)\n",
      "Epoch: [44][5/5]\tTime 0.085 (0.149)\tData 0.061 (0.124)\tLoss 0.8028 (0.7713)\tAcc 0.667 (0.699)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.407 (0.407)\tData 0.375 (0.375)\tLoss 0.3057 (0.3057)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.072 (0.240)\tData 0.047 (0.211)\tLoss 1.1467 (0.7262)\tAcc 0.438 (0.688)\n",
      "Epoch: [44][3/9]\tTime 0.078 (0.186)\tData 0.054 (0.159)\tLoss 0.5420 (0.6648)\tAcc 0.812 (0.729)\n",
      "Epoch: [44][4/9]\tTime 0.079 (0.159)\tData 0.058 (0.134)\tLoss 0.6649 (0.6648)\tAcc 0.688 (0.719)\n",
      "Epoch: [44][5/9]\tTime 0.080 (0.143)\tData 0.059 (0.119)\tLoss 0.7110 (0.6741)\tAcc 0.750 (0.725)\n",
      "Epoch: [44][6/9]\tTime 0.079 (0.133)\tData 0.059 (0.109)\tLoss 0.2294 (0.6000)\tAcc 1.000 (0.771)\n",
      "Epoch: [44][7/9]\tTime 0.079 (0.125)\tData 0.060 (0.102)\tLoss 0.7501 (0.6214)\tAcc 0.625 (0.750)\n",
      "Epoch: [44][8/9]\tTime 0.076 (0.119)\tData 0.056 (0.096)\tLoss 1.1281 (0.6847)\tAcc 0.438 (0.711)\n",
      "Epoch: [44][9/9]\tTime 0.079 (0.115)\tData 0.060 (0.092)\tLoss 0.3012 (0.6788)\tAcc 1.000 (0.715)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.319 (0.319)\tData 0.285 (0.285)\tLoss 0.5540 (0.5540)\tAcc 0.812 (0.812)\n",
      "Epoch: [45][2/5]\tTime 0.069 (0.194)\tData 0.045 (0.165)\tLoss 0.8371 (0.6956)\tAcc 0.688 (0.750)\n",
      "Epoch: [45][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.128)\tLoss 0.8135 (0.7349)\tAcc 0.688 (0.729)\n",
      "Epoch: [45][4/5]\tTime 0.077 (0.135)\tData 0.053 (0.109)\tLoss 0.7280 (0.7332)\tAcc 0.688 (0.719)\n",
      "Epoch: [45][5/5]\tTime 0.080 (0.124)\tData 0.055 (0.098)\tLoss 0.9569 (0.7607)\tAcc 0.556 (0.699)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.323 (0.323)\tData 0.287 (0.287)\tLoss 0.2492 (0.2492)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/9]\tTime 0.075 (0.199)\tData 0.043 (0.165)\tLoss 0.9589 (0.6040)\tAcc 0.438 (0.688)\n",
      "Epoch: [45][3/9]\tTime 0.073 (0.157)\tData 0.050 (0.127)\tLoss 0.6777 (0.6286)\tAcc 0.750 (0.708)\n",
      "Epoch: [45][4/9]\tTime 0.080 (0.138)\tData 0.058 (0.110)\tLoss 0.6496 (0.6338)\tAcc 0.688 (0.703)\n",
      "Epoch: [45][5/9]\tTime 0.079 (0.126)\tData 0.058 (0.099)\tLoss 0.8652 (0.6801)\tAcc 0.688 (0.700)\n",
      "Epoch: [45][6/9]\tTime 0.079 (0.118)\tData 0.059 (0.093)\tLoss 0.1908 (0.5986)\tAcc 1.000 (0.750)\n",
      "Epoch: [45][7/9]\tTime 0.081 (0.113)\tData 0.060 (0.088)\tLoss 0.7146 (0.6151)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][8/9]\tTime 0.078 (0.108)\tData 0.056 (0.084)\tLoss 0.8909 (0.6496)\tAcc 0.688 (0.742)\n",
      "Epoch: [45][9/9]\tTime 0.080 (0.105)\tData 0.059 (0.081)\tLoss 0.2630 (0.6436)\tAcc 1.000 (0.746)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.387 (0.387)\tData 0.355 (0.355)\tLoss 0.4971 (0.4971)\tAcc 0.812 (0.812)\n",
      "Epoch: [46][2/5]\tTime 0.083 (0.235)\tData 0.055 (0.205)\tLoss 0.5112 (0.5042)\tAcc 0.750 (0.781)\n",
      "Epoch: [46][3/5]\tTime 0.080 (0.183)\tData 0.054 (0.155)\tLoss 0.4761 (0.4948)\tAcc 0.812 (0.792)\n",
      "Epoch: [46][4/5]\tTime 0.086 (0.159)\tData 0.060 (0.131)\tLoss 0.9719 (0.6141)\tAcc 0.625 (0.750)\n",
      "Epoch: [46][5/5]\tTime 0.082 (0.143)\tData 0.056 (0.116)\tLoss 0.7082 (0.6257)\tAcc 0.778 (0.753)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.395 (0.395)\tData 0.361 (0.361)\tLoss 0.2986 (0.2986)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/9]\tTime 0.070 (0.233)\tData 0.048 (0.204)\tLoss 0.9930 (0.6458)\tAcc 0.438 (0.688)\n",
      "Epoch: [46][3/9]\tTime 0.075 (0.180)\tData 0.053 (0.154)\tLoss 0.4697 (0.5871)\tAcc 0.875 (0.750)\n",
      "Epoch: [46][4/9]\tTime 0.080 (0.155)\tData 0.058 (0.130)\tLoss 0.7315 (0.6232)\tAcc 0.688 (0.734)\n",
      "Epoch: [46][5/9]\tTime 0.078 (0.140)\tData 0.058 (0.116)\tLoss 0.9142 (0.6814)\tAcc 0.688 (0.725)\n",
      "Epoch: [46][6/9]\tTime 0.081 (0.130)\tData 0.061 (0.107)\tLoss 0.2552 (0.6104)\tAcc 1.000 (0.771)\n",
      "Epoch: [46][7/9]\tTime 0.077 (0.122)\tData 0.056 (0.099)\tLoss 0.6157 (0.6111)\tAcc 0.812 (0.777)\n",
      "Epoch: [46][8/9]\tTime 0.075 (0.117)\tData 0.054 (0.094)\tLoss 0.9764 (0.6568)\tAcc 0.625 (0.758)\n",
      "Epoch: [46][9/9]\tTime 0.080 (0.112)\tData 0.059 (0.090)\tLoss 0.1389 (0.6488)\tAcc 1.000 (0.762)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.367 (0.367)\tData 0.335 (0.335)\tLoss 0.7368 (0.7368)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][2/5]\tTime 0.075 (0.221)\tData 0.047 (0.191)\tLoss 0.8415 (0.7891)\tAcc 0.625 (0.656)\n",
      "Epoch: [47][3/5]\tTime 0.085 (0.176)\tData 0.060 (0.147)\tLoss 0.8352 (0.8045)\tAcc 0.688 (0.667)\n",
      "Epoch: [47][4/5]\tTime 0.083 (0.152)\tData 0.058 (0.125)\tLoss 0.6507 (0.7660)\tAcc 0.812 (0.703)\n",
      "Epoch: [47][5/5]\tTime 0.080 (0.138)\tData 0.055 (0.111)\tLoss 0.5254 (0.7364)\tAcc 0.778 (0.712)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.370 (0.370)\tData 0.334 (0.334)\tLoss 0.2830 (0.2830)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/9]\tTime 0.067 (0.218)\tData 0.045 (0.189)\tLoss 0.9887 (0.6359)\tAcc 0.438 (0.688)\n",
      "Epoch: [47][3/9]\tTime 0.083 (0.173)\tData 0.060 (0.146)\tLoss 0.5298 (0.6005)\tAcc 0.875 (0.750)\n",
      "Epoch: [47][4/9]\tTime 0.081 (0.150)\tData 0.054 (0.123)\tLoss 0.7343 (0.6340)\tAcc 0.625 (0.719)\n",
      "Epoch: [47][5/9]\tTime 0.095 (0.139)\tData 0.074 (0.113)\tLoss 0.8674 (0.6806)\tAcc 0.750 (0.725)\n",
      "Epoch: [47][6/9]\tTime 0.079 (0.129)\tData 0.059 (0.104)\tLoss 0.2283 (0.6052)\tAcc 1.000 (0.771)\n",
      "Epoch: [47][7/9]\tTime 0.074 (0.121)\tData 0.054 (0.097)\tLoss 0.7815 (0.6304)\tAcc 0.625 (0.750)\n",
      "Epoch: [47][8/9]\tTime 0.075 (0.115)\tData 0.054 (0.092)\tLoss 0.9824 (0.6744)\tAcc 0.625 (0.734)\n",
      "Epoch: [47][9/9]\tTime 0.075 (0.111)\tData 0.055 (0.087)\tLoss 0.1873 (0.6669)\tAcc 1.000 (0.738)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.337 (0.337)\tData 0.308 (0.308)\tLoss 0.8789 (0.8789)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][2/5]\tTime 0.074 (0.205)\tData 0.050 (0.179)\tLoss 0.7468 (0.8129)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][3/5]\tTime 0.080 (0.163)\tData 0.055 (0.138)\tLoss 0.6894 (0.7717)\tAcc 0.750 (0.708)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.142)\tData 0.053 (0.116)\tLoss 0.7693 (0.7711)\tAcc 0.688 (0.703)\n",
      "Epoch: [48][5/5]\tTime 0.085 (0.130)\tData 0.060 (0.105)\tLoss 0.6253 (0.7531)\tAcc 0.667 (0.699)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.395 (0.395)\tData 0.371 (0.371)\tLoss 0.3141 (0.3141)\tAcc 0.875 (0.875)\n",
      "Epoch: [48][2/9]\tTime 0.073 (0.234)\tData 0.050 (0.211)\tLoss 0.9060 (0.6100)\tAcc 0.500 (0.688)\n",
      "Epoch: [48][3/9]\tTime 0.072 (0.180)\tData 0.051 (0.158)\tLoss 0.7257 (0.6486)\tAcc 0.750 (0.708)\n",
      "Epoch: [48][4/9]\tTime 0.077 (0.154)\tData 0.057 (0.133)\tLoss 0.5050 (0.6127)\tAcc 0.688 (0.703)\n",
      "Epoch: [48][5/9]\tTime 0.082 (0.140)\tData 0.061 (0.118)\tLoss 0.8029 (0.6507)\tAcc 0.812 (0.725)\n",
      "Epoch: [48][6/9]\tTime 0.079 (0.130)\tData 0.059 (0.108)\tLoss 0.2496 (0.5839)\tAcc 1.000 (0.771)\n",
      "Epoch: [48][7/9]\tTime 0.081 (0.123)\tData 0.060 (0.101)\tLoss 0.6425 (0.5922)\tAcc 0.688 (0.759)\n",
      "Epoch: [48][8/9]\tTime 0.075 (0.117)\tData 0.054 (0.095)\tLoss 0.9114 (0.6321)\tAcc 0.625 (0.742)\n",
      "Epoch: [48][9/9]\tTime 0.074 (0.112)\tData 0.054 (0.091)\tLoss 0.1894 (0.6253)\tAcc 1.000 (0.746)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.382 (0.382)\tData 0.355 (0.355)\tLoss 0.8303 (0.8303)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][2/5]\tTime 0.077 (0.229)\tData 0.051 (0.203)\tLoss 0.6782 (0.7543)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][3/5]\tTime 0.076 (0.178)\tData 0.052 (0.153)\tLoss 0.6778 (0.7288)\tAcc 0.688 (0.729)\n",
      "Epoch: [49][4/5]\tTime 0.080 (0.154)\tData 0.053 (0.128)\tLoss 0.8051 (0.7479)\tAcc 0.688 (0.719)\n",
      "Epoch: [49][5/5]\tTime 0.078 (0.138)\tData 0.053 (0.113)\tLoss 0.9524 (0.7731)\tAcc 0.667 (0.712)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.442 (0.442)\tData 0.401 (0.401)\tLoss 0.3454 (0.3454)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.063 (0.252)\tData 0.040 (0.221)\tLoss 0.9137 (0.6295)\tAcc 0.438 (0.688)\n",
      "Epoch: [49][3/9]\tTime 0.080 (0.195)\tData 0.058 (0.166)\tLoss 0.5759 (0.6117)\tAcc 0.875 (0.750)\n",
      "Epoch: [49][4/9]\tTime 0.076 (0.165)\tData 0.054 (0.138)\tLoss 0.6201 (0.6138)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][5/9]\tTime 0.073 (0.147)\tData 0.052 (0.121)\tLoss 0.9151 (0.6740)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][6/9]\tTime 0.075 (0.135)\tData 0.054 (0.110)\tLoss 0.2698 (0.6067)\tAcc 1.000 (0.792)\n",
      "Epoch: [49][7/9]\tTime 0.080 (0.127)\tData 0.059 (0.103)\tLoss 0.6574 (0.6139)\tAcc 0.688 (0.777)\n",
      "Epoch: [49][8/9]\tTime 0.081 (0.121)\tData 0.060 (0.097)\tLoss 0.9520 (0.6562)\tAcc 0.625 (0.758)\n",
      "Epoch: [49][9/9]\tTime 0.076 (0.116)\tData 0.056 (0.093)\tLoss 0.2901 (0.6505)\tAcc 1.000 (0.762)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.334 (0.334)\tData 0.297 (0.297)\tLoss 0.4544 (0.4544)\tAcc 0.875 (0.875)\n",
      "Epoch: [50][2/5]\tTime 0.075 (0.205)\tData 0.050 (0.174)\tLoss 0.5565 (0.5054)\tAcc 0.750 (0.812)\n",
      "Epoch: [50][3/5]\tTime 0.083 (0.164)\tData 0.058 (0.135)\tLoss 0.9567 (0.6559)\tAcc 0.562 (0.729)\n",
      "Epoch: [50][4/5]\tTime 0.084 (0.144)\tData 0.060 (0.116)\tLoss 0.7958 (0.6909)\tAcc 0.688 (0.719)\n",
      "Epoch: [50][5/5]\tTime 0.085 (0.132)\tData 0.061 (0.105)\tLoss 0.9889 (0.7276)\tAcc 0.667 (0.712)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.396 (0.396)\tData 0.363 (0.363)\tLoss 0.4385 (0.4385)\tAcc 0.875 (0.875)\n",
      "Epoch: [50][2/9]\tTime 0.090 (0.243)\tData 0.067 (0.215)\tLoss 1.0445 (0.7415)\tAcc 0.438 (0.656)\n",
      "Epoch: [50][3/9]\tTime 0.080 (0.188)\tData 0.058 (0.162)\tLoss 0.6432 (0.7087)\tAcc 0.750 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.080 (0.161)\tData 0.059 (0.137)\tLoss 0.5229 (0.6623)\tAcc 0.812 (0.719)\n",
      "Epoch: [50][5/9]\tTime 0.075 (0.144)\tData 0.054 (0.120)\tLoss 0.9750 (0.7248)\tAcc 0.625 (0.700)\n",
      "Epoch: [50][6/9]\tTime 0.075 (0.132)\tData 0.054 (0.109)\tLoss 0.2206 (0.6408)\tAcc 1.000 (0.750)\n",
      "Epoch: [50][7/9]\tTime 0.076 (0.124)\tData 0.055 (0.101)\tLoss 0.7481 (0.6561)\tAcc 0.625 (0.732)\n",
      "Epoch: [50][8/9]\tTime 0.081 (0.119)\tData 0.060 (0.096)\tLoss 1.0270 (0.7025)\tAcc 0.688 (0.727)\n",
      "Epoch: [50][9/9]\tTime 0.079 (0.114)\tData 0.059 (0.092)\tLoss 0.2681 (0.6958)\tAcc 1.000 (0.731)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.368 (0.368)\tData 0.336 (0.336)\tLoss 0.9900 (0.9900)\tAcc 0.562 (0.562)\n",
      "Epoch: [51][2/5]\tTime 0.074 (0.221)\tData 0.048 (0.192)\tLoss 0.8347 (0.9124)\tAcc 0.625 (0.594)\n",
      "Epoch: [51][3/5]\tTime 0.076 (0.172)\tData 0.052 (0.145)\tLoss 0.6840 (0.8363)\tAcc 0.750 (0.646)\n",
      "Epoch: [51][4/5]\tTime 0.080 (0.149)\tData 0.055 (0.123)\tLoss 0.4506 (0.7398)\tAcc 0.875 (0.703)\n",
      "Epoch: [51][5/5]\tTime 0.079 (0.135)\tData 0.056 (0.109)\tLoss 0.7566 (0.7419)\tAcc 0.556 (0.685)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.363 (0.363)\tData 0.339 (0.339)\tLoss 0.2961 (0.2961)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/9]\tTime 0.092 (0.227)\tData 0.066 (0.203)\tLoss 0.9404 (0.6182)\tAcc 0.438 (0.688)\n",
      "Epoch: [51][3/9]\tTime 0.076 (0.177)\tData 0.054 (0.153)\tLoss 0.7455 (0.6607)\tAcc 0.750 (0.708)\n",
      "Epoch: [51][4/9]\tTime 0.080 (0.152)\tData 0.059 (0.129)\tLoss 0.5383 (0.6301)\tAcc 0.812 (0.734)\n",
      "Epoch: [51][5/9]\tTime 0.079 (0.138)\tData 0.058 (0.115)\tLoss 0.7381 (0.6517)\tAcc 0.750 (0.738)\n",
      "Epoch: [51][6/9]\tTime 0.080 (0.128)\tData 0.059 (0.106)\tLoss 0.3059 (0.5940)\tAcc 1.000 (0.781)\n",
      "Epoch: [51][7/9]\tTime 0.079 (0.121)\tData 0.058 (0.099)\tLoss 0.7815 (0.6208)\tAcc 0.500 (0.741)\n",
      "Epoch: [51][8/9]\tTime 0.074 (0.115)\tData 0.053 (0.093)\tLoss 1.0441 (0.6737)\tAcc 0.562 (0.719)\n",
      "Epoch: [51][9/9]\tTime 0.079 (0.111)\tData 0.059 (0.090)\tLoss 0.3242 (0.6683)\tAcc 1.000 (0.723)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.404 (0.404)\tData 0.377 (0.377)\tLoss 0.4665 (0.4665)\tAcc 0.875 (0.875)\n",
      "Epoch: [52][2/5]\tTime 0.074 (0.239)\tData 0.051 (0.214)\tLoss 0.7930 (0.6298)\tAcc 0.688 (0.781)\n",
      "Epoch: [52][3/5]\tTime 0.077 (0.185)\tData 0.054 (0.160)\tLoss 0.6770 (0.6455)\tAcc 0.562 (0.708)\n",
      "Epoch: [52][4/5]\tTime 0.076 (0.158)\tData 0.054 (0.134)\tLoss 0.7261 (0.6657)\tAcc 0.688 (0.703)\n",
      "Epoch: [52][5/5]\tTime 0.083 (0.143)\tData 0.058 (0.119)\tLoss 1.1249 (0.7223)\tAcc 0.667 (0.699)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.374 (0.374)\tData 0.334 (0.334)\tLoss 0.2851 (0.2851)\tAcc 1.000 (1.000)\n",
      "Epoch: [52][2/9]\tTime 0.069 (0.221)\tData 0.046 (0.190)\tLoss 0.9078 (0.5965)\tAcc 0.500 (0.750)\n",
      "Epoch: [52][3/9]\tTime 0.078 (0.174)\tData 0.055 (0.145)\tLoss 0.8451 (0.6793)\tAcc 0.688 (0.729)\n",
      "Epoch: [52][4/9]\tTime 0.077 (0.150)\tData 0.051 (0.121)\tLoss 0.6065 (0.6611)\tAcc 0.688 (0.719)\n",
      "Epoch: [52][5/9]\tTime 0.070 (0.134)\tData 0.050 (0.107)\tLoss 0.8825 (0.7054)\tAcc 0.750 (0.725)\n",
      "Epoch: [52][6/9]\tTime 0.074 (0.124)\tData 0.053 (0.098)\tLoss 0.2740 (0.6335)\tAcc 1.000 (0.771)\n",
      "Epoch: [52][7/9]\tTime 0.072 (0.116)\tData 0.053 (0.092)\tLoss 0.7362 (0.6482)\tAcc 0.625 (0.750)\n",
      "Epoch: [52][8/9]\tTime 0.075 (0.111)\tData 0.055 (0.087)\tLoss 0.9810 (0.6898)\tAcc 0.625 (0.734)\n",
      "Epoch: [52][9/9]\tTime 0.074 (0.107)\tData 0.054 (0.083)\tLoss 0.1457 (0.6814)\tAcc 1.000 (0.738)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.345 (0.345)\tData 0.316 (0.316)\tLoss 0.6024 (0.6024)\tAcc 0.688 (0.688)\n",
      "Epoch: [53][2/5]\tTime 0.073 (0.209)\tData 0.049 (0.182)\tLoss 0.6487 (0.6255)\tAcc 0.812 (0.750)\n",
      "Epoch: [53][3/5]\tTime 0.076 (0.165)\tData 0.053 (0.139)\tLoss 0.5954 (0.6155)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.6235 (0.6175)\tAcc 0.812 (0.766)\n",
      "Epoch: [53][5/5]\tTime 0.080 (0.130)\tData 0.057 (0.105)\tLoss 1.2643 (0.6972)\tAcc 0.444 (0.726)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.432 (0.432)\tData 0.398 (0.398)\tLoss 0.4200 (0.4200)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/9]\tTime 0.072 (0.252)\tData 0.047 (0.223)\tLoss 0.9665 (0.6932)\tAcc 0.562 (0.750)\n",
      "Epoch: [53][3/9]\tTime 0.077 (0.194)\tData 0.057 (0.167)\tLoss 0.6216 (0.6694)\tAcc 0.812 (0.771)\n",
      "Epoch: [53][4/9]\tTime 0.081 (0.165)\tData 0.059 (0.140)\tLoss 0.6735 (0.6704)\tAcc 0.688 (0.750)\n",
      "Epoch: [53][5/9]\tTime 0.078 (0.148)\tData 0.058 (0.124)\tLoss 0.9560 (0.7275)\tAcc 0.688 (0.738)\n",
      "Epoch: [53][6/9]\tTime 0.081 (0.137)\tData 0.060 (0.113)\tLoss 0.2743 (0.6520)\tAcc 1.000 (0.781)\n",
      "Epoch: [53][7/9]\tTime 0.075 (0.128)\tData 0.054 (0.105)\tLoss 0.7084 (0.6600)\tAcc 0.750 (0.777)\n",
      "Epoch: [53][8/9]\tTime 0.074 (0.121)\tData 0.054 (0.098)\tLoss 1.1209 (0.7177)\tAcc 0.500 (0.742)\n",
      "Epoch: [53][9/9]\tTime 0.075 (0.116)\tData 0.055 (0.094)\tLoss 0.4947 (0.7142)\tAcc 1.000 (0.746)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.315 (0.315)\tData 0.287 (0.287)\tLoss 0.6301 (0.6301)\tAcc 0.688 (0.688)\n",
      "Epoch: [54][2/5]\tTime 0.074 (0.195)\tData 0.050 (0.169)\tLoss 0.6389 (0.6345)\tAcc 0.750 (0.719)\n",
      "Epoch: [54][3/5]\tTime 0.077 (0.155)\tData 0.054 (0.130)\tLoss 0.3934 (0.5541)\tAcc 0.938 (0.792)\n",
      "Epoch: [54][4/5]\tTime 0.077 (0.136)\tData 0.054 (0.111)\tLoss 0.8984 (0.6402)\tAcc 0.688 (0.766)\n",
      "Epoch: [54][5/5]\tTime 0.080 (0.124)\tData 0.057 (0.100)\tLoss 1.3960 (0.7334)\tAcc 0.444 (0.726)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.345 (0.345)\tData 0.321 (0.321)\tLoss 0.3428 (0.3428)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/9]\tTime 0.071 (0.208)\tData 0.050 (0.185)\tLoss 1.0034 (0.6731)\tAcc 0.562 (0.750)\n",
      "Epoch: [54][3/9]\tTime 0.074 (0.164)\tData 0.052 (0.141)\tLoss 0.5535 (0.6333)\tAcc 0.812 (0.771)\n",
      "Epoch: [54][4/9]\tTime 0.072 (0.141)\tData 0.051 (0.119)\tLoss 0.7725 (0.6681)\tAcc 0.688 (0.750)\n",
      "Epoch: [54][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.106)\tLoss 0.9475 (0.7240)\tAcc 0.625 (0.725)\n",
      "Epoch: [54][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.097)\tLoss 0.2865 (0.6510)\tAcc 1.000 (0.771)\n",
      "Epoch: [54][7/9]\tTime 0.072 (0.112)\tData 0.053 (0.091)\tLoss 0.7082 (0.6592)\tAcc 0.688 (0.759)\n",
      "Epoch: [54][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 1.0399 (0.7068)\tAcc 0.438 (0.719)\n",
      "Epoch: [54][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.3057 (0.7006)\tAcc 1.000 (0.723)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.389 (0.389)\tData 0.362 (0.362)\tLoss 0.6356 (0.6356)\tAcc 0.750 (0.750)\n",
      "Epoch: [55][2/5]\tTime 0.076 (0.233)\tData 0.051 (0.207)\tLoss 0.7673 (0.7014)\tAcc 0.688 (0.719)\n",
      "Epoch: [55][3/5]\tTime 0.075 (0.180)\tData 0.052 (0.155)\tLoss 0.7898 (0.7309)\tAcc 0.562 (0.667)\n",
      "Epoch: [55][4/5]\tTime 0.077 (0.154)\tData 0.054 (0.130)\tLoss 0.8861 (0.7697)\tAcc 0.688 (0.672)\n",
      "Epoch: [55][5/5]\tTime 0.081 (0.140)\tData 0.057 (0.115)\tLoss 0.5701 (0.7451)\tAcc 0.889 (0.699)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.241 (0.241)\tData 0.218 (0.218)\tLoss 0.2866 (0.2866)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/9]\tTime 0.073 (0.157)\tData 0.050 (0.134)\tLoss 0.8880 (0.5873)\tAcc 0.562 (0.750)\n",
      "Epoch: [55][3/9]\tTime 0.071 (0.129)\tData 0.051 (0.106)\tLoss 0.7508 (0.6418)\tAcc 0.812 (0.771)\n",
      "Epoch: [55][4/9]\tTime 0.074 (0.115)\tData 0.053 (0.093)\tLoss 0.5965 (0.6305)\tAcc 0.812 (0.781)\n",
      "Epoch: [55][5/9]\tTime 0.072 (0.106)\tData 0.053 (0.085)\tLoss 0.8655 (0.6775)\tAcc 0.750 (0.775)\n",
      "Epoch: [55][6/9]\tTime 0.078 (0.102)\tData 0.059 (0.080)\tLoss 0.2658 (0.6089)\tAcc 1.000 (0.812)\n",
      "Epoch: [55][7/9]\tTime 0.075 (0.098)\tData 0.055 (0.077)\tLoss 0.6338 (0.6124)\tAcc 0.688 (0.795)\n",
      "Epoch: [55][8/9]\tTime 0.072 (0.095)\tData 0.053 (0.074)\tLoss 1.0660 (0.6691)\tAcc 0.562 (0.766)\n",
      "Epoch: [55][9/9]\tTime 0.076 (0.093)\tData 0.056 (0.072)\tLoss 0.2471 (0.6626)\tAcc 1.000 (0.769)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.343 (0.343)\tData 0.314 (0.314)\tLoss 0.7143 (0.7143)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][2/5]\tTime 0.073 (0.208)\tData 0.049 (0.181)\tLoss 0.9149 (0.8146)\tAcc 0.625 (0.656)\n",
      "Epoch: [56][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.138)\tLoss 0.4988 (0.7093)\tAcc 0.875 (0.729)\n",
      "Epoch: [56][4/5]\tTime 0.076 (0.142)\tData 0.053 (0.117)\tLoss 0.7005 (0.7071)\tAcc 0.750 (0.734)\n",
      "Epoch: [56][5/5]\tTime 0.080 (0.130)\tData 0.057 (0.105)\tLoss 0.6568 (0.7009)\tAcc 0.667 (0.726)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.325 (0.325)\tData 0.299 (0.299)\tLoss 0.3495 (0.3495)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/9]\tTime 0.069 (0.197)\tData 0.048 (0.173)\tLoss 1.1577 (0.7536)\tAcc 0.438 (0.688)\n",
      "Epoch: [56][3/9]\tTime 0.074 (0.156)\tData 0.053 (0.133)\tLoss 0.8070 (0.7714)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][4/9]\tTime 0.074 (0.136)\tData 0.052 (0.113)\tLoss 0.7147 (0.7572)\tAcc 0.750 (0.703)\n",
      "Epoch: [56][5/9]\tTime 0.072 (0.123)\tData 0.052 (0.101)\tLoss 0.7637 (0.7585)\tAcc 0.750 (0.713)\n",
      "Epoch: [56][6/9]\tTime 0.075 (0.115)\tData 0.054 (0.093)\tLoss 0.3328 (0.6876)\tAcc 1.000 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.072 (0.109)\tData 0.053 (0.087)\tLoss 0.6788 (0.6863)\tAcc 0.750 (0.759)\n",
      "Epoch: [56][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 0.9141 (0.7148)\tAcc 0.625 (0.742)\n",
      "Epoch: [56][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.1576 (0.7062)\tAcc 1.000 (0.746)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.390 (0.390)\tData 0.361 (0.361)\tLoss 0.5711 (0.5711)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][2/5]\tTime 0.073 (0.232)\tData 0.049 (0.205)\tLoss 0.6336 (0.6023)\tAcc 0.812 (0.781)\n",
      "Epoch: [57][3/5]\tTime 0.076 (0.180)\tData 0.053 (0.154)\tLoss 0.8700 (0.6916)\tAcc 0.625 (0.729)\n",
      "Epoch: [57][4/5]\tTime 0.077 (0.154)\tData 0.053 (0.129)\tLoss 0.8367 (0.7278)\tAcc 0.562 (0.688)\n",
      "Epoch: [57][5/5]\tTime 0.079 (0.139)\tData 0.056 (0.114)\tLoss 0.6345 (0.7163)\tAcc 0.667 (0.685)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.329 (0.329)\tData 0.303 (0.303)\tLoss 0.3746 (0.3746)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/9]\tTime 0.069 (0.199)\tData 0.048 (0.176)\tLoss 0.8543 (0.6145)\tAcc 0.625 (0.781)\n",
      "Epoch: [57][3/9]\tTime 0.075 (0.158)\tData 0.053 (0.135)\tLoss 0.6768 (0.6352)\tAcc 0.750 (0.771)\n",
      "Epoch: [57][4/9]\tTime 0.071 (0.136)\tData 0.052 (0.114)\tLoss 0.6060 (0.6279)\tAcc 0.750 (0.766)\n",
      "Epoch: [57][5/9]\tTime 0.074 (0.124)\tData 0.055 (0.102)\tLoss 0.8418 (0.6707)\tAcc 0.688 (0.750)\n",
      "Epoch: [57][6/9]\tTime 0.075 (0.115)\tData 0.054 (0.094)\tLoss 0.2821 (0.6059)\tAcc 1.000 (0.792)\n",
      "Epoch: [57][7/9]\tTime 0.072 (0.109)\tData 0.054 (0.088)\tLoss 0.7662 (0.6288)\tAcc 0.625 (0.768)\n",
      "Epoch: [57][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.084)\tLoss 1.0686 (0.6838)\tAcc 0.500 (0.734)\n",
      "Epoch: [57][9/9]\tTime 0.074 (0.102)\tData 0.054 (0.081)\tLoss 0.3661 (0.6789)\tAcc 1.000 (0.738)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.322 (0.322)\tData 0.291 (0.291)\tLoss 0.4539 (0.4539)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/5]\tTime 0.073 (0.197)\tData 0.047 (0.169)\tLoss 0.9428 (0.6983)\tAcc 0.500 (0.719)\n",
      "Epoch: [58][3/5]\tTime 0.076 (0.157)\tData 0.052 (0.130)\tLoss 0.9945 (0.7971)\tAcc 0.562 (0.667)\n",
      "Epoch: [58][4/5]\tTime 0.076 (0.136)\tData 0.053 (0.111)\tLoss 0.6246 (0.7539)\tAcc 0.875 (0.719)\n",
      "Epoch: [58][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.100)\tLoss 0.9418 (0.7771)\tAcc 0.556 (0.699)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.285 (0.285)\tData 0.262 (0.262)\tLoss 0.3594 (0.3594)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/9]\tTime 0.072 (0.178)\tData 0.051 (0.156)\tLoss 0.9388 (0.6491)\tAcc 0.438 (0.688)\n",
      "Epoch: [58][3/9]\tTime 0.074 (0.144)\tData 0.053 (0.122)\tLoss 0.7833 (0.6938)\tAcc 0.750 (0.708)\n",
      "Epoch: [58][4/9]\tTime 0.073 (0.126)\tData 0.053 (0.105)\tLoss 0.7640 (0.7114)\tAcc 0.750 (0.719)\n",
      "Epoch: [58][5/9]\tTime 0.074 (0.116)\tData 0.054 (0.094)\tLoss 0.9604 (0.7612)\tAcc 0.625 (0.700)\n",
      "Epoch: [58][6/9]\tTime 0.074 (0.109)\tData 0.054 (0.088)\tLoss 0.2600 (0.6776)\tAcc 1.000 (0.750)\n",
      "Epoch: [58][7/9]\tTime 0.072 (0.103)\tData 0.053 (0.083)\tLoss 0.8801 (0.7066)\tAcc 0.562 (0.723)\n",
      "Epoch: [58][8/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 1.0837 (0.7537)\tAcc 0.562 (0.703)\n",
      "Epoch: [58][9/9]\tTime 0.074 (0.097)\tData 0.054 (0.077)\tLoss 0.1511 (0.7444)\tAcc 1.000 (0.708)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 0.9200 (0.9200)\tAcc 0.750 (0.750)\n",
      "Epoch: [59][2/5]\tTime 0.073 (0.204)\tData 0.048 (0.176)\tLoss 0.9498 (0.9349)\tAcc 0.625 (0.688)\n",
      "Epoch: [59][3/5]\tTime 0.075 (0.161)\tData 0.052 (0.135)\tLoss 0.8272 (0.8990)\tAcc 0.750 (0.708)\n",
      "Epoch: [59][4/5]\tTime 0.077 (0.140)\tData 0.054 (0.115)\tLoss 0.7459 (0.8607)\tAcc 0.750 (0.719)\n",
      "Epoch: [59][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 0.6885 (0.8395)\tAcc 0.778 (0.726)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.438 (0.438)\tData 0.414 (0.414)\tLoss 0.3745 (0.3745)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/9]\tTime 0.071 (0.255)\tData 0.051 (0.233)\tLoss 0.9010 (0.6378)\tAcc 0.562 (0.750)\n",
      "Epoch: [59][3/9]\tTime 0.073 (0.194)\tData 0.053 (0.173)\tLoss 0.6126 (0.6294)\tAcc 0.812 (0.771)\n",
      "Epoch: [59][4/9]\tTime 0.073 (0.164)\tData 0.053 (0.143)\tLoss 0.6209 (0.6273)\tAcc 0.750 (0.766)\n",
      "Epoch: [59][5/9]\tTime 0.074 (0.146)\tData 0.055 (0.125)\tLoss 0.7448 (0.6508)\tAcc 0.688 (0.750)\n",
      "Epoch: [59][6/9]\tTime 0.075 (0.134)\tData 0.054 (0.113)\tLoss 0.3237 (0.5963)\tAcc 1.000 (0.792)\n",
      "Epoch: [59][7/9]\tTime 0.073 (0.125)\tData 0.054 (0.105)\tLoss 0.6574 (0.6050)\tAcc 0.812 (0.795)\n",
      "Epoch: [59][8/9]\tTime 0.074 (0.119)\tData 0.055 (0.099)\tLoss 1.1070 (0.6677)\tAcc 0.500 (0.758)\n",
      "Epoch: [59][9/9]\tTime 0.074 (0.114)\tData 0.054 (0.094)\tLoss 0.2640 (0.6615)\tAcc 1.000 (0.762)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.341 (0.341)\tData 0.314 (0.314)\tLoss 0.7177 (0.7177)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][2/5]\tTime 0.076 (0.208)\tData 0.051 (0.183)\tLoss 0.7371 (0.7274)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.140)\tLoss 0.4825 (0.6458)\tAcc 0.812 (0.771)\n",
      "Epoch: [60][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.7881 (0.6814)\tAcc 0.688 (0.750)\n",
      "Epoch: [60][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.106)\tLoss 1.0051 (0.7213)\tAcc 0.667 (0.740)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.339 (0.339)\tData 0.312 (0.312)\tLoss 0.3985 (0.3985)\tAcc 0.875 (0.875)\n",
      "Epoch: [60][2/9]\tTime 0.070 (0.204)\tData 0.049 (0.180)\tLoss 0.8262 (0.6123)\tAcc 0.500 (0.688)\n",
      "Epoch: [60][3/9]\tTime 0.073 (0.160)\tData 0.053 (0.138)\tLoss 0.6802 (0.6349)\tAcc 0.750 (0.708)\n",
      "Epoch: [60][4/9]\tTime 0.073 (0.139)\tData 0.053 (0.117)\tLoss 0.7378 (0.6606)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][5/9]\tTime 0.074 (0.126)\tData 0.055 (0.104)\tLoss 0.8866 (0.7058)\tAcc 0.688 (0.688)\n",
      "Epoch: [60][6/9]\tTime 0.074 (0.117)\tData 0.054 (0.096)\tLoss 0.2428 (0.6287)\tAcc 1.000 (0.740)\n",
      "Epoch: [60][7/9]\tTime 0.073 (0.111)\tData 0.054 (0.090)\tLoss 0.6810 (0.6361)\tAcc 0.688 (0.732)\n",
      "Epoch: [60][8/9]\tTime 0.076 (0.106)\tData 0.056 (0.086)\tLoss 0.9010 (0.6692)\tAcc 0.562 (0.711)\n",
      "Epoch: [60][9/9]\tTime 0.075 (0.103)\tData 0.055 (0.082)\tLoss 0.2968 (0.6635)\tAcc 1.000 (0.715)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.372 (0.372)\tData 0.344 (0.344)\tLoss 0.7884 (0.7884)\tAcc 0.688 (0.688)\n",
      "Epoch: [61][2/5]\tTime 0.075 (0.224)\tData 0.051 (0.198)\tLoss 0.9281 (0.8583)\tAcc 0.688 (0.688)\n",
      "Epoch: [61][3/5]\tTime 0.077 (0.175)\tData 0.053 (0.149)\tLoss 0.5779 (0.7648)\tAcc 0.812 (0.729)\n",
      "Epoch: [61][4/5]\tTime 0.078 (0.150)\tData 0.054 (0.125)\tLoss 0.6646 (0.7398)\tAcc 0.812 (0.750)\n",
      "Epoch: [61][5/5]\tTime 0.080 (0.136)\tData 0.055 (0.111)\tLoss 1.0580 (0.7790)\tAcc 0.556 (0.726)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.404 (0.404)\tData 0.380 (0.380)\tLoss 0.3439 (0.3439)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.075 (0.240)\tData 0.052 (0.216)\tLoss 0.8816 (0.6128)\tAcc 0.438 (0.688)\n",
      "Epoch: [61][3/9]\tTime 0.071 (0.183)\tData 0.051 (0.161)\tLoss 0.6225 (0.6160)\tAcc 0.750 (0.708)\n",
      "Epoch: [61][4/9]\tTime 0.075 (0.156)\tData 0.054 (0.134)\tLoss 0.5864 (0.6086)\tAcc 0.625 (0.688)\n",
      "Epoch: [61][5/9]\tTime 0.073 (0.140)\tData 0.053 (0.118)\tLoss 0.9749 (0.6819)\tAcc 0.625 (0.675)\n",
      "Epoch: [61][6/9]\tTime 0.074 (0.129)\tData 0.054 (0.107)\tLoss 0.2693 (0.6131)\tAcc 1.000 (0.729)\n",
      "Epoch: [61][7/9]\tTime 0.073 (0.121)\tData 0.054 (0.100)\tLoss 0.7517 (0.6329)\tAcc 0.562 (0.705)\n",
      "Epoch: [61][8/9]\tTime 0.075 (0.115)\tData 0.056 (0.094)\tLoss 1.0436 (0.6842)\tAcc 0.500 (0.680)\n",
      "Epoch: [61][9/9]\tTime 0.074 (0.111)\tData 0.054 (0.090)\tLoss 0.2591 (0.6777)\tAcc 1.000 (0.685)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.353 (0.353)\tData 0.324 (0.324)\tLoss 0.6240 (0.6240)\tAcc 0.812 (0.812)\n",
      "Epoch: [62][2/5]\tTime 0.074 (0.213)\tData 0.050 (0.187)\tLoss 0.5307 (0.5773)\tAcc 0.812 (0.812)\n",
      "Epoch: [62][3/5]\tTime 0.076 (0.168)\tData 0.053 (0.142)\tLoss 0.6138 (0.5895)\tAcc 0.812 (0.812)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.145)\tData 0.053 (0.120)\tLoss 0.8646 (0.6583)\tAcc 0.688 (0.781)\n",
      "Epoch: [62][5/5]\tTime 0.080 (0.132)\tData 0.055 (0.107)\tLoss 1.0669 (0.7086)\tAcc 0.556 (0.753)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.256 (0.256)\tData 0.232 (0.232)\tLoss 0.3778 (0.3778)\tAcc 0.938 (0.938)\n",
      "Epoch: [62][2/9]\tTime 0.109 (0.182)\tData 0.087 (0.160)\tLoss 0.9282 (0.6530)\tAcc 0.438 (0.688)\n",
      "Epoch: [62][3/9]\tTime 0.073 (0.146)\tData 0.053 (0.124)\tLoss 0.7813 (0.6957)\tAcc 0.812 (0.729)\n",
      "Epoch: [62][4/9]\tTime 0.080 (0.130)\tData 0.054 (0.106)\tLoss 0.7315 (0.7047)\tAcc 0.625 (0.703)\n",
      "Epoch: [62][5/9]\tTime 0.069 (0.118)\tData 0.048 (0.095)\tLoss 0.8460 (0.7329)\tAcc 0.750 (0.713)\n",
      "Epoch: [62][6/9]\tTime 0.074 (0.110)\tData 0.053 (0.088)\tLoss 0.2878 (0.6588)\tAcc 1.000 (0.760)\n",
      "Epoch: [62][7/9]\tTime 0.073 (0.105)\tData 0.053 (0.083)\tLoss 0.6577 (0.6586)\tAcc 0.688 (0.750)\n",
      "Epoch: [62][8/9]\tTime 0.075 (0.101)\tData 0.055 (0.079)\tLoss 0.9061 (0.6895)\tAcc 0.688 (0.742)\n",
      "Epoch: [62][9/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.2106 (0.6822)\tAcc 1.000 (0.746)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.394 (0.394)\tData 0.367 (0.367)\tLoss 0.8823 (0.8823)\tAcc 0.562 (0.562)\n",
      "Epoch: [63][2/5]\tTime 0.076 (0.235)\tData 0.050 (0.209)\tLoss 0.6482 (0.7653)\tAcc 0.688 (0.625)\n",
      "Epoch: [63][3/5]\tTime 0.075 (0.182)\tData 0.052 (0.156)\tLoss 0.5350 (0.6885)\tAcc 0.812 (0.688)\n",
      "Epoch: [63][4/5]\tTime 0.076 (0.155)\tData 0.053 (0.131)\tLoss 0.6640 (0.6824)\tAcc 0.750 (0.703)\n",
      "Epoch: [63][5/5]\tTime 0.080 (0.140)\tData 0.056 (0.116)\tLoss 0.6202 (0.6747)\tAcc 0.778 (0.712)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.352 (0.352)\tData 0.326 (0.326)\tLoss 0.2962 (0.2962)\tAcc 1.000 (1.000)\n",
      "Epoch: [63][2/9]\tTime 0.070 (0.211)\tData 0.049 (0.188)\tLoss 0.9585 (0.6274)\tAcc 0.500 (0.750)\n",
      "Epoch: [63][3/9]\tTime 0.074 (0.165)\tData 0.052 (0.142)\tLoss 0.5429 (0.5992)\tAcc 0.812 (0.771)\n",
      "Epoch: [63][4/9]\tTime 0.072 (0.142)\tData 0.052 (0.120)\tLoss 0.7525 (0.6375)\tAcc 0.750 (0.766)\n",
      "Epoch: [63][5/9]\tTime 0.075 (0.129)\tData 0.055 (0.107)\tLoss 1.0618 (0.7224)\tAcc 0.625 (0.738)\n",
      "Epoch: [63][6/9]\tTime 0.075 (0.120)\tData 0.054 (0.098)\tLoss 0.2963 (0.6514)\tAcc 1.000 (0.781)\n",
      "Epoch: [63][7/9]\tTime 0.072 (0.113)\tData 0.053 (0.092)\tLoss 0.6302 (0.6483)\tAcc 0.688 (0.768)\n",
      "Epoch: [63][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.087)\tLoss 1.0403 (0.6973)\tAcc 0.562 (0.742)\n",
      "Epoch: [63][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.084)\tLoss 0.2776 (0.6909)\tAcc 1.000 (0.746)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.333 (0.333)\tData 0.304 (0.304)\tLoss 0.6575 (0.6575)\tAcc 0.750 (0.750)\n",
      "Epoch: [64][2/5]\tTime 0.074 (0.204)\tData 0.049 (0.177)\tLoss 0.4961 (0.5768)\tAcc 0.875 (0.812)\n",
      "Epoch: [64][3/5]\tTime 0.076 (0.161)\tData 0.052 (0.135)\tLoss 0.4956 (0.5497)\tAcc 0.812 (0.812)\n",
      "Epoch: [64][4/5]\tTime 0.077 (0.140)\tData 0.053 (0.115)\tLoss 0.8014 (0.6126)\tAcc 0.750 (0.797)\n",
      "Epoch: [64][5/5]\tTime 0.081 (0.128)\tData 0.056 (0.103)\tLoss 1.1467 (0.6785)\tAcc 0.444 (0.753)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.368 (0.368)\tData 0.341 (0.341)\tLoss 0.3605 (0.3605)\tAcc 1.000 (1.000)\n",
      "Epoch: [64][2/9]\tTime 0.069 (0.218)\tData 0.048 (0.195)\tLoss 1.0135 (0.6870)\tAcc 0.438 (0.719)\n",
      "Epoch: [64][3/9]\tTime 0.074 (0.170)\tData 0.053 (0.148)\tLoss 0.6619 (0.6786)\tAcc 0.812 (0.750)\n",
      "Epoch: [64][4/9]\tTime 0.073 (0.146)\tData 0.053 (0.124)\tLoss 0.7183 (0.6885)\tAcc 0.750 (0.750)\n",
      "Epoch: [64][5/9]\tTime 0.074 (0.131)\tData 0.054 (0.110)\tLoss 0.8801 (0.7268)\tAcc 0.688 (0.738)\n",
      "Epoch: [64][6/9]\tTime 0.074 (0.122)\tData 0.054 (0.101)\tLoss 0.2988 (0.6555)\tAcc 1.000 (0.781)\n",
      "Epoch: [64][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.8102 (0.6776)\tAcc 0.750 (0.777)\n",
      "Epoch: [64][8/9]\tTime 0.076 (0.110)\tData 0.056 (0.089)\tLoss 1.0213 (0.7206)\tAcc 0.625 (0.758)\n",
      "Epoch: [64][9/9]\tTime 0.072 (0.106)\tData 0.054 (0.085)\tLoss 0.1266 (0.7114)\tAcc 1.000 (0.762)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.279 (0.279)\tData 0.249 (0.249)\tLoss 0.6221 (0.6221)\tAcc 0.750 (0.750)\n",
      "Epoch: [65][2/5]\tTime 0.078 (0.179)\tData 0.054 (0.152)\tLoss 0.6211 (0.6216)\tAcc 0.688 (0.719)\n",
      "Epoch: [65][3/5]\tTime 0.077 (0.145)\tData 0.053 (0.119)\tLoss 0.8342 (0.6925)\tAcc 0.625 (0.688)\n",
      "Epoch: [65][4/5]\tTime 0.077 (0.128)\tData 0.053 (0.102)\tLoss 0.8175 (0.7237)\tAcc 0.688 (0.688)\n",
      "Epoch: [65][5/5]\tTime 0.080 (0.118)\tData 0.056 (0.093)\tLoss 0.6101 (0.7097)\tAcc 0.778 (0.699)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.319 (0.319)\tData 0.295 (0.295)\tLoss 0.3239 (0.3239)\tAcc 1.000 (1.000)\n",
      "Epoch: [65][2/9]\tTime 0.072 (0.195)\tData 0.050 (0.173)\tLoss 0.8140 (0.5690)\tAcc 0.500 (0.750)\n",
      "Epoch: [65][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.132)\tLoss 0.5686 (0.5689)\tAcc 0.812 (0.771)\n",
      "Epoch: [65][4/9]\tTime 0.075 (0.135)\tData 0.053 (0.112)\tLoss 0.5968 (0.5758)\tAcc 0.750 (0.766)\n",
      "Epoch: [65][5/9]\tTime 0.074 (0.123)\tData 0.052 (0.100)\tLoss 0.8211 (0.6249)\tAcc 0.688 (0.750)\n",
      "Epoch: [65][6/9]\tTime 0.072 (0.114)\tData 0.052 (0.092)\tLoss 0.2897 (0.5690)\tAcc 1.000 (0.792)\n",
      "Epoch: [65][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.7471 (0.5945)\tAcc 0.812 (0.795)\n",
      "Epoch: [65][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 1.1129 (0.6593)\tAcc 0.500 (0.758)\n",
      "Epoch: [65][9/9]\tTime 0.074 (0.101)\tData 0.054 (0.080)\tLoss 0.1991 (0.6522)\tAcc 1.000 (0.762)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.322 (0.322)\tData 0.293 (0.293)\tLoss 0.6034 (0.6034)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][2/5]\tTime 0.074 (0.198)\tData 0.050 (0.171)\tLoss 0.4677 (0.5356)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][3/5]\tTime 0.078 (0.158)\tData 0.053 (0.132)\tLoss 0.9444 (0.6718)\tAcc 0.562 (0.688)\n",
      "Epoch: [66][4/5]\tTime 0.076 (0.137)\tData 0.053 (0.112)\tLoss 0.8681 (0.7209)\tAcc 0.562 (0.656)\n",
      "Epoch: [66][5/5]\tTime 0.080 (0.126)\tData 0.056 (0.101)\tLoss 0.5680 (0.7021)\tAcc 0.778 (0.671)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.328 (0.328)\tData 0.304 (0.304)\tLoss 0.3277 (0.3277)\tAcc 1.000 (1.000)\n",
      "Epoch: [66][2/9]\tTime 0.071 (0.200)\tData 0.050 (0.177)\tLoss 1.0827 (0.7052)\tAcc 0.500 (0.750)\n",
      "Epoch: [66][3/9]\tTime 0.073 (0.157)\tData 0.053 (0.136)\tLoss 0.6187 (0.6764)\tAcc 0.875 (0.792)\n",
      "Epoch: [66][4/9]\tTime 0.075 (0.137)\tData 0.053 (0.115)\tLoss 0.5924 (0.6554)\tAcc 0.750 (0.781)\n",
      "Epoch: [66][5/9]\tTime 0.074 (0.124)\tData 0.054 (0.103)\tLoss 0.8068 (0.6857)\tAcc 0.750 (0.775)\n",
      "Epoch: [66][6/9]\tTime 0.073 (0.116)\tData 0.053 (0.095)\tLoss 0.3244 (0.6255)\tAcc 1.000 (0.812)\n",
      "Epoch: [66][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.5765 (0.6185)\tAcc 0.750 (0.804)\n",
      "Epoch: [66][8/9]\tTime 0.076 (0.106)\tData 0.055 (0.084)\tLoss 1.0149 (0.6680)\tAcc 0.562 (0.773)\n",
      "Epoch: [66][9/9]\tTime 0.072 (0.102)\tData 0.053 (0.081)\tLoss 0.1663 (0.6603)\tAcc 1.000 (0.777)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.427 (0.427)\tData 0.400 (0.400)\tLoss 0.5730 (0.5730)\tAcc 0.812 (0.812)\n",
      "Epoch: [67][2/5]\tTime 0.075 (0.251)\tData 0.051 (0.226)\tLoss 0.9050 (0.7390)\tAcc 0.562 (0.688)\n",
      "Epoch: [67][3/5]\tTime 0.077 (0.193)\tData 0.054 (0.168)\tLoss 0.5493 (0.6758)\tAcc 0.812 (0.729)\n",
      "Epoch: [67][4/5]\tTime 0.077 (0.164)\tData 0.054 (0.140)\tLoss 0.7598 (0.6968)\tAcc 0.750 (0.734)\n",
      "Epoch: [67][5/5]\tTime 0.081 (0.147)\tData 0.056 (0.123)\tLoss 0.8110 (0.7109)\tAcc 0.667 (0.726)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.311 (0.311)\tData 0.285 (0.285)\tLoss 0.3843 (0.3843)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/9]\tTime 0.069 (0.190)\tData 0.048 (0.167)\tLoss 0.8317 (0.6080)\tAcc 0.438 (0.688)\n",
      "Epoch: [67][3/9]\tTime 0.074 (0.151)\tData 0.053 (0.129)\tLoss 0.8139 (0.6767)\tAcc 0.812 (0.729)\n",
      "Epoch: [67][4/9]\tTime 0.075 (0.132)\tData 0.052 (0.110)\tLoss 0.7065 (0.6841)\tAcc 0.625 (0.703)\n",
      "Epoch: [67][5/9]\tTime 0.071 (0.120)\tData 0.051 (0.098)\tLoss 0.8867 (0.7246)\tAcc 0.750 (0.713)\n",
      "Epoch: [67][6/9]\tTime 0.075 (0.113)\tData 0.055 (0.091)\tLoss 0.2839 (0.6512)\tAcc 1.000 (0.760)\n",
      "Epoch: [67][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.6021 (0.6442)\tAcc 0.688 (0.750)\n",
      "Epoch: [67][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 1.0211 (0.6913)\tAcc 0.625 (0.734)\n",
      "Epoch: [67][9/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 0.2561 (0.6846)\tAcc 1.000 (0.738)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.278 (0.278)\tData 0.247 (0.247)\tLoss 0.4722 (0.4722)\tAcc 0.875 (0.875)\n",
      "Epoch: [68][2/5]\tTime 0.160 (0.219)\tData 0.136 (0.192)\tLoss 0.5238 (0.4980)\tAcc 0.812 (0.844)\n",
      "Epoch: [68][3/5]\tTime 0.077 (0.171)\tData 0.053 (0.146)\tLoss 1.1482 (0.7147)\tAcc 0.500 (0.729)\n",
      "Epoch: [68][4/5]\tTime 0.080 (0.149)\tData 0.056 (0.123)\tLoss 0.8528 (0.7493)\tAcc 0.750 (0.734)\n",
      "Epoch: [68][5/5]\tTime 0.076 (0.134)\tData 0.053 (0.109)\tLoss 0.8910 (0.7667)\tAcc 0.667 (0.726)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.360 (0.360)\tData 0.336 (0.336)\tLoss 0.2876 (0.2876)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.072 (0.216)\tData 0.050 (0.193)\tLoss 0.9479 (0.6178)\tAcc 0.500 (0.719)\n",
      "Epoch: [68][3/9]\tTime 0.074 (0.168)\tData 0.053 (0.146)\tLoss 0.4834 (0.5730)\tAcc 0.875 (0.771)\n",
      "Epoch: [68][4/9]\tTime 0.074 (0.145)\tData 0.052 (0.123)\tLoss 0.7333 (0.6131)\tAcc 0.688 (0.750)\n",
      "Epoch: [68][5/9]\tTime 0.072 (0.130)\tData 0.052 (0.109)\tLoss 0.9126 (0.6730)\tAcc 0.625 (0.725)\n",
      "Epoch: [68][6/9]\tTime 0.075 (0.121)\tData 0.054 (0.100)\tLoss 0.2579 (0.6038)\tAcc 1.000 (0.771)\n",
      "Epoch: [68][7/9]\tTime 0.072 (0.114)\tData 0.053 (0.093)\tLoss 0.8209 (0.6348)\tAcc 0.625 (0.750)\n",
      "Epoch: [68][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 0.9148 (0.6698)\tAcc 0.688 (0.742)\n",
      "Epoch: [68][9/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 0.3057 (0.6642)\tAcc 1.000 (0.746)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.367 (0.367)\tData 0.339 (0.339)\tLoss 0.8359 (0.8359)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][2/5]\tTime 0.074 (0.221)\tData 0.050 (0.195)\tLoss 0.5572 (0.6966)\tAcc 0.812 (0.781)\n",
      "Epoch: [69][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.7570 (0.7167)\tAcc 0.625 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 0.8990 (0.7623)\tAcc 0.562 (0.688)\n",
      "Epoch: [69][5/5]\tTime 0.081 (0.135)\tData 0.056 (0.110)\tLoss 0.4024 (0.7179)\tAcc 1.000 (0.726)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.323 (0.323)\tData 0.294 (0.294)\tLoss 0.3481 (0.3481)\tAcc 0.938 (0.938)\n",
      "Epoch: [69][2/9]\tTime 0.066 (0.195)\tData 0.046 (0.170)\tLoss 0.8836 (0.6158)\tAcc 0.625 (0.781)\n",
      "Epoch: [69][3/9]\tTime 0.074 (0.154)\tData 0.053 (0.131)\tLoss 0.6280 (0.6199)\tAcc 0.812 (0.792)\n",
      "Epoch: [69][4/9]\tTime 0.073 (0.134)\tData 0.053 (0.111)\tLoss 0.6651 (0.6312)\tAcc 0.750 (0.781)\n",
      "Epoch: [69][5/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.8336 (0.6717)\tAcc 0.750 (0.775)\n",
      "Epoch: [69][6/9]\tTime 0.073 (0.114)\tData 0.053 (0.092)\tLoss 0.2936 (0.6087)\tAcc 1.000 (0.812)\n",
      "Epoch: [69][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.8022 (0.6363)\tAcc 0.750 (0.804)\n",
      "Epoch: [69][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 0.9215 (0.6720)\tAcc 0.688 (0.789)\n",
      "Epoch: [69][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.3116 (0.6664)\tAcc 1.000 (0.792)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.353 (0.353)\tData 0.324 (0.324)\tLoss 0.7320 (0.7320)\tAcc 0.750 (0.750)\n",
      "Epoch: [70][2/5]\tTime 0.074 (0.213)\tData 0.050 (0.187)\tLoss 0.4148 (0.5734)\tAcc 0.938 (0.844)\n",
      "Epoch: [70][3/5]\tTime 0.077 (0.168)\tData 0.053 (0.142)\tLoss 0.7557 (0.6342)\tAcc 0.625 (0.771)\n",
      "Epoch: [70][4/5]\tTime 0.076 (0.145)\tData 0.054 (0.120)\tLoss 0.8703 (0.6932)\tAcc 0.688 (0.750)\n",
      "Epoch: [70][5/5]\tTime 0.080 (0.132)\tData 0.056 (0.107)\tLoss 0.8675 (0.7147)\tAcc 0.667 (0.740)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.357 (0.357)\tData 0.331 (0.331)\tLoss 0.3630 (0.3630)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/9]\tTime 0.070 (0.213)\tData 0.048 (0.190)\tLoss 0.9506 (0.6568)\tAcc 0.562 (0.750)\n",
      "Epoch: [70][3/9]\tTime 0.075 (0.167)\tData 0.053 (0.144)\tLoss 0.5266 (0.6134)\tAcc 0.875 (0.792)\n",
      "Epoch: [70][4/9]\tTime 0.072 (0.143)\tData 0.052 (0.121)\tLoss 0.7092 (0.6374)\tAcc 0.688 (0.766)\n",
      "Epoch: [70][5/9]\tTime 0.083 (0.131)\tData 0.061 (0.109)\tLoss 0.7457 (0.6590)\tAcc 0.812 (0.775)\n",
      "Epoch: [70][6/9]\tTime 0.072 (0.121)\tData 0.052 (0.099)\tLoss 0.3015 (0.5994)\tAcc 1.000 (0.812)\n",
      "Epoch: [70][7/9]\tTime 0.073 (0.114)\tData 0.054 (0.093)\tLoss 0.5487 (0.5922)\tAcc 0.875 (0.821)\n",
      "Epoch: [70][8/9]\tTime 0.075 (0.110)\tData 0.056 (0.088)\tLoss 1.1179 (0.6579)\tAcc 0.562 (0.789)\n",
      "Epoch: [70][9/9]\tTime 0.075 (0.106)\tData 0.054 (0.085)\tLoss 0.1980 (0.6508)\tAcc 1.000 (0.792)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.353 (0.353)\tData 0.324 (0.324)\tLoss 0.7369 (0.7369)\tAcc 0.625 (0.625)\n",
      "Epoch: [71][2/5]\tTime 0.073 (0.213)\tData 0.049 (0.187)\tLoss 1.0121 (0.8745)\tAcc 0.500 (0.562)\n",
      "Epoch: [71][3/5]\tTime 0.077 (0.168)\tData 0.053 (0.142)\tLoss 0.7982 (0.8491)\tAcc 0.625 (0.583)\n",
      "Epoch: [71][4/5]\tTime 0.077 (0.145)\tData 0.053 (0.120)\tLoss 0.4579 (0.7513)\tAcc 0.938 (0.672)\n",
      "Epoch: [71][5/5]\tTime 0.080 (0.132)\tData 0.056 (0.107)\tLoss 0.3846 (0.7061)\tAcc 1.000 (0.712)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.390 (0.390)\tData 0.362 (0.362)\tLoss 0.3303 (0.3303)\tAcc 0.938 (0.938)\n",
      "Epoch: [71][2/9]\tTime 0.068 (0.229)\tData 0.047 (0.205)\tLoss 1.0971 (0.7137)\tAcc 0.438 (0.688)\n",
      "Epoch: [71][3/9]\tTime 0.075 (0.177)\tData 0.053 (0.154)\tLoss 0.5481 (0.6585)\tAcc 0.938 (0.771)\n",
      "Epoch: [71][4/9]\tTime 0.072 (0.151)\tData 0.051 (0.128)\tLoss 0.6487 (0.6560)\tAcc 0.750 (0.766)\n",
      "Epoch: [71][5/9]\tTime 0.074 (0.136)\tData 0.054 (0.114)\tLoss 0.8879 (0.7024)\tAcc 0.688 (0.750)\n",
      "Epoch: [71][6/9]\tTime 0.074 (0.125)\tData 0.054 (0.104)\tLoss 0.3114 (0.6372)\tAcc 1.000 (0.792)\n",
      "Epoch: [71][7/9]\tTime 0.072 (0.118)\tData 0.053 (0.096)\tLoss 0.8187 (0.6632)\tAcc 0.625 (0.768)\n",
      "Epoch: [71][8/9]\tTime 0.075 (0.112)\tData 0.055 (0.091)\tLoss 0.8733 (0.6894)\tAcc 0.500 (0.734)\n",
      "Epoch: [71][9/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 0.2400 (0.6825)\tAcc 1.000 (0.738)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.318 (0.318)\tData 0.290 (0.290)\tLoss 0.7995 (0.7995)\tAcc 0.750 (0.750)\n",
      "Epoch: [72][2/5]\tTime 0.074 (0.196)\tData 0.050 (0.170)\tLoss 0.7749 (0.7872)\tAcc 0.688 (0.719)\n",
      "Epoch: [72][3/5]\tTime 0.077 (0.156)\tData 0.053 (0.131)\tLoss 0.7062 (0.7602)\tAcc 0.750 (0.729)\n",
      "Epoch: [72][4/5]\tTime 0.076 (0.136)\tData 0.053 (0.111)\tLoss 0.7691 (0.7624)\tAcc 0.625 (0.703)\n",
      "Epoch: [72][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.100)\tLoss 0.5384 (0.7348)\tAcc 0.889 (0.726)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.273 (0.273)\tData 0.249 (0.249)\tLoss 0.3237 (0.3237)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.086 (0.179)\tData 0.065 (0.157)\tLoss 0.8964 (0.6100)\tAcc 0.500 (0.719)\n",
      "Epoch: [72][3/9]\tTime 0.073 (0.144)\tData 0.053 (0.122)\tLoss 0.5736 (0.5979)\tAcc 0.750 (0.729)\n",
      "Epoch: [72][4/9]\tTime 0.074 (0.127)\tData 0.053 (0.105)\tLoss 0.6356 (0.6073)\tAcc 0.688 (0.719)\n",
      "Epoch: [72][5/9]\tTime 0.075 (0.116)\tData 0.054 (0.095)\tLoss 0.7784 (0.6415)\tAcc 0.625 (0.700)\n",
      "Epoch: [72][6/9]\tTime 0.072 (0.109)\tData 0.052 (0.087)\tLoss 0.2900 (0.5829)\tAcc 1.000 (0.750)\n",
      "Epoch: [72][7/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 0.9565 (0.6363)\tAcc 0.688 (0.741)\n",
      "Epoch: [72][8/9]\tTime 0.075 (0.100)\tData 0.054 (0.079)\tLoss 0.9977 (0.6815)\tAcc 0.625 (0.727)\n",
      "Epoch: [72][9/9]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.1787 (0.6737)\tAcc 1.000 (0.731)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.292 (0.292)\tData 0.263 (0.263)\tLoss 0.9818 (0.9818)\tAcc 0.625 (0.625)\n",
      "Epoch: [73][2/5]\tTime 0.075 (0.184)\tData 0.049 (0.156)\tLoss 0.6501 (0.8159)\tAcc 0.688 (0.656)\n",
      "Epoch: [73][3/5]\tTime 0.075 (0.148)\tData 0.051 (0.121)\tLoss 0.5622 (0.7314)\tAcc 0.750 (0.688)\n",
      "Epoch: [73][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.104)\tLoss 0.6685 (0.7157)\tAcc 0.812 (0.719)\n",
      "Epoch: [73][5/5]\tTime 0.080 (0.120)\tData 0.056 (0.094)\tLoss 0.4853 (0.6873)\tAcc 0.778 (0.726)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.350 (0.350)\tData 0.325 (0.325)\tLoss 0.3508 (0.3508)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.070 (0.210)\tData 0.048 (0.187)\tLoss 0.8707 (0.6107)\tAcc 0.500 (0.719)\n",
      "Epoch: [73][3/9]\tTime 0.075 (0.165)\tData 0.053 (0.142)\tLoss 0.6917 (0.6377)\tAcc 0.750 (0.729)\n",
      "Epoch: [73][4/9]\tTime 0.074 (0.142)\tData 0.052 (0.119)\tLoss 0.6097 (0.6307)\tAcc 0.750 (0.734)\n",
      "Epoch: [73][5/9]\tTime 0.072 (0.128)\tData 0.052 (0.106)\tLoss 0.8529 (0.6752)\tAcc 0.688 (0.725)\n",
      "Epoch: [73][6/9]\tTime 0.074 (0.119)\tData 0.054 (0.097)\tLoss 0.3043 (0.6133)\tAcc 1.000 (0.771)\n",
      "Epoch: [73][7/9]\tTime 0.072 (0.113)\tData 0.053 (0.091)\tLoss 0.5084 (0.5984)\tAcc 0.812 (0.777)\n",
      "Epoch: [73][8/9]\tTime 0.075 (0.108)\tData 0.055 (0.086)\tLoss 0.9686 (0.6446)\tAcc 0.562 (0.750)\n",
      "Epoch: [73][9/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 0.1975 (0.6378)\tAcc 1.000 (0.754)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.307 (0.307)\tData 0.277 (0.277)\tLoss 1.0700 (1.0700)\tAcc 0.500 (0.500)\n",
      "Epoch: [74][2/5]\tTime 0.075 (0.191)\tData 0.049 (0.163)\tLoss 0.8749 (0.9725)\tAcc 0.688 (0.594)\n",
      "Epoch: [74][3/5]\tTime 0.074 (0.152)\tData 0.050 (0.125)\tLoss 0.8044 (0.9164)\tAcc 0.688 (0.625)\n",
      "Epoch: [74][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.107)\tLoss 0.5987 (0.8370)\tAcc 0.750 (0.656)\n",
      "Epoch: [74][5/5]\tTime 0.080 (0.123)\tData 0.055 (0.097)\tLoss 0.3891 (0.7818)\tAcc 1.000 (0.699)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.335 (0.335)\tData 0.309 (0.309)\tLoss 0.3020 (0.3020)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/9]\tTime 0.070 (0.203)\tData 0.049 (0.179)\tLoss 0.9591 (0.6306)\tAcc 0.438 (0.688)\n",
      "Epoch: [74][3/9]\tTime 0.073 (0.160)\tData 0.053 (0.137)\tLoss 0.7547 (0.6719)\tAcc 0.750 (0.708)\n",
      "Epoch: [74][4/9]\tTime 0.075 (0.138)\tData 0.053 (0.116)\tLoss 0.6285 (0.6611)\tAcc 0.688 (0.703)\n",
      "Epoch: [74][5/9]\tTime 0.074 (0.126)\tData 0.053 (0.103)\tLoss 0.7523 (0.6793)\tAcc 0.688 (0.700)\n",
      "Epoch: [74][6/9]\tTime 0.073 (0.117)\tData 0.052 (0.095)\tLoss 0.2500 (0.6078)\tAcc 1.000 (0.750)\n",
      "Epoch: [74][7/9]\tTime 0.073 (0.110)\tData 0.053 (0.089)\tLoss 0.7800 (0.6324)\tAcc 0.625 (0.732)\n",
      "Epoch: [74][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 1.0984 (0.6906)\tAcc 0.438 (0.695)\n",
      "Epoch: [74][9/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 0.3873 (0.6860)\tAcc 1.000 (0.700)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.274 (0.274)\tData 0.244 (0.244)\tLoss 0.6995 (0.6995)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][2/5]\tTime 0.072 (0.173)\tData 0.047 (0.146)\tLoss 0.8540 (0.7768)\tAcc 0.625 (0.656)\n",
      "Epoch: [75][3/5]\tTime 0.077 (0.141)\tData 0.053 (0.115)\tLoss 0.6845 (0.7460)\tAcc 0.688 (0.667)\n",
      "Epoch: [75][4/5]\tTime 0.077 (0.125)\tData 0.053 (0.099)\tLoss 0.9090 (0.7868)\tAcc 0.562 (0.641)\n",
      "Epoch: [75][5/5]\tTime 0.078 (0.116)\tData 0.055 (0.090)\tLoss 0.4543 (0.7458)\tAcc 0.778 (0.658)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.305 (0.305)\tData 0.279 (0.279)\tLoss 0.4418 (0.4418)\tAcc 0.875 (0.875)\n",
      "Epoch: [75][2/9]\tTime 0.070 (0.187)\tData 0.048 (0.164)\tLoss 0.8939 (0.6678)\tAcc 0.562 (0.719)\n",
      "Epoch: [75][3/9]\tTime 0.073 (0.149)\tData 0.053 (0.127)\tLoss 0.5744 (0.6367)\tAcc 0.812 (0.750)\n",
      "Epoch: [75][4/9]\tTime 0.076 (0.131)\tData 0.053 (0.108)\tLoss 0.5729 (0.6207)\tAcc 0.688 (0.734)\n",
      "Epoch: [75][5/9]\tTime 0.071 (0.119)\tData 0.051 (0.097)\tLoss 0.9022 (0.6770)\tAcc 0.625 (0.713)\n",
      "Epoch: [75][6/9]\tTime 0.075 (0.112)\tData 0.055 (0.090)\tLoss 0.2762 (0.6102)\tAcc 1.000 (0.760)\n",
      "Epoch: [75][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.085)\tLoss 0.5047 (0.5952)\tAcc 0.812 (0.768)\n",
      "Epoch: [75][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.081)\tLoss 0.8614 (0.6284)\tAcc 0.688 (0.758)\n",
      "Epoch: [75][9/9]\tTime 0.074 (0.099)\tData 0.054 (0.078)\tLoss 0.3000 (0.6234)\tAcc 1.000 (0.762)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.308 (0.308)\tData 0.277 (0.277)\tLoss 0.8178 (0.8178)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][2/5]\tTime 0.072 (0.190)\tData 0.048 (0.162)\tLoss 0.6831 (0.7505)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][3/5]\tTime 0.077 (0.152)\tData 0.053 (0.126)\tLoss 0.7256 (0.7422)\tAcc 0.750 (0.708)\n",
      "Epoch: [76][4/5]\tTime 0.078 (0.133)\tData 0.054 (0.108)\tLoss 0.5601 (0.6967)\tAcc 0.812 (0.734)\n",
      "Epoch: [76][5/5]\tTime 0.080 (0.123)\tData 0.055 (0.097)\tLoss 0.7501 (0.7033)\tAcc 0.667 (0.726)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.377 (0.377)\tData 0.354 (0.354)\tLoss 0.2856 (0.2856)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/9]\tTime 0.072 (0.225)\tData 0.051 (0.202)\tLoss 0.9491 (0.6174)\tAcc 0.562 (0.750)\n",
      "Epoch: [76][3/9]\tTime 0.075 (0.175)\tData 0.054 (0.153)\tLoss 0.7623 (0.6657)\tAcc 0.688 (0.729)\n",
      "Epoch: [76][4/9]\tTime 0.072 (0.149)\tData 0.052 (0.127)\tLoss 0.6489 (0.6615)\tAcc 0.750 (0.734)\n",
      "Epoch: [76][5/9]\tTime 0.073 (0.134)\tData 0.054 (0.113)\tLoss 0.8224 (0.6937)\tAcc 0.750 (0.738)\n",
      "Epoch: [76][6/9]\tTime 0.075 (0.124)\tData 0.055 (0.103)\tLoss 0.2990 (0.6279)\tAcc 1.000 (0.781)\n",
      "Epoch: [76][7/9]\tTime 0.075 (0.117)\tData 0.054 (0.096)\tLoss 0.7877 (0.6507)\tAcc 0.625 (0.759)\n",
      "Epoch: [76][8/9]\tTime 0.074 (0.112)\tData 0.055 (0.091)\tLoss 1.0351 (0.6988)\tAcc 0.562 (0.734)\n",
      "Epoch: [76][9/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 0.2194 (0.6914)\tAcc 1.000 (0.738)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.404 (0.404)\tData 0.376 (0.376)\tLoss 0.8767 (0.8767)\tAcc 0.625 (0.625)\n",
      "Epoch: [77][2/5]\tTime 0.075 (0.239)\tData 0.051 (0.214)\tLoss 0.8076 (0.8422)\tAcc 0.750 (0.688)\n",
      "Epoch: [77][3/5]\tTime 0.076 (0.185)\tData 0.053 (0.160)\tLoss 0.6247 (0.7697)\tAcc 0.750 (0.708)\n",
      "Epoch: [77][4/5]\tTime 0.077 (0.158)\tData 0.054 (0.133)\tLoss 0.7143 (0.7558)\tAcc 0.625 (0.688)\n",
      "Epoch: [77][5/5]\tTime 0.080 (0.142)\tData 0.056 (0.118)\tLoss 0.7247 (0.7520)\tAcc 0.778 (0.699)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.337 (0.337)\tData 0.310 (0.310)\tLoss 0.3762 (0.3762)\tAcc 0.875 (0.875)\n",
      "Epoch: [77][2/9]\tTime 0.079 (0.208)\tData 0.058 (0.184)\tLoss 0.8926 (0.6344)\tAcc 0.438 (0.656)\n",
      "Epoch: [77][3/9]\tTime 0.074 (0.163)\tData 0.053 (0.141)\tLoss 0.5469 (0.6052)\tAcc 0.812 (0.708)\n",
      "Epoch: [77][4/9]\tTime 0.074 (0.141)\tData 0.053 (0.119)\tLoss 0.6179 (0.6084)\tAcc 0.750 (0.719)\n",
      "Epoch: [77][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.106)\tLoss 0.9960 (0.6859)\tAcc 0.688 (0.713)\n",
      "Epoch: [77][6/9]\tTime 0.074 (0.118)\tData 0.054 (0.097)\tLoss 0.2938 (0.6206)\tAcc 1.000 (0.760)\n",
      "Epoch: [77][7/9]\tTime 0.072 (0.112)\tData 0.054 (0.091)\tLoss 0.6630 (0.6266)\tAcc 0.688 (0.750)\n",
      "Epoch: [77][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.087)\tLoss 1.0652 (0.6814)\tAcc 0.625 (0.734)\n",
      "Epoch: [77][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.2541 (0.6749)\tAcc 1.000 (0.738)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.298 (0.298)\tData 0.268 (0.268)\tLoss 0.6271 (0.6271)\tAcc 0.812 (0.812)\n",
      "Epoch: [78][2/5]\tTime 0.074 (0.186)\tData 0.048 (0.158)\tLoss 0.6063 (0.6167)\tAcc 0.812 (0.812)\n",
      "Epoch: [78][3/5]\tTime 0.075 (0.149)\tData 0.051 (0.122)\tLoss 0.7377 (0.6571)\tAcc 0.625 (0.750)\n",
      "Epoch: [78][4/5]\tTime 0.077 (0.131)\tData 0.053 (0.105)\tLoss 0.6980 (0.6673)\tAcc 0.688 (0.734)\n",
      "Epoch: [78][5/5]\tTime 0.078 (0.121)\tData 0.055 (0.095)\tLoss 0.8628 (0.6914)\tAcc 0.667 (0.726)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.305 (0.305)\tData 0.279 (0.279)\tLoss 0.2862 (0.2862)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/9]\tTime 0.070 (0.187)\tData 0.049 (0.164)\tLoss 0.9854 (0.6358)\tAcc 0.438 (0.688)\n",
      "Epoch: [78][3/9]\tTime 0.074 (0.149)\tData 0.053 (0.127)\tLoss 0.5851 (0.6189)\tAcc 0.812 (0.729)\n",
      "Epoch: [78][4/9]\tTime 0.075 (0.131)\tData 0.053 (0.108)\tLoss 0.6446 (0.6253)\tAcc 0.750 (0.734)\n",
      "Epoch: [78][5/9]\tTime 0.073 (0.119)\tData 0.053 (0.097)\tLoss 0.8840 (0.6771)\tAcc 0.625 (0.713)\n",
      "Epoch: [78][6/9]\tTime 0.074 (0.112)\tData 0.054 (0.090)\tLoss 0.2315 (0.6028)\tAcc 1.000 (0.760)\n",
      "Epoch: [78][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.085)\tLoss 0.7383 (0.6222)\tAcc 0.688 (0.750)\n",
      "Epoch: [78][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.081)\tLoss 1.0865 (0.6802)\tAcc 0.562 (0.727)\n",
      "Epoch: [78][9/9]\tTime 0.074 (0.099)\tData 0.055 (0.078)\tLoss 0.2330 (0.6733)\tAcc 1.000 (0.731)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.357 (0.357)\tData 0.330 (0.330)\tLoss 0.4941 (0.4941)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][2/5]\tTime 0.075 (0.216)\tData 0.051 (0.191)\tLoss 0.5042 (0.4992)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][3/5]\tTime 0.077 (0.170)\tData 0.054 (0.145)\tLoss 0.6756 (0.5580)\tAcc 0.812 (0.812)\n",
      "Epoch: [79][4/5]\tTime 0.077 (0.147)\tData 0.054 (0.122)\tLoss 0.7305 (0.6011)\tAcc 0.750 (0.797)\n",
      "Epoch: [79][5/5]\tTime 0.081 (0.133)\tData 0.056 (0.109)\tLoss 1.2154 (0.6768)\tAcc 0.444 (0.753)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.287 (0.287)\tData 0.263 (0.263)\tLoss 0.3361 (0.3361)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.088 (0.187)\tData 0.065 (0.164)\tLoss 0.9594 (0.6477)\tAcc 0.562 (0.750)\n",
      "Epoch: [79][3/9]\tTime 0.072 (0.149)\tData 0.051 (0.126)\tLoss 0.5100 (0.6018)\tAcc 0.875 (0.792)\n",
      "Epoch: [79][4/9]\tTime 0.075 (0.130)\tData 0.053 (0.108)\tLoss 0.6344 (0.6100)\tAcc 0.688 (0.766)\n",
      "Epoch: [79][5/9]\tTime 0.075 (0.119)\tData 0.053 (0.097)\tLoss 0.8951 (0.6670)\tAcc 0.688 (0.750)\n",
      "Epoch: [79][6/9]\tTime 0.073 (0.112)\tData 0.053 (0.090)\tLoss 0.2690 (0.6007)\tAcc 1.000 (0.792)\n",
      "Epoch: [79][7/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 0.6306 (0.6049)\tAcc 0.812 (0.795)\n",
      "Epoch: [79][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.081)\tLoss 0.9061 (0.6426)\tAcc 0.500 (0.758)\n",
      "Epoch: [79][9/9]\tTime 0.074 (0.099)\tData 0.054 (0.078)\tLoss 0.2178 (0.6360)\tAcc 1.000 (0.762)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.359 (0.359)\tData 0.332 (0.332)\tLoss 0.6785 (0.6785)\tAcc 0.750 (0.750)\n",
      "Epoch: [80][2/5]\tTime 0.076 (0.218)\tData 0.051 (0.192)\tLoss 0.6478 (0.6632)\tAcc 0.688 (0.719)\n",
      "Epoch: [80][3/5]\tTime 0.076 (0.170)\tData 0.052 (0.145)\tLoss 0.8480 (0.7248)\tAcc 0.688 (0.708)\n",
      "Epoch: [80][4/5]\tTime 0.077 (0.147)\tData 0.054 (0.122)\tLoss 0.7590 (0.7333)\tAcc 0.688 (0.703)\n",
      "Epoch: [80][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.109)\tLoss 0.7238 (0.7322)\tAcc 0.778 (0.712)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.354 (0.354)\tData 0.330 (0.330)\tLoss 0.4234 (0.4234)\tAcc 0.875 (0.875)\n",
      "Epoch: [80][2/9]\tTime 0.071 (0.213)\tData 0.050 (0.190)\tLoss 0.8767 (0.6501)\tAcc 0.500 (0.688)\n",
      "Epoch: [80][3/9]\tTime 0.074 (0.167)\tData 0.053 (0.144)\tLoss 0.7006 (0.6669)\tAcc 0.750 (0.708)\n",
      "Epoch: [80][4/9]\tTime 0.072 (0.143)\tData 0.052 (0.121)\tLoss 0.6876 (0.6721)\tAcc 0.625 (0.688)\n",
      "Epoch: [80][5/9]\tTime 0.074 (0.129)\tData 0.054 (0.108)\tLoss 1.1236 (0.7624)\tAcc 0.688 (0.688)\n",
      "Epoch: [80][6/9]\tTime 0.075 (0.120)\tData 0.054 (0.099)\tLoss 0.2432 (0.6759)\tAcc 1.000 (0.740)\n",
      "Epoch: [80][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.5518 (0.6581)\tAcc 0.812 (0.750)\n",
      "Epoch: [80][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.088)\tLoss 0.9478 (0.6943)\tAcc 0.625 (0.734)\n",
      "Epoch: [80][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 0.2482 (0.6875)\tAcc 1.000 (0.738)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.302 (0.302)\tData 0.260 (0.260)\tLoss 0.7892 (0.7892)\tAcc 0.688 (0.688)\n",
      "Epoch: [81][2/5]\tTime 0.060 (0.181)\tData 0.036 (0.148)\tLoss 0.6975 (0.7433)\tAcc 0.750 (0.719)\n",
      "Epoch: [81][3/5]\tTime 0.077 (0.147)\tData 0.053 (0.117)\tLoss 0.5473 (0.6780)\tAcc 0.875 (0.771)\n",
      "Epoch: [81][4/5]\tTime 0.077 (0.129)\tData 0.053 (0.101)\tLoss 0.8128 (0.7117)\tAcc 0.688 (0.750)\n",
      "Epoch: [81][5/5]\tTime 0.081 (0.119)\tData 0.056 (0.092)\tLoss 0.6370 (0.7025)\tAcc 0.667 (0.740)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.284 (0.284)\tData 0.260 (0.260)\tLoss 0.3270 (0.3270)\tAcc 0.875 (0.875)\n",
      "Epoch: [81][2/9]\tTime 0.072 (0.178)\tData 0.051 (0.155)\tLoss 1.0141 (0.6705)\tAcc 0.438 (0.656)\n",
      "Epoch: [81][3/9]\tTime 0.073 (0.143)\tData 0.053 (0.121)\tLoss 0.8388 (0.7266)\tAcc 0.625 (0.646)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.075 (0.126)\tData 0.054 (0.104)\tLoss 0.5466 (0.6816)\tAcc 0.812 (0.688)\n",
      "Epoch: [81][5/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.6804 (0.6814)\tAcc 0.750 (0.700)\n",
      "Epoch: [81][6/9]\tTime 0.074 (0.108)\tData 0.054 (0.087)\tLoss 0.2689 (0.6126)\tAcc 1.000 (0.750)\n",
      "Epoch: [81][7/9]\tTime 0.072 (0.103)\tData 0.053 (0.082)\tLoss 0.6687 (0.6206)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][8/9]\tTime 0.076 (0.100)\tData 0.056 (0.079)\tLoss 1.1495 (0.6867)\tAcc 0.500 (0.719)\n",
      "Epoch: [81][9/9]\tTime 0.072 (0.097)\tData 0.053 (0.076)\tLoss 0.1912 (0.6791)\tAcc 1.000 (0.723)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.351 (0.351)\tData 0.322 (0.322)\tLoss 0.6693 (0.6693)\tAcc 0.750 (0.750)\n",
      "Epoch: [82][2/5]\tTime 0.073 (0.212)\tData 0.049 (0.185)\tLoss 0.7145 (0.6919)\tAcc 0.688 (0.719)\n",
      "Epoch: [82][3/5]\tTime 0.076 (0.167)\tData 0.053 (0.141)\tLoss 0.8413 (0.7417)\tAcc 0.750 (0.729)\n",
      "Epoch: [82][4/5]\tTime 0.078 (0.145)\tData 0.054 (0.120)\tLoss 0.9645 (0.7974)\tAcc 0.688 (0.719)\n",
      "Epoch: [82][5/5]\tTime 0.079 (0.131)\tData 0.055 (0.107)\tLoss 0.7084 (0.7864)\tAcc 0.667 (0.712)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.285 (0.285)\tData 0.261 (0.261)\tLoss 0.3682 (0.3682)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/9]\tTime 0.072 (0.178)\tData 0.050 (0.156)\tLoss 0.8970 (0.6326)\tAcc 0.562 (0.750)\n",
      "Epoch: [82][3/9]\tTime 0.074 (0.143)\tData 0.052 (0.121)\tLoss 0.6595 (0.6416)\tAcc 0.812 (0.771)\n",
      "Epoch: [82][4/9]\tTime 0.074 (0.126)\tData 0.052 (0.104)\tLoss 0.6398 (0.6411)\tAcc 0.625 (0.734)\n",
      "Epoch: [82][5/9]\tTime 0.073 (0.115)\tData 0.053 (0.094)\tLoss 0.9076 (0.6944)\tAcc 0.688 (0.725)\n",
      "Epoch: [82][6/9]\tTime 0.074 (0.109)\tData 0.054 (0.087)\tLoss 0.2418 (0.6190)\tAcc 1.000 (0.771)\n",
      "Epoch: [82][7/9]\tTime 0.072 (0.103)\tData 0.053 (0.082)\tLoss 0.7651 (0.6399)\tAcc 0.875 (0.786)\n",
      "Epoch: [82][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 0.9439 (0.6779)\tAcc 0.625 (0.766)\n",
      "Epoch: [82][9/9]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.2171 (0.6708)\tAcc 1.000 (0.769)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.360 (0.360)\tData 0.328 (0.328)\tLoss 0.6534 (0.6534)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][2/5]\tTime 0.075 (0.217)\tData 0.049 (0.188)\tLoss 0.6793 (0.6664)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][3/5]\tTime 0.086 (0.173)\tData 0.060 (0.146)\tLoss 0.9665 (0.7664)\tAcc 0.625 (0.708)\n",
      "Epoch: [83][4/5]\tTime 0.080 (0.150)\tData 0.054 (0.123)\tLoss 0.4748 (0.6935)\tAcc 0.875 (0.750)\n",
      "Epoch: [83][5/5]\tTime 0.078 (0.136)\tData 0.053 (0.109)\tLoss 0.8738 (0.7157)\tAcc 0.667 (0.740)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.365 (0.365)\tData 0.327 (0.327)\tLoss 0.3348 (0.3348)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.072 (0.219)\tData 0.048 (0.188)\tLoss 0.9248 (0.6298)\tAcc 0.500 (0.719)\n",
      "Epoch: [83][3/9]\tTime 0.086 (0.174)\tData 0.060 (0.145)\tLoss 0.7573 (0.6723)\tAcc 0.750 (0.729)\n",
      "Epoch: [83][4/9]\tTime 0.073 (0.149)\tData 0.050 (0.121)\tLoss 0.6198 (0.6592)\tAcc 0.688 (0.719)\n",
      "Epoch: [83][5/9]\tTime 0.079 (0.135)\tData 0.058 (0.109)\tLoss 0.8140 (0.6901)\tAcc 0.625 (0.700)\n",
      "Epoch: [83][6/9]\tTime 0.080 (0.126)\tData 0.060 (0.101)\tLoss 0.2688 (0.6199)\tAcc 1.000 (0.750)\n",
      "Epoch: [83][7/9]\tTime 0.081 (0.119)\tData 0.061 (0.095)\tLoss 0.6974 (0.6310)\tAcc 0.688 (0.741)\n",
      "Epoch: [83][8/9]\tTime 0.077 (0.114)\tData 0.056 (0.090)\tLoss 1.1147 (0.6914)\tAcc 0.500 (0.711)\n",
      "Epoch: [83][9/9]\tTime 0.080 (0.110)\tData 0.060 (0.087)\tLoss 0.2093 (0.6840)\tAcc 1.000 (0.715)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.446 (0.446)\tData 0.418 (0.418)\tLoss 0.7378 (0.7378)\tAcc 0.625 (0.625)\n",
      "Epoch: [84][2/5]\tTime 0.078 (0.262)\tData 0.051 (0.235)\tLoss 0.7926 (0.7652)\tAcc 0.750 (0.688)\n",
      "Epoch: [84][3/5]\tTime 0.077 (0.200)\tData 0.052 (0.174)\tLoss 0.3946 (0.6417)\tAcc 0.938 (0.771)\n",
      "Epoch: [84][4/5]\tTime 0.088 (0.172)\tData 0.061 (0.146)\tLoss 0.8272 (0.6880)\tAcc 0.625 (0.734)\n",
      "Epoch: [84][5/5]\tTime 0.079 (0.154)\tData 0.053 (0.127)\tLoss 0.7955 (0.7013)\tAcc 0.667 (0.726)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.415 (0.415)\tData 0.383 (0.383)\tLoss 0.2897 (0.2897)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/9]\tTime 0.087 (0.251)\tData 0.043 (0.213)\tLoss 0.9138 (0.6018)\tAcc 0.438 (0.688)\n",
      "Epoch: [84][3/9]\tTime 0.075 (0.193)\tData 0.041 (0.156)\tLoss 0.6724 (0.6253)\tAcc 0.750 (0.708)\n",
      "Epoch: [84][4/9]\tTime 0.075 (0.163)\tData 0.053 (0.130)\tLoss 0.6633 (0.6348)\tAcc 0.750 (0.719)\n",
      "Epoch: [84][5/9]\tTime 0.075 (0.146)\tData 0.054 (0.115)\tLoss 0.8386 (0.6756)\tAcc 0.688 (0.713)\n",
      "Epoch: [84][6/9]\tTime 0.075 (0.134)\tData 0.054 (0.105)\tLoss 0.2136 (0.5986)\tAcc 1.000 (0.760)\n",
      "Epoch: [84][7/9]\tTime 0.081 (0.126)\tData 0.060 (0.098)\tLoss 0.6620 (0.6076)\tAcc 0.812 (0.768)\n",
      "Epoch: [84][8/9]\tTime 0.082 (0.121)\tData 0.061 (0.094)\tLoss 1.0322 (0.6607)\tAcc 0.500 (0.734)\n",
      "Epoch: [84][9/9]\tTime 0.078 (0.116)\tData 0.058 (0.090)\tLoss 0.2923 (0.6550)\tAcc 1.000 (0.738)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.406 (0.406)\tData 0.374 (0.374)\tLoss 0.7939 (0.7939)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/5]\tTime 0.081 (0.243)\tData 0.056 (0.215)\tLoss 0.6804 (0.7371)\tAcc 0.750 (0.719)\n",
      "Epoch: [85][3/5]\tTime 0.084 (0.190)\tData 0.059 (0.163)\tLoss 0.8637 (0.7793)\tAcc 0.625 (0.688)\n",
      "Epoch: [85][4/5]\tTime 0.080 (0.163)\tData 0.054 (0.136)\tLoss 0.7234 (0.7653)\tAcc 0.750 (0.703)\n",
      "Epoch: [85][5/5]\tTime 0.078 (0.146)\tData 0.053 (0.119)\tLoss 0.8202 (0.7721)\tAcc 0.667 (0.699)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.474 (0.474)\tData 0.449 (0.449)\tLoss 0.2889 (0.2889)\tAcc 1.000 (1.000)\n",
      "Epoch: [85][2/9]\tTime 0.080 (0.277)\tData 0.052 (0.250)\tLoss 0.8532 (0.5710)\tAcc 0.562 (0.781)\n",
      "Epoch: [85][3/9]\tTime 0.077 (0.210)\tData 0.046 (0.182)\tLoss 0.6648 (0.6023)\tAcc 0.812 (0.792)\n",
      "Epoch: [85][4/9]\tTime 0.063 (0.174)\tData 0.043 (0.147)\tLoss 0.7390 (0.6365)\tAcc 0.688 (0.766)\n",
      "Epoch: [85][5/9]\tTime 0.074 (0.154)\tData 0.054 (0.129)\tLoss 0.8031 (0.6698)\tAcc 0.750 (0.762)\n",
      "Epoch: [85][6/9]\tTime 0.076 (0.141)\tData 0.055 (0.117)\tLoss 0.2394 (0.5981)\tAcc 1.000 (0.802)\n",
      "Epoch: [85][7/9]\tTime 0.074 (0.131)\tData 0.053 (0.107)\tLoss 0.8442 (0.6332)\tAcc 0.562 (0.768)\n",
      "Epoch: [85][8/9]\tTime 0.074 (0.124)\tData 0.054 (0.101)\tLoss 0.9972 (0.6787)\tAcc 0.562 (0.742)\n",
      "Epoch: [85][9/9]\tTime 0.080 (0.119)\tData 0.059 (0.096)\tLoss 0.2252 (0.6718)\tAcc 1.000 (0.746)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.346 (0.346)\tData 0.312 (0.312)\tLoss 0.7592 (0.7592)\tAcc 0.625 (0.625)\n",
      "Epoch: [86][2/5]\tTime 0.070 (0.208)\tData 0.046 (0.179)\tLoss 1.0779 (0.9185)\tAcc 0.625 (0.625)\n",
      "Epoch: [86][3/5]\tTime 0.077 (0.164)\tData 0.053 (0.137)\tLoss 0.6737 (0.8369)\tAcc 0.750 (0.667)\n",
      "Epoch: [86][4/5]\tTime 0.077 (0.142)\tData 0.053 (0.116)\tLoss 0.6894 (0.8000)\tAcc 0.750 (0.688)\n",
      "Epoch: [86][5/5]\tTime 0.080 (0.130)\tData 0.057 (0.104)\tLoss 0.7040 (0.7882)\tAcc 0.667 (0.685)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.360 (0.360)\tData 0.322 (0.322)\tLoss 0.3789 (0.3789)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.081 (0.221)\tData 0.054 (0.188)\tLoss 0.9631 (0.6710)\tAcc 0.500 (0.719)\n",
      "Epoch: [86][3/9]\tTime 0.074 (0.172)\tData 0.053 (0.143)\tLoss 0.6559 (0.6660)\tAcc 0.688 (0.708)\n",
      "Epoch: [86][4/9]\tTime 0.076 (0.148)\tData 0.054 (0.121)\tLoss 0.6491 (0.6617)\tAcc 0.625 (0.688)\n",
      "Epoch: [86][5/9]\tTime 0.079 (0.134)\tData 0.058 (0.108)\tLoss 0.9809 (0.7256)\tAcc 0.688 (0.688)\n",
      "Epoch: [86][6/9]\tTime 0.077 (0.125)\tData 0.056 (0.100)\tLoss 0.3028 (0.6551)\tAcc 1.000 (0.740)\n",
      "Epoch: [86][7/9]\tTime 0.075 (0.117)\tData 0.054 (0.093)\tLoss 0.5407 (0.6388)\tAcc 0.812 (0.750)\n",
      "Epoch: [86][8/9]\tTime 0.075 (0.112)\tData 0.054 (0.088)\tLoss 1.0555 (0.6908)\tAcc 0.562 (0.727)\n",
      "Epoch: [86][9/9]\tTime 0.073 (0.108)\tData 0.054 (0.084)\tLoss 0.4175 (0.6866)\tAcc 1.000 (0.731)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.319 (0.319)\tData 0.290 (0.290)\tLoss 0.5784 (0.5784)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][2/5]\tTime 0.078 (0.198)\tData 0.052 (0.171)\tLoss 0.5669 (0.5727)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][3/5]\tTime 0.078 (0.158)\tData 0.053 (0.132)\tLoss 1.1413 (0.7622)\tAcc 0.562 (0.688)\n",
      "Epoch: [87][4/5]\tTime 0.076 (0.138)\tData 0.053 (0.112)\tLoss 0.9370 (0.8059)\tAcc 0.625 (0.672)\n",
      "Epoch: [87][5/5]\tTime 0.080 (0.126)\tData 0.057 (0.101)\tLoss 0.6255 (0.7837)\tAcc 0.778 (0.685)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.362 (0.362)\tData 0.338 (0.338)\tLoss 0.3260 (0.3260)\tAcc 1.000 (1.000)\n",
      "Epoch: [87][2/9]\tTime 0.071 (0.216)\tData 0.050 (0.194)\tLoss 0.9161 (0.6210)\tAcc 0.500 (0.750)\n",
      "Epoch: [87][3/9]\tTime 0.074 (0.169)\tData 0.053 (0.147)\tLoss 0.6305 (0.6242)\tAcc 0.812 (0.771)\n",
      "Epoch: [87][4/9]\tTime 0.072 (0.145)\tData 0.052 (0.123)\tLoss 0.6524 (0.6312)\tAcc 0.688 (0.750)\n",
      "Epoch: [87][5/9]\tTime 0.074 (0.131)\tData 0.054 (0.109)\tLoss 0.7773 (0.6604)\tAcc 0.688 (0.738)\n",
      "Epoch: [87][6/9]\tTime 0.075 (0.121)\tData 0.054 (0.100)\tLoss 0.2891 (0.5986)\tAcc 1.000 (0.781)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.073 (0.114)\tData 0.054 (0.094)\tLoss 0.5730 (0.5949)\tAcc 0.812 (0.786)\n",
      "Epoch: [87][8/9]\tTime 0.076 (0.109)\tData 0.056 (0.089)\tLoss 0.9559 (0.6400)\tAcc 0.562 (0.758)\n",
      "Epoch: [87][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.3232 (0.6352)\tAcc 1.000 (0.762)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.373 (0.373)\tData 0.345 (0.345)\tLoss 0.7475 (0.7475)\tAcc 0.750 (0.750)\n",
      "Epoch: [88][2/5]\tTime 0.076 (0.224)\tData 0.051 (0.198)\tLoss 0.9814 (0.8645)\tAcc 0.562 (0.656)\n",
      "Epoch: [88][3/5]\tTime 0.075 (0.175)\tData 0.052 (0.149)\tLoss 0.5929 (0.7739)\tAcc 0.688 (0.667)\n",
      "Epoch: [88][4/5]\tTime 0.077 (0.150)\tData 0.054 (0.126)\tLoss 0.8873 (0.8023)\tAcc 0.625 (0.656)\n",
      "Epoch: [88][5/5]\tTime 0.080 (0.136)\tData 0.056 (0.112)\tLoss 0.3809 (0.7503)\tAcc 0.889 (0.685)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.337 (0.337)\tData 0.312 (0.312)\tLoss 0.3624 (0.3624)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/9]\tTime 0.070 (0.204)\tData 0.049 (0.181)\tLoss 0.9380 (0.6502)\tAcc 0.562 (0.750)\n",
      "Epoch: [88][3/9]\tTime 0.073 (0.160)\tData 0.053 (0.138)\tLoss 0.4808 (0.5938)\tAcc 0.812 (0.771)\n",
      "Epoch: [88][4/9]\tTime 0.073 (0.138)\tData 0.053 (0.117)\tLoss 0.6165 (0.5994)\tAcc 0.750 (0.766)\n",
      "Epoch: [88][5/9]\tTime 0.076 (0.126)\tData 0.056 (0.105)\tLoss 0.8046 (0.6405)\tAcc 0.750 (0.762)\n",
      "Epoch: [88][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.3262 (0.5881)\tAcc 1.000 (0.802)\n",
      "Epoch: [88][7/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 0.6844 (0.6018)\tAcc 0.750 (0.795)\n",
      "Epoch: [88][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.086)\tLoss 0.8144 (0.6284)\tAcc 0.625 (0.773)\n",
      "Epoch: [88][9/9]\tTime 0.075 (0.103)\tData 0.055 (0.083)\tLoss 0.2209 (0.6221)\tAcc 1.000 (0.777)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.314 (0.314)\tData 0.283 (0.283)\tLoss 0.5639 (0.5639)\tAcc 0.812 (0.812)\n",
      "Epoch: [89][2/5]\tTime 0.071 (0.193)\tData 0.047 (0.165)\tLoss 0.4700 (0.5170)\tAcc 0.875 (0.844)\n",
      "Epoch: [89][3/5]\tTime 0.076 (0.154)\tData 0.053 (0.128)\tLoss 0.6347 (0.5562)\tAcc 0.750 (0.812)\n",
      "Epoch: [89][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.109)\tLoss 0.8191 (0.6219)\tAcc 0.688 (0.781)\n",
      "Epoch: [89][5/5]\tTime 0.079 (0.123)\tData 0.056 (0.099)\tLoss 0.9717 (0.6650)\tAcc 0.444 (0.740)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.375 (0.375)\tData 0.351 (0.351)\tLoss 0.3520 (0.3520)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.073 (0.224)\tData 0.051 (0.201)\tLoss 0.9929 (0.6725)\tAcc 0.500 (0.719)\n",
      "Epoch: [89][3/9]\tTime 0.071 (0.173)\tData 0.051 (0.151)\tLoss 0.7657 (0.7035)\tAcc 0.688 (0.708)\n",
      "Epoch: [89][4/9]\tTime 0.073 (0.148)\tData 0.054 (0.127)\tLoss 0.7532 (0.7160)\tAcc 0.688 (0.703)\n",
      "Epoch: [89][5/9]\tTime 0.075 (0.133)\tData 0.055 (0.113)\tLoss 0.8993 (0.7526)\tAcc 0.688 (0.700)\n",
      "Epoch: [89][6/9]\tTime 0.076 (0.124)\tData 0.054 (0.103)\tLoss 0.2832 (0.6744)\tAcc 1.000 (0.750)\n",
      "Epoch: [89][7/9]\tTime 0.071 (0.116)\tData 0.052 (0.096)\tLoss 0.7204 (0.6810)\tAcc 0.688 (0.741)\n",
      "Epoch: [89][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.091)\tLoss 1.0640 (0.7288)\tAcc 0.375 (0.695)\n",
      "Epoch: [89][9/9]\tTime 0.075 (0.107)\tData 0.055 (0.087)\tLoss 0.2365 (0.7213)\tAcc 1.000 (0.700)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.322 (0.322)\tData 0.293 (0.293)\tLoss 0.6436 (0.6436)\tAcc 0.812 (0.812)\n",
      "Epoch: [90][2/5]\tTime 0.074 (0.198)\tData 0.049 (0.171)\tLoss 0.7042 (0.6739)\tAcc 0.750 (0.781)\n",
      "Epoch: [90][3/5]\tTime 0.076 (0.157)\tData 0.053 (0.132)\tLoss 0.7284 (0.6921)\tAcc 0.688 (0.750)\n",
      "Epoch: [90][4/5]\tTime 0.077 (0.137)\tData 0.054 (0.112)\tLoss 0.8832 (0.7398)\tAcc 0.688 (0.734)\n",
      "Epoch: [90][5/5]\tTime 0.082 (0.126)\tData 0.056 (0.101)\tLoss 1.1655 (0.7923)\tAcc 0.556 (0.712)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.347 (0.347)\tData 0.321 (0.321)\tLoss 0.3843 (0.3843)\tAcc 0.875 (0.875)\n",
      "Epoch: [90][2/9]\tTime 0.070 (0.209)\tData 0.048 (0.185)\tLoss 0.9809 (0.6826)\tAcc 0.562 (0.719)\n",
      "Epoch: [90][3/9]\tTime 0.073 (0.163)\tData 0.052 (0.141)\tLoss 0.4856 (0.6169)\tAcc 0.938 (0.792)\n",
      "Epoch: [90][4/9]\tTime 0.075 (0.141)\tData 0.053 (0.119)\tLoss 0.6050 (0.6139)\tAcc 0.688 (0.766)\n",
      "Epoch: [90][5/9]\tTime 0.072 (0.127)\tData 0.053 (0.105)\tLoss 0.9295 (0.6770)\tAcc 0.688 (0.750)\n",
      "Epoch: [90][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.097)\tLoss 0.2760 (0.6102)\tAcc 1.000 (0.792)\n",
      "Epoch: [90][7/9]\tTime 0.073 (0.112)\tData 0.053 (0.091)\tLoss 0.5931 (0.6077)\tAcc 0.812 (0.795)\n",
      "Epoch: [90][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.086)\tLoss 0.8523 (0.6383)\tAcc 0.625 (0.773)\n",
      "Epoch: [90][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.2002 (0.6316)\tAcc 1.000 (0.777)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.359 (0.359)\tData 0.331 (0.331)\tLoss 0.4413 (0.4413)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/5]\tTime 0.074 (0.216)\tData 0.050 (0.190)\tLoss 0.7981 (0.6197)\tAcc 0.625 (0.781)\n",
      "Epoch: [91][3/5]\tTime 0.077 (0.170)\tData 0.053 (0.145)\tLoss 0.5680 (0.6025)\tAcc 0.812 (0.792)\n",
      "Epoch: [91][4/5]\tTime 0.076 (0.146)\tData 0.053 (0.122)\tLoss 0.9999 (0.7018)\tAcc 0.562 (0.734)\n",
      "Epoch: [91][5/5]\tTime 0.079 (0.133)\tData 0.055 (0.109)\tLoss 0.5724 (0.6859)\tAcc 0.778 (0.740)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.283 (0.283)\tData 0.256 (0.256)\tLoss 0.4055 (0.4055)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/9]\tTime 0.070 (0.176)\tData 0.048 (0.152)\tLoss 1.0512 (0.7283)\tAcc 0.438 (0.688)\n",
      "Epoch: [91][3/9]\tTime 0.073 (0.142)\tData 0.052 (0.119)\tLoss 0.5830 (0.6799)\tAcc 0.938 (0.771)\n",
      "Epoch: [91][4/9]\tTime 0.076 (0.125)\tData 0.053 (0.102)\tLoss 0.5405 (0.6451)\tAcc 0.750 (0.766)\n",
      "Epoch: [91][5/9]\tTime 0.072 (0.115)\tData 0.052 (0.092)\tLoss 0.8488 (0.6858)\tAcc 0.750 (0.762)\n",
      "Epoch: [91][6/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 0.3036 (0.6221)\tAcc 1.000 (0.802)\n",
      "Epoch: [91][7/9]\tTime 0.072 (0.103)\tData 0.053 (0.081)\tLoss 0.8795 (0.6589)\tAcc 0.812 (0.804)\n",
      "Epoch: [91][8/9]\tTime 0.074 (0.099)\tData 0.055 (0.078)\tLoss 0.9698 (0.6977)\tAcc 0.688 (0.789)\n",
      "Epoch: [91][9/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.3004 (0.6916)\tAcc 1.000 (0.792)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.377 (0.377)\tData 0.350 (0.350)\tLoss 0.8258 (0.8258)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][2/5]\tTime 0.075 (0.226)\tData 0.052 (0.201)\tLoss 0.7445 (0.7852)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][3/5]\tTime 0.077 (0.176)\tData 0.054 (0.152)\tLoss 0.5146 (0.6950)\tAcc 0.875 (0.750)\n",
      "Epoch: [92][4/5]\tTime 0.077 (0.151)\tData 0.054 (0.127)\tLoss 0.7693 (0.7136)\tAcc 0.750 (0.750)\n",
      "Epoch: [92][5/5]\tTime 0.079 (0.137)\tData 0.056 (0.113)\tLoss 0.6402 (0.7045)\tAcc 0.778 (0.753)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.289 (0.289)\tData 0.263 (0.263)\tLoss 0.4193 (0.4193)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/9]\tTime 0.070 (0.179)\tData 0.048 (0.155)\tLoss 0.8739 (0.6466)\tAcc 0.500 (0.719)\n",
      "Epoch: [92][3/9]\tTime 0.074 (0.144)\tData 0.052 (0.121)\tLoss 0.7033 (0.6655)\tAcc 0.750 (0.729)\n",
      "Epoch: [92][4/9]\tTime 0.073 (0.126)\tData 0.052 (0.104)\tLoss 0.8440 (0.7101)\tAcc 0.688 (0.719)\n",
      "Epoch: [92][5/9]\tTime 0.074 (0.116)\tData 0.054 (0.094)\tLoss 0.7790 (0.7239)\tAcc 0.688 (0.713)\n",
      "Epoch: [92][6/9]\tTime 0.074 (0.109)\tData 0.054 (0.087)\tLoss 0.3418 (0.6602)\tAcc 1.000 (0.760)\n",
      "Epoch: [92][7/9]\tTime 0.072 (0.104)\tData 0.053 (0.082)\tLoss 0.8066 (0.6811)\tAcc 0.812 (0.768)\n",
      "Epoch: [92][8/9]\tTime 0.075 (0.100)\tData 0.056 (0.079)\tLoss 1.0377 (0.7257)\tAcc 0.562 (0.742)\n",
      "Epoch: [92][9/9]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.3138 (0.7194)\tAcc 1.000 (0.746)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.297 (0.297)\tData 0.267 (0.267)\tLoss 0.9956 (0.9956)\tAcc 0.562 (0.562)\n",
      "Epoch: [93][2/5]\tTime 0.073 (0.185)\tData 0.049 (0.158)\tLoss 0.8306 (0.9131)\tAcc 0.688 (0.625)\n",
      "Epoch: [93][3/5]\tTime 0.077 (0.149)\tData 0.053 (0.123)\tLoss 0.4839 (0.7700)\tAcc 0.812 (0.688)\n",
      "Epoch: [93][4/5]\tTime 0.076 (0.131)\tData 0.053 (0.106)\tLoss 0.4274 (0.6844)\tAcc 0.938 (0.750)\n",
      "Epoch: [93][5/5]\tTime 0.079 (0.120)\tData 0.055 (0.096)\tLoss 0.7821 (0.6964)\tAcc 0.667 (0.740)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.362 (0.362)\tData 0.339 (0.339)\tLoss 0.3048 (0.3048)\tAcc 1.000 (1.000)\n",
      "Epoch: [93][2/9]\tTime 0.072 (0.217)\tData 0.051 (0.195)\tLoss 0.9445 (0.6246)\tAcc 0.500 (0.750)\n",
      "Epoch: [93][3/9]\tTime 0.072 (0.169)\tData 0.052 (0.147)\tLoss 0.7740 (0.6744)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][4/9]\tTime 0.075 (0.145)\tData 0.053 (0.124)\tLoss 0.5256 (0.6372)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][5/9]\tTime 0.072 (0.131)\tData 0.053 (0.110)\tLoss 0.9105 (0.6919)\tAcc 0.688 (0.738)\n",
      "Epoch: [93][6/9]\tTime 0.075 (0.121)\tData 0.055 (0.100)\tLoss 0.3328 (0.6320)\tAcc 1.000 (0.781)\n",
      "Epoch: [93][7/9]\tTime 0.072 (0.114)\tData 0.053 (0.094)\tLoss 0.5335 (0.6179)\tAcc 0.812 (0.786)\n",
      "Epoch: [93][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.089)\tLoss 1.0821 (0.6760)\tAcc 0.375 (0.734)\n",
      "Epoch: [93][9/9]\tTime 0.074 (0.105)\tData 0.054 (0.085)\tLoss 0.2653 (0.6696)\tAcc 1.000 (0.738)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.375 (0.375)\tData 0.347 (0.347)\tLoss 0.6874 (0.6874)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][2/5]\tTime 0.074 (0.225)\tData 0.050 (0.198)\tLoss 0.5859 (0.6366)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][3/5]\tTime 0.076 (0.175)\tData 0.053 (0.150)\tLoss 0.7898 (0.6877)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][4/5]\tTime 0.077 (0.151)\tData 0.055 (0.126)\tLoss 0.5456 (0.6522)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][5/5]\tTime 0.080 (0.136)\tData 0.056 (0.112)\tLoss 0.7790 (0.6678)\tAcc 0.556 (0.781)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.261 (0.261)\tData 0.236 (0.236)\tLoss 0.3287 (0.3287)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/9]\tTime 0.071 (0.166)\tData 0.050 (0.143)\tLoss 0.9703 (0.6495)\tAcc 0.438 (0.688)\n",
      "Epoch: [94][3/9]\tTime 0.074 (0.135)\tData 0.053 (0.113)\tLoss 0.6045 (0.6345)\tAcc 0.750 (0.708)\n",
      "Epoch: [94][4/9]\tTime 0.073 (0.120)\tData 0.053 (0.098)\tLoss 0.6134 (0.6292)\tAcc 0.688 (0.703)\n",
      "Epoch: [94][5/9]\tTime 0.074 (0.111)\tData 0.054 (0.089)\tLoss 0.7745 (0.6583)\tAcc 0.812 (0.725)\n",
      "Epoch: [94][6/9]\tTime 0.075 (0.105)\tData 0.053 (0.083)\tLoss 0.2563 (0.5913)\tAcc 1.000 (0.771)\n",
      "Epoch: [94][7/9]\tTime 0.071 (0.100)\tData 0.052 (0.079)\tLoss 0.8184 (0.6237)\tAcc 0.625 (0.750)\n",
      "Epoch: [94][8/9]\tTime 0.076 (0.097)\tData 0.055 (0.076)\tLoss 0.8901 (0.6570)\tAcc 0.625 (0.734)\n",
      "Epoch: [94][9/9]\tTime 0.072 (0.094)\tData 0.053 (0.073)\tLoss 0.2408 (0.6506)\tAcc 1.000 (0.738)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.339 (0.339)\tData 0.309 (0.309)\tLoss 0.8268 (0.8268)\tAcc 0.562 (0.562)\n",
      "Epoch: [95][2/5]\tTime 0.072 (0.205)\tData 0.048 (0.179)\tLoss 0.5131 (0.6699)\tAcc 0.875 (0.719)\n",
      "Epoch: [95][3/5]\tTime 0.078 (0.163)\tData 0.054 (0.137)\tLoss 0.8625 (0.7341)\tAcc 0.688 (0.708)\n",
      "Epoch: [95][4/5]\tTime 0.076 (0.141)\tData 0.053 (0.116)\tLoss 0.7358 (0.7345)\tAcc 0.688 (0.703)\n",
      "Epoch: [95][5/5]\tTime 0.081 (0.129)\tData 0.057 (0.104)\tLoss 0.7088 (0.7314)\tAcc 0.667 (0.699)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.360 (0.360)\tData 0.336 (0.336)\tLoss 0.3455 (0.3455)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/9]\tTime 0.072 (0.216)\tData 0.051 (0.193)\tLoss 0.8688 (0.6071)\tAcc 0.438 (0.688)\n",
      "Epoch: [95][3/9]\tTime 0.073 (0.168)\tData 0.053 (0.146)\tLoss 0.5904 (0.6016)\tAcc 0.750 (0.708)\n",
      "Epoch: [95][4/9]\tTime 0.073 (0.144)\tData 0.053 (0.123)\tLoss 0.5747 (0.5948)\tAcc 0.750 (0.719)\n",
      "Epoch: [95][5/9]\tTime 0.078 (0.131)\tData 0.057 (0.110)\tLoss 0.8457 (0.6450)\tAcc 0.750 (0.725)\n",
      "Epoch: [95][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.101)\tLoss 0.3000 (0.5875)\tAcc 1.000 (0.771)\n",
      "Epoch: [95][7/9]\tTime 0.081 (0.116)\tData 0.060 (0.095)\tLoss 0.5903 (0.5879)\tAcc 0.750 (0.768)\n",
      "Epoch: [95][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 1.0697 (0.6481)\tAcc 0.500 (0.734)\n",
      "Epoch: [95][9/9]\tTime 0.075 (0.107)\tData 0.055 (0.086)\tLoss 0.2314 (0.6417)\tAcc 1.000 (0.738)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.340 (0.340)\tData 0.298 (0.298)\tLoss 0.7962 (0.7962)\tAcc 0.625 (0.625)\n",
      "Epoch: [96][2/5]\tTime 0.061 (0.201)\tData 0.036 (0.167)\tLoss 0.4840 (0.6401)\tAcc 0.875 (0.750)\n",
      "Epoch: [96][3/5]\tTime 0.078 (0.160)\tData 0.053 (0.129)\tLoss 0.8924 (0.7242)\tAcc 0.625 (0.708)\n",
      "Epoch: [96][4/5]\tTime 0.076 (0.139)\tData 0.052 (0.110)\tLoss 0.8885 (0.7653)\tAcc 0.688 (0.703)\n",
      "Epoch: [96][5/5]\tTime 0.079 (0.127)\tData 0.056 (0.099)\tLoss 1.2359 (0.8233)\tAcc 0.444 (0.671)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.293 (0.293)\tData 0.270 (0.270)\tLoss 0.3634 (0.3634)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/9]\tTime 0.074 (0.183)\tData 0.050 (0.160)\tLoss 0.9925 (0.6780)\tAcc 0.500 (0.719)\n",
      "Epoch: [96][3/9]\tTime 0.072 (0.146)\tData 0.051 (0.124)\tLoss 0.6728 (0.6762)\tAcc 0.750 (0.729)\n",
      "Epoch: [96][4/9]\tTime 0.075 (0.128)\tData 0.052 (0.106)\tLoss 0.6062 (0.6587)\tAcc 0.750 (0.734)\n",
      "Epoch: [96][5/9]\tTime 0.072 (0.117)\tData 0.052 (0.095)\tLoss 0.7292 (0.6728)\tAcc 0.812 (0.750)\n",
      "Epoch: [96][6/9]\tTime 0.074 (0.110)\tData 0.054 (0.088)\tLoss 0.2305 (0.5991)\tAcc 1.000 (0.792)\n",
      "Epoch: [96][7/9]\tTime 0.073 (0.105)\tData 0.053 (0.083)\tLoss 0.6694 (0.6091)\tAcc 0.750 (0.786)\n",
      "Epoch: [96][8/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.9571 (0.6526)\tAcc 0.562 (0.758)\n",
      "Epoch: [96][9/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.1541 (0.6450)\tAcc 1.000 (0.762)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.367 (0.367)\tData 0.340 (0.340)\tLoss 0.3580 (0.3580)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/5]\tTime 0.076 (0.221)\tData 0.051 (0.196)\tLoss 1.1879 (0.7729)\tAcc 0.562 (0.750)\n",
      "Epoch: [97][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.9877 (0.8445)\tAcc 0.500 (0.667)\n",
      "Epoch: [97][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 0.4148 (0.7371)\tAcc 0.812 (0.703)\n",
      "Epoch: [97][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.111)\tLoss 0.7908 (0.7437)\tAcc 0.667 (0.699)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.346 (0.346)\tData 0.320 (0.320)\tLoss 0.3915 (0.3915)\tAcc 0.875 (0.875)\n",
      "Epoch: [97][2/9]\tTime 0.070 (0.208)\tData 0.048 (0.184)\tLoss 0.9830 (0.6873)\tAcc 0.500 (0.688)\n",
      "Epoch: [97][3/9]\tTime 0.073 (0.163)\tData 0.053 (0.140)\tLoss 0.6876 (0.6874)\tAcc 0.750 (0.708)\n",
      "Epoch: [97][4/9]\tTime 0.073 (0.141)\tData 0.053 (0.118)\tLoss 0.5529 (0.6538)\tAcc 0.812 (0.734)\n",
      "Epoch: [97][5/9]\tTime 0.075 (0.127)\tData 0.055 (0.106)\tLoss 0.9511 (0.7132)\tAcc 0.625 (0.713)\n",
      "Epoch: [97][6/9]\tTime 0.074 (0.118)\tData 0.053 (0.097)\tLoss 0.3058 (0.6453)\tAcc 1.000 (0.760)\n",
      "Epoch: [97][7/9]\tTime 0.075 (0.112)\tData 0.053 (0.091)\tLoss 0.6968 (0.6527)\tAcc 0.812 (0.768)\n",
      "Epoch: [97][8/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.9427 (0.6889)\tAcc 0.625 (0.750)\n",
      "Epoch: [97][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.082)\tLoss 0.2762 (0.6826)\tAcc 1.000 (0.754)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.348 (0.348)\tData 0.320 (0.320)\tLoss 0.6990 (0.6990)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][2/5]\tTime 0.075 (0.211)\tData 0.050 (0.185)\tLoss 0.6430 (0.6710)\tAcc 0.875 (0.812)\n",
      "Epoch: [98][3/5]\tTime 0.076 (0.166)\tData 0.053 (0.141)\tLoss 0.6270 (0.6563)\tAcc 0.812 (0.812)\n",
      "Epoch: [98][4/5]\tTime 0.077 (0.144)\tData 0.053 (0.119)\tLoss 0.8773 (0.7116)\tAcc 0.688 (0.781)\n",
      "Epoch: [98][5/5]\tTime 0.090 (0.133)\tData 0.065 (0.108)\tLoss 0.7095 (0.7113)\tAcc 0.778 (0.781)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.303 (0.303)\tData 0.280 (0.280)\tLoss 0.4060 (0.4060)\tAcc 0.875 (0.875)\n",
      "Epoch: [98][2/9]\tTime 0.080 (0.191)\tData 0.058 (0.169)\tLoss 0.8586 (0.6323)\tAcc 0.500 (0.688)\n",
      "Epoch: [98][3/9]\tTime 0.073 (0.152)\tData 0.052 (0.130)\tLoss 0.5890 (0.6179)\tAcc 0.812 (0.729)\n",
      "Epoch: [98][4/9]\tTime 0.073 (0.132)\tData 0.053 (0.111)\tLoss 0.5363 (0.5975)\tAcc 0.750 (0.734)\n",
      "Epoch: [98][5/9]\tTime 0.077 (0.121)\tData 0.054 (0.099)\tLoss 0.8276 (0.6435)\tAcc 0.688 (0.725)\n",
      "Epoch: [98][6/9]\tTime 0.071 (0.113)\tData 0.052 (0.091)\tLoss 0.2870 (0.5841)\tAcc 1.000 (0.771)\n",
      "Epoch: [98][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.9046 (0.6299)\tAcc 0.562 (0.741)\n",
      "Epoch: [98][8/9]\tTime 0.077 (0.103)\tData 0.056 (0.082)\tLoss 0.9153 (0.6655)\tAcc 0.562 (0.719)\n",
      "Epoch: [98][9/9]\tTime 0.072 (0.100)\tData 0.053 (0.079)\tLoss 0.3508 (0.6607)\tAcc 1.000 (0.723)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.361 (0.361)\tData 0.334 (0.334)\tLoss 0.7487 (0.7487)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][2/5]\tTime 0.075 (0.218)\tData 0.051 (0.193)\tLoss 0.5800 (0.6643)\tAcc 0.625 (0.688)\n",
      "Epoch: [99][3/5]\tTime 0.077 (0.171)\tData 0.054 (0.146)\tLoss 0.8823 (0.7370)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.123)\tLoss 0.7405 (0.7379)\tAcc 0.625 (0.672)\n",
      "Epoch: [99][5/5]\tTime 0.081 (0.134)\tData 0.056 (0.110)\tLoss 0.5359 (0.7130)\tAcc 0.778 (0.685)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.399 (0.399)\tData 0.375 (0.375)\tLoss 0.3669 (0.3669)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.072 (0.236)\tData 0.050 (0.213)\tLoss 0.8899 (0.6284)\tAcc 0.562 (0.750)\n",
      "Epoch: [99][3/9]\tTime 0.072 (0.181)\tData 0.052 (0.159)\tLoss 0.6529 (0.6366)\tAcc 0.812 (0.771)\n",
      "Epoch: [99][4/9]\tTime 0.073 (0.154)\tData 0.053 (0.133)\tLoss 0.5126 (0.6056)\tAcc 0.812 (0.781)\n",
      "Epoch: [99][5/9]\tTime 0.076 (0.138)\tData 0.055 (0.117)\tLoss 0.7981 (0.6441)\tAcc 0.750 (0.775)\n",
      "Epoch: [99][6/9]\tTime 0.072 (0.127)\tData 0.053 (0.106)\tLoss 0.2677 (0.5814)\tAcc 1.000 (0.812)\n",
      "Epoch: [99][7/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.4961 (0.5692)\tAcc 0.812 (0.813)\n",
      "Epoch: [99][8/9]\tTime 0.074 (0.114)\tData 0.055 (0.093)\tLoss 0.9777 (0.6202)\tAcc 0.562 (0.781)\n",
      "Epoch: [99][9/9]\tTime 0.075 (0.110)\tData 0.054 (0.089)\tLoss 0.1843 (0.6135)\tAcc 1.000 (0.785)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.383 (0.383)\tData 0.354 (0.354)\tLoss 0.7470 (0.7470)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][2/5]\tTime 0.073 (0.228)\tData 0.049 (0.202)\tLoss 0.8511 (0.7991)\tAcc 0.688 (0.719)\n",
      "Epoch: [100][3/5]\tTime 0.077 (0.178)\tData 0.053 (0.152)\tLoss 0.6169 (0.7383)\tAcc 0.750 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.077 (0.153)\tData 0.053 (0.128)\tLoss 0.8055 (0.7551)\tAcc 0.625 (0.703)\n",
      "Epoch: [100][5/5]\tTime 0.079 (0.138)\tData 0.055 (0.113)\tLoss 0.6937 (0.7476)\tAcc 0.778 (0.712)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.360 (0.360)\tData 0.336 (0.336)\tLoss 0.4243 (0.4243)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.072 (0.216)\tData 0.050 (0.193)\tLoss 0.9156 (0.6700)\tAcc 0.562 (0.750)\n",
      "Epoch: [100][3/9]\tTime 0.073 (0.168)\tData 0.052 (0.146)\tLoss 0.6011 (0.6470)\tAcc 0.812 (0.771)\n",
      "Epoch: [100][4/9]\tTime 0.075 (0.145)\tData 0.053 (0.123)\tLoss 0.7322 (0.6683)\tAcc 0.750 (0.766)\n",
      "Epoch: [100][5/9]\tTime 0.072 (0.130)\tData 0.052 (0.109)\tLoss 0.9085 (0.7163)\tAcc 0.562 (0.725)\n",
      "Epoch: [100][6/9]\tTime 0.074 (0.121)\tData 0.054 (0.099)\tLoss 0.3235 (0.6509)\tAcc 1.000 (0.771)\n",
      "Epoch: [100][7/9]\tTime 0.073 (0.114)\tData 0.054 (0.093)\tLoss 0.7877 (0.6704)\tAcc 0.625 (0.750)\n",
      "Epoch: [100][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.088)\tLoss 1.0659 (0.7199)\tAcc 0.438 (0.711)\n",
      "Epoch: [100][9/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 0.2149 (0.7121)\tAcc 1.000 (0.715)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:55:17.626496Z",
     "start_time": "2020-03-16T18:55:17.583428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T18:55:18.293993Z",
     "start_time": "2020-03-16T18:55:18.259017Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:23:57.626667Z",
     "start_time": "2020-03-16T19:23:51.794003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:24:01.857636Z",
     "start_time": "2020-03-16T19:24:01.830731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 1.8249683380126953},\n",
       " {'label': 'none', 'score': 1.8249683380126953},\n",
       " {'label': 'none', 'score': 1.8249683380126953},\n",
       " {'label': 'none', 'score': 1.6979138851165771},\n",
       " {'label': 'none', 'score': 1.6979138851165771},\n",
       " {'label': 'none', 'score': 1.6979138851165771},\n",
       " {'label': 'none', 'score': 2.0698530673980713},\n",
       " {'label': 'none', 'score': 2.0698530673980713},\n",
       " {'label': 'none', 'score': 2.0698530673980713},\n",
       " {'label': 'none', 'score': 1.9975199699401855},\n",
       " {'label': 'none', 'score': 1.9975199699401855},\n",
       " {'label': 'none', 'score': 1.9975199699401855},\n",
       " {'label': 'none', 'score': 1.2998839616775513},\n",
       " {'label': 'none', 'score': 1.2998839616775513},\n",
       " {'label': 'none', 'score': 1.2998839616775513},\n",
       " {'label': 'none', 'score': 1.4115772247314453},\n",
       " {'label': 'none', 'score': 1.4115772247314453},\n",
       " {'label': 'none', 'score': 1.4115772247314453},\n",
       " {'label': 'none', 'score': 1.912355899810791},\n",
       " {'label': 'none', 'score': 1.912355899810791},\n",
       " {'label': 'none', 'score': 1.912355899810791},\n",
       " {'label': 'none', 'score': 1.343998670578003},\n",
       " {'label': 'none', 'score': 1.343998670578003},\n",
       " {'label': 'none', 'score': 1.343998670578003},\n",
       " {'label': 'none', 'score': 1.6943492889404297},\n",
       " {'label': 'none', 'score': 1.6943492889404297},\n",
       " {'label': 'none', 'score': 1.6943492889404297},\n",
       " {'label': 'none', 'score': 1.4179058074951172},\n",
       " {'label': 'none', 'score': 1.4179058074951172},\n",
       " {'label': 'none', 'score': 1.4179058074951172},\n",
       " {'label': 'none', 'score': 1.836334466934204},\n",
       " {'label': 'none', 'score': 1.836334466934204},\n",
       " {'label': 'none', 'score': 1.836334466934204},\n",
       " {'label': 'none', 'score': 2.218372106552124},\n",
       " {'label': 'none', 'score': 2.218372106552124},\n",
       " {'label': 'none', 'score': 2.218372106552124},\n",
       " {'label': 'none', 'score': 1.9051258563995361},\n",
       " {'label': 'none', 'score': 1.9051258563995361},\n",
       " {'label': 'none', 'score': 1.9051258563995361},\n",
       " {'label': 'none', 'score': 1.6770057678222656},\n",
       " {'label': 'none', 'score': 1.6770057678222656},\n",
       " {'label': 'none', 'score': 1.6770057678222656},\n",
       " {'label': 'none', 'score': 1.6171619892120361},\n",
       " {'label': 'none', 'score': 1.6171619892120361},\n",
       " {'label': 'none', 'score': 1.6171619892120361},\n",
       " {'label': 'none', 'score': 1.5517292022705078},\n",
       " {'label': 'none', 'score': 1.5517292022705078},\n",
       " {'label': 'none', 'score': 1.5517292022705078},\n",
       " {'label': 'none', 'score': 1.9480619430541992},\n",
       " {'label': 'none', 'score': 1.9480619430541992},\n",
       " {'label': 'none', 'score': 1.9480619430541992},\n",
       " {'label': 'none', 'score': 1.8691761493682861},\n",
       " {'label': 'none', 'score': 1.8691761493682861},\n",
       " {'label': 'none', 'score': 1.8691761493682861},\n",
       " {'label': 'none', 'score': 1.934288501739502},\n",
       " {'label': 'none', 'score': 1.934288501739502},\n",
       " {'label': 'none', 'score': 1.934288501739502},\n",
       " {'label': 'none', 'score': 2.2583956718444824},\n",
       " {'label': 'none', 'score': 2.2583956718444824},\n",
       " {'label': 'none', 'score': 2.2583956718444824},\n",
       " {'label': 'none', 'score': 1.557267665863037},\n",
       " {'label': 'none', 'score': 1.557267665863037},\n",
       " {'label': 'none', 'score': 1.557267665863037},\n",
       " {'label': 'none', 'score': 1.670262098312378},\n",
       " {'label': 'none', 'score': 1.670262098312378},\n",
       " {'label': 'none', 'score': 1.670262098312378},\n",
       " {'label': 'returning', 'score': 0.7037209868431091},\n",
       " {'label': 'returning', 'score': 0.7037209868431091},\n",
       " {'label': 'returning', 'score': 0.7037209868431091},\n",
       " {'label': 'leaving', 'score': 1.2585530281066895},\n",
       " {'label': 'leaving', 'score': 1.2585530281066895},\n",
       " {'label': 'leaving', 'score': 1.2585530281066895},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.8597133159637451},\n",
       " {'label': 'returning', 'score': 0.8597133159637451},\n",
       " {'label': 'returning', 'score': 0.8597133159637451},\n",
       " {'label': 'returning', 'score': 0.4984481930732727},\n",
       " {'label': 'returning', 'score': 0.4984481930732727},\n",
       " {'label': 'returning', 'score': 0.4984481930732727},\n",
       " {'label': 'returning', 'score': 0.6159896850585938},\n",
       " {'label': 'returning', 'score': 0.6159896850585938},\n",
       " {'label': 'returning', 'score': 0.6159896850585938},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.37929269671440125},\n",
       " {'label': 'returning', 'score': 0.37929269671440125},\n",
       " {'label': 'returning', 'score': 0.37929269671440125},\n",
       " {'label': 'leaving', 'score': 1.5401906967163086},\n",
       " {'label': 'leaving', 'score': 1.5401906967163086},\n",
       " {'label': 'leaving', 'score': 1.5401906967163086},\n",
       " {'label': 'none', 'score': 1.5538618564605713},\n",
       " {'label': 'none', 'score': 1.5538618564605713},\n",
       " {'label': 'none', 'score': 1.5538618564605713},\n",
       " {'label': 'none', 'score': 2.3601653575897217},\n",
       " {'label': 'none', 'score': 2.3601653575897217},\n",
       " {'label': 'none', 'score': 2.3601653575897217},\n",
       " {'label': 'none', 'score': 1.4433512687683105},\n",
       " {'label': 'none', 'score': 1.4433512687683105},\n",
       " {'label': 'none', 'score': 1.4433512687683105},\n",
       " {'label': 'none', 'score': 1.8655505180358887},\n",
       " {'label': 'none', 'score': 1.8655505180358887},\n",
       " {'label': 'none', 'score': 1.8655505180358887},\n",
       " {'label': 'none', 'score': 1.631906270980835},\n",
       " {'label': 'none', 'score': 1.631906270980835},\n",
       " {'label': 'none', 'score': 1.631906270980835},\n",
       " {'label': 'none', 'score': 1.676961898803711},\n",
       " {'label': 'none', 'score': 1.676961898803711},\n",
       " {'label': 'none', 'score': 1.676961898803711},\n",
       " {'label': 'none', 'score': 2.093625545501709},\n",
       " {'label': 'none', 'score': 2.093625545501709},\n",
       " {'label': 'none', 'score': 2.093625545501709},\n",
       " {'label': 'none', 'score': 1.3949644565582275},\n",
       " {'label': 'none', 'score': 1.3949644565582275},\n",
       " {'label': 'none', 'score': 1.3949644565582275},\n",
       " {'label': 'none', 'score': 1.8406521081924438},\n",
       " {'label': 'none', 'score': 1.8406521081924438},\n",
       " {'label': 'none', 'score': 1.8406521081924438},\n",
       " {'label': 'none', 'score': 1.8636534214019775},\n",
       " {'label': 'none', 'score': 1.8636534214019775},\n",
       " {'label': 'none', 'score': 1.8636534214019775},\n",
       " {'label': 'none', 'score': 2.145379066467285},\n",
       " {'label': 'none', 'score': 2.145379066467285},\n",
       " {'label': 'none', 'score': 2.145379066467285},\n",
       " {'label': 'none', 'score': 2.238710880279541},\n",
       " {'label': 'none', 'score': 2.238710880279541},\n",
       " {'label': 'none', 'score': 2.238710880279541},\n",
       " {'label': 'none', 'score': 1.6829993724822998},\n",
       " {'label': 'none', 'score': 1.6829993724822998},\n",
       " {'label': 'none', 'score': 1.6829993724822998},\n",
       " {'label': 'none', 'score': 1.278073787689209},\n",
       " {'label': 'none', 'score': 1.278073787689209},\n",
       " {'label': 'none', 'score': 1.278073787689209},\n",
       " {'label': 'none', 'score': 1.8410162925720215},\n",
       " {'label': 'none', 'score': 1.8410162925720215},\n",
       " {'label': 'none', 'score': 1.8410162925720215},\n",
       " {'label': 'none', 'score': 1.4805629253387451},\n",
       " {'label': 'none', 'score': 1.4805629253387451},\n",
       " {'label': 'none', 'score': 1.4805629253387451},\n",
       " {'label': 'none', 'score': 1.7652475833892822},\n",
       " {'label': 'none', 'score': 1.7652475833892822},\n",
       " {'label': 'none', 'score': 1.7652475833892822},\n",
       " {'label': 'none', 'score': 1.430694580078125},\n",
       " {'label': 'none', 'score': 1.430694580078125},\n",
       " {'label': 'none', 'score': 1.430694580078125},\n",
       " {'label': 'returning', 'score': 1.4018495082855225},\n",
       " {'label': 'returning', 'score': 1.4018495082855225},\n",
       " {'label': 'returning', 'score': 1.4018495082855225},\n",
       " {'label': 'returning', 'score': 0.9853601455688477},\n",
       " {'label': 'returning', 'score': 0.9853601455688477},\n",
       " {'label': 'returning', 'score': 0.9853601455688477},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.589546799659729},\n",
       " {'label': 'returning', 'score': 0.589546799659729},\n",
       " {'label': 'returning', 'score': 0.589546799659729},\n",
       " {'label': 'returning', 'score': 1.301594853401184},\n",
       " {'label': 'returning', 'score': 1.301594853401184},\n",
       " {'label': 'returning', 'score': 1.301594853401184},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.5519297122955322},\n",
       " {'label': 'none', 'score': 1.5519297122955322},\n",
       " {'label': 'none', 'score': 1.5519297122955322},\n",
       " {'label': 'none', 'score': 1.7110278606414795},\n",
       " {'label': 'none', 'score': 1.7110278606414795},\n",
       " {'label': 'none', 'score': 1.7110278606414795},\n",
       " {'label': 'none', 'score': 1.7265194654464722},\n",
       " {'label': 'none', 'score': 1.7265194654464722},\n",
       " {'label': 'none', 'score': 1.7265194654464722},\n",
       " {'label': 'none', 'score': 1.6244765520095825},\n",
       " {'label': 'none', 'score': 1.6244765520095825},\n",
       " {'label': 'none', 'score': 1.6244765520095825},\n",
       " {'label': 'none', 'score': 1.7943010330200195},\n",
       " {'label': 'none', 'score': 1.7943010330200195},\n",
       " {'label': 'none', 'score': 1.7943010330200195},\n",
       " {'label': 'none', 'score': 1.4503002166748047},\n",
       " {'label': 'none', 'score': 1.4503002166748047},\n",
       " {'label': 'none', 'score': 1.4503002166748047},\n",
       " {'label': 'none', 'score': 1.665391206741333},\n",
       " {'label': 'none', 'score': 1.665391206741333},\n",
       " {'label': 'none', 'score': 1.665391206741333},\n",
       " {'label': 'none', 'score': 1.7767397165298462},\n",
       " {'label': 'none', 'score': 1.7767397165298462},\n",
       " {'label': 'none', 'score': 1.7767397165298462},\n",
       " {'label': 'none', 'score': 1.9321534633636475},\n",
       " {'label': 'none', 'score': 1.9321534633636475},\n",
       " {'label': 'none', 'score': 1.9321534633636475},\n",
       " {'label': 'none', 'score': 1.5918986797332764},\n",
       " {'label': 'none', 'score': 1.5918986797332764},\n",
       " {'label': 'none', 'score': 1.5918986797332764},\n",
       " {'label': 'none', 'score': 2.0151803493499756},\n",
       " {'label': 'none', 'score': 2.0151803493499756},\n",
       " {'label': 'none', 'score': 2.0151803493499756},\n",
       " {'label': 'none', 'score': 2.2003018856048584},\n",
       " {'label': 'none', 'score': 2.2003018856048584},\n",
       " {'label': 'none', 'score': 2.2003018856048584},\n",
       " {'label': 'none', 'score': 1.7507760524749756},\n",
       " {'label': 'none', 'score': 1.7507760524749756},\n",
       " {'label': 'none', 'score': 1.7507760524749756},\n",
       " {'label': 'none', 'score': 2.9119491577148438},\n",
       " {'label': 'none', 'score': 2.9119491577148438},\n",
       " {'label': 'none', 'score': 2.9119491577148438},\n",
       " {'label': 'none', 'score': 1.256546974182129},\n",
       " {'label': 'none', 'score': 1.256546974182129},\n",
       " {'label': 'none', 'score': 1.256546974182129},\n",
       " {'label': 'none', 'score': 1.3332264423370361},\n",
       " {'label': 'none', 'score': 1.3332264423370361},\n",
       " {'label': 'none', 'score': 1.3332264423370361},\n",
       " {'label': 'none', 'score': 1.6328229904174805},\n",
       " {'label': 'none', 'score': 1.6328229904174805},\n",
       " {'label': 'none', 'score': 1.6328229904174805},\n",
       " {'label': 'none', 'score': 1.8440563678741455},\n",
       " {'label': 'none', 'score': 1.8440563678741455},\n",
       " {'label': 'none', 'score': 1.8440563678741455},\n",
       " {'label': 'none', 'score': 1.81553316116333},\n",
       " {'label': 'none', 'score': 1.81553316116333},\n",
       " {'label': 'none', 'score': 1.81553316116333},\n",
       " {'label': 'none', 'score': 1.7713677883148193},\n",
       " {'label': 'none', 'score': 1.7713677883148193},\n",
       " {'label': 'none', 'score': 1.7713677883148193},\n",
       " {'label': 'returning', 'score': 0.5171248912811279},\n",
       " {'label': 'returning', 'score': 0.5171248912811279},\n",
       " {'label': 'returning', 'score': 0.5171248912811279},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.49799567461013794},\n",
       " {'label': 'returning', 'score': 0.49799567461013794},\n",
       " {'label': 'returning', 'score': 0.49799567461013794},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.7206672430038452},\n",
       " {'label': 'returning', 'score': 0.7206672430038452},\n",
       " {'label': 'returning', 'score': 0.7206672430038452},\n",
       " {'label': 'returning', 'score': 0.8424665331840515},\n",
       " {'label': 'returning', 'score': 0.8424665331840515},\n",
       " {'label': 'returning', 'score': 0.8424665331840515},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.846163272857666},\n",
       " {'label': 'none', 'score': 1.846163272857666},\n",
       " {'label': 'none', 'score': 1.846163272857666},\n",
       " {'label': 'none', 'score': 1.7959213256835938},\n",
       " {'label': 'none', 'score': 1.7959213256835938},\n",
       " {'label': 'none', 'score': 1.7959213256835938},\n",
       " {'label': 'none', 'score': 1.9973161220550537},\n",
       " {'label': 'none', 'score': 1.9973161220550537},\n",
       " {'label': 'none', 'score': 1.9973161220550537},\n",
       " {'label': 'none', 'score': 1.7310917377471924},\n",
       " {'label': 'none', 'score': 1.7310917377471924},\n",
       " {'label': 'none', 'score': 1.7310917377471924},\n",
       " {'label': 'none', 'score': 2.379962205886841},\n",
       " {'label': 'none', 'score': 2.379962205886841},\n",
       " {'label': 'none', 'score': 2.379962205886841},\n",
       " {'label': 'none', 'score': 1.5314046144485474},\n",
       " {'label': 'none', 'score': 1.5314046144485474},\n",
       " {'label': 'none', 'score': 1.5314046144485474},\n",
       " {'label': 'none', 'score': 1.7044858932495117},\n",
       " {'label': 'none', 'score': 1.7044858932495117},\n",
       " {'label': 'none', 'score': 1.7044858932495117},\n",
       " {'label': 'none', 'score': 1.381817102432251},\n",
       " {'label': 'none', 'score': 1.381817102432251},\n",
       " {'label': 'none', 'score': 1.381817102432251},\n",
       " {'label': 'none', 'score': 1.6192796230316162},\n",
       " {'label': 'none', 'score': 1.6192796230316162},\n",
       " {'label': 'none', 'score': 1.6192796230316162},\n",
       " {'label': 'none', 'score': 1.912454605102539},\n",
       " {'label': 'none', 'score': 1.912454605102539},\n",
       " {'label': 'none', 'score': 1.912454605102539},\n",
       " {'label': 'none', 'score': 1.845761775970459},\n",
       " {'label': 'none', 'score': 1.845761775970459},\n",
       " {'label': 'none', 'score': 1.845761775970459},\n",
       " {'label': 'none', 'score': 1.7116453647613525},\n",
       " {'label': 'none', 'score': 1.7116453647613525},\n",
       " {'label': 'none', 'score': 1.7116453647613525},\n",
       " {'label': 'none', 'score': 1.2875564098358154},\n",
       " {'label': 'none', 'score': 1.2875564098358154},\n",
       " {'label': 'none', 'score': 1.2875564098358154},\n",
       " {'label': 'none', 'score': 1.8555915355682373},\n",
       " {'label': 'none', 'score': 1.8555915355682373},\n",
       " {'label': 'none', 'score': 1.8555915355682373},\n",
       " {'label': 'none', 'score': 2.402852773666382},\n",
       " {'label': 'none', 'score': 2.402852773666382},\n",
       " {'label': 'none', 'score': 2.402852773666382},\n",
       " {'label': 'none', 'score': 1.9398884773254395},\n",
       " {'label': 'none', 'score': 1.9398884773254395},\n",
       " {'label': 'none', 'score': 1.9398884773254395},\n",
       " {'label': 'none', 'score': 2.0803399085998535},\n",
       " {'label': 'none', 'score': 2.0803399085998535},\n",
       " {'label': 'none', 'score': 2.0803399085998535},\n",
       " {'label': 'none', 'score': 1.8555858135223389},\n",
       " {'label': 'none', 'score': 1.8555858135223389},\n",
       " {'label': 'none', 'score': 1.8555858135223389},\n",
       " {'label': 'none', 'score': 1.5669915676116943},\n",
       " {'label': 'none', 'score': 1.5669915676116943},\n",
       " {'label': 'none', 'score': 1.5669915676116943},\n",
       " {'label': 'returning', 'score': 1.0082578659057617},\n",
       " {'label': 'returning', 'score': 1.0082578659057617},\n",
       " {'label': 'returning', 'score': 1.0082578659057617},\n",
       " {'label': 'returning', 'score': 0.6833579540252686},\n",
       " {'label': 'returning', 'score': 0.6833579540252686},\n",
       " {'label': 'returning', 'score': 0.6833579540252686},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.28687939047813416},\n",
       " {'label': 'returning', 'score': 0.28687939047813416},\n",
       " {'label': 'returning', 'score': 0.28687939047813416},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.4776360988616943},\n",
       " {'label': 'none', 'score': 1.4776360988616943},\n",
       " {'label': 'none', 'score': 1.4776360988616943},\n",
       " {'label': 'none', 'score': 1.501846194267273},\n",
       " {'label': 'none', 'score': 1.501846194267273},\n",
       " {'label': 'none', 'score': 1.501846194267273},\n",
       " {'label': 'none', 'score': 1.9600105285644531},\n",
       " {'label': 'none', 'score': 1.9600105285644531},\n",
       " {'label': 'none', 'score': 1.9600105285644531},\n",
       " {'label': 'none', 'score': 2.192796230316162},\n",
       " {'label': 'none', 'score': 2.192796230316162},\n",
       " {'label': 'none', 'score': 2.192796230316162},\n",
       " {'label': 'none', 'score': 1.827092170715332},\n",
       " {'label': 'none', 'score': 1.827092170715332},\n",
       " {'label': 'none', 'score': 1.827092170715332},\n",
       " {'label': 'none', 'score': 2.1472935676574707},\n",
       " {'label': 'none', 'score': 2.1472935676574707},\n",
       " {'label': 'none', 'score': 2.1472935676574707},\n",
       " {'label': 'none', 'score': 1.7449016571044922},\n",
       " {'label': 'none', 'score': 1.7449016571044922},\n",
       " {'label': 'none', 'score': 1.7449016571044922},\n",
       " {'label': 'none', 'score': 2.112426280975342},\n",
       " {'label': 'none', 'score': 2.112426280975342},\n",
       " {'label': 'none', 'score': 2.112426280975342},\n",
       " {'label': 'none', 'score': 1.784639596939087},\n",
       " {'label': 'none', 'score': 1.784639596939087},\n",
       " {'label': 'none', 'score': 1.784639596939087},\n",
       " {'label': 'none', 'score': 1.840376853942871},\n",
       " {'label': 'none', 'score': 1.840376853942871},\n",
       " {'label': 'none', 'score': 1.840376853942871},\n",
       " {'label': 'none', 'score': 1.8221359252929688},\n",
       " {'label': 'none', 'score': 1.8221359252929688},\n",
       " {'label': 'none', 'score': 1.8221359252929688},\n",
       " {'label': 'none', 'score': 2.309237480163574},\n",
       " {'label': 'none', 'score': 2.309237480163574},\n",
       " {'label': 'none', 'score': 2.309237480163574},\n",
       " {'label': 'none', 'score': 1.9480557441711426},\n",
       " {'label': 'none', 'score': 1.9480557441711426},\n",
       " {'label': 'none', 'score': 1.9480557441711426},\n",
       " {'label': 'none', 'score': 1.8429512977600098},\n",
       " {'label': 'none', 'score': 1.8429512977600098},\n",
       " {'label': 'none', 'score': 1.8429512977600098},\n",
       " {'label': 'none', 'score': 2.095883846282959},\n",
       " {'label': 'none', 'score': 2.095883846282959},\n",
       " {'label': 'none', 'score': 2.095883846282959},\n",
       " {'label': 'none', 'score': 1.4048500061035156},\n",
       " {'label': 'none', 'score': 1.4048500061035156},\n",
       " {'label': 'none', 'score': 1.4048500061035156},\n",
       " {'label': 'none', 'score': 2.2485172748565674},\n",
       " {'label': 'none', 'score': 2.2485172748565674},\n",
       " {'label': 'none', 'score': 2.2485172748565674},\n",
       " {'label': 'leaving', 'score': 1.3902900218963623},\n",
       " {'label': 'leaving', 'score': 1.3902900218963623},\n",
       " {'label': 'leaving', 'score': 1.3902900218963623},\n",
       " {'label': 'returning', 'score': 0.5793955326080322},\n",
       " {'label': 'returning', 'score': 0.5793955326080322},\n",
       " {'label': 'returning', 'score': 0.5793955326080322},\n",
       " {'label': 'none', 'score': 0.9981842041015625},\n",
       " {'label': 'none', 'score': 0.9981842041015625},\n",
       " {'label': 'none', 'score': 0.9981842041015625},\n",
       " {'label': 'none', 'score': 2.063458204269409},\n",
       " {'label': 'none', 'score': 2.063458204269409},\n",
       " {'label': 'none', 'score': 2.063458204269409},\n",
       " {'label': 'none', 'score': 2.15735125541687},\n",
       " {'label': 'none', 'score': 2.15735125541687},\n",
       " {'label': 'none', 'score': 2.15735125541687},\n",
       " {'label': 'none', 'score': 2.2945303916931152},\n",
       " {'label': 'none', 'score': 2.2945303916931152},\n",
       " {'label': 'none', 'score': 2.2945303916931152},\n",
       " {'label': 'none', 'score': 1.9379463195800781},\n",
       " {'label': 'none', 'score': 1.9379463195800781},\n",
       " {'label': 'none', 'score': 1.9379463195800781},\n",
       " {'label': 'none', 'score': 1.4375896453857422},\n",
       " {'label': 'none', 'score': 1.4375896453857422},\n",
       " {'label': 'none', 'score': 1.4375896453857422},\n",
       " {'label': 'none', 'score': 1.8596000671386719},\n",
       " {'label': 'none', 'score': 1.8596000671386719},\n",
       " {'label': 'none', 'score': 1.8596000671386719},\n",
       " {'label': 'none', 'score': 1.9449939727783203},\n",
       " {'label': 'none', 'score': 1.9449939727783203},\n",
       " {'label': 'none', 'score': 1.9449939727783203},\n",
       " {'label': 'none', 'score': 1.849595546722412},\n",
       " {'label': 'none', 'score': 1.849595546722412},\n",
       " {'label': 'none', 'score': 1.849595546722412},\n",
       " {'label': 'none', 'score': 1.9467077255249023},\n",
       " {'label': 'none', 'score': 1.9467077255249023},\n",
       " {'label': 'none', 'score': 1.9467077255249023},\n",
       " {'label': 'returning', 'score': 1.0284538269042969},\n",
       " {'label': 'returning', 'score': 1.0284538269042969},\n",
       " {'label': 'returning', 'score': 1.0284538269042969},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.47677338123321533},\n",
       " {'label': 'returning', 'score': 0.47677338123321533},\n",
       " {'label': 'returning', 'score': 0.47677338123321533},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 2.013993740081787},\n",
       " {'label': 'none', 'score': 2.013993740081787},\n",
       " {'label': 'none', 'score': 2.013993740081787},\n",
       " {'label': 'none', 'score': 2.2695705890655518},\n",
       " {'label': 'none', 'score': 2.2695705890655518},\n",
       " {'label': 'none', 'score': 2.2695705890655518},\n",
       " {'label': 'none', 'score': 1.790031909942627},\n",
       " {'label': 'none', 'score': 1.790031909942627},\n",
       " {'label': 'none', 'score': 1.790031909942627},\n",
       " {'label': 'none', 'score': 2.2455310821533203},\n",
       " {'label': 'none', 'score': 2.2455310821533203},\n",
       " {'label': 'none', 'score': 2.2455310821533203},\n",
       " {'label': 'none', 'score': 2.5032331943511963},\n",
       " {'label': 'none', 'score': 2.5032331943511963},\n",
       " {'label': 'none', 'score': 2.5032331943511963},\n",
       " {'label': 'none', 'score': 1.8032047748565674},\n",
       " {'label': 'none', 'score': 1.8032047748565674},\n",
       " {'label': 'none', 'score': 1.8032047748565674},\n",
       " {'label': 'none', 'score': 1.4437320232391357},\n",
       " {'label': 'none', 'score': 1.4437320232391357},\n",
       " {'label': 'none', 'score': 1.4437320232391357},\n",
       " {'label': 'none', 'score': 1.9327292442321777},\n",
       " {'label': 'none', 'score': 1.9327292442321777},\n",
       " {'label': 'none', 'score': 1.9327292442321777},\n",
       " {'label': 'none', 'score': 1.9833886623382568},\n",
       " {'label': 'none', 'score': 1.9833886623382568},\n",
       " {'label': 'none', 'score': 1.9833886623382568},\n",
       " {'label': 'none', 'score': 1.8101544380187988},\n",
       " {'label': 'none', 'score': 1.8101544380187988},\n",
       " {'label': 'none', 'score': 1.8101544380187988},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.8638221025466919},\n",
       " {'label': 'returning', 'score': 0.8638221025466919},\n",
       " {'label': 'returning', 'score': 0.8638221025466919},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.7022759914398193},\n",
       " {'label': 'returning', 'score': 0.7022759914398193},\n",
       " {'label': 'returning', 'score': 0.7022759914398193},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.619018018245697},\n",
       " {'label': 'returning', 'score': 0.619018018245697},\n",
       " {'label': 'returning', 'score': 0.619018018245697},\n",
       " {'label': 'returning', 'score': 1.4331837892532349},\n",
       " {'label': 'returning', 'score': 1.4331837892532349},\n",
       " {'label': 'returning', 'score': 1.4331837892532349},\n",
       " {'label': 'none', 'score': 1.8651094436645508},\n",
       " {'label': 'none', 'score': 1.8651094436645508},\n",
       " {'label': 'none', 'score': 1.8651094436645508},\n",
       " {'label': 'none', 'score': 1.8166685104370117},\n",
       " {'label': 'none', 'score': 1.8166685104370117},\n",
       " {'label': 'none', 'score': 1.8166685104370117},\n",
       " {'label': 'none', 'score': 1.7949200868606567},\n",
       " {'label': 'none', 'score': 1.7949200868606567},\n",
       " {'label': 'none', 'score': 1.7949200868606567},\n",
       " {'label': 'none', 'score': 1.5707305669784546},\n",
       " {'label': 'none', 'score': 1.5707305669784546},\n",
       " {'label': 'none', 'score': 1.5707305669784546},\n",
       " {'label': 'none', 'score': 1.8183317184448242},\n",
       " {'label': 'none', 'score': 1.8183317184448242},\n",
       " {'label': 'none', 'score': 1.8183317184448242},\n",
       " {'label': 'none', 'score': 1.965153455734253},\n",
       " {'label': 'none', 'score': 1.965153455734253},\n",
       " {'label': 'none', 'score': 1.965153455734253},\n",
       " {'label': 'none', 'score': 1.6522502899169922},\n",
       " {'label': 'none', 'score': 1.6522502899169922},\n",
       " {'label': 'none', 'score': 1.6522502899169922},\n",
       " {'label': 'none', 'score': 1.8722589015960693},\n",
       " {'label': 'none', 'score': 1.8722589015960693},\n",
       " {'label': 'none', 'score': 1.8722589015960693},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.2330517768859863},\n",
       " {'label': 'none', 'score': 1.8975532054901123},\n",
       " {'label': 'none', 'score': 1.8975532054901123},\n",
       " {'label': 'none', 'score': 1.8975532054901123},\n",
       " {'label': 'none', 'score': 2.171699285507202},\n",
       " {'label': 'none', 'score': 2.171699285507202},\n",
       " {'label': 'none', 'score': 2.171699285507202},\n",
       " {'label': 'none', 'score': 1.8386590480804443},\n",
       " {'label': 'none', 'score': 1.8386590480804443},\n",
       " {'label': 'none', 'score': 1.8386590480804443},\n",
       " {'label': 'none', 'score': 1.764005422592163},\n",
       " {'label': 'none', 'score': 1.764005422592163},\n",
       " {'label': 'none', 'score': 1.764005422592163},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.7902252674102783},\n",
       " {'label': 'returning', 'score': 0.7902252674102783},\n",
       " {'label': 'returning', 'score': 0.7902252674102783},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 1.2330517768859863},\n",
       " {'label': 'returning', 'score': 0.4700310528278351},\n",
       " {'label': 'returning', 'score': 0.4700310528278351},\n",
       " {'label': 'returning', 'score': 0.4700310528278351},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 1.2330517768859863},\n",
       " {'label': 'leaving', 'score': 0.4364086091518402},\n",
       " {'label': 'leaving', 'score': 0.4364086091518402},\n",
       " {'label': 'leaving', 'score': 0.4364086091518402},\n",
       " {'label': 'returning', 'score': 1.4821200370788574},\n",
       " {'label': 'returning', 'score': 1.4821200370788574},\n",
       " {'label': 'returning', 'score': 1.4821200370788574},\n",
       " {'label': 'none', 'score': 1.4938416481018066},\n",
       " {'label': 'none', 'score': 1.4938416481018066},\n",
       " {'label': 'none', 'score': 1.4938416481018066},\n",
       " {'label': 'none', 'score': 1.9450855255126953},\n",
       " {'label': 'none', 'score': 1.9450855255126953},\n",
       " {'label': 'none', 'score': 1.9450855255126953},\n",
       " {'label': 'none', 'score': 1.9587678909301758},\n",
       " {'label': 'none', 'score': 1.9587678909301758},\n",
       " {'label': 'none', 'score': 1.9587678909301758},\n",
       " {'label': 'none', 'score': 2.1641347408294678},\n",
       " {'label': 'none', 'score': 2.1641347408294678},\n",
       " {'label': 'none', 'score': 2.1641347408294678},\n",
       " {'label': 'none', 'score': 2.0584816932678223},\n",
       " {'label': 'none', 'score': 2.0584816932678223},\n",
       " {'label': 'none', 'score': 2.0584816932678223}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:23:00.366660Z",
     "start_time": "2020-03-16T19:23:00.354478Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " with open(os.path.join(results_path,'validation_results.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:01.683681Z",
     "start_time": "2020-03-16T19:27:01.667199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:02.601425Z",
     "start_time": "2020-03-16T19:27:02.416046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - More diverse dataset \n",
    "    - Hyperparameter tuning\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
