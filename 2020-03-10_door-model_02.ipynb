{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T23:39:59.103973Z",
     "start_time": "2020-03-13T23:39:59.094530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T23:39:59.726055Z",
     "start_time": "2020-03-13T23:39:59.688383Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T23:40:00.426751Z",
     "start_time": "2020-03-13T23:40:00.392862Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T23:40:36.825424Z",
     "start_time": "2020-03-13T23:40:36.810409Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 256), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=0))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-2,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 0.638 (0.638)\tData 0.347 (0.347)\tLoss 1.0935 (1.0935)\tAcc 0.500 (0.500)\n",
      "Epoch: [1][2/5]\tTime 0.026 (0.332)\tData 0.002 (0.175)\tLoss 0.9553 (1.0244)\tAcc 0.688 (0.594)\n",
      "Epoch: [1][3/5]\tTime 0.092 (0.252)\tData 0.068 (0.139)\tLoss 1.2481 (1.0990)\tAcc 0.375 (0.521)\n",
      "Epoch: [1][4/5]\tTime 0.087 (0.211)\tData 0.063 (0.120)\tLoss 0.6308 (0.9819)\tAcc 0.812 (0.594)\n",
      "Epoch: [1][5/5]\tTime 0.080 (0.185)\tData 0.056 (0.107)\tLoss 0.7501 (0.9533)\tAcc 0.778 (0.616)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.279 (0.279)\tData 0.254 (0.254)\tLoss 0.4447 (0.4447)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.070 (0.174)\tData 0.049 (0.151)\tLoss 1.3541 (0.8994)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.073 (0.140)\tData 0.052 (0.118)\tLoss 0.8728 (0.8905)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.073 (0.124)\tData 0.052 (0.102)\tLoss 0.8340 (0.8764)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.078 (0.114)\tData 0.057 (0.093)\tLoss 0.8410 (0.8693)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.073 (0.108)\tData 0.052 (0.086)\tLoss 0.3153 (0.7770)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.072 (0.102)\tData 0.052 (0.081)\tLoss 0.5598 (0.7460)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.073 (0.099)\tData 0.053 (0.078)\tLoss 1.2403 (0.8077)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.074 (0.096)\tData 0.054 (0.075)\tLoss 0.2778 (0.7996)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.313 (0.313)\tData 0.283 (0.283)\tLoss 0.7991 (0.7991)\tAcc 0.750 (0.750)\n",
      "Epoch: [2][2/5]\tTime 0.076 (0.195)\tData 0.051 (0.167)\tLoss 0.5912 (0.6952)\tAcc 0.812 (0.781)\n",
      "Epoch: [2][3/5]\tTime 0.076 (0.155)\tData 0.052 (0.129)\tLoss 0.9625 (0.7843)\tAcc 0.562 (0.708)\n",
      "Epoch: [2][4/5]\tTime 0.076 (0.135)\tData 0.052 (0.110)\tLoss 1.0526 (0.8514)\tAcc 0.625 (0.688)\n",
      "Epoch: [2][5/5]\tTime 0.079 (0.124)\tData 0.055 (0.099)\tLoss 0.9515 (0.8637)\tAcc 0.556 (0.671)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.380 (0.380)\tData 0.356 (0.356)\tLoss 0.6616 (0.6616)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.071 (0.225)\tData 0.050 (0.203)\tLoss 1.2582 (0.9599)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.073 (0.174)\tData 0.052 (0.152)\tLoss 0.8328 (0.9175)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.073 (0.149)\tData 0.052 (0.127)\tLoss 0.9742 (0.9317)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.071 (0.133)\tData 0.051 (0.112)\tLoss 0.8173 (0.9088)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.074 (0.124)\tData 0.053 (0.102)\tLoss 0.6139 (0.8597)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.071 (0.116)\tData 0.052 (0.095)\tLoss 0.7232 (0.8402)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.073 (0.111)\tData 0.053 (0.090)\tLoss 1.0349 (0.8645)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.075 (0.107)\tData 0.054 (0.086)\tLoss 0.5231 (0.8592)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.309 (0.309)\tData 0.280 (0.280)\tLoss 0.8192 (0.8192)\tAcc 0.750 (0.750)\n",
      "Epoch: [3][2/5]\tTime 0.072 (0.190)\tData 0.048 (0.164)\tLoss 1.0107 (0.9149)\tAcc 0.500 (0.625)\n",
      "Epoch: [3][3/5]\tTime 0.076 (0.152)\tData 0.053 (0.127)\tLoss 0.8432 (0.8910)\tAcc 0.750 (0.667)\n",
      "Epoch: [3][4/5]\tTime 0.075 (0.133)\tData 0.052 (0.108)\tLoss 0.8189 (0.8730)\tAcc 0.875 (0.719)\n",
      "Epoch: [3][5/5]\tTime 0.078 (0.122)\tData 0.055 (0.098)\tLoss 0.8874 (0.8748)\tAcc 0.556 (0.699)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.336 (0.336)\tData 0.311 (0.311)\tLoss 0.4156 (0.4156)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.069 (0.203)\tData 0.048 (0.179)\tLoss 1.1519 (0.7837)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.137)\tLoss 0.9255 (0.8310)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.072 (0.138)\tData 0.052 (0.116)\tLoss 0.7838 (0.8192)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.072 (0.125)\tData 0.053 (0.103)\tLoss 0.9238 (0.8401)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.095)\tLoss 0.3411 (0.7569)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.071 (0.110)\tData 0.052 (0.089)\tLoss 0.5131 (0.7221)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.073 (0.105)\tData 0.053 (0.084)\tLoss 1.2203 (0.7844)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.3874 (0.7783)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.329 (0.329)\tData 0.301 (0.301)\tLoss 0.6431 (0.6431)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][2/5]\tTime 0.075 (0.202)\tData 0.050 (0.176)\tLoss 0.2967 (0.4699)\tAcc 0.938 (0.812)\n",
      "Epoch: [4][3/5]\tTime 0.075 (0.160)\tData 0.051 (0.134)\tLoss 1.2062 (0.7153)\tAcc 0.562 (0.729)\n",
      "Epoch: [4][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.114)\tLoss 1.4171 (0.8908)\tAcc 0.625 (0.703)\n",
      "Epoch: [4][5/5]\tTime 0.078 (0.127)\tData 0.054 (0.102)\tLoss 1.3645 (0.9492)\tAcc 0.444 (0.671)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.296 (0.296)\tData 0.271 (0.271)\tLoss 0.3938 (0.3938)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.110 (0.203)\tData 0.089 (0.180)\tLoss 1.2557 (0.8247)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.074 (0.160)\tData 0.052 (0.137)\tLoss 0.9419 (0.8638)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/9]\tTime 0.071 (0.138)\tData 0.050 (0.115)\tLoss 0.8309 (0.8556)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/9]\tTime 0.076 (0.126)\tData 0.054 (0.103)\tLoss 1.0054 (0.8855)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/9]\tTime 0.073 (0.117)\tData 0.052 (0.095)\tLoss 0.2621 (0.7816)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/9]\tTime 0.072 (0.110)\tData 0.052 (0.088)\tLoss 0.4956 (0.7408)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/9]\tTime 0.073 (0.106)\tData 0.053 (0.084)\tLoss 1.2422 (0.8034)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/9]\tTime 0.075 (0.102)\tData 0.054 (0.081)\tLoss 0.2727 (0.7953)\tAcc 1.000 (0.731)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.293 (0.293)\tData 0.265 (0.265)\tLoss 0.7170 (0.7170)\tAcc 0.625 (0.625)\n",
      "Epoch: [5][2/5]\tTime 0.073 (0.183)\tData 0.049 (0.157)\tLoss 0.7579 (0.7375)\tAcc 0.688 (0.656)\n",
      "Epoch: [5][3/5]\tTime 0.076 (0.147)\tData 0.052 (0.122)\tLoss 0.8722 (0.7824)\tAcc 0.625 (0.646)\n",
      "Epoch: [5][4/5]\tTime 0.076 (0.129)\tData 0.053 (0.105)\tLoss 0.9672 (0.8286)\tAcc 0.500 (0.609)\n",
      "Epoch: [5][5/5]\tTime 0.078 (0.119)\tData 0.055 (0.095)\tLoss 0.8066 (0.8259)\tAcc 0.667 (0.616)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.318 (0.318)\tData 0.294 (0.294)\tLoss 0.6944 (0.6944)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.071 (0.194)\tData 0.049 (0.172)\tLoss 1.0679 (0.8812)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.073 (0.154)\tData 0.052 (0.132)\tLoss 0.9114 (0.8913)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.073 (0.134)\tData 0.051 (0.112)\tLoss 0.8982 (0.8930)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.072 (0.121)\tData 0.051 (0.099)\tLoss 0.9218 (0.8988)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.074 (0.114)\tData 0.053 (0.092)\tLoss 0.6088 (0.8504)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.072 (0.108)\tData 0.052 (0.086)\tLoss 0.6530 (0.8222)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.073 (0.103)\tData 0.053 (0.082)\tLoss 1.0700 (0.8532)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 0.5997 (0.8493)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.291 (0.291)\tData 0.261 (0.261)\tLoss 0.7049 (0.7049)\tAcc 0.750 (0.750)\n",
      "Epoch: [6][2/5]\tTime 0.075 (0.183)\tData 0.048 (0.155)\tLoss 0.8936 (0.7992)\tAcc 0.500 (0.625)\n",
      "Epoch: [6][3/5]\tTime 0.074 (0.147)\tData 0.050 (0.120)\tLoss 0.9698 (0.8561)\tAcc 0.562 (0.604)\n",
      "Epoch: [6][4/5]\tTime 0.075 (0.129)\tData 0.052 (0.103)\tLoss 0.6387 (0.8017)\tAcc 0.750 (0.641)\n",
      "Epoch: [6][5/5]\tTime 0.078 (0.119)\tData 0.055 (0.093)\tLoss 0.5152 (0.7664)\tAcc 0.889 (0.671)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.340 (0.340)\tData 0.314 (0.314)\tLoss 0.3402 (0.3402)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.069 (0.204)\tData 0.048 (0.181)\tLoss 1.5363 (0.9382)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/9]\tTime 0.074 (0.161)\tData 0.052 (0.138)\tLoss 0.9824 (0.9530)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/9]\tTime 0.073 (0.139)\tData 0.051 (0.116)\tLoss 0.9741 (0.9582)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/9]\tTime 0.071 (0.125)\tData 0.051 (0.103)\tLoss 1.0194 (0.9705)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/9]\tTime 0.075 (0.117)\tData 0.054 (0.095)\tLoss 0.1784 (0.8385)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.4550 (0.7837)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 1.4757 (0.8702)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.1598 (0.8593)\tAcc 1.000 (0.731)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.286 (0.286)\tData 0.258 (0.258)\tLoss 0.4896 (0.4896)\tAcc 0.750 (0.750)\n",
      "Epoch: [7][2/5]\tTime 0.106 (0.196)\tData 0.081 (0.170)\tLoss 1.3396 (0.9146)\tAcc 0.562 (0.656)\n",
      "Epoch: [7][3/5]\tTime 0.076 (0.156)\tData 0.052 (0.131)\tLoss 1.3130 (1.0474)\tAcc 0.500 (0.604)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.077 (0.136)\tData 0.052 (0.111)\tLoss 0.8384 (0.9951)\tAcc 0.688 (0.625)\n",
      "Epoch: [7][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.100)\tLoss 0.6294 (0.9500)\tAcc 0.778 (0.644)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.330 (0.330)\tData 0.306 (0.306)\tLoss 0.6591 (0.6591)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.071 (0.201)\tData 0.050 (0.178)\tLoss 1.0927 (0.8759)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.073 (0.158)\tData 0.052 (0.136)\tLoss 0.8912 (0.8810)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.073 (0.137)\tData 0.052 (0.115)\tLoss 0.9107 (0.8884)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.072 (0.124)\tData 0.052 (0.103)\tLoss 0.8861 (0.8879)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.094)\tLoss 0.6145 (0.8424)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.072 (0.109)\tData 0.053 (0.088)\tLoss 0.6966 (0.8215)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 1.0392 (0.8487)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.6123 (0.8451)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.332 (0.332)\tData 0.303 (0.303)\tLoss 0.8531 (0.8531)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][2/5]\tTime 0.073 (0.203)\tData 0.049 (0.176)\tLoss 0.7923 (0.8227)\tAcc 0.688 (0.719)\n",
      "Epoch: [8][3/5]\tTime 0.076 (0.161)\tData 0.053 (0.135)\tLoss 0.8467 (0.8307)\tAcc 0.625 (0.688)\n",
      "Epoch: [8][4/5]\tTime 0.076 (0.139)\tData 0.053 (0.114)\tLoss 0.8096 (0.8254)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/5]\tTime 0.079 (0.127)\tData 0.056 (0.103)\tLoss 0.6123 (0.7991)\tAcc 0.778 (0.699)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.366 (0.366)\tData 0.341 (0.341)\tLoss 0.5031 (0.5031)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.071 (0.218)\tData 0.050 (0.196)\tLoss 1.2304 (0.8667)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/9]\tTime 0.073 (0.170)\tData 0.052 (0.148)\tLoss 0.7883 (0.8406)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/9]\tTime 0.075 (0.146)\tData 0.052 (0.124)\tLoss 0.8673 (0.8473)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/9]\tTime 0.070 (0.131)\tData 0.050 (0.109)\tLoss 0.8351 (0.8448)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.3836 (0.7680)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.093)\tLoss 0.5706 (0.7398)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 1.1388 (0.7896)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.084)\tLoss 0.4211 (0.7840)\tAcc 1.000 (0.731)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.264 (0.264)\tData 0.235 (0.235)\tLoss 0.7950 (0.7950)\tAcc 0.625 (0.625)\n",
      "Epoch: [9][2/5]\tTime 0.074 (0.169)\tData 0.049 (0.142)\tLoss 0.8351 (0.8151)\tAcc 0.688 (0.656)\n",
      "Epoch: [9][3/5]\tTime 0.076 (0.138)\tData 0.052 (0.112)\tLoss 1.0737 (0.9013)\tAcc 0.562 (0.625)\n",
      "Epoch: [9][4/5]\tTime 0.076 (0.122)\tData 0.053 (0.097)\tLoss 0.6082 (0.8280)\tAcc 0.750 (0.656)\n",
      "Epoch: [9][5/5]\tTime 0.080 (0.114)\tData 0.055 (0.089)\tLoss 0.5416 (0.7927)\tAcc 0.778 (0.671)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.299 (0.299)\tData 0.272 (0.272)\tLoss 0.5106 (0.5106)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/9]\tTime 0.078 (0.188)\tData 0.050 (0.161)\tLoss 1.3776 (0.9441)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/9]\tTime 0.074 (0.150)\tData 0.046 (0.123)\tLoss 0.9591 (0.9491)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/9]\tTime 0.068 (0.130)\tData 0.047 (0.104)\tLoss 0.9146 (0.9405)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/9]\tTime 0.074 (0.118)\tData 0.052 (0.093)\tLoss 0.8804 (0.9285)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/9]\tTime 0.073 (0.111)\tData 0.053 (0.086)\tLoss 0.3330 (0.8292)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/9]\tTime 0.072 (0.105)\tData 0.052 (0.082)\tLoss 0.6280 (0.8005)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/9]\tTime 0.074 (0.101)\tData 0.054 (0.078)\tLoss 1.1219 (0.8406)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/9]\tTime 0.075 (0.099)\tData 0.055 (0.075)\tLoss 0.3678 (0.8334)\tAcc 1.000 (0.731)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.338 (0.338)\tData 0.310 (0.310)\tLoss 0.9537 (0.9537)\tAcc 0.562 (0.562)\n",
      "Epoch: [10][2/5]\tTime 0.075 (0.207)\tData 0.050 (0.180)\tLoss 0.7679 (0.8608)\tAcc 0.688 (0.625)\n",
      "Epoch: [10][3/5]\tTime 0.075 (0.163)\tData 0.051 (0.137)\tLoss 0.7444 (0.8220)\tAcc 0.750 (0.667)\n",
      "Epoch: [10][4/5]\tTime 0.076 (0.141)\tData 0.053 (0.116)\tLoss 0.9506 (0.8541)\tAcc 0.688 (0.672)\n",
      "Epoch: [10][5/5]\tTime 0.080 (0.129)\tData 0.055 (0.104)\tLoss 0.7886 (0.8461)\tAcc 0.778 (0.685)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.379 (0.379)\tData 0.352 (0.352)\tLoss 0.7742 (0.7742)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.069 (0.224)\tData 0.047 (0.200)\tLoss 1.1347 (0.9544)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/9]\tTime 0.073 (0.173)\tData 0.052 (0.150)\tLoss 0.8666 (0.9251)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.075 (0.149)\tData 0.054 (0.126)\tLoss 0.9589 (0.9336)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.073 (0.134)\tData 0.053 (0.112)\tLoss 0.8729 (0.9214)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.075 (0.124)\tData 0.054 (0.102)\tLoss 0.6845 (0.8819)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.072 (0.117)\tData 0.053 (0.095)\tLoss 0.7693 (0.8659)\tAcc 0.812 (0.750)\n",
      "Epoch: [10][8/9]\tTime 0.074 (0.111)\tData 0.054 (0.090)\tLoss 1.0239 (0.8856)\tAcc 0.438 (0.711)\n",
      "Epoch: [10][9/9]\tTime 0.075 (0.107)\tData 0.055 (0.086)\tLoss 0.8344 (0.8848)\tAcc 1.000 (0.715)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.395 (0.395)\tData 0.367 (0.367)\tLoss 0.6623 (0.6623)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][2/5]\tTime 0.075 (0.235)\tData 0.050 (0.209)\tLoss 0.7772 (0.7197)\tAcc 0.750 (0.719)\n",
      "Epoch: [11][3/5]\tTime 0.076 (0.182)\tData 0.052 (0.157)\tLoss 0.6731 (0.7042)\tAcc 0.625 (0.688)\n",
      "Epoch: [11][4/5]\tTime 0.076 (0.156)\tData 0.053 (0.131)\tLoss 0.9196 (0.7580)\tAcc 0.625 (0.672)\n",
      "Epoch: [11][5/5]\tTime 0.079 (0.140)\tData 0.055 (0.115)\tLoss 0.9512 (0.7818)\tAcc 0.556 (0.658)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.333 (0.333)\tData 0.307 (0.307)\tLoss 0.4997 (0.4997)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/9]\tTime 0.073 (0.203)\tData 0.051 (0.179)\tLoss 1.2366 (0.8682)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.137)\tLoss 0.9826 (0.9063)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][4/9]\tTime 0.075 (0.138)\tData 0.052 (0.115)\tLoss 0.8891 (0.9020)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][5/9]\tTime 0.072 (0.125)\tData 0.051 (0.103)\tLoss 0.7886 (0.8793)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][6/9]\tTime 0.073 (0.117)\tData 0.052 (0.094)\tLoss 0.4128 (0.8016)\tAcc 1.000 (0.740)\n",
      "Epoch: [11][7/9]\tTime 0.072 (0.110)\tData 0.053 (0.088)\tLoss 0.5759 (0.7693)\tAcc 0.875 (0.759)\n",
      "Epoch: [11][8/9]\tTime 0.074 (0.106)\tData 0.054 (0.084)\tLoss 1.2263 (0.8265)\tAcc 0.500 (0.727)\n",
      "Epoch: [11][9/9]\tTime 0.076 (0.102)\tData 0.055 (0.081)\tLoss 0.6232 (0.8233)\tAcc 1.000 (0.731)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.341 (0.341)\tData 0.311 (0.311)\tLoss 0.9100 (0.9100)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][2/5]\tTime 0.073 (0.207)\tData 0.048 (0.179)\tLoss 0.9427 (0.9264)\tAcc 0.500 (0.594)\n",
      "Epoch: [12][3/5]\tTime 0.075 (0.163)\tData 0.052 (0.137)\tLoss 0.7575 (0.8701)\tAcc 0.750 (0.646)\n",
      "Epoch: [12][4/5]\tTime 0.076 (0.141)\tData 0.053 (0.116)\tLoss 0.8792 (0.8724)\tAcc 0.625 (0.641)\n",
      "Epoch: [12][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.104)\tLoss 0.6769 (0.8483)\tAcc 0.778 (0.658)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.350 (0.350)\tData 0.326 (0.326)\tLoss 0.6798 (0.6798)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/9]\tTime 0.071 (0.211)\tData 0.050 (0.188)\tLoss 1.0281 (0.8540)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/9]\tTime 0.073 (0.165)\tData 0.052 (0.143)\tLoss 0.9190 (0.8757)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][4/9]\tTime 0.072 (0.142)\tData 0.052 (0.120)\tLoss 0.7928 (0.8550)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/9]\tTime 0.074 (0.128)\tData 0.054 (0.107)\tLoss 0.9773 (0.8794)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][6/9]\tTime 0.074 (0.119)\tData 0.054 (0.098)\tLoss 0.6160 (0.8355)\tAcc 1.000 (0.740)\n",
      "Epoch: [12][7/9]\tTime 0.073 (0.112)\tData 0.053 (0.092)\tLoss 0.6788 (0.8131)\tAcc 0.875 (0.759)\n",
      "Epoch: [12][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.087)\tLoss 1.1192 (0.8514)\tAcc 0.562 (0.734)\n",
      "Epoch: [12][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.4758 (0.8456)\tAcc 1.000 (0.738)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.289 (0.289)\tData 0.260 (0.260)\tLoss 0.7190 (0.7190)\tAcc 0.750 (0.750)\n",
      "Epoch: [13][2/5]\tTime 0.073 (0.181)\tData 0.049 (0.154)\tLoss 0.7941 (0.7566)\tAcc 0.688 (0.719)\n",
      "Epoch: [13][3/5]\tTime 0.076 (0.146)\tData 0.053 (0.120)\tLoss 0.7443 (0.7525)\tAcc 0.688 (0.708)\n",
      "Epoch: [13][4/5]\tTime 0.077 (0.129)\tData 0.053 (0.104)\tLoss 0.9108 (0.7921)\tAcc 0.562 (0.672)\n",
      "Epoch: [13][5/5]\tTime 0.079 (0.119)\tData 0.056 (0.094)\tLoss 0.6591 (0.7757)\tAcc 0.667 (0.671)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.368 (0.368)\tData 0.343 (0.343)\tLoss 0.5170 (0.5170)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/9]\tTime 0.071 (0.220)\tData 0.049 (0.196)\tLoss 1.1199 (0.8185)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/9]\tTime 0.073 (0.171)\tData 0.052 (0.148)\tLoss 0.8690 (0.8353)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/9]\tTime 0.073 (0.146)\tData 0.052 (0.124)\tLoss 0.7085 (0.8036)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][5/9]\tTime 0.074 (0.132)\tData 0.052 (0.110)\tLoss 0.8445 (0.8118)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][6/9]\tTime 0.074 (0.122)\tData 0.053 (0.100)\tLoss 0.3791 (0.7397)\tAcc 1.000 (0.740)\n",
      "Epoch: [13][7/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.5834 (0.7173)\tAcc 0.875 (0.759)\n",
      "Epoch: [13][8/9]\tTime 0.074 (0.110)\tData 0.054 (0.088)\tLoss 1.1777 (0.7749)\tAcc 0.500 (0.727)\n",
      "Epoch: [13][9/9]\tTime 0.075 (0.106)\tData 0.054 (0.085)\tLoss 0.4955 (0.7706)\tAcc 1.000 (0.731)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.370 (0.370)\tData 0.341 (0.341)\tLoss 0.7026 (0.7026)\tAcc 0.625 (0.625)\n",
      "Epoch: [14][2/5]\tTime 0.073 (0.222)\tData 0.049 (0.195)\tLoss 0.5649 (0.6338)\tAcc 0.812 (0.719)\n",
      "Epoch: [14][3/5]\tTime 0.076 (0.173)\tData 0.052 (0.147)\tLoss 0.8609 (0.7095)\tAcc 0.688 (0.708)\n",
      "Epoch: [14][4/5]\tTime 0.076 (0.149)\tData 0.053 (0.124)\tLoss 0.8358 (0.7411)\tAcc 0.688 (0.703)\n",
      "Epoch: [14][5/5]\tTime 0.079 (0.135)\tData 0.056 (0.110)\tLoss 1.0917 (0.7843)\tAcc 0.556 (0.685)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.308 (0.308)\tData 0.282 (0.282)\tLoss 0.5139 (0.5139)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.069 (0.189)\tData 0.048 (0.165)\tLoss 1.1230 (0.8184)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/9]\tTime 0.073 (0.150)\tData 0.053 (0.127)\tLoss 0.9083 (0.8484)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][4/9]\tTime 0.075 (0.131)\tData 0.052 (0.109)\tLoss 0.8638 (0.8523)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][5/9]\tTime 0.071 (0.119)\tData 0.051 (0.097)\tLoss 0.8919 (0.8602)\tAcc 0.625 (0.675)\n",
      "Epoch: [14][6/9]\tTime 0.075 (0.112)\tData 0.054 (0.090)\tLoss 0.4018 (0.7838)\tAcc 1.000 (0.729)\n",
      "Epoch: [14][7/9]\tTime 0.072 (0.106)\tData 0.053 (0.085)\tLoss 0.6634 (0.7666)\tAcc 0.812 (0.741)\n",
      "Epoch: [14][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.081)\tLoss 1.1498 (0.8145)\tAcc 0.500 (0.711)\n",
      "Epoch: [14][9/9]\tTime 0.075 (0.099)\tData 0.055 (0.078)\tLoss 0.2101 (0.8052)\tAcc 1.000 (0.715)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.311 (0.311)\tData 0.281 (0.281)\tLoss 0.8666 (0.8666)\tAcc 0.625 (0.625)\n",
      "Epoch: [15][2/5]\tTime 0.071 (0.191)\tData 0.048 (0.164)\tLoss 0.5664 (0.7165)\tAcc 0.812 (0.719)\n",
      "Epoch: [15][3/5]\tTime 0.076 (0.153)\tData 0.053 (0.127)\tLoss 0.7404 (0.7245)\tAcc 0.812 (0.750)\n",
      "Epoch: [15][4/5]\tTime 0.077 (0.134)\tData 0.054 (0.109)\tLoss 0.8724 (0.7615)\tAcc 0.500 (0.688)\n",
      "Epoch: [15][5/5]\tTime 0.079 (0.123)\tData 0.056 (0.098)\tLoss 0.8441 (0.7716)\tAcc 0.667 (0.685)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.312 (0.312)\tData 0.285 (0.285)\tLoss 0.7250 (0.7250)\tAcc 0.812 (0.812)\n",
      "Epoch: [15][2/9]\tTime 0.068 (0.190)\tData 0.047 (0.166)\tLoss 1.0810 (0.9030)\tAcc 0.500 (0.656)\n",
      "Epoch: [15][3/9]\tTime 0.075 (0.152)\tData 0.052 (0.128)\tLoss 0.8307 (0.8789)\tAcc 0.562 (0.625)\n",
      "Epoch: [15][4/9]\tTime 0.071 (0.132)\tData 0.051 (0.109)\tLoss 0.8721 (0.8772)\tAcc 0.688 (0.641)\n",
      "Epoch: [15][5/9]\tTime 0.074 (0.120)\tData 0.054 (0.098)\tLoss 1.1415 (0.9301)\tAcc 0.438 (0.600)\n",
      "Epoch: [15][6/9]\tTime 0.074 (0.112)\tData 0.054 (0.090)\tLoss 0.5654 (0.8693)\tAcc 0.875 (0.646)\n",
      "Epoch: [15][7/9]\tTime 0.073 (0.107)\tData 0.053 (0.085)\tLoss 0.8774 (0.8704)\tAcc 0.688 (0.652)\n",
      "Epoch: [15][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 1.0173 (0.8888)\tAcc 0.375 (0.617)\n",
      "Epoch: [15][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.8939 (0.8889)\tAcc 1.000 (0.623)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.341 (0.341)\tData 0.311 (0.311)\tLoss 1.0279 (1.0279)\tAcc 0.500 (0.500)\n",
      "Epoch: [16][2/5]\tTime 0.073 (0.207)\tData 0.048 (0.180)\tLoss 0.5630 (0.7955)\tAcc 0.875 (0.688)\n",
      "Epoch: [16][3/5]\tTime 0.076 (0.163)\tData 0.053 (0.137)\tLoss 0.7104 (0.7671)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.116)\tLoss 1.0108 (0.8280)\tAcc 0.625 (0.672)\n",
      "Epoch: [16][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.104)\tLoss 0.7701 (0.8209)\tAcc 0.667 (0.671)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.317 (0.317)\tData 0.290 (0.290)\tLoss 0.4355 (0.4355)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.069 (0.193)\tData 0.047 (0.169)\tLoss 1.1148 (0.7752)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/9]\tTime 0.073 (0.153)\tData 0.052 (0.130)\tLoss 0.7109 (0.7538)\tAcc 0.750 (0.708)\n",
      "Epoch: [16][4/9]\tTime 0.073 (0.133)\tData 0.052 (0.110)\tLoss 0.7783 (0.7599)\tAcc 0.688 (0.703)\n",
      "Epoch: [16][5/9]\tTime 0.074 (0.121)\tData 0.053 (0.099)\tLoss 0.7928 (0.7665)\tAcc 0.688 (0.700)\n",
      "Epoch: [16][6/9]\tTime 0.074 (0.113)\tData 0.053 (0.091)\tLoss 0.2894 (0.6870)\tAcc 1.000 (0.750)\n",
      "Epoch: [16][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.6451 (0.6810)\tAcc 0.812 (0.759)\n",
      "Epoch: [16][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.082)\tLoss 1.2518 (0.7523)\tAcc 0.500 (0.727)\n",
      "Epoch: [16][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 0.2563 (0.7447)\tAcc 1.000 (0.731)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.292 (0.292)\tData 0.261 (0.261)\tLoss 0.4877 (0.4877)\tAcc 0.812 (0.812)\n",
      "Epoch: [17][2/5]\tTime 0.071 (0.182)\tData 0.047 (0.154)\tLoss 0.5061 (0.4969)\tAcc 0.875 (0.844)\n",
      "Epoch: [17][3/5]\tTime 0.078 (0.147)\tData 0.053 (0.120)\tLoss 1.2007 (0.7315)\tAcc 0.562 (0.750)\n",
      "Epoch: [17][4/5]\tTime 0.075 (0.129)\tData 0.052 (0.103)\tLoss 0.5100 (0.6761)\tAcc 0.750 (0.750)\n",
      "Epoch: [17][5/5]\tTime 0.079 (0.119)\tData 0.055 (0.094)\tLoss 1.7926 (0.8138)\tAcc 0.222 (0.685)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.320 (0.320)\tData 0.295 (0.295)\tLoss 0.4496 (0.4496)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/9]\tTime 0.072 (0.196)\tData 0.050 (0.172)\tLoss 1.0292 (0.7394)\tAcc 0.562 (0.750)\n",
      "Epoch: [17][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.132)\tLoss 0.7176 (0.7321)\tAcc 0.625 (0.708)\n",
      "Epoch: [17][4/9]\tTime 0.072 (0.134)\tData 0.052 (0.112)\tLoss 0.7226 (0.7298)\tAcc 0.750 (0.719)\n",
      "Epoch: [17][5/9]\tTime 0.073 (0.122)\tData 0.054 (0.100)\tLoss 0.7999 (0.7438)\tAcc 0.688 (0.713)\n",
      "Epoch: [17][6/9]\tTime 0.075 (0.114)\tData 0.054 (0.093)\tLoss 0.4569 (0.6960)\tAcc 1.000 (0.760)\n",
      "Epoch: [17][7/9]\tTime 0.072 (0.108)\tData 0.053 (0.087)\tLoss 0.5716 (0.6782)\tAcc 0.938 (0.786)\n",
      "Epoch: [17][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 1.0566 (0.7255)\tAcc 0.625 (0.766)\n",
      "Epoch: [17][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.5572 (0.7229)\tAcc 1.000 (0.769)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.350 (0.350)\tData 0.322 (0.322)\tLoss 0.7484 (0.7484)\tAcc 0.812 (0.812)\n",
      "Epoch: [18][2/5]\tTime 0.074 (0.212)\tData 0.050 (0.186)\tLoss 0.8782 (0.8133)\tAcc 0.562 (0.688)\n",
      "Epoch: [18][3/5]\tTime 0.076 (0.167)\tData 0.052 (0.141)\tLoss 0.9361 (0.8543)\tAcc 0.562 (0.646)\n",
      "Epoch: [18][4/5]\tTime 0.077 (0.144)\tData 0.053 (0.119)\tLoss 0.8344 (0.8493)\tAcc 0.750 (0.672)\n",
      "Epoch: [18][5/5]\tTime 0.079 (0.131)\tData 0.056 (0.107)\tLoss 0.9464 (0.8613)\tAcc 0.667 (0.671)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.365 (0.365)\tData 0.340 (0.340)\tLoss 0.6796 (0.6796)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/9]\tTime 0.071 (0.218)\tData 0.050 (0.195)\tLoss 1.0540 (0.8668)\tAcc 0.500 (0.719)\n",
      "Epoch: [18][3/9]\tTime 0.074 (0.170)\tData 0.052 (0.147)\tLoss 0.9545 (0.8960)\tAcc 0.625 (0.688)\n",
      "Epoch: [18][4/9]\tTime 0.072 (0.145)\tData 0.051 (0.123)\tLoss 0.8602 (0.8871)\tAcc 0.750 (0.703)\n",
      "Epoch: [18][5/9]\tTime 0.072 (0.131)\tData 0.052 (0.109)\tLoss 0.8618 (0.8820)\tAcc 0.625 (0.688)\n",
      "Epoch: [18][6/9]\tTime 0.085 (0.123)\tData 0.064 (0.102)\tLoss 0.6325 (0.8404)\tAcc 1.000 (0.740)\n",
      "Epoch: [18][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.9007 (0.8490)\tAcc 0.750 (0.741)\n",
      "Epoch: [18][8/9]\tTime 0.075 (0.111)\tData 0.055 (0.090)\tLoss 1.0002 (0.8679)\tAcc 0.500 (0.711)\n",
      "Epoch: [18][9/9]\tTime 0.075 (0.107)\tData 0.055 (0.086)\tLoss 0.6425 (0.8645)\tAcc 1.000 (0.715)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.313 (0.313)\tData 0.283 (0.283)\tLoss 0.8603 (0.8603)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][2/5]\tTime 0.073 (0.193)\tData 0.048 (0.165)\tLoss 0.9439 (0.9021)\tAcc 0.625 (0.656)\n",
      "Epoch: [19][3/5]\tTime 0.076 (0.154)\tData 0.052 (0.128)\tLoss 0.7321 (0.8454)\tAcc 0.750 (0.688)\n",
      "Epoch: [19][4/5]\tTime 0.076 (0.134)\tData 0.052 (0.109)\tLoss 0.7464 (0.8207)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][5/5]\tTime 0.079 (0.123)\tData 0.056 (0.098)\tLoss 1.2831 (0.8777)\tAcc 0.333 (0.644)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.310 (0.310)\tData 0.285 (0.285)\tLoss 0.4037 (0.4037)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/9]\tTime 0.081 (0.195)\tData 0.059 (0.172)\tLoss 1.0783 (0.7410)\tAcc 0.438 (0.688)\n",
      "Epoch: [19][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.132)\tLoss 0.7457 (0.7426)\tAcc 0.688 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.074 (0.135)\tData 0.052 (0.112)\tLoss 0.7287 (0.7391)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][5/9]\tTime 0.071 (0.122)\tData 0.052 (0.100)\tLoss 0.8333 (0.7579)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][6/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 0.2777 (0.6779)\tAcc 1.000 (0.740)\n",
      "Epoch: [19][7/9]\tTime 0.072 (0.108)\tData 0.053 (0.087)\tLoss 0.5651 (0.6618)\tAcc 0.875 (0.759)\n",
      "Epoch: [19][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.1106 (0.7179)\tAcc 0.500 (0.727)\n",
      "Epoch: [19][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.3760 (0.7126)\tAcc 1.000 (0.731)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.357 (0.357)\tData 0.330 (0.330)\tLoss 0.9091 (0.9091)\tAcc 0.625 (0.625)\n",
      "Epoch: [20][2/5]\tTime 0.074 (0.216)\tData 0.050 (0.190)\tLoss 0.5479 (0.7285)\tAcc 0.812 (0.719)\n",
      "Epoch: [20][3/5]\tTime 0.077 (0.170)\tData 0.053 (0.144)\tLoss 1.0485 (0.8352)\tAcc 0.500 (0.646)\n",
      "Epoch: [20][4/5]\tTime 0.075 (0.146)\tData 0.052 (0.121)\tLoss 0.8564 (0.8405)\tAcc 0.625 (0.641)\n",
      "Epoch: [20][5/5]\tTime 0.079 (0.133)\tData 0.056 (0.108)\tLoss 0.5304 (0.8023)\tAcc 0.889 (0.671)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.377 (0.377)\tData 0.352 (0.352)\tLoss 0.4556 (0.4556)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/9]\tTime 0.070 (0.224)\tData 0.048 (0.200)\tLoss 0.9730 (0.7143)\tAcc 0.438 (0.688)\n",
      "Epoch: [20][3/9]\tTime 0.074 (0.174)\tData 0.053 (0.151)\tLoss 0.7223 (0.7170)\tAcc 0.750 (0.708)\n",
      "Epoch: [20][4/9]\tTime 0.074 (0.149)\tData 0.053 (0.126)\tLoss 0.7302 (0.7203)\tAcc 0.625 (0.688)\n",
      "Epoch: [20][5/9]\tTime 0.072 (0.133)\tData 0.053 (0.111)\tLoss 0.7891 (0.7340)\tAcc 0.750 (0.700)\n",
      "Epoch: [20][6/9]\tTime 0.075 (0.124)\tData 0.055 (0.102)\tLoss 0.3097 (0.6633)\tAcc 1.000 (0.750)\n",
      "Epoch: [20][7/9]\tTime 0.074 (0.117)\tData 0.054 (0.095)\tLoss 0.6932 (0.6676)\tAcc 0.750 (0.750)\n",
      "Epoch: [20][8/9]\tTime 0.076 (0.111)\tData 0.055 (0.090)\tLoss 1.1223 (0.7244)\tAcc 0.562 (0.727)\n",
      "Epoch: [20][9/9]\tTime 0.080 (0.108)\tData 0.060 (0.087)\tLoss 0.2373 (0.7169)\tAcc 1.000 (0.731)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.371 (0.371)\tData 0.343 (0.343)\tLoss 0.8108 (0.8108)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][2/5]\tTime 0.074 (0.223)\tData 0.050 (0.196)\tLoss 1.0463 (0.9285)\tAcc 0.500 (0.594)\n",
      "Epoch: [21][3/5]\tTime 0.076 (0.174)\tData 0.053 (0.149)\tLoss 0.7476 (0.8682)\tAcc 0.688 (0.625)\n",
      "Epoch: [21][4/5]\tTime 0.077 (0.150)\tData 0.053 (0.125)\tLoss 0.5510 (0.7889)\tAcc 0.938 (0.703)\n",
      "Epoch: [21][5/5]\tTime 0.081 (0.136)\tData 0.056 (0.111)\tLoss 1.1255 (0.8304)\tAcc 0.556 (0.685)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.271 (0.271)\tData 0.244 (0.244)\tLoss 0.2923 (0.2923)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.069 (0.170)\tData 0.048 (0.146)\tLoss 1.0616 (0.6770)\tAcc 0.438 (0.688)\n",
      "Epoch: [21][3/9]\tTime 0.073 (0.138)\tData 0.053 (0.115)\tLoss 0.6478 (0.6672)\tAcc 0.750 (0.708)\n",
      "Epoch: [21][4/9]\tTime 0.075 (0.122)\tData 0.053 (0.100)\tLoss 0.6903 (0.6730)\tAcc 0.688 (0.703)\n",
      "Epoch: [21][5/9]\tTime 0.072 (0.112)\tData 0.052 (0.090)\tLoss 0.8125 (0.7009)\tAcc 0.750 (0.713)\n",
      "Epoch: [21][6/9]\tTime 0.075 (0.106)\tData 0.054 (0.084)\tLoss 0.2038 (0.6180)\tAcc 1.000 (0.760)\n",
      "Epoch: [21][7/9]\tTime 0.072 (0.101)\tData 0.053 (0.080)\tLoss 0.5510 (0.6085)\tAcc 0.875 (0.777)\n",
      "Epoch: [21][8/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 1.2275 (0.6858)\tAcc 0.500 (0.742)\n",
      "Epoch: [21][9/9]\tTime 0.076 (0.095)\tData 0.056 (0.074)\tLoss 0.1428 (0.6775)\tAcc 1.000 (0.746)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.313 (0.313)\tData 0.284 (0.284)\tLoss 0.5128 (0.5128)\tAcc 0.875 (0.875)\n",
      "Epoch: [22][2/5]\tTime 0.073 (0.193)\tData 0.049 (0.167)\tLoss 0.8502 (0.6815)\tAcc 0.625 (0.750)\n",
      "Epoch: [22][3/5]\tTime 0.076 (0.154)\tData 0.053 (0.129)\tLoss 0.8602 (0.7411)\tAcc 0.562 (0.688)\n",
      "Epoch: [22][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.110)\tLoss 0.8987 (0.7805)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][5/5]\tTime 0.080 (0.124)\tData 0.057 (0.099)\tLoss 0.7276 (0.7739)\tAcc 0.556 (0.671)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.284 (0.284)\tData 0.260 (0.260)\tLoss 0.3844 (0.3844)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.071 (0.178)\tData 0.050 (0.155)\tLoss 1.0474 (0.7159)\tAcc 0.438 (0.688)\n",
      "Epoch: [22][3/9]\tTime 0.074 (0.143)\tData 0.052 (0.121)\tLoss 0.5541 (0.6620)\tAcc 0.812 (0.729)\n",
      "Epoch: [22][4/9]\tTime 0.075 (0.126)\tData 0.053 (0.104)\tLoss 0.6658 (0.6629)\tAcc 0.688 (0.719)\n",
      "Epoch: [22][5/9]\tTime 0.076 (0.116)\tData 0.052 (0.093)\tLoss 0.9759 (0.7255)\tAcc 0.625 (0.700)\n",
      "Epoch: [22][6/9]\tTime 0.071 (0.108)\tData 0.050 (0.086)\tLoss 0.2860 (0.6523)\tAcc 1.000 (0.750)\n",
      "Epoch: [22][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.8740 (0.6840)\tAcc 0.562 (0.723)\n",
      "Epoch: [22][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.078)\tLoss 1.0364 (0.7280)\tAcc 0.625 (0.711)\n",
      "Epoch: [22][9/9]\tTime 0.076 (0.097)\tData 0.055 (0.075)\tLoss 0.2010 (0.7199)\tAcc 1.000 (0.715)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.373 (0.373)\tData 0.346 (0.346)\tLoss 1.0778 (1.0778)\tAcc 0.562 (0.562)\n",
      "Epoch: [23][2/5]\tTime 0.075 (0.224)\tData 0.051 (0.199)\tLoss 0.7883 (0.9330)\tAcc 0.688 (0.625)\n",
      "Epoch: [23][3/5]\tTime 0.076 (0.175)\tData 0.053 (0.150)\tLoss 0.8344 (0.9001)\tAcc 0.562 (0.604)\n",
      "Epoch: [23][4/5]\tTime 0.077 (0.150)\tData 0.054 (0.126)\tLoss 0.6281 (0.8321)\tAcc 0.812 (0.656)\n",
      "Epoch: [23][5/5]\tTime 0.079 (0.136)\tData 0.056 (0.112)\tLoss 1.0307 (0.8566)\tAcc 0.667 (0.658)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.305 (0.305)\tData 0.276 (0.276)\tLoss 0.2725 (0.2725)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.068 (0.186)\tData 0.046 (0.161)\tLoss 1.0954 (0.6840)\tAcc 0.500 (0.719)\n",
      "Epoch: [23][3/9]\tTime 0.073 (0.149)\tData 0.052 (0.125)\tLoss 0.7418 (0.7032)\tAcc 0.625 (0.688)\n",
      "Epoch: [23][4/9]\tTime 0.076 (0.130)\tData 0.052 (0.107)\tLoss 0.5253 (0.6588)\tAcc 0.875 (0.734)\n",
      "Epoch: [23][5/9]\tTime 0.071 (0.118)\tData 0.050 (0.096)\tLoss 0.8374 (0.6945)\tAcc 0.688 (0.725)\n",
      "Epoch: [23][6/9]\tTime 0.075 (0.111)\tData 0.054 (0.089)\tLoss 0.1605 (0.6055)\tAcc 1.000 (0.771)\n",
      "Epoch: [23][7/9]\tTime 0.072 (0.106)\tData 0.053 (0.084)\tLoss 0.4934 (0.5895)\tAcc 0.875 (0.786)\n",
      "Epoch: [23][8/9]\tTime 0.075 (0.102)\tData 0.054 (0.080)\tLoss 1.1247 (0.6564)\tAcc 0.500 (0.750)\n",
      "Epoch: [23][9/9]\tTime 0.075 (0.099)\tData 0.054 (0.077)\tLoss 0.2214 (0.6497)\tAcc 1.000 (0.754)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.343 (0.343)\tData 0.314 (0.314)\tLoss 0.6732 (0.6732)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][2/5]\tTime 0.072 (0.208)\tData 0.049 (0.181)\tLoss 0.7502 (0.7117)\tAcc 0.688 (0.719)\n",
      "Epoch: [24][3/5]\tTime 0.077 (0.164)\tData 0.053 (0.138)\tLoss 0.9948 (0.8061)\tAcc 0.562 (0.667)\n",
      "Epoch: [24][4/5]\tTime 0.076 (0.142)\tData 0.054 (0.117)\tLoss 0.8508 (0.8172)\tAcc 0.625 (0.656)\n",
      "Epoch: [24][5/5]\tTime 0.078 (0.129)\tData 0.055 (0.105)\tLoss 0.6950 (0.8022)\tAcc 0.778 (0.671)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.325 (0.325)\tData 0.295 (0.295)\tLoss 0.4585 (0.4585)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/9]\tTime 0.065 (0.195)\tData 0.044 (0.169)\tLoss 0.9332 (0.6959)\tAcc 0.562 (0.750)\n",
      "Epoch: [24][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.130)\tLoss 0.7992 (0.7303)\tAcc 0.625 (0.708)\n",
      "Epoch: [24][4/9]\tTime 0.074 (0.134)\tData 0.053 (0.111)\tLoss 0.6699 (0.7152)\tAcc 0.812 (0.734)\n",
      "Epoch: [24][5/9]\tTime 0.072 (0.122)\tData 0.052 (0.099)\tLoss 0.8778 (0.7477)\tAcc 0.688 (0.725)\n",
      "Epoch: [24][6/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 0.3514 (0.6817)\tAcc 1.000 (0.771)\n",
      "Epoch: [24][7/9]\tTime 0.073 (0.108)\tData 0.053 (0.086)\tLoss 0.5819 (0.6674)\tAcc 0.938 (0.795)\n",
      "Epoch: [24][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 1.1364 (0.7260)\tAcc 0.500 (0.758)\n",
      "Epoch: [24][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.079)\tLoss 0.3099 (0.7196)\tAcc 1.000 (0.762)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.309 (0.309)\tData 0.279 (0.279)\tLoss 0.9250 (0.9250)\tAcc 0.562 (0.562)\n",
      "Epoch: [25][2/5]\tTime 0.074 (0.191)\tData 0.049 (0.164)\tLoss 0.7962 (0.8606)\tAcc 0.625 (0.594)\n",
      "Epoch: [25][3/5]\tTime 0.076 (0.153)\tData 0.052 (0.126)\tLoss 0.8083 (0.8432)\tAcc 0.688 (0.625)\n",
      "Epoch: [25][4/5]\tTime 0.077 (0.134)\tData 0.054 (0.108)\tLoss 0.8605 (0.8475)\tAcc 0.625 (0.625)\n",
      "Epoch: [25][5/5]\tTime 0.080 (0.123)\tData 0.056 (0.098)\tLoss 0.8455 (0.8473)\tAcc 0.667 (0.630)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.349 (0.349)\tData 0.323 (0.323)\tLoss 0.4190 (0.4190)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.069 (0.209)\tData 0.048 (0.185)\tLoss 1.0697 (0.7443)\tAcc 0.438 (0.688)\n",
      "Epoch: [25][3/9]\tTime 0.073 (0.164)\tData 0.052 (0.141)\tLoss 0.7638 (0.7508)\tAcc 0.688 (0.688)\n",
      "Epoch: [25][4/9]\tTime 0.073 (0.141)\tData 0.053 (0.119)\tLoss 0.7746 (0.7568)\tAcc 0.625 (0.672)\n",
      "Epoch: [25][5/9]\tTime 0.074 (0.128)\tData 0.054 (0.106)\tLoss 0.8143 (0.7683)\tAcc 0.688 (0.675)\n",
      "Epoch: [25][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.097)\tLoss 0.3172 (0.6931)\tAcc 1.000 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.072 (0.112)\tData 0.053 (0.091)\tLoss 0.5047 (0.6662)\tAcc 0.875 (0.750)\n",
      "Epoch: [25][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 1.0660 (0.7162)\tAcc 0.500 (0.719)\n",
      "Epoch: [25][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.4045 (0.7114)\tAcc 1.000 (0.723)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.262 (0.262)\tData 0.233 (0.233)\tLoss 0.6751 (0.6751)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][2/5]\tTime 0.103 (0.183)\tData 0.079 (0.156)\tLoss 0.6497 (0.6624)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][3/5]\tTime 0.077 (0.147)\tData 0.053 (0.122)\tLoss 0.7180 (0.6810)\tAcc 0.625 (0.708)\n",
      "Epoch: [26][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.105)\tLoss 0.9462 (0.7473)\tAcc 0.500 (0.656)\n",
      "Epoch: [26][5/5]\tTime 0.081 (0.120)\tData 0.057 (0.095)\tLoss 0.6274 (0.7325)\tAcc 0.778 (0.671)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.328 (0.328)\tData 0.302 (0.302)\tLoss 0.2845 (0.2845)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/9]\tTime 0.070 (0.199)\tData 0.048 (0.175)\tLoss 1.0517 (0.6681)\tAcc 0.500 (0.719)\n",
      "Epoch: [26][3/9]\tTime 0.073 (0.157)\tData 0.052 (0.134)\tLoss 0.5343 (0.6235)\tAcc 0.812 (0.750)\n",
      "Epoch: [26][4/9]\tTime 0.073 (0.136)\tData 0.053 (0.114)\tLoss 0.7137 (0.6461)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][5/9]\tTime 0.073 (0.124)\tData 0.053 (0.102)\tLoss 0.9540 (0.7076)\tAcc 0.625 (0.725)\n",
      "Epoch: [26][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.094)\tLoss 0.2407 (0.6298)\tAcc 1.000 (0.771)\n",
      "Epoch: [26][7/9]\tTime 0.072 (0.109)\tData 0.053 (0.088)\tLoss 0.7067 (0.6408)\tAcc 0.750 (0.768)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 1.0440 (0.6912)\tAcc 0.562 (0.742)\n",
      "Epoch: [26][9/9]\tTime 0.075 (0.102)\tData 0.054 (0.080)\tLoss 0.1308 (0.6826)\tAcc 1.000 (0.746)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.335 (0.335)\tData 0.306 (0.306)\tLoss 0.6023 (0.6023)\tAcc 0.812 (0.812)\n",
      "Epoch: [27][2/5]\tTime 0.073 (0.204)\tData 0.049 (0.178)\tLoss 0.7718 (0.6870)\tAcc 0.625 (0.719)\n",
      "Epoch: [27][3/5]\tTime 0.078 (0.162)\tData 0.053 (0.136)\tLoss 1.0075 (0.7938)\tAcc 0.688 (0.708)\n",
      "Epoch: [27][4/5]\tTime 0.076 (0.140)\tData 0.052 (0.115)\tLoss 0.7132 (0.7737)\tAcc 0.625 (0.688)\n",
      "Epoch: [27][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 0.7176 (0.7668)\tAcc 0.778 (0.699)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.393 (0.393)\tData 0.367 (0.367)\tLoss 0.1602 (0.1602)\tAcc 1.000 (1.000)\n",
      "Epoch: [27][2/9]\tTime 0.070 (0.232)\tData 0.048 (0.207)\tLoss 0.9942 (0.5772)\tAcc 0.625 (0.812)\n",
      "Epoch: [27][3/9]\tTime 0.074 (0.179)\tData 0.052 (0.156)\tLoss 0.6827 (0.6124)\tAcc 0.562 (0.729)\n",
      "Epoch: [27][4/9]\tTime 0.072 (0.152)\tData 0.051 (0.130)\tLoss 0.7302 (0.6418)\tAcc 0.750 (0.734)\n",
      "Epoch: [27][5/9]\tTime 0.074 (0.137)\tData 0.054 (0.114)\tLoss 0.8868 (0.6908)\tAcc 0.688 (0.725)\n",
      "Epoch: [27][6/9]\tTime 0.075 (0.126)\tData 0.054 (0.104)\tLoss 0.2088 (0.6105)\tAcc 1.000 (0.771)\n",
      "Epoch: [27][7/9]\tTime 0.073 (0.119)\tData 0.053 (0.097)\tLoss 0.7557 (0.6312)\tAcc 0.625 (0.750)\n",
      "Epoch: [27][8/9]\tTime 0.074 (0.113)\tData 0.054 (0.092)\tLoss 1.1170 (0.6919)\tAcc 0.500 (0.719)\n",
      "Epoch: [27][9/9]\tTime 0.075 (0.109)\tData 0.054 (0.087)\tLoss 0.0577 (0.6822)\tAcc 1.000 (0.723)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.337 (0.337)\tData 0.307 (0.307)\tLoss 0.5141 (0.5141)\tAcc 0.875 (0.875)\n",
      "Epoch: [28][2/5]\tTime 0.074 (0.205)\tData 0.049 (0.178)\tLoss 0.8273 (0.6707)\tAcc 0.812 (0.844)\n",
      "Epoch: [28][3/5]\tTime 0.075 (0.162)\tData 0.052 (0.136)\tLoss 1.7272 (1.0229)\tAcc 0.438 (0.708)\n",
      "Epoch: [28][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.115)\tLoss 0.6278 (0.9241)\tAcc 0.750 (0.719)\n",
      "Epoch: [28][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 1.2143 (0.9599)\tAcc 0.556 (0.699)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.370 (0.370)\tData 0.343 (0.343)\tLoss 0.5752 (0.5752)\tAcc 0.875 (0.875)\n",
      "Epoch: [28][2/9]\tTime 0.070 (0.220)\tData 0.048 (0.196)\tLoss 0.9377 (0.7565)\tAcc 0.688 (0.781)\n",
      "Epoch: [28][3/9]\tTime 0.073 (0.171)\tData 0.053 (0.148)\tLoss 0.9498 (0.8209)\tAcc 0.562 (0.708)\n",
      "Epoch: [28][4/9]\tTime 0.075 (0.147)\tData 0.053 (0.124)\tLoss 0.8235 (0.8216)\tAcc 0.688 (0.703)\n",
      "Epoch: [28][5/9]\tTime 0.072 (0.132)\tData 0.052 (0.110)\tLoss 0.9044 (0.8381)\tAcc 0.562 (0.675)\n",
      "Epoch: [28][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.101)\tLoss 0.4808 (0.7786)\tAcc 0.938 (0.719)\n",
      "Epoch: [28][7/9]\tTime 0.073 (0.115)\tData 0.053 (0.094)\tLoss 0.7754 (0.7781)\tAcc 0.750 (0.723)\n",
      "Epoch: [28][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 1.1959 (0.8303)\tAcc 0.375 (0.680)\n",
      "Epoch: [28][9/9]\tTime 0.076 (0.106)\tData 0.055 (0.085)\tLoss 0.2675 (0.8217)\tAcc 1.000 (0.685)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.347 (0.347)\tData 0.319 (0.319)\tLoss 0.8470 (0.8470)\tAcc 0.562 (0.562)\n",
      "Epoch: [29][2/5]\tTime 0.075 (0.211)\tData 0.051 (0.185)\tLoss 0.8652 (0.8561)\tAcc 0.625 (0.594)\n",
      "Epoch: [29][3/5]\tTime 0.077 (0.166)\tData 0.053 (0.141)\tLoss 0.8579 (0.8567)\tAcc 0.625 (0.604)\n",
      "Epoch: [29][4/5]\tTime 0.076 (0.144)\tData 0.053 (0.119)\tLoss 0.7530 (0.8308)\tAcc 0.750 (0.641)\n",
      "Epoch: [29][5/5]\tTime 0.079 (0.131)\tData 0.056 (0.106)\tLoss 0.6267 (0.8056)\tAcc 0.889 (0.671)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.362 (0.362)\tData 0.337 (0.337)\tLoss 0.3882 (0.3882)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.072 (0.217)\tData 0.050 (0.194)\tLoss 1.0900 (0.7391)\tAcc 0.438 (0.688)\n",
      "Epoch: [29][3/9]\tTime 0.074 (0.169)\tData 0.052 (0.146)\tLoss 0.6855 (0.7212)\tAcc 0.688 (0.688)\n",
      "Epoch: [29][4/9]\tTime 0.072 (0.145)\tData 0.051 (0.123)\tLoss 0.7437 (0.7269)\tAcc 0.688 (0.688)\n",
      "Epoch: [29][5/9]\tTime 0.073 (0.131)\tData 0.053 (0.109)\tLoss 0.8302 (0.7475)\tAcc 0.688 (0.688)\n",
      "Epoch: [29][6/9]\tTime 0.075 (0.121)\tData 0.054 (0.100)\tLoss 0.3064 (0.6740)\tAcc 1.000 (0.740)\n",
      "Epoch: [29][7/9]\tTime 0.072 (0.114)\tData 0.053 (0.093)\tLoss 0.5371 (0.6544)\tAcc 0.875 (0.759)\n",
      "Epoch: [29][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 1.0814 (0.7078)\tAcc 0.500 (0.727)\n",
      "Epoch: [29][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.085)\tLoss 0.3102 (0.7017)\tAcc 1.000 (0.731)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.370 (0.370)\tData 0.342 (0.342)\tLoss 1.0311 (1.0311)\tAcc 0.500 (0.500)\n",
      "Epoch: [30][2/5]\tTime 0.076 (0.223)\tData 0.051 (0.197)\tLoss 0.6469 (0.8390)\tAcc 0.812 (0.656)\n",
      "Epoch: [30][3/5]\tTime 0.077 (0.174)\tData 0.053 (0.149)\tLoss 0.7948 (0.8242)\tAcc 0.688 (0.667)\n",
      "Epoch: [30][4/5]\tTime 0.077 (0.150)\tData 0.053 (0.125)\tLoss 0.6036 (0.7691)\tAcc 0.750 (0.688)\n",
      "Epoch: [30][5/5]\tTime 0.080 (0.136)\tData 0.056 (0.111)\tLoss 0.9400 (0.7902)\tAcc 0.556 (0.671)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.282 (0.282)\tData 0.256 (0.256)\tLoss 0.3560 (0.3560)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/9]\tTime 0.070 (0.176)\tData 0.049 (0.152)\tLoss 1.2124 (0.7842)\tAcc 0.438 (0.688)\n",
      "Epoch: [30][3/9]\tTime 0.074 (0.142)\tData 0.053 (0.119)\tLoss 0.7096 (0.7593)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][4/9]\tTime 0.074 (0.125)\tData 0.053 (0.103)\tLoss 0.7189 (0.7492)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][5/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.8414 (0.7677)\tAcc 0.688 (0.688)\n",
      "Epoch: [30][6/9]\tTime 0.075 (0.108)\tData 0.054 (0.086)\tLoss 0.2051 (0.6739)\tAcc 1.000 (0.740)\n",
      "Epoch: [30][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.082)\tLoss 0.4687 (0.6446)\tAcc 0.875 (0.759)\n",
      "Epoch: [30][8/9]\tTime 0.074 (0.099)\tData 0.054 (0.078)\tLoss 1.1973 (0.7137)\tAcc 0.500 (0.727)\n",
      "Epoch: [30][9/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.1596 (0.7052)\tAcc 1.000 (0.731)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.302 (0.302)\tData 0.275 (0.275)\tLoss 0.7713 (0.7713)\tAcc 0.688 (0.688)\n",
      "Epoch: [31][2/5]\tTime 0.078 (0.190)\tData 0.051 (0.163)\tLoss 0.7134 (0.7423)\tAcc 0.750 (0.719)\n",
      "Epoch: [31][3/5]\tTime 0.074 (0.151)\tData 0.050 (0.125)\tLoss 0.8837 (0.7894)\tAcc 0.562 (0.667)\n",
      "Epoch: [31][4/5]\tTime 0.076 (0.133)\tData 0.053 (0.107)\tLoss 0.8906 (0.8147)\tAcc 0.625 (0.656)\n",
      "Epoch: [31][5/5]\tTime 0.081 (0.122)\tData 0.057 (0.097)\tLoss 0.6127 (0.7898)\tAcc 0.778 (0.671)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.360 (0.360)\tData 0.336 (0.336)\tLoss 0.3614 (0.3614)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.072 (0.216)\tData 0.050 (0.193)\tLoss 1.0802 (0.7208)\tAcc 0.500 (0.719)\n",
      "Epoch: [31][3/9]\tTime 0.073 (0.168)\tData 0.052 (0.146)\tLoss 0.6117 (0.6844)\tAcc 0.688 (0.708)\n",
      "Epoch: [31][4/9]\tTime 0.074 (0.145)\tData 0.053 (0.123)\tLoss 0.7001 (0.6883)\tAcc 0.750 (0.719)\n",
      "Epoch: [31][5/9]\tTime 0.073 (0.130)\tData 0.053 (0.109)\tLoss 0.8491 (0.7205)\tAcc 0.688 (0.713)\n",
      "Epoch: [31][6/9]\tTime 0.075 (0.121)\tData 0.054 (0.100)\tLoss 0.2807 (0.6472)\tAcc 1.000 (0.760)\n",
      "Epoch: [31][7/9]\tTime 0.071 (0.114)\tData 0.052 (0.093)\tLoss 0.5595 (0.6347)\tAcc 0.812 (0.768)\n",
      "Epoch: [31][8/9]\tTime 0.074 (0.109)\tData 0.054 (0.088)\tLoss 1.0580 (0.6876)\tAcc 0.500 (0.734)\n",
      "Epoch: [31][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 0.1545 (0.6794)\tAcc 1.000 (0.738)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.325 (0.325)\tData 0.294 (0.294)\tLoss 0.8196 (0.8196)\tAcc 0.562 (0.562)\n",
      "Epoch: [32][2/5]\tTime 0.077 (0.201)\tData 0.051 (0.173)\tLoss 0.6509 (0.7352)\tAcc 0.750 (0.656)\n",
      "Epoch: [32][3/5]\tTime 0.077 (0.160)\tData 0.051 (0.132)\tLoss 0.8349 (0.7685)\tAcc 0.688 (0.667)\n",
      "Epoch: [32][4/5]\tTime 0.076 (0.139)\tData 0.052 (0.112)\tLoss 0.5124 (0.7044)\tAcc 0.750 (0.688)\n",
      "Epoch: [32][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.101)\tLoss 0.8737 (0.7253)\tAcc 0.556 (0.671)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.277 (0.277)\tData 0.253 (0.253)\tLoss 0.4221 (0.4221)\tAcc 0.875 (0.875)\n",
      "Epoch: [32][2/9]\tTime 0.074 (0.175)\tData 0.050 (0.151)\tLoss 1.0384 (0.7302)\tAcc 0.625 (0.750)\n",
      "Epoch: [32][3/9]\tTime 0.074 (0.142)\tData 0.050 (0.118)\tLoss 0.6259 (0.6955)\tAcc 0.625 (0.708)\n",
      "Epoch: [32][4/9]\tTime 0.072 (0.124)\tData 0.051 (0.101)\tLoss 0.5599 (0.6616)\tAcc 0.812 (0.734)\n",
      "Epoch: [32][5/9]\tTime 0.074 (0.114)\tData 0.053 (0.091)\tLoss 0.8688 (0.7030)\tAcc 0.688 (0.725)\n",
      "Epoch: [32][6/9]\tTime 0.075 (0.107)\tData 0.054 (0.085)\tLoss 0.1945 (0.6183)\tAcc 1.000 (0.771)\n",
      "Epoch: [32][7/9]\tTime 0.072 (0.102)\tData 0.053 (0.080)\tLoss 0.5695 (0.6113)\tAcc 0.812 (0.777)\n",
      "Epoch: [32][8/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 1.1165 (0.6744)\tAcc 0.562 (0.750)\n",
      "Epoch: [32][9/9]\tTime 0.075 (0.096)\tData 0.054 (0.075)\tLoss 0.1946 (0.6671)\tAcc 1.000 (0.754)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.423 (0.423)\tData 0.396 (0.396)\tLoss 0.6437 (0.6437)\tAcc 0.812 (0.812)\n",
      "Epoch: [33][2/5]\tTime 0.076 (0.249)\tData 0.051 (0.223)\tLoss 0.8157 (0.7297)\tAcc 0.625 (0.719)\n",
      "Epoch: [33][3/5]\tTime 0.076 (0.191)\tData 0.052 (0.166)\tLoss 0.6822 (0.7139)\tAcc 0.750 (0.729)\n",
      "Epoch: [33][4/5]\tTime 0.077 (0.163)\tData 0.054 (0.138)\tLoss 0.7298 (0.7179)\tAcc 0.625 (0.703)\n",
      "Epoch: [33][5/5]\tTime 0.080 (0.146)\tData 0.056 (0.122)\tLoss 0.4080 (0.6797)\tAcc 1.000 (0.740)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.325 (0.325)\tData 0.299 (0.299)\tLoss 0.1856 (0.1856)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.096 (0.210)\tData 0.074 (0.187)\tLoss 1.1550 (0.6703)\tAcc 0.500 (0.719)\n",
      "Epoch: [33][3/9]\tTime 0.075 (0.165)\tData 0.052 (0.142)\tLoss 0.8246 (0.7217)\tAcc 0.625 (0.688)\n",
      "Epoch: [33][4/9]\tTime 0.077 (0.143)\tData 0.051 (0.119)\tLoss 0.6872 (0.7131)\tAcc 0.750 (0.703)\n",
      "Epoch: [33][5/9]\tTime 0.070 (0.129)\tData 0.050 (0.105)\tLoss 1.1664 (0.8037)\tAcc 0.562 (0.675)\n",
      "Epoch: [33][6/9]\tTime 0.075 (0.120)\tData 0.054 (0.097)\tLoss 0.1676 (0.6977)\tAcc 1.000 (0.729)\n",
      "Epoch: [33][7/9]\tTime 0.072 (0.113)\tData 0.053 (0.090)\tLoss 0.5503 (0.6767)\tAcc 0.875 (0.750)\n",
      "Epoch: [33][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 1.1644 (0.7376)\tAcc 0.500 (0.719)\n",
      "Epoch: [33][9/9]\tTime 0.075 (0.104)\tData 0.054 (0.082)\tLoss 0.0078 (0.7264)\tAcc 1.000 (0.723)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.371 (0.371)\tData 0.342 (0.342)\tLoss 0.9357 (0.9357)\tAcc 0.688 (0.688)\n",
      "Epoch: [34][2/5]\tTime 0.073 (0.222)\tData 0.048 (0.195)\tLoss 0.7042 (0.8200)\tAcc 0.812 (0.750)\n",
      "Epoch: [34][3/5]\tTime 0.076 (0.173)\tData 0.052 (0.147)\tLoss 0.6580 (0.7660)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 0.6869 (0.7462)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.110)\tLoss 0.6427 (0.7335)\tAcc 0.778 (0.753)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.316 (0.316)\tData 0.292 (0.292)\tLoss 0.2380 (0.2380)\tAcc 0.875 (0.875)\n",
      "Epoch: [34][2/9]\tTime 0.072 (0.194)\tData 0.050 (0.171)\tLoss 1.1508 (0.6944)\tAcc 0.438 (0.656)\n",
      "Epoch: [34][3/9]\tTime 0.080 (0.156)\tData 0.052 (0.131)\tLoss 0.5106 (0.6331)\tAcc 0.812 (0.708)\n",
      "Epoch: [34][4/9]\tTime 0.068 (0.134)\tData 0.047 (0.110)\tLoss 0.5634 (0.6157)\tAcc 0.688 (0.703)\n",
      "Epoch: [34][5/9]\tTime 0.073 (0.122)\tData 0.052 (0.099)\tLoss 0.8929 (0.6711)\tAcc 0.688 (0.700)\n",
      "Epoch: [34][6/9]\tTime 0.075 (0.114)\tData 0.054 (0.091)\tLoss 0.0815 (0.5729)\tAcc 1.000 (0.750)\n",
      "Epoch: [34][7/9]\tTime 0.072 (0.108)\tData 0.053 (0.086)\tLoss 0.6083 (0.5779)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 1.0807 (0.6408)\tAcc 0.625 (0.734)\n",
      "Epoch: [34][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.079)\tLoss 0.0401 (0.6315)\tAcc 1.000 (0.738)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.362 (0.362)\tData 0.335 (0.335)\tLoss 0.6925 (0.6925)\tAcc 0.562 (0.562)\n",
      "Epoch: [35][2/5]\tTime 0.075 (0.219)\tData 0.051 (0.193)\tLoss 1.1583 (0.9254)\tAcc 0.438 (0.500)\n",
      "Epoch: [35][3/5]\tTime 0.076 (0.171)\tData 0.053 (0.146)\tLoss 0.8034 (0.8847)\tAcc 0.750 (0.583)\n",
      "Epoch: [35][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.123)\tLoss 0.7741 (0.8571)\tAcc 0.688 (0.609)\n",
      "Epoch: [35][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.110)\tLoss 0.4638 (0.8086)\tAcc 0.778 (0.630)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.378 (0.378)\tData 0.352 (0.352)\tLoss 0.3112 (0.3112)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/9]\tTime 0.070 (0.224)\tData 0.048 (0.200)\tLoss 0.9909 (0.6510)\tAcc 0.562 (0.750)\n",
      "Epoch: [35][3/9]\tTime 0.074 (0.174)\tData 0.052 (0.151)\tLoss 0.4320 (0.5780)\tAcc 0.938 (0.812)\n",
      "Epoch: [35][4/9]\tTime 0.078 (0.150)\tData 0.051 (0.126)\tLoss 0.6271 (0.5903)\tAcc 0.688 (0.781)\n",
      "Epoch: [35][5/9]\tTime 0.067 (0.133)\tData 0.047 (0.110)\tLoss 0.6912 (0.6105)\tAcc 0.750 (0.775)\n",
      "Epoch: [35][6/9]\tTime 0.075 (0.124)\tData 0.054 (0.101)\tLoss 0.1219 (0.5290)\tAcc 1.000 (0.812)\n",
      "Epoch: [35][7/9]\tTime 0.072 (0.116)\tData 0.053 (0.094)\tLoss 0.5221 (0.5280)\tAcc 0.750 (0.804)\n",
      "Epoch: [35][8/9]\tTime 0.074 (0.111)\tData 0.054 (0.089)\tLoss 1.0773 (0.5967)\tAcc 0.562 (0.773)\n",
      "Epoch: [35][9/9]\tTime 0.075 (0.107)\tData 0.054 (0.085)\tLoss 0.1808 (0.5903)\tAcc 1.000 (0.777)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.332 (0.332)\tData 0.305 (0.305)\tLoss 0.8319 (0.8319)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][2/5]\tTime 0.076 (0.204)\tData 0.051 (0.178)\tLoss 0.6861 (0.7590)\tAcc 0.750 (0.750)\n",
      "Epoch: [36][3/5]\tTime 0.077 (0.162)\tData 0.053 (0.136)\tLoss 0.5896 (0.7026)\tAcc 0.875 (0.792)\n",
      "Epoch: [36][4/5]\tTime 0.076 (0.140)\tData 0.052 (0.115)\tLoss 0.9963 (0.7760)\tAcc 0.562 (0.734)\n",
      "Epoch: [36][5/5]\tTime 0.079 (0.128)\tData 0.056 (0.103)\tLoss 1.1619 (0.8236)\tAcc 0.444 (0.699)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.335 (0.335)\tData 0.309 (0.309)\tLoss 0.3806 (0.3806)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/9]\tTime 0.070 (0.202)\tData 0.048 (0.178)\tLoss 1.0018 (0.6912)\tAcc 0.500 (0.719)\n",
      "Epoch: [36][3/9]\tTime 0.074 (0.160)\tData 0.052 (0.136)\tLoss 0.7701 (0.7175)\tAcc 0.625 (0.688)\n",
      "Epoch: [36][4/9]\tTime 0.073 (0.138)\tData 0.052 (0.115)\tLoss 0.7578 (0.7276)\tAcc 0.688 (0.688)\n",
      "Epoch: [36][5/9]\tTime 0.074 (0.125)\tData 0.054 (0.103)\tLoss 0.8249 (0.7470)\tAcc 0.688 (0.688)\n",
      "Epoch: [36][6/9]\tTime 0.075 (0.117)\tData 0.055 (0.095)\tLoss 0.3278 (0.6772)\tAcc 1.000 (0.740)\n",
      "Epoch: [36][7/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.5045 (0.6525)\tAcc 0.875 (0.759)\n",
      "Epoch: [36][8/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 1.0239 (0.6989)\tAcc 0.500 (0.727)\n",
      "Epoch: [36][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.3906 (0.6942)\tAcc 1.000 (0.731)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.281 (0.281)\tData 0.252 (0.252)\tLoss 0.9917 (0.9917)\tAcc 0.500 (0.500)\n",
      "Epoch: [37][2/5]\tTime 0.074 (0.178)\tData 0.049 (0.151)\tLoss 0.5955 (0.7936)\tAcc 0.875 (0.688)\n",
      "Epoch: [37][3/5]\tTime 0.076 (0.144)\tData 0.052 (0.118)\tLoss 0.8332 (0.8068)\tAcc 0.688 (0.688)\n",
      "Epoch: [37][4/5]\tTime 0.077 (0.127)\tData 0.053 (0.102)\tLoss 1.0046 (0.8562)\tAcc 0.562 (0.656)\n",
      "Epoch: [37][5/5]\tTime 0.079 (0.118)\tData 0.055 (0.092)\tLoss 0.8077 (0.8503)\tAcc 0.667 (0.658)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.314 (0.314)\tData 0.288 (0.288)\tLoss 0.4922 (0.4922)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/9]\tTime 0.070 (0.192)\tData 0.049 (0.168)\tLoss 1.0210 (0.7566)\tAcc 0.625 (0.781)\n",
      "Epoch: [37][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.130)\tLoss 0.7261 (0.7464)\tAcc 0.688 (0.750)\n",
      "Epoch: [37][4/9]\tTime 0.074 (0.133)\tData 0.052 (0.111)\tLoss 0.7069 (0.7365)\tAcc 0.688 (0.734)\n",
      "Epoch: [37][5/9]\tTime 0.073 (0.121)\tData 0.052 (0.099)\tLoss 0.8431 (0.7578)\tAcc 0.625 (0.713)\n",
      "Epoch: [37][6/9]\tTime 0.074 (0.113)\tData 0.054 (0.091)\tLoss 0.3858 (0.6958)\tAcc 1.000 (0.760)\n",
      "Epoch: [37][7/9]\tTime 0.073 (0.108)\tData 0.053 (0.086)\tLoss 0.5875 (0.6804)\tAcc 0.875 (0.777)\n",
      "Epoch: [37][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.082)\tLoss 1.0095 (0.7215)\tAcc 0.438 (0.734)\n",
      "Epoch: [37][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 0.4750 (0.7177)\tAcc 1.000 (0.738)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.320 (0.320)\tData 0.293 (0.293)\tLoss 0.7136 (0.7136)\tAcc 0.688 (0.688)\n",
      "Epoch: [38][2/5]\tTime 0.075 (0.198)\tData 0.050 (0.171)\tLoss 1.0068 (0.8602)\tAcc 0.625 (0.656)\n",
      "Epoch: [38][3/5]\tTime 0.076 (0.157)\tData 0.052 (0.131)\tLoss 0.6305 (0.7837)\tAcc 0.812 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.077 (0.137)\tData 0.053 (0.112)\tLoss 0.7884 (0.7848)\tAcc 0.688 (0.703)\n",
      "Epoch: [38][5/5]\tTime 0.080 (0.126)\tData 0.056 (0.101)\tLoss 0.7749 (0.7836)\tAcc 0.778 (0.712)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.392 (0.392)\tData 0.367 (0.367)\tLoss 0.3353 (0.3353)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.073 (0.232)\tData 0.050 (0.209)\tLoss 0.9237 (0.6295)\tAcc 0.625 (0.781)\n",
      "Epoch: [38][3/9]\tTime 0.072 (0.179)\tData 0.051 (0.156)\tLoss 0.6446 (0.6345)\tAcc 0.688 (0.750)\n",
      "Epoch: [38][4/9]\tTime 0.073 (0.152)\tData 0.052 (0.130)\tLoss 0.6687 (0.6431)\tAcc 0.812 (0.766)\n",
      "Epoch: [38][5/9]\tTime 0.073 (0.136)\tData 0.053 (0.115)\tLoss 0.8174 (0.6779)\tAcc 0.688 (0.750)\n",
      "Epoch: [38][6/9]\tTime 0.076 (0.126)\tData 0.055 (0.105)\tLoss 0.1937 (0.5972)\tAcc 1.000 (0.792)\n",
      "Epoch: [38][7/9]\tTime 0.072 (0.119)\tData 0.053 (0.097)\tLoss 0.6061 (0.5985)\tAcc 0.812 (0.795)\n",
      "Epoch: [38][8/9]\tTime 0.074 (0.113)\tData 0.054 (0.092)\tLoss 1.0411 (0.6538)\tAcc 0.500 (0.758)\n",
      "Epoch: [38][9/9]\tTime 0.075 (0.109)\tData 0.054 (0.088)\tLoss 0.1215 (0.6456)\tAcc 1.000 (0.762)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.382 (0.382)\tData 0.355 (0.355)\tLoss 0.7386 (0.7386)\tAcc 0.688 (0.688)\n",
      "Epoch: [39][2/5]\tTime 0.076 (0.229)\tData 0.051 (0.203)\tLoss 0.7826 (0.7606)\tAcc 0.625 (0.656)\n",
      "Epoch: [39][3/5]\tTime 0.076 (0.178)\tData 0.053 (0.153)\tLoss 1.0267 (0.8493)\tAcc 0.625 (0.646)\n",
      "Epoch: [39][4/5]\tTime 0.077 (0.153)\tData 0.054 (0.128)\tLoss 0.5520 (0.7750)\tAcc 0.750 (0.672)\n",
      "Epoch: [39][5/5]\tTime 0.080 (0.138)\tData 0.056 (0.114)\tLoss 0.6080 (0.7544)\tAcc 0.667 (0.671)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.318 (0.318)\tData 0.287 (0.287)\tLoss 0.2606 (0.2606)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/9]\tTime 0.066 (0.192)\tData 0.044 (0.166)\tLoss 1.0670 (0.6638)\tAcc 0.438 (0.688)\n",
      "Epoch: [39][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.128)\tLoss 0.6559 (0.6612)\tAcc 0.812 (0.729)\n",
      "Epoch: [39][4/9]\tTime 0.078 (0.134)\tData 0.052 (0.109)\tLoss 0.5811 (0.6412)\tAcc 0.688 (0.719)\n",
      "Epoch: [39][5/9]\tTime 0.069 (0.121)\tData 0.048 (0.097)\tLoss 0.8081 (0.6746)\tAcc 0.750 (0.725)\n",
      "Epoch: [39][6/9]\tTime 0.074 (0.113)\tData 0.054 (0.090)\tLoss 0.1369 (0.5849)\tAcc 1.000 (0.771)\n",
      "Epoch: [39][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.084)\tLoss 0.6527 (0.5946)\tAcc 0.750 (0.768)\n",
      "Epoch: [39][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 1.1991 (0.6702)\tAcc 0.438 (0.727)\n",
      "Epoch: [39][9/9]\tTime 0.075 (0.100)\tData 0.054 (0.078)\tLoss 0.1377 (0.6620)\tAcc 1.000 (0.731)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 0.6601 (0.6601)\tAcc 0.750 (0.750)\n",
      "Epoch: [40][2/5]\tTime 0.075 (0.204)\tData 0.049 (0.177)\tLoss 0.5867 (0.6234)\tAcc 0.750 (0.750)\n",
      "Epoch: [40][3/5]\tTime 0.076 (0.161)\tData 0.052 (0.135)\tLoss 0.8839 (0.7102)\tAcc 0.625 (0.708)\n",
      "Epoch: [40][4/5]\tTime 0.077 (0.140)\tData 0.053 (0.115)\tLoss 0.8993 (0.7575)\tAcc 0.625 (0.688)\n",
      "Epoch: [40][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 0.9417 (0.7802)\tAcc 0.556 (0.671)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.318 (0.318)\tData 0.291 (0.291)\tLoss 0.3280 (0.3280)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/9]\tTime 0.071 (0.194)\tData 0.048 (0.170)\tLoss 0.9458 (0.6369)\tAcc 0.438 (0.688)\n",
      "Epoch: [40][3/9]\tTime 0.072 (0.153)\tData 0.051 (0.130)\tLoss 0.6673 (0.6470)\tAcc 0.750 (0.708)\n",
      "Epoch: [40][4/9]\tTime 0.074 (0.134)\tData 0.052 (0.111)\tLoss 0.5996 (0.6352)\tAcc 0.688 (0.703)\n",
      "Epoch: [40][5/9]\tTime 0.072 (0.121)\tData 0.052 (0.099)\tLoss 0.8704 (0.6822)\tAcc 0.688 (0.700)\n",
      "Epoch: [40][6/9]\tTime 0.075 (0.114)\tData 0.054 (0.092)\tLoss 0.1897 (0.6001)\tAcc 1.000 (0.750)\n",
      "Epoch: [40][7/9]\tTime 0.073 (0.108)\tData 0.053 (0.086)\tLoss 0.9214 (0.6460)\tAcc 0.500 (0.714)\n",
      "Epoch: [40][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 1.1060 (0.7035)\tAcc 0.562 (0.695)\n",
      "Epoch: [40][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 0.3174 (0.6976)\tAcc 1.000 (0.700)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.372 (0.372)\tData 0.343 (0.343)\tLoss 0.7054 (0.7054)\tAcc 0.750 (0.750)\n",
      "Epoch: [41][2/5]\tTime 0.074 (0.223)\tData 0.049 (0.196)\tLoss 0.9370 (0.8212)\tAcc 0.562 (0.656)\n",
      "Epoch: [41][3/5]\tTime 0.076 (0.174)\tData 0.052 (0.148)\tLoss 0.6188 (0.7537)\tAcc 0.812 (0.708)\n",
      "Epoch: [41][4/5]\tTime 0.076 (0.149)\tData 0.053 (0.124)\tLoss 1.2595 (0.8802)\tAcc 0.625 (0.688)\n",
      "Epoch: [41][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.111)\tLoss 0.7317 (0.8619)\tAcc 0.667 (0.685)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.317 (0.317)\tData 0.293 (0.293)\tLoss 0.2806 (0.2806)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/9]\tTime 0.072 (0.194)\tData 0.050 (0.172)\tLoss 0.9864 (0.6335)\tAcc 0.438 (0.688)\n",
      "Epoch: [41][3/9]\tTime 0.076 (0.155)\tData 0.053 (0.132)\tLoss 0.7410 (0.6694)\tAcc 0.688 (0.688)\n",
      "Epoch: [41][4/9]\tTime 0.070 (0.134)\tData 0.050 (0.112)\tLoss 0.7459 (0.6885)\tAcc 0.688 (0.688)\n",
      "Epoch: [41][5/9]\tTime 0.073 (0.122)\tData 0.053 (0.100)\tLoss 1.0740 (0.7656)\tAcc 0.688 (0.688)\n",
      "Epoch: [41][6/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 0.2558 (0.6806)\tAcc 1.000 (0.740)\n",
      "Epoch: [41][7/9]\tTime 0.072 (0.108)\tData 0.053 (0.087)\tLoss 0.5300 (0.6591)\tAcc 0.875 (0.759)\n",
      "Epoch: [41][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.1736 (0.7234)\tAcc 0.500 (0.727)\n",
      "Epoch: [41][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.0785 (0.7135)\tAcc 1.000 (0.731)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.389 (0.389)\tData 0.361 (0.361)\tLoss 0.6102 (0.6102)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][2/5]\tTime 0.075 (0.232)\tData 0.050 (0.206)\tLoss 0.8369 (0.7235)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][3/5]\tTime 0.077 (0.180)\tData 0.053 (0.155)\tLoss 0.7464 (0.7311)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][4/5]\tTime 0.077 (0.154)\tData 0.053 (0.129)\tLoss 0.8254 (0.7547)\tAcc 0.625 (0.672)\n",
      "Epoch: [42][5/5]\tTime 0.079 (0.139)\tData 0.055 (0.115)\tLoss 0.8998 (0.7726)\tAcc 0.667 (0.671)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.364 (0.364)\tData 0.337 (0.337)\tLoss 0.4426 (0.4426)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/9]\tTime 0.069 (0.216)\tData 0.048 (0.192)\tLoss 0.9278 (0.6852)\tAcc 0.500 (0.719)\n",
      "Epoch: [42][3/9]\tTime 0.074 (0.169)\tData 0.052 (0.146)\tLoss 0.7734 (0.7146)\tAcc 0.688 (0.708)\n",
      "Epoch: [42][4/9]\tTime 0.072 (0.145)\tData 0.052 (0.122)\tLoss 0.7243 (0.7170)\tAcc 0.688 (0.703)\n",
      "Epoch: [42][5/9]\tTime 0.073 (0.130)\tData 0.053 (0.108)\tLoss 0.9820 (0.7700)\tAcc 0.688 (0.700)\n",
      "Epoch: [42][6/9]\tTime 0.075 (0.121)\tData 0.055 (0.099)\tLoss 0.3776 (0.7046)\tAcc 1.000 (0.750)\n",
      "Epoch: [42][7/9]\tTime 0.072 (0.114)\tData 0.053 (0.093)\tLoss 0.6114 (0.6913)\tAcc 0.938 (0.777)\n",
      "Epoch: [42][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 1.0227 (0.7327)\tAcc 0.500 (0.742)\n",
      "Epoch: [42][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 0.2792 (0.7258)\tAcc 1.000 (0.746)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.319 (0.319)\tData 0.290 (0.290)\tLoss 0.9591 (0.9591)\tAcc 0.500 (0.500)\n",
      "Epoch: [43][2/5]\tTime 0.075 (0.197)\tData 0.051 (0.171)\tLoss 0.9579 (0.9585)\tAcc 0.688 (0.594)\n",
      "Epoch: [43][3/5]\tTime 0.077 (0.157)\tData 0.053 (0.131)\tLoss 0.6269 (0.8480)\tAcc 0.812 (0.667)\n",
      "Epoch: [43][4/5]\tTime 0.077 (0.137)\tData 0.054 (0.112)\tLoss 0.7817 (0.8314)\tAcc 0.750 (0.688)\n",
      "Epoch: [43][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.101)\tLoss 0.8056 (0.8282)\tAcc 0.556 (0.671)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.388 (0.388)\tData 0.363 (0.363)\tLoss 0.4235 (0.4235)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/9]\tTime 0.070 (0.229)\tData 0.049 (0.206)\tLoss 0.9610 (0.6922)\tAcc 0.562 (0.750)\n",
      "Epoch: [43][3/9]\tTime 0.075 (0.178)\tData 0.053 (0.155)\tLoss 0.7434 (0.7093)\tAcc 0.750 (0.750)\n",
      "Epoch: [43][4/9]\tTime 0.072 (0.151)\tData 0.051 (0.129)\tLoss 0.7080 (0.7090)\tAcc 0.688 (0.734)\n",
      "Epoch: [43][5/9]\tTime 0.073 (0.136)\tData 0.053 (0.114)\tLoss 0.8783 (0.7428)\tAcc 0.625 (0.713)\n",
      "Epoch: [43][6/9]\tTime 0.076 (0.126)\tData 0.055 (0.104)\tLoss 0.4586 (0.6955)\tAcc 1.000 (0.760)\n",
      "Epoch: [43][7/9]\tTime 0.073 (0.118)\tData 0.054 (0.097)\tLoss 0.6463 (0.6884)\tAcc 0.875 (0.777)\n",
      "Epoch: [43][8/9]\tTime 0.074 (0.113)\tData 0.054 (0.091)\tLoss 1.0342 (0.7317)\tAcc 0.438 (0.734)\n",
      "Epoch: [43][9/9]\tTime 0.079 (0.109)\tData 0.060 (0.088)\tLoss 0.4897 (0.7279)\tAcc 1.000 (0.738)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.306 (0.306)\tData 0.275 (0.275)\tLoss 0.7645 (0.7645)\tAcc 0.750 (0.750)\n",
      "Epoch: [44][2/5]\tTime 0.074 (0.190)\tData 0.048 (0.162)\tLoss 0.8749 (0.8197)\tAcc 0.562 (0.656)\n",
      "Epoch: [44][3/5]\tTime 0.077 (0.152)\tData 0.053 (0.125)\tLoss 0.6103 (0.7499)\tAcc 0.812 (0.708)\n",
      "Epoch: [44][4/5]\tTime 0.077 (0.133)\tData 0.053 (0.107)\tLoss 1.1316 (0.8453)\tAcc 0.500 (0.656)\n",
      "Epoch: [44][5/5]\tTime 0.080 (0.123)\tData 0.056 (0.097)\tLoss 0.4562 (0.7974)\tAcc 0.889 (0.685)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.368 (0.368)\tData 0.344 (0.344)\tLoss 0.4548 (0.4548)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.072 (0.220)\tData 0.050 (0.197)\tLoss 0.9652 (0.7100)\tAcc 0.438 (0.688)\n",
      "Epoch: [44][3/9]\tTime 0.074 (0.171)\tData 0.052 (0.149)\tLoss 0.5282 (0.6494)\tAcc 0.875 (0.750)\n",
      "Epoch: [44][4/9]\tTime 0.073 (0.147)\tData 0.052 (0.125)\tLoss 0.7051 (0.6633)\tAcc 0.625 (0.719)\n",
      "Epoch: [44][5/9]\tTime 0.073 (0.132)\tData 0.053 (0.110)\tLoss 0.8408 (0.6988)\tAcc 0.750 (0.725)\n",
      "Epoch: [44][6/9]\tTime 0.075 (0.123)\tData 0.054 (0.101)\tLoss 0.3274 (0.6369)\tAcc 1.000 (0.771)\n",
      "Epoch: [44][7/9]\tTime 0.074 (0.116)\tData 0.053 (0.094)\tLoss 0.6093 (0.6330)\tAcc 0.812 (0.777)\n",
      "Epoch: [44][8/9]\tTime 0.074 (0.110)\tData 0.054 (0.089)\tLoss 0.8909 (0.6652)\tAcc 0.750 (0.773)\n",
      "Epoch: [44][9/9]\tTime 0.076 (0.106)\tData 0.055 (0.085)\tLoss 0.1329 (0.6570)\tAcc 1.000 (0.777)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.311 (0.311)\tData 0.282 (0.282)\tLoss 1.3337 (1.3337)\tAcc 0.438 (0.438)\n",
      "Epoch: [45][2/5]\tTime 0.073 (0.192)\tData 0.049 (0.165)\tLoss 0.6783 (1.0060)\tAcc 0.750 (0.594)\n",
      "Epoch: [45][3/5]\tTime 0.076 (0.154)\tData 0.053 (0.128)\tLoss 0.8732 (0.9618)\tAcc 0.688 (0.625)\n",
      "Epoch: [45][4/5]\tTime 0.077 (0.134)\tData 0.053 (0.109)\tLoss 0.9709 (0.9640)\tAcc 0.562 (0.609)\n",
      "Epoch: [45][5/5]\tTime 0.080 (0.123)\tData 0.056 (0.098)\tLoss 0.5200 (0.9093)\tAcc 0.889 (0.644)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.4886 (0.4886)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/9]\tTime 0.070 (0.218)\tData 0.049 (0.194)\tLoss 1.0085 (0.7486)\tAcc 0.438 (0.688)\n",
      "Epoch: [45][3/9]\tTime 0.074 (0.170)\tData 0.052 (0.147)\tLoss 0.6823 (0.7265)\tAcc 0.750 (0.708)\n",
      "Epoch: [45][4/9]\tTime 0.072 (0.146)\tData 0.052 (0.123)\tLoss 0.7701 (0.7374)\tAcc 0.688 (0.703)\n",
      "Epoch: [45][5/9]\tTime 0.074 (0.131)\tData 0.053 (0.109)\tLoss 0.7509 (0.7401)\tAcc 0.750 (0.713)\n",
      "Epoch: [45][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.3241 (0.6708)\tAcc 1.000 (0.760)\n",
      "Epoch: [45][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.093)\tLoss 0.7867 (0.6873)\tAcc 0.688 (0.750)\n",
      "Epoch: [45][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 0.9597 (0.7214)\tAcc 0.625 (0.734)\n",
      "Epoch: [45][9/9]\tTime 0.076 (0.106)\tData 0.055 (0.085)\tLoss 0.2165 (0.7136)\tAcc 1.000 (0.738)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.328 (0.328)\tData 0.298 (0.298)\tLoss 0.7407 (0.7407)\tAcc 0.688 (0.688)\n",
      "Epoch: [46][2/5]\tTime 0.073 (0.200)\tData 0.048 (0.173)\tLoss 0.8607 (0.8007)\tAcc 0.625 (0.656)\n",
      "Epoch: [46][3/5]\tTime 0.078 (0.160)\tData 0.053 (0.133)\tLoss 0.8868 (0.8294)\tAcc 0.625 (0.646)\n",
      "Epoch: [46][4/5]\tTime 0.076 (0.139)\tData 0.052 (0.113)\tLoss 0.8196 (0.8269)\tAcc 0.688 (0.656)\n",
      "Epoch: [46][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.101)\tLoss 0.6586 (0.8062)\tAcc 0.778 (0.671)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.287 (0.287)\tData 0.260 (0.260)\tLoss 0.3823 (0.3823)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/9]\tTime 0.070 (0.178)\tData 0.048 (0.154)\tLoss 1.2430 (0.8126)\tAcc 0.438 (0.688)\n",
      "Epoch: [46][3/9]\tTime 0.073 (0.143)\tData 0.052 (0.120)\tLoss 0.6532 (0.7595)\tAcc 0.688 (0.688)\n",
      "Epoch: [46][4/9]\tTime 0.076 (0.126)\tData 0.052 (0.103)\tLoss 0.6420 (0.7301)\tAcc 0.688 (0.688)\n",
      "Epoch: [46][5/9]\tTime 0.071 (0.115)\tData 0.050 (0.092)\tLoss 0.7276 (0.7296)\tAcc 0.688 (0.688)\n",
      "Epoch: [46][6/9]\tTime 0.075 (0.109)\tData 0.054 (0.086)\tLoss 0.2470 (0.6492)\tAcc 1.000 (0.740)\n",
      "Epoch: [46][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.5538 (0.6355)\tAcc 0.875 (0.759)\n",
      "Epoch: [46][8/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 1.0857 (0.6918)\tAcc 0.500 (0.727)\n",
      "Epoch: [46][9/9]\tTime 0.076 (0.097)\tData 0.055 (0.075)\tLoss 0.1596 (0.6836)\tAcc 1.000 (0.731)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.368 (0.368)\tData 0.341 (0.341)\tLoss 0.8016 (0.8016)\tAcc 0.625 (0.625)\n",
      "Epoch: [47][2/5]\tTime 0.075 (0.221)\tData 0.050 (0.195)\tLoss 1.1150 (0.9583)\tAcc 0.500 (0.562)\n",
      "Epoch: [47][3/5]\tTime 0.077 (0.173)\tData 0.053 (0.148)\tLoss 0.7924 (0.9030)\tAcc 0.688 (0.604)\n",
      "Epoch: [47][4/5]\tTime 0.077 (0.149)\tData 0.053 (0.124)\tLoss 0.7126 (0.8554)\tAcc 0.750 (0.641)\n",
      "Epoch: [47][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.111)\tLoss 0.4486 (0.8053)\tAcc 0.889 (0.671)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.327 (0.327)\tData 0.301 (0.301)\tLoss 0.3590 (0.3590)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/9]\tTime 0.069 (0.198)\tData 0.048 (0.174)\tLoss 1.1714 (0.7652)\tAcc 0.438 (0.688)\n",
      "Epoch: [47][3/9]\tTime 0.074 (0.157)\tData 0.053 (0.134)\tLoss 0.6883 (0.7395)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][4/9]\tTime 0.073 (0.136)\tData 0.053 (0.114)\tLoss 0.6790 (0.7244)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][5/9]\tTime 0.076 (0.124)\tData 0.054 (0.102)\tLoss 0.7650 (0.7325)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][6/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.2382 (0.6502)\tAcc 1.000 (0.740)\n",
      "Epoch: [47][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.6122 (0.6447)\tAcc 0.875 (0.759)\n",
      "Epoch: [47][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 1.2473 (0.7201)\tAcc 0.500 (0.727)\n",
      "Epoch: [47][9/9]\tTime 0.076 (0.102)\tData 0.055 (0.080)\tLoss 0.3025 (0.7136)\tAcc 1.000 (0.731)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.366 (0.366)\tData 0.337 (0.337)\tLoss 0.8440 (0.8440)\tAcc 0.625 (0.625)\n",
      "Epoch: [48][2/5]\tTime 0.073 (0.220)\tData 0.049 (0.193)\tLoss 0.6895 (0.7668)\tAcc 0.625 (0.625)\n",
      "Epoch: [48][3/5]\tTime 0.076 (0.172)\tData 0.053 (0.146)\tLoss 0.6158 (0.7164)\tAcc 0.750 (0.667)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.123)\tLoss 0.7256 (0.7187)\tAcc 0.688 (0.672)\n",
      "Epoch: [48][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.110)\tLoss 0.8435 (0.7341)\tAcc 0.667 (0.671)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.352 (0.352)\tData 0.325 (0.325)\tLoss 0.4123 (0.4123)\tAcc 0.938 (0.938)\n",
      "Epoch: [48][2/9]\tTime 0.069 (0.211)\tData 0.047 (0.186)\tLoss 1.0868 (0.7496)\tAcc 0.438 (0.688)\n",
      "Epoch: [48][3/9]\tTime 0.073 (0.165)\tData 0.052 (0.141)\tLoss 0.6221 (0.7071)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][4/9]\tTime 0.073 (0.142)\tData 0.052 (0.119)\tLoss 0.7668 (0.7220)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][5/9]\tTime 0.074 (0.128)\tData 0.053 (0.106)\tLoss 0.8375 (0.7451)\tAcc 0.688 (0.688)\n",
      "Epoch: [48][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.097)\tLoss 0.2569 (0.6637)\tAcc 1.000 (0.740)\n",
      "Epoch: [48][7/9]\tTime 0.072 (0.113)\tData 0.053 (0.091)\tLoss 0.5456 (0.6469)\tAcc 0.875 (0.759)\n",
      "Epoch: [48][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 1.0549 (0.6979)\tAcc 0.500 (0.727)\n",
      "Epoch: [48][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.2800 (0.6914)\tAcc 1.000 (0.731)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.315 (0.315)\tData 0.285 (0.285)\tLoss 0.5702 (0.5702)\tAcc 0.812 (0.812)\n",
      "Epoch: [49][2/5]\tTime 0.074 (0.194)\tData 0.049 (0.167)\tLoss 1.1097 (0.8399)\tAcc 0.500 (0.656)\n",
      "Epoch: [49][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.129)\tLoss 0.6409 (0.7736)\tAcc 0.688 (0.667)\n",
      "Epoch: [49][4/5]\tTime 0.076 (0.135)\tData 0.053 (0.110)\tLoss 0.7591 (0.7700)\tAcc 0.625 (0.656)\n",
      "Epoch: [49][5/5]\tTime 0.079 (0.124)\tData 0.056 (0.099)\tLoss 0.5097 (0.7379)\tAcc 0.778 (0.671)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.370 (0.370)\tData 0.345 (0.345)\tLoss 0.3196 (0.3196)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.072 (0.221)\tData 0.050 (0.198)\tLoss 1.0983 (0.7090)\tAcc 0.438 (0.688)\n",
      "Epoch: [49][3/9]\tTime 0.076 (0.172)\tData 0.052 (0.149)\tLoss 0.7109 (0.7096)\tAcc 0.688 (0.688)\n",
      "Epoch: [49][4/9]\tTime 0.070 (0.147)\tData 0.050 (0.124)\tLoss 0.7491 (0.7195)\tAcc 0.688 (0.688)\n",
      "Epoch: [49][5/9]\tTime 0.074 (0.132)\tData 0.054 (0.110)\tLoss 0.7774 (0.7311)\tAcc 0.688 (0.688)\n",
      "Epoch: [49][6/9]\tTime 0.075 (0.123)\tData 0.053 (0.101)\tLoss 0.2131 (0.6448)\tAcc 1.000 (0.740)\n",
      "Epoch: [49][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.5238 (0.6275)\tAcc 0.875 (0.759)\n",
      "Epoch: [49][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 1.0313 (0.6780)\tAcc 0.500 (0.727)\n",
      "Epoch: [49][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.2685 (0.6717)\tAcc 1.000 (0.731)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.366 (0.366)\tData 0.339 (0.339)\tLoss 0.6900 (0.6900)\tAcc 0.625 (0.625)\n",
      "Epoch: [50][2/5]\tTime 0.075 (0.220)\tData 0.051 (0.195)\tLoss 0.5864 (0.6382)\tAcc 0.812 (0.719)\n",
      "Epoch: [50][3/5]\tTime 0.077 (0.173)\tData 0.053 (0.148)\tLoss 0.7534 (0.6766)\tAcc 0.688 (0.708)\n",
      "Epoch: [50][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 1.2005 (0.8076)\tAcc 0.500 (0.656)\n",
      "Epoch: [50][5/5]\tTime 0.081 (0.135)\tData 0.056 (0.111)\tLoss 0.6193 (0.7843)\tAcc 0.778 (0.671)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.363 (0.363)\tData 0.339 (0.339)\tLoss 0.3020 (0.3020)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/9]\tTime 0.072 (0.217)\tData 0.051 (0.195)\tLoss 1.0431 (0.6725)\tAcc 0.438 (0.688)\n",
      "Epoch: [50][3/9]\tTime 0.073 (0.169)\tData 0.053 (0.147)\tLoss 0.5925 (0.6458)\tAcc 0.688 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.073 (0.145)\tData 0.053 (0.124)\tLoss 0.7221 (0.6649)\tAcc 0.688 (0.688)\n",
      "Epoch: [50][5/9]\tTime 0.073 (0.131)\tData 0.053 (0.110)\tLoss 0.8871 (0.7094)\tAcc 0.688 (0.688)\n",
      "Epoch: [50][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.100)\tLoss 0.3413 (0.6480)\tAcc 1.000 (0.740)\n",
      "Epoch: [50][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.5936 (0.6402)\tAcc 0.938 (0.768)\n",
      "Epoch: [50][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 1.1052 (0.6984)\tAcc 0.500 (0.734)\n",
      "Epoch: [50][9/9]\tTime 0.076 (0.106)\tData 0.055 (0.085)\tLoss 0.1874 (0.6905)\tAcc 1.000 (0.738)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 0.6036 (0.6036)\tAcc 0.812 (0.812)\n",
      "Epoch: [51][2/5]\tTime 0.073 (0.204)\tData 0.049 (0.177)\tLoss 0.8939 (0.7488)\tAcc 0.562 (0.688)\n",
      "Epoch: [51][3/5]\tTime 0.077 (0.161)\tData 0.053 (0.136)\tLoss 0.6551 (0.7176)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][4/5]\tTime 0.077 (0.140)\tData 0.054 (0.115)\tLoss 0.7841 (0.7342)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 0.7737 (0.7391)\tAcc 0.778 (0.699)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.306 (0.306)\tData 0.282 (0.282)\tLoss 0.3422 (0.3422)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/9]\tTime 0.072 (0.189)\tData 0.051 (0.166)\tLoss 0.9575 (0.6499)\tAcc 0.438 (0.688)\n",
      "Epoch: [51][3/9]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 0.6352 (0.6450)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][4/9]\tTime 0.073 (0.131)\tData 0.052 (0.109)\tLoss 0.6801 (0.6538)\tAcc 0.688 (0.688)\n",
      "Epoch: [51][5/9]\tTime 0.073 (0.120)\tData 0.053 (0.098)\tLoss 0.8510 (0.6932)\tAcc 0.625 (0.675)\n",
      "Epoch: [51][6/9]\tTime 0.075 (0.112)\tData 0.054 (0.091)\tLoss 0.2526 (0.6198)\tAcc 1.000 (0.729)\n",
      "Epoch: [51][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.085)\tLoss 0.5706 (0.6128)\tAcc 0.875 (0.750)\n",
      "Epoch: [51][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 1.0431 (0.6665)\tAcc 0.500 (0.719)\n",
      "Epoch: [51][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.1814 (0.6591)\tAcc 1.000 (0.723)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.287 (0.287)\tData 0.256 (0.256)\tLoss 0.8010 (0.8010)\tAcc 0.812 (0.812)\n",
      "Epoch: [52][2/5]\tTime 0.072 (0.179)\tData 0.048 (0.152)\tLoss 0.8209 (0.8110)\tAcc 0.562 (0.688)\n",
      "Epoch: [52][3/5]\tTime 0.077 (0.145)\tData 0.053 (0.119)\tLoss 0.6252 (0.7490)\tAcc 0.688 (0.688)\n",
      "Epoch: [52][4/5]\tTime 0.077 (0.128)\tData 0.054 (0.103)\tLoss 0.6237 (0.7177)\tAcc 0.812 (0.719)\n",
      "Epoch: [52][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.093)\tLoss 1.1099 (0.7660)\tAcc 0.556 (0.699)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.285 (0.285)\tData 0.260 (0.260)\tLoss 0.3682 (0.3682)\tAcc 0.938 (0.938)\n",
      "Epoch: [52][2/9]\tTime 0.072 (0.178)\tData 0.050 (0.155)\tLoss 1.0111 (0.6897)\tAcc 0.500 (0.719)\n",
      "Epoch: [52][3/9]\tTime 0.075 (0.144)\tData 0.052 (0.121)\tLoss 0.7819 (0.7204)\tAcc 0.688 (0.708)\n",
      "Epoch: [52][4/9]\tTime 0.072 (0.126)\tData 0.052 (0.104)\tLoss 0.6758 (0.7093)\tAcc 0.688 (0.703)\n",
      "Epoch: [52][5/9]\tTime 0.074 (0.115)\tData 0.053 (0.094)\tLoss 0.8270 (0.7328)\tAcc 0.625 (0.688)\n",
      "Epoch: [52][6/9]\tTime 0.075 (0.109)\tData 0.054 (0.087)\tLoss 0.2703 (0.6557)\tAcc 1.000 (0.740)\n",
      "Epoch: [52][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.082)\tLoss 0.6414 (0.6537)\tAcc 0.812 (0.750)\n",
      "Epoch: [52][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 0.9836 (0.6949)\tAcc 0.688 (0.742)\n",
      "Epoch: [52][9/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.1454 (0.6865)\tAcc 1.000 (0.746)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.347 (0.347)\tData 0.319 (0.319)\tLoss 0.7045 (0.7045)\tAcc 0.875 (0.875)\n",
      "Epoch: [53][2/5]\tTime 0.075 (0.211)\tData 0.050 (0.184)\tLoss 0.8129 (0.7587)\tAcc 0.625 (0.750)\n",
      "Epoch: [53][3/5]\tTime 0.076 (0.166)\tData 0.053 (0.141)\tLoss 0.7881 (0.7685)\tAcc 0.688 (0.729)\n",
      "Epoch: [53][4/5]\tTime 0.077 (0.144)\tData 0.054 (0.119)\tLoss 0.8302 (0.7839)\tAcc 0.750 (0.734)\n",
      "Epoch: [53][5/5]\tTime 0.080 (0.131)\tData 0.056 (0.106)\tLoss 1.0681 (0.8190)\tAcc 0.444 (0.699)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.282 (0.282)\tData 0.255 (0.255)\tLoss 0.3399 (0.3399)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/9]\tTime 0.069 (0.175)\tData 0.047 (0.151)\tLoss 0.8656 (0.6027)\tAcc 0.500 (0.719)\n",
      "Epoch: [53][3/9]\tTime 0.074 (0.141)\tData 0.052 (0.118)\tLoss 0.6551 (0.6202)\tAcc 0.625 (0.688)\n",
      "Epoch: [53][4/9]\tTime 0.074 (0.125)\tData 0.052 (0.102)\tLoss 0.5885 (0.6123)\tAcc 0.688 (0.688)\n",
      "Epoch: [53][5/9]\tTime 0.072 (0.114)\tData 0.053 (0.092)\tLoss 0.7827 (0.6464)\tAcc 0.750 (0.700)\n",
      "Epoch: [53][6/9]\tTime 0.076 (0.108)\tData 0.055 (0.086)\tLoss 0.2872 (0.5865)\tAcc 1.000 (0.750)\n",
      "Epoch: [53][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.6635 (0.5975)\tAcc 0.812 (0.759)\n",
      "Epoch: [53][8/9]\tTime 0.074 (0.099)\tData 0.055 (0.078)\tLoss 1.0601 (0.6553)\tAcc 0.500 (0.727)\n",
      "Epoch: [53][9/9]\tTime 0.076 (0.097)\tData 0.056 (0.075)\tLoss 0.3438 (0.6505)\tAcc 1.000 (0.731)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.279 (0.279)\tData 0.250 (0.250)\tLoss 0.7439 (0.7439)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][2/5]\tTime 0.075 (0.177)\tData 0.049 (0.150)\tLoss 1.1222 (0.9330)\tAcc 0.500 (0.625)\n",
      "Epoch: [54][3/5]\tTime 0.076 (0.143)\tData 0.052 (0.117)\tLoss 0.6888 (0.8516)\tAcc 0.812 (0.688)\n",
      "Epoch: [54][4/5]\tTime 0.077 (0.127)\tData 0.053 (0.101)\tLoss 0.6323 (0.7968)\tAcc 0.688 (0.688)\n",
      "Epoch: [54][5/5]\tTime 0.079 (0.117)\tData 0.056 (0.092)\tLoss 0.9105 (0.8108)\tAcc 0.556 (0.671)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.306 (0.306)\tData 0.280 (0.280)\tLoss 0.3564 (0.3564)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/9]\tTime 0.070 (0.188)\tData 0.048 (0.164)\tLoss 1.0069 (0.6816)\tAcc 0.562 (0.750)\n",
      "Epoch: [54][3/9]\tTime 0.074 (0.150)\tData 0.053 (0.127)\tLoss 0.7777 (0.7136)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][4/9]\tTime 0.075 (0.131)\tData 0.053 (0.109)\tLoss 0.7229 (0.7160)\tAcc 0.688 (0.734)\n",
      "Epoch: [54][5/9]\tTime 0.076 (0.120)\tData 0.055 (0.098)\tLoss 0.7423 (0.7212)\tAcc 0.812 (0.750)\n",
      "Epoch: [54][6/9]\tTime 0.080 (0.114)\tData 0.060 (0.092)\tLoss 0.3322 (0.6564)\tAcc 1.000 (0.792)\n",
      "Epoch: [54][7/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 0.7007 (0.6627)\tAcc 0.812 (0.795)\n",
      "Epoch: [54][8/9]\tTime 0.075 (0.104)\tData 0.054 (0.082)\tLoss 1.2097 (0.7311)\tAcc 0.438 (0.750)\n",
      "Epoch: [54][9/9]\tTime 0.079 (0.101)\tData 0.060 (0.080)\tLoss 0.2819 (0.7242)\tAcc 1.000 (0.754)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.341 (0.341)\tData 0.311 (0.311)\tLoss 0.9053 (0.9053)\tAcc 0.625 (0.625)\n",
      "Epoch: [55][2/5]\tTime 0.073 (0.207)\tData 0.049 (0.180)\tLoss 0.6527 (0.7790)\tAcc 0.688 (0.656)\n",
      "Epoch: [55][3/5]\tTime 0.076 (0.163)\tData 0.053 (0.137)\tLoss 0.6148 (0.7243)\tAcc 0.812 (0.708)\n",
      "Epoch: [55][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.116)\tLoss 0.7128 (0.7214)\tAcc 0.625 (0.688)\n",
      "Epoch: [55][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.104)\tLoss 0.8778 (0.7407)\tAcc 0.667 (0.685)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.312 (0.312)\tData 0.284 (0.284)\tLoss 0.4338 (0.4338)\tAcc 0.875 (0.875)\n",
      "Epoch: [55][2/9]\tTime 0.068 (0.190)\tData 0.047 (0.165)\tLoss 0.9439 (0.6888)\tAcc 0.562 (0.719)\n",
      "Epoch: [55][3/9]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 0.7287 (0.7021)\tAcc 0.688 (0.708)\n",
      "Epoch: [55][4/9]\tTime 0.075 (0.132)\tData 0.052 (0.109)\tLoss 0.6323 (0.6847)\tAcc 0.688 (0.703)\n",
      "Epoch: [55][5/9]\tTime 0.072 (0.120)\tData 0.052 (0.097)\tLoss 0.8798 (0.7237)\tAcc 0.750 (0.713)\n",
      "Epoch: [55][6/9]\tTime 0.075 (0.113)\tData 0.054 (0.090)\tLoss 0.3559 (0.6624)\tAcc 1.000 (0.760)\n",
      "Epoch: [55][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.085)\tLoss 0.7466 (0.6744)\tAcc 0.625 (0.741)\n",
      "Epoch: [55][8/9]\tTime 0.074 (0.103)\tData 0.054 (0.081)\tLoss 1.1494 (0.7338)\tAcc 0.562 (0.719)\n",
      "Epoch: [55][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.2102 (0.7258)\tAcc 1.000 (0.723)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.335 (0.335)\tData 0.307 (0.307)\tLoss 0.5982 (0.5982)\tAcc 0.875 (0.875)\n",
      "Epoch: [56][2/5]\tTime 0.075 (0.205)\tData 0.050 (0.179)\tLoss 0.7767 (0.6874)\tAcc 0.750 (0.812)\n",
      "Epoch: [56][3/5]\tTime 0.076 (0.162)\tData 0.053 (0.137)\tLoss 0.8424 (0.7391)\tAcc 0.688 (0.771)\n",
      "Epoch: [56][4/5]\tTime 0.077 (0.141)\tData 0.053 (0.116)\tLoss 0.6426 (0.7150)\tAcc 0.688 (0.750)\n",
      "Epoch: [56][5/5]\tTime 0.080 (0.129)\tData 0.056 (0.104)\tLoss 0.7135 (0.7148)\tAcc 0.556 (0.726)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.355 (0.355)\tData 0.328 (0.328)\tLoss 0.3357 (0.3357)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/9]\tTime 0.069 (0.212)\tData 0.048 (0.188)\tLoss 0.9809 (0.6583)\tAcc 0.500 (0.719)\n",
      "Epoch: [56][3/9]\tTime 0.074 (0.166)\tData 0.053 (0.143)\tLoss 0.6879 (0.6682)\tAcc 0.750 (0.729)\n",
      "Epoch: [56][4/9]\tTime 0.075 (0.143)\tData 0.052 (0.120)\tLoss 0.7494 (0.6885)\tAcc 0.625 (0.703)\n",
      "Epoch: [56][5/9]\tTime 0.072 (0.129)\tData 0.052 (0.106)\tLoss 0.7941 (0.7096)\tAcc 0.688 (0.700)\n",
      "Epoch: [56][6/9]\tTime 0.075 (0.120)\tData 0.054 (0.098)\tLoss 0.2372 (0.6309)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.073 (0.113)\tData 0.053 (0.091)\tLoss 0.5517 (0.6196)\tAcc 0.812 (0.759)\n",
      "Epoch: [56][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.087)\tLoss 1.0629 (0.6750)\tAcc 0.500 (0.727)\n",
      "Epoch: [56][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.083)\tLoss 0.3036 (0.6693)\tAcc 1.000 (0.731)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.345 (0.345)\tData 0.314 (0.314)\tLoss 0.7011 (0.7011)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][2/5]\tTime 0.072 (0.208)\tData 0.047 (0.180)\tLoss 0.6814 (0.6913)\tAcc 0.625 (0.688)\n",
      "Epoch: [57][3/5]\tTime 0.076 (0.164)\tData 0.053 (0.138)\tLoss 0.7196 (0.7007)\tAcc 0.688 (0.688)\n",
      "Epoch: [57][4/5]\tTime 0.077 (0.142)\tData 0.053 (0.117)\tLoss 0.8306 (0.7332)\tAcc 0.625 (0.672)\n",
      "Epoch: [57][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.105)\tLoss 0.7891 (0.7401)\tAcc 0.667 (0.671)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.370 (0.370)\tData 0.342 (0.342)\tLoss 0.3993 (0.3993)\tAcc 0.875 (0.875)\n",
      "Epoch: [57][2/9]\tTime 0.069 (0.219)\tData 0.047 (0.194)\tLoss 1.0103 (0.7048)\tAcc 0.500 (0.688)\n",
      "Epoch: [57][3/9]\tTime 0.074 (0.171)\tData 0.053 (0.147)\tLoss 0.5581 (0.6559)\tAcc 0.812 (0.729)\n",
      "Epoch: [57][4/9]\tTime 0.075 (0.147)\tData 0.053 (0.124)\tLoss 0.6581 (0.6565)\tAcc 0.688 (0.719)\n",
      "Epoch: [57][5/9]\tTime 0.072 (0.132)\tData 0.052 (0.109)\tLoss 0.9323 (0.7116)\tAcc 0.625 (0.700)\n",
      "Epoch: [57][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.2493 (0.6346)\tAcc 1.000 (0.750)\n",
      "Epoch: [57][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.093)\tLoss 0.7697 (0.6539)\tAcc 0.625 (0.732)\n",
      "Epoch: [57][8/9]\tTime 0.074 (0.110)\tData 0.054 (0.089)\tLoss 1.1408 (0.7148)\tAcc 0.438 (0.695)\n",
      "Epoch: [57][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.1576 (0.7062)\tAcc 1.000 (0.700)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.290 (0.290)\tData 0.261 (0.261)\tLoss 0.8972 (0.8972)\tAcc 0.625 (0.625)\n",
      "Epoch: [58][2/5]\tTime 0.076 (0.183)\tData 0.050 (0.156)\tLoss 1.0107 (0.9540)\tAcc 0.688 (0.656)\n",
      "Epoch: [58][3/5]\tTime 0.076 (0.147)\tData 0.052 (0.121)\tLoss 0.5866 (0.8315)\tAcc 0.625 (0.646)\n",
      "Epoch: [58][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.104)\tLoss 0.7963 (0.8227)\tAcc 0.688 (0.656)\n",
      "Epoch: [58][5/5]\tTime 0.079 (0.120)\tData 0.056 (0.095)\tLoss 0.4329 (0.7746)\tAcc 0.778 (0.671)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.391 (0.391)\tData 0.367 (0.367)\tLoss 0.3470 (0.3470)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/9]\tTime 0.072 (0.231)\tData 0.051 (0.209)\tLoss 1.0194 (0.6832)\tAcc 0.438 (0.688)\n",
      "Epoch: [58][3/9]\tTime 0.074 (0.179)\tData 0.053 (0.157)\tLoss 0.5766 (0.6477)\tAcc 0.750 (0.708)\n",
      "Epoch: [58][4/9]\tTime 0.072 (0.152)\tData 0.052 (0.131)\tLoss 0.7059 (0.6622)\tAcc 0.625 (0.688)\n",
      "Epoch: [58][5/9]\tTime 0.075 (0.137)\tData 0.054 (0.115)\tLoss 0.8277 (0.6953)\tAcc 0.688 (0.688)\n",
      "Epoch: [58][6/9]\tTime 0.077 (0.127)\tData 0.054 (0.105)\tLoss 0.3092 (0.6310)\tAcc 1.000 (0.740)\n",
      "Epoch: [58][7/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.8565 (0.6632)\tAcc 0.562 (0.714)\n",
      "Epoch: [58][8/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 1.2513 (0.7367)\tAcc 0.438 (0.680)\n",
      "Epoch: [58][9/9]\tTime 0.076 (0.109)\tData 0.055 (0.088)\tLoss 0.2587 (0.7293)\tAcc 1.000 (0.685)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.337 (0.337)\tData 0.307 (0.307)\tLoss 0.8040 (0.8040)\tAcc 0.625 (0.625)\n",
      "Epoch: [59][2/5]\tTime 0.074 (0.205)\tData 0.049 (0.178)\tLoss 1.0646 (0.9343)\tAcc 0.625 (0.625)\n",
      "Epoch: [59][3/5]\tTime 0.078 (0.163)\tData 0.053 (0.136)\tLoss 0.4615 (0.7767)\tAcc 0.938 (0.729)\n",
      "Epoch: [59][4/5]\tTime 0.078 (0.142)\tData 0.053 (0.115)\tLoss 0.7034 (0.7584)\tAcc 0.688 (0.719)\n",
      "Epoch: [59][5/5]\tTime 0.082 (0.130)\tData 0.056 (0.103)\tLoss 0.7369 (0.7558)\tAcc 0.667 (0.712)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.391 (0.391)\tData 0.366 (0.366)\tLoss 0.3588 (0.3588)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/9]\tTime 0.072 (0.232)\tData 0.051 (0.208)\tLoss 0.9479 (0.6534)\tAcc 0.500 (0.719)\n",
      "Epoch: [59][3/9]\tTime 0.074 (0.179)\tData 0.053 (0.156)\tLoss 0.5754 (0.6274)\tAcc 0.875 (0.771)\n",
      "Epoch: [59][4/9]\tTime 0.073 (0.153)\tData 0.052 (0.130)\tLoss 0.6606 (0.6357)\tAcc 0.750 (0.766)\n",
      "Epoch: [59][5/9]\tTime 0.074 (0.137)\tData 0.054 (0.115)\tLoss 0.9249 (0.6935)\tAcc 0.688 (0.750)\n",
      "Epoch: [59][6/9]\tTime 0.075 (0.126)\tData 0.054 (0.105)\tLoss 0.2535 (0.6202)\tAcc 1.000 (0.792)\n",
      "Epoch: [59][7/9]\tTime 0.072 (0.119)\tData 0.053 (0.097)\tLoss 0.7878 (0.6441)\tAcc 0.688 (0.777)\n",
      "Epoch: [59][8/9]\tTime 0.075 (0.113)\tData 0.055 (0.092)\tLoss 1.0545 (0.6954)\tAcc 0.438 (0.734)\n",
      "Epoch: [59][9/9]\tTime 0.076 (0.109)\tData 0.056 (0.088)\tLoss 0.3882 (0.6907)\tAcc 1.000 (0.738)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.371 (0.371)\tData 0.342 (0.342)\tLoss 0.9227 (0.9227)\tAcc 0.625 (0.625)\n",
      "Epoch: [60][2/5]\tTime 0.080 (0.226)\tData 0.050 (0.196)\tLoss 0.8986 (0.9107)\tAcc 0.625 (0.625)\n",
      "Epoch: [60][3/5]\tTime 0.076 (0.176)\tData 0.047 (0.146)\tLoss 1.0129 (0.9448)\tAcc 0.562 (0.604)\n",
      "Epoch: [60][4/5]\tTime 0.077 (0.151)\tData 0.048 (0.122)\tLoss 0.6580 (0.8731)\tAcc 0.812 (0.656)\n",
      "Epoch: [60][5/5]\tTime 0.080 (0.137)\tData 0.050 (0.107)\tLoss 0.7776 (0.8613)\tAcc 0.667 (0.658)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.334 (0.334)\tData 0.303 (0.303)\tLoss 0.3557 (0.3557)\tAcc 0.938 (0.938)\n",
      "Epoch: [60][2/9]\tTime 0.064 (0.199)\tData 0.043 (0.173)\tLoss 0.9500 (0.6529)\tAcc 0.500 (0.719)\n",
      "Epoch: [60][3/9]\tTime 0.073 (0.157)\tData 0.052 (0.133)\tLoss 0.5999 (0.6352)\tAcc 0.812 (0.750)\n",
      "Epoch: [60][4/9]\tTime 0.074 (0.136)\tData 0.053 (0.113)\tLoss 0.6465 (0.6380)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][5/9]\tTime 0.073 (0.124)\tData 0.053 (0.101)\tLoss 0.6954 (0.6495)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.093)\tLoss 0.3467 (0.5990)\tAcc 1.000 (0.792)\n",
      "Epoch: [60][7/9]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.7268 (0.6173)\tAcc 0.625 (0.768)\n",
      "Epoch: [60][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.083)\tLoss 1.0091 (0.6662)\tAcc 0.625 (0.750)\n",
      "Epoch: [60][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.080)\tLoss 0.3622 (0.6616)\tAcc 1.000 (0.754)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.320 (0.320)\tData 0.290 (0.290)\tLoss 0.6215 (0.6215)\tAcc 0.812 (0.812)\n",
      "Epoch: [61][2/5]\tTime 0.073 (0.197)\tData 0.049 (0.170)\tLoss 0.9174 (0.7695)\tAcc 0.500 (0.656)\n",
      "Epoch: [61][3/5]\tTime 0.077 (0.157)\tData 0.053 (0.131)\tLoss 0.9028 (0.8139)\tAcc 0.562 (0.625)\n",
      "Epoch: [61][4/5]\tTime 0.077 (0.137)\tData 0.053 (0.112)\tLoss 0.6317 (0.7684)\tAcc 0.750 (0.656)\n",
      "Epoch: [61][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.100)\tLoss 0.6010 (0.7477)\tAcc 0.778 (0.671)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.350 (0.350)\tData 0.326 (0.326)\tLoss 0.2405 (0.2405)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.072 (0.211)\tData 0.050 (0.188)\tLoss 1.0296 (0.6351)\tAcc 0.500 (0.719)\n",
      "Epoch: [61][3/9]\tTime 0.073 (0.165)\tData 0.052 (0.143)\tLoss 0.5651 (0.6117)\tAcc 0.688 (0.708)\n",
      "Epoch: [61][4/9]\tTime 0.078 (0.143)\tData 0.053 (0.120)\tLoss 0.7364 (0.6429)\tAcc 0.625 (0.688)\n",
      "Epoch: [61][5/9]\tTime 0.068 (0.128)\tData 0.048 (0.106)\tLoss 0.8167 (0.6777)\tAcc 0.625 (0.675)\n",
      "Epoch: [61][6/9]\tTime 0.076 (0.120)\tData 0.055 (0.098)\tLoss 0.2431 (0.6052)\tAcc 1.000 (0.729)\n",
      "Epoch: [61][7/9]\tTime 0.073 (0.113)\tData 0.053 (0.091)\tLoss 0.6375 (0.6098)\tAcc 0.688 (0.723)\n",
      "Epoch: [61][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.087)\tLoss 1.1181 (0.6734)\tAcc 0.625 (0.711)\n",
      "Epoch: [61][9/9]\tTime 0.078 (0.105)\tData 0.059 (0.084)\tLoss 0.1481 (0.6653)\tAcc 1.000 (0.715)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.360 (0.360)\tData 0.333 (0.333)\tLoss 0.6529 (0.6529)\tAcc 0.750 (0.750)\n",
      "Epoch: [62][2/5]\tTime 0.075 (0.217)\tData 0.051 (0.192)\tLoss 0.8486 (0.7507)\tAcc 0.625 (0.688)\n",
      "Epoch: [62][3/5]\tTime 0.077 (0.170)\tData 0.053 (0.146)\tLoss 0.7213 (0.7409)\tAcc 0.688 (0.688)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.147)\tData 0.054 (0.123)\tLoss 0.6972 (0.7300)\tAcc 0.750 (0.703)\n",
      "Epoch: [62][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.109)\tLoss 0.6721 (0.7229)\tAcc 0.667 (0.699)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.322 (0.322)\tData 0.296 (0.296)\tLoss 0.2819 (0.2819)\tAcc 0.938 (0.938)\n",
      "Epoch: [62][2/9]\tTime 0.070 (0.196)\tData 0.048 (0.172)\tLoss 1.0570 (0.6694)\tAcc 0.562 (0.750)\n",
      "Epoch: [62][3/9]\tTime 0.073 (0.155)\tData 0.052 (0.132)\tLoss 0.6466 (0.6618)\tAcc 0.750 (0.750)\n",
      "Epoch: [62][4/9]\tTime 0.073 (0.134)\tData 0.052 (0.112)\tLoss 0.6325 (0.6545)\tAcc 0.625 (0.719)\n",
      "Epoch: [62][5/9]\tTime 0.074 (0.122)\tData 0.054 (0.100)\tLoss 0.8296 (0.6895)\tAcc 0.562 (0.688)\n",
      "Epoch: [62][6/9]\tTime 0.075 (0.115)\tData 0.054 (0.093)\tLoss 0.2418 (0.6149)\tAcc 1.000 (0.740)\n",
      "Epoch: [62][7/9]\tTime 0.072 (0.109)\tData 0.053 (0.087)\tLoss 0.7009 (0.6272)\tAcc 0.688 (0.732)\n",
      "Epoch: [62][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.0530 (0.6804)\tAcc 0.562 (0.711)\n",
      "Epoch: [62][9/9]\tTime 0.075 (0.101)\tData 0.054 (0.080)\tLoss 0.1586 (0.6724)\tAcc 1.000 (0.715)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.332 (0.332)\tData 0.299 (0.299)\tLoss 0.7726 (0.7726)\tAcc 0.625 (0.625)\n",
      "Epoch: [63][2/5]\tTime 0.071 (0.201)\tData 0.046 (0.173)\tLoss 0.8401 (0.8063)\tAcc 0.688 (0.656)\n",
      "Epoch: [63][3/5]\tTime 0.077 (0.160)\tData 0.053 (0.133)\tLoss 1.2278 (0.9468)\tAcc 0.438 (0.583)\n",
      "Epoch: [63][4/5]\tTime 0.076 (0.139)\tData 0.053 (0.113)\tLoss 0.3548 (0.7988)\tAcc 0.938 (0.672)\n",
      "Epoch: [63][5/5]\tTime 0.085 (0.128)\tData 0.057 (0.102)\tLoss 0.6446 (0.7798)\tAcc 0.778 (0.685)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.367 (0.367)\tData 0.341 (0.341)\tLoss 0.3042 (0.3042)\tAcc 0.938 (0.938)\n",
      "Epoch: [63][2/9]\tTime 0.070 (0.219)\tData 0.049 (0.195)\tLoss 0.9709 (0.6375)\tAcc 0.562 (0.750)\n",
      "Epoch: [63][3/9]\tTime 0.073 (0.170)\tData 0.052 (0.147)\tLoss 0.6418 (0.6390)\tAcc 0.688 (0.729)\n",
      "Epoch: [63][4/9]\tTime 0.073 (0.146)\tData 0.053 (0.124)\tLoss 0.6035 (0.6301)\tAcc 0.688 (0.719)\n",
      "Epoch: [63][5/9]\tTime 0.074 (0.132)\tData 0.053 (0.110)\tLoss 0.7612 (0.6563)\tAcc 0.688 (0.713)\n",
      "Epoch: [63][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.2340 (0.5859)\tAcc 1.000 (0.760)\n",
      "Epoch: [63][7/9]\tTime 0.072 (0.115)\tData 0.052 (0.093)\tLoss 0.5580 (0.5819)\tAcc 0.875 (0.777)\n",
      "Epoch: [63][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 1.1017 (0.6469)\tAcc 0.562 (0.750)\n",
      "Epoch: [63][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.2117 (0.6402)\tAcc 1.000 (0.754)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.291 (0.291)\tData 0.263 (0.263)\tLoss 0.7721 (0.7721)\tAcc 0.688 (0.688)\n",
      "Epoch: [64][2/5]\tTime 0.079 (0.185)\tData 0.051 (0.157)\tLoss 0.5701 (0.6711)\tAcc 0.812 (0.750)\n",
      "Epoch: [64][3/5]\tTime 0.073 (0.148)\tData 0.049 (0.121)\tLoss 0.6411 (0.6611)\tAcc 0.750 (0.750)\n",
      "Epoch: [64][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.104)\tLoss 0.6801 (0.6659)\tAcc 0.625 (0.719)\n",
      "Epoch: [64][5/5]\tTime 0.080 (0.120)\tData 0.056 (0.094)\tLoss 0.6780 (0.6674)\tAcc 0.667 (0.712)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.318 (0.318)\tData 0.290 (0.290)\tLoss 0.3288 (0.3288)\tAcc 0.938 (0.938)\n",
      "Epoch: [64][2/9]\tTime 0.069 (0.193)\tData 0.047 (0.169)\tLoss 1.0547 (0.6917)\tAcc 0.500 (0.719)\n",
      "Epoch: [64][3/9]\tTime 0.073 (0.153)\tData 0.052 (0.130)\tLoss 0.5443 (0.6426)\tAcc 0.750 (0.729)\n",
      "Epoch: [64][4/9]\tTime 0.073 (0.133)\tData 0.053 (0.110)\tLoss 0.5850 (0.6282)\tAcc 0.812 (0.750)\n",
      "Epoch: [64][5/9]\tTime 0.073 (0.121)\tData 0.054 (0.099)\tLoss 0.7243 (0.6474)\tAcc 0.750 (0.750)\n",
      "Epoch: [64][6/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 0.2784 (0.5859)\tAcc 1.000 (0.792)\n",
      "Epoch: [64][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.086)\tLoss 0.7353 (0.6073)\tAcc 0.562 (0.759)\n",
      "Epoch: [64][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.082)\tLoss 1.0287 (0.6599)\tAcc 0.500 (0.727)\n",
      "Epoch: [64][9/9]\tTime 0.076 (0.101)\tData 0.055 (0.079)\tLoss 0.1825 (0.6526)\tAcc 1.000 (0.731)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.373 (0.373)\tData 0.346 (0.346)\tLoss 1.1042 (1.1042)\tAcc 0.438 (0.438)\n",
      "Epoch: [65][2/5]\tTime 0.075 (0.224)\tData 0.051 (0.199)\tLoss 0.5910 (0.8476)\tAcc 0.750 (0.594)\n",
      "Epoch: [65][3/5]\tTime 0.076 (0.175)\tData 0.053 (0.150)\tLoss 0.7797 (0.8250)\tAcc 0.625 (0.604)\n",
      "Epoch: [65][4/5]\tTime 0.077 (0.150)\tData 0.054 (0.126)\tLoss 0.4490 (0.7310)\tAcc 0.875 (0.672)\n",
      "Epoch: [65][5/5]\tTime 0.080 (0.136)\tData 0.056 (0.112)\tLoss 0.7613 (0.7347)\tAcc 0.778 (0.685)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.314 (0.314)\tData 0.290 (0.290)\tLoss 0.3365 (0.3365)\tAcc 0.938 (0.938)\n",
      "Epoch: [65][2/9]\tTime 0.080 (0.197)\tData 0.058 (0.174)\tLoss 0.9932 (0.6649)\tAcc 0.438 (0.688)\n",
      "Epoch: [65][3/9]\tTime 0.073 (0.156)\tData 0.052 (0.134)\tLoss 0.6083 (0.6460)\tAcc 0.812 (0.729)\n",
      "Epoch: [65][4/9]\tTime 0.073 (0.135)\tData 0.053 (0.114)\tLoss 0.7695 (0.6769)\tAcc 0.688 (0.719)\n",
      "Epoch: [65][5/9]\tTime 0.075 (0.123)\tData 0.054 (0.102)\tLoss 0.7859 (0.6987)\tAcc 0.688 (0.713)\n",
      "Epoch: [65][6/9]\tTime 0.075 (0.115)\tData 0.054 (0.094)\tLoss 0.2384 (0.6220)\tAcc 1.000 (0.760)\n",
      "Epoch: [65][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.7720 (0.6434)\tAcc 0.750 (0.759)\n",
      "Epoch: [65][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 0.9569 (0.6826)\tAcc 0.625 (0.742)\n",
      "Epoch: [65][9/9]\tTime 0.078 (0.102)\tData 0.058 (0.081)\tLoss 0.2460 (0.6759)\tAcc 1.000 (0.746)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.367 (0.367)\tData 0.338 (0.338)\tLoss 0.6464 (0.6464)\tAcc 0.688 (0.688)\n",
      "Epoch: [66][2/5]\tTime 0.075 (0.221)\tData 0.050 (0.194)\tLoss 1.0095 (0.8279)\tAcc 0.562 (0.625)\n",
      "Epoch: [66][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.147)\tLoss 0.4890 (0.7149)\tAcc 0.812 (0.688)\n",
      "Epoch: [66][4/5]\tTime 0.077 (0.149)\tData 0.053 (0.124)\tLoss 0.7260 (0.7177)\tAcc 0.812 (0.719)\n",
      "Epoch: [66][5/5]\tTime 0.082 (0.135)\tData 0.056 (0.110)\tLoss 0.8372 (0.7324)\tAcc 0.444 (0.685)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.364 (0.364)\tData 0.339 (0.339)\tLoss 0.3636 (0.3636)\tAcc 0.875 (0.875)\n",
      "Epoch: [66][2/9]\tTime 0.071 (0.217)\tData 0.050 (0.194)\tLoss 0.9931 (0.6784)\tAcc 0.500 (0.688)\n",
      "Epoch: [66][3/9]\tTime 0.074 (0.170)\tData 0.053 (0.147)\tLoss 0.5776 (0.6448)\tAcc 0.875 (0.750)\n",
      "Epoch: [66][4/9]\tTime 0.075 (0.146)\tData 0.053 (0.124)\tLoss 0.6738 (0.6520)\tAcc 0.625 (0.719)\n",
      "Epoch: [66][5/9]\tTime 0.073 (0.131)\tData 0.052 (0.109)\tLoss 0.8481 (0.6912)\tAcc 0.625 (0.700)\n",
      "Epoch: [66][6/9]\tTime 0.074 (0.122)\tData 0.053 (0.100)\tLoss 0.2555 (0.6186)\tAcc 1.000 (0.750)\n",
      "Epoch: [66][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.093)\tLoss 0.5703 (0.6117)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][8/9]\tTime 0.075 (0.110)\tData 0.056 (0.089)\tLoss 1.0020 (0.6605)\tAcc 0.500 (0.719)\n",
      "Epoch: [66][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.2634 (0.6544)\tAcc 1.000 (0.723)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.329 (0.329)\tData 0.301 (0.301)\tLoss 0.7268 (0.7268)\tAcc 0.688 (0.688)\n",
      "Epoch: [67][2/5]\tTime 0.075 (0.202)\tData 0.050 (0.176)\tLoss 0.7558 (0.7413)\tAcc 0.688 (0.688)\n",
      "Epoch: [67][3/5]\tTime 0.076 (0.160)\tData 0.052 (0.134)\tLoss 0.7651 (0.7492)\tAcc 0.625 (0.667)\n",
      "Epoch: [67][4/5]\tTime 0.079 (0.140)\tData 0.056 (0.115)\tLoss 0.6115 (0.7148)\tAcc 0.812 (0.703)\n",
      "Epoch: [67][5/5]\tTime 0.080 (0.128)\tData 0.056 (0.103)\tLoss 1.4464 (0.8050)\tAcc 0.333 (0.658)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.299 (0.299)\tData 0.274 (0.274)\tLoss 0.3037 (0.3037)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/9]\tTime 0.104 (0.201)\tData 0.082 (0.178)\tLoss 1.0512 (0.6775)\tAcc 0.438 (0.688)\n",
      "Epoch: [67][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.136)\tLoss 0.5414 (0.6321)\tAcc 0.750 (0.708)\n",
      "Epoch: [67][4/9]\tTime 0.073 (0.137)\tData 0.052 (0.115)\tLoss 0.6670 (0.6408)\tAcc 0.688 (0.703)\n",
      "Epoch: [67][5/9]\tTime 0.077 (0.125)\tData 0.056 (0.103)\tLoss 0.8572 (0.6841)\tAcc 0.688 (0.700)\n",
      "Epoch: [67][6/9]\tTime 0.075 (0.117)\tData 0.053 (0.095)\tLoss 0.2313 (0.6086)\tAcc 1.000 (0.750)\n",
      "Epoch: [67][7/9]\tTime 0.078 (0.111)\tData 0.056 (0.089)\tLoss 0.6495 (0.6145)\tAcc 0.688 (0.741)\n",
      "Epoch: [67][8/9]\tTime 0.077 (0.107)\tData 0.053 (0.085)\tLoss 1.1980 (0.6874)\tAcc 0.500 (0.711)\n",
      "Epoch: [67][9/9]\tTime 0.088 (0.105)\tData 0.068 (0.083)\tLoss 0.1644 (0.6794)\tAcc 1.000 (0.715)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.366 (0.366)\tData 0.338 (0.338)\tLoss 0.3990 (0.3990)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/5]\tTime 0.075 (0.220)\tData 0.050 (0.194)\tLoss 0.6884 (0.5437)\tAcc 0.750 (0.844)\n",
      "Epoch: [68][3/5]\tTime 0.076 (0.172)\tData 0.053 (0.147)\tLoss 0.8299 (0.6391)\tAcc 0.562 (0.750)\n",
      "Epoch: [68][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 0.8646 (0.6955)\tAcc 0.688 (0.734)\n",
      "Epoch: [68][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.110)\tLoss 1.2329 (0.7618)\tAcc 0.444 (0.699)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.309 (0.309)\tData 0.283 (0.283)\tLoss 0.3347 (0.3347)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.074 (0.191)\tData 0.051 (0.167)\tLoss 0.9977 (0.6662)\tAcc 0.438 (0.688)\n",
      "Epoch: [68][3/9]\tTime 0.073 (0.152)\tData 0.051 (0.128)\tLoss 0.5196 (0.6173)\tAcc 0.875 (0.750)\n",
      "Epoch: [68][4/9]\tTime 0.074 (0.132)\tData 0.054 (0.110)\tLoss 0.6919 (0.6359)\tAcc 0.625 (0.719)\n",
      "Epoch: [68][5/9]\tTime 0.075 (0.121)\tData 0.054 (0.098)\tLoss 0.8590 (0.6806)\tAcc 0.625 (0.700)\n",
      "Epoch: [68][6/9]\tTime 0.080 (0.114)\tData 0.060 (0.092)\tLoss 0.2178 (0.6034)\tAcc 1.000 (0.750)\n",
      "Epoch: [68][7/9]\tTime 0.075 (0.109)\tData 0.054 (0.087)\tLoss 0.7818 (0.6289)\tAcc 0.625 (0.732)\n",
      "Epoch: [68][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.1122 (0.6893)\tAcc 0.500 (0.703)\n",
      "Epoch: [68][9/9]\tTime 0.076 (0.101)\tData 0.055 (0.080)\tLoss 0.2149 (0.6820)\tAcc 1.000 (0.708)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.393 (0.393)\tData 0.365 (0.365)\tLoss 0.6847 (0.6847)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][2/5]\tTime 0.074 (0.234)\tData 0.050 (0.207)\tLoss 0.5080 (0.5964)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][3/5]\tTime 0.076 (0.181)\tData 0.053 (0.156)\tLoss 0.6182 (0.6036)\tAcc 0.750 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.077 (0.155)\tData 0.054 (0.130)\tLoss 0.9143 (0.6813)\tAcc 0.562 (0.703)\n",
      "Epoch: [69][5/5]\tTime 0.080 (0.140)\tData 0.056 (0.115)\tLoss 0.9476 (0.7141)\tAcc 0.556 (0.685)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.346 (0.346)\tData 0.320 (0.320)\tLoss 0.3657 (0.3657)\tAcc 0.938 (0.938)\n",
      "Epoch: [69][2/9]\tTime 0.070 (0.208)\tData 0.048 (0.184)\tLoss 1.0590 (0.7123)\tAcc 0.500 (0.719)\n",
      "Epoch: [69][3/9]\tTime 0.075 (0.164)\tData 0.052 (0.140)\tLoss 0.5376 (0.6541)\tAcc 0.812 (0.750)\n",
      "Epoch: [69][4/9]\tTime 0.072 (0.141)\tData 0.051 (0.118)\tLoss 0.6353 (0.6494)\tAcc 0.812 (0.766)\n",
      "Epoch: [69][5/9]\tTime 0.072 (0.127)\tData 0.052 (0.104)\tLoss 0.8584 (0.6912)\tAcc 0.625 (0.738)\n",
      "Epoch: [69][6/9]\tTime 0.076 (0.119)\tData 0.055 (0.096)\tLoss 0.2651 (0.6202)\tAcc 1.000 (0.781)\n",
      "Epoch: [69][7/9]\tTime 0.073 (0.112)\tData 0.053 (0.090)\tLoss 0.8030 (0.6463)\tAcc 0.562 (0.750)\n",
      "Epoch: [69][8/9]\tTime 0.075 (0.107)\tData 0.055 (0.086)\tLoss 1.0741 (0.6998)\tAcc 0.500 (0.719)\n",
      "Epoch: [69][9/9]\tTime 0.076 (0.104)\tData 0.055 (0.082)\tLoss 0.1828 (0.6918)\tAcc 1.000 (0.723)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.350 (0.350)\tData 0.321 (0.321)\tLoss 0.6687 (0.6687)\tAcc 0.688 (0.688)\n",
      "Epoch: [70][2/5]\tTime 0.074 (0.212)\tData 0.049 (0.185)\tLoss 0.8150 (0.7419)\tAcc 0.688 (0.688)\n",
      "Epoch: [70][3/5]\tTime 0.077 (0.167)\tData 0.053 (0.141)\tLoss 0.8559 (0.7799)\tAcc 0.688 (0.688)\n",
      "Epoch: [70][4/5]\tTime 0.077 (0.144)\tData 0.054 (0.119)\tLoss 0.8274 (0.7918)\tAcc 0.750 (0.703)\n",
      "Epoch: [70][5/5]\tTime 0.080 (0.131)\tData 0.056 (0.107)\tLoss 0.4139 (0.7452)\tAcc 0.889 (0.726)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.327 (0.327)\tData 0.300 (0.300)\tLoss 0.2629 (0.2629)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/9]\tTime 0.070 (0.198)\tData 0.048 (0.174)\tLoss 1.0973 (0.6801)\tAcc 0.438 (0.688)\n",
      "Epoch: [70][3/9]\tTime 0.074 (0.157)\tData 0.053 (0.134)\tLoss 0.5224 (0.6275)\tAcc 0.750 (0.708)\n",
      "Epoch: [70][4/9]\tTime 0.074 (0.136)\tData 0.052 (0.113)\tLoss 0.6424 (0.6312)\tAcc 0.625 (0.688)\n",
      "Epoch: [70][5/9]\tTime 0.072 (0.123)\tData 0.052 (0.101)\tLoss 0.9244 (0.6899)\tAcc 0.625 (0.675)\n",
      "Epoch: [70][6/9]\tTime 0.079 (0.116)\tData 0.059 (0.094)\tLoss 0.1850 (0.6057)\tAcc 1.000 (0.729)\n",
      "Epoch: [70][7/9]\tTime 0.075 (0.110)\tData 0.054 (0.088)\tLoss 0.8292 (0.6376)\tAcc 0.625 (0.714)\n",
      "Epoch: [70][8/9]\tTime 0.074 (0.106)\tData 0.054 (0.084)\tLoss 1.1571 (0.7026)\tAcc 0.438 (0.680)\n",
      "Epoch: [70][9/9]\tTime 0.076 (0.102)\tData 0.055 (0.081)\tLoss 0.1646 (0.6943)\tAcc 1.000 (0.685)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.338 (0.338)\tData 0.308 (0.308)\tLoss 0.7301 (0.7301)\tAcc 0.750 (0.750)\n",
      "Epoch: [71][2/5]\tTime 0.073 (0.205)\tData 0.049 (0.178)\tLoss 0.4217 (0.5759)\tAcc 0.750 (0.750)\n",
      "Epoch: [71][3/5]\tTime 0.077 (0.162)\tData 0.053 (0.137)\tLoss 0.8875 (0.6798)\tAcc 0.625 (0.708)\n",
      "Epoch: [71][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.116)\tLoss 0.8821 (0.7304)\tAcc 0.625 (0.688)\n",
      "Epoch: [71][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.104)\tLoss 0.7451 (0.7322)\tAcc 0.667 (0.685)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.328 (0.328)\tData 0.304 (0.304)\tLoss 0.3657 (0.3657)\tAcc 0.875 (0.875)\n",
      "Epoch: [71][2/9]\tTime 0.072 (0.200)\tData 0.050 (0.177)\tLoss 0.9631 (0.6644)\tAcc 0.500 (0.688)\n",
      "Epoch: [71][3/9]\tTime 0.073 (0.158)\tData 0.052 (0.135)\tLoss 0.6237 (0.6508)\tAcc 0.750 (0.708)\n",
      "Epoch: [71][4/9]\tTime 0.076 (0.137)\tData 0.055 (0.115)\tLoss 0.6429 (0.6488)\tAcc 0.688 (0.703)\n",
      "Epoch: [71][5/9]\tTime 0.073 (0.124)\tData 0.053 (0.103)\tLoss 0.7736 (0.6738)\tAcc 0.688 (0.700)\n",
      "Epoch: [71][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.095)\tLoss 0.2135 (0.5971)\tAcc 1.000 (0.750)\n",
      "Epoch: [71][7/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.5592 (0.5917)\tAcc 0.812 (0.759)\n",
      "Epoch: [71][8/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 0.9350 (0.6346)\tAcc 0.625 (0.742)\n",
      "Epoch: [71][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.1853 (0.6277)\tAcc 1.000 (0.746)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.351 (0.351)\tData 0.320 (0.320)\tLoss 0.7698 (0.7698)\tAcc 0.562 (0.562)\n",
      "Epoch: [72][2/5]\tTime 0.074 (0.212)\tData 0.048 (0.184)\tLoss 0.8653 (0.8176)\tAcc 0.562 (0.562)\n",
      "Epoch: [72][3/5]\tTime 0.076 (0.167)\tData 0.052 (0.140)\tLoss 0.7548 (0.7967)\tAcc 0.750 (0.625)\n",
      "Epoch: [72][4/5]\tTime 0.077 (0.144)\tData 0.053 (0.118)\tLoss 0.6748 (0.7662)\tAcc 0.812 (0.672)\n",
      "Epoch: [72][5/5]\tTime 0.080 (0.132)\tData 0.056 (0.106)\tLoss 0.6397 (0.7506)\tAcc 0.778 (0.685)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.325 (0.325)\tData 0.298 (0.298)\tLoss 0.3542 (0.3542)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.069 (0.197)\tData 0.048 (0.173)\tLoss 1.0268 (0.6905)\tAcc 0.438 (0.688)\n",
      "Epoch: [72][3/9]\tTime 0.074 (0.156)\tData 0.053 (0.133)\tLoss 0.5729 (0.6513)\tAcc 0.750 (0.708)\n",
      "Epoch: [72][4/9]\tTime 0.074 (0.135)\tData 0.052 (0.113)\tLoss 0.7826 (0.6841)\tAcc 0.688 (0.703)\n",
      "Epoch: [72][5/9]\tTime 0.072 (0.123)\tData 0.052 (0.101)\tLoss 0.8302 (0.7134)\tAcc 0.562 (0.675)\n",
      "Epoch: [72][6/9]\tTime 0.075 (0.115)\tData 0.055 (0.093)\tLoss 0.2167 (0.6306)\tAcc 1.000 (0.729)\n",
      "Epoch: [72][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.087)\tLoss 0.6998 (0.6405)\tAcc 0.750 (0.732)\n",
      "Epoch: [72][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 1.1268 (0.7013)\tAcc 0.438 (0.695)\n",
      "Epoch: [72][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.2390 (0.6942)\tAcc 1.000 (0.700)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.308 (0.308)\tData 0.276 (0.276)\tLoss 0.7801 (0.7801)\tAcc 0.625 (0.625)\n",
      "Epoch: [73][2/5]\tTime 0.071 (0.190)\tData 0.047 (0.162)\tLoss 0.9208 (0.8505)\tAcc 0.688 (0.656)\n",
      "Epoch: [73][3/5]\tTime 0.076 (0.152)\tData 0.053 (0.125)\tLoss 0.5518 (0.7509)\tAcc 0.812 (0.708)\n",
      "Epoch: [73][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.108)\tLoss 0.8124 (0.7663)\tAcc 0.562 (0.672)\n",
      "Epoch: [73][5/5]\tTime 0.080 (0.123)\tData 0.057 (0.097)\tLoss 0.5814 (0.7435)\tAcc 0.778 (0.685)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.380 (0.380)\tData 0.355 (0.355)\tLoss 0.2841 (0.2841)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.072 (0.226)\tData 0.050 (0.203)\tLoss 0.9139 (0.5990)\tAcc 0.500 (0.719)\n",
      "Epoch: [73][3/9]\tTime 0.073 (0.175)\tData 0.053 (0.153)\tLoss 0.6161 (0.6047)\tAcc 0.812 (0.750)\n",
      "Epoch: [73][4/9]\tTime 0.073 (0.149)\tData 0.053 (0.128)\tLoss 0.6168 (0.6077)\tAcc 0.750 (0.750)\n",
      "Epoch: [73][5/9]\tTime 0.074 (0.134)\tData 0.054 (0.113)\tLoss 0.8207 (0.6503)\tAcc 0.562 (0.713)\n",
      "Epoch: [73][6/9]\tTime 0.075 (0.124)\tData 0.055 (0.103)\tLoss 0.2268 (0.5797)\tAcc 1.000 (0.760)\n",
      "Epoch: [73][7/9]\tTime 0.073 (0.117)\tData 0.053 (0.096)\tLoss 0.6342 (0.5875)\tAcc 0.875 (0.777)\n",
      "Epoch: [73][8/9]\tTime 0.074 (0.112)\tData 0.055 (0.091)\tLoss 0.9855 (0.6373)\tAcc 0.562 (0.750)\n",
      "Epoch: [73][9/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 0.1666 (0.6300)\tAcc 1.000 (0.754)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.369 (0.369)\tData 0.339 (0.339)\tLoss 1.1278 (1.1278)\tAcc 0.562 (0.562)\n",
      "Epoch: [74][2/5]\tTime 0.073 (0.221)\tData 0.049 (0.194)\tLoss 0.8376 (0.9827)\tAcc 0.688 (0.625)\n",
      "Epoch: [74][3/5]\tTime 0.077 (0.173)\tData 0.053 (0.147)\tLoss 0.5341 (0.8332)\tAcc 0.812 (0.688)\n",
      "Epoch: [74][4/5]\tTime 0.077 (0.149)\tData 0.053 (0.124)\tLoss 0.5418 (0.7603)\tAcc 0.750 (0.703)\n",
      "Epoch: [74][5/5]\tTime 0.077 (0.134)\tData 0.054 (0.110)\tLoss 0.7422 (0.7581)\tAcc 0.556 (0.685)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.348 (0.348)\tData 0.322 (0.322)\tLoss 0.3146 (0.3146)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/9]\tTime 0.070 (0.209)\tData 0.049 (0.185)\tLoss 1.0706 (0.6926)\tAcc 0.438 (0.688)\n",
      "Epoch: [74][3/9]\tTime 0.073 (0.164)\tData 0.052 (0.141)\tLoss 0.5563 (0.6472)\tAcc 0.750 (0.708)\n",
      "Epoch: [74][4/9]\tTime 0.074 (0.141)\tData 0.053 (0.119)\tLoss 0.7636 (0.6763)\tAcc 0.625 (0.688)\n",
      "Epoch: [74][5/9]\tTime 0.073 (0.127)\tData 0.053 (0.106)\tLoss 0.8631 (0.7137)\tAcc 0.562 (0.663)\n",
      "Epoch: [74][6/9]\tTime 0.075 (0.119)\tData 0.054 (0.097)\tLoss 0.2958 (0.6440)\tAcc 1.000 (0.719)\n",
      "Epoch: [74][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.8306 (0.6707)\tAcc 0.500 (0.688)\n",
      "Epoch: [74][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 1.0451 (0.7175)\tAcc 0.562 (0.672)\n",
      "Epoch: [74][9/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.3404 (0.7117)\tAcc 1.000 (0.677)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.315 (0.315)\tData 0.287 (0.287)\tLoss 0.6509 (0.6509)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][2/5]\tTime 0.074 (0.195)\tData 0.050 (0.168)\tLoss 0.8601 (0.7555)\tAcc 0.562 (0.625)\n",
      "Epoch: [75][3/5]\tTime 0.076 (0.155)\tData 0.053 (0.130)\tLoss 0.6764 (0.7291)\tAcc 0.750 (0.667)\n",
      "Epoch: [75][4/5]\tTime 0.077 (0.136)\tData 0.053 (0.111)\tLoss 0.6556 (0.7107)\tAcc 0.750 (0.688)\n",
      "Epoch: [75][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.100)\tLoss 0.5256 (0.6879)\tAcc 0.778 (0.699)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.360 (0.360)\tData 0.332 (0.332)\tLoss 0.3171 (0.3171)\tAcc 0.938 (0.938)\n",
      "Epoch: [75][2/9]\tTime 0.068 (0.214)\tData 0.046 (0.189)\tLoss 1.0392 (0.6782)\tAcc 0.562 (0.750)\n",
      "Epoch: [75][3/9]\tTime 0.074 (0.167)\tData 0.053 (0.143)\tLoss 0.5462 (0.6342)\tAcc 0.812 (0.771)\n",
      "Epoch: [75][4/9]\tTime 0.073 (0.144)\tData 0.052 (0.121)\tLoss 0.5892 (0.6229)\tAcc 0.625 (0.734)\n",
      "Epoch: [75][5/9]\tTime 0.075 (0.130)\tData 0.053 (0.107)\tLoss 0.9266 (0.6837)\tAcc 0.562 (0.700)\n",
      "Epoch: [75][6/9]\tTime 0.074 (0.120)\tData 0.053 (0.098)\tLoss 0.2410 (0.6099)\tAcc 1.000 (0.750)\n",
      "Epoch: [75][7/9]\tTime 0.073 (0.114)\tData 0.053 (0.092)\tLoss 0.7986 (0.6368)\tAcc 0.562 (0.723)\n",
      "Epoch: [75][8/9]\tTime 0.074 (0.109)\tData 0.053 (0.087)\tLoss 1.0785 (0.6920)\tAcc 0.500 (0.695)\n",
      "Epoch: [75][9/9]\tTime 0.078 (0.105)\tData 0.058 (0.084)\tLoss 0.2740 (0.6856)\tAcc 1.000 (0.700)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.356 (0.356)\tData 0.323 (0.323)\tLoss 0.6386 (0.6386)\tAcc 0.750 (0.750)\n",
      "Epoch: [76][2/5]\tTime 0.070 (0.213)\tData 0.045 (0.184)\tLoss 0.5282 (0.5834)\tAcc 0.938 (0.844)\n",
      "Epoch: [76][3/5]\tTime 0.076 (0.168)\tData 0.052 (0.140)\tLoss 0.8803 (0.6824)\tAcc 0.688 (0.792)\n",
      "Epoch: [76][4/5]\tTime 0.077 (0.145)\tData 0.053 (0.118)\tLoss 0.8688 (0.7290)\tAcc 0.688 (0.766)\n",
      "Epoch: [76][5/5]\tTime 0.080 (0.132)\tData 0.056 (0.106)\tLoss 0.5006 (0.7008)\tAcc 0.889 (0.781)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.305 (0.305)\tData 0.281 (0.281)\tLoss 0.3331 (0.3331)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/9]\tTime 0.072 (0.189)\tData 0.051 (0.166)\tLoss 1.0680 (0.7005)\tAcc 0.500 (0.719)\n",
      "Epoch: [76][3/9]\tTime 0.073 (0.150)\tData 0.052 (0.128)\tLoss 0.6374 (0.6795)\tAcc 0.750 (0.729)\n",
      "Epoch: [76][4/9]\tTime 0.075 (0.132)\tData 0.052 (0.109)\tLoss 0.6744 (0.6782)\tAcc 0.688 (0.719)\n",
      "Epoch: [76][5/9]\tTime 0.073 (0.120)\tData 0.051 (0.097)\tLoss 0.9849 (0.7396)\tAcc 0.688 (0.713)\n",
      "Epoch: [76][6/9]\tTime 0.074 (0.112)\tData 0.053 (0.090)\tLoss 0.2756 (0.6622)\tAcc 1.000 (0.760)\n",
      "Epoch: [76][7/9]\tTime 0.073 (0.107)\tData 0.053 (0.085)\tLoss 0.5537 (0.6467)\tAcc 0.875 (0.777)\n",
      "Epoch: [76][8/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 1.0457 (0.6966)\tAcc 0.438 (0.734)\n",
      "Epoch: [76][9/9]\tTime 0.075 (0.100)\tData 0.054 (0.078)\tLoss 0.2793 (0.6902)\tAcc 1.000 (0.738)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.400 (0.400)\tData 0.372 (0.372)\tLoss 0.5925 (0.5925)\tAcc 0.812 (0.812)\n",
      "Epoch: [77][2/5]\tTime 0.075 (0.237)\tData 0.051 (0.211)\tLoss 0.6811 (0.6368)\tAcc 0.688 (0.750)\n",
      "Epoch: [77][3/5]\tTime 0.077 (0.184)\tData 0.053 (0.159)\tLoss 0.6131 (0.6289)\tAcc 0.750 (0.750)\n",
      "Epoch: [77][4/5]\tTime 0.077 (0.157)\tData 0.053 (0.132)\tLoss 0.9257 (0.7031)\tAcc 0.562 (0.703)\n",
      "Epoch: [77][5/5]\tTime 0.080 (0.142)\tData 0.056 (0.117)\tLoss 1.0023 (0.7400)\tAcc 0.556 (0.685)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.324 (0.324)\tData 0.300 (0.300)\tLoss 0.3499 (0.3499)\tAcc 0.938 (0.938)\n",
      "Epoch: [77][2/9]\tTime 0.074 (0.199)\tData 0.050 (0.175)\tLoss 0.9107 (0.6303)\tAcc 0.438 (0.688)\n",
      "Epoch: [77][3/9]\tTime 0.071 (0.156)\tData 0.051 (0.134)\tLoss 0.5690 (0.6099)\tAcc 0.812 (0.729)\n",
      "Epoch: [77][4/9]\tTime 0.074 (0.136)\tData 0.053 (0.114)\tLoss 0.6270 (0.6141)\tAcc 0.688 (0.719)\n",
      "Epoch: [77][5/9]\tTime 0.073 (0.123)\tData 0.053 (0.102)\tLoss 0.7412 (0.6396)\tAcc 0.750 (0.725)\n",
      "Epoch: [77][6/9]\tTime 0.076 (0.115)\tData 0.055 (0.094)\tLoss 0.3304 (0.5880)\tAcc 1.000 (0.771)\n",
      "Epoch: [77][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.5828 (0.5873)\tAcc 0.938 (0.795)\n",
      "Epoch: [77][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 0.8828 (0.6242)\tAcc 0.688 (0.781)\n",
      "Epoch: [77][9/9]\tTime 0.076 (0.102)\tData 0.056 (0.081)\tLoss 0.2076 (0.6178)\tAcc 1.000 (0.785)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.359 (0.359)\tData 0.329 (0.329)\tLoss 0.6719 (0.6719)\tAcc 0.625 (0.625)\n",
      "Epoch: [78][2/5]\tTime 0.073 (0.216)\tData 0.049 (0.189)\tLoss 0.7190 (0.6955)\tAcc 0.688 (0.656)\n",
      "Epoch: [78][3/5]\tTime 0.077 (0.170)\tData 0.053 (0.144)\tLoss 0.6819 (0.6909)\tAcc 0.812 (0.708)\n",
      "Epoch: [78][4/5]\tTime 0.077 (0.146)\tData 0.054 (0.121)\tLoss 0.9750 (0.7620)\tAcc 0.562 (0.672)\n",
      "Epoch: [78][5/5]\tTime 0.080 (0.133)\tData 0.056 (0.108)\tLoss 0.9791 (0.7887)\tAcc 0.667 (0.671)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.376 (0.376)\tData 0.350 (0.350)\tLoss 0.3415 (0.3415)\tAcc 0.875 (0.875)\n",
      "Epoch: [78][2/9]\tTime 0.072 (0.224)\tData 0.049 (0.200)\tLoss 0.9832 (0.6623)\tAcc 0.500 (0.688)\n",
      "Epoch: [78][3/9]\tTime 0.074 (0.174)\tData 0.052 (0.151)\tLoss 0.6734 (0.6660)\tAcc 0.750 (0.708)\n",
      "Epoch: [78][4/9]\tTime 0.073 (0.149)\tData 0.052 (0.126)\tLoss 0.5801 (0.6445)\tAcc 0.812 (0.734)\n",
      "Epoch: [78][5/9]\tTime 0.072 (0.133)\tData 0.053 (0.111)\tLoss 0.8055 (0.6767)\tAcc 0.688 (0.725)\n",
      "Epoch: [78][6/9]\tTime 0.075 (0.124)\tData 0.055 (0.102)\tLoss 0.2990 (0.6138)\tAcc 1.000 (0.771)\n",
      "Epoch: [78][7/9]\tTime 0.073 (0.116)\tData 0.053 (0.095)\tLoss 0.6567 (0.6199)\tAcc 0.688 (0.759)\n",
      "Epoch: [78][8/9]\tTime 0.075 (0.111)\tData 0.055 (0.090)\tLoss 0.8865 (0.6532)\tAcc 0.500 (0.727)\n",
      "Epoch: [78][9/9]\tTime 0.076 (0.107)\tData 0.056 (0.086)\tLoss 0.1750 (0.6459)\tAcc 1.000 (0.731)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.329 (0.329)\tData 0.297 (0.297)\tLoss 0.5060 (0.5060)\tAcc 0.875 (0.875)\n",
      "Epoch: [79][2/5]\tTime 0.073 (0.201)\tData 0.047 (0.172)\tLoss 0.6878 (0.5969)\tAcc 0.812 (0.844)\n",
      "Epoch: [79][3/5]\tTime 0.075 (0.159)\tData 0.052 (0.132)\tLoss 0.6654 (0.6198)\tAcc 0.812 (0.833)\n",
      "Epoch: [79][4/5]\tTime 0.077 (0.138)\tData 0.053 (0.112)\tLoss 1.1752 (0.7586)\tAcc 0.500 (0.750)\n",
      "Epoch: [79][5/5]\tTime 0.078 (0.126)\tData 0.054 (0.101)\tLoss 0.5534 (0.7333)\tAcc 0.778 (0.753)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.3016 (0.3016)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.070 (0.218)\tData 0.049 (0.194)\tLoss 0.8712 (0.5864)\tAcc 0.562 (0.750)\n",
      "Epoch: [79][3/9]\tTime 0.075 (0.170)\tData 0.053 (0.147)\tLoss 0.7059 (0.6262)\tAcc 0.750 (0.750)\n",
      "Epoch: [79][4/9]\tTime 0.074 (0.146)\tData 0.052 (0.123)\tLoss 0.7247 (0.6508)\tAcc 0.625 (0.719)\n",
      "Epoch: [79][5/9]\tTime 0.072 (0.131)\tData 0.052 (0.109)\tLoss 0.8704 (0.6947)\tAcc 0.625 (0.700)\n",
      "Epoch: [79][6/9]\tTime 0.075 (0.122)\tData 0.055 (0.100)\tLoss 0.3441 (0.6363)\tAcc 0.938 (0.740)\n",
      "Epoch: [79][7/9]\tTime 0.073 (0.115)\tData 0.054 (0.093)\tLoss 0.7596 (0.6539)\tAcc 0.688 (0.732)\n",
      "Epoch: [79][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 1.0829 (0.7075)\tAcc 0.562 (0.711)\n",
      "Epoch: [79][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.4034 (0.7029)\tAcc 1.000 (0.715)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.384 (0.384)\tData 0.356 (0.356)\tLoss 0.5983 (0.5983)\tAcc 0.812 (0.812)\n",
      "Epoch: [80][2/5]\tTime 0.075 (0.230)\tData 0.050 (0.203)\tLoss 0.8081 (0.7032)\tAcc 0.625 (0.719)\n",
      "Epoch: [80][3/5]\tTime 0.076 (0.178)\tData 0.053 (0.153)\tLoss 0.5549 (0.6538)\tAcc 0.812 (0.750)\n",
      "Epoch: [80][4/5]\tTime 0.077 (0.153)\tData 0.054 (0.128)\tLoss 0.7222 (0.6709)\tAcc 0.750 (0.750)\n",
      "Epoch: [80][5/5]\tTime 0.080 (0.138)\tData 0.056 (0.114)\tLoss 0.8988 (0.6990)\tAcc 0.556 (0.726)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.298 (0.298)\tData 0.270 (0.270)\tLoss 0.3229 (0.3229)\tAcc 0.938 (0.938)\n",
      "Epoch: [80][2/9]\tTime 0.068 (0.183)\tData 0.046 (0.158)\tLoss 1.0378 (0.6804)\tAcc 0.500 (0.719)\n",
      "Epoch: [80][3/9]\tTime 0.074 (0.146)\tData 0.053 (0.123)\tLoss 0.5195 (0.6267)\tAcc 0.875 (0.771)\n",
      "Epoch: [80][4/9]\tTime 0.077 (0.129)\tData 0.053 (0.105)\tLoss 0.6643 (0.6361)\tAcc 0.688 (0.750)\n",
      "Epoch: [80][5/9]\tTime 0.070 (0.117)\tData 0.051 (0.094)\tLoss 0.7036 (0.6496)\tAcc 0.812 (0.762)\n",
      "Epoch: [80][6/9]\tTime 0.081 (0.111)\tData 0.061 (0.089)\tLoss 0.2738 (0.5870)\tAcc 1.000 (0.802)\n",
      "Epoch: [80][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 0.7844 (0.6152)\tAcc 0.562 (0.768)\n",
      "Epoch: [80][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.080)\tLoss 1.1470 (0.6817)\tAcc 0.438 (0.727)\n",
      "Epoch: [80][9/9]\tTime 0.075 (0.099)\tData 0.055 (0.078)\tLoss 0.2596 (0.6752)\tAcc 1.000 (0.731)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.326 (0.326)\tData 0.297 (0.297)\tLoss 0.6746 (0.6746)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][2/5]\tTime 0.075 (0.200)\tData 0.050 (0.173)\tLoss 0.8987 (0.7866)\tAcc 0.688 (0.719)\n",
      "Epoch: [81][3/5]\tTime 0.076 (0.159)\tData 0.052 (0.133)\tLoss 0.5614 (0.7116)\tAcc 0.812 (0.750)\n",
      "Epoch: [81][4/5]\tTime 0.076 (0.138)\tData 0.053 (0.113)\tLoss 0.9637 (0.7746)\tAcc 0.625 (0.719)\n",
      "Epoch: [81][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.101)\tLoss 0.7531 (0.7719)\tAcc 0.667 (0.712)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.350 (0.350)\tData 0.326 (0.326)\tLoss 0.3214 (0.3214)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/9]\tTime 0.072 (0.211)\tData 0.051 (0.189)\tLoss 1.0555 (0.6885)\tAcc 0.562 (0.750)\n",
      "Epoch: [81][3/9]\tTime 0.075 (0.166)\tData 0.053 (0.143)\tLoss 0.6290 (0.6686)\tAcc 0.750 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.073 (0.142)\tData 0.051 (0.120)\tLoss 0.7347 (0.6851)\tAcc 0.625 (0.719)\n",
      "Epoch: [81][5/9]\tTime 0.072 (0.128)\tData 0.053 (0.107)\tLoss 0.8510 (0.7183)\tAcc 0.688 (0.713)\n",
      "Epoch: [81][6/9]\tTime 0.075 (0.119)\tData 0.055 (0.098)\tLoss 0.3009 (0.6487)\tAcc 1.000 (0.760)\n",
      "Epoch: [81][7/9]\tTime 0.073 (0.113)\tData 0.053 (0.092)\tLoss 0.6979 (0.6558)\tAcc 0.688 (0.750)\n",
      "Epoch: [81][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.087)\tLoss 0.9543 (0.6931)\tAcc 0.625 (0.734)\n",
      "Epoch: [81][9/9]\tTime 0.076 (0.104)\tData 0.056 (0.084)\tLoss 0.2760 (0.6867)\tAcc 1.000 (0.738)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.348 (0.348)\tData 0.321 (0.321)\tLoss 0.5519 (0.5519)\tAcc 0.812 (0.812)\n",
      "Epoch: [82][2/5]\tTime 0.075 (0.212)\tData 0.051 (0.186)\tLoss 0.5571 (0.5545)\tAcc 0.875 (0.844)\n",
      "Epoch: [82][3/5]\tTime 0.078 (0.167)\tData 0.053 (0.141)\tLoss 0.9409 (0.6833)\tAcc 0.562 (0.750)\n",
      "Epoch: [82][4/5]\tTime 0.076 (0.144)\tData 0.052 (0.119)\tLoss 0.7351 (0.6962)\tAcc 0.688 (0.734)\n",
      "Epoch: [82][5/5]\tTime 0.080 (0.131)\tData 0.056 (0.106)\tLoss 0.9606 (0.7288)\tAcc 0.556 (0.712)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.334 (0.334)\tData 0.302 (0.302)\tLoss 0.2924 (0.2924)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/9]\tTime 0.065 (0.199)\tData 0.043 (0.172)\tLoss 0.9615 (0.6269)\tAcc 0.500 (0.719)\n",
      "Epoch: [82][3/9]\tTime 0.080 (0.159)\tData 0.052 (0.132)\tLoss 0.6767 (0.6435)\tAcc 0.812 (0.750)\n",
      "Epoch: [82][4/9]\tTime 0.068 (0.137)\tData 0.046 (0.111)\tLoss 0.5314 (0.6155)\tAcc 0.812 (0.766)\n",
      "Epoch: [82][5/9]\tTime 0.073 (0.124)\tData 0.053 (0.099)\tLoss 0.8200 (0.6564)\tAcc 0.625 (0.738)\n",
      "Epoch: [82][6/9]\tTime 0.077 (0.116)\tData 0.054 (0.092)\tLoss 0.3464 (0.6047)\tAcc 0.938 (0.771)\n",
      "Epoch: [82][7/9]\tTime 0.073 (0.110)\tData 0.053 (0.086)\tLoss 0.7578 (0.6266)\tAcc 0.562 (0.741)\n",
      "Epoch: [82][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.082)\tLoss 1.0750 (0.6826)\tAcc 0.438 (0.703)\n",
      "Epoch: [82][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.079)\tLoss 0.2059 (0.6753)\tAcc 1.000 (0.708)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.364 (0.364)\tData 0.336 (0.336)\tLoss 0.4809 (0.4809)\tAcc 0.812 (0.812)\n",
      "Epoch: [83][2/5]\tTime 0.076 (0.220)\tData 0.051 (0.193)\tLoss 1.2109 (0.8459)\tAcc 0.500 (0.656)\n",
      "Epoch: [83][3/5]\tTime 0.076 (0.172)\tData 0.052 (0.146)\tLoss 0.5404 (0.7441)\tAcc 0.812 (0.708)\n",
      "Epoch: [83][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.123)\tLoss 1.0329 (0.8163)\tAcc 0.562 (0.672)\n",
      "Epoch: [83][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.110)\tLoss 0.7164 (0.8040)\tAcc 0.778 (0.685)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.315 (0.315)\tData 0.289 (0.289)\tLoss 0.3764 (0.3764)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.070 (0.193)\tData 0.048 (0.169)\tLoss 0.9958 (0.6861)\tAcc 0.562 (0.750)\n",
      "Epoch: [83][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.130)\tLoss 0.6662 (0.6795)\tAcc 0.688 (0.729)\n",
      "Epoch: [83][4/9]\tTime 0.073 (0.133)\tData 0.053 (0.111)\tLoss 0.6069 (0.6613)\tAcc 0.812 (0.750)\n",
      "Epoch: [83][5/9]\tTime 0.075 (0.121)\tData 0.054 (0.099)\tLoss 1.0135 (0.7318)\tAcc 0.625 (0.725)\n",
      "Epoch: [83][6/9]\tTime 0.081 (0.115)\tData 0.060 (0.093)\tLoss 0.3290 (0.6646)\tAcc 1.000 (0.771)\n",
      "Epoch: [83][7/9]\tTime 0.073 (0.109)\tData 0.053 (0.087)\tLoss 0.6650 (0.6647)\tAcc 0.750 (0.768)\n",
      "Epoch: [83][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.9976 (0.7063)\tAcc 0.500 (0.734)\n",
      "Epoch: [83][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.1911 (0.6984)\tAcc 1.000 (0.738)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.362 (0.362)\tData 0.335 (0.335)\tLoss 0.7191 (0.7191)\tAcc 0.625 (0.625)\n",
      "Epoch: [84][2/5]\tTime 0.075 (0.219)\tData 0.051 (0.193)\tLoss 0.6204 (0.6697)\tAcc 0.812 (0.719)\n",
      "Epoch: [84][3/5]\tTime 0.077 (0.171)\tData 0.053 (0.146)\tLoss 0.8514 (0.7303)\tAcc 0.625 (0.688)\n",
      "Epoch: [84][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.123)\tLoss 0.8379 (0.7572)\tAcc 0.625 (0.672)\n",
      "Epoch: [84][5/5]\tTime 0.078 (0.134)\tData 0.055 (0.110)\tLoss 1.0090 (0.7883)\tAcc 0.556 (0.658)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.374 (0.374)\tData 0.334 (0.334)\tLoss 0.4276 (0.4276)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/9]\tTime 0.058 (0.216)\tData 0.035 (0.184)\tLoss 0.8778 (0.6527)\tAcc 0.562 (0.750)\n",
      "Epoch: [84][3/9]\tTime 0.073 (0.168)\tData 0.050 (0.140)\tLoss 0.6897 (0.6651)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][4/9]\tTime 0.075 (0.145)\tData 0.051 (0.118)\tLoss 0.6644 (0.6649)\tAcc 0.625 (0.719)\n",
      "Epoch: [84][5/9]\tTime 0.071 (0.130)\tData 0.050 (0.104)\tLoss 0.7949 (0.6909)\tAcc 0.688 (0.713)\n",
      "Epoch: [84][6/9]\tTime 0.075 (0.121)\tData 0.054 (0.096)\tLoss 0.3637 (0.6364)\tAcc 0.938 (0.750)\n",
      "Epoch: [84][7/9]\tTime 0.073 (0.114)\tData 0.053 (0.090)\tLoss 0.8900 (0.6726)\tAcc 0.562 (0.723)\n",
      "Epoch: [84][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.085)\tLoss 1.1989 (0.7384)\tAcc 0.438 (0.688)\n",
      "Epoch: [84][9/9]\tTime 0.075 (0.105)\tData 0.055 (0.082)\tLoss 0.2547 (0.7309)\tAcc 1.000 (0.692)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.359 (0.359)\tData 0.331 (0.331)\tLoss 1.0031 (1.0031)\tAcc 0.562 (0.562)\n",
      "Epoch: [85][2/5]\tTime 0.075 (0.217)\tData 0.051 (0.191)\tLoss 0.8867 (0.9449)\tAcc 0.562 (0.562)\n",
      "Epoch: [85][3/5]\tTime 0.077 (0.170)\tData 0.053 (0.145)\tLoss 0.5621 (0.8173)\tAcc 0.812 (0.646)\n",
      "Epoch: [85][4/5]\tTime 0.077 (0.147)\tData 0.053 (0.122)\tLoss 0.5816 (0.7583)\tAcc 0.812 (0.688)\n",
      "Epoch: [85][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.109)\tLoss 0.5475 (0.7323)\tAcc 0.778 (0.699)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.312 (0.312)\tData 0.287 (0.287)\tLoss 0.3201 (0.3201)\tAcc 0.938 (0.938)\n",
      "Epoch: [85][2/9]\tTime 0.072 (0.192)\tData 0.050 (0.168)\tLoss 0.9797 (0.6499)\tAcc 0.438 (0.688)\n",
      "Epoch: [85][3/9]\tTime 0.073 (0.152)\tData 0.052 (0.129)\tLoss 0.5945 (0.6314)\tAcc 0.812 (0.729)\n",
      "Epoch: [85][4/9]\tTime 0.073 (0.132)\tData 0.053 (0.110)\tLoss 0.6239 (0.6295)\tAcc 0.875 (0.766)\n",
      "Epoch: [85][5/9]\tTime 0.089 (0.124)\tData 0.068 (0.102)\tLoss 0.9045 (0.6845)\tAcc 0.562 (0.725)\n",
      "Epoch: [85][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.094)\tLoss 0.2661 (0.6148)\tAcc 1.000 (0.771)\n",
      "Epoch: [85][7/9]\tTime 0.073 (0.109)\tData 0.053 (0.088)\tLoss 0.8353 (0.6463)\tAcc 0.562 (0.741)\n",
      "Epoch: [85][8/9]\tTime 0.076 (0.105)\tData 0.056 (0.084)\tLoss 1.0029 (0.6909)\tAcc 0.625 (0.727)\n",
      "Epoch: [85][9/9]\tTime 0.075 (0.102)\tData 0.055 (0.081)\tLoss 0.1636 (0.6828)\tAcc 1.000 (0.731)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.404 (0.404)\tData 0.376 (0.376)\tLoss 0.5561 (0.5561)\tAcc 0.812 (0.812)\n",
      "Epoch: [86][2/5]\tTime 0.076 (0.240)\tData 0.051 (0.213)\tLoss 0.7710 (0.6635)\tAcc 0.688 (0.750)\n",
      "Epoch: [86][3/5]\tTime 0.076 (0.185)\tData 0.052 (0.160)\tLoss 0.9228 (0.7500)\tAcc 0.500 (0.667)\n",
      "Epoch: [86][4/5]\tTime 0.077 (0.158)\tData 0.053 (0.133)\tLoss 0.7307 (0.7452)\tAcc 0.750 (0.688)\n",
      "Epoch: [86][5/5]\tTime 0.080 (0.143)\tData 0.056 (0.118)\tLoss 0.8420 (0.7571)\tAcc 0.667 (0.685)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.422 (0.422)\tData 0.398 (0.398)\tLoss 0.2900 (0.2900)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.072 (0.247)\tData 0.050 (0.224)\tLoss 0.8988 (0.5944)\tAcc 0.625 (0.781)\n",
      "Epoch: [86][3/9]\tTime 0.072 (0.189)\tData 0.052 (0.167)\tLoss 0.6212 (0.6033)\tAcc 0.812 (0.792)\n",
      "Epoch: [86][4/9]\tTime 0.073 (0.160)\tData 0.053 (0.138)\tLoss 0.7927 (0.6507)\tAcc 0.562 (0.734)\n",
      "Epoch: [86][5/9]\tTime 0.073 (0.142)\tData 0.054 (0.121)\tLoss 0.8196 (0.6845)\tAcc 0.750 (0.738)\n",
      "Epoch: [86][6/9]\tTime 0.075 (0.131)\tData 0.055 (0.110)\tLoss 0.3468 (0.6282)\tAcc 0.938 (0.771)\n",
      "Epoch: [86][7/9]\tTime 0.072 (0.123)\tData 0.053 (0.102)\tLoss 0.7950 (0.6520)\tAcc 0.562 (0.741)\n",
      "Epoch: [86][8/9]\tTime 0.074 (0.117)\tData 0.055 (0.096)\tLoss 1.1492 (0.7142)\tAcc 0.438 (0.703)\n",
      "Epoch: [86][9/9]\tTime 0.076 (0.112)\tData 0.055 (0.092)\tLoss 0.3457 (0.7085)\tAcc 1.000 (0.708)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.325 (0.325)\tData 0.294 (0.294)\tLoss 0.6284 (0.6284)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][2/5]\tTime 0.072 (0.198)\tData 0.048 (0.171)\tLoss 0.6315 (0.6300)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][3/5]\tTime 0.077 (0.158)\tData 0.053 (0.132)\tLoss 0.9855 (0.7485)\tAcc 0.625 (0.708)\n",
      "Epoch: [87][4/5]\tTime 0.076 (0.137)\tData 0.053 (0.112)\tLoss 0.6630 (0.7271)\tAcc 0.812 (0.734)\n",
      "Epoch: [87][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.101)\tLoss 0.4710 (0.6955)\tAcc 0.889 (0.753)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.362 (0.362)\tData 0.338 (0.338)\tLoss 0.4133 (0.4133)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][2/9]\tTime 0.072 (0.217)\tData 0.050 (0.194)\tLoss 0.9373 (0.6753)\tAcc 0.438 (0.656)\n",
      "Epoch: [87][3/9]\tTime 0.074 (0.169)\tData 0.053 (0.147)\tLoss 0.6099 (0.6535)\tAcc 0.875 (0.729)\n",
      "Epoch: [87][4/9]\tTime 0.073 (0.145)\tData 0.053 (0.123)\tLoss 0.7089 (0.6674)\tAcc 0.625 (0.703)\n",
      "Epoch: [87][5/9]\tTime 0.074 (0.131)\tData 0.053 (0.109)\tLoss 0.8453 (0.7030)\tAcc 0.625 (0.688)\n",
      "Epoch: [87][6/9]\tTime 0.074 (0.121)\tData 0.054 (0.100)\tLoss 0.2251 (0.6233)\tAcc 1.000 (0.740)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.7792 (0.6456)\tAcc 0.688 (0.732)\n",
      "Epoch: [87][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.089)\tLoss 0.9408 (0.6825)\tAcc 0.562 (0.711)\n",
      "Epoch: [87][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.2694 (0.6761)\tAcc 1.000 (0.715)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.262 (0.262)\tData 0.233 (0.233)\tLoss 0.5716 (0.5716)\tAcc 0.812 (0.812)\n",
      "Epoch: [88][2/5]\tTime 0.107 (0.185)\tData 0.081 (0.157)\tLoss 0.7808 (0.6762)\tAcc 0.688 (0.750)\n",
      "Epoch: [88][3/5]\tTime 0.075 (0.148)\tData 0.051 (0.122)\tLoss 0.9015 (0.7513)\tAcc 0.625 (0.708)\n",
      "Epoch: [88][4/5]\tTime 0.077 (0.130)\tData 0.053 (0.104)\tLoss 0.7735 (0.7568)\tAcc 0.562 (0.672)\n",
      "Epoch: [88][5/5]\tTime 0.081 (0.121)\tData 0.057 (0.095)\tLoss 0.7444 (0.7553)\tAcc 0.667 (0.671)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.271 (0.271)\tData 0.247 (0.247)\tLoss 0.3575 (0.3575)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/9]\tTime 0.081 (0.176)\tData 0.059 (0.153)\tLoss 1.0863 (0.7219)\tAcc 0.438 (0.688)\n",
      "Epoch: [88][3/9]\tTime 0.073 (0.142)\tData 0.052 (0.119)\tLoss 0.6167 (0.6868)\tAcc 0.812 (0.729)\n",
      "Epoch: [88][4/9]\tTime 0.075 (0.125)\tData 0.053 (0.103)\tLoss 0.6274 (0.6720)\tAcc 0.750 (0.734)\n",
      "Epoch: [88][5/9]\tTime 0.073 (0.115)\tData 0.052 (0.093)\tLoss 0.9356 (0.7247)\tAcc 0.562 (0.700)\n",
      "Epoch: [88][6/9]\tTime 0.074 (0.108)\tData 0.053 (0.086)\tLoss 0.3152 (0.6564)\tAcc 1.000 (0.750)\n",
      "Epoch: [88][7/9]\tTime 0.073 (0.103)\tData 0.053 (0.081)\tLoss 0.6735 (0.6589)\tAcc 0.750 (0.750)\n",
      "Epoch: [88][8/9]\tTime 0.075 (0.099)\tData 0.055 (0.078)\tLoss 1.2765 (0.7361)\tAcc 0.438 (0.711)\n",
      "Epoch: [88][9/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.2259 (0.7282)\tAcc 1.000 (0.715)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.357 (0.357)\tData 0.329 (0.329)\tLoss 0.7209 (0.7209)\tAcc 0.812 (0.812)\n",
      "Epoch: [89][2/5]\tTime 0.074 (0.215)\tData 0.050 (0.189)\tLoss 0.5867 (0.6538)\tAcc 0.812 (0.812)\n",
      "Epoch: [89][3/5]\tTime 0.076 (0.169)\tData 0.053 (0.144)\tLoss 0.6256 (0.6444)\tAcc 0.750 (0.792)\n",
      "Epoch: [89][4/5]\tTime 0.077 (0.146)\tData 0.054 (0.122)\tLoss 0.6994 (0.6581)\tAcc 0.688 (0.766)\n",
      "Epoch: [89][5/5]\tTime 0.081 (0.133)\tData 0.056 (0.108)\tLoss 0.5026 (0.6390)\tAcc 0.889 (0.781)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.327 (0.327)\tData 0.302 (0.302)\tLoss 0.3344 (0.3344)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.072 (0.199)\tData 0.050 (0.176)\tLoss 0.9659 (0.6501)\tAcc 0.438 (0.688)\n",
      "Epoch: [89][3/9]\tTime 0.074 (0.158)\tData 0.052 (0.135)\tLoss 0.7128 (0.6710)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][4/9]\tTime 0.076 (0.137)\tData 0.053 (0.114)\tLoss 0.6460 (0.6648)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][5/9]\tTime 0.071 (0.124)\tData 0.051 (0.102)\tLoss 0.8406 (0.6999)\tAcc 0.688 (0.688)\n",
      "Epoch: [89][6/9]\tTime 0.075 (0.116)\tData 0.054 (0.094)\tLoss 0.2431 (0.6238)\tAcc 1.000 (0.740)\n",
      "Epoch: [89][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.088)\tLoss 0.6817 (0.6321)\tAcc 0.688 (0.732)\n",
      "Epoch: [89][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.084)\tLoss 1.0761 (0.6876)\tAcc 0.375 (0.688)\n",
      "Epoch: [89][9/9]\tTime 0.076 (0.102)\tData 0.055 (0.081)\tLoss 0.3552 (0.6825)\tAcc 1.000 (0.692)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.345 (0.345)\tData 0.316 (0.316)\tLoss 0.4796 (0.4796)\tAcc 0.812 (0.812)\n",
      "Epoch: [90][2/5]\tTime 0.074 (0.210)\tData 0.049 (0.183)\tLoss 0.8086 (0.6441)\tAcc 0.688 (0.750)\n",
      "Epoch: [90][3/5]\tTime 0.077 (0.165)\tData 0.053 (0.139)\tLoss 0.5754 (0.6212)\tAcc 0.750 (0.750)\n",
      "Epoch: [90][4/5]\tTime 0.076 (0.143)\tData 0.053 (0.118)\tLoss 0.9898 (0.7133)\tAcc 0.500 (0.688)\n",
      "Epoch: [90][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.105)\tLoss 0.5585 (0.6943)\tAcc 0.889 (0.712)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.362 (0.362)\tData 0.336 (0.336)\tLoss 0.2780 (0.2780)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/9]\tTime 0.070 (0.216)\tData 0.049 (0.192)\tLoss 0.9749 (0.6264)\tAcc 0.500 (0.719)\n",
      "Epoch: [90][3/9]\tTime 0.073 (0.168)\tData 0.052 (0.146)\tLoss 0.7335 (0.6621)\tAcc 0.625 (0.688)\n",
      "Epoch: [90][4/9]\tTime 0.074 (0.145)\tData 0.053 (0.122)\tLoss 0.7729 (0.6898)\tAcc 0.688 (0.688)\n",
      "Epoch: [90][5/9]\tTime 0.073 (0.130)\tData 0.053 (0.109)\tLoss 0.9103 (0.7339)\tAcc 0.625 (0.675)\n",
      "Epoch: [90][6/9]\tTime 0.075 (0.121)\tData 0.055 (0.100)\tLoss 0.2347 (0.6507)\tAcc 1.000 (0.729)\n",
      "Epoch: [90][7/9]\tTime 0.073 (0.114)\tData 0.053 (0.093)\tLoss 0.6828 (0.6553)\tAcc 0.625 (0.714)\n",
      "Epoch: [90][8/9]\tTime 0.074 (0.109)\tData 0.054 (0.088)\tLoss 1.0023 (0.6987)\tAcc 0.500 (0.688)\n",
      "Epoch: [90][9/9]\tTime 0.076 (0.106)\tData 0.056 (0.085)\tLoss 0.1468 (0.6902)\tAcc 1.000 (0.692)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.298 (0.298)\tData 0.268 (0.268)\tLoss 0.9016 (0.9016)\tAcc 0.625 (0.625)\n",
      "Epoch: [91][2/5]\tTime 0.074 (0.186)\tData 0.049 (0.158)\tLoss 0.7650 (0.8333)\tAcc 0.750 (0.688)\n",
      "Epoch: [91][3/5]\tTime 0.077 (0.149)\tData 0.053 (0.123)\tLoss 0.7316 (0.7994)\tAcc 0.750 (0.708)\n",
      "Epoch: [91][4/5]\tTime 0.077 (0.131)\tData 0.054 (0.106)\tLoss 0.6156 (0.7534)\tAcc 0.750 (0.719)\n",
      "Epoch: [91][5/5]\tTime 0.080 (0.121)\tData 0.056 (0.096)\tLoss 0.6174 (0.7367)\tAcc 0.667 (0.712)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.291 (0.291)\tData 0.265 (0.265)\tLoss 0.3278 (0.3278)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/9]\tTime 0.070 (0.181)\tData 0.048 (0.157)\tLoss 1.1252 (0.7265)\tAcc 0.500 (0.719)\n",
      "Epoch: [91][3/9]\tTime 0.076 (0.146)\tData 0.053 (0.122)\tLoss 0.6582 (0.7037)\tAcc 0.875 (0.771)\n",
      "Epoch: [91][4/9]\tTime 0.074 (0.128)\tData 0.051 (0.104)\tLoss 0.6704 (0.6954)\tAcc 0.750 (0.766)\n",
      "Epoch: [91][5/9]\tTime 0.072 (0.117)\tData 0.052 (0.094)\tLoss 0.8174 (0.7198)\tAcc 0.688 (0.750)\n",
      "Epoch: [91][6/9]\tTime 0.076 (0.110)\tData 0.055 (0.087)\tLoss 0.2375 (0.6394)\tAcc 1.000 (0.792)\n",
      "Epoch: [91][7/9]\tTime 0.073 (0.105)\tData 0.053 (0.082)\tLoss 0.6759 (0.6446)\tAcc 0.812 (0.795)\n",
      "Epoch: [91][8/9]\tTime 0.074 (0.101)\tData 0.054 (0.079)\tLoss 1.1140 (0.7033)\tAcc 0.500 (0.758)\n",
      "Epoch: [91][9/9]\tTime 0.075 (0.098)\tData 0.055 (0.076)\tLoss 0.1618 (0.6950)\tAcc 1.000 (0.762)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.376 (0.376)\tData 0.348 (0.348)\tLoss 0.8493 (0.8493)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][2/5]\tTime 0.075 (0.226)\tData 0.050 (0.199)\tLoss 0.8128 (0.8310)\tAcc 0.625 (0.656)\n",
      "Epoch: [92][3/5]\tTime 0.075 (0.175)\tData 0.052 (0.150)\tLoss 0.9078 (0.8566)\tAcc 0.562 (0.625)\n",
      "Epoch: [92][4/5]\tTime 0.077 (0.151)\tData 0.053 (0.126)\tLoss 0.5964 (0.7916)\tAcc 0.750 (0.656)\n",
      "Epoch: [92][5/5]\tTime 0.079 (0.136)\tData 0.056 (0.112)\tLoss 0.7372 (0.7849)\tAcc 0.667 (0.658)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.311 (0.311)\tData 0.282 (0.282)\tLoss 0.2887 (0.2887)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/9]\tTime 0.070 (0.191)\tData 0.047 (0.164)\tLoss 1.0838 (0.6863)\tAcc 0.438 (0.688)\n",
      "Epoch: [92][3/9]\tTime 0.072 (0.151)\tData 0.051 (0.127)\tLoss 0.5715 (0.6480)\tAcc 0.812 (0.729)\n",
      "Epoch: [92][4/9]\tTime 0.073 (0.132)\tData 0.052 (0.108)\tLoss 0.6232 (0.6418)\tAcc 0.625 (0.703)\n",
      "Epoch: [92][5/9]\tTime 0.075 (0.120)\tData 0.054 (0.097)\tLoss 0.9385 (0.7011)\tAcc 0.625 (0.688)\n",
      "Epoch: [92][6/9]\tTime 0.074 (0.113)\tData 0.054 (0.090)\tLoss 0.2935 (0.6332)\tAcc 1.000 (0.740)\n",
      "Epoch: [92][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.7071 (0.6437)\tAcc 0.688 (0.732)\n",
      "Epoch: [92][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.081)\tLoss 1.2280 (0.7168)\tAcc 0.375 (0.688)\n",
      "Epoch: [92][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.078)\tLoss 0.3229 (0.7107)\tAcc 1.000 (0.692)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.363 (0.363)\tData 0.335 (0.335)\tLoss 0.7801 (0.7801)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][2/5]\tTime 0.075 (0.219)\tData 0.051 (0.193)\tLoss 0.6930 (0.7365)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][3/5]\tTime 0.077 (0.172)\tData 0.053 (0.146)\tLoss 0.5820 (0.6850)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][4/5]\tTime 0.076 (0.148)\tData 0.053 (0.123)\tLoss 0.5368 (0.6480)\tAcc 0.750 (0.703)\n",
      "Epoch: [93][5/5]\tTime 0.080 (0.134)\tData 0.056 (0.110)\tLoss 1.1054 (0.7044)\tAcc 0.444 (0.671)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.337 (0.337)\tData 0.311 (0.311)\tLoss 0.3233 (0.3233)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/9]\tTime 0.070 (0.203)\tData 0.048 (0.180)\tLoss 1.0082 (0.6658)\tAcc 0.438 (0.688)\n",
      "Epoch: [93][3/9]\tTime 0.074 (0.160)\tData 0.052 (0.137)\tLoss 0.5776 (0.6364)\tAcc 0.875 (0.750)\n",
      "Epoch: [93][4/9]\tTime 0.074 (0.139)\tData 0.052 (0.116)\tLoss 0.6305 (0.6349)\tAcc 0.750 (0.750)\n",
      "Epoch: [93][5/9]\tTime 0.072 (0.125)\tData 0.052 (0.103)\tLoss 0.8689 (0.6817)\tAcc 0.688 (0.738)\n",
      "Epoch: [93][6/9]\tTime 0.075 (0.117)\tData 0.054 (0.095)\tLoss 0.2272 (0.6059)\tAcc 1.000 (0.781)\n",
      "Epoch: [93][7/9]\tTime 0.073 (0.111)\tData 0.053 (0.089)\tLoss 0.6732 (0.6156)\tAcc 0.750 (0.777)\n",
      "Epoch: [93][8/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 1.0636 (0.6716)\tAcc 0.500 (0.742)\n",
      "Epoch: [93][9/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.1068 (0.6629)\tAcc 1.000 (0.746)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.328 (0.328)\tData 0.283 (0.283)\tLoss 0.6084 (0.6084)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][2/5]\tTime 0.063 (0.195)\tData 0.038 (0.160)\tLoss 0.6385 (0.6235)\tAcc 0.750 (0.812)\n",
      "Epoch: [94][3/5]\tTime 0.075 (0.155)\tData 0.052 (0.124)\tLoss 0.7641 (0.6704)\tAcc 0.625 (0.750)\n",
      "Epoch: [94][4/5]\tTime 0.077 (0.136)\tData 0.054 (0.106)\tLoss 0.7622 (0.6933)\tAcc 0.688 (0.734)\n",
      "Epoch: [94][5/5]\tTime 0.080 (0.125)\tData 0.056 (0.096)\tLoss 0.8015 (0.7067)\tAcc 0.667 (0.726)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.314 (0.314)\tData 0.290 (0.290)\tLoss 0.3793 (0.3793)\tAcc 0.875 (0.875)\n",
      "Epoch: [94][2/9]\tTime 0.072 (0.193)\tData 0.051 (0.170)\tLoss 1.0674 (0.7234)\tAcc 0.438 (0.656)\n",
      "Epoch: [94][3/9]\tTime 0.074 (0.153)\tData 0.052 (0.131)\tLoss 0.7637 (0.7368)\tAcc 0.625 (0.646)\n",
      "Epoch: [94][4/9]\tTime 0.073 (0.133)\tData 0.052 (0.111)\tLoss 0.7013 (0.7279)\tAcc 0.625 (0.641)\n",
      "Epoch: [94][5/9]\tTime 0.092 (0.125)\tData 0.060 (0.101)\tLoss 0.8279 (0.7479)\tAcc 0.812 (0.675)\n",
      "Epoch: [94][6/9]\tTime 0.074 (0.117)\tData 0.054 (0.093)\tLoss 0.2733 (0.6688)\tAcc 1.000 (0.729)\n",
      "Epoch: [94][7/9]\tTime 0.073 (0.110)\tData 0.053 (0.087)\tLoss 0.6704 (0.6690)\tAcc 0.750 (0.732)\n",
      "Epoch: [94][8/9]\tTime 0.078 (0.106)\tData 0.057 (0.084)\tLoss 1.0235 (0.7133)\tAcc 0.562 (0.711)\n",
      "Epoch: [94][9/9]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 0.2901 (0.7068)\tAcc 1.000 (0.715)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.341 (0.341)\tData 0.312 (0.312)\tLoss 0.8317 (0.8317)\tAcc 0.625 (0.625)\n",
      "Epoch: [95][2/5]\tTime 0.074 (0.208)\tData 0.049 (0.180)\tLoss 0.7861 (0.8089)\tAcc 0.625 (0.625)\n",
      "Epoch: [95][3/5]\tTime 0.075 (0.164)\tData 0.052 (0.138)\tLoss 0.8704 (0.8294)\tAcc 0.688 (0.646)\n",
      "Epoch: [95][4/5]\tTime 0.077 (0.142)\tData 0.053 (0.116)\tLoss 0.7327 (0.8052)\tAcc 0.750 (0.672)\n",
      "Epoch: [95][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.104)\tLoss 0.4244 (0.7583)\tAcc 0.889 (0.699)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.317 (0.317)\tData 0.292 (0.292)\tLoss 0.2996 (0.2996)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/9]\tTime 0.071 (0.194)\tData 0.050 (0.171)\tLoss 1.0260 (0.6628)\tAcc 0.500 (0.719)\n",
      "Epoch: [95][3/9]\tTime 0.074 (0.154)\tData 0.052 (0.131)\tLoss 0.5984 (0.6413)\tAcc 0.750 (0.729)\n",
      "Epoch: [95][4/9]\tTime 0.075 (0.134)\tData 0.052 (0.112)\tLoss 0.7638 (0.6720)\tAcc 0.625 (0.703)\n",
      "Epoch: [95][5/9]\tTime 0.073 (0.122)\tData 0.051 (0.099)\tLoss 0.7758 (0.6927)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][6/9]\tTime 0.074 (0.114)\tData 0.053 (0.092)\tLoss 0.2238 (0.6146)\tAcc 1.000 (0.740)\n",
      "Epoch: [95][7/9]\tTime 0.074 (0.108)\tData 0.053 (0.086)\tLoss 0.7482 (0.6337)\tAcc 0.750 (0.741)\n",
      "Epoch: [95][8/9]\tTime 0.073 (0.104)\tData 0.053 (0.082)\tLoss 1.0905 (0.6908)\tAcc 0.438 (0.703)\n",
      "Epoch: [95][9/9]\tTime 0.076 (0.101)\tData 0.055 (0.079)\tLoss 0.1978 (0.6832)\tAcc 1.000 (0.708)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.340 (0.340)\tData 0.311 (0.311)\tLoss 0.4982 (0.4982)\tAcc 0.875 (0.875)\n",
      "Epoch: [96][2/5]\tTime 0.074 (0.207)\tData 0.050 (0.180)\tLoss 1.1257 (0.8120)\tAcc 0.562 (0.719)\n",
      "Epoch: [96][3/5]\tTime 0.077 (0.164)\tData 0.053 (0.138)\tLoss 0.8277 (0.8172)\tAcc 0.562 (0.667)\n",
      "Epoch: [96][4/5]\tTime 0.076 (0.142)\tData 0.053 (0.117)\tLoss 0.7092 (0.7902)\tAcc 0.750 (0.688)\n",
      "Epoch: [96][5/5]\tTime 0.080 (0.129)\tData 0.056 (0.104)\tLoss 0.8084 (0.7925)\tAcc 0.667 (0.685)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.305 (0.305)\tData 0.281 (0.281)\tLoss 0.3197 (0.3197)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/9]\tTime 0.074 (0.189)\tData 0.050 (0.166)\tLoss 1.1997 (0.7597)\tAcc 0.438 (0.688)\n",
      "Epoch: [96][3/9]\tTime 0.072 (0.150)\tData 0.051 (0.128)\tLoss 0.5644 (0.6946)\tAcc 0.875 (0.750)\n",
      "Epoch: [96][4/9]\tTime 0.075 (0.132)\tData 0.053 (0.109)\tLoss 0.6372 (0.6802)\tAcc 0.688 (0.734)\n",
      "Epoch: [96][5/9]\tTime 0.073 (0.120)\tData 0.052 (0.097)\tLoss 0.8913 (0.7225)\tAcc 0.688 (0.725)\n",
      "Epoch: [96][6/9]\tTime 0.074 (0.112)\tData 0.053 (0.090)\tLoss 0.2905 (0.6505)\tAcc 1.000 (0.771)\n",
      "Epoch: [96][7/9]\tTime 0.072 (0.106)\tData 0.054 (0.085)\tLoss 0.6754 (0.6540)\tAcc 0.688 (0.759)\n",
      "Epoch: [96][8/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 1.0523 (0.7038)\tAcc 0.625 (0.742)\n",
      "Epoch: [96][9/9]\tTime 0.075 (0.099)\tData 0.055 (0.078)\tLoss 0.3009 (0.6976)\tAcc 1.000 (0.746)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.367 (0.367)\tData 0.340 (0.340)\tLoss 0.6795 (0.6795)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][2/5]\tTime 0.075 (0.221)\tData 0.051 (0.195)\tLoss 0.7522 (0.7159)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.8257 (0.7525)\tAcc 0.500 (0.667)\n",
      "Epoch: [97][4/5]\tTime 0.078 (0.149)\tData 0.053 (0.124)\tLoss 0.6763 (0.7334)\tAcc 0.688 (0.672)\n",
      "Epoch: [97][5/5]\tTime 0.079 (0.135)\tData 0.055 (0.110)\tLoss 1.0921 (0.7777)\tAcc 0.556 (0.658)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.301 (0.301)\tData 0.274 (0.274)\tLoss 0.3818 (0.3818)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/9]\tTime 0.071 (0.186)\tData 0.048 (0.161)\tLoss 1.0189 (0.7004)\tAcc 0.500 (0.719)\n",
      "Epoch: [97][3/9]\tTime 0.072 (0.148)\tData 0.050 (0.124)\tLoss 0.7279 (0.7096)\tAcc 0.750 (0.729)\n",
      "Epoch: [97][4/9]\tTime 0.075 (0.130)\tData 0.052 (0.106)\tLoss 0.5813 (0.6775)\tAcc 0.688 (0.719)\n",
      "Epoch: [97][5/9]\tTime 0.071 (0.118)\tData 0.051 (0.095)\tLoss 0.9135 (0.7247)\tAcc 0.750 (0.725)\n",
      "Epoch: [97][6/9]\tTime 0.075 (0.111)\tData 0.054 (0.088)\tLoss 0.2508 (0.6457)\tAcc 1.000 (0.771)\n",
      "Epoch: [97][7/9]\tTime 0.073 (0.105)\tData 0.053 (0.083)\tLoss 0.6332 (0.6439)\tAcc 0.812 (0.777)\n",
      "Epoch: [97][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.080)\tLoss 1.1037 (0.7014)\tAcc 0.562 (0.750)\n",
      "Epoch: [97][9/9]\tTime 0.076 (0.099)\tData 0.055 (0.077)\tLoss 0.2443 (0.6944)\tAcc 1.000 (0.754)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.390 (0.390)\tData 0.362 (0.362)\tLoss 0.7019 (0.7019)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][2/5]\tTime 0.076 (0.233)\tData 0.051 (0.206)\tLoss 0.7787 (0.7403)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][3/5]\tTime 0.080 (0.182)\tData 0.053 (0.155)\tLoss 1.0586 (0.8464)\tAcc 0.562 (0.688)\n",
      "Epoch: [98][4/5]\tTime 0.074 (0.155)\tData 0.050 (0.129)\tLoss 0.7431 (0.8206)\tAcc 0.625 (0.672)\n",
      "Epoch: [98][5/5]\tTime 0.080 (0.140)\tData 0.056 (0.114)\tLoss 0.4937 (0.7803)\tAcc 0.778 (0.685)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.364 (0.364)\tData 0.339 (0.339)\tLoss 0.3682 (0.3682)\tAcc 0.875 (0.875)\n",
      "Epoch: [98][2/9]\tTime 0.071 (0.217)\tData 0.050 (0.194)\tLoss 0.9713 (0.6698)\tAcc 0.500 (0.688)\n",
      "Epoch: [98][3/9]\tTime 0.073 (0.169)\tData 0.052 (0.147)\tLoss 0.6526 (0.6641)\tAcc 0.750 (0.708)\n",
      "Epoch: [98][4/9]\tTime 0.074 (0.146)\tData 0.053 (0.123)\tLoss 0.7083 (0.6751)\tAcc 0.688 (0.703)\n",
      "Epoch: [98][5/9]\tTime 0.072 (0.131)\tData 0.052 (0.109)\tLoss 0.8193 (0.7040)\tAcc 0.562 (0.675)\n",
      "Epoch: [98][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.100)\tLoss 0.3324 (0.6420)\tAcc 1.000 (0.729)\n",
      "Epoch: [98][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.093)\tLoss 0.7189 (0.6530)\tAcc 0.750 (0.732)\n",
      "Epoch: [98][8/9]\tTime 0.075 (0.110)\tData 0.055 (0.088)\tLoss 1.0255 (0.6996)\tAcc 0.562 (0.711)\n",
      "Epoch: [98][9/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 0.1415 (0.6910)\tAcc 1.000 (0.715)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.373 (0.373)\tData 0.344 (0.344)\tLoss 0.8123 (0.8123)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][2/5]\tTime 0.073 (0.223)\tData 0.049 (0.197)\tLoss 0.8591 (0.8357)\tAcc 0.688 (0.688)\n",
      "Epoch: [99][3/5]\tTime 0.076 (0.174)\tData 0.053 (0.149)\tLoss 0.4431 (0.7048)\tAcc 0.875 (0.750)\n",
      "Epoch: [99][4/5]\tTime 0.077 (0.150)\tData 0.054 (0.125)\tLoss 0.6260 (0.6851)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][5/5]\tTime 0.083 (0.136)\tData 0.058 (0.112)\tLoss 0.5856 (0.6728)\tAcc 0.667 (0.740)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.310 (0.310)\tData 0.284 (0.284)\tLoss 0.3287 (0.3287)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.070 (0.190)\tData 0.048 (0.166)\tLoss 1.1459 (0.7373)\tAcc 0.438 (0.688)\n",
      "Epoch: [99][3/9]\tTime 0.073 (0.151)\tData 0.052 (0.128)\tLoss 0.7516 (0.7421)\tAcc 0.625 (0.667)\n",
      "Epoch: [99][4/9]\tTime 0.074 (0.132)\tData 0.053 (0.109)\tLoss 0.8005 (0.7567)\tAcc 0.625 (0.656)\n",
      "Epoch: [99][5/9]\tTime 0.073 (0.120)\tData 0.053 (0.098)\tLoss 0.7669 (0.7587)\tAcc 0.688 (0.663)\n",
      "Epoch: [99][6/9]\tTime 0.075 (0.112)\tData 0.054 (0.091)\tLoss 0.3149 (0.6848)\tAcc 1.000 (0.719)\n",
      "Epoch: [99][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.6143 (0.6747)\tAcc 0.688 (0.714)\n",
      "Epoch: [99][8/9]\tTime 0.075 (0.103)\tData 0.055 (0.082)\tLoss 1.1116 (0.7293)\tAcc 0.438 (0.680)\n",
      "Epoch: [99][9/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 0.2952 (0.7226)\tAcc 1.000 (0.685)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.343 (0.343)\tData 0.314 (0.314)\tLoss 1.1711 (1.1711)\tAcc 0.562 (0.562)\n",
      "Epoch: [100][2/5]\tTime 0.074 (0.208)\tData 0.049 (0.181)\tLoss 0.4390 (0.8051)\tAcc 0.875 (0.719)\n",
      "Epoch: [100][3/5]\tTime 0.077 (0.165)\tData 0.053 (0.139)\tLoss 0.9071 (0.8391)\tAcc 0.688 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.077 (0.143)\tData 0.053 (0.117)\tLoss 0.8550 (0.8430)\tAcc 0.688 (0.703)\n",
      "Epoch: [100][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.105)\tLoss 0.7572 (0.8325)\tAcc 0.667 (0.699)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.288 (0.288)\tData 0.264 (0.264)\tLoss 0.4688 (0.4688)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.072 (0.180)\tData 0.051 (0.157)\tLoss 1.0223 (0.7456)\tAcc 0.688 (0.812)\n",
      "Epoch: [100][3/9]\tTime 0.075 (0.145)\tData 0.052 (0.122)\tLoss 0.5877 (0.6930)\tAcc 0.750 (0.792)\n",
      "Epoch: [100][4/9]\tTime 0.071 (0.127)\tData 0.051 (0.105)\tLoss 0.6213 (0.6750)\tAcc 0.750 (0.781)\n",
      "Epoch: [100][5/9]\tTime 0.075 (0.116)\tData 0.053 (0.094)\tLoss 0.8448 (0.7090)\tAcc 0.688 (0.762)\n",
      "Epoch: [100][6/9]\tTime 0.074 (0.109)\tData 0.054 (0.088)\tLoss 0.3912 (0.6560)\tAcc 0.938 (0.792)\n",
      "Epoch: [100][7/9]\tTime 0.072 (0.104)\tData 0.053 (0.083)\tLoss 0.7275 (0.6662)\tAcc 0.625 (0.768)\n",
      "Epoch: [100][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 1.0896 (0.7191)\tAcc 0.562 (0.742)\n",
      "Epoch: [100][9/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.3810 (0.7139)\tAcc 1.000 (0.746)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=100\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 71 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHiCAYAAAAatlGFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydedgcRbn276fnTQh7kEQRIYAbGEIIIWExbAoioCDoUVRccAHcUPRTFI8KB/UTheMHKMLBI6KieETliAoaOYgoGBWQowFBdomBAIEAgQTyTtf3R3fP9FK9V3XV1Dy/68o1b3p6untqennqrue5i4QQYBiGYRiGYRhmiGf6ABiGYRiGYRjGNjhIZhiGYRiGYZgUHCQzDMMwDMMwTAoOkhmGYRiGYRgmBQfJDMMwDMMwDJOCg2SGYRiGYRiGScFBMsMwpRDRUUS02PRxRBDR+kT0UyJ6jIgu6Xjf+xHRsorrnkJEF+k+pnBf9xDRAV3sK7bPWt+PiBYR0e1EtJqIDtd5bBWORRDRC8O/zyOiT1dZt8F+tFw7RLQ3Ed2mersMwwzhIJlhOoSI3kxE14dBwv1EdAUR7WX6uMoQQnxXCHGg6eOI8S8AngNgcyHE600fjO0Q0YVE9LmW26jcOSjgVABfFUJsJIT475bbUoYQ4j1CiM+23Q4RbRsG1BOxbWu5doQQvxVCbK96uzLadBIYZpThIJlhOoKIPgLgTAD/F0GANwvA1wC8xuRxlRF/4FvENgD+LoSYNH0gLtDhb7wNgJubfNDS85BhGIfhIJlhOoCINkWgor1fCPFjIcSTQoh1QoifCiE+Fq6zHhGdSUTLw39nEtF64Xv7EdEyIjqRiB4MVejDiegQIvo7ET1CRJ+M7e8UIvohEf0XET1BRDcS0c6x9z9BRHeG791CREfE3juaiK4lov9HRI8AOCVc9rvwfQrfezBMd/gLEc2JvicRfZuIHiKie4noU0Tkxbb7OyI6g4geJaK7iejggjZ7CRFdTUSriOhmIjosXP5vAD4D4MhQkX+X5LOnENElRHRR+B3/SkQvJqKTwuO+j4gOjK2/JRFdFrbjHUR0TOy99UMl9lEiugXAwtS+tiSiH4Xf+W4i+mDFc2IzIvpZ+LlHw7+3ir1/NRF9NvwtniCixUQ0I/b+W8M2XklE/1qwn2MBHAXgxLC9fhouv4eIPk5EfwHwJBFNpBXDSIEmog0BXAFgy3Abq4loy3C1qeFv/kT4Oy3IOY47ATwfwE/Dz69X0u7ROXwRET0O4OjU9vYgogeIqBdbdkT4fUBEuxHR78Pz534i+ioRTc05toTSTkQfCz+znIjemVr3VUT0ZyJ6PDyPTom9fU34uir8jnvGr53w8y8loj+F186fiOilsfcKf/PUcSSU/fD3/CgF1+NjFFz70+LrEtEniejhcN2jUvt9d+z/8es9+k7/G36nI2XHwzAuwkEyw3TDngCmAbi0YJ1/BbAHgHkAdgawG4BPxd7fItzG8xAEiV8H8BYAuwLYG8BniOj5sfVfA+ASAM8C8D0A/01EU8L37gw/symAfwNwERE9N/bZ3QHcBeDZAD6fOs4DAewD4MUApgM4EsDK8L2vhNt8PoB9AbwNwDtS270NwAwAXwLwDSKidEOEx/lTAIvDYzgewHeJaHshxMkI1Pj/Coftv5H+fMihAL4DYDMAfwbwSwT3vOch6LD8R2zdiwEsA7AlglSO/0tE+4fvnQzgBeG/VwJ4e+w4vfA4/zfc7v4ATiCiV+YcUxwPwDcRqKuzAKwB8NXUOm9G0H7PBjAVwEfD/c4GcC6At4bHvDmArSBBCHE+gO8C+FLYXofG3n4TgFcBmF6kygshngRwMIDl4TY2EkIsD98+DMD3EZwLl0m+Q7SNFwD4B4BDw88/jeJ2B4Jz+Ifhtr+b2t4SAE8CeHls8ZsRnOsA0AfwYQTn2p4Ifpv35X3HCCI6CEE7vwLAiwCk87yfRHBeT0fQdu+lYX71PuHr9PA7/j617WcB+DmAsxH8Zl8G8HMi2jz1HTK/eUXeAOAgANsBmItkx2ILBG3xPATn8PlEVJquIYSIvtPO4Xf6rxrHwzAjDQfJDNMNmwN4uCQ94CgApwohHhRCPIQgeH1r7P11AD4vhFiHICiZAeAsIcQTQoibEQxjz42tf4MQ4ofh+l9GEGDvAQBCiEuEEMuFEH740LsdQVAesVwI8RUhxKQQYk3qONcB2BjADgBICPE3IcT9oaJ3JICTwmO6B8C/p77DvUKIrwsh+gC+BeC5CFJP0uwBYCMApwkhnhFCXAXgZwiCuqr8Vgjxy7DNLwEwM9xe1H7bEtF0ItoawF4APi6EWCuEuAnAf8aO+w0I2v0RIcR9CAKciIUAZgohTg2P8y4EnZc3lh2cEGKlEOJHQoinhBBPIOiM7Jta7ZtCiL+Hv8EPEHSggCCg/JkQ4pow2Pw0AL9G20ScLYS4T/Ib1+F3QojLw9/0Owg6eKVUaHcA+L0Q4r/D81R2jBcjPCeIaGMAh4TLIIS4QQixJDyH70HQKUq3r4w3IGj3pWHn4JT4m0KIq4UQfw2P6S/h/qpsFwiC6tuFEN8Jj+tiALci6NBF5P3mVTg7vK4fQdB5S3/200KIp4UQv0EQrL+hxrYZZuzgIJlhumElgBlUnFe5JYB7Y/+/N1w22EYYiACB6ggAK2Lvr0EQWEbcF/0hhPAxVOxARG8jopvCoehVAOYgCLozn00TBqxfBXAOgBVEdD4RbRJ+fqrkOzwv9v8HYtt5KvwzfswRWwK4LzzuvG2VkW6bhyXtt1G4r0fCQFW2ry2RbI/499sGQQrCqlhbfhLywD8BEW1ARP8Rpkw8jmCofno8fQCx9gLwFIZtlTimMJhbifrk/s41SB/jtJLzPKKs3asc3/cAvJaCtKTXArhRCHEvAFCQXvOzMCXjcQSjD9LUBclx5f3eIKLdiejXFKTJPAbgPRW3G2373tSy3GsEyd+8CkWffTQ8T+L7jd9fGIZJwUEyw3TD7wGsBVBke7UcQdAVMStc1pStoz/CtICtACwnom0QqJ0fQOAOMR3AUgDxtAdRtGEhxNlCiF0B7Igg7eJjAB5GoDKnv8M/Gxz7cgBbh8fddltV9vWsUImU7et+xNoyfC/iPgB3CyGmx/5tLIQ4pMJ+/w+A7QHsLoTYBMOh+kz6iYTEMRHRBghGK/LI+z3Ty58CsEHs/1tU2EZTytq9dJ9CiFsQBHsHI5lqAQTpKLcCeFHYvp9Eg7ZF8vdGuI/LAGwthNgUwHmx7Za1Ufoaj7av47xOsxkFueXx/Ub3lyeR/7szzNjCQTLDdIAQ4jEEecTnUFBwtwERTSGig4noS+FqFwP4FBHNDIt1PgOgjcfurkT02lDVOwHA0wCWANgQwcP8IQAgoncgUJIrQUQLQzVtCoKH61oA/VCl/QGAzxPRxmEw/pGG3+EP4bZPDNtpPwRD0t9vsK1CwhSK6wB8gYimEdFcAO/CMAf2BwBOoqDQbisE+dERfwTwOAUFcOsTUY+I5hBRorgvh40RKNqrwlzVk2sc9g8BvJqI9qKgGO1UFN/PVyDIEy/jJgBvDr/HQUimEawAsDkFRaitqdDuVfkegA8i6GTEPbM3BvA4gNVEtAOA91bc3g8AHE1Es8POR/p32RiBAr6WiHZDEJxHPIQg7SWvrS8H8GIKrCAnwiK42QhSibrg34hoKhHtDeDVGLbXTQgU+Q0oKNxMF8NWPX8Yxik4SGaYjhBCfBlB0PgpBA/T+xCouZFf7OcAXA/gLwD+CuDGcFlTfoIgR/hRBHmerw0dNW5BkCv8ewQPv50AXFtju5sgUKIfRaDirQRwRvje8QiC27sA/A5BAHNB3QMXQjyDoCDsYAQK9dcAvE0IcWvdbVXkTQC2RaCsXQrgZCHEr8L3/g3B97wbQSHhd2LH2UcQvM8L338YQV5tlUDyTADrh59ZAuAXVQ82zEF/P4L2vR/Bb1HkYfwNALPDlJAif+IPIfg+qxDkyA/WDdv+YgB3hdtRMVRf1O5VuRjAfgCuEkI8HFv+UQQB7BMIztdKBWdCiCsQ/DZXAbgjfI3zPgCnEtETCDqyP4h99ikEueXXhm20R2rbKxEEp/8HwXVzIoBXp45bFw8gOE+WI+iIvCd2Pf0/AM8guB98C9mOyikAvhV+J85jZsYGEkL1CBrDMKahwJbqhUKIt5g+FoZhzBKOxFwkhJA6oDAMI4eVZIZhGIZhGIZJwUEywzAMwzAMw6TgdAuGYRiGYRiGScFKMsMwDMMwDMOk4CCZYRiGYRiGYVJUmRWpc2bMmCG23XZb04fBMAzDMAzDOMwNN9zwsBBipuw9K4PkbbfdFtdff73pw2AYhmEYhmEchojSU8UP4HQLhmEYhmEYhknBQTLDMAzDMAzDpOAgmWEYhmEYhmFSWJmTLGPdunVYtmwZ1q5da/pQmJpMmzYNW221FaZMmWL6UBiGYRiGYSoxMkHysmXLsPHGG2PbbbcFEZk+HKYiQgisXLkSy5Ytw3bbbWf6cBiGYRiGYSoxMukWa9euxeabb84B8ohBRNh88815BIBhGIZhmJFiZIJkABwgjyj8uzEMwzAMM2qMVJBsml6vh3nz5mHOnDl4/etfj6eeeqrxtq6++mq8+tWvBgBcdtllOO2003LXXbVqFb72ta/V3scpp5yCM844Q/ret7/9bcyZMwc77rgjZs+ePVjv6KOPxg9/+MPa+2IYhmEYhnEJDpJrsP766+Omm27C0qVLMXXqVJx33nmJ94UQ8H2/9nYPO+wwfOITn8h9v2mQnMcVV1yBM888E4sXL8bNN9+MG2+8EZtuuqmy7TMMwzAMw4w6HCQ3ZO+998Ydd9yBe+65By95yUvwvve9D/Pnz8d9992HxYsXY88998T8+fPx+te/HqtXrwYA/OIXv8AOO+yAvfbaCz/+8Y8H27rwwgvxgQ98AACwYsUKHHHEEdh5552x884747rrrsMnPvEJ3HnnnZg3bx4+9rGPAQBOP/10LFy4EHPnzsXJJ5882NbnP/95bL/99jjggANw2223SY/9C1/4As444wxsueWWAAL3iWOOOSaz3qmnnoqFCxdizpw5OPbYYyGEAACcffbZmD17NubOnYs3vvGNAIDf/OY3mDdvHubNm4dddtkFTzzxRNsmZhiGYRiGMcbIuFvEOfeXN+OuFY8r3ebzn7MJ3vvKHSutOzk5iSuuuAIHHXQQAOC2227DN7/5TXzta1/Dww8/jM997nO48sorseGGG+KLX/wivvzlL+PEE0/EMcccg6uuugovfOELceSRR0q3/cEPfhD77rsvLr30UvT7faxevRqnnXYali5diptuugkAsHjxYtx+++344x//CCEEDjvsMFxzzTXYcMMN8f3vfx9//vOfMTk5ifnz52PXXXfN7GPp0qXS5Wk+8IEP4DOf+QwA4K1vfSt+9rOf4dBDD8Vpp52Gu+++G+uttx5WrVoFADjjjDNwzjnnYNGiRVi9ejWmTZtWqS0ZhmEYhmFshJXkGqxZswbz5s3DggULMGvWLLzrXe8CAGyzzTbYY489AABLlizBLbfcgkWLFmHevHn41re+hXvvvRe33nortttuO7zoRS8CEeEtb3mLdB9XXXUV3vve9wIIcqBlaRCLFy/G4sWLscsuu2D+/Pm49dZbcfvtt+O3v/0tjjjiCGywwQbYZJNNcNhhh7X6vr/+9a+x++67Y6eddsJVV12Fm2++GQAwd+5cHHXUUbjoooswMRH0sxYtWoSPfOQjOPvss7Fq1arBcoZhGIZhmFFkJCOZqoqvaqKc5DQbbrjh4G8hBF7xilfg4osvTqxz0003KXN5EELgpJNOwnHHHZdYfuaZZ1bax4477ogbbrgBL3/5y3PXWbt2Ld73vvfh+uuvx9Zbb41TTjllYOP285//HNdccw0uu+wyfPazn8XNN9+MT3ziE3jVq16Fyy+/HHvssQeuvPJK7LDDDu2+KMMwDMMwjCFYSVbMHnvsgWuvvRZ33HEHAOCpp57C3//+d+ywww64++67ceeddwJAJoiO2H///XHuuecCAPr9Ph5//HFsvPHGiRzfV77ylbjgggsGuc7//Oc/8eCDD2KfffbBpZdeijVr1uCJJ57AT3/6U+k+TjrpJJx44ol44IEHAABPP/00zj777MQ6UUA8Y8YMrF69euB44fs+7rvvPrzsZS/Dl770JaxatQqrV6/GnXfeiZ122gkf//jHsWDBAtx6662N2o9hGIZhGMYGSpVkItoawLcBbAHAB3C+EOKs1DoE4CwAhwB4CsDRQogbw/feDuBT4aqfE0J8S93h28fMmTNx4YUX4k1vehOefvppAMDnPvc5vPjFL8b555+PV73qVZgxYwb22msvLF26NPP5s846C8ceeyy+8Y1voNfr4dxzz8Wee+6JRYsWYc6cOTj44INx+umn429/+xv23HNPAMBGG22Eiy66CPPnz8eRRx6JefPmYZtttsHee+8tPcZDDjkEK1aswAEHHAAhBIgI73znOxPrTJ8+Hccccwx22mknbLvttli4cCGAIHB/y1vegsceewxCCHz4wx/G9OnT8elPfxq//vWv0ev1MHv2bBx88MEqm5VhGIZhGKZTKHIsyF2B6LkAniuEuJGINgZwA4DDhRC3xNY5BMDxCILk3QGcJYTYnYieBeB6AAsAiPCzuwohHi3a54IFC8T111+fWPa3v/0NL3nJS+p+P8YS+PdjGIZhGMY2iOgGIcQC2XulSrIQ4n4A94d/P0FEfwPwPAC3xFZ7DYBviyDiXkJE08Pgej8AvxJCPBIeyK8AHARAnmvAWIUQAn5JJ6oqvhBYvXZd6XrrTelhSm/8soCEEHjy6cnB/6c9tRoTXja/fO0zk5j0m/8m6z9rU/SmTm38eRd5cu06qDnLk6w/tYee59i5/NRTwDPPVF49fV7ntcla6mFyvWJHHAKwwXoTTs/gueaZSfTD63tKz8N6U3pGjqPv+1jzTF/6Xu5vmHNv6nmE9afaUf40Vtf6unXAk08CAPq+wJpnJks+UBHPAzbZRPrWButNwHPs+qx15hLRtgB2AfCH1FvPA3Bf7P/LwmV5y5kR4MHH1+CxJ6s/EIt46LG1+Mjpi0vXe9ZG6+GiD+2PniRAdJmzL1+Ky2/8BwDgX373Yxyz+ALpem2N9e5+4U7Y7va/tNyKO/zgujvxjf/Rkz+/49ab4ctHv1TLto3w178C8+cDk9UftgRgoyrrTUzFsSecj5WbzChc7+37vRhv3vtFlfc/Siz5+wqc/F/DEdQpPQ9ff+++eO5mG3R+LB+58Pe49Z+rpO/tNOtZOOPteyaW/fXelTjxO0uQ138/+fW74qU7bKH6MGvx4z/cjf9YfEv5ig3YfsvpOPtdi7RsuzG77hpcswB6qHYdVuWsQ9+PyxdmUyoXbf8cfOYNUkF2ZKkcJBPRRgB+BOAEIUTapFgW0YiC5bLtHwvgWACYNWtW1cNiNDI5KTDR87DZhuu13tYT60/BcQfOLlznprsfxh9ufxCTfR89z4yCYooVj63BczZdH4fvvh2ec/UFWDN1Gtb/4hcS69y14nEsvmkZdt5uc2ywXn1lZtPLLsWmDy1XdchOsGLVU5g2pYe3v2x7pdv9zc3LsWLVGqXbNM4//xkEyB/6ELDttpU+8tPr78XjTz2DOds8C3eveAKPPrkW73hZ0vXmgd/9EVv86GK8/vkbQczPv0dc9Ju/u9emMVY8Fny3t+/3Yjz0+FpcfuM/8MjqtUaC5BWr1mD2Vpth79nPTSy/eunywXHGeejxtfAF8MZFL8CmsefF0+v6uPDXt+HBx83/bitWPYWpEx7e8XK1rku/veV+LH/0SaXbVMLddwP77gscfjguue5OCAFsv9X01pvd6StfwEGb9bF16nn+iz//Q3pujDqVnrRENAVBgPxdIcSPJassA7B17P9bAVgeLt8vtfxq2T6EEOcDOB8IcpKrHBejF4EwSN6ofZC8wXoTeO287QrX6fs+/nD7gyjLk3cRIQQ233gaXrv7drhlgylYO3V9rH/CCYl1lt1yPy7d4EYcdNw+2PbZG9fex19vvRWbXnu/qkN2Al+E5+buxedmXf7x0BN40LUHhu8Hr29+M7DbbpU+8rvvLMG6vo+jjn4pliy+Bb+46T6844RXJtZ5cOq3scWPLsaeL5yBLQp+hx8vuUtZ+peNRPe9Qxdsi9vvfwyX3/gPmPq6vhB4wRabZK6Lex98AivvWitdHwAO2mVWIqh/cu06XPjr23IV5i7xhcB6U3rKr/XljzyJfz5iYZDs+8DChcAJJ+B/1r8GW262Ad6gQuX9j3/H9ltsgu1T7fiXe1Y6GSSXJtGEzhXfAPA3IcSXc1a7DMDbKGAPAI+Fucy/BHAgEW1GRJsBODBcxowIXSY9RLlMNtxQu8YXAlEqlycEfEleVz8MUpqmogiPQMJvfIwuImLtrhIiMhbgaCMKkmvkXvpCDK7rnkeDfNvEOuFdpmyrnottGiNqGo+CfwCMCQZ51wWR/JiiRenPRPnjNggfQkBLvqxHZGfnzfcH16oQUJfL73nDe0F8cc65MepUUZIXAXgrgL8SUTSTxicBzAIAIcR5AC5H4GxxBwILuHeE7z1CRJ8F8Kfwc6dGRXwMk8amG2rXxG/gnhAQ0iA5aJfG+drkwRvDti1C6cMjhkew88HZhgZBctC+0ccIvixIjoLoUqclB9s0RnTfI6LBOWlKMPBzAsq8zl/0u6Q/E92qbPjdfG0dYkufWbEg2Q+tXpWQEySTrZ2FllRxt/gdSgTF0NXi/TnvXQBAXoU0IqxcuRL7778/AOCBBx5Ar9fDzJkzAQB//OMfMVWhW8CSJUvw0Y9+FA899BCICPvssw/OOussfPe738XSpUtx5plnKttXGV2f78Mbarf7tYG4cuPBh0/ewMM6onWQ7HmsJKeIK50qCYIJx07khkrylHD9QEnOnn/98PFCJb4DTrZpjGGgaYuSnL0u8jp/wwA/uXwofKg/xrroVZKVb7Y9CSVZQFktfEGQbMPvrBo7fFksZ/PNNx9MR33KKadgo402wkc/+tHEOkKI4ERsYQNz//3348gjj8Qll1yC3XbbDb7v45JLLhnMrGeCLt1cxllJ9gUGlm8Uplv4QqAnDZIbnmOeBxrDti0irnSqxNoHZxsaK8lRuoUHX2Q7JlGQ3ENxB87JNo0xTFkwryTnXRf5SnLwmg5CyXCwH2ecleSu0i1cVJItM/YbLe644w7MmTMH73nPezB//nzcd999mD59WD36/e9/H+9+97sBACtWrMBrX/taLFiwALvtthuWLFmS2d5XvvIVvOtd78JuYVGM53k48sgjB6p1xE9+8hPsvvvu2GWXXXDggQfiwQcfBABcddVV2HnnnTFv3jzMnz8fTz75JP75z39ir732wrx58zBnzhxcd911upqjNTYNzXVNXLmJ0i3S+ZtKlGTJzW2c0ackW/rgbEOjIHmoYEXnbTrlIgqSy1KBnGzTGHE11nRwmXdd5OXf5inJNtWZ5KnjbbG28xZPtwAryU0ZTSX5hBOAm24qX68O8+YBDVIZbrnlFnzzm9/Eeeedh8kC/9APfvCDOPHEE7HHHnvgnnvuwatf/erMtNRLly7FcccdV7rPffbZB4cddhiICOeddx7+/d//HV/84hdx+umn4/zzz8fuu++O1atXY9q0abjoootw6KGH4uMf/zj6/T7WrLG3+tSmobmu8WPBhCd8CPIyQbLfunCPc5LT6Crcc7LIrFG6RVxJDl77vsBEzOFxqCQXY20wooi4GjsMLg2mW0iW53VU8pVke0YH8/Ks22JlGlB0PKwkt2Y0g2SLeMELXoCFCxeWrnfllVfitttuG/z/0UcfxZo1a7D++uvX3uc//vEPvOENb8ADDzyAp59+Gi9+8YsBAIsWLcIJJ5yAN7/5zXjd616HjTbaCAsXLsRxxx2HtWvX4vDDD8fOO+9ceT+B0XV3+RamHwwmid/EonQLLUoy5yQn8AXgaTjHnSwyU6QkZzp/rCQDkBfumbOAkweUeR2V+LEn1x9uzzT6nGwsFHZS16rSEbNCJdm2hmjPaAbJHRavlbHhhhsO/vY8L3GSrF079JMUQpQW+e2444644YYb8KpXvapwn+9///vxyU9+EocccgiuvPJKnHbaaQCAT33qUzjssMPw85//HAsXLsTVV1+Nl7/85bj66qvx85//HEcddRROOukkHHXUUdW+nKZ8zTyGQ4zd7dMWEkoyhFRJVuFuwTnJSfQqyY61dcPCvbSSPJl6wA7SLSrkJDvXpjFkFnBGleRaFnBlhXvmf7exsoBLXatKay9ylWQHR8/AOclK8TwPm222GW6//Xb4vo9LL7108N4BBxyAc845Z/D/myTpIscffzy+8Y1v4Prrg6lJhRD41re+hYceeiix3mOPPYbnPe95g/cj7rzzTsydOxcnnXQSdtllF9x222249957scUWW+DYY4/F0UcfjT//+c81vpHo1Ch5nJVk34/lJPt+qCSngonwKeq1UJI9VpITKLVGikEupgb0+8Fry3SLbE5yQK8kX56I0HetTWNE7ZIs3LMxJzm7fl8M389+Jvubm6Dv61OSbfh+CdJKsq9YSY7uBTGcHD0DB8nK+eIXv4iDDjoI+++/P7baaqvB8nPOOQfXXnst5s6di9mzZ+PrX/965rNbbrklvve97+FDH/oQdthhB8yePRtLlizBRhslZ10/5ZRTcMQRR2DffffFc57znMHyM844A3PmzMHcuXMxffp0HHjggfif//kf7Lzzzthll13wk5/8BMcff3zl79L16U6G1ROTxNMtgpxkwmQqIphU4G7BQXISfXmKDp7HrdMtgs9lRkgqWsC5OllBRLythhZwZo4l3rmJQyT3us5TkgefseB3E0JoSa3yKDhzrTo3Ux1apc4eBUqyDb+zakYz3cIgp5xyyuDvF77whRlF+Mgjj8SRRx6Z+dzMmTPxwx/+sHT7ixYtwrXXXptZHrlkAMDrXvc6vO51r8usc+6552aWvfOd78Q73/nO0v3m0aGQPMh/dvA6KyWebhHkJHtZxS28MTWuUmYLuAycboCSvX4AACAASURBVFEDRekW6SB5snJOsoNtGiPeViaV5KiNZfeZ/MK96DNy9dmGn83XlD44SClBt8/LQqTpFrpzkt18drOSzFiD6Tw8kySV5HwLuAmPmt/sQncLwTZwA/Qqyco3a5aGPsllhXuRkix78MZxsk1jxHNmo1cTt8KojeWTieQV7uV/xpZRFX0WcMPtW4O0cE/Rtsdsxj0Okplcuj7fbSry6JqkkhzMuJfOSfZ90bxoD0jMvsQE6FSSo+07gzIlOV24l9p+Dk6q8zHiQ+ImU8+KUyeKC/fk6nNZIk03CG2e6PZ4QQ/IKMn6p6X2WElmGL3YZDzfNfGbGBUoyY3zkYHhDVNSdDGujNWDsy2NleQoSM7LSU5tPwfnlWQgk25holNQmjqB7HEVq892KMm60i1GQ0lWOGLGSrK9WHUSjgkqrquqvxvZeLPpiMRQa1i4JwuSGztbAMMbZp/TLSLyCpTaYuWDsy2NleTg79x0C1Et3WIclGQbCveKUyeG+bfJz5QoyRb8bGPVIZYqyYq2XWgBZ1MjqGFkguRp06Zh5cqVTv4IdtPuyhJCYOXKlZg2bVrpuibz8EzjIzbUGhbu9UU6SPbVpFuwkjwg7iigEtMWXlpo7G5RrXCvXEl2U6mKiNcl2Fq4l9f5K1OSbXhu+9BVuBe82vAdB0gK9/QryZZ1FBQxMu4WW221FZYtW5bxDGb08fATazGl52HVBvkToFRh2rRpCTu8PMbdAi66iZGfrySrCJJZSR6iX0lWvmlzNEy3KFOS/YpBsqs5jxFJCzg7C/fiqml8GvFBHrNke7Z0bnQpyVb6+0sK91hJbsbIBMlTpkzBdtttZ/owxoq3f+Uq7Lj1s3Di4S/pZH9OFjtVJH4T80IlWWgKkllJHqJvqloHz+WWhXteTuFeHSU5/VmXSFrADZd1TTMlWYCQ74hhw2Wgq0NsegpxKZJ0C1aSmzEy6RZM9ygdoqmAlbldHZEYah3kJGdn3FOjJHOQHJE3s1hbhkGO8k2bQ5EFXMb/O/pvhcI9qwIRxcgt4EwU7gWvZUpynCIfXpss4HSkVllpXSop3NPvbuGmksxBMpOL0iGaCliZ29UR2clE1Ltb0EBJdleNq0s8HUAlTo6KtLaAk7tbTKa3n4OrD+EIuQVc98dRNplIfJ2IIh9ee5RkfVPQA5Z14AwU7tlSoKkaDpKZXLpWktkCLq4ky2bca6kk91hJTqNPSXbwXG5tAZfjblGrcK/yrkcOe5TkyCdZnjoRXydiNJRktoBTQmG6hUVtoAgOkplcWEnujmThntwn2VfkbgFWkgcUPdzbYOWDsy2aLOAmK1vAOdaeKexRkqNjKLCAy6Rb5CvJtkwnrt8Czvx3HMAWcMrgIJnJRVcAkYeVVcIdkXhADmbc48I93bAFXA3aWsCFr5Ppwj2qFiTb4pKgi/hokg1KclHhXvp3KEplyJvKumv0TSZid7qFEAICbAHXFA6SmVyUzvdeAStzuzqikgWcUDSZiM9BcgRbwNWgkZJcbgFXtXDPg2PtmSI+JG7SHaWZkpwfhJElIwD6lOTg1aoOXDxIDhd1UbgH2PFbq4SDZCYXpfO9V8DJIeqKJFJbBoV7at0tuHAvCyvJNdA2mUhq+zmMh5Ic/G0y3aKKkiy1gBvTwr1RUJIB+e/ZiILCPcA9NZmDZCYXpcn+FXD1IqtCPJgIlGQPk/1UMNH3W7lbwAvs/zndYshYPTjb0ngykaS7RbogddKvk5Ncedcjhy2Fe4OJQQot4EazcE9Phzh4teE7Dohdq0WWfo3IVZKDV9dELg6SmVx0TbSQR5RK4NpFVoXEUKvw4UtUs9ZK8kQUJI9f++ahy8HFSu/UtjQs3Ev7JGcL91Lbz8Hz3FaS404rJp1+oiaWXRd5nT9f5N+bbFKSW6Wr5UCwsEMcXUu9XkxJ7ibdwrVrlINkJpfuLeCC13FVkoeFewJCUrjn+wITKgr3OCd5gK68e2dn3Ks5kpFIt+hFQXLzGfecas8UcYsyk6pcUbpFnmpaJKh4lqTJ6HayseE7DpAoyV2lW9jUDCrgIJnJRVfPOw8nA4uKJJRk34fvedpm3OOc5CH6HpwOPjAaBMnxwsi2Ocm2KJK6iCvJJlPPigr38pXkESnc07BdK0dAJTnJyu5zvR6nWzAMEKoDHe7Pyh55RySKJMN0C5kFnKdgxj2eTGSIvlm4htt3hoZK8tDdImfGvYo+yUSAD4faM4WscM+skpwfJNdXktUeYxN0OdlYWUuTUJK5cK8NHCQzuZgq3HMprqhKfKg1KtzT5ZMMDpIH6HK3YCU5/EjsHtI6J9l5JTlbuGeikzVUHrPvDYP39GeKCvfsSJPRf62b/44DEkpy8CcX7jWDg2Qml84L9xxN/K9CYnpkX+Qoye1m3KNeULjnlwQj44SudAtWkgOSSrI8SK4+LbVj7ZkiMTW9wU7WMIe1upJcNL27R3aoi7pHjaw6NVlJVgYHyUwunSvJ4atVN5uOSBbu5U8m0k5JDj/LOckDfHDhXmVqBsnpmb7yc5LrFO5VP9xRw49ZlJlU5aopyTILOPn27FGS9dYfWNWBYyVZGRwkM7l0PZmIk4FFRRIdEl/PtNQ08EnmIDlC/4NT+abNUTdIDl+zhXvJ829d5XQLywIRxciUZDOTiQSvMoEk77iKlGRbCvf0OdkErzZ8xwE6C/dKlWSL2kEBHCQzUoYqUHf7HNfCvfRNbDgttWJ3ix5bwKUperi3wcoHZ1saKMlAXB0NH6INc5JtUSR1kU5v8wwFl0VBVV7+7SgU7o1Vh9hguoVrlygHyYyUtArUBa5eZGVkfCx9H8jxSW4z495wWmoOkiOKhonbYOWDsy01g+T0TF9EBE+SRsSFewHp9DZT03AP7/3Z9/Lyb30BeDleSKwkG8BguoVrIhcHyYyUorw0Xbh6kZWRUW7CYCStuLVXkjndIg0ryTVoqSQDQcpF0yB5PAr3hv831Slw1QJOV/qglR1iVpKVwUEyI6UoL00Xrl5kZWRuYmEwotrdItqBYHeLAbocXAbD0uo3bY6WSjIQBMmT6TQiAQgiVpIzSrLNFnBZdwv7LeD0PM+srKVhJVkZHCQzUpQn+1fAyirhDsjcxHwfQhokt5sBkQv3srAFXA0aKsnx5pUpyX0/mIadleRkoElERjpZ1Szgsp8ptoAz/7v5mjrEVl7rUiW5m8I9qzoLCuAgmZESDfV3Wbhn5c2mA/x0MNHvh0qypHCvzY0uKtzrT5asOD70/TGaYKAt4XlZleE9JKkky3LtheeVTnLjEWVSkFwinTPrUbbIsZPj8PMFknwLuPwAlCxJt9CVWmV9uoWf7ay2IudadXICJXCQzOQgGyrVjasXWRmZnr7vAzmKWzsLuChIZiU5QleeopPG+krSLeRpRKiQbjEOPslpJdlkuoXsVtNESbalcE9Xka6V9QeSdAv9SnK4a5vaQQEcJDNSim6UunD1IitDlm4Bz8Nk7EkkhAiD5BbuFlHhHuckD9A1YY6VD862KCrci6ujvhDwBQIlmdMtJBZw3R9HkUCS54VbXrhn/nfTNeOelWmCknQLpUqyNCfZTZGLg2RGigkl2dWcpjLyCvfSwQQAJUpy2bD2OKG7cG+8leTssH063SL6u0qQ7FlSAKaLdDqAjUpyUbpFvpJsxwhAULinfrtWFpwbmUwk3LVVDdGeibIViOgCAK8G8KAQYo7k/Y8BOCq2vZcAmCmEeISI7gHwBIA+gEkhxAJVB87oxYSS7GRgUQG5ktyTBhMTPQU5yawkD9BX8R68OpVDW1tJDl4TSnIvOUlOf9gbL1eS4fa9IV1EaqpTUCSQFKVb5AVhdhXu6VCSh9u3hkgI8Tz1TlU8416GCwEclPemEOJ0IcQ8IcQ8ACcB+I0Q4pHYKi8L3+cAeYSQqUC6cXKIugKZDsnAAi4bTLRzt+Cc5DS6Kt6dLNxToSRTWkkOzkVWkrOFe0F6SffH0cQCThRM1GGPkqzLE31UlGRF2+Z0iyRCiGsAPFK2XsibAFzc6ogYK1DurViBcVWSM8GExCc5+ltNTjKnW0TofnA6dS43VpLzC/cGf1fOSa5+uKOGPUpyvmVYXv5toZIMOzqLvqbCPc9GcSeRkxz+yekWjVCWk0xEGyBQnH8UWywALCaiG4joWFX7YvSjfJaeCoyvkhy8FrlbDIPkFj/IICeZleSIood7G6x8cLalsZI8XJbOSR6ko1TwSXZdSRZCJB7IZKhwr0ggyVNNR8ECTn+H2IIvGWFUSbaoHRRQmpNcg0MBXJtKtVgkhFhORM8G8CsiujVUpjOEQfSxADBr1iyFh8U0waSS7NpFVkYmmPB9UCYnObgptSrcC3OSy4KRcUJX4Z6VD862NHa3SBXuiWznr5q7RTC5hi7bPtPYYgFXJJDk5d8WeRB7lljA6VOSLUwziAfJ4aLulGQ1u7EFle4Wb0Qq1UIIsTx8fRDApQB2y/uwEOJ8IcQCIcSCmTNnKjwspglmlGQHh6grIFeS89It2uQkRzPucbpFhC4LuKGSrHzT5miYblGkJNdJtxi0aeUjGC3Seb2mpuFupiTnB6Cmgv002pTk8NWG7zjAqAWcRe2gACVBMhFtCmBfAD+JLduQiDaO/gZwIIClKvbH6MfMtNTJfY8LMiU5r3BPhZIsxq0XUgAryTVomm6BYQN7Xo67hVfB3cLRh3BE2n3BlC908WQiyXUiipRkewr3dE1Bb7mSXJBj3ogxU5KrWMBdDGA/ADOIaBmAkwFMAQAhxHnhakcAWCyEeDL20ecAuDQ8gSYAfE8I8Qt1h87oRFZ0o5txV5IHwYTvg3o5SnKL32PgbsGFewCCB72ALiXZwgdnW1RYwKUmExm4W1TISY4/hHuVj2J0sK1wr95kIqNiAad+u1ZawEkK93T7JLuqJJcGyUKIN1VY50IEVnHxZXcB2LnpgTFmUT5EU4FxV5I9Qiyy8FLBhAp3Cy7cixO1rhZ1KdqHS+eykslEPDy9bthJq5du4eZDOMIeC7jgtcjdQla4xxZwyjfdHAOFe06OnoFn3GNyYCW5OxKpLeHNh1I5yb6SdAueljqOzglznHxgqCrca2wB5/b9IaMkw7SSnH0vL/92NCYT0WsBZ8N3HGDQAs6mZlABB8mMFBNK8rhawCVuYtHNp6fB3SIs3GN3iwCdU69z4V68fYfLerk5yTUK95xq1CG2Kcl1LeCKlWSzv5nyvNwYVubKswWcMjhIZqSYKdxzUH2rQOImFru5yRS3VjPuRYV77G4BgJXk2lijJDvUpjHS1namgsumFnD5SrL5dAu9HWK70y2KJodpxJgV7nGQzEhRPkRTAStzuzogkdqSSLdQ624B9klOwEpyTZQpydkRknpKcuVDGCmESN5vTRXuFQkkxRZwee4W5js2ejvEwavp75ggoSQHf3LhXjM4SGakKB+iqYDrw6l5+DIluedJJ11oU7jneRwkx9F5jjupeipRkpMFqT4ryQPS7gum0i2KBJLiyUTk27NDSdY3Mjo6SrKibZcW7inajyVwkMxIMaUkE9y7yMoYBBMxr1jyPPT7w4aYVJGTPBGY2Qh2twAwfHC2sdXLI0qLcarD5/tAr7r5WvTN4ylC6Rn3JuvkJHsWBiMKESLbVkaUZOQHVXn5t2kVPI7nmZ9MRGchutVKcq+n/rvnKsnBq1P3PHCQzORgQkkO9me+yKNrZIV7uT7JLYJkr8eFe3GUD0PG8FxUVRpbwA2XeSpm3HP0/pCekIOIYOJKLbou8lTTopxkIvMdmy7qD6w6L6WFewqDZCDzo7paU8RBMiNloAJ1HCXbYhfUJbLCPfJ6Ugu4iV6L32MwmQgHyUBxgVJbBk4tLk2irCDdYiLjbjHsFI57uoVIWZQFwaXJwj1ZTnJynYgidwuPzCvJXRTuWdUh1p1uEd9HiKs1RRwkM1JMWMAF+zOfv9Y1+UqyrHCvzWQikZLM7hZAN0qyU+dy48K9Cu4WFWbcc7JNY6SV5CC47P44htdF9r38yUSKC/dMq6xdFO6Z/o4JdBfuxfcRLbYx7UQBHCQzUnT6ShYx3koyxW5uaZ/k9r+HN5hxb7zaNw+dNodW5im2paGSnHS3kKcRoZKSHB6GS20aQ0gK90ZFSfZRpiQrPcTasJLMSnJTOEhmpJgo3ANCJbnTPZpH5m5BE/IgWY0FHCvJgN50CydVz4ZKciWf5F6PleRU8ZupNIWiepS8gtRiJdl8nYlOJdnKIl2dSnJObYurNQMcJDNSTEwmAtiRv9Y1cp9k9TPueTwtdQKd6RZOqp5KlGSS5tqTVx4kO9mmMeSTiXR/HMUWcHLVNJ0qEseGwj2dFnC2p1tomUwkvo8QV2sGOEhmpAxvlN3u14YbatdIC/c0uFsQ+yQn6EZJduhkbuhukVBHPUr4JNeacQ9uK8npwj3PULpF8WQiyXWGn8mvX7FB+Bg7Jxupkqxo27k5yW5enxwkM1JMKck2DM11TV7hni/EoC3YAk49epVkCx+cbamtJAev2cK9rLtFlZxkVwuDIqQWcEaV5Ox7jZRkmO8sduJkY9N5KVGSdRfuuTrSw0EyI0XnTaUILtyLguQgoPUzQXKLS5aD5ATKhyFjWPngbEtjJXm4rOd58EX2vKYaM+451aYxhBCIn4mmCveqTUudKtzzRYmSrPYY6zLeSjIX7rWBg2RGis6bShHjbQGHwY0nmkI6CiLUKMmRuwUHyUCx1VVbrHxwtkWRkgxkz+sqQbKTbRrDlsK9IoGkON3CXgs4vUqyhZ03toBTBgfJjBRTPsk25K91jdQCrpcMkn0V01Jz4V4CVpJr0ngykeGyvCC5iruFk20aI2sBZ0YwKAqqitMt5NuzQ0nWlz44DA6Vb7o50bUUe552Vbjn2vXJQTIjJeG40CHjWLiXUDlS6RZalGQOkgHonXrdySlaG09LLVOS/fC1vpLsUpPGySrJZs6fousiX0kumpbafJ2JzueZlcFh7FrtunDPqs6CAjhIZqQMrJlMWMC5dpWVkAgm+oGHsachSB7MuNdnn2RA7znuZH5ev18vSI5GfKukW/S80vMy2kzf0fuDL7GAM3EvLJq4KF9Jzg9APQIEzAaRfa0d4uDVqg5xLEjWpiSnrtdBB8qxmQ44SGakmCrco7Es3Ate0+4WQFZx81oFyawkx9E5YY6TxvpNfZJjy6Ig2R8EycPcyepKskNtGiJLTfFgppNVlG6Rp5qmU0VknzHZt9E5g6wN3y+DJEhmC7hmcJDMSDFVuOeNZeFeLJiICvd6eYV7zS9ZtoBLojPdwsoHZ1uUpFukc+0jJblKTnL4EK5+xCODbNpkMlSfUeSGkJd/KwqUZBtyyYftq37b0Sat6rxJ0i305ySHi21qBwVwkMxI0TmNZxHjrCTLLOD6/eDNySh4bvF7EAfJCVhJrklDd4uiwr1JPyj4qmYBFx6GS20aIuuweYbqM2QBe0SuBVyBkmxDfr7Owj2iYJobq85LVpKVwUEyI0XnNJ5F2FDk0TXSwj2JBVzPo1a/BxfuJWEluSYKlOToQZo8r72xT7eQ5Y2aVJLznSqC1/RxiaLJRCwInnQXoltnXZpQkrtytwgXW9UQ7eEgmZFiyt3CBrugrpEpyd7EBIBhzqbvC0y0lPV5Wuok0WmmJU8x2odLDwwFSvJEL+1u4Qfqci0lufohjwqy9DZTgkG6gDBOXufPF/mCig2jKrotTa2bBCuhJAeL9Psku9mJ5SCZkWLKJ9kG4/mukSnJspzkVrPthfSpPBgZF3Se44MhWJciOg05ydEIybgrydLCPUPpFoX5xYN1uHAvjnVKcsyJRvmIWYlPslP3PHCQzORgsnDPsWuslKJpqePBRBtni8G+4hOWjDldPDitUpfa0ngykWILuOpKsvlgSxe5hXsGyhSL8ovz8m/LLOAA00py8KpTSbaq8yZRkrtLt1CzG1vgIJmRYtICzqqbTQfILOAGSrIYWmW18Uge7IuD5AHKhyFTmFICtVFbSQ5e480rD5Kr5iQHry7eH6xSklF8TchUU1aSLesQS3KSuyvcs6gdFMBBMiNFZzVwEd4YF+5RIt0iqySrCJJ98kCCg2RAb+FesF3LHpxtqasko1xJ9hspyQ61aYhNFnBFU0wD2fxbIYJferyVZMvSLbqYTISVZGac0WmPVQSNZbpF8JpUkvUEyYIIgpVkAPrP8WimMWdoWLiXsDWTTEtdPSc5uV2XkCvJZgIvUVCEB2SVZBFbnrc+YIcFnD4l2bLOm3Raai7cawIHyYyUSAXqunDPutyuDpApyTSRnXFPTZDsgThIBsBKcm2UFO6l0y38IHAeeyU521amAq8iCzgge48u89S3wQJOt6WpdYV7Ugs4RdsuK9yzqR0UwEEyI8WUBVxQrDJeyAr35Epy+8vV55zkAcqHIVNYNwTblsYWcGrcLaLNONWmITK1z1TqWZEFHJDt/JXl9ud5K3eJbFRDJWwBZ0dajQ44SGaksAVcdySG/VNBsq863aJCMDIu6HZwce5cbqwkD5e1cbdwdTgXkBdKk4UWcEC28zcKSnI3FnAWnZdGlWSL2kEBHCQzUngyke5IDPvnKMk+u1soR7eDy7inWxRbwMXTiKq5W7j6EAbyJxMxVbhXdNtPp4GMgpLcReGeVc8to0qymt3YAgfJjBRWkrtDpiTLfJJV5SRzkBygW0lmC7jgNaEkU0pJFly4B8g7bDZOJgJICvdKnhVkwQhAF4V7Vj23ZBZwqrZdoiRb1Q4K4CCZkaL7ppKH55r6VgGZktxLz7gn1Ewm4hOBrJI8zKF8GDIFK8nlFnDNJhNxqE1DZJabtirJ6fzbstz+YZqMumOsi35PdMvqD1IWcAT9SnK0ddceLxwkM1J031TysK5KuAMSwUSUbjERKcnq3S3APskA9Fe8W/fgbEtjJbnY3YKVZHl6m6nCPVGhcC/pbjFcLl8/eLXDAk7P9m23gFN6jytQkgmsJDNjgm57rDzG0wIuePU8/e4WXLg3RHfevedZ9uBsi+8D4XlZhUFgEjtto3PYH+Ta1y/cc6pNQ6TpFp6ZPFdfDNNiZKTzb6Nj7+V8xA4lecycbGLXqi/UCCwDcoLk4C3HRs/AQTKTg6nJRKwrgOgAaeHeRCrdQtmMe8Q+ySFdFO450+Eb9Cjqu1uUpVvU9Ul2pUnjyAv3zAgGRVNMA9njKlOSbejcdOFkY1VwmFGSFW67KEi2rbOgAA6SGSmmlGSnAouKyC3gJgDEgom+IncLVpIH6C/cc6jDF50zjWbci6UQpNwtJvvV3S1scEnQhaxDYer8KRuez7OAK0u3MDst9Zh1iFOFe12kWwAWdhYUwEEyI0X38FQe1pmyd4BsMpHelGxO8gTnJCtF9zluXcV7GxoFydnAZKKXzUmeqK0kO9KmMWSihKn8Tl+IEneLvMI9+fpDJVndMdZl7DrEqcI9pZ2DwiCZYFMzqICDZEaK7ptKHuNYuDdUklGYk+ypyEnmdIsBw3Ncz/adGnpsECTLC/eaz7hnQ26rLmTpbabOn7Lh+aySHLzarCR3UbhnVefNQOEe4KbIVXrHI6ILiOhBIlqa8/5+RPQYEd0U/vtM7L2DiOg2IrqDiD6h8sAZvei+qeTh4kVWhnRaak05yYFP8ni1bx663S2cGnpUpCS3s4ALD8WVNo0hVZINnT8uKsldONlYdVs1qSTb1A4KqHLHuxDAQSXr/FYIMS/8dyoAEFEPwDkADgYwG8CbiGh2m4NluoMt4Loj8ZAZ+CSncpJVzbjnsZIcobsj6MGhc1mZkpwMkv0aM+6Np5JsY+FeXQs482kyup1sWEkO37KtHRRQescTQlwD4JEG294NwB1CiLuEEM8A+D6A1zTYDmMAU5OJWFcA0QGJh0ykJE9JBcmKbHw4J3nI2FW8t6GFkhxv3cy01NF53euxkgzZZCLdH4sviu/7vbQFnF/8rBikWyg7wvronkHWVIcml4ySrPCLRzaQOUqya9enqpzkPYnof4noCiLaMVz2PAD3xdZZFi5jRoBEnmyHBOkW3e7TNIlgIlKSJ3RNS81KcoT+wj3LHpxtaKQkZ2f6UmMB50ibxoi+UfxUHE6e0u33LZ9MJHlMZQHoOFjA2ZxuUTYyUJsxs4CbULCNGwFsI4RYTUSHAPhvAC+CfKrw3OYjomMBHAsAs2bNUnBYTBvKbH104VRgURFfYBhMxAr3CBpm3GMLuAFdFO5Z9eBsQ0MLuPT9IwqYms24Zz63VReyDhvFvm/eRB16jqVYHEkr3GWpDDYU7um3gLOs85ZQkhULAWwBVw8hxONCiNXh35cDmEJEMxAox1vHVt0KwPKC7ZwvhFgghFgwc+bMtofFtER5sn9FxrVwbxBMxIKRnkfZ3M22+yIPNGbtmwdbwNWgoZKcvocQETyiVoV7zrRpjLzCvfh7XR5LuU9yEyVZ3THWRbfo4xHBKumBlWRltH7qEtEWFJ55RLRbuM2VAP4E4EVEtB0RTQXwRgCXtd0f0w3Kk/0rMq6Fe4NgIhUk+xrSLVhJDtA9YQ4ryfJ7SLzz18QCzpk2jZFXuBe8ZyJIzn8/3fkrn0zEfJqM7hlkrRsBNVS456KSXJpuQUQXA9gPwAwiWgbgZABTAEAIcR6AfwHwXiKaBLAGwBtFcLZMEtEHAPwSQA/ABUKIm7V8C0Y5ypP9K+I5mPhfRuImlgiSPeXuFvA8EBfuAejiwemQ6tmwcE92ygZBcjyNyBtut8CkdzyU5Gy6Rddft2x4Pt35K7uOhjMlqjrC+gjo7hBb1nnzfWAiCO+UP8tLLeBsaoj2lAbJQog3lbz/VQBfzXnvcgCXNzs0xiS+r3iIpiIu9kTLSCjJ/X7w6nnwUoqbp8jdgvocJANjWPHehth5WfkjOcP2uUpytJ8J+WPJhgIwXQwdIobLTE3D7TdWkvPWD383g1FkmQNHW4jI6PfLkHK34fMnYQAAIABJREFU0JJuEd0T4m+5NHoWwjPuMVIEzKRbuJjTVIZfmJMcU9wU/B7CI7aAC9Ftc2jKwksLDdMtZG2bybUnKlSnIuKFbK4h85QmQ52CMuUxnX9bVUm2Id1C1yPNulGjVLpFl4V7VrWDAjhIZqSYKtwbRyU5cRPLKdxTOeMeW8AF6J4wxylj/YbpFrKmlaYRVQiSbQi2dCGb2Gb4fbs+luJrIjuZSEUl2YLCPV0dYuvSBLtQkrlwjxlnuHCvOxI3MUmQLIQY5m62RHBO8gDdhXvjriQnRkhiRAWpvhCBvVnFINmUstoFNinJebnkEen8WzFYbm8ueTdKsp5tNyKtJEsdeRsyZoV7HCQzUspulLoYTwu4vMK9IEiObvDq3C3Gq33z4MK9GjROt8guH5zXUZ5obSW58iGMDLIOm6nv69dUkkdjMhFWkpVRpCTDPZGLg2RGSp4KpBsXq2PLyLeAC4alo7xkdrdQSzcWcI6cywqVZC/MtZ8Mg+SEu0UFJdnF+0PRZCJmfJLz3w9cJLPpFvlKshmXjji6fZKtGwHN+CSzktwUDpIZKcqT/SviYk5TGcWTifiD/M2egmm3OCd5SDeTiWjZdPcoLNybCJXkqPM30auabhGu4kqbxojOExvSLSoV7iWU5OA1LxAz5dIRR3e6hXX1B8Zm3HNP5OIgmZGifIimIi72RMtI3MQk6Rb9uOLWEuERz7gXIgtMVMJKcnHh3vC8rppuMQ5K8nCZvYV7yWOqWrhng5I8Nk42Bmfcs6odFMBBMiOFleTuSNzECoNkBb8HK8kDZI4CKrFuCLYNjScTybeA82sGyTa4JOjCPiU5//08JXmcLeBYSQ5wqg4jhINkRgoryd2RbwGnPidZeB77JId0YQHnzLncSEmWByWZNKKKOck2BFu6GD0LuPj6VS3g3C3cI9tGjfp9c0qyY71YDpIZKcqT/Svi1CxlFSmzgFOpJAsikGM3saZ0oSRb9eBsgwYluW66hQ3Bli6GDhHmlWQhRGFgkFZNy3L7h2kyyg6xNro7xNaNGqXSLbpUkl2TYDhIZqQoH6KpiHW5XR1QPJmIrzbdgt0tBnQzmYiWTXdPw8I9WdN6qSDZo2pBcrCuQ20aI/pO8XuuqeCyigVcwie55DoaFlzaoCTr2b51o0apdIuu3C1cFLk4SGakKB+iqYiLOU1lVFaSFfwggjwu3AsZDBNr2r5Tld6KJxPJpBFVDJKdUudjyLyGTQWXVSYTkSvJ8vVtKNyTKfUqsV9JVrjtEncL10QuDpIZKSYL91y7yMqQWsARDWYmU+luAY8L9yJ8IUDQ++B05lxWaAHX1N0CcLewV6bGmnLzKPPIT3dUypRkGyzghkq9nu2zkhy+5aDIxUEyI8VY4R7cu8jKyFjAhTchqQtASwQRp1uElBUotcWpB4ZSC7hmOcmAuyNNMjXWlC9008K9ciXZfLqFXiXZovPSkAWciyM9HCQzUoSA2vneK+KqUlRExgIuvAl52mbcG7MGzqHM6qotTj0wlBfu1Xe3ABxr0xiyIM5UcFluAZdUTctSGYbTUqs7xroM6g80bd+651ZqWupuLeDU7coGOEhmpLAFXHeUKcmDAidFFnCcbhHQjZKsbfPdotwCrmm6hUNtGkPmNWyqcK++khy85k9LHa4Hs0qy3tQqwDf4/TIklGTF/tBcuMcwBi3gPPcusjISilsmSFbtbtFjJTlECKGk45GHkzPu9XqVP1JuAVe/cM+pNo0RBZAyn2QTk4kU3WvylOS8j9hhAaf/WrfqtPT9wbWq/LsXBcmeQ3UYIRwkM1JMWcCNb+Fe+J90kCxUT0vNFnARXaRbWPXgbENDJTmvcM9vMOMe4FibxrCpcK8shzWdf1teuGfe31p3Ibp1I6ApJZln3GsOB8mMFHMWcOaLPLqmaroF+ySrpYt0C6senG1omJOcm24hmqdbONOmMWQTcpiahrvsukirpmWTiQzSLQwryTqfZ9Z13jKFe935JLt2fXKQzEgxpyQP9z8uFCrJqmfc83jGvYhulGRH2lph4V5mMpHaSrIjbRpjqMYOlw2DS7sK99L5t7Jjj2OFkowx6xCnLOCU3ufSdqWJtyzrLCiAg2RGCivJ3eEjT0n20O8rdrcgVpIj9CvJDj0wGhfu5btbTA7O6+ruFq6mY8nUWFOuEE2V5LIZ90ze08euQ6xTSQaCbef4JFvVWVAAB8mMFOXzvVfEBuP5rslMJpJTuDfRUzSZyBi1bRHKrZFSWJen2IbGSnJ2+URKSZ5gn+SYBdxwmVklucjdInlel/kk22ABN3Yd4rQFnOrt5wTJrCQzY4PyWXoqYsMUpl2TGA4rsoBT8Htw4d4Q3aMl1j0426BUSeYZ99IUWcB1Py11sWVYngVcvpJsfnRQ+dTMKazrEGcs4DpSkuFeJ5aDZEaK7ptKHjYMzXVNsZKsoXDPxfHqBujOu7fuwdkG1YV7/eYz7jnTpjGKJxPp9ljKlOT0kHpZJ96GOpOyqbbbYl3nLTOZiOLtFyjJrj1eOEhmpJhSkm0YmuuaROV1OidZ8Yx7wuNpqSN0K8lODT02nJa6aMa9oQVcvZxkZ9o0xlBJHi7zDAkGtS3gkE0VSa8fbdcU424B12VOsmsCFwfJjBQu3OuOxA1ct5JMHrwxatsi2AKuBo2UZHnglHa3YCW5WEnuWjAoG2FJd1SEGC6Xrx9t12zhnv7UKovOy5SS3FWQ7OK08RwkM1J0FzXlYcPQXNcUWcD5aT/ZtnBO8gD9hXuWPTjboFxJHo6QsAWcfNY6s0py9cK9obtF3vrm60z0K8mWpRmk3C26TLdw7fLkIJmRIgS0TuOZxzgqyZnJRMLpRKOg+JnJmFVWW9jdYkBZgVJbnLIra6wkywv3BIB1/VjnL5ruekwt4GTFb2YnE8l/v66SbEOdiX4l2bJnlu50i16PLeCY8Ub3TSUPG4bmuqaocA8A1k32E/9vheeBSgKRcaELCzirHpxtUGgBJz2v2QIOwGhYwKVnVStTkm2oM9HiFRzDus5bPN0CrCS3gYNkRoru4ak8bBia65pE9XHs5uZllGQ1FnCckxzAFnA1UDyZCJAaIRn7yUSCVzss4ASKLot0R2Xok2yvBZx+JxuL0oAG0r6Zwj3XBC4Okhkpui1z8rBhCtOu8f3YTazfT7hbAGqDZHgePM5JBhA+OAvDgXY4VWTWD1Tf+jnJ2eXZIDmmJEf7ycGpNo0ROX3I0y26VpLLC/fiHZXo77znxWB00GDvxvd1O9mY/X4JUh1a39cwYuZ50mvVqs6CIjhIZqTonsYzj0HWgWMXWhEiR0keBhMK0y14WuoBY1fx3obGPslFSnL9dAun2jSGbNa6YeFet8dSdl3kKcllhXum0y10KslWjXCkg2Qd97lcJdmh0bMQDpIZKbrtsfLwBkNzne/aGAnVXpaT3I+5ALSFC/cG6M5TtK7ivQ0a0i2i87peTrJDbRpDpsaaUpLLAso8JblsAhLT6Ra6lWRrOm+pa1VL6mRuTrJ7AhcHyYwUITTM916B8VSSURgkq3a34HSLgC5m3LPmwdkWpYV7yTSiOhZwpoMtXcjaypySXCyQZCYTKVGSo8+YvKcHzzO9SrKAJecmK8lK4SCZkWJqxj3CeCrJVdItlKS/sJI8oIvCPWdUz4Y+yWXpFh6FHRX2Sc60lQklWZb2kSbo/A3/P/R4LlafTf5s+pXk8LmlbxfVkSjJ3U0m4p7AxUEyI0WLAXkFxtMCLkdJpqGS3PNIzY0udLcQbAPHSnIdGvoky+4hXuK89pLbrTTjXuVDGBlkQ+ImUs/KivCArAWczOM5jengSb8F3HA/xpEoyWwB1xwOkhkpptwtbLAL6pp8JTkcll7XV1O0ByRmYRp3OrGAgyNtrUNJXtcf5tmPeeGebEjcROpZtdSJpJNDNfWZjKqsugv3bChOHJBRkrublpot4JixwXThnhU3m47InUykFyx7etLHhIp8ZGB44yyx2hoHunpwOnEqN1aSs+070Qu2EZzX9YJkZ5VkZO+3JgSDyqkTGB5XNfXZbPCkO93CbiW5y8I99zqxHCQzUkxbwLl2oRWRCCZycpKVTREe3Tj7nG6hO+/eqgdnWxorydnl8fO6x0oyAPn91kThXrXUiWTnr7KS7LAFnP1KsuJ9FBTuWdEGCuEgmZFiWkl28DmYi4/YTUw6LbWvPt2ClWTtefdWPTjb0tjdosACrlFOslmXBF3I7re2Fu6lO39VlWSjFnDQbwEHWNIhNmwBZ0UbKKT0jkdEFxDRg0S0NOf9o4joL+G/64ho59h79xDRX4noJiK6XuWBM3oxrSS7+CDMI19JHlplqQ6SWUlmJbkWDdMtipVkv4GS7GYHWm4BZ2fhXrrzN8hjLtiu6c5NF5OJAJY8t9gCTilV7ngXAjio4P27AewrhJgL4LMAzk+9/zIhxDwhxIJmh8iYQHc1cB7DB4NjV1oBiZuYLN2ir6Fwj5Vk7YV7g2DCBSlZYeGeJzuvx1xJllvADd/rimZKsgCh3BHDvAVcB/UHNpyaqSnktXQQCpTkvhWNoI7SO54Q4hoAjxS8f50Q4tHwv0sAbKXo2BiDaBmiqYBTQ9QVqTKZiHolmYNkX3ueYrQfbbvoDoUWcPHzuq67Rdqj1xWKLeC6LNwLXuspyeUBqA0WcDpHRq2yLpUU7nXnbuFezYDqnOR3Abgi9n8BYDER3UBExyreF6MRLUM0FbAqt6sjyiYTSeRutoQGSjKnW+SlA6jCqVERpRZwwTbWNUq3cO8hDJRZwHV3HFUnE4mvWyU1z7ySrH8KesCSDpzBwj3TBZo6mFC1ISJ6GYIgea/Y4kVCiOVE9GwAvyKiW0NlWvb5YwEcCwCzZs1SdVhMQ0wpyWwB5wMTwWWZdAGYqmZnPVaSI3whMEWVtZ4Ep0ZFFFrASc/rWukWlQ9hZLBHSY58kotTJ+LrjoaSzBZwSuEZ9+pBRHMB/CeA1wghVkbLhRDLw9cHAVwKYLe8bQghzhdCLBBCLJg5c6aKw2JawEpyd5go3AMrydodXKx6cLZFiwVcfXcL0y4JurBHSY72XcECLla4V3Z7Mu2f250FnAXnpmELONeuz9ZBMhHNAvBjAG8VQvw9tnxDIto4+hvAgQCkDhmMfZi2gLPiZtMReYV7UVv0fcGFexrozgLOgXNZpQWc7Lwe88I9WaG0SSW5SuFetG6VVAbT/rn6JxOxM91CCAGBrpVktbsyTWm6BRFdDGA/ADOIaBmAkwFMAQAhxHkAPgNgcwBfCy+UydDJ4jkALg2XTQD4nhDiFxq+A6MBUxZwUSGPFTebjiibTAQYtktrer1wNxwk+0Jhu0qw6sHZluiBGJ4/lT5Skm6R+LtWTnLlQxgZfDHsPESYCJKjXRVdF1klufw6Mj0CIISA19OZWhW8WtGBi12r0dF0FST3YuesCZFNB6VBshDiTSXvvxvAuyXL7wKwc/YTzChg6iQfx3SLhMtCTpCsSkmmMMjhwj3957hVFe9taagkF6VbJP6ukW7hRHumkLWViZz2atNSB691CvdMF3TpdrKxqkOcUpIBDSp6QeEeEHX6FO/TEDzjHiNFS7J/Bca3cC/8T26QrOhSjZR6TrcIHpwat29VxXtblBbuebG/66dbONGeKWTpbSZy2qsEVek0oiqpeZ7hNBnd6YNWKsmeN3iOdpluAbglcnGQzEjRPdFCHhQbrhkXEh0S3UqyFynJ49O+eXRVuGfFg7Mt0QOxRnuVFe4BsWH6MVeSZUqnCSV5ULhXMH9eWjWtotKa9rfWnT4YtZcVp6ZUSe4mSHaxpoiDZEaKOQu44JWV5BzFrS1R4R7nJOt/cLrU4Yudl1XJK9zzZCMktZRkB9ozhcyizISSXKVwL62aVhFUXFeSreoQS5VkxfsoSbewoRlUwUEyI8WcBZxDgUVFulSSh+4WnJOs/8Hp0AOjQZCcN9MXF+5lsU5JruCTPFSSywUVsqFwT+P2rXpuGVWSg1cr2kERHCQzUnT7SuZhVY+8IzKTiURBck+iuLUkmnGPJxPpYhau4X5GnoZKsqx5J2IuAxMNpqX24UB7ppAX7g3f64oqhXvp87qKoGKHBZz+DrEVI6AJJbl8ZKARFQr3XIGDZEaK7ptKHi4O15SRGGrtSEkGB8nafZJZSWYLuKrI2spEfmelwr1U/m0VlxjTaTL6PdGH+zFOQkkO/mQluTkcJDNSTBXuuZj4X0a+BZz6nGQa+CRzusVYVby3RaGSLHVtqaMku9CeKWSBpgnBoIobQnYykfJ0i6DgUskhNkL3qJFVHWJWkpXCQTIjxZQFXLRHK242HVHNAk6Vkhxuh3OS4YML9ypTM0gumumrjZLsqgVccL9NLrPdAi5at4qgYl5JHqMOMSvJSuEgmZHCFnDdYcYCjoPkrgr3nFBV6gbJ4WtZ4R5bwAUUKcndTiYSvBYrycnjquKEZLpwT7eTjYnZEXMxWLiX9tB2AQ6SmQza5nuvwLgV7mVuYrFgxKOhW6kyJbnHFnARumfhsipPsS0NlGRAPswbb/NmSrID7ZkiT5ToejrnKkFV+rwehcI9/UqyRR1iC9ItXLpEOUhmMhSpQLpx8SIrIuNjmQpGoiBCtbsFz7gn96ZVyTgrydF3lt1DiGjQNly4F5CX3kYd+wsP7/3566Tzb4UAvILJR6LtuawkW9UhtiDdwiWRi4NkJoPva+p9VmCQMuvQRVaEn1Zu+n0gLK4D4kGyKiWZ0y0ifJ+V5Mr0+/WC5JJ7SOa8rui6QgT0neh1JMlTY7tWYPuD360g3cJLDqlXVZJN3tN1F+71Um1ilFiQ3Nf1LO/1pNeqiyIXB8lMhipemboYt5zkzLB0RknO5ie3ItwOK8n6J8wZKG76dtEdDdMt8gKTzAgJUWhdUUVJdqJFE+Sl/nStwFYr3EuuW90CTskhNqJK3nQbbE23MDWZiBWdBUVwkMxk0DZEUwGrrHQ6IDMsnQpGItXGU164x0HyWFW8t6VxuoX8fekISc6DN05gAVf5MEaGvHOx63SLKgJJOo2oqgWc6XQLnY8zq0aNJOkWyjsIpTnJFrSDIjhIZjIUFd3oxqnAogIZ5SYvJ1nVTW5QuMfpFmNV8d6WxoV7JUoy1QuSXVWS8ya7CILLLo8jeK1TuFfVAs5s4Z7e1Cqr6g8khXvKv3qukuyeyMVBMpOhqOhGNy5eZEVklJvcwj1VSnJUuMdBcpVh4jZYNQTbFoWFe0BOGlElJdndwj0blOQqAkkTJdl04Z7uIl1WkgNcFLk4SGYysJLcHRnlRre7RVS4x0qy9glzrHpwtkWhBRzQNt3CgfZMUWwB191xVBFImkwm4nUc7KfpasY9K85NVpKVwkEyk8GkkuxiTlMRGR/LjpTkMheBcUD3hDlWDcG2pbaSXK1wz6sZJLuabpFfuGefkpwWMqqkMpgeAQgK9/Rt3ypXB6OTiYSHYEVDqIGDZCaDSSXZqcCiAuVKsmJ3C85JHqC/4j3ajwMnc20lOXjNO2092QhJFSUZbt4b8gr3uu4UVBFI0mphXqpI8jNmAyf9SvJwP8ZJKMnhn1y41xgOkpkMZSqQTpwKLCpQbgHHOcm66MoCzooHZ1s0Kcl10y3cVpKzy7t282hqAVd2ezKvJOv2RLddSVa8j5J0C5c6shwkMxlssIBz6SIrIhNM6A6SBznJnG4xVg/OtjRWktUGyeNmAde9klzdAi6aHKSSkgzTFnC6Z9cMXq3owBlVkoNXK9pBERwkMxm0zfdeARcvsiIywURekNxTdKkOcpJZSa7ycG+DVUOwbWmsJMvfnwi3NdFjJRkIO2yS5WSlBVyy88cWcHEnGwvOTVaSlcJBMpPBBiXZxQehjEwwoTknmaJgm3OStRfujbeSXNEnuW5OMhEE3Ls/2GIBV0UgSXf+8ooO059xW0m26FqPB8nhIlaSm8NBMpPBrJLsXk+0iMpKMs+4pxzdFnBWDcG2pWG6RV7zNs9JDrdf+UhGg/zJRLrN5W2mJJcHoF0H+2m0K8nhq21KsjELOMW7MwkHyUwGbbYxFXAqsKhAuZKsOic5crcYj/Ytoisl2YoHZ1uapltA3sCD6dapXpDsYvU8kO++0LUvdLXJRJLrVlGSzRfu6Z6C3lIluUKOeSPYAo4ZZ8qKbnQyrkryIJjQPC31wN1izAv3hBAQ0K0kh+eyC5ktii3g2hTuAe7dH2wr3KuiJA99kkfFAk7f9q2qP4hGCWOFe135JA/veRa0gyI4SGYyaBuiqcC4KskeIRZZ6Jxxjwv3gOFwoFZ1KdqXC+eycgu4ZtNSu1qzYI8FXPBaxd0iXrjHFnB2K8ldpVs4NXoWwkEyk4GV5O5IpLbEbm4R+izgxjxI7iDv3qkHhrbCvWbpFq7dH3KVZJhSkvPXSeffjsZkIt1YwFlxrVthAad2dybhIJnJYFJJdrE6tojETUwSJHuq3S3Cwj03cgCa08XU655LD4zaSnLwWl64V8/dwtWRJtuU5LoWcNWUZDO/mba83BhW5cpbYAFnRTsogoNkJoPJwr3o4WlFj7wDBjdwr1hJ9lQFyRPsbgF08+D0XDqXfR8IRyGqkDivJTR2t3CpTWMIIaRt5XlmlOSiGohGFnCeuXQLbWpqDCst4Hq9Sr9nI9gnmRlnurip5GFVblcHJKyyOkm3YJ9kIH6O69uHU+dyQyVZV7qFE20aw5bCvWrTUqeVZLvTLbSpqTGscnVIKMnBn90V7gWvrCQzTtPFTSUPp4qdKpCYBrYwSFZUuMfpFgC6GS2xKk+xLQ1zkvPTLZoW7oWH40KbxshPt+h2proqAolcSS7ersnCvSpTbbfFSiXZgE+yizUDHCQzGUwryQS3LrIiEsFEh0qyGHN3iy4mzLEqT7EtdYPk8JWV5GrkK8ndnj8CdZTkYZBcriSbm0xEm5oaw3YlmWfcaw4HyUwGk0pysF9zRR5dU1a4pzpI9nqsJAPdPDidys9rbAEnf38wmUjTGfccuz/k5fUSEbq8UqtcF1kLuPLriMhcx6ZLJxsrzktp4Z6GIBnI/KjDe54F7aAIDpKZDGUqkG5M2wV1SbmSrNbdItr2uFvAdaMkB6/ChUlatVnA1XO3cMpWL4bIsSijjpXkKqkJadW0SrqFSSW5GycbizrEknQL5fc5T17b4uJIDwfJTAaTFnDBfs0az3dJ10oyDZTkcXe3CF67eHA6cS43toBT7G7hUpvGyFOSvY5zkhOFxDk0V5JNW8Dp24dVaQZdFe7F9xUttintRBEcJDMZurDHKmI8leSu0i2iGffGo33z6KJwz6o8xbYoL9xrmpMcHo4LbRpDCPm0yW4pyUoOsTasJLOS3AYOkpkMXdxUiiAiFwaoK5FQ7Ttwt8DAAm68leQu0i2cUj0VW8BNhNuaYCUZQNBe+UqyrRZwYvBariTbMJmIvn2wkhwutqkdFMFBMpPBdOGeyfy1rklUH3eQk+zxtNQAxrDivS3alOS6Ocnh4bjQpjHyAs2uU8+qWcAlVVORE+DHMVm4NxQiukitsuC8lCrJ3QTJLtYMcJDMZDBpAQeYvaF2TecWcDk3t3GjWyXZgZO5obtF3j3Ea5puATeV5LzCvc4t4CoElGnV1M9JFYnjvgWcnekWVXLMG5GrJLt3fXKQzGQwrSSzBRxbwOlm7B6cbamtJAevZYV7TS3gXFKqgBILOCNKcv46jZRkmOssdtMhDl6teG5JJxPpSkkOF9vQDoqodNcjoguI6EEiWprzPhHR2UR0BxH9hYjmx957OxHdHv57u6oDZ/TRxQxFRXDhns6cZA6SgW7OcavyFNvSWEmWv990xj2r/GgVIoSArKm6LtzTqyQrOcTajF2HWOKTzIV7zal617sQwEEF7x8M4EXhv2MBnAsARPQsACcD2B3AbgBOJqLNmh4s0w3ReW+ycM+34m6jn378JtYPi+k6cbcY88I9X/9oiVUV723p9+sFyX5xsJXrblFyXg7a1IlGHVJYuNfhd432VUVJHhbuVbOAM+eT3J2SbIW4E1eSS67Dxnjy54hV7aCIiSorCSGuIaJtC1Z5DYBvi+CqWUJE04nouQD2A/ArIcQjAEBEv0IQbF/c5qAZvUQ3v2n33gUs/nHn+9//D7fgBfduAiz/Q7sN7bILsOuuag5KEwmVQ6IkS3M3W0BcuAcgVTAZ8dhjwKWXApOTSvYxZV0fB91wM7ZZ8xfgiYXAAQco2a4RGqZb5CvJbQv3Kh/KSJCnxppKtyhWkpOdv6oWcKbTLRoFilddBdx1V+lqvb6Pg25Yiu2e/F/glmeXb3diAjj8cGD69PrHVMZQ5dJXX1SqJLtzgVYKkivwPAD3xf6/LFyWtzwDER2LQIXGrFmzFB0W04ToprLF504GFl/e+f6PU7WhHXYA/vY3VVvTQmI4LLrhRCkRALaYvgE23WAqpk3tST5dn4GSPOZBsnTCnO98Bzj+eGX7WA/AhwHgJwC+1APWrAGmTFG2/U5pPC21/OEcndfrTYlts9cDnnmmcLtOFUPGELmTiZhKt8hfZzgjcT0LONPpFrUDxX4feOUrK3WapyB2rVdl1SrghBPqHVMVYtdqNNun8hGznLQ9p0bPQlQFybKfQBQszy4U4nwA5wPAggULHGri0WNwU1m7Bpg/H/hJnSu/Pcf/5+8wd5vNccwrXtJ8Ix/+MPCnP6k7KE0kggmJkrzXDlvgpdtvoX7Gvf54B8nS3Munngpe//53YP31W+9j7bo+3nXO1fjXh/6A2d8+F1i3bmyC5LLAZO+XbIFFO2zRYjKRyocyEvg5KQvUsStElVz9dCCUlyqS/EzwWiWgVk3jGWQnJ4N/H/848IEPFK7a93287exf41/2fD6O2H274u0+8wzwghcEnWYdxIPkzpXk4FU4NNOBqiB5GYCtY//fCsDycPl+qeVXK9ono4nBTWVyEthwQ2CrrTrd/6ObzcRbFD5UAAAgAElEQVTjm89ot99NN1U2bK6TMp9kIkJP4f2NWEkGkGNzGJ0v22wDTJ3aeh/eZB8PbzoDTz89Pbn9UaSpT3LO+9LzutZkIu48hIuKqzx0WwRVpchNPplI8XbjKRoq72dVaDyDbHS9br556bOIhMDDm87AkzO3KH9uRXm8uu4HsWu1cQehDLaAq81lAN4WulzsAeAxIcT9AH4J4EAi2iws2DswXMZYzOBG2Z8Mcqc6xlNhoD8xMRJBiR8PJiRBsmrYAi5AOqwcnS+KzvlBYBC1+Qicj7koTreQUsfdovpWracoD7hrJbmKG8KwOCv6TLXJROLb75Jh+9b8YI37QbTpSt8vuo46CJJNKcljV7hHRBcjUIRnENEyBI4VUwBACHEegMsBHALgDgBPAXhH+N4jRPRZANG496lRER9jL4MAot83EiQrqYQekSC5rHBPNcRBMoACJZlIWfsPgglv/ILkssI9KWM6415RHnCQk9zdsdQp3KtrARet2zVVbO2k1AmSKZjmptL3I9L7fGIlWSlV3S3eVPK+APD+nPcuAHBB/UNjTDG40CfNKMlKJhMZkSA5YU/UiZLM6RZAgZKs8HyPHsr9MQySdSnJLqZbFOUBm1CSy50qgtfouPKKDuOY9M9trKbWHFmqNYV4R0Fy41STMsZISeYZ95gMA3XTUJCsxHh+YiIolLKczpVknpYawHC4PvHwWLdObZAcvg7SLUbgfMzFOiW5xnYtpygPuOvZR/2KThXA8Ljzig7jmJyRrrGaGl2vFe8JtSbB0vl8SijJwaKuZtxzsRPLQTKTYXBTMZSTrGSWKVaSc+lTeTDiOtIHpwYlmcBKcmXGVEkuLNzrON2iUn7xYN1mhXtd07pwzwEluat0C6tmHlQEB8lMBmeU5BEISsqmpdayz/i+xhTpg1PD+U5EY1m41ygwqVG459JDuLRwr8MyxSr5xYPO3yAnuZ4FXNd0UbgH1PS07iwnOTq2ji3gHOrEcpDMZBjmJPeN+LoqUZKnTAkuYMuDwTILOC375CBZHphMTio/3z0C+r2J4fZHldpKcvBa69lcSUkOXl16CFulJKOa+h9XTZ1XkiveE2rlj0+Z4qSS7OJkIhwkMxmG7hYmLeAUpFsAmbnlbSMx7N9RkOyTBxLjHSR3UbgXbJ/G090CupVkd57CNlnAVZliGhjm3woR/NKsJNe0Lu3Y3YKV5OZwkMxkGNxUDLpbKEm3AKwPTEwpyYKVZAD60y08Gm8LOH1Kco3tWk6xkqzAM77WsdRTkkXs/2XrA2Yt4PTnJNcs3OvQJ7nrwj2XOrEcJDMZBlNKGlOSFRXuAdYHJiaUZEEeaMyD5C6VZC7cq8jYKsn5baXEM74GVSzggOE9usrkI4BZC7hG5yLgVOFeLZeZKpQU7jl0eXKQzGQZFu6ZmkyE0DqEG5Eg2UThns85yfJhSC1K8ngGyY28aWtYwLn0EC5S+5SkntWgigUcMEwDqWoxlvZW7pJGoxpAo8I925Tk7i3ggldOt2CcxvxkIuOkJAevnaZbVAhGXEcamGhRkoH+GLpbNPKmHVMLOL9A7SMLLeCAYRrIKCjJ3VrA2RUkm1KSXSrc6z4CYqxnEEAYLNwbn5xkE+kWrCRLAxNd6RbkDbc/qlhnAefOU7hsMpGuC/eq/GRRGsgoKMldFu5Vfm7pDJL7feNKsu9QlMxBMpPBtJKs1N3C8sAkupf0vC7TLVhJlqYDaDjfex7BJ0eU5EgRr7J61L51JKwKQXLPcy/nMbrf9iRt1fO6L9yr0rGhjJJcEiR75kYAon32Oijcs0ZJDq/VrqeldnGkh9MtmAzCcJCspFhlRIJkI5OJeB7IoZ5+ExLtHqEp3WJyLHOS9aRbRJtzS0nOb6uuC/cCC7gq6RahkuxXTLeAycK98Bg0B8m2WsApT7UAxirdgoNkJoMvAAhhdMa91jfTkQuS0W26xZj7JHeVbuGNqU9yo5m+aqRbOBQjD9MtkG2rrgv3qkwMAgzzb0ch3aLxhBqOWMApT7UAcoNkQJE7lUVwkMxkEELAi4IoLtzTipHCPU636LRwj5XkitTwSXZJSS4u3FNQn1HrWKoX7vkjUrjXeEINZ5TkboPkrvPodcNBMpPBF0DPNxckc+Gefgu4cfdJ7rJwz/dGvHBvkMBd392CleRyigv3ulXlqivJCJXkah7EJieZaDyhhjNKsoZ9FCrJ3ebR64aDZCaDEAKeH07nbMgnmZVkfbAFXHdKskc0+kpyg/OyUWAy9kqyPN2iSyW56vD80AIu+H/5jHvR9k24WzS0QXPEAq7rdIv/397ZB02TleX9umfe5wVBkUUWCvaDXXChhCgfvgValGIqfCyWtUsgiYsmwcRkY+KaGP8RYgqRlAlqjMYqkoDlVoglLEpC8mpBEEVMpRTYBRFkV5ZlRVkX+XAFsuzHO8/0nT+6e6Z7eqbnnDN9Puac61f1VD/PPD3dPT2nu++++r6vO3QevW8YJJMBlSrOLO1OEFNiZcq+i3a7F4vDN8gjUQr3ZMac5G2ByWLhJd1ilZOc+FjciVOQ7BCYWCnJ+VyERwv3EPazmj6eX1vAmX3PayX54E20xllJbo9XXxZwvs4HEQv3gOZmwcMqY8EgmQxQBebRleQDF3J0SjKCFu6Vnm6xtQsXO+5tx2FcOjkKWDUTMV9s6owVOYZ+dG36eP6YlGTnhhrHbAEXuXCPSjLJGlWNnJNMCziv65RZXh49DmzNpfRVuHfszUSSUpKbTcroInyMFnDHpCSb5k0PONZmIikoyfkcngySyZCqqySfnARf/yQHWbvdiQcmvYtMsJxkKslbg7jT08nH+wyC5fw4bth2QiXZK/uV5BQL9+rt2uo3vmP+dvmh0ZH9O0p7vBqeE6yU5JOTrJXknNKhGCSTAbWSHDvdohQluZ4yJzkstICz4AAl2eryXLySvM3dInULuPXfY6zSLQ7dQAeqEaV+FCcLuLTSLWgBdzgMksmAnpIcLd3iwIUcTZDcCSaYkxyMrYV7nizglgWmW1SqEEyvJGdZuNdMt+2q9klHqM9r6oYwtIAbn78MC7j00i1MnwxYQws4UjJUksNRKdbBBC3gghGycK9MJdkhKLFIt8gppX7MAi50m99aSd4/n7OSnLEFnFWaQTAl2SHNxARawJGSqaq4QfJMgOWhV4WjCZI7ys2y2ecB0i2oJIdSkoHlsTcTcRiXVeVQMDSbrde1gxzTLapqvHAPCPd5K89K8sHndQdCFe5ZpRkETLfwqiRvOV6pJJPsqVRxJmpb6pKU5E4wETLdovCc5K0Xd18WcFKekmwabPWYzdDzFds2S4bpFvuaiQCh0y32z9fm39oX7h28idYcXLhn1XHPcNlsJnI0MEgmA1QRNUie5E70SILk3mPpQEGyyWPt3Nl64fSkJCsAzOfJj8WduKRbwOHxdrv8kYN/raxaLjthxnJm46RbmCjJdbrFmDNHl9C51V0OLtwzHPdpFu7FSLcI68jiGwbJZEClijMRfZJFgOrQOuijCZJjKMkzSE5RhgMhlWRV9XtR9E1IJbm7vm2zZKgkj3lKxync2z9fm3875vHcJXSw30VHlPpR2vOB4fvSVZI9rGNP4V5OlxcGyWSAAjijMXOSy1GSe8FEQJ9kWsCFc7eoFMUFyeqiYBkEyTGDLV+MeUqvP2+4nGRjJRnHoiTXUycl2eJ8kKKS7HQcmrAn3SKnm1gGyWRApYqTqDnJJXXc65zE2hPOfO53nSzc2x6YeFGSUaSS7KRgteN+VEleLz8XzJTkUNtiVuA2zEken/+olWRDZi6Fez6+2BCFeyPHKgv3SPaoAvOISvIkHfeOJEjuncQCWsCVXrg3uLir1pXaVJKHJJRuEVpZDUFKSnIv/WuE1steV3+nbAHX3wZjLIPkWkE1nLldrg+xYlNJtmvpYwYL90jJaGR3i1lhSnLwdAur5Lk8GTwmXvq5KZRileQDCveMlGTLZSfMmBob+vNWhkpyW5x1HM1EElWS23VMTUgLuG1KMqgkk8ypC/diK8llBMkxLOBAJXkYmFjaPZmyunAWFiT7VpJzSrcwaSaSWuFeqxaaBqBxLeAO8Em2UpItgsNAQTIt4A6HQTIZoIqoQfKkhXuLxcHb45PeSSyou0XZQfIgMGnHiRcluVlu4mNxJ0kV7jWz5HMNNrSAS6twrz1Hj6WK9OdfLz80zukWi4WlkmzZca9dx9TQAm5SGCSTAfGbiZSTbtE7iQV0t5CMTmIuDAITKsm7cVaSLddTqAXcWNvkVAv32jQi28K9mEqy73SLVf2BCUGV5OlXQQs4UjRZKcmJBya9k1iodAsqyUNHAU9B8uoRbGFBshoqkj0KtYBLT0neP99MBMtKaQHXwUlJ9p6TTAu4Q2GQTAZUqpi3QfLJSfD1T6Ikz2b1T+KByVYLuADuFqX7JA8eE7fjZOLxvrpwnpwkPxZ34qQkOwQlVoV7+VyEj9ECrr35s7eAO7LCPYvzgdgU7rXLpZKcPAySyQBVxTx6W+oJjrIjUO+iWMCJFN9xL6SSXKIFnH8lOZ/xu3aIiK8kq6pRUNDe/I0VHfbnj5duYZo3PSCTwj0qyYfBIJkMqBSR21JPdCd6BIFJDCWZ7hYjSjKbiQxxLNzzoSQD7T61XHbCtJ9lWzATOri0sYCrdDxVpD9/u/yYSrLlGx3SLdKzgHO4OTBhj5LMIJlkjXbTLSIV7lFJ9ofKjIV7rXrXvuBVSS4vSPZlAQdYPtY+Asa8hkMHlzbNRPpK8vj8MQv3xpT6UbJRkqdfxT53i5weVDJIJgNUgTMRO+5NltN0BIHJVgs4L0lkHWYs3KtUIfCvJJdbuOfHAg6YqLA3IcbU2NBuHqY3N+2NiqmSHNMCbq3UW76RSvJuRpXkAtMtRORqEfm4iNwhIq/c8v+fE5EPNz+3i8gXO/9bdv53fsqNJ36oYivJKElJ3ki38J1qgSYnufB0i0GBksd0i3KVZMv1GCvJeV2Ex9TY0L7QtoV7VWWrJMdLtwijJKcVJMco3MtNSd47AkRkDuD1AF4A4C4AN4vIeVW9tZ1HVf9lZ/4fAvDMziLuV9VnTLfJxDeqwDxiTvJsNpFSdASBSe9xWKggeT4vPt2iUsV8FiJI7ijJ99036bKD0Z4L5nPjt/gq3AM63tOZMOa+EENJnhtIru3Nn2nh3jyidZ+pTd0Ah7bUyaRbNMeq6fdpzZiSPCsvJ/nZAO5Q1TtV9QKAmwBcOzL/ywG8ZYqNI3GIrSRPdhE8giC59zgsUJDMdIsthWXMSd6NowUc0y3MGAviQhfumRZcri3g1n+Pz98sH3GUZKc40VpJBirTz+czSF4uO0pynHSLnG5iTc56lwD4dOfvu5rXBojIEwBcCeA9nZcfKiK3iMj7ROQlzltKglEX7sXtuFdKukVPcQsVJLNwr58LDjDdYgxHCzif6RY5XYTbwDGFwj3zttRocpKPo3DPKVA8ZiV5lZPMdItDMRkB23bxrl1wHYC3qbZVXwCAy1X1bhF5IoD3iMhHVfWTg5WIXA/gegC4/PLLDTaL+KK2gGu+whBB2wblFe41f4RKt6AF3LCzGAv3dpOYkmzlInAEpFS4Z3pz0+bfmjpHtJ8jVuGek1ewi5KcXE4yO+4dislZ7y4Al3X+vhTA3TvmvQ4bqRaqenczvRPAe9HPV+7O90ZVPaeq5y6++GKDzSK+WFnAnTnj32lhC5MVeRxBYBKjcI8+ySzcsyIxJTm3x7ljeb2h23CbPp5vVdMxj+cuq3SLaEqywxszsYCL4ZOc0/Fpcta7GcBVInKliJxFHQgPXCpE5CkALgLw+53XLhKRhzS/PxrAcwHcuvlekhaVYh0kR2BtF3Tggo4gMImjJLPjXlglucwg2a+SnM/4XSvJw/+tg8uQ6Rb752vzb8c8nrtEVZLhmJebiQWcF5/kTdvS3r/yetKzdwSo6qmI3ADgXQDmAG5U1Y+JyGsB3KKqbcD8cgA3af9o/gYAbxCRCnVA/rquKwZJk7otdbwgua8kH3CEH0FgUiGCkixUksMpyeWmW/hqJjJZOlYijCnJsyNRko0L9yJET6aB/4BsLOA8PQ2ezYoo3DMaAar6DgDv2Hjt1Rt/v2bL+34PwDcesH0kAqqK+TIFJXmCdIvF4vAN8sigmUiwdIt8TmIuDAqU2nEyuZLcSbdIfCzuxFlJtlxPoT7JOqLGxlGSTXySNy3gxucPHex3cXZ4WCz8F+75OCdsFO55u6LsCJJzU5LZcY8MiJ1uMVkl9BGod73HYSzcC8YgZ5ZK8m4SVJJzugibWMCFa0ttawFnVrgXu5lIMAu45JRkTxZwwG4lGXndxDJIJgN6hXsRmEw9OYLAJJqSnNPzagcG7gvecpJZuGdMqRZwI4FmaOs0Wws400Ydk9WZOFC6BZyXnGRgVEnO6fLCIJkMqJXkCjg5ibL+yR7NnZwkH5j0Kq9DFu5RSd6uJE885lePHo9gLO7EsS01m4mYsQ40h/+bTSUYGGJrATfm8bw5f7v80BxkAWdxPrC6eWuXm6OSnFk6FINkMkBVMUsi3aIEJTlO4d4so5OYC7SAs8BJSXZwj6SSPPhfaAs4U39rWwu4yepMHAhlATdLsHDPWUU3YVRJzuf4ZJBMBqzaUkcv3DtwQUcQmMSwgKNP8halkxZwu0lMSc7NAm6s+C2OkmxfuGeuJB+8idYcpCRbulsYX7MCulvESLfI6PBkkEyGVIqo7hZr9SR/JXlZdYKJ5TJYkDzbE4jkzkBd8li4Vx174d7Svvumk4LVLn+5HJ8ts5zH9lAcU5KXAd0tTL4212YiVYQvrqpCNROx+HwBfZK9KslbjtXcLOAYJJMBsQv3JlNPjiAw6T32pwVcMAbqksfCvRKVZHVpYlB8usXwf6E71ZmmW9gqyTGbiYQt3EstSKaSfCgMksmAKpGc5BKU5N7jMFrABSOkkryygFPdGwAmiWO6hV8LuHyuwibNRIKmWxjM134HOrLtXY4u3ULVXkmGRYqgryB5Je2zmchUMEgmAzSyT/JsqhPqEQTJVSQlmYV7wAxhlORV4V53PcdEkkqy5bITpj0Uxwv3wvkkmynJdcpLNbLtXULnVndxKtxrx+CxKckbx6pzPrYJo0pyPgcog2QyoFLFLGpO8no7DuIIguQYSjLbUodWkksMkqkkm7JWY4f/WweXYbbFNKBs04jGUkX688fsuOdQROpwPrC6eQsUJDs7e5iwU0lmugXJHCrJ4eg9lmZOcjAGQZxHd4tV4V53PcdEYh33cmtWMKbGhleSTZuJ9JVk0wYkcZRkBztCh/MBleSa3GoGGCSTAfF9kutpGUpyrHSL0pXkCIV73fUcE45Ksq90i9yaFYztq/BKstnNjcBOSa7nieOfq6r91CoTnJRkgcJwbLZjnUpy8jBIJgOiW8ChLCW5l24xn/tfKZXk7R33RCa/SZkVqyQ7pFu0Y79An+Rd+yqkkjyW9rHJbFYHQmNFh4P3RAqeginJzY4z+ogifq5PW5Rkb4V78zmVZFImsZXkybozHUGQHE9JVugxOi1MxFYl2cN4L1dJZuGeKWOPxCdLPTPAtAgPaG/+dLTocJNYwZNTfrxTusV6fUYECJJpAXc4DJLJgFQs4ErwSR4oyYGCZCCvR9a2bFWSPYz3WfsItlVJEx+PW6EFnFfGHolPlnpmgF3qRD/dwiQQa9MRQhOucM+yODGIkkwLuENhkEwGqAJzT0GDCTPbk80uzpwBFovDN8gjvZNY6CB5T2eznBlcOBcLT0pyc8PXLjvx8bgVZyXZV+FeZkoydiuxkwkGBtimTthYwNXvidVMxCHdoj1OfSvJU58PBkoyLeAOhUEyGRBfSa6nJSjJvWAicJBcLctOtxi4W3hRkptfilSSLddTsJKcQuGeXepEI2RUlkpy1hZwqSrJ065ixUjhXk43sQySyQBVRPVJntQCrqqS7nJWoXMSo5IcjIGjgLec5ObCWVxOskNgYmUBl89VeKy4KtnCvWaeZdWmaCRsAYcwhXvW4k6gwr0YFnA53cQySCYDVkryyUmU9U+Wh9duf8LBIJXkOGxVkj2M95USeOZkvZ5jwzHdwp+SHKe9sS/GLeDSLNxr5zltviuTrzqqBZyrkmxxTpjZ3tCcnNAC7ghgkEwGqMbtuLe+MEyQbgEkHZj0TmJUkoMRqnBvlVNaZLoFlWQTxi3g1vP4xkVJriqFwNwRI54FXLh0C+PPGCjdgs1EDoNBMhmgiiTcLSYp3AOSDkxiWcABQFVwkFxtXjw8WsABgM7TH4s7SdACLqNrsKEFXIjCvXpqoyQvK/OboZgWcNZj8QALOOPPGMQCzqNP8qiSnM8ByiCZDKgiK8mTFu4BSQcmMSzgZKUkl5tuMUgH8GgBBwAVleT9FFy4t98Czv922Nm51dPTqjIOQOMpyWF8klNVkkOnW+TWNp5BMhlQF+5lYgEHJB2YRLGAm1NJDqckN+s4grG4k+Qs4PK6CKejJNsU4R2Tkhyo416ChXtxLOBYuEcyJ7YF3Kq9ZwFKcpTCvVbVLFxJns38B8nz9qvNQUm2aJnu1OnLMEieZ3YRHtywdZhMMDCg3aUzgy+um25hMj8Q7wmAqmJuOxgPsoBLIEhujtUYOcnzzG5iGSSTAbEt4CYrVjmCIDlqx72CleRBJyrvhXvpj8WdOFrAsXDPjLFH4pOlnhlg10ykni4r85uhWP65oQr3rJ1IPCvJqgqFQ22AKWwmQkqlUoUk4W5x4IKOIEiOWrhXlRskV5uFZXS32I1TTrLfdIuMrsGj+ypkusW6mcj+ebvNRGzSLWIpySF9kpNQkmezVQvwGG2pFfk87WGQTAZoVWEeMSe5vMK9sEGytI/iik63CKMkryreCwuSnQITC5/kcpTkcOkWvpXkWDc3Y+ksO8lESQYc8rFNGVGSASCXI5RBMhnSDnwW7nmnd4EMpiQ3J7GC0y0q1f7Jz3fHvVn6Y3EnCRbuZRQjj3bcsy4GO2g7zIOqdU5yZaxUzqI1Ewnlk1xPoyrJ7Tl9NltdP2MU7gHrluXHDoNkMkCW9ieISddfVDOR8IV7MmuV5DxOYi4MLpxUknfTXggtLrZOnb4KVZLHlM6QSvIq3cKgf17X3cI0CIvlb+1UROoSJCNVJTm8TzKQzzHKIJkMmC1jK8n1lEqyJ9rCvaJzkpU5yaY4jEunqnorJTmPCzAwblEWUklep1vsn7fd3toCzmz5uSvJqTUTWSvJ065ixb50i0wOUQbJZACV5HDEUJLX7hYl5ySHUpIzcbewHJdOjgJWzUTsFp0yySnJlj7JdkpypI57tm86qJlIGkFyPCW5nuZyI8sgmQyYnS7qX6IryRMFyYvFYcvxSIxmIm3HvdKbifQuHouF17bUy1ZJTngs7sRRSfaVbiECVNmUBR2nBZy7kuy6de443bAt7K+B1rU0Z85Mfz7oKcnmTwac2KMkZ5KSzCCZDJE2eIquJB+4oCNQknuPWgMrySg4SNZA6RYrJfnYC/cclGRf6Rb5Kcn7LeBCpClYFe7BvnAvVprM4Fg34YDCvXSU5Ha7qCQfAoNkMmAWOUie7MJwBEFyTAu4ak8wkjOh0i1WX23TCjzlsbiTFJXkTC7AwHjjlZD5nTZuCH0LOFN3izjq4uCpkQkZWMBRSZ4GBslkwEpJPjmJs/5mevCFod3+hAOTmBZwJbelrrBFSfYw3lcXjCO4YduJ5bhcd/qiBZwJg8Y2HVK3gKss0i3iKckHFO5ZnBOsLeBOTqgkHwEMksmAGQv3ghHXAq7cIDl04V5VUOGec6evQi3gTJTkMM1E6qmZknw8hXuhLOCsuyNmWri3HrN5HKMMkkkPVcW8ip1uUU+XmQfJ1eZJbLkMoyQ3j/6rRPdLCKrNi7vndAudHbEFnOW4bJsIWAcmhrnyIpJNowJgv6d0qJuCwfloBNfCvRjW7KHSLaxvaDwHyUvX49CU2WzrsUoLOJI1lQKzyEFyKYV7upkzFtjdovSOe73rpmcleVmQkmwTbPVg4d5WJJC/sE26RU9JNmg+0i43VrpFyMK9VHySY6dbUEkmWVIryak0E8ldSa6noS3g0NqRZXISc2HQNtm7klxO4Z6uHttbrqfowr3d/w91U2CTbrFWkqvkm4mEL9xLI0iOXbiXyyHKIJn0qBJItyglJzmWktyukEpy5wXfFnAi9c1JomNxFIfCPcBBwereLI4wy6zj3lgzESCcAuukJFsEoLEKLgc3xCa0x6nFuF8ryYZvyDQnuUglWUSuFpGPi8gdIvLKLf//PhH5vIh8uPn5R53/vUJEPtH8vGLKjSfTo4roQbK1lc4uEg+SYynJ68K9coPk4BZwqn4uiiGwTreop07X5h0X3i4SyUrMF/vcF0KlW9g1E7Ev3JtFLNyzHovt+cDijakpyWrxZMCJvUpyHgfp3quCiMwBvB7ACwDcBeBmETmvqrduzPpWVb1h472PAvDjAM6hLnr+YPPev5pk68nkpFC4Z53btYvEg+SBchMs3aLJSS7YJ3lQ8e5bSS4oSFaLYGuAQZCcm5K8r9lFHVyG2I566qtwT0RWxWQh0T1K/VYczgepFe5VFk8GnNipJJeXbvFsAHeo6p2qegHATQCuNVz+iwC8W1XvaQLjdwO42m1TSQgqKsnBGCg3wQv3yg2SB7Zb3pTkzoWzkCB58ITEBiMlOb/CvRSU5EH61wgra8MjsIDrdTU1xeF8YO0P3J4PptwnSSjJzaZkcpCanPkuAfDpzt93Na9t8jIR+YiIvE1ELrN8L0mEFAr3ylGS62nwdIumcK9sJblz8VCtrYx8Fu4VqSQ7rMs43SKPCzBgUrgXtuOeTwu4oyrcc1aSLYJkYO94t4JK8uSYnPm27eLNj//rAK5Q1W8C8FsA3mTx3npGketF5BYRueXzn/+8wWYRH6SgJJdSuDeoPg6sJO/zo82ZXss1tUoAACAASURBVGDisQ37rEgl+YCCoQLTLfYX7qWrJC+rykJJjlm4Z/mmg5Rkwzf4uD4lULhXopJ8F4DLOn9fCuDu7gyq+peq+mDz5y8C+GbT93aW8UZVPaeq5y6++GKTbSceSCEnuRdYHELiQXIsJZk5yRsV7w52T6aUqSTXU29KMsoq3At1U2CnJK8L90yDsFidEpNXkj0FyTaWfk4UUrhncua7GcBVInKliJwFcB2A890ZRORxnT+vAXBb8/u7ALxQRC4SkYsAvLB5jSRKpZpAM5F6mruSvNUCrvUw9ghzkjcq3j0GybPuhbOQIPkgJXk+L1RJ3v3/UG4eVhZw7cOoyrzlczwlOUzh3qy11kxOSZ5u8T12HKuTiVyJsHcUqOqpiNyAOridA7hRVT8mIq8FcIuqngfwz0XkGgCnAO4B8H3Ne+8RkX+DOtAGgNeq6j0ePgeZCFXgjMfHzyZMriQvFgcuyA+DYCJ4TnLZ6RarC2c7PjwW7mmbbpHoWBzFWUn2VbiXzwUYSElJNnclmbkoyYhlAecQKC4WYQr32nVNRRJKcj3N5UbWaBSo6jsAvGPjtVd3fn8VgFfteO+NAG48YBtJQNJoJlJP81eS62lod4uODOR/XYnScxTwqiS36ytRSXZYV4E5yao6+khXkrSA6wbJZsuvc6tdt86d8BZwaaRbeFeS9xTu5XIjy457pEdazUQOPMpms/oMkWhgMggmginJZu1/c6ZXuOc1J3lDSU50LI6SmE+yiECRj1KVigWcTRvj7jzpNxMJZQGXWLrFxnZNTiFKMoNk0qOnJJ+cRNkGa1P2MU5Okg1MYinJ7Li3YQHXjg8P4733CDbhsTiKY7qFPyW5WY/D4lNkfzORMLm8Lkpy/bvZ8kMF+5s4K8mW54OV1mH6Gdvleyvci2wB52m1oWGQTHqk4W6x3paDSVi9i60kay7PwxwIrSQXmW6x1QF0D4ZKMpCPUrXPfSGUL7SdBVz39/Qt4EK6WySjJB/yRMcEWsCREqnTLWI3E5lQSU44MFkpNwitJLdBcplKsqpCEcYCrvcINuGxOEpqFnCri7DD8hMktcI9eyX5GCzgLN90gE9yKjnJB3W+NGFvM5E8DlAGyaRHChZwayudMpTkebelVogguf1eCy3cG+TqsXBvHEtrwlVuq0uUbBAkz6c8PyRApbr6TNuYBSp4s3El6c5j+j3PZvEs4OalKcnzeTQlmYV7JGvSKNyrp/kryZ10i44C4BspvJnIoOqbhXvjOBbu+eq4N+mTpgTQPYVlEqjgzaZwrzuL6b1QvLbUYdItUlWSnZ7omMBmIqRE0rCAK0VJrqciEjZIbgr3SnW3GPiHspnIONY5yfXUp08ykM9FeF9b6tBKsq90i1DBfhebPOseBynJaQTJsdpSTypyJQCDZNIjpcK9SVSHhAOT3uOwGEpyoe4Wg4tHkLbUSHosjuKsJDusy9AnGcinMKhXRLqF8EqySbpF53fD5cco3HPOy83AAs7myYATVJJJiVQJpFtY53aNkXBg0rPKihAkU0luXqC7xTjJKckTnh8SIJXCPZubm2Mp3HO+YXNSkutpKukWNk8GnNirJOdxgDJIJj1qJTlcwLaN9pDOP90ikpJceLpFSCW5Z2eY8FgcJTkludmsTC7C1R6f5FCd6mxubvoWcGbLj6MkOxavZaQkh/ZJzu0mlkEy6dEqydWZMx6PrnFEalM0Fu75YZ1uUWaQPHgMycK9cWyD5GZKJdmM/UpymEfXCt9KcvjCPWc1NSMlmT7Jh8EgmfRoc5J1HifVokWmesSYcGDSU24CBsmzeelKcj0NoyTX61hW5SjJBylYNh33MrkI7yvcExGEOFJtAsqZQ5AsEv7GprjCvbbOJFThHjD4Ulc1A5lU7jFIJj0UTU6yhS+qDybLX0s4MImlJLfrKNUCLqySXE8V5QTJB/mzWlnA5XERTs8CzsTdYv17yhZwMQr3jGPDHAr3uutsyO1JD4Nk0qNtJqKRivZaJstfSzgwiaUky0pJLtXdop6GVJJLSrc4qNOXhbtFLhfh9Czg9s/rriTnbAHXX+decijc666zfZnpFiRn2sK92OkWZSnJodMtmnUs8ziJ2RLDAq4kdwvfhXu55TweowWcu5LssmXuUEmmknwoDJJJj0qBM8tT6Jm46RYigkmOsTNngMViiiVNTi93M2S6xcoCrkwleXDxaMdHCCU50bE4SmIWcPkpyeP7KlSagm8LuMnqTCxwVpIXi3BK8pTnhISU5FxqBhgkkx6rZiLRleSJLgwJq3e96uMIhXul5iSHTLegkmxJsUryeOFeiI9qZwEnW38fI0bhXrX51MiUgyzg0ki3cLa/M2WPkpzL8ckgmfRoLeD05CTqdkx2Qj05STYwiWYBt+PkVgo7C/c8jPnehTPhsTiKo7uFt8I95KUk7yvcC2YBZxFQdmcx/ZqPzgLO8nywDg4N39Au33tO8nSL77FTSc7r+GSQTHpUVZuTHD/dYhILmYTVu2U3mOhY9/hmZQFXaFvqdlyFUZI7F86Ex+Ioy6VdkNxcM50L9/aMy1VhUCYWU0sDC7hlgM/a7k+T1AQnJRnh1UXnvFwnJbm/zr34VpI3z3NT054TNo7X3J70MEgmPVbpFpHdLcoo3KunoQv3wHQLAJ2LewgLuALTLZwKhoq0gFOM7apQaQo2RW6uSnLO6RbW45KFe0cBg2TSo1IkZAGXd5DcO4lFcLeQQoPkQbOLABZwR60kOzcT8V24l8dVWA0K90KmW9gqyTYWcLHSLUIqycYf0bsFXCAlmRZwpCTSUZInsgtKODCJpSQLlWQAkZRk1ePLBbdWkuupPyW52aw8rsGo9lrAhbFOs1OSu+kWZssPFex3cbphUz3ejnvrXKfDXGZM2Ksk53GAMkgmPapE3C0m8wZNOkiOqyQfXbA2EXGUZPVzUQwBlWSv6N5mIqEL9/bP2w2MbSzgQt/YDG6ITWjHn6MFXHSf5LajKg5wmTFhT+FeLjexDJJJD1XUhXuRfZIny19LOEjuBRMxOu4tywySwzYT2fBJ7q7vWHBWkj25W2SnJI8HmhLIFcKumYh94V4M/9zBDbEJjueDZCzg2iA5mpJcT3WaTgfRYZBMeqyU5Og5yeUU7oVvS126klxPQ6Rb9AKDYoLkJjBxWVdhSrJJHvAMYYqgbOzS+kqy2fKtLdImQC0C/xWO5wPrz+c5SHa6QbCBFnCkRLTxSY4dJBelJANRmomUGiQPHiuHtIDrru9YSCzdYqXO2y89OUzygEMpyTaFey5KsnVHuglY71+LNzkryfXU+PO1x1SmSjIL90iWpNJxryQlOVq6RaFB8lYlWcTLvi9TSa6n/gv3jv8ibJIHPMvIAq5eT7jvzcnh4WAl2fDziUx/faKSPDkMkkmPNt2CFnD+iW0BV2qQvFVJ9jTeqSRbUli6hUkecEgl2capYtvvY8Twz3VSUw94smR9Q+MxSHZKNbGBSjIpEVVgVlVJpFvQAs4PpbelbodVT0n2FSS366SSbEZhhXsmecCTCQZ7qK3o7ALezd/HyL1wr16P5Q2NVyV5vU1e2KskZ3CAgkEy2SClwj0qyf5Yyv5gJFe2WsB5VJKlXWchQTKVZHOMCvcCpVvsa2rShYV727GupQmgJIdOt4jxPfuEQTLpkVLhXv5K8hYLuHkY6z3trrMwBhdOj0Ey0CqBKCZIPugx73xu0ZbafvGpYVy4F6BMcV9Tky7tzR+QugVcPQ2lJFt7WgdQkr2lW+yobYlRoOkTBsmkR6WKM8tTSE5K8nKZZBVBLAs4oOwgeRCYLBZeg+SZbCjJi4W3dXnBWkmup07XZiMluZ7mcBFOSkmGnfrfzpudktwen6HSLaY8HySgJLOZCMma2t0ijZzkyYJkIEn1rvfYP3CQXMkMomUGySEL9+r1FKYk4wAl2cICLofCoJQs4CqLwj1gHdhTSV6TUrqFTXMYJ/Y1E8ng+AQYJJMNqjbd4uQk6nZM1sK0/RwJBiaxlWQtXEnupVt4HO+rR7AJj8VRHAv3/CvJDstPDDMleSLP+L3b4qok2xX7xbCAc8pJdjgnWFuXnpx490mOVbiXw00swCCZbKBQzJLISZ4w3QJIMjCJqSSrzCCFBskxlGQW7hlSnJK8f19N5hm/BxsLOKCrJJvNH8MCzmksHuhukYqSbNMcxok9hXsZHJ4AGCSTDVaFeyexg2TBJCFcwoHJ6iQ2C68kVwbBSK60F855oMK92SyDdAuLgtL24jh3uTqbKMmzfC7Cq6dJI/uqHj+h0i3slWTT97TjIaySXE9D+iRHt4BrjlXvhXs7leR6ynQLkiXpWMCVkJNcT2OkW1QFF+4NHkP6DpI3C/cSHIujOCvJDusqrHDPJG801XSLdpvN0y3W6wmFk5p6sJKchruFU7dBG1i4R0qkVpKr6O4WdWAxwYISDkx6j/0jpFuUGiSH9Emu15OBkhzKAq6wdAuT/O1Q6Rb2SnI9te3SF/J7c2qocWDhntV1K4gF3HSL77E33eL4j0+AQTLZgEpyOGIqySVbwA0ewXpXkkvLSa6n/puJ2C8+NdJTks3nty/ca9cTo3DP4k0HKcnp+CTHU5KblzM4PgEGyWQDbYLk2EryZOpJwoHJ1mYioYLk2QySy1nMksHFw7uSXFpbar/pFu1i81CS9++rVJVk68I9xCjca9ZdYMc9W0s/a6gkkxKpKsWZBCzgJlNPEg5M4qZbCFCoT3K1qS4FUZKR9FgcxVFJ9p1ukcM1eJVugX1Kchh3C59K8lphDK8kh/JJtr6h8aoke1SRgZ1BMuBQwJgwRmc+EblaRD4uIneIyCu3/P9HRORWEfmIiPy2iDyh87+liHy4+Tk/5caT6dHlsv4lASWZ6Rb+KDknOXThHpVkCywK93K4CA9u2LYwmWf83m2xu7Fp5z0GC7hw7hapKclxgmRrK7yE2TsKRGQO4PUAXgDgLgA3i8h5Vb21M9sfADinqveJyD8F8NMAvrv53/2q+oyJt5v4ojlgJQELuNMprgwJByYxleRKpFif5K1K8tmz3tZ31IV7a48y47cc1OmrVCV5j09ymkpyOzVVkuNZwIXzSXZQkh94wHo9OxkoydMtesCokhymS2QITM58zwZwh6reqaoXANwE4NruDKr6O6p6X/Pn+wBcOu1mkmC0QXJ0JZmFez7Rgn2Sw1vAHXHhnsO4PKjTV7FK8ni6RQglOZwFXEh3i7It4GKlW9Q3dv5WHRKTM98lAD7d+fuu5rVdfD+Ad3b+fqiI3CIi7xORlzhsIwmIHnCCmJLJcpoSDkyiFu7JjDnJQdMtkPRY3IlTkHxApy8rJfn4r8JGhXsI81nDWcDZbpk7oZXktCzg4hTuAROKXAlgMgq27eatn15E/i6AcwCe13n5clW9W0SeCOA9IvJRVf3klvdeD+B6ALj88ssNNov4QFbpFnEL9ybLaUo4MOn5WEYo3Cs13WLgTUsleTcO45IWcOaYFDmmagF3DEpycRZwy2UyhXvLHA5QmCnJdwG4rPP3pQDu3pxJRJ4P4McAXKOqD7avq+rdzfROAO8F8MxtK1HVN6rqOVU9d/HFFxt/ADIxiaRbUEn2vG6Z5WNkaUnV3e9AECW5pCDZv5LcbFoGF+FjtoA7BiV5cKybQCXZjEIK90zOfDcDuEpErhSRswCuA9BzqRCRZwJ4A+oA+XOd1y8SkYc0vz8awHMBdAv+SGosFvU0cuHe5Epy+7kSopcvFzwnuWQleSOIWyz8KsnYKNxLcCzuhEqyV8yV5BQL92yV5PBpMoPGQSa0x2coJXnK80FCFnDFpFuo6qmI3ADgXQDmAG5U1Y+JyGsB3KKq5wH8DICvBvBrzZfyZ6p6DYBvAPAGEalQB+Sv23DFIKmxqO9qZwkU7lWZu1v0gonWei+okrwMsq7UaMcVlWQDHMblav+6rG82W69zBzkpySZKZ2sB57sQq6psm4lIb7qPGN/b0kCpH3CwkpxG4V4wC7gtx6tk5G5hNApU9R0A3rHx2qs7vz9/x/t+D8A3HrKBJDDtAevREsuEydIt2tzqBAOT1aNWgDnJARmod6enXpvnrIpYEh6LO3FMtxD4U5Lb5eZwETZJt2ifeCgcbzwMqSyVx7UFnNn8cQr3Dki3cDgnWHtan5x4DZJjWsBlcHgCYMc9sskyjZzkMgr3OsFEDAu4XM5ilig2AhN23NuNU7rFAYon0y0GhEpTUMscVlclOU66hcWbDlKSIxfubaRbxGsmksdNLMAgmWyQirtFGYV7HYUjQuFeqUryIE+RHfd24+iT7FwwxMK9AevP63dbKoRSksP7JIdrJpKOTzKV5GlgkEz6JOKTXEYzkY5yEyPdonCf5OBK8ny+Xt+xEENJVh2ViWeBlNUQmDYTAcIoyX4t4MI/AXAq3Du4457FGzJuJpLDTSzAIJlsctok4Ue3gMs/3SKmkmyi2OVKNCVZpA6UExyLO3FRknGgkgyMRlKhlNUQmLWlDpPLW1k+nm+3y/Q9q9zqKEqyxZva49PhXGztROJVSY6ZbpFPMxEGyaRPMkoyUG3vWWNH0kFyTCV5BskhynAghpK8umBMfVH0TQwlubvebbNkpCSbeEqHCi7tleR6avqeUMF+FzVQ6ge05wOHMZyekjzdogfsSbfI5fLCIJn0kCqNILkEJbkXTETwSS61LfXgwuldSe5cMAoIkg8qGDIIkmMEW74w8ZQO5eZh30zkGJTkemqtJDueD1JSkmMX7uVwEwswSCabpKQkZ56T3DuJsXAvGIPAxLuSjKKU5IMULCMleb2eY8dOSfa9LX4L945OSXbA2h+4PR9M9eWycG9yGCSTHpJITnIxFnCx0i1ms2IL93qOAqq1GT6V5O0kmG6Rk09ySkpyjhZw4ZVky3i3Xc9UgsWmkuzTWZuFe6REZJmGkkwLOM/rtk6ey4eeN+3S/02hFKckT1C4Z6QkO64jIayaiQQo3MvNAu4olOR2nVOQipIMKskkV5JJt6AFnFeoJNcXkADjvdeqtoAgOZSSnEO6hYkFXMhmIi4WcOZKcgwLOEefZOcg2VFJ9hAk0wJuGhgkkx6SSJBcQuFe7yTGnORg9AKTAOO9d+EsIEj2X7jXzJLBNdjOAi7Nwj3TQGy2+t5yTrdwKNxr1zkFtICbHAbJpEcq6RYlFO71TmIR3C0kk5OYLb3AhEryOM5KsuP6CrOAW9+w7Z4n1cI9Vwu4GEpy2HQLizd4V5KnWexWaAFHSiSVwr1ylOTmj9DpFgUryT1HgSBKshSmJNspkj0Ks4BLT0k2n58WcEN6TjYmZKsk53ETCzBIJhvI6aL+JRcleTarF7ZYHL6siYlqATebFeuT3HMUWPgf7wMLuATH4k6clGSnPgz99dACbkWqSrK7BVzihXuLRfjCvanOCVSSJ4dBMumRSrqFdW7XGImqd1st4ObzIOtWkWI77sVQkkuygDtISW7HfzEWcPsLy4JawFnMP7dWksOnW5hY7A04OCfZ4g2e0y28KskjxyqVZJIvrSXWyUnUzbDO7Rrj5CTJwCSmklyyu0XvwtmOC4/jvackJzoWd+JYuOdTSQYc/GgTpf0MY8FMqODS3gLOrnBvXXAZQ0m2eNPpqfP5wNq6tF2Pp3SLWO4Wk4pckWGQTHrMknG3mPBONFH1rlLFbBYnSNbZvODCvbDuFlkU7lk84eiNa1uMg2TLx9qJYlO4F0RJtvje2llN3xJHSQ5fuBddSW6O1fr7nGaxWxkLkmdMtyCZIgGaK5gwaU5TooHJ1sI9r0lknXXPyi3c6xUosXBvHFcLONdOX4ZB8mQdOSNjU7jnW5nzX7gXIye5noZLt7D8fCzcSx4GyaRHKjnJk/osJhqYVN1gonNyC4JIsekWvQKlIEoyjl9JTsgCDpj4SVNETJTOdXDpd1vsC/fc0i1Cfm/O6RYHKclpBMkxm4mwcI9kSyoWcNadi8ZINDAZKMkBg2SdzYpNt+g1TaCSPI5j4Z7PjnuAg4tAopi0pQ4VXNo2E3FNtwgZPJVcuGf7ZMAaNhMhJZKKkjxpzmGigUmvsCK0klxwukWvsCyYu0VJSrLfjnvAhD7qkWmDuBQK92wLLp2VZIRVkq0DxQPbUlc2n8+rkhyzcC8P9xmAQTLZIJWc5ElzmhINTHoWPcHTLcpVkntKZ6B0Cy0oSD7In9VYSc7jItwGjCZKcmptqW2V5Bgd9yqXpxoZKcmxfJJzqRkAGCSTDVZBcsiAbQtFFu4FT7coU0lm4Z4FiSrJuVyETQrLQrXhtr25sVWSYxXuWY/FQ5XkZHKS4xbu5XATCzBIJhvMlqdYzubBXBZ2MWlFd6KBSS+YiJFuUWiQHKVwD1SSjbAo3MvhImxSuBeqDbft4/l2m00DsXVutfWmOeOkph67BVwihXsZHJ4AGCSTDeR0iWWgrm9jrL1BJ1hYooFJXCW53I57VJItCN1xz0pJPv7xu1aSd88TtnDPfP52u0y/6ihKMhzycrOygJtmsVvZbITV+1cexyfAIJlsIMtTVLP4QXIRSjIiKslCJRkAm4nswzHdwre7RS4WU8dsAdduV8oWcE4OD7SAM2c2Gync87vqUDBIJj1my1NUSSnJ+QbJvZNYlHSLTM5iloS3gEOBSrLj+iwK93JQqo7ZAq6dNWULOCeHh4wK97xfUXYEyVSSSbbIcolqFtfZApi4EjrRwKT3OIyFe8HopblQSR4nYSU5h2uwjQWc/7bUvi3gwhQgdoliAZeMkuzZAg7YrSQjj5oBgEEy2WC2TCMneVL1JNHAJLqSnMvzMEt6BZOBlOSqKidIpgWcOWsleX/hnu+P624BZ+pu0a7HdsvcKc4CbrkM10wEGFWSc7m8MEgmPWS5SCInuT3xLqcKkheLw5czMVXVCSY6J7cQ6Ewwq5bB1pcSvYr3dlyELNxLcCzuxMES0jbY6tGuZzk+NidtNhSR9uZpLJiZNPVsbFucLeDs5q8CRk9V5TAWF4uDlOSlzedr1zPVOWHgkxxASd5yrObSNh5gkEw2mC2XSeQkl5FuwWYiMYjRTKS8dAvH9VnlJDuuIyFM2iavLeD8+yTbKcl2FnBtsB+2cM9hLB6sJDPdIpe28QCDZLJBHSTHz0meVD05OUkyMOnlANInORhb0y1OTrytr1fEkuhY3EnCFnA5XITbcWGiJPtPt7ALqmwt4EL5PXdxGounp87nA2uf5HY9vgr3IqZbZHB4AmCQTDYQKsnBiKokz2aY5XIWsyRO4R7W60lwLO7ESUk+4DFvoYV7qSjJNl+bezORsB33wjYTYeEekE+zH4BBMtkgNQu4vAv3OicxWsAFQ7cpyd4t4MpJt9BDmhgUW7i3e55Qneps24kfQzOROIV7aQTJVJKngUEy6TGrlkkU7k2qniQamPTsiWgBF4wqgpLcK9xT3RsEJkPSSvLxX4Vtmon4/ryqCptvzV5JDuPS0UUtA3+oHqYkwzKdZMogud2xyTQTOf7jE2CQTDZIJye5hHSLuEpyuekWwAxhleRe4V53vamTtJLsuI6EaIdFGukWtkqynU9ynMI9SzvCdtwdo5K8caxa3yC4wGYipDTSyUmup1SSPVFwW+o4SnJJQTKVZFPSKtyztYDrT/fPfwSFeweeD6xv3jwGydY3CC7sVJKZbkEyZbZcQhMIkstQktmWOgahLeB6xvoFBMkhOu7l0qwgtcI9nxZw9byJW8AdeD6gklyTS80AwCCZbDCvThPJSa6neSvJsdMtSlWSIxfuddebOs4WcI7rM1aS82hWYLKvkrWAa6eWDUhCBk+quk6tMuFgJVmgsBib7XinkpwsDJJJD0kkJ1lQhpIcLd2ieCW5+eP0tL7Ke9z3Awu4dr3HQKKFe7nkPJrsqxBKsknaxyZuSnLY4Cm8klxPjT+iyHTXpy1KcrxmIoUpySJytYh8XETuEJFXbvn/Q0Tkrc3/3y8iV3T+96rm9Y+LyIum23Tig3ky6Rb1lEqyJ5rCPT0Wl4UJGSjJHlVkoEQlmYV7ppg8Ep809WwHJmkfm6xzku3eE1pJtgoUJ1CS2/Ua4ylIpgXcNOw984nIHMDrAbwYwFMBvFxEnrox2/cD+CtV/XoAPwfgp5r3PhXAdQCeBuBqAP+pWR5JlFmVSuHehLZHiQbJsZVkII9H1rYMlGTPQfKs+wi2gCCZFnDmmDwSnzT1bAcmfs2brJVk8/e06QihiFG4BzgU73lRkmkBNwUmZ75nA7hDVe9U1QsAbgJw7cY81wJ4U/P72wD8Dam/nWsB3KSqD6rqnwC4o1keSZS6cC9+usXaeH6ChSUaJPdOYrGC5OUy3DoToXfhDKIkNzd8QBFB8kEFQ6UpydivxE4qGOzAxK95E1sLuHr5oZuJhC/cA1JRkmkBNwUmI+ESAJ/u/H0XgOfsmkdVT0XkSwC+rnn9fRvvvcR5az3yh9f9Y3zVbX8UezOic9kX7saXn/DE2JuxOrH9/G98BA89e1gQ84I//hz++oMP4vanf+sEWzYd/+z+BR758LPALz4C+OAHgSuuCLfy5kR65zd/GzRkcJ4AL3tggYeczIG3XQTcdlsAJbme/us3fwBPf/+f4rsBfOo7X4oLD/kqr+udgkd+4S/wGAD/9n/+Ie595F1G7/nCl+/Hkx//tW4rbMfiT/wE8IY37JztB/78i7j/wilu/5kTt/UkwnMuLPHNVQW89+d3zvOYxRI/+Wf34KtuOoPbz/g5VlWBn7z/Ai75jYcDFz3M6D3Pv+creOpf3Ycz//cXjCPRV//JF3Dmv85w+9kwTytf8uApTuYz4O0Xmb3hvvvq6YHpFq++6RbMDCX2H1sCi195Kz733g84rbNlfrrAkwD8+oc+jd9/8wdw34OnYQr33vMe4Oqrey9f84V78S1fvh+3//KPWy1u8fLvxdNeecOUW3gwJiNh227evEXYNY/Je+sFiFwP4HoAuPzyvuBApAAACLJJREFUyw02a1rkK/fi7L1fDr7e1PjspU+EXrP5oCA8T378I/FNT3gULpxW+MoDi4OW9dGnPAtP+Ppbkvt+HwXgoqoCvlgBT3oS8LKXBVv3I77rRbjzd38bJ/fdG2ydqXAWwNecnAW++EXgcY8DXvpSr+t7+hVfh6deehG+8uApbr/0yfjEU56Bk8UFnF0cNq5DcN9DH4Y/fNbz8PmTh6EyPA6vfOwj8C1PfqzbCp/0JODFLwbuuaf+fnbwGH0QXz69ANx7v9t6EuEsgIeenBn9rGdV8VhcwPKBB7xuy0MBPHIhwBcvGM1/0ekpZvNT4EtfMl7H42WBBy6cAmarOJizAL5mfjK6fwc873nAczZ1QDOefsWj8LTLLsL9F8yV4fd/69V44h0fmeT69Mmrvgm3XfE0fOWBBZ7y+K/FuSddfPAyR/me7wHe+c7B/n3U6QLV8gHgXrsxe8HzGHdB9kniIvKtAF6jqi9q/n4VAKjqv+vM865mnt8XkTMA/gLAxQBe2Z23O9/YOs+dO6e33HKL84cihBBCCCFkHyLyQVU9t+1/Js9ubgZwlYhcKSJnURfind+Y5zyAVzS//y0A79E6+j4P4LrG/eJKAFcBOOyZAiGEEEIIIZ7Zm27R5BjfAOBdAOYAblTVj4nIawHcoqrnAfwSgF8WkTsA3IM6kEYz368CuBXAKYAfVNXyKoUIIYQQQshRsTfdIgZMtyCEEEIIIb45NN2CEEIIIYSQomCQTAghhBBCyAYMkgkhhBBCCNmAQTIhhBBCCCEbMEgmhBBCCCFkAwbJhBBCCCGEbMAgmRBCCCGEkA0YJBNCCCGEELIBg2RCCCGEEEI2YJBMCCGEEELIBgySCSGEEEII2YBBMiGEEEIIIRswSCaEEEIIIWQDBsmEEEIIIYRswCCZEEIIIYSQDURVY2/DABH5PIA/jbDqRwP4QoT1Hjvcb+5w37nB/eYO950b3G/ucN+5wf3mjs2+e4KqXrztH0kGybEQkVtU9Vzs7Tg2uN/c4b5zg/vNHe47N7jf3OG+c4P7zZ2p9h3TLQghhBBCCNmAQTIhhBBCCCEbMEju88bYG3CkcL+5w33nBvebO9x3bnC/ucN95wb3mzuT7DvmJBNCCCGEELIBlWRCCCGEEEI2YJDcICJXi8jHReQOEXll7O1JFRG5TER+R0RuE5GPici/aF5/jYj8uYh8uPn5ztjbmhoi8ikR+Wizf25pXnuUiLxbRD7RTC+KvZ2pISJP6YyrD4vIl0XkhznmhojIjSLyORH5o85rW8eY1PxCc877iIg8K96Wx2fHvvsZEfnjZv+8XUQe2bx+hYjc3xl7/yXelsdlx37beWyKyKuaMfdxEXlRnK1Ogx377q2d/fYpEflw8zrHXMNIHDL5uY7pFgBEZA7gdgAvAHAXgJsBvFxVb426YQkiIo8D8DhV/ZCIfA2ADwJ4CYC/A+BeVf33UTcwYUTkUwDOqeoXOq/9NIB7VPV1zc3ZRar6o7G2MXWaY/XPATwHwD8Ax1wPEfl2APcC+G+q+tea17aOsSZw+SEA34l6f/5HVX1OrG2PzY5990IA71HVUxH5KQBo9t0VAH6jna9kduy312DLsSkiTwXwFgDPBvB4AL8F4Mmqugy60Ymwbd9t/P9nAXxJVV/LMbdmJA75Pkx8rqOSXPNsAHeo6p2qegHATQCujbxNSaKqn1HVDzW//z8AtwG4JO5WHTXXAnhT8/ubUB/oZDd/A8AnVTVGs6HkUdX/A+CejZd3jbFrUV+cVVXfB+CRzcWnSLbtO1X9TVU9bf58H4BLg29Y4uwYc7u4FsBNqvqgqv4JgDtQX3+LZGzfiYigFp/eEnSjjoCROGTycx2D5JpLAHy68/ddYOC3l+bO9pkA3t+8dEPzKONGpg1sRQH8poh8UESub157rKp+BqgPfACPibZ1x8F16F80OOb2s2uM8bxnxz8E8M7O31eKyB+IyO+KyLfF2qiE2XZscsyZ820APquqn+i8xjG3wUYcMvm5jkFyjWx5jXkoI4jIVwP47wB+WFW/DOA/A3gSgGcA+AyAn424eanyXFV9FoAXA/jB5lEbMUREzgK4BsCvNS9xzB0Gz3uGiMiPATgF8CvNS58BcLmqPhPAjwB4s4g8Itb2JciuY5NjzpyXoy8IcMxtsCUO2TnrlteMxh2D5Jq7AFzW+ftSAHdH2pbkEZET1APzV1T1fwCAqn5WVZeqWgH4RRT8CG0Xqnp3M/0cgLej3kefbR/7NNPPxdvC5HkxgA+p6mcBjjkLdo0xnvcMEJFXAPguAN+rTRFPky7wl83vHwTwSQBPjreVaTFybHLMGSAiZwC8FMBb29c45vpsi0Pg4VzHILnmZgBXiciVjVp1HYDzkbcpSZo8qV8CcJuq/ofO6938nr8J4I8231syIvLwpsAAIvJwAC9EvY/OA3hFM9srAPyvOFt4FPSUFY45Y3aNsfMA/n5T+f0tqAuEPhNjA1NFRK4G8KMArlHV+zqvX9wUkUJEngjgKgB3xtnK9Bg5Ns8DuE5EHiIiV6Lebx8IvX1HwPMB/LGq3tW+wDG3ZlccAg/nujMTbfNR01Qu3wDgXQDmAG5U1Y9F3qxUeS6Avwfgo601DYB/BeDlIvIM1I8wPgXgn8TZvGR5LIC318c2zgB4s6r+bxG5GcCvisj3A/gzAH874jYmi4g8DLX7THdc/TTHXB8ReQuA7wDwaBG5C8CPA3gdto+xd6Cu9r4DwH2o3UKKZce+exWAhwB4d3Psvk9VfwDAtwN4rYicAlgC+AFVNS1ey4od++07th2bqvoxEflVALeiTl/5wVKdLYDt+05VfwnD2guAY67Lrjhk8nMdLeAIIYQQQgjZgOkWhBBCCCGEbMAgmRBCCCGEkA0YJBNCCCGEELIBg2RCCCGEEEI2YJBMCCGEEELIBgySCSGEEEII2YBBMiGEEEIIIRswSCaEEEIIIWSD/w+P6nFyCSZtlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - More diverse dataset \n",
    "    - Hyperparameter tuning\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
