{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:50.277071Z",
     "start_time": "2020-05-01T02:18:50.266412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:50.834072Z",
     "start_time": "2020-05-01T02:18:50.278564Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.419240Z",
     "start_time": "2020-05-01T02:18:50.835620Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.432411Z",
     "start_time": "2020-05-01T02:18:51.420614Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.475823Z",
     "start_time": "2020-05-01T02:18:51.433693Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.488607Z",
     "start_time": "2020-05-01T02:18:51.476940Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.504550Z",
     "start_time": "2020-05-01T02:18:51.490724Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:51.514580Z",
     "start_time": "2020-05-01T02:18:51.506071Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:52.357694Z",
     "start_time": "2020-05-01T02:18:51.515758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:52.369986Z",
     "start_time": "2020-05-01T02:18:52.358863Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:18:56.082881Z",
     "start_time": "2020-05-01T02:18:52.371068Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:00.969962Z",
     "start_time": "2020-05-01T02:18:56.084143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:05.704132Z",
     "start_time": "2020-05-01T02:19:00.971189Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:07.174078Z",
     "start_time": "2020-05-01T02:19:05.705462Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:11.856780Z",
     "start_time": "2020-05-01T02:19:07.175192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:11.869215Z",
     "start_time": "2020-05-01T02:19:11.858745Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:14.091740Z",
     "start_time": "2020-05-01T02:19:11.870445Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 1200), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1200,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:14.115398Z",
     "start_time": "2020-05-01T02:19:14.092977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1200, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:14.130975Z",
     "start_time": "2020-05-01T02:19:14.117325Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-3,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:19:14.146257Z",
     "start_time": "2020-05-01T02:19:14.132439Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:48.361648Z",
     "start_time": "2020-05-01T02:19:14.147392Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 0.760 (0.760)\tData 0.334 (0.334)\tLoss 1.0767 (1.0767)\tAcc 0.750 (0.750)\n",
      "Epoch: [1][2/5]\tTime 0.029 (0.395)\tData 0.002 (0.168)\tLoss 1.0800 (1.0784)\tAcc 0.625 (0.688)\n",
      "Epoch: [1][3/5]\tTime 0.093 (0.294)\tData 0.066 (0.134)\tLoss 1.0638 (1.0735)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/5]\tTime 0.077 (0.240)\tData 0.050 (0.113)\tLoss 1.0547 (1.0688)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/5]\tTime 0.077 (0.207)\tData 0.051 (0.101)\tLoss 1.0716 (1.0691)\tAcc 0.556 (0.671)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.429 (0.429)\tData 0.371 (0.371)\tLoss 1.0093 (1.0093)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.075 (0.252)\tData 0.022 (0.197)\tLoss 1.0888 (1.0491)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.081 (0.195)\tData 0.029 (0.141)\tLoss 1.0507 (1.0496)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.069 (0.164)\tData 0.027 (0.112)\tLoss 1.0480 (1.0492)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.062 (0.143)\tData 0.033 (0.096)\tLoss 1.0469 (1.0487)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.082 (0.133)\tData 0.061 (0.091)\tLoss 1.0000 (1.0406)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.073 (0.125)\tData 0.052 (0.085)\tLoss 1.0181 (1.0374)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.074 (0.118)\tData 0.052 (0.081)\tLoss 1.0796 (1.0427)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.075 (0.113)\tData 0.053 (0.078)\tLoss 1.0001 (1.0420)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.372 (0.372)\tData 0.309 (0.309)\tLoss 1.0539 (1.0539)\tAcc 0.625 (0.625)\n",
      "Epoch: [2][2/5]\tTime 0.069 (0.221)\tData 0.018 (0.164)\tLoss 1.0199 (1.0369)\tAcc 0.750 (0.688)\n",
      "Epoch: [2][3/5]\tTime 0.077 (0.173)\tData 0.034 (0.120)\tLoss 0.9995 (1.0244)\tAcc 0.750 (0.708)\n",
      "Epoch: [2][4/5]\tTime 0.065 (0.146)\tData 0.035 (0.099)\tLoss 1.0184 (1.0229)\tAcc 0.625 (0.688)\n",
      "Epoch: [2][5/5]\tTime 0.077 (0.132)\tData 0.049 (0.089)\tLoss 1.0199 (1.0226)\tAcc 0.556 (0.671)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.365 (0.365)\tData 0.266 (0.266)\tLoss 0.9367 (0.9367)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.088 (0.226)\tData 0.001 (0.133)\tLoss 1.0911 (1.0139)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.076 (0.176)\tData 0.007 (0.091)\tLoss 1.0075 (1.0118)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.049 (0.145)\tData 0.006 (0.070)\tLoss 1.0178 (1.0133)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.073 (0.130)\tData 0.036 (0.063)\tLoss 1.0026 (1.0111)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.071 (0.120)\tData 0.042 (0.060)\tLoss 0.9174 (0.9955)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.065 (0.112)\tData 0.044 (0.057)\tLoss 0.9428 (0.9880)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.074 (0.108)\tData 0.052 (0.057)\tLoss 1.0632 (0.9974)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.074 (0.104)\tData 0.053 (0.056)\tLoss 0.9174 (0.9961)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.389 (0.389)\tData 0.325 (0.325)\tLoss 0.9707 (0.9707)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][2/5]\tTime 0.077 (0.233)\tData 0.029 (0.177)\tLoss 0.9551 (0.9629)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][3/5]\tTime 0.064 (0.177)\tData 0.030 (0.128)\tLoss 0.9765 (0.9674)\tAcc 0.625 (0.667)\n",
      "Epoch: [3][4/5]\tTime 0.088 (0.155)\tData 0.062 (0.112)\tLoss 0.8986 (0.9502)\tAcc 0.750 (0.688)\n",
      "Epoch: [3][5/5]\tTime 0.087 (0.141)\tData 0.056 (0.101)\tLoss 1.0121 (0.9578)\tAcc 0.556 (0.671)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.299 (0.299)\tData 0.260 (0.260)\tLoss 0.8442 (0.8442)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.083 (0.191)\tData 0.040 (0.150)\tLoss 1.1057 (0.9750)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.072 (0.151)\tData 0.031 (0.110)\tLoss 0.9668 (0.9722)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.074 (0.132)\tData 0.040 (0.093)\tLoss 0.9752 (0.9730)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.089 (0.123)\tData 0.045 (0.083)\tLoss 0.9560 (0.9696)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.080 (0.116)\tData 0.045 (0.077)\tLoss 0.8193 (0.9445)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.070 (0.110)\tData 0.038 (0.071)\tLoss 0.8626 (0.9328)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.068 (0.104)\tData 0.047 (0.068)\tLoss 1.0570 (0.9484)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.073 (0.101)\tData 0.052 (0.066)\tLoss 0.8309 (0.9466)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.374 (0.374)\tData 0.300 (0.300)\tLoss 0.9465 (0.9465)\tAcc 0.625 (0.625)\n",
      "Epoch: [4][2/5]\tTime 0.084 (0.229)\tData 0.027 (0.164)\tLoss 0.9845 (0.9655)\tAcc 0.562 (0.594)\n",
      "Epoch: [4][3/5]\tTime 0.072 (0.177)\tData 0.029 (0.119)\tLoss 0.9993 (0.9768)\tAcc 0.562 (0.583)\n",
      "Epoch: [4][4/5]\tTime 0.064 (0.149)\tData 0.034 (0.098)\tLoss 0.8134 (0.9359)\tAcc 0.750 (0.625)\n",
      "Epoch: [4][5/5]\tTime 0.092 (0.137)\tData 0.063 (0.091)\tLoss 0.5749 (0.8914)\tAcc 1.000 (0.671)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.307 (0.307)\tData 0.269 (0.269)\tLoss 0.7798 (0.7798)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.083 (0.195)\tData 0.050 (0.159)\tLoss 1.1233 (0.9515)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.094 (0.161)\tData 0.050 (0.123)\tLoss 0.9461 (0.9497)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/9]\tTime 0.089 (0.143)\tData 0.040 (0.102)\tLoss 0.9563 (0.9514)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/9]\tTime 0.086 (0.132)\tData 0.030 (0.088)\tLoss 0.9372 (0.9485)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/9]\tTime 0.051 (0.118)\tData 0.028 (0.078)\tLoss 0.7215 (0.9107)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/9]\tTime 0.073 (0.112)\tData 0.051 (0.074)\tLoss 0.7939 (0.8940)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/9]\tTime 0.076 (0.107)\tData 0.055 (0.072)\tLoss 1.0567 (0.9143)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/9]\tTime 0.074 (0.104)\tData 0.053 (0.070)\tLoss 0.7197 (0.9113)\tAcc 1.000 (0.731)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.515 (0.515)\tData 0.451 (0.451)\tLoss 0.8586 (0.8586)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][2/5]\tTime 0.064 (0.290)\tData 0.029 (0.240)\tLoss 0.9141 (0.8864)\tAcc 0.625 (0.656)\n",
      "Epoch: [5][3/5]\tTime 0.088 (0.222)\tData 0.049 (0.176)\tLoss 0.9159 (0.8962)\tAcc 0.625 (0.646)\n",
      "Epoch: [5][4/5]\tTime 0.074 (0.185)\tData 0.048 (0.144)\tLoss 0.6240 (0.8282)\tAcc 0.875 (0.703)\n",
      "Epoch: [5][5/5]\tTime 0.081 (0.164)\tData 0.055 (0.126)\tLoss 1.1616 (0.8693)\tAcc 0.444 (0.671)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.425 (0.425)\tData 0.367 (0.367)\tLoss 0.6895 (0.6895)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.072 (0.248)\tData 0.023 (0.195)\tLoss 1.1596 (0.9245)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.062 (0.186)\tData 0.031 (0.140)\tLoss 0.9235 (0.9242)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.074 (0.158)\tData 0.045 (0.116)\tLoss 0.9445 (0.9293)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.067 (0.140)\tData 0.046 (0.102)\tLoss 0.8967 (0.9227)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.077 (0.129)\tData 0.056 (0.095)\tLoss 0.6349 (0.8748)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.080 (0.122)\tData 0.060 (0.090)\tLoss 0.7151 (0.8520)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.076 (0.117)\tData 0.054 (0.085)\tLoss 1.0679 (0.8789)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.079 (0.112)\tData 0.057 (0.082)\tLoss 0.6277 (0.8751)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.388 (0.388)\tData 0.326 (0.326)\tLoss 0.9771 (0.9771)\tAcc 0.562 (0.562)\n",
      "Epoch: [6][2/5]\tTime 0.073 (0.231)\tData 0.038 (0.182)\tLoss 0.7537 (0.8654)\tAcc 0.750 (0.656)\n",
      "Epoch: [6][3/5]\tTime 0.080 (0.180)\tData 0.046 (0.137)\tLoss 0.8296 (0.8535)\tAcc 0.688 (0.667)\n",
      "Epoch: [6][4/5]\tTime 0.076 (0.154)\tData 0.046 (0.114)\tLoss 0.8178 (0.8446)\tAcc 0.688 (0.672)\n",
      "Epoch: [6][5/5]\tTime 0.076 (0.139)\tData 0.050 (0.101)\tLoss 0.8540 (0.8457)\tAcc 0.667 (0.671)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.388 (0.388)\tData 0.335 (0.335)\tLoss 0.6373 (0.6373)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.079 (0.234)\tData 0.022 (0.179)\tLoss 1.2213 (0.9293)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/9]\tTime 0.064 (0.177)\tData 0.023 (0.127)\tLoss 0.9380 (0.9322)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/9]\tTime 0.059 (0.147)\tData 0.035 (0.104)\tLoss 0.9160 (0.9282)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/9]\tTime 0.074 (0.133)\tData 0.053 (0.094)\tLoss 0.8710 (0.9167)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/9]\tTime 0.074 (0.123)\tData 0.053 (0.087)\tLoss 0.5770 (0.8601)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/9]\tTime 0.080 (0.117)\tData 0.053 (0.082)\tLoss 0.6778 (0.8341)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/9]\tTime 0.072 (0.111)\tData 0.051 (0.078)\tLoss 1.1170 (0.8694)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/9]\tTime 0.073 (0.107)\tData 0.053 (0.075)\tLoss 0.5867 (0.8651)\tAcc 1.000 (0.731)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.273 (0.273)\tData 0.238 (0.238)\tLoss 0.9170 (0.9170)\tAcc 0.625 (0.625)\n",
      "Epoch: [7][2/5]\tTime 0.112 (0.192)\tData 0.084 (0.161)\tLoss 0.7368 (0.8269)\tAcc 0.750 (0.688)\n",
      "Epoch: [7][3/5]\tTime 0.079 (0.154)\tData 0.053 (0.125)\tLoss 0.7569 (0.8035)\tAcc 0.750 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.079 (0.135)\tData 0.053 (0.107)\tLoss 0.9656 (0.8441)\tAcc 0.625 (0.688)\n",
      "Epoch: [7][5/5]\tTime 0.080 (0.124)\tData 0.055 (0.097)\tLoss 1.0454 (0.8689)\tAcc 0.556 (0.671)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.255 (0.255)\tData 0.213 (0.213)\tLoss 0.6042 (0.6042)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.098 (0.177)\tData 0.036 (0.125)\tLoss 1.2211 (0.9126)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.036 (0.130)\tData 0.016 (0.088)\tLoss 0.9168 (0.9140)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.075 (0.116)\tData 0.055 (0.080)\tLoss 0.9033 (0.9114)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.076 (0.108)\tData 0.056 (0.075)\tLoss 0.8950 (0.9081)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.074 (0.102)\tData 0.055 (0.072)\tLoss 0.5069 (0.8412)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.076 (0.099)\tData 0.057 (0.070)\tLoss 0.6303 (0.8111)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.073 (0.095)\tData 0.053 (0.068)\tLoss 1.1148 (0.8491)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.075 (0.093)\tData 0.056 (0.066)\tLoss 0.5322 (0.8442)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.221 (0.221)\tData 0.183 (0.183)\tLoss 0.7205 (0.7205)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][2/5]\tTime 0.070 (0.146)\tData 0.046 (0.115)\tLoss 0.7361 (0.7283)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][3/5]\tTime 0.082 (0.124)\tData 0.057 (0.095)\tLoss 0.7292 (0.7286)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][4/5]\tTime 0.079 (0.113)\tData 0.055 (0.085)\tLoss 1.0120 (0.7994)\tAcc 0.562 (0.703)\n",
      "Epoch: [8][5/5]\tTime 0.079 (0.106)\tData 0.055 (0.079)\tLoss 1.1334 (0.8406)\tAcc 0.444 (0.671)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.223 (0.223)\tData 0.195 (0.195)\tLoss 0.5691 (0.5691)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.076 (0.150)\tData 0.047 (0.121)\tLoss 1.1957 (0.8824)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/9]\tTime 0.071 (0.123)\tData 0.050 (0.097)\tLoss 0.8853 (0.8834)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/9]\tTime 0.074 (0.111)\tData 0.054 (0.087)\tLoss 0.9078 (0.8895)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/9]\tTime 0.074 (0.104)\tData 0.054 (0.080)\tLoss 0.8922 (0.8900)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/9]\tTime 0.075 (0.099)\tData 0.056 (0.076)\tLoss 0.4965 (0.8244)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/9]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.6385 (0.7979)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/9]\tTime 0.078 (0.093)\tData 0.057 (0.071)\tLoss 1.1189 (0.8380)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/9]\tTime 0.073 (0.091)\tData 0.054 (0.069)\tLoss 0.4730 (0.8324)\tAcc 1.000 (0.731)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.213 (0.213)\tData 0.179 (0.179)\tLoss 0.4668 (0.4668)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/5]\tTime 0.070 (0.141)\tData 0.045 (0.112)\tLoss 1.1588 (0.8128)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/5]\tTime 0.081 (0.121)\tData 0.056 (0.093)\tLoss 0.8264 (0.8173)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/5]\tTime 0.081 (0.111)\tData 0.057 (0.084)\tLoss 0.9209 (0.8432)\tAcc 0.562 (0.656)\n",
      "Epoch: [9][5/5]\tTime 0.077 (0.104)\tData 0.053 (0.078)\tLoss 0.6933 (0.8247)\tAcc 0.778 (0.671)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.205 (0.205)\tData 0.172 (0.172)\tLoss 0.5735 (0.5735)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/9]\tTime 0.069 (0.137)\tData 0.043 (0.107)\tLoss 1.1721 (0.8728)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/9]\tTime 0.070 (0.114)\tData 0.050 (0.088)\tLoss 0.8557 (0.8671)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/9]\tTime 0.075 (0.104)\tData 0.055 (0.080)\tLoss 0.8738 (0.8688)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/9]\tTime 0.075 (0.099)\tData 0.055 (0.075)\tLoss 0.8503 (0.8651)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.071)\tLoss 0.5013 (0.8044)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.069)\tLoss 0.6446 (0.7816)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/9]\tTime 0.075 (0.090)\tData 0.055 (0.067)\tLoss 1.0694 (0.8176)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/9]\tTime 0.075 (0.088)\tData 0.056 (0.066)\tLoss 0.4677 (0.8122)\tAcc 1.000 (0.731)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.214 (0.214)\tData 0.183 (0.183)\tLoss 0.7329 (0.7329)\tAcc 0.750 (0.750)\n",
      "Epoch: [10][2/5]\tTime 0.074 (0.144)\tData 0.050 (0.116)\tLoss 0.5487 (0.6408)\tAcc 0.875 (0.812)\n",
      "Epoch: [10][3/5]\tTime 0.078 (0.122)\tData 0.054 (0.096)\tLoss 0.8618 (0.7144)\tAcc 0.625 (0.750)\n",
      "Epoch: [10][4/5]\tTime 0.080 (0.112)\tData 0.056 (0.086)\tLoss 1.1470 (0.8226)\tAcc 0.438 (0.672)\n",
      "Epoch: [10][5/5]\tTime 0.079 (0.105)\tData 0.055 (0.080)\tLoss 0.8817 (0.8299)\tAcc 0.667 (0.671)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.218 (0.218)\tData 0.185 (0.185)\tLoss 0.5385 (0.5385)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.074 (0.146)\tData 0.047 (0.116)\tLoss 1.1758 (0.8571)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/9]\tTime 0.070 (0.121)\tData 0.050 (0.094)\tLoss 0.8488 (0.8544)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.074 (0.109)\tData 0.055 (0.084)\tLoss 0.8427 (0.8515)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.074 (0.102)\tData 0.054 (0.078)\tLoss 0.8516 (0.8515)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.079 (0.098)\tData 0.059 (0.075)\tLoss 0.4677 (0.7875)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.076 (0.095)\tData 0.056 (0.072)\tLoss 0.6215 (0.7638)\tAcc 0.875 (0.759)\n",
      "Epoch: [10][8/9]\tTime 0.076 (0.093)\tData 0.057 (0.071)\tLoss 1.0571 (0.8005)\tAcc 0.500 (0.727)\n",
      "Epoch: [10][9/9]\tTime 0.077 (0.091)\tData 0.057 (0.069)\tLoss 0.4523 (0.7951)\tAcc 1.000 (0.731)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.210 (0.210)\tData 0.180 (0.180)\tLoss 0.7628 (0.7628)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][2/5]\tTime 0.078 (0.144)\tData 0.052 (0.116)\tLoss 0.5864 (0.6746)\tAcc 0.875 (0.781)\n",
      "Epoch: [11][3/5]\tTime 0.078 (0.122)\tData 0.053 (0.095)\tLoss 0.8266 (0.7253)\tAcc 0.625 (0.729)\n",
      "Epoch: [11][4/5]\tTime 0.081 (0.112)\tData 0.057 (0.086)\tLoss 0.9042 (0.7700)\tAcc 0.562 (0.688)\n",
      "Epoch: [11][5/5]\tTime 0.079 (0.105)\tData 0.055 (0.080)\tLoss 0.9594 (0.7933)\tAcc 0.556 (0.671)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.207 (0.207)\tData 0.179 (0.179)\tLoss 0.5059 (0.5059)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/9]\tTime 0.080 (0.143)\tData 0.051 (0.115)\tLoss 1.1754 (0.8406)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/9]\tTime 0.067 (0.118)\tData 0.047 (0.092)\tLoss 0.8277 (0.8363)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][4/9]\tTime 0.075 (0.107)\tData 0.055 (0.083)\tLoss 0.8283 (0.8343)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][5/9]\tTime 0.075 (0.101)\tData 0.055 (0.077)\tLoss 0.8290 (0.8333)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][6/9]\tTime 0.076 (0.097)\tData 0.057 (0.074)\tLoss 0.4319 (0.7664)\tAcc 1.000 (0.740)\n",
      "Epoch: [11][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.6120 (0.7443)\tAcc 0.875 (0.759)\n",
      "Epoch: [11][8/9]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 1.0458 (0.7820)\tAcc 0.500 (0.727)\n",
      "Epoch: [11][9/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.4456 (0.7768)\tAcc 1.000 (0.731)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.214 (0.214)\tData 0.185 (0.185)\tLoss 0.6037 (0.6037)\tAcc 0.812 (0.812)\n",
      "Epoch: [12][2/5]\tTime 0.076 (0.145)\tData 0.051 (0.118)\tLoss 0.7344 (0.6690)\tAcc 0.688 (0.750)\n",
      "Epoch: [12][3/5]\tTime 0.081 (0.124)\tData 0.056 (0.097)\tLoss 0.6865 (0.6749)\tAcc 0.750 (0.750)\n",
      "Epoch: [12][4/5]\tTime 0.081 (0.113)\tData 0.057 (0.087)\tLoss 1.0216 (0.7616)\tAcc 0.500 (0.688)\n",
      "Epoch: [12][5/5]\tTime 0.079 (0.106)\tData 0.055 (0.081)\tLoss 0.8892 (0.7773)\tAcc 0.556 (0.671)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.214 (0.214)\tData 0.188 (0.188)\tLoss 0.4482 (0.4482)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/9]\tTime 0.077 (0.145)\tData 0.050 (0.119)\tLoss 1.1827 (0.8155)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/9]\tTime 0.068 (0.120)\tData 0.048 (0.095)\tLoss 0.8120 (0.8143)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][4/9]\tTime 0.076 (0.109)\tData 0.056 (0.086)\tLoss 0.8166 (0.8149)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/9]\tTime 0.074 (0.102)\tData 0.055 (0.079)\tLoss 0.8134 (0.8146)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][6/9]\tTime 0.077 (0.098)\tData 0.056 (0.076)\tLoss 0.3731 (0.7410)\tAcc 1.000 (0.740)\n",
      "Epoch: [12][7/9]\tTime 0.076 (0.095)\tData 0.056 (0.073)\tLoss 0.6079 (0.7220)\tAcc 0.875 (0.759)\n",
      "Epoch: [12][8/9]\tTime 0.076 (0.092)\tData 0.056 (0.071)\tLoss 1.0937 (0.7684)\tAcc 0.500 (0.727)\n",
      "Epoch: [12][9/9]\tTime 0.076 (0.091)\tData 0.056 (0.069)\tLoss 0.3985 (0.7628)\tAcc 1.000 (0.731)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.203 (0.203)\tData 0.170 (0.170)\tLoss 0.5651 (0.5651)\tAcc 0.875 (0.875)\n",
      "Epoch: [13][2/5]\tTime 0.072 (0.138)\tData 0.048 (0.109)\tLoss 0.7459 (0.6555)\tAcc 0.750 (0.812)\n",
      "Epoch: [13][3/5]\tTime 0.080 (0.118)\tData 0.056 (0.091)\tLoss 0.9603 (0.7571)\tAcc 0.500 (0.708)\n",
      "Epoch: [13][4/5]\tTime 0.080 (0.109)\tData 0.055 (0.082)\tLoss 0.8652 (0.7841)\tAcc 0.562 (0.672)\n",
      "Epoch: [13][5/5]\tTime 0.079 (0.103)\tData 0.055 (0.077)\tLoss 0.7711 (0.7825)\tAcc 0.667 (0.671)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.209 (0.209)\tData 0.178 (0.178)\tLoss 0.4240 (0.4240)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/9]\tTime 0.075 (0.142)\tData 0.051 (0.114)\tLoss 1.1749 (0.7995)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/9]\tTime 0.072 (0.119)\tData 0.052 (0.094)\tLoss 0.7502 (0.7830)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/9]\tTime 0.074 (0.107)\tData 0.054 (0.084)\tLoss 0.7607 (0.7775)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][5/9]\tTime 0.075 (0.101)\tData 0.055 (0.078)\tLoss 0.8211 (0.7862)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][6/9]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.3615 (0.7154)\tAcc 1.000 (0.740)\n",
      "Epoch: [13][7/9]\tTime 0.076 (0.094)\tData 0.055 (0.071)\tLoss 0.5499 (0.6918)\tAcc 0.875 (0.759)\n",
      "Epoch: [13][8/9]\tTime 0.076 (0.091)\tData 0.056 (0.069)\tLoss 1.0419 (0.7355)\tAcc 0.500 (0.727)\n",
      "Epoch: [13][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.3432 (0.7295)\tAcc 1.000 (0.731)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.199 (0.199)\tData 0.166 (0.166)\tLoss 0.5870 (0.5870)\tAcc 0.750 (0.750)\n",
      "Epoch: [14][2/5]\tTime 0.073 (0.136)\tData 0.049 (0.107)\tLoss 0.8215 (0.7043)\tAcc 0.562 (0.656)\n",
      "Epoch: [14][3/5]\tTime 0.081 (0.118)\tData 0.057 (0.091)\tLoss 0.6053 (0.6713)\tAcc 0.812 (0.708)\n",
      "Epoch: [14][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.082)\tLoss 0.8519 (0.7164)\tAcc 0.562 (0.672)\n",
      "Epoch: [14][5/5]\tTime 0.079 (0.102)\tData 0.055 (0.076)\tLoss 0.8011 (0.7269)\tAcc 0.667 (0.671)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.215 (0.215)\tData 0.179 (0.179)\tLoss 0.3875 (0.3875)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.068 (0.142)\tData 0.040 (0.110)\tLoss 1.1155 (0.7515)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/9]\tTime 0.067 (0.117)\tData 0.047 (0.089)\tLoss 0.7052 (0.7361)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][4/9]\tTime 0.075 (0.106)\tData 0.054 (0.080)\tLoss 0.7707 (0.7447)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][5/9]\tTime 0.079 (0.101)\tData 0.058 (0.076)\tLoss 0.7768 (0.7511)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][6/9]\tTime 0.074 (0.096)\tData 0.053 (0.072)\tLoss 0.2995 (0.6759)\tAcc 1.000 (0.740)\n",
      "Epoch: [14][7/9]\tTime 0.077 (0.094)\tData 0.057 (0.070)\tLoss 0.5657 (0.6601)\tAcc 0.875 (0.759)\n",
      "Epoch: [14][8/9]\tTime 0.078 (0.092)\tData 0.058 (0.068)\tLoss 1.0458 (0.7083)\tAcc 0.500 (0.727)\n",
      "Epoch: [14][9/9]\tTime 0.075 (0.090)\tData 0.056 (0.067)\tLoss 0.2668 (0.7015)\tAcc 1.000 (0.731)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.211 (0.211)\tData 0.184 (0.184)\tLoss 0.5557 (0.5557)\tAcc 0.875 (0.875)\n",
      "Epoch: [15][2/5]\tTime 0.083 (0.147)\tData 0.058 (0.121)\tLoss 0.8406 (0.6982)\tAcc 0.562 (0.719)\n",
      "Epoch: [15][3/5]\tTime 0.080 (0.125)\tData 0.055 (0.099)\tLoss 0.8755 (0.7573)\tAcc 0.688 (0.708)\n",
      "Epoch: [15][4/5]\tTime 0.082 (0.114)\tData 0.057 (0.089)\tLoss 0.9769 (0.8122)\tAcc 0.500 (0.656)\n",
      "Epoch: [15][5/5]\tTime 0.081 (0.107)\tData 0.057 (0.082)\tLoss 0.6222 (0.7888)\tAcc 0.778 (0.671)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.215 (0.215)\tData 0.183 (0.183)\tLoss 0.3698 (0.3698)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/9]\tTime 0.071 (0.143)\tData 0.046 (0.114)\tLoss 1.1381 (0.7540)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/9]\tTime 0.071 (0.119)\tData 0.052 (0.093)\tLoss 0.6864 (0.7314)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][4/9]\tTime 0.075 (0.108)\tData 0.055 (0.084)\tLoss 0.7384 (0.7332)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][5/9]\tTime 0.075 (0.102)\tData 0.056 (0.078)\tLoss 0.7439 (0.7353)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][6/9]\tTime 0.074 (0.097)\tData 0.055 (0.074)\tLoss 0.3062 (0.6638)\tAcc 1.000 (0.740)\n",
      "Epoch: [15][7/9]\tTime 0.076 (0.094)\tData 0.056 (0.072)\tLoss 0.5645 (0.6496)\tAcc 0.875 (0.759)\n",
      "Epoch: [15][8/9]\tTime 0.075 (0.092)\tData 0.056 (0.070)\tLoss 1.0374 (0.6981)\tAcc 0.500 (0.727)\n",
      "Epoch: [15][9/9]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.2507 (0.6912)\tAcc 1.000 (0.731)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.218 (0.218)\tData 0.187 (0.187)\tLoss 0.6976 (0.6976)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][2/5]\tTime 0.078 (0.148)\tData 0.054 (0.120)\tLoss 0.5085 (0.6031)\tAcc 0.875 (0.781)\n",
      "Epoch: [16][3/5]\tTime 0.081 (0.125)\tData 0.056 (0.099)\tLoss 0.8232 (0.6764)\tAcc 0.625 (0.729)\n",
      "Epoch: [16][4/5]\tTime 0.082 (0.114)\tData 0.057 (0.088)\tLoss 0.8970 (0.7316)\tAcc 0.625 (0.703)\n",
      "Epoch: [16][5/5]\tTime 0.081 (0.108)\tData 0.056 (0.082)\tLoss 0.6136 (0.7170)\tAcc 0.778 (0.712)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.254 (0.254)\tData 0.183 (0.183)\tLoss 0.3453 (0.3453)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.063 (0.159)\tData 0.010 (0.097)\tLoss 1.1213 (0.7333)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/9]\tTime 0.047 (0.121)\tData 0.025 (0.073)\tLoss 0.6471 (0.7046)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][4/9]\tTime 0.079 (0.111)\tData 0.058 (0.069)\tLoss 0.6982 (0.7030)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][5/9]\tTime 0.080 (0.104)\tData 0.059 (0.067)\tLoss 0.7335 (0.7091)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][6/9]\tTime 0.080 (0.100)\tData 0.060 (0.066)\tLoss 0.2767 (0.6370)\tAcc 1.000 (0.740)\n",
      "Epoch: [16][7/9]\tTime 0.082 (0.098)\tData 0.061 (0.065)\tLoss 0.5653 (0.6268)\tAcc 0.875 (0.759)\n",
      "Epoch: [16][8/9]\tTime 0.083 (0.096)\tData 0.062 (0.065)\tLoss 1.0893 (0.6846)\tAcc 0.500 (0.727)\n",
      "Epoch: [16][9/9]\tTime 0.079 (0.094)\tData 0.059 (0.064)\tLoss 0.2453 (0.6778)\tAcc 1.000 (0.731)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.210 (0.210)\tData 0.181 (0.181)\tLoss 0.6976 (0.6976)\tAcc 0.750 (0.750)\n",
      "Epoch: [17][2/5]\tTime 0.076 (0.143)\tData 0.051 (0.116)\tLoss 0.6108 (0.6542)\tAcc 0.812 (0.781)\n",
      "Epoch: [17][3/5]\tTime 0.084 (0.123)\tData 0.060 (0.098)\tLoss 0.6679 (0.6587)\tAcc 0.625 (0.729)\n",
      "Epoch: [17][4/5]\tTime 0.086 (0.114)\tData 0.062 (0.089)\tLoss 0.8656 (0.7105)\tAcc 0.562 (0.688)\n",
      "Epoch: [17][5/5]\tTime 0.084 (0.108)\tData 0.060 (0.083)\tLoss 0.8705 (0.7302)\tAcc 0.556 (0.671)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.206 (0.206)\tData 0.170 (0.170)\tLoss 0.3156 (0.3156)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/9]\tTime 0.074 (0.140)\tData 0.045 (0.108)\tLoss 1.1396 (0.7276)\tAcc 0.438 (0.688)\n",
      "Epoch: [17][3/9]\tTime 0.072 (0.117)\tData 0.051 (0.089)\tLoss 0.6180 (0.6911)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][4/9]\tTime 0.079 (0.108)\tData 0.059 (0.082)\tLoss 0.7052 (0.6946)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][5/9]\tTime 0.079 (0.102)\tData 0.059 (0.077)\tLoss 0.8583 (0.7273)\tAcc 0.625 (0.675)\n",
      "Epoch: [17][6/9]\tTime 0.078 (0.098)\tData 0.058 (0.074)\tLoss 0.2629 (0.6499)\tAcc 1.000 (0.729)\n",
      "Epoch: [17][7/9]\tTime 0.079 (0.095)\tData 0.058 (0.072)\tLoss 0.4866 (0.6266)\tAcc 0.812 (0.741)\n",
      "Epoch: [17][8/9]\tTime 0.074 (0.093)\tData 0.053 (0.069)\tLoss 1.1264 (0.6891)\tAcc 0.500 (0.711)\n",
      "Epoch: [17][9/9]\tTime 0.083 (0.091)\tData 0.062 (0.069)\tLoss 0.2232 (0.6819)\tAcc 1.000 (0.715)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.207 (0.207)\tData 0.177 (0.177)\tLoss 0.6295 (0.6295)\tAcc 0.750 (0.750)\n",
      "Epoch: [18][2/5]\tTime 0.076 (0.141)\tData 0.051 (0.114)\tLoss 1.0559 (0.8427)\tAcc 0.500 (0.625)\n",
      "Epoch: [18][3/5]\tTime 0.084 (0.122)\tData 0.059 (0.096)\tLoss 0.5428 (0.7427)\tAcc 0.750 (0.667)\n",
      "Epoch: [18][4/5]\tTime 0.083 (0.112)\tData 0.059 (0.086)\tLoss 0.5308 (0.6898)\tAcc 0.875 (0.719)\n",
      "Epoch: [18][5/5]\tTime 0.088 (0.108)\tData 0.064 (0.082)\tLoss 0.9514 (0.7220)\tAcc 0.444 (0.685)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.216 (0.216)\tData 0.186 (0.186)\tLoss 0.3023 (0.3023)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/9]\tTime 0.078 (0.147)\tData 0.049 (0.118)\tLoss 1.0733 (0.6878)\tAcc 0.438 (0.688)\n",
      "Epoch: [18][3/9]\tTime 0.066 (0.120)\tData 0.046 (0.094)\tLoss 0.6032 (0.6596)\tAcc 0.750 (0.708)\n",
      "Epoch: [18][4/9]\tTime 0.077 (0.109)\tData 0.057 (0.085)\tLoss 0.6511 (0.6575)\tAcc 0.688 (0.703)\n",
      "Epoch: [18][5/9]\tTime 0.094 (0.106)\tData 0.074 (0.082)\tLoss 0.7871 (0.6834)\tAcc 0.750 (0.713)\n",
      "Epoch: [18][6/9]\tTime 0.077 (0.101)\tData 0.057 (0.078)\tLoss 0.2478 (0.6108)\tAcc 1.000 (0.760)\n",
      "Epoch: [18][7/9]\tTime 0.076 (0.098)\tData 0.056 (0.075)\tLoss 0.6187 (0.6119)\tAcc 0.812 (0.768)\n",
      "Epoch: [18][8/9]\tTime 0.076 (0.095)\tData 0.056 (0.073)\tLoss 0.9609 (0.6555)\tAcc 0.562 (0.742)\n",
      "Epoch: [18][9/9]\tTime 0.076 (0.093)\tData 0.057 (0.071)\tLoss 0.2053 (0.6486)\tAcc 1.000 (0.746)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.199 (0.199)\tData 0.168 (0.168)\tLoss 0.7518 (0.7518)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][2/5]\tTime 0.077 (0.138)\tData 0.052 (0.110)\tLoss 0.6898 (0.7208)\tAcc 0.750 (0.719)\n",
      "Epoch: [19][3/5]\tTime 0.080 (0.119)\tData 0.056 (0.092)\tLoss 0.6960 (0.7125)\tAcc 0.750 (0.729)\n",
      "Epoch: [19][4/5]\tTime 0.081 (0.109)\tData 0.056 (0.083)\tLoss 0.6293 (0.6917)\tAcc 0.688 (0.719)\n",
      "Epoch: [19][5/5]\tTime 0.083 (0.104)\tData 0.059 (0.078)\tLoss 0.5817 (0.6781)\tAcc 0.667 (0.712)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.212 (0.212)\tData 0.175 (0.175)\tLoss 0.3414 (0.3414)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/9]\tTime 0.081 (0.147)\tData 0.043 (0.109)\tLoss 1.0324 (0.6869)\tAcc 0.438 (0.688)\n",
      "Epoch: [19][3/9]\tTime 0.063 (0.119)\tData 0.043 (0.087)\tLoss 0.5618 (0.6452)\tAcc 0.688 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.077 (0.108)\tData 0.057 (0.080)\tLoss 0.6908 (0.6566)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][5/9]\tTime 0.078 (0.102)\tData 0.058 (0.075)\tLoss 0.7974 (0.6847)\tAcc 0.750 (0.700)\n",
      "Epoch: [19][6/9]\tTime 0.075 (0.098)\tData 0.055 (0.072)\tLoss 0.2560 (0.6133)\tAcc 1.000 (0.750)\n",
      "Epoch: [19][7/9]\tTime 0.075 (0.095)\tData 0.055 (0.070)\tLoss 0.6188 (0.6141)\tAcc 0.750 (0.750)\n",
      "Epoch: [19][8/9]\tTime 0.078 (0.092)\tData 0.058 (0.068)\tLoss 1.0477 (0.6683)\tAcc 0.625 (0.734)\n",
      "Epoch: [19][9/9]\tTime 0.074 (0.090)\tData 0.054 (0.067)\tLoss 0.1619 (0.6605)\tAcc 1.000 (0.738)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.203 (0.203)\tData 0.171 (0.171)\tLoss 0.9243 (0.9243)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][2/5]\tTime 0.075 (0.139)\tData 0.050 (0.111)\tLoss 0.5075 (0.7159)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][3/5]\tTime 0.080 (0.119)\tData 0.056 (0.092)\tLoss 0.8006 (0.7441)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][4/5]\tTime 0.081 (0.110)\tData 0.056 (0.083)\tLoss 0.6564 (0.7222)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][5/5]\tTime 0.079 (0.104)\tData 0.055 (0.078)\tLoss 0.7750 (0.7287)\tAcc 0.778 (0.699)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.205 (0.205)\tData 0.180 (0.180)\tLoss 0.3099 (0.3099)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/9]\tTime 0.078 (0.142)\tData 0.050 (0.115)\tLoss 1.0544 (0.6822)\tAcc 0.438 (0.688)\n",
      "Epoch: [20][3/9]\tTime 0.068 (0.117)\tData 0.048 (0.092)\tLoss 0.6534 (0.6726)\tAcc 0.812 (0.729)\n",
      "Epoch: [20][4/9]\tTime 0.076 (0.107)\tData 0.055 (0.083)\tLoss 0.6508 (0.6671)\tAcc 0.625 (0.703)\n",
      "Epoch: [20][5/9]\tTime 0.077 (0.101)\tData 0.057 (0.078)\tLoss 0.7145 (0.6766)\tAcc 0.750 (0.713)\n",
      "Epoch: [20][6/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.2419 (0.6042)\tAcc 1.000 (0.760)\n",
      "Epoch: [20][7/9]\tTime 0.074 (0.093)\tData 0.055 (0.071)\tLoss 0.6536 (0.6112)\tAcc 0.688 (0.750)\n",
      "Epoch: [20][8/9]\tTime 0.075 (0.091)\tData 0.055 (0.069)\tLoss 1.0808 (0.6699)\tAcc 0.625 (0.734)\n",
      "Epoch: [20][9/9]\tTime 0.075 (0.089)\tData 0.055 (0.068)\tLoss 0.2185 (0.6630)\tAcc 1.000 (0.738)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.202 (0.202)\tData 0.170 (0.170)\tLoss 0.8827 (0.8827)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][2/5]\tTime 0.075 (0.139)\tData 0.050 (0.110)\tLoss 0.7200 (0.8014)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][3/5]\tTime 0.081 (0.119)\tData 0.055 (0.092)\tLoss 0.5886 (0.7305)\tAcc 0.750 (0.708)\n",
      "Epoch: [21][4/5]\tTime 0.080 (0.109)\tData 0.055 (0.083)\tLoss 0.4982 (0.6724)\tAcc 0.875 (0.750)\n",
      "Epoch: [21][5/5]\tTime 0.079 (0.103)\tData 0.055 (0.077)\tLoss 0.4807 (0.6487)\tAcc 0.778 (0.753)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.208 (0.208)\tData 0.174 (0.174)\tLoss 0.2855 (0.2855)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.073 (0.141)\tData 0.044 (0.109)\tLoss 1.0212 (0.6534)\tAcc 0.438 (0.688)\n",
      "Epoch: [21][3/9]\tTime 0.067 (0.116)\tData 0.047 (0.088)\tLoss 0.5027 (0.6032)\tAcc 0.750 (0.708)\n",
      "Epoch: [21][4/9]\tTime 0.076 (0.106)\tData 0.056 (0.080)\tLoss 0.6739 (0.6208)\tAcc 0.625 (0.688)\n",
      "Epoch: [21][5/9]\tTime 0.076 (0.100)\tData 0.056 (0.075)\tLoss 0.7584 (0.6484)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][6/9]\tTime 0.077 (0.096)\tData 0.057 (0.072)\tLoss 0.2501 (0.5820)\tAcc 1.000 (0.740)\n",
      "Epoch: [21][7/9]\tTime 0.078 (0.093)\tData 0.058 (0.070)\tLoss 0.5223 (0.5734)\tAcc 0.875 (0.759)\n",
      "Epoch: [21][8/9]\tTime 0.078 (0.091)\tData 0.058 (0.069)\tLoss 1.0094 (0.6279)\tAcc 0.562 (0.734)\n",
      "Epoch: [21][9/9]\tTime 0.077 (0.090)\tData 0.057 (0.067)\tLoss 0.1884 (0.6212)\tAcc 1.000 (0.738)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.205 (0.205)\tData 0.178 (0.178)\tLoss 0.7556 (0.7556)\tAcc 0.750 (0.750)\n",
      "Epoch: [22][2/5]\tTime 0.080 (0.143)\tData 0.055 (0.116)\tLoss 0.4477 (0.6017)\tAcc 0.875 (0.812)\n",
      "Epoch: [22][3/5]\tTime 0.084 (0.123)\tData 0.060 (0.098)\tLoss 0.7608 (0.6547)\tAcc 0.625 (0.750)\n",
      "Epoch: [22][4/5]\tTime 0.082 (0.113)\tData 0.058 (0.088)\tLoss 0.7492 (0.6783)\tAcc 0.625 (0.719)\n",
      "Epoch: [22][5/5]\tTime 0.080 (0.106)\tData 0.057 (0.082)\tLoss 0.6205 (0.6712)\tAcc 0.778 (0.726)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.199 (0.199)\tData 0.172 (0.172)\tLoss 0.2066 (0.2066)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.073 (0.136)\tData 0.050 (0.111)\tLoss 1.0568 (0.6317)\tAcc 0.438 (0.688)\n",
      "Epoch: [22][3/9]\tTime 0.072 (0.115)\tData 0.053 (0.092)\tLoss 0.5818 (0.6151)\tAcc 0.812 (0.729)\n",
      "Epoch: [22][4/9]\tTime 0.077 (0.105)\tData 0.057 (0.083)\tLoss 0.6210 (0.6165)\tAcc 0.688 (0.719)\n",
      "Epoch: [22][5/9]\tTime 0.077 (0.100)\tData 0.058 (0.078)\tLoss 0.7554 (0.6443)\tAcc 0.688 (0.713)\n",
      "Epoch: [22][6/9]\tTime 0.078 (0.096)\tData 0.058 (0.075)\tLoss 0.2410 (0.5771)\tAcc 1.000 (0.760)\n",
      "Epoch: [22][7/9]\tTime 0.075 (0.093)\tData 0.055 (0.072)\tLoss 0.5304 (0.5704)\tAcc 0.750 (0.759)\n",
      "Epoch: [22][8/9]\tTime 0.076 (0.091)\tData 0.056 (0.070)\tLoss 1.1526 (0.6432)\tAcc 0.438 (0.719)\n",
      "Epoch: [22][9/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.2329 (0.6369)\tAcc 1.000 (0.723)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.219 (0.219)\tData 0.191 (0.191)\tLoss 0.4465 (0.4465)\tAcc 0.812 (0.812)\n",
      "Epoch: [23][2/5]\tTime 0.077 (0.148)\tData 0.052 (0.122)\tLoss 0.8535 (0.6500)\tAcc 0.562 (0.688)\n",
      "Epoch: [23][3/5]\tTime 0.081 (0.126)\tData 0.057 (0.100)\tLoss 0.6224 (0.6408)\tAcc 0.625 (0.667)\n",
      "Epoch: [23][4/5]\tTime 0.078 (0.114)\tData 0.054 (0.089)\tLoss 0.8156 (0.6845)\tAcc 0.750 (0.688)\n",
      "Epoch: [23][5/5]\tTime 0.078 (0.107)\tData 0.055 (0.082)\tLoss 0.8119 (0.7002)\tAcc 0.556 (0.671)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.210 (0.210)\tData 0.180 (0.180)\tLoss 0.2599 (0.2599)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.078 (0.144)\tData 0.051 (0.115)\tLoss 1.0394 (0.6497)\tAcc 0.438 (0.688)\n",
      "Epoch: [23][3/9]\tTime 0.070 (0.119)\tData 0.050 (0.094)\tLoss 0.6206 (0.6400)\tAcc 0.812 (0.729)\n",
      "Epoch: [23][4/9]\tTime 0.075 (0.108)\tData 0.055 (0.084)\tLoss 0.6252 (0.6363)\tAcc 0.625 (0.703)\n",
      "Epoch: [23][5/9]\tTime 0.079 (0.102)\tData 0.059 (0.079)\tLoss 0.8539 (0.6798)\tAcc 0.688 (0.700)\n",
      "Epoch: [23][6/9]\tTime 0.080 (0.099)\tData 0.059 (0.076)\tLoss 0.2209 (0.6033)\tAcc 1.000 (0.750)\n",
      "Epoch: [23][7/9]\tTime 0.080 (0.096)\tData 0.059 (0.073)\tLoss 0.5616 (0.5974)\tAcc 0.750 (0.750)\n",
      "Epoch: [23][8/9]\tTime 0.080 (0.094)\tData 0.060 (0.072)\tLoss 1.0137 (0.6494)\tAcc 0.562 (0.727)\n",
      "Epoch: [23][9/9]\tTime 0.079 (0.092)\tData 0.059 (0.070)\tLoss 0.1295 (0.6414)\tAcc 1.000 (0.731)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.216 (0.216)\tData 0.187 (0.187)\tLoss 1.2057 (1.2057)\tAcc 0.562 (0.562)\n",
      "Epoch: [24][2/5]\tTime 0.078 (0.147)\tData 0.053 (0.120)\tLoss 0.7667 (0.9862)\tAcc 0.750 (0.656)\n",
      "Epoch: [24][3/5]\tTime 0.078 (0.124)\tData 0.054 (0.098)\tLoss 0.4280 (0.8001)\tAcc 0.875 (0.729)\n",
      "Epoch: [24][4/5]\tTime 0.078 (0.113)\tData 0.053 (0.087)\tLoss 0.9487 (0.8373)\tAcc 0.688 (0.719)\n",
      "Epoch: [24][5/5]\tTime 0.079 (0.106)\tData 0.055 (0.081)\tLoss 0.5358 (0.8001)\tAcc 0.778 (0.726)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.205 (0.205)\tData 0.175 (0.175)\tLoss 0.3654 (0.3654)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/9]\tTime 0.067 (0.136)\tData 0.045 (0.110)\tLoss 0.9386 (0.6520)\tAcc 0.438 (0.688)\n",
      "Epoch: [24][3/9]\tTime 0.070 (0.114)\tData 0.051 (0.090)\tLoss 0.6153 (0.6398)\tAcc 0.812 (0.729)\n",
      "Epoch: [24][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.6624 (0.6454)\tAcc 0.625 (0.703)\n",
      "Epoch: [24][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.7891 (0.6742)\tAcc 0.688 (0.700)\n",
      "Epoch: [24][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.3008 (0.6119)\tAcc 1.000 (0.750)\n",
      "Epoch: [24][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5999 (0.6102)\tAcc 0.688 (0.741)\n",
      "Epoch: [24][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9068 (0.6473)\tAcc 0.625 (0.727)\n",
      "Epoch: [24][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.3193 (0.6422)\tAcc 1.000 (0.731)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.200 (0.200)\tData 0.168 (0.168)\tLoss 0.8131 (0.8131)\tAcc 0.750 (0.750)\n",
      "Epoch: [25][2/5]\tTime 0.072 (0.136)\tData 0.048 (0.108)\tLoss 0.5845 (0.6988)\tAcc 0.625 (0.688)\n",
      "Epoch: [25][3/5]\tTime 0.079 (0.117)\tData 0.055 (0.090)\tLoss 0.4712 (0.6229)\tAcc 1.000 (0.792)\n",
      "Epoch: [25][4/5]\tTime 0.081 (0.108)\tData 0.057 (0.082)\tLoss 0.6626 (0.6328)\tAcc 0.750 (0.781)\n",
      "Epoch: [25][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.076)\tLoss 0.6440 (0.6342)\tAcc 0.667 (0.767)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.195 (0.195)\tData 0.165 (0.165)\tLoss 0.2514 (0.2514)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.070 (0.132)\tData 0.045 (0.105)\tLoss 0.9299 (0.5907)\tAcc 0.438 (0.688)\n",
      "Epoch: [25][3/9]\tTime 0.076 (0.114)\tData 0.056 (0.089)\tLoss 0.5660 (0.5824)\tAcc 0.875 (0.750)\n",
      "Epoch: [25][4/9]\tTime 0.078 (0.105)\tData 0.059 (0.081)\tLoss 0.6561 (0.6008)\tAcc 0.625 (0.719)\n",
      "Epoch: [25][5/9]\tTime 0.073 (0.098)\tData 0.054 (0.076)\tLoss 0.7669 (0.6341)\tAcc 0.688 (0.713)\n",
      "Epoch: [25][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.3002 (0.5784)\tAcc 1.000 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.6627 (0.5905)\tAcc 0.625 (0.741)\n",
      "Epoch: [25][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 1.0718 (0.6506)\tAcc 0.562 (0.719)\n",
      "Epoch: [25][9/9]\tTime 0.075 (0.088)\tData 0.055 (0.066)\tLoss 0.1976 (0.6437)\tAcc 1.000 (0.723)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.199 (0.199)\tData 0.167 (0.167)\tLoss 0.7447 (0.7447)\tAcc 0.750 (0.750)\n",
      "Epoch: [26][2/5]\tTime 0.072 (0.136)\tData 0.047 (0.107)\tLoss 0.5106 (0.6277)\tAcc 0.812 (0.781)\n",
      "Epoch: [26][3/5]\tTime 0.081 (0.118)\tData 0.057 (0.090)\tLoss 0.8555 (0.7036)\tAcc 0.625 (0.729)\n",
      "Epoch: [26][4/5]\tTime 0.082 (0.109)\tData 0.058 (0.082)\tLoss 0.9948 (0.7764)\tAcc 0.688 (0.719)\n",
      "Epoch: [26][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.076)\tLoss 0.4087 (0.7311)\tAcc 0.778 (0.726)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.198 (0.198)\tData 0.170 (0.170)\tLoss 0.3647 (0.3647)\tAcc 0.875 (0.875)\n",
      "Epoch: [26][2/9]\tTime 0.069 (0.134)\tData 0.046 (0.108)\tLoss 0.9668 (0.6657)\tAcc 0.438 (0.656)\n",
      "Epoch: [26][3/9]\tTime 0.070 (0.112)\tData 0.051 (0.089)\tLoss 0.6449 (0.6588)\tAcc 0.625 (0.646)\n",
      "Epoch: [26][4/9]\tTime 0.074 (0.103)\tData 0.054 (0.080)\tLoss 0.6978 (0.6685)\tAcc 0.625 (0.641)\n",
      "Epoch: [26][5/9]\tTime 0.078 (0.098)\tData 0.058 (0.076)\tLoss 0.8613 (0.7071)\tAcc 0.625 (0.637)\n",
      "Epoch: [26][6/9]\tTime 0.078 (0.095)\tData 0.058 (0.073)\tLoss 0.1965 (0.6220)\tAcc 1.000 (0.698)\n",
      "Epoch: [26][7/9]\tTime 0.072 (0.091)\tData 0.053 (0.070)\tLoss 0.5918 (0.6177)\tAcc 0.750 (0.705)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.9491 (0.6591)\tAcc 0.562 (0.688)\n",
      "Epoch: [26][9/9]\tTime 0.079 (0.088)\tData 0.060 (0.067)\tLoss 0.2104 (0.6522)\tAcc 1.000 (0.692)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.225 (0.225)\tData 0.198 (0.198)\tLoss 1.4052 (1.4052)\tAcc 0.562 (0.562)\n",
      "Epoch: [27][2/5]\tTime 0.077 (0.151)\tData 0.053 (0.125)\tLoss 0.6269 (1.0161)\tAcc 0.750 (0.656)\n",
      "Epoch: [27][3/5]\tTime 0.077 (0.127)\tData 0.053 (0.101)\tLoss 0.4791 (0.8371)\tAcc 0.812 (0.708)\n",
      "Epoch: [27][4/5]\tTime 0.077 (0.114)\tData 0.053 (0.089)\tLoss 0.7327 (0.8110)\tAcc 0.688 (0.703)\n",
      "Epoch: [27][5/5]\tTime 0.079 (0.107)\tData 0.055 (0.082)\tLoss 0.4213 (0.7630)\tAcc 0.778 (0.712)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.199 (0.199)\tData 0.172 (0.172)\tLoss 0.3172 (0.3172)\tAcc 0.938 (0.938)\n",
      "Epoch: [27][2/9]\tTime 0.070 (0.135)\tData 0.046 (0.109)\tLoss 0.9371 (0.6271)\tAcc 0.438 (0.688)\n",
      "Epoch: [27][3/9]\tTime 0.071 (0.113)\tData 0.052 (0.090)\tLoss 0.6076 (0.6206)\tAcc 0.750 (0.708)\n",
      "Epoch: [27][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6605 (0.6306)\tAcc 0.625 (0.688)\n",
      "Epoch: [27][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.076)\tLoss 0.8302 (0.6705)\tAcc 0.625 (0.675)\n",
      "Epoch: [27][6/9]\tTime 0.073 (0.094)\tData 0.053 (0.072)\tLoss 0.2630 (0.6026)\tAcc 1.000 (0.729)\n",
      "Epoch: [27][7/9]\tTime 0.083 (0.092)\tData 0.063 (0.071)\tLoss 0.6815 (0.6139)\tAcc 0.688 (0.723)\n",
      "Epoch: [27][8/9]\tTime 0.088 (0.092)\tData 0.068 (0.070)\tLoss 0.9943 (0.6614)\tAcc 0.625 (0.711)\n",
      "Epoch: [27][9/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.2366 (0.6549)\tAcc 1.000 (0.715)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.7520 (0.7520)\tAcc 0.562 (0.562)\n",
      "Epoch: [28][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.3462 (0.5491)\tAcc 0.875 (0.719)\n",
      "Epoch: [28][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.093)\tLoss 0.8087 (0.6356)\tAcc 0.562 (0.667)\n",
      "Epoch: [28][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.9546 (0.7154)\tAcc 0.562 (0.641)\n",
      "Epoch: [28][5/5]\tTime 0.077 (0.102)\tData 0.053 (0.078)\tLoss 0.3742 (0.6733)\tAcc 0.889 (0.671)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.248 (0.248)\tData 0.202 (0.202)\tLoss 0.3050 (0.3050)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/9]\tTime 0.056 (0.152)\tData 0.029 (0.115)\tLoss 1.0405 (0.6728)\tAcc 0.438 (0.688)\n",
      "Epoch: [28][3/9]\tTime 0.069 (0.124)\tData 0.049 (0.093)\tLoss 0.5830 (0.6428)\tAcc 0.812 (0.729)\n",
      "Epoch: [28][4/9]\tTime 0.073 (0.112)\tData 0.053 (0.083)\tLoss 0.6161 (0.6362)\tAcc 0.625 (0.703)\n",
      "Epoch: [28][5/9]\tTime 0.073 (0.104)\tData 0.053 (0.077)\tLoss 0.7977 (0.6685)\tAcc 0.812 (0.725)\n",
      "Epoch: [28][6/9]\tTime 0.074 (0.099)\tData 0.055 (0.074)\tLoss 0.2694 (0.6020)\tAcc 1.000 (0.771)\n",
      "Epoch: [28][7/9]\tTime 0.073 (0.095)\tData 0.054 (0.071)\tLoss 0.5977 (0.6014)\tAcc 0.688 (0.759)\n",
      "Epoch: [28][8/9]\tTime 0.073 (0.093)\tData 0.053 (0.069)\tLoss 1.0140 (0.6529)\tAcc 0.688 (0.750)\n",
      "Epoch: [28][9/9]\tTime 0.073 (0.090)\tData 0.053 (0.067)\tLoss 0.1516 (0.6452)\tAcc 1.000 (0.754)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.300 (0.300)\tData 0.248 (0.248)\tLoss 0.7748 (0.7748)\tAcc 0.750 (0.750)\n",
      "Epoch: [29][2/5]\tTime 0.055 (0.177)\tData 0.029 (0.138)\tLoss 0.5902 (0.6825)\tAcc 0.812 (0.781)\n",
      "Epoch: [29][3/5]\tTime 0.079 (0.145)\tData 0.054 (0.110)\tLoss 0.7784 (0.7145)\tAcc 0.562 (0.708)\n",
      "Epoch: [29][4/5]\tTime 0.082 (0.129)\tData 0.056 (0.096)\tLoss 0.8007 (0.7360)\tAcc 0.625 (0.688)\n",
      "Epoch: [29][5/5]\tTime 0.077 (0.119)\tData 0.052 (0.088)\tLoss 0.5728 (0.7159)\tAcc 0.889 (0.712)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.254 (0.254)\tData 0.213 (0.213)\tLoss 0.3064 (0.3064)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.070 (0.162)\tData 0.033 (0.123)\tLoss 1.0506 (0.6785)\tAcc 0.438 (0.688)\n",
      "Epoch: [29][3/9]\tTime 0.073 (0.132)\tData 0.049 (0.098)\tLoss 0.6826 (0.6798)\tAcc 0.750 (0.708)\n",
      "Epoch: [29][4/9]\tTime 0.075 (0.118)\tData 0.054 (0.087)\tLoss 0.5828 (0.6556)\tAcc 0.688 (0.703)\n",
      "Epoch: [29][5/9]\tTime 0.073 (0.109)\tData 0.053 (0.080)\tLoss 0.8003 (0.6845)\tAcc 0.750 (0.713)\n",
      "Epoch: [29][6/9]\tTime 0.073 (0.103)\tData 0.053 (0.076)\tLoss 0.2632 (0.6143)\tAcc 1.000 (0.760)\n",
      "Epoch: [29][7/9]\tTime 0.078 (0.099)\tData 0.057 (0.073)\tLoss 0.5722 (0.6083)\tAcc 0.688 (0.750)\n",
      "Epoch: [29][8/9]\tTime 0.075 (0.096)\tData 0.054 (0.071)\tLoss 1.0693 (0.6659)\tAcc 0.562 (0.727)\n",
      "Epoch: [29][9/9]\tTime 0.076 (0.094)\tData 0.053 (0.069)\tLoss 0.2480 (0.6595)\tAcc 1.000 (0.731)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.282 (0.282)\tData 0.250 (0.250)\tLoss 0.5306 (0.5306)\tAcc 0.812 (0.812)\n",
      "Epoch: [30][2/5]\tTime 0.076 (0.179)\tData 0.050 (0.150)\tLoss 0.6529 (0.5917)\tAcc 0.812 (0.812)\n",
      "Epoch: [30][3/5]\tTime 0.080 (0.146)\tData 0.054 (0.118)\tLoss 1.0608 (0.7481)\tAcc 0.500 (0.708)\n",
      "Epoch: [30][4/5]\tTime 0.078 (0.129)\tData 0.052 (0.102)\tLoss 0.4602 (0.6761)\tAcc 0.812 (0.734)\n",
      "Epoch: [30][5/5]\tTime 0.087 (0.121)\tData 0.056 (0.092)\tLoss 0.7557 (0.6859)\tAcc 0.667 (0.726)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.251 (0.251)\tData 0.207 (0.207)\tLoss 0.2839 (0.2839)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/9]\tTime 0.107 (0.179)\tData 0.034 (0.121)\tLoss 0.9625 (0.6232)\tAcc 0.500 (0.719)\n",
      "Epoch: [30][3/9]\tTime 0.048 (0.135)\tData 0.005 (0.082)\tLoss 0.6209 (0.6224)\tAcc 0.812 (0.750)\n",
      "Epoch: [30][4/9]\tTime 0.056 (0.115)\tData 0.035 (0.070)\tLoss 0.5907 (0.6145)\tAcc 0.625 (0.719)\n",
      "Epoch: [30][5/9]\tTime 0.073 (0.107)\tData 0.052 (0.067)\tLoss 0.7694 (0.6455)\tAcc 0.750 (0.725)\n",
      "Epoch: [30][6/9]\tTime 0.078 (0.102)\tData 0.057 (0.065)\tLoss 0.2889 (0.5860)\tAcc 1.000 (0.771)\n",
      "Epoch: [30][7/9]\tTime 0.075 (0.098)\tData 0.053 (0.064)\tLoss 0.5670 (0.5833)\tAcc 0.750 (0.768)\n",
      "Epoch: [30][8/9]\tTime 0.073 (0.095)\tData 0.053 (0.062)\tLoss 0.9033 (0.6233)\tAcc 0.562 (0.742)\n",
      "Epoch: [30][9/9]\tTime 0.078 (0.093)\tData 0.058 (0.062)\tLoss 0.1647 (0.6162)\tAcc 1.000 (0.746)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.249 (0.249)\tData 0.207 (0.207)\tLoss 0.8254 (0.8254)\tAcc 0.812 (0.812)\n",
      "Epoch: [31][2/5]\tTime 0.067 (0.158)\tData 0.041 (0.124)\tLoss 0.6475 (0.7364)\tAcc 0.688 (0.750)\n",
      "Epoch: [31][3/5]\tTime 0.077 (0.131)\tData 0.052 (0.100)\tLoss 0.5041 (0.6590)\tAcc 0.875 (0.792)\n",
      "Epoch: [31][4/5]\tTime 0.078 (0.118)\tData 0.053 (0.088)\tLoss 0.7934 (0.6926)\tAcc 0.625 (0.750)\n",
      "Epoch: [31][5/5]\tTime 0.083 (0.111)\tData 0.058 (0.082)\tLoss 0.4898 (0.6676)\tAcc 0.889 (0.767)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.246 (0.246)\tData 0.220 (0.220)\tLoss 0.4097 (0.4097)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.071 (0.158)\tData 0.049 (0.135)\tLoss 1.0050 (0.7074)\tAcc 0.438 (0.688)\n",
      "Epoch: [31][3/9]\tTime 0.072 (0.129)\tData 0.052 (0.107)\tLoss 0.6081 (0.6743)\tAcc 0.812 (0.729)\n",
      "Epoch: [31][4/9]\tTime 0.073 (0.115)\tData 0.053 (0.094)\tLoss 0.6439 (0.6667)\tAcc 0.625 (0.703)\n",
      "Epoch: [31][5/9]\tTime 0.073 (0.107)\tData 0.053 (0.086)\tLoss 0.6455 (0.6624)\tAcc 0.750 (0.713)\n",
      "Epoch: [31][6/9]\tTime 0.073 (0.101)\tData 0.053 (0.080)\tLoss 0.2344 (0.5911)\tAcc 1.000 (0.760)\n",
      "Epoch: [31][7/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.6559 (0.6003)\tAcc 0.625 (0.741)\n",
      "Epoch: [31][8/9]\tTime 0.073 (0.094)\tData 0.053 (0.074)\tLoss 0.9324 (0.6419)\tAcc 0.688 (0.734)\n",
      "Epoch: [31][9/9]\tTime 0.073 (0.092)\tData 0.053 (0.071)\tLoss 0.2033 (0.6351)\tAcc 1.000 (0.738)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.256 (0.256)\tData 0.224 (0.224)\tLoss 0.7821 (0.7821)\tAcc 0.625 (0.625)\n",
      "Epoch: [32][2/5]\tTime 0.084 (0.170)\tData 0.054 (0.139)\tLoss 0.5810 (0.6816)\tAcc 0.688 (0.656)\n",
      "Epoch: [32][3/5]\tTime 0.084 (0.141)\tData 0.054 (0.111)\tLoss 0.7011 (0.6881)\tAcc 0.688 (0.667)\n",
      "Epoch: [32][4/5]\tTime 0.076 (0.125)\tData 0.052 (0.096)\tLoss 0.6069 (0.6678)\tAcc 0.750 (0.688)\n",
      "Epoch: [32][5/5]\tTime 0.077 (0.115)\tData 0.054 (0.088)\tLoss 0.8255 (0.6872)\tAcc 0.667 (0.685)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.260 (0.260)\tData 0.232 (0.232)\tLoss 0.3502 (0.3502)\tAcc 0.875 (0.875)\n",
      "Epoch: [32][2/9]\tTime 0.079 (0.169)\tData 0.056 (0.144)\tLoss 0.9587 (0.6544)\tAcc 0.500 (0.688)\n",
      "Epoch: [32][3/9]\tTime 0.076 (0.138)\tData 0.055 (0.115)\tLoss 0.5753 (0.6281)\tAcc 0.750 (0.708)\n",
      "Epoch: [32][4/9]\tTime 0.074 (0.122)\tData 0.054 (0.099)\tLoss 0.5313 (0.6039)\tAcc 0.688 (0.703)\n",
      "Epoch: [32][5/9]\tTime 0.073 (0.112)\tData 0.053 (0.090)\tLoss 0.8284 (0.6488)\tAcc 0.688 (0.700)\n",
      "Epoch: [32][6/9]\tTime 0.074 (0.106)\tData 0.054 (0.084)\tLoss 0.2674 (0.5852)\tAcc 1.000 (0.750)\n",
      "Epoch: [32][7/9]\tTime 0.074 (0.101)\tData 0.054 (0.080)\tLoss 0.6044 (0.5879)\tAcc 0.750 (0.750)\n",
      "Epoch: [32][8/9]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.8907 (0.6258)\tAcc 0.688 (0.742)\n",
      "Epoch: [32][9/9]\tTime 0.075 (0.095)\tData 0.054 (0.074)\tLoss 0.2351 (0.6198)\tAcc 1.000 (0.746)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.208 (0.208)\tData 0.178 (0.178)\tLoss 0.8740 (0.8740)\tAcc 0.688 (0.688)\n",
      "Epoch: [33][2/5]\tTime 0.073 (0.141)\tData 0.049 (0.113)\tLoss 0.5367 (0.7053)\tAcc 0.750 (0.719)\n",
      "Epoch: [33][3/5]\tTime 0.078 (0.120)\tData 0.053 (0.093)\tLoss 0.7320 (0.7142)\tAcc 0.688 (0.708)\n",
      "Epoch: [33][4/5]\tTime 0.078 (0.109)\tData 0.053 (0.083)\tLoss 0.6938 (0.7091)\tAcc 0.750 (0.719)\n",
      "Epoch: [33][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.077)\tLoss 0.7090 (0.7091)\tAcc 0.778 (0.726)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.218 (0.218)\tData 0.194 (0.194)\tLoss 0.3415 (0.3415)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.077 (0.148)\tData 0.051 (0.122)\tLoss 0.9964 (0.6690)\tAcc 0.438 (0.688)\n",
      "Epoch: [33][3/9]\tTime 0.066 (0.121)\tData 0.047 (0.097)\tLoss 0.5888 (0.6422)\tAcc 0.875 (0.750)\n",
      "Epoch: [33][4/9]\tTime 0.077 (0.110)\tData 0.057 (0.087)\tLoss 0.5819 (0.6272)\tAcc 0.688 (0.734)\n",
      "Epoch: [33][5/9]\tTime 0.080 (0.104)\tData 0.060 (0.082)\tLoss 0.6032 (0.6224)\tAcc 0.812 (0.750)\n",
      "Epoch: [33][6/9]\tTime 0.077 (0.099)\tData 0.057 (0.078)\tLoss 0.3016 (0.5689)\tAcc 1.000 (0.792)\n",
      "Epoch: [33][7/9]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.6720 (0.5836)\tAcc 0.750 (0.786)\n",
      "Epoch: [33][8/9]\tTime 0.077 (0.093)\tData 0.057 (0.072)\tLoss 0.9361 (0.6277)\tAcc 0.625 (0.766)\n",
      "Epoch: [33][9/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.2264 (0.6215)\tAcc 1.000 (0.769)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.361 (0.361)\tData 0.330 (0.330)\tLoss 0.4442 (0.4442)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][2/5]\tTime 0.074 (0.218)\tData 0.049 (0.190)\tLoss 0.6602 (0.5522)\tAcc 0.875 (0.812)\n",
      "Epoch: [34][3/5]\tTime 0.078 (0.171)\tData 0.054 (0.145)\tLoss 0.8597 (0.6547)\tAcc 0.562 (0.729)\n",
      "Epoch: [34][4/5]\tTime 0.079 (0.148)\tData 0.055 (0.122)\tLoss 0.6692 (0.6583)\tAcc 0.750 (0.734)\n",
      "Epoch: [34][5/5]\tTime 0.077 (0.134)\tData 0.053 (0.108)\tLoss 0.7051 (0.6641)\tAcc 0.667 (0.726)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.2665 (0.2665)\tAcc 0.938 (0.938)\n",
      "Epoch: [34][2/9]\tTime 0.070 (0.133)\tData 0.048 (0.109)\tLoss 0.9875 (0.6270)\tAcc 0.562 (0.750)\n",
      "Epoch: [34][3/9]\tTime 0.072 (0.113)\tData 0.052 (0.090)\tLoss 0.6406 (0.6316)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][4/9]\tTime 0.079 (0.104)\tData 0.059 (0.082)\tLoss 0.7193 (0.6535)\tAcc 0.625 (0.719)\n",
      "Epoch: [34][5/9]\tTime 0.080 (0.099)\tData 0.060 (0.078)\tLoss 0.6855 (0.6599)\tAcc 0.750 (0.725)\n",
      "Epoch: [34][6/9]\tTime 0.079 (0.096)\tData 0.060 (0.075)\tLoss 0.2576 (0.5928)\tAcc 1.000 (0.771)\n",
      "Epoch: [34][7/9]\tTime 0.078 (0.093)\tData 0.059 (0.073)\tLoss 0.7416 (0.6141)\tAcc 0.750 (0.768)\n",
      "Epoch: [34][8/9]\tTime 0.078 (0.092)\tData 0.059 (0.071)\tLoss 1.1086 (0.6759)\tAcc 0.625 (0.750)\n",
      "Epoch: [34][9/9]\tTime 0.078 (0.090)\tData 0.060 (0.070)\tLoss 0.2391 (0.6692)\tAcc 1.000 (0.754)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.212 (0.212)\tData 0.180 (0.180)\tLoss 0.5323 (0.5323)\tAcc 0.812 (0.812)\n",
      "Epoch: [35][2/5]\tTime 0.077 (0.145)\tData 0.053 (0.116)\tLoss 0.8278 (0.6801)\tAcc 0.625 (0.719)\n",
      "Epoch: [35][3/5]\tTime 0.083 (0.124)\tData 0.059 (0.097)\tLoss 0.5151 (0.6251)\tAcc 0.750 (0.729)\n",
      "Epoch: [35][4/5]\tTime 0.082 (0.114)\tData 0.058 (0.087)\tLoss 0.4867 (0.5905)\tAcc 0.688 (0.719)\n",
      "Epoch: [35][5/5]\tTime 0.083 (0.108)\tData 0.059 (0.082)\tLoss 0.9347 (0.6329)\tAcc 0.778 (0.726)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.3554 (0.3554)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/9]\tTime 0.066 (0.132)\tData 0.044 (0.105)\tLoss 1.0290 (0.6922)\tAcc 0.438 (0.688)\n",
      "Epoch: [35][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.088)\tLoss 0.5989 (0.6611)\tAcc 0.750 (0.708)\n",
      "Epoch: [35][4/9]\tTime 0.073 (0.102)\tData 0.053 (0.079)\tLoss 0.5377 (0.6303)\tAcc 0.688 (0.703)\n",
      "Epoch: [35][5/9]\tTime 0.073 (0.096)\tData 0.053 (0.074)\tLoss 0.8758 (0.6794)\tAcc 0.625 (0.688)\n",
      "Epoch: [35][6/9]\tTime 0.073 (0.092)\tData 0.053 (0.071)\tLoss 0.2829 (0.6133)\tAcc 1.000 (0.740)\n",
      "Epoch: [35][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.5743 (0.6077)\tAcc 0.750 (0.741)\n",
      "Epoch: [35][8/9]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 0.9537 (0.6510)\tAcc 0.688 (0.734)\n",
      "Epoch: [35][9/9]\tTime 0.075 (0.086)\tData 0.055 (0.065)\tLoss 0.3099 (0.6457)\tAcc 1.000 (0.738)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.198 (0.198)\tData 0.167 (0.167)\tLoss 0.4415 (0.4415)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/5]\tTime 0.081 (0.139)\tData 0.057 (0.112)\tLoss 0.9034 (0.6725)\tAcc 0.625 (0.781)\n",
      "Epoch: [36][3/5]\tTime 0.083 (0.120)\tData 0.059 (0.094)\tLoss 0.7161 (0.6870)\tAcc 0.750 (0.771)\n",
      "Epoch: [36][4/5]\tTime 0.083 (0.111)\tData 0.059 (0.086)\tLoss 0.5982 (0.6648)\tAcc 0.812 (0.781)\n",
      "Epoch: [36][5/5]\tTime 0.084 (0.106)\tData 0.061 (0.081)\tLoss 0.6951 (0.6685)\tAcc 0.667 (0.767)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.215 (0.215)\tData 0.178 (0.178)\tLoss 0.3614 (0.3614)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/9]\tTime 0.080 (0.148)\tData 0.053 (0.115)\tLoss 0.9003 (0.6309)\tAcc 0.625 (0.781)\n",
      "Epoch: [36][3/9]\tTime 0.070 (0.122)\tData 0.051 (0.094)\tLoss 0.6737 (0.6451)\tAcc 0.625 (0.729)\n",
      "Epoch: [36][4/9]\tTime 0.078 (0.111)\tData 0.059 (0.085)\tLoss 0.6630 (0.6496)\tAcc 0.688 (0.719)\n",
      "Epoch: [36][5/9]\tTime 0.078 (0.104)\tData 0.059 (0.080)\tLoss 0.8825 (0.6962)\tAcc 0.688 (0.713)\n",
      "Epoch: [36][6/9]\tTime 0.088 (0.102)\tData 0.068 (0.078)\tLoss 0.3523 (0.6389)\tAcc 0.938 (0.750)\n",
      "Epoch: [36][7/9]\tTime 0.080 (0.098)\tData 0.060 (0.075)\tLoss 0.6860 (0.6456)\tAcc 0.688 (0.741)\n",
      "Epoch: [36][8/9]\tTime 0.079 (0.096)\tData 0.059 (0.073)\tLoss 0.9212 (0.6800)\tAcc 0.625 (0.727)\n",
      "Epoch: [36][9/9]\tTime 0.077 (0.094)\tData 0.058 (0.072)\tLoss 0.2204 (0.6730)\tAcc 1.000 (0.731)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.3874 (0.3874)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.110)\tLoss 0.9504 (0.6689)\tAcc 0.688 (0.812)\n",
      "Epoch: [37][3/5]\tTime 0.081 (0.118)\tData 0.056 (0.092)\tLoss 0.7921 (0.7100)\tAcc 0.750 (0.792)\n",
      "Epoch: [37][4/5]\tTime 0.084 (0.110)\tData 0.060 (0.084)\tLoss 0.7349 (0.7162)\tAcc 0.688 (0.766)\n",
      "Epoch: [37][5/5]\tTime 0.082 (0.104)\tData 0.058 (0.079)\tLoss 0.7795 (0.7240)\tAcc 0.667 (0.753)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.199 (0.199)\tData 0.171 (0.171)\tLoss 0.3136 (0.3136)\tAcc 0.875 (0.875)\n",
      "Epoch: [37][2/9]\tTime 0.069 (0.134)\tData 0.047 (0.109)\tLoss 0.9177 (0.6156)\tAcc 0.688 (0.781)\n",
      "Epoch: [37][3/9]\tTime 0.073 (0.114)\tData 0.053 (0.091)\tLoss 0.6880 (0.6398)\tAcc 0.750 (0.771)\n",
      "Epoch: [37][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.5693 (0.6221)\tAcc 0.812 (0.781)\n",
      "Epoch: [37][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.8606 (0.6698)\tAcc 0.688 (0.762)\n",
      "Epoch: [37][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.2706 (0.6033)\tAcc 1.000 (0.802)\n",
      "Epoch: [37][7/9]\tTime 0.076 (0.091)\tData 0.056 (0.070)\tLoss 0.5818 (0.6002)\tAcc 0.688 (0.786)\n",
      "Epoch: [37][8/9]\tTime 0.079 (0.090)\tData 0.060 (0.069)\tLoss 0.9778 (0.6474)\tAcc 0.438 (0.742)\n",
      "Epoch: [37][9/9]\tTime 0.079 (0.089)\tData 0.059 (0.068)\tLoss 0.2296 (0.6410)\tAcc 1.000 (0.746)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.229 (0.229)\tData 0.199 (0.199)\tLoss 0.5489 (0.5489)\tAcc 0.812 (0.812)\n",
      "Epoch: [38][2/5]\tTime 0.081 (0.155)\tData 0.056 (0.128)\tLoss 0.7715 (0.6602)\tAcc 0.812 (0.812)\n",
      "Epoch: [38][3/5]\tTime 0.085 (0.132)\tData 0.060 (0.105)\tLoss 0.6939 (0.6714)\tAcc 0.750 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.086 (0.120)\tData 0.061 (0.094)\tLoss 0.4705 (0.6212)\tAcc 0.750 (0.781)\n",
      "Epoch: [38][5/5]\tTime 0.084 (0.113)\tData 0.060 (0.087)\tLoss 0.5350 (0.6106)\tAcc 0.889 (0.795)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.206 (0.206)\tData 0.174 (0.174)\tLoss 0.3019 (0.3019)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.066 (0.136)\tData 0.043 (0.109)\tLoss 0.9381 (0.6200)\tAcc 0.750 (0.844)\n",
      "Epoch: [38][3/9]\tTime 0.073 (0.115)\tData 0.053 (0.090)\tLoss 0.6139 (0.6180)\tAcc 0.688 (0.792)\n",
      "Epoch: [38][4/9]\tTime 0.076 (0.105)\tData 0.056 (0.082)\tLoss 0.6007 (0.6136)\tAcc 0.875 (0.812)\n",
      "Epoch: [38][5/9]\tTime 0.075 (0.099)\tData 0.055 (0.076)\tLoss 0.8913 (0.6692)\tAcc 0.625 (0.775)\n",
      "Epoch: [38][6/9]\tTime 0.076 (0.095)\tData 0.056 (0.073)\tLoss 0.2671 (0.6022)\tAcc 1.000 (0.812)\n",
      "Epoch: [38][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.070)\tLoss 0.6624 (0.6108)\tAcc 0.688 (0.795)\n",
      "Epoch: [38][8/9]\tTime 0.077 (0.090)\tData 0.057 (0.068)\tLoss 0.8910 (0.6458)\tAcc 0.562 (0.766)\n",
      "Epoch: [38][9/9]\tTime 0.079 (0.089)\tData 0.059 (0.067)\tLoss 0.0855 (0.6372)\tAcc 1.000 (0.769)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.213 (0.213)\tData 0.181 (0.181)\tLoss 0.8595 (0.8595)\tAcc 0.625 (0.625)\n",
      "Epoch: [39][2/5]\tTime 0.084 (0.149)\tData 0.059 (0.120)\tLoss 0.3885 (0.6240)\tAcc 0.812 (0.719)\n",
      "Epoch: [39][3/5]\tTime 0.083 (0.127)\tData 0.059 (0.100)\tLoss 0.7986 (0.6822)\tAcc 0.750 (0.729)\n",
      "Epoch: [39][4/5]\tTime 0.084 (0.116)\tData 0.059 (0.090)\tLoss 0.6676 (0.6785)\tAcc 0.812 (0.750)\n",
      "Epoch: [39][5/5]\tTime 0.083 (0.109)\tData 0.059 (0.084)\tLoss 0.6494 (0.6749)\tAcc 0.778 (0.753)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.204 (0.204)\tData 0.167 (0.167)\tLoss 0.3194 (0.3194)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/9]\tTime 0.068 (0.136)\tData 0.044 (0.105)\tLoss 0.9225 (0.6209)\tAcc 0.562 (0.750)\n",
      "Epoch: [39][3/9]\tTime 0.076 (0.116)\tData 0.055 (0.089)\tLoss 0.6314 (0.6244)\tAcc 0.688 (0.729)\n",
      "Epoch: [39][4/9]\tTime 0.080 (0.107)\tData 0.060 (0.081)\tLoss 0.5621 (0.6088)\tAcc 0.812 (0.750)\n",
      "Epoch: [39][5/9]\tTime 0.080 (0.101)\tData 0.060 (0.077)\tLoss 0.7452 (0.6361)\tAcc 0.750 (0.750)\n",
      "Epoch: [39][6/9]\tTime 0.080 (0.098)\tData 0.060 (0.074)\tLoss 0.2822 (0.5771)\tAcc 1.000 (0.792)\n",
      "Epoch: [39][7/9]\tTime 0.081 (0.095)\tData 0.060 (0.072)\tLoss 0.6092 (0.5817)\tAcc 0.750 (0.786)\n",
      "Epoch: [39][8/9]\tTime 0.081 (0.094)\tData 0.061 (0.071)\tLoss 0.9826 (0.6318)\tAcc 0.562 (0.758)\n",
      "Epoch: [39][9/9]\tTime 0.079 (0.092)\tData 0.059 (0.070)\tLoss 0.1376 (0.6242)\tAcc 1.000 (0.762)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.209 (0.209)\tData 0.181 (0.181)\tLoss 0.4882 (0.4882)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/5]\tTime 0.080 (0.145)\tData 0.056 (0.118)\tLoss 0.7449 (0.6166)\tAcc 0.688 (0.812)\n",
      "Epoch: [40][3/5]\tTime 0.082 (0.124)\tData 0.058 (0.098)\tLoss 0.6467 (0.6266)\tAcc 0.812 (0.812)\n",
      "Epoch: [40][4/5]\tTime 0.078 (0.112)\tData 0.055 (0.087)\tLoss 0.6380 (0.6295)\tAcc 0.688 (0.781)\n",
      "Epoch: [40][5/5]\tTime 0.084 (0.107)\tData 0.060 (0.082)\tLoss 0.7407 (0.6432)\tAcc 0.778 (0.781)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.232 (0.232)\tData 0.203 (0.203)\tLoss 0.3638 (0.3638)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/9]\tTime 0.073 (0.152)\tData 0.051 (0.127)\tLoss 0.9768 (0.6703)\tAcc 0.562 (0.750)\n",
      "Epoch: [40][3/9]\tTime 0.077 (0.127)\tData 0.056 (0.103)\tLoss 0.5927 (0.6444)\tAcc 0.812 (0.771)\n",
      "Epoch: [40][4/9]\tTime 0.077 (0.115)\tData 0.057 (0.092)\tLoss 0.6058 (0.6348)\tAcc 0.625 (0.734)\n",
      "Epoch: [40][5/9]\tTime 0.078 (0.107)\tData 0.059 (0.085)\tLoss 0.8769 (0.6832)\tAcc 0.750 (0.738)\n",
      "Epoch: [40][6/9]\tTime 0.079 (0.103)\tData 0.060 (0.081)\tLoss 0.2855 (0.6169)\tAcc 1.000 (0.781)\n",
      "Epoch: [40][7/9]\tTime 0.079 (0.099)\tData 0.059 (0.078)\tLoss 0.6115 (0.6161)\tAcc 0.750 (0.777)\n",
      "Epoch: [40][8/9]\tTime 0.079 (0.097)\tData 0.060 (0.076)\tLoss 1.0232 (0.6670)\tAcc 0.688 (0.766)\n",
      "Epoch: [40][9/9]\tTime 0.079 (0.095)\tData 0.060 (0.074)\tLoss 0.4045 (0.6630)\tAcc 1.000 (0.769)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.8510 (0.8510)\tAcc 0.688 (0.688)\n",
      "Epoch: [41][2/5]\tTime 0.077 (0.139)\tData 0.052 (0.113)\tLoss 0.5795 (0.7153)\tAcc 0.875 (0.781)\n",
      "Epoch: [41][3/5]\tTime 0.082 (0.120)\tData 0.058 (0.095)\tLoss 0.6841 (0.7049)\tAcc 0.750 (0.771)\n",
      "Epoch: [41][4/5]\tTime 0.078 (0.110)\tData 0.055 (0.085)\tLoss 0.3918 (0.6266)\tAcc 0.812 (0.781)\n",
      "Epoch: [41][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 0.5745 (0.6202)\tAcc 0.667 (0.767)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.204 (0.204)\tData 0.179 (0.179)\tLoss 0.2999 (0.2999)\tAcc 0.938 (0.938)\n",
      "Epoch: [41][2/9]\tTime 0.075 (0.139)\tData 0.050 (0.114)\tLoss 1.0073 (0.6536)\tAcc 0.438 (0.688)\n",
      "Epoch: [41][3/9]\tTime 0.068 (0.116)\tData 0.049 (0.092)\tLoss 0.5457 (0.6176)\tAcc 0.875 (0.750)\n",
      "Epoch: [41][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.083)\tLoss 0.5936 (0.6116)\tAcc 0.625 (0.719)\n",
      "Epoch: [41][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.5975 (0.6088)\tAcc 0.812 (0.738)\n",
      "Epoch: [41][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.2570 (0.5502)\tAcc 1.000 (0.781)\n",
      "Epoch: [41][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.6274 (0.5612)\tAcc 0.688 (0.768)\n",
      "Epoch: [41][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.8025 (0.5914)\tAcc 0.750 (0.766)\n",
      "Epoch: [41][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.1876 (0.5852)\tAcc 1.000 (0.769)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.200 (0.200)\tData 0.169 (0.169)\tLoss 0.3674 (0.3674)\tAcc 0.812 (0.812)\n",
      "Epoch: [42][2/5]\tTime 0.073 (0.136)\tData 0.048 (0.109)\tLoss 0.8061 (0.5868)\tAcc 0.750 (0.781)\n",
      "Epoch: [42][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.090)\tLoss 0.6338 (0.6024)\tAcc 0.875 (0.812)\n",
      "Epoch: [42][4/5]\tTime 0.080 (0.108)\tData 0.055 (0.082)\tLoss 0.9328 (0.6850)\tAcc 0.625 (0.766)\n",
      "Epoch: [42][5/5]\tTime 0.077 (0.102)\tData 0.053 (0.076)\tLoss 0.5790 (0.6719)\tAcc 0.778 (0.767)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.223 (0.223)\tData 0.193 (0.193)\tLoss 0.2723 (0.2723)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/9]\tTime 0.072 (0.148)\tData 0.046 (0.119)\tLoss 0.9542 (0.6133)\tAcc 0.500 (0.719)\n",
      "Epoch: [42][3/9]\tTime 0.069 (0.121)\tData 0.049 (0.096)\tLoss 0.5964 (0.6077)\tAcc 0.750 (0.729)\n",
      "Epoch: [42][4/9]\tTime 0.074 (0.110)\tData 0.055 (0.086)\tLoss 0.6267 (0.6124)\tAcc 0.625 (0.703)\n",
      "Epoch: [42][5/9]\tTime 0.073 (0.102)\tData 0.054 (0.079)\tLoss 0.6904 (0.6280)\tAcc 0.812 (0.725)\n",
      "Epoch: [42][6/9]\tTime 0.073 (0.097)\tData 0.054 (0.075)\tLoss 0.2909 (0.5718)\tAcc 1.000 (0.771)\n",
      "Epoch: [42][7/9]\tTime 0.074 (0.094)\tData 0.055 (0.072)\tLoss 0.6033 (0.5763)\tAcc 0.688 (0.759)\n",
      "Epoch: [42][8/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.8529 (0.6109)\tAcc 0.688 (0.750)\n",
      "Epoch: [42][9/9]\tTime 0.073 (0.089)\tData 0.055 (0.068)\tLoss 0.4297 (0.6081)\tAcc 1.000 (0.754)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.205 (0.205)\tData 0.177 (0.177)\tLoss 0.6851 (0.6851)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][2/5]\tTime 0.075 (0.140)\tData 0.051 (0.114)\tLoss 0.8073 (0.7462)\tAcc 0.562 (0.625)\n",
      "Epoch: [43][3/5]\tTime 0.077 (0.119)\tData 0.053 (0.094)\tLoss 0.6236 (0.7053)\tAcc 0.688 (0.646)\n",
      "Epoch: [43][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.5438 (0.6650)\tAcc 0.875 (0.703)\n",
      "Epoch: [43][5/5]\tTime 0.077 (0.102)\tData 0.053 (0.078)\tLoss 0.6285 (0.6605)\tAcc 0.889 (0.726)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.199 (0.199)\tData 0.168 (0.168)\tLoss 0.2985 (0.2985)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/9]\tTime 0.076 (0.137)\tData 0.050 (0.109)\tLoss 0.9202 (0.6093)\tAcc 0.438 (0.688)\n",
      "Epoch: [43][3/9]\tTime 0.069 (0.115)\tData 0.049 (0.089)\tLoss 0.5973 (0.6053)\tAcc 0.875 (0.750)\n",
      "Epoch: [43][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.080)\tLoss 0.6672 (0.6208)\tAcc 0.688 (0.734)\n",
      "Epoch: [43][5/9]\tTime 0.073 (0.098)\tData 0.054 (0.075)\tLoss 0.6297 (0.6226)\tAcc 0.812 (0.750)\n",
      "Epoch: [43][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.071)\tLoss 0.3102 (0.5705)\tAcc 1.000 (0.792)\n",
      "Epoch: [43][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.6877 (0.5873)\tAcc 0.750 (0.786)\n",
      "Epoch: [43][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.067)\tLoss 0.9311 (0.6302)\tAcc 0.625 (0.766)\n",
      "Epoch: [43][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.3358 (0.6257)\tAcc 1.000 (0.769)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.215 (0.215)\tData 0.187 (0.187)\tLoss 0.6791 (0.6791)\tAcc 0.750 (0.750)\n",
      "Epoch: [44][2/5]\tTime 0.075 (0.145)\tData 0.051 (0.119)\tLoss 0.9456 (0.8124)\tAcc 0.562 (0.656)\n",
      "Epoch: [44][3/5]\tTime 0.077 (0.122)\tData 0.054 (0.097)\tLoss 0.7022 (0.7756)\tAcc 0.750 (0.688)\n",
      "Epoch: [44][4/5]\tTime 0.078 (0.111)\tData 0.054 (0.086)\tLoss 0.5619 (0.7222)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][5/5]\tTime 0.077 (0.104)\tData 0.054 (0.080)\tLoss 0.6839 (0.7175)\tAcc 0.778 (0.699)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.212 (0.212)\tData 0.167 (0.167)\tLoss 0.4205 (0.4205)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.053 (0.133)\tData 0.031 (0.099)\tLoss 0.9497 (0.6851)\tAcc 0.375 (0.656)\n",
      "Epoch: [44][3/9]\tTime 0.071 (0.112)\tData 0.052 (0.083)\tLoss 0.8051 (0.7251)\tAcc 0.750 (0.688)\n",
      "Epoch: [44][4/9]\tTime 0.075 (0.103)\tData 0.056 (0.076)\tLoss 0.6306 (0.7015)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][5/9]\tTime 0.075 (0.097)\tData 0.055 (0.072)\tLoss 0.8320 (0.7276)\tAcc 0.750 (0.700)\n",
      "Epoch: [44][6/9]\tTime 0.074 (0.093)\tData 0.055 (0.069)\tLoss 0.3090 (0.6578)\tAcc 0.938 (0.740)\n",
      "Epoch: [44][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.067)\tLoss 0.8033 (0.6786)\tAcc 0.562 (0.714)\n",
      "Epoch: [44][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.066)\tLoss 1.0109 (0.7201)\tAcc 0.625 (0.703)\n",
      "Epoch: [44][9/9]\tTime 0.075 (0.087)\tData 0.056 (0.065)\tLoss 0.4646 (0.7162)\tAcc 1.000 (0.708)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 1.0447 (1.0447)\tAcc 0.562 (0.562)\n",
      "Epoch: [45][2/5]\tTime 0.076 (0.139)\tData 0.052 (0.113)\tLoss 0.8411 (0.9429)\tAcc 0.562 (0.562)\n",
      "Epoch: [45][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.093)\tLoss 0.5482 (0.8114)\tAcc 0.938 (0.688)\n",
      "Epoch: [45][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.084)\tLoss 0.5793 (0.7533)\tAcc 0.688 (0.688)\n",
      "Epoch: [45][5/5]\tTime 0.077 (0.102)\tData 0.054 (0.078)\tLoss 0.5743 (0.7313)\tAcc 0.667 (0.685)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.200 (0.200)\tData 0.174 (0.174)\tLoss 0.3247 (0.3247)\tAcc 0.938 (0.938)\n",
      "Epoch: [45][2/9]\tTime 0.088 (0.144)\tData 0.062 (0.118)\tLoss 0.9306 (0.6277)\tAcc 0.438 (0.688)\n",
      "Epoch: [45][3/9]\tTime 0.067 (0.119)\tData 0.048 (0.095)\tLoss 0.4834 (0.5796)\tAcc 0.875 (0.750)\n",
      "Epoch: [45][4/9]\tTime 0.074 (0.107)\tData 0.054 (0.084)\tLoss 0.6408 (0.5949)\tAcc 0.688 (0.734)\n",
      "Epoch: [45][5/9]\tTime 0.076 (0.101)\tData 0.056 (0.079)\tLoss 0.6966 (0.6152)\tAcc 0.750 (0.738)\n",
      "Epoch: [45][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.2788 (0.5592)\tAcc 1.000 (0.781)\n",
      "Epoch: [45][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.7032 (0.5797)\tAcc 0.750 (0.777)\n",
      "Epoch: [45][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.9273 (0.6232)\tAcc 0.688 (0.766)\n",
      "Epoch: [45][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.2775 (0.6178)\tAcc 1.000 (0.769)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.202 (0.202)\tData 0.172 (0.172)\tLoss 0.5963 (0.5963)\tAcc 0.812 (0.812)\n",
      "Epoch: [46][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.112)\tLoss 0.7074 (0.6518)\tAcc 0.812 (0.812)\n",
      "Epoch: [46][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.093)\tLoss 0.7004 (0.6680)\tAcc 0.688 (0.771)\n",
      "Epoch: [46][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 1.0054 (0.7524)\tAcc 0.625 (0.734)\n",
      "Epoch: [46][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.7856 (0.7565)\tAcc 0.778 (0.740)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.195 (0.195)\tData 0.166 (0.166)\tLoss 0.3316 (0.3316)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/9]\tTime 0.067 (0.131)\tData 0.046 (0.106)\tLoss 0.9767 (0.6542)\tAcc 0.438 (0.688)\n",
      "Epoch: [46][3/9]\tTime 0.073 (0.112)\tData 0.053 (0.089)\tLoss 0.6860 (0.6648)\tAcc 0.750 (0.708)\n",
      "Epoch: [46][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.5635 (0.6395)\tAcc 0.688 (0.703)\n",
      "Epoch: [46][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.7404 (0.6597)\tAcc 0.750 (0.713)\n",
      "Epoch: [46][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.1769 (0.5792)\tAcc 1.000 (0.760)\n",
      "Epoch: [46][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5440 (0.5742)\tAcc 0.750 (0.759)\n",
      "Epoch: [46][8/9]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.9632 (0.6228)\tAcc 0.625 (0.742)\n",
      "Epoch: [46][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.3094 (0.6180)\tAcc 1.000 (0.746)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.198 (0.198)\tData 0.170 (0.170)\tLoss 0.4482 (0.4482)\tAcc 0.875 (0.875)\n",
      "Epoch: [47][2/5]\tTime 0.075 (0.136)\tData 0.051 (0.110)\tLoss 0.8025 (0.6254)\tAcc 0.750 (0.812)\n",
      "Epoch: [47][3/5]\tTime 0.077 (0.117)\tData 0.054 (0.091)\tLoss 0.5910 (0.6139)\tAcc 0.812 (0.812)\n",
      "Epoch: [47][4/5]\tTime 0.078 (0.107)\tData 0.054 (0.082)\tLoss 1.0672 (0.7272)\tAcc 0.562 (0.750)\n",
      "Epoch: [47][5/5]\tTime 0.078 (0.101)\tData 0.055 (0.077)\tLoss 0.4223 (0.6896)\tAcc 0.778 (0.753)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.198 (0.198)\tData 0.169 (0.169)\tLoss 0.3695 (0.3695)\tAcc 0.938 (0.938)\n",
      "Epoch: [47][2/9]\tTime 0.068 (0.133)\tData 0.046 (0.108)\tLoss 0.8959 (0.6327)\tAcc 0.438 (0.688)\n",
      "Epoch: [47][3/9]\tTime 0.072 (0.113)\tData 0.052 (0.089)\tLoss 0.7147 (0.6600)\tAcc 0.688 (0.688)\n",
      "Epoch: [47][4/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.6092 (0.6473)\tAcc 0.625 (0.672)\n",
      "Epoch: [47][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.7969 (0.6772)\tAcc 0.750 (0.688)\n",
      "Epoch: [47][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2579 (0.6073)\tAcc 1.000 (0.740)\n",
      "Epoch: [47][7/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.5876 (0.6045)\tAcc 0.750 (0.741)\n",
      "Epoch: [47][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 1.0768 (0.6636)\tAcc 0.500 (0.711)\n",
      "Epoch: [47][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.3123 (0.6582)\tAcc 1.000 (0.715)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.197 (0.197)\tData 0.164 (0.164)\tLoss 0.7911 (0.7911)\tAcc 0.750 (0.750)\n",
      "Epoch: [48][2/5]\tTime 0.073 (0.135)\tData 0.048 (0.106)\tLoss 0.6897 (0.7404)\tAcc 0.750 (0.750)\n",
      "Epoch: [48][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.089)\tLoss 0.6342 (0.7050)\tAcc 0.812 (0.771)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.106)\tData 0.054 (0.080)\tLoss 0.7464 (0.7153)\tAcc 0.688 (0.750)\n",
      "Epoch: [48][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.075)\tLoss 1.0200 (0.7529)\tAcc 0.556 (0.726)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.199 (0.199)\tData 0.173 (0.173)\tLoss 0.4401 (0.4401)\tAcc 0.938 (0.938)\n",
      "Epoch: [48][2/9]\tTime 0.075 (0.137)\tData 0.050 (0.112)\tLoss 0.8997 (0.6699)\tAcc 0.438 (0.688)\n",
      "Epoch: [48][3/9]\tTime 0.069 (0.114)\tData 0.049 (0.091)\tLoss 0.6102 (0.6500)\tAcc 0.812 (0.729)\n",
      "Epoch: [48][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.081)\tLoss 0.6127 (0.6407)\tAcc 0.750 (0.734)\n",
      "Epoch: [48][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.7200 (0.6565)\tAcc 0.812 (0.750)\n",
      "Epoch: [48][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.2490 (0.5886)\tAcc 1.000 (0.792)\n",
      "Epoch: [48][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.5723 (0.5863)\tAcc 0.812 (0.795)\n",
      "Epoch: [48][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.8942 (0.6248)\tAcc 0.625 (0.773)\n",
      "Epoch: [48][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.4210 (0.6217)\tAcc 1.000 (0.777)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.204 (0.204)\tData 0.177 (0.177)\tLoss 0.9872 (0.9872)\tAcc 0.562 (0.562)\n",
      "Epoch: [49][2/5]\tTime 0.075 (0.140)\tData 0.052 (0.114)\tLoss 0.5992 (0.7932)\tAcc 0.688 (0.625)\n",
      "Epoch: [49][3/5]\tTime 0.078 (0.119)\tData 0.055 (0.094)\tLoss 0.4873 (0.6912)\tAcc 0.750 (0.667)\n",
      "Epoch: [49][4/5]\tTime 0.080 (0.109)\tData 0.056 (0.085)\tLoss 0.7173 (0.6978)\tAcc 0.688 (0.672)\n",
      "Epoch: [49][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 0.6327 (0.6897)\tAcc 0.778 (0.685)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.201 (0.201)\tData 0.176 (0.176)\tLoss 0.4136 (0.4136)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.074 (0.137)\tData 0.050 (0.113)\tLoss 0.9252 (0.6694)\tAcc 0.562 (0.750)\n",
      "Epoch: [49][3/9]\tTime 0.070 (0.115)\tData 0.050 (0.092)\tLoss 0.6402 (0.6597)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.6692 (0.6621)\tAcc 0.688 (0.734)\n",
      "Epoch: [49][5/9]\tTime 0.075 (0.099)\tData 0.056 (0.077)\tLoss 0.6859 (0.6668)\tAcc 0.688 (0.725)\n",
      "Epoch: [49][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.4080 (0.6237)\tAcc 1.000 (0.771)\n",
      "Epoch: [49][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.071)\tLoss 0.6461 (0.6269)\tAcc 0.875 (0.786)\n",
      "Epoch: [49][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.069)\tLoss 0.8791 (0.6584)\tAcc 0.500 (0.750)\n",
      "Epoch: [49][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.4286 (0.6549)\tAcc 1.000 (0.754)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.200 (0.200)\tData 0.173 (0.173)\tLoss 0.5824 (0.5824)\tAcc 0.812 (0.812)\n",
      "Epoch: [50][2/5]\tTime 0.075 (0.138)\tData 0.052 (0.112)\tLoss 0.7242 (0.6533)\tAcc 0.812 (0.812)\n",
      "Epoch: [50][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.093)\tLoss 0.6248 (0.6438)\tAcc 0.812 (0.812)\n",
      "Epoch: [50][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.083)\tLoss 0.6715 (0.6507)\tAcc 0.750 (0.797)\n",
      "Epoch: [50][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.7511 (0.6631)\tAcc 0.667 (0.781)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.196 (0.196)\tData 0.169 (0.169)\tLoss 0.3704 (0.3704)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/9]\tTime 0.069 (0.133)\tData 0.047 (0.108)\tLoss 0.8670 (0.6187)\tAcc 0.500 (0.719)\n",
      "Epoch: [50][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.089)\tLoss 0.6382 (0.6252)\tAcc 0.750 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.7214 (0.6493)\tAcc 0.688 (0.719)\n",
      "Epoch: [50][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.8186 (0.6831)\tAcc 0.750 (0.725)\n",
      "Epoch: [50][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.3467 (0.6271)\tAcc 1.000 (0.771)\n",
      "Epoch: [50][7/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.6754 (0.6340)\tAcc 0.688 (0.759)\n",
      "Epoch: [50][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.8287 (0.6583)\tAcc 0.688 (0.750)\n",
      "Epoch: [50][9/9]\tTime 0.074 (0.087)\tData 0.054 (0.066)\tLoss 0.2957 (0.6527)\tAcc 1.000 (0.754)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.204 (0.204)\tData 0.177 (0.177)\tLoss 0.9374 (0.9374)\tAcc 0.500 (0.500)\n",
      "Epoch: [51][2/5]\tTime 0.075 (0.140)\tData 0.051 (0.114)\tLoss 0.7918 (0.8646)\tAcc 0.688 (0.594)\n",
      "Epoch: [51][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.094)\tLoss 0.5145 (0.7479)\tAcc 0.875 (0.688)\n",
      "Epoch: [51][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.5520 (0.6989)\tAcc 0.875 (0.734)\n",
      "Epoch: [51][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.8443 (0.7169)\tAcc 0.667 (0.726)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.2961 (0.2961)\tAcc 1.000 (1.000)\n",
      "Epoch: [51][2/9]\tTime 0.066 (0.133)\tData 0.045 (0.108)\tLoss 1.0073 (0.6517)\tAcc 0.438 (0.719)\n",
      "Epoch: [51][3/9]\tTime 0.072 (0.113)\tData 0.053 (0.090)\tLoss 0.6592 (0.6542)\tAcc 0.750 (0.729)\n",
      "Epoch: [51][4/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 0.6163 (0.6447)\tAcc 0.688 (0.719)\n",
      "Epoch: [51][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.076)\tLoss 0.7818 (0.6721)\tAcc 0.750 (0.725)\n",
      "Epoch: [51][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.3119 (0.6121)\tAcc 1.000 (0.771)\n",
      "Epoch: [51][7/9]\tTime 0.076 (0.091)\tData 0.056 (0.070)\tLoss 0.5385 (0.6016)\tAcc 0.812 (0.777)\n",
      "Epoch: [51][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.9559 (0.6459)\tAcc 0.688 (0.766)\n",
      "Epoch: [51][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.067)\tLoss 0.2661 (0.6400)\tAcc 1.000 (0.769)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.206 (0.206)\tData 0.178 (0.178)\tLoss 0.8594 (0.8594)\tAcc 0.562 (0.562)\n",
      "Epoch: [52][2/5]\tTime 0.075 (0.141)\tData 0.051 (0.115)\tLoss 0.6247 (0.7421)\tAcc 0.875 (0.719)\n",
      "Epoch: [52][3/5]\tTime 0.078 (0.120)\tData 0.054 (0.095)\tLoss 0.7048 (0.7297)\tAcc 0.688 (0.708)\n",
      "Epoch: [52][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.6600 (0.7122)\tAcc 0.625 (0.688)\n",
      "Epoch: [52][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.078)\tLoss 0.8821 (0.7332)\tAcc 0.778 (0.699)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.202 (0.202)\tData 0.176 (0.176)\tLoss 0.4456 (0.4456)\tAcc 0.938 (0.938)\n",
      "Epoch: [52][2/9]\tTime 0.072 (0.137)\tData 0.049 (0.112)\tLoss 0.9106 (0.6781)\tAcc 0.562 (0.750)\n",
      "Epoch: [52][3/9]\tTime 0.070 (0.114)\tData 0.050 (0.092)\tLoss 0.5611 (0.6391)\tAcc 0.875 (0.792)\n",
      "Epoch: [52][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6850 (0.6506)\tAcc 0.688 (0.766)\n",
      "Epoch: [52][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 0.7805 (0.6766)\tAcc 0.812 (0.775)\n",
      "Epoch: [52][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3393 (0.6204)\tAcc 0.938 (0.802)\n",
      "Epoch: [52][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.4088 (0.5901)\tAcc 0.875 (0.813)\n",
      "Epoch: [52][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.069)\tLoss 0.9477 (0.6348)\tAcc 0.500 (0.773)\n",
      "Epoch: [52][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.067)\tLoss 0.3967 (0.6312)\tAcc 1.000 (0.777)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.7989 (0.7989)\tAcc 0.625 (0.625)\n",
      "Epoch: [53][2/5]\tTime 0.073 (0.135)\tData 0.049 (0.108)\tLoss 0.6023 (0.7006)\tAcc 0.875 (0.750)\n",
      "Epoch: [53][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.090)\tLoss 0.5428 (0.6480)\tAcc 0.875 (0.792)\n",
      "Epoch: [53][4/5]\tTime 0.079 (0.107)\tData 0.056 (0.081)\tLoss 0.8009 (0.6862)\tAcc 0.500 (0.719)\n",
      "Epoch: [53][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.5029 (0.6636)\tAcc 0.778 (0.726)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.3100 (0.3100)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/9]\tTime 0.066 (0.132)\tData 0.045 (0.106)\tLoss 0.9716 (0.6408)\tAcc 0.500 (0.719)\n",
      "Epoch: [53][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.088)\tLoss 0.7677 (0.6831)\tAcc 0.625 (0.688)\n",
      "Epoch: [53][4/9]\tTime 0.074 (0.102)\tData 0.054 (0.080)\tLoss 0.7276 (0.6942)\tAcc 0.688 (0.688)\n",
      "Epoch: [53][5/9]\tTime 0.073 (0.096)\tData 0.054 (0.074)\tLoss 0.7581 (0.7070)\tAcc 0.750 (0.700)\n",
      "Epoch: [53][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.1611 (0.6160)\tAcc 1.000 (0.750)\n",
      "Epoch: [53][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5310 (0.6039)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8831 (0.6388)\tAcc 0.688 (0.742)\n",
      "Epoch: [53][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.4481 (0.6359)\tAcc 1.000 (0.746)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.8840 (0.8840)\tAcc 0.625 (0.625)\n",
      "Epoch: [54][2/5]\tTime 0.076 (0.139)\tData 0.051 (0.113)\tLoss 0.9272 (0.9056)\tAcc 0.625 (0.625)\n",
      "Epoch: [54][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.094)\tLoss 0.5527 (0.7880)\tAcc 0.875 (0.708)\n",
      "Epoch: [54][4/5]\tTime 0.079 (0.109)\tData 0.054 (0.084)\tLoss 0.6603 (0.7561)\tAcc 0.750 (0.719)\n",
      "Epoch: [54][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.7341 (0.7534)\tAcc 0.667 (0.712)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.201 (0.201)\tData 0.173 (0.173)\tLoss 0.4182 (0.4182)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/9]\tTime 0.071 (0.136)\tData 0.046 (0.110)\tLoss 0.9396 (0.6789)\tAcc 0.562 (0.750)\n",
      "Epoch: [54][3/9]\tTime 0.069 (0.114)\tData 0.049 (0.090)\tLoss 0.7438 (0.7005)\tAcc 0.688 (0.729)\n",
      "Epoch: [54][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.5893 (0.6727)\tAcc 0.688 (0.719)\n",
      "Epoch: [54][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.075)\tLoss 0.6940 (0.6770)\tAcc 0.750 (0.725)\n",
      "Epoch: [54][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.2807 (0.6109)\tAcc 1.000 (0.771)\n",
      "Epoch: [54][7/9]\tTime 0.075 (0.091)\tData 0.055 (0.070)\tLoss 0.6272 (0.6133)\tAcc 0.812 (0.777)\n",
      "Epoch: [54][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9276 (0.6525)\tAcc 0.688 (0.766)\n",
      "Epoch: [54][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2342 (0.6461)\tAcc 1.000 (0.769)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.205 (0.205)\tData 0.176 (0.176)\tLoss 0.8747 (0.8747)\tAcc 0.562 (0.562)\n",
      "Epoch: [55][2/5]\tTime 0.074 (0.140)\tData 0.050 (0.113)\tLoss 0.7393 (0.8070)\tAcc 0.750 (0.656)\n",
      "Epoch: [55][3/5]\tTime 0.077 (0.119)\tData 0.053 (0.093)\tLoss 0.7355 (0.7832)\tAcc 0.688 (0.667)\n",
      "Epoch: [55][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.5740 (0.7309)\tAcc 0.875 (0.719)\n",
      "Epoch: [55][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 0.3359 (0.6822)\tAcc 0.889 (0.740)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.196 (0.196)\tData 0.169 (0.169)\tLoss 0.3194 (0.3194)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/9]\tTime 0.070 (0.133)\tData 0.048 (0.108)\tLoss 0.9341 (0.6267)\tAcc 0.562 (0.750)\n",
      "Epoch: [55][3/9]\tTime 0.071 (0.112)\tData 0.052 (0.090)\tLoss 0.6098 (0.6211)\tAcc 0.688 (0.729)\n",
      "Epoch: [55][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.6374 (0.6252)\tAcc 0.688 (0.719)\n",
      "Epoch: [55][5/9]\tTime 0.073 (0.097)\tData 0.055 (0.075)\tLoss 0.7516 (0.6505)\tAcc 0.688 (0.713)\n",
      "Epoch: [55][6/9]\tTime 0.073 (0.093)\tData 0.055 (0.072)\tLoss 0.2932 (0.5909)\tAcc 1.000 (0.760)\n",
      "Epoch: [55][7/9]\tTime 0.073 (0.090)\tData 0.055 (0.070)\tLoss 0.5091 (0.5792)\tAcc 0.812 (0.768)\n",
      "Epoch: [55][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.068)\tLoss 0.8172 (0.6090)\tAcc 0.625 (0.750)\n",
      "Epoch: [55][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.066)\tLoss 0.7223 (0.6107)\tAcc 1.000 (0.754)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.4763 (0.4763)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.8117 (0.6440)\tAcc 0.688 (0.812)\n",
      "Epoch: [56][3/5]\tTime 0.080 (0.119)\tData 0.056 (0.094)\tLoss 0.4938 (0.5939)\tAcc 0.750 (0.792)\n",
      "Epoch: [56][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.6430 (0.6062)\tAcc 0.750 (0.781)\n",
      "Epoch: [56][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.8000 (0.6301)\tAcc 0.778 (0.781)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.205 (0.205)\tData 0.180 (0.180)\tLoss 0.2908 (0.2908)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/9]\tTime 0.078 (0.141)\tData 0.050 (0.115)\tLoss 0.9601 (0.6254)\tAcc 0.500 (0.719)\n",
      "Epoch: [56][3/9]\tTime 0.067 (0.117)\tData 0.048 (0.092)\tLoss 0.6224 (0.6244)\tAcc 0.812 (0.750)\n",
      "Epoch: [56][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.6975 (0.6427)\tAcc 0.625 (0.719)\n",
      "Epoch: [56][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7695 (0.6681)\tAcc 0.750 (0.725)\n",
      "Epoch: [56][6/9]\tTime 0.074 (0.095)\tData 0.055 (0.073)\tLoss 0.2687 (0.6015)\tAcc 1.000 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.5839 (0.5990)\tAcc 0.750 (0.768)\n",
      "Epoch: [56][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.8657 (0.6323)\tAcc 0.625 (0.750)\n",
      "Epoch: [56][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.2566 (0.6265)\tAcc 1.000 (0.754)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.6157 (0.6157)\tAcc 0.688 (0.688)\n",
      "Epoch: [57][2/5]\tTime 0.075 (0.140)\tData 0.051 (0.113)\tLoss 0.8047 (0.7102)\tAcc 0.812 (0.750)\n",
      "Epoch: [57][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.093)\tLoss 0.6862 (0.7022)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.083)\tLoss 0.5731 (0.6699)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 0.4069 (0.6375)\tAcc 0.889 (0.767)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.200 (0.200)\tData 0.175 (0.175)\tLoss 0.2728 (0.2728)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/9]\tTime 0.075 (0.138)\tData 0.050 (0.112)\tLoss 0.9041 (0.5884)\tAcc 0.438 (0.688)\n",
      "Epoch: [57][3/9]\tTime 0.068 (0.114)\tData 0.048 (0.091)\tLoss 0.6247 (0.6005)\tAcc 0.875 (0.750)\n",
      "Epoch: [57][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6373 (0.6097)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.8111 (0.6500)\tAcc 0.625 (0.725)\n",
      "Epoch: [57][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3083 (0.5931)\tAcc 1.000 (0.771)\n",
      "Epoch: [57][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.5815 (0.5914)\tAcc 0.750 (0.768)\n",
      "Epoch: [57][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.9308 (0.6338)\tAcc 0.688 (0.758)\n",
      "Epoch: [57][9/9]\tTime 0.077 (0.088)\tData 0.058 (0.067)\tLoss 0.4349 (0.6308)\tAcc 1.000 (0.762)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.4612 (0.4612)\tAcc 0.812 (0.812)\n",
      "Epoch: [58][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.111)\tLoss 0.9530 (0.7071)\tAcc 0.625 (0.719)\n",
      "Epoch: [58][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.092)\tLoss 0.6232 (0.6791)\tAcc 0.812 (0.750)\n",
      "Epoch: [58][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.8320 (0.7174)\tAcc 0.688 (0.734)\n",
      "Epoch: [58][5/5]\tTime 0.079 (0.102)\tData 0.056 (0.077)\tLoss 0.5050 (0.6912)\tAcc 0.889 (0.753)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.4394 (0.4394)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/9]\tTime 0.069 (0.133)\tData 0.048 (0.109)\tLoss 0.9325 (0.6860)\tAcc 0.438 (0.688)\n",
      "Epoch: [58][3/9]\tTime 0.073 (0.113)\tData 0.054 (0.090)\tLoss 0.5922 (0.6547)\tAcc 0.812 (0.729)\n",
      "Epoch: [58][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6852 (0.6623)\tAcc 0.625 (0.703)\n",
      "Epoch: [58][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.076)\tLoss 0.9165 (0.7132)\tAcc 0.688 (0.700)\n",
      "Epoch: [58][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2339 (0.6333)\tAcc 1.000 (0.750)\n",
      "Epoch: [58][7/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.6062 (0.6294)\tAcc 0.812 (0.759)\n",
      "Epoch: [58][8/9]\tTime 0.074 (0.088)\tData 0.054 (0.068)\tLoss 0.9155 (0.6652)\tAcc 0.625 (0.742)\n",
      "Epoch: [58][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.2760 (0.6592)\tAcc 1.000 (0.746)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.9350 (0.9350)\tAcc 0.500 (0.500)\n",
      "Epoch: [59][2/5]\tTime 0.080 (0.142)\tData 0.056 (0.115)\tLoss 0.7665 (0.8508)\tAcc 0.750 (0.625)\n",
      "Epoch: [59][3/5]\tTime 0.078 (0.120)\tData 0.054 (0.095)\tLoss 0.6881 (0.7965)\tAcc 0.750 (0.667)\n",
      "Epoch: [59][4/5]\tTime 0.077 (0.110)\tData 0.054 (0.084)\tLoss 0.6515 (0.7603)\tAcc 0.812 (0.703)\n",
      "Epoch: [59][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.3992 (0.7158)\tAcc 0.889 (0.726)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.199 (0.199)\tData 0.173 (0.173)\tLoss 0.3840 (0.3840)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/9]\tTime 0.075 (0.137)\tData 0.050 (0.111)\tLoss 0.8662 (0.6251)\tAcc 0.438 (0.688)\n",
      "Epoch: [59][3/9]\tTime 0.069 (0.114)\tData 0.049 (0.091)\tLoss 0.8065 (0.6856)\tAcc 0.625 (0.667)\n",
      "Epoch: [59][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.6436 (0.6751)\tAcc 0.688 (0.672)\n",
      "Epoch: [59][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.8011 (0.7003)\tAcc 0.750 (0.688)\n",
      "Epoch: [59][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.2734 (0.6291)\tAcc 1.000 (0.740)\n",
      "Epoch: [59][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5601 (0.6193)\tAcc 0.812 (0.750)\n",
      "Epoch: [59][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.9043 (0.6549)\tAcc 0.688 (0.742)\n",
      "Epoch: [59][9/9]\tTime 0.077 (0.087)\tData 0.056 (0.067)\tLoss 0.4434 (0.6516)\tAcc 1.000 (0.746)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.203 (0.203)\tData 0.171 (0.171)\tLoss 0.6791 (0.6791)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][2/5]\tTime 0.071 (0.137)\tData 0.048 (0.109)\tLoss 0.6678 (0.6735)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 0.7541 (0.7003)\tAcc 0.625 (0.708)\n",
      "Epoch: [60][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.082)\tLoss 0.6190 (0.6800)\tAcc 0.812 (0.734)\n",
      "Epoch: [60][5/5]\tTime 0.077 (0.102)\tData 0.054 (0.076)\tLoss 0.4486 (0.6515)\tAcc 0.778 (0.740)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.2886 (0.2886)\tAcc 0.938 (0.938)\n",
      "Epoch: [60][2/9]\tTime 0.070 (0.133)\tData 0.048 (0.109)\tLoss 0.8214 (0.5550)\tAcc 0.500 (0.719)\n",
      "Epoch: [60][3/9]\tTime 0.072 (0.113)\tData 0.052 (0.090)\tLoss 0.7158 (0.6086)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6170 (0.6107)\tAcc 0.688 (0.688)\n",
      "Epoch: [60][5/9]\tTime 0.073 (0.097)\tData 0.054 (0.076)\tLoss 0.7199 (0.6325)\tAcc 0.812 (0.713)\n",
      "Epoch: [60][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2663 (0.5715)\tAcc 1.000 (0.760)\n",
      "Epoch: [60][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 0.5128 (0.5631)\tAcc 0.812 (0.768)\n",
      "Epoch: [60][8/9]\tTime 0.075 (0.088)\tData 0.055 (0.068)\tLoss 0.8514 (0.5992)\tAcc 0.688 (0.758)\n",
      "Epoch: [60][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.066)\tLoss 0.3207 (0.5949)\tAcc 1.000 (0.762)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.219 (0.219)\tData 0.191 (0.191)\tLoss 0.7043 (0.7043)\tAcc 0.750 (0.750)\n",
      "Epoch: [61][2/5]\tTime 0.075 (0.147)\tData 0.051 (0.121)\tLoss 0.7893 (0.7468)\tAcc 0.688 (0.719)\n",
      "Epoch: [61][3/5]\tTime 0.078 (0.124)\tData 0.054 (0.098)\tLoss 0.5759 (0.6898)\tAcc 0.750 (0.729)\n",
      "Epoch: [61][4/5]\tTime 0.081 (0.113)\tData 0.057 (0.088)\tLoss 0.8232 (0.7232)\tAcc 0.688 (0.719)\n",
      "Epoch: [61][5/5]\tTime 0.078 (0.106)\tData 0.054 (0.081)\tLoss 0.8729 (0.7416)\tAcc 0.556 (0.699)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.209 (0.209)\tData 0.184 (0.184)\tLoss 0.3115 (0.3115)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.078 (0.144)\tData 0.052 (0.118)\tLoss 0.9050 (0.6082)\tAcc 0.438 (0.688)\n",
      "Epoch: [61][3/9]\tTime 0.068 (0.119)\tData 0.049 (0.095)\tLoss 0.6172 (0.6112)\tAcc 0.812 (0.729)\n",
      "Epoch: [61][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.6594 (0.6233)\tAcc 0.625 (0.703)\n",
      "Epoch: [61][5/9]\tTime 0.075 (0.101)\tData 0.056 (0.079)\tLoss 0.7658 (0.6518)\tAcc 0.812 (0.725)\n",
      "Epoch: [61][6/9]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.2807 (0.5899)\tAcc 1.000 (0.771)\n",
      "Epoch: [61][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.6261 (0.5951)\tAcc 0.750 (0.768)\n",
      "Epoch: [61][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.8667 (0.6291)\tAcc 0.750 (0.766)\n",
      "Epoch: [61][9/9]\tTime 0.072 (0.089)\tData 0.054 (0.068)\tLoss 0.2267 (0.6229)\tAcc 1.000 (0.769)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.196 (0.196)\tData 0.163 (0.163)\tLoss 0.7165 (0.7165)\tAcc 0.688 (0.688)\n",
      "Epoch: [62][2/5]\tTime 0.072 (0.134)\tData 0.048 (0.106)\tLoss 0.8098 (0.7632)\tAcc 0.688 (0.688)\n",
      "Epoch: [62][3/5]\tTime 0.077 (0.115)\tData 0.054 (0.088)\tLoss 0.7765 (0.7676)\tAcc 0.625 (0.667)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.106)\tData 0.054 (0.080)\tLoss 0.5499 (0.7132)\tAcc 0.875 (0.719)\n",
      "Epoch: [62][5/5]\tTime 0.078 (0.100)\tData 0.055 (0.075)\tLoss 0.4516 (0.6809)\tAcc 0.778 (0.726)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.208 (0.208)\tData 0.174 (0.174)\tLoss 0.3451 (0.3451)\tAcc 0.938 (0.938)\n",
      "Epoch: [62][2/9]\tTime 0.076 (0.142)\tData 0.046 (0.110)\tLoss 1.0158 (0.6804)\tAcc 0.438 (0.688)\n",
      "Epoch: [62][3/9]\tTime 0.070 (0.118)\tData 0.050 (0.090)\tLoss 0.7670 (0.7093)\tAcc 0.625 (0.667)\n",
      "Epoch: [62][4/9]\tTime 0.078 (0.108)\tData 0.058 (0.082)\tLoss 0.6417 (0.6924)\tAcc 0.625 (0.656)\n",
      "Epoch: [62][5/9]\tTime 0.079 (0.102)\tData 0.059 (0.078)\tLoss 0.6822 (0.6903)\tAcc 0.812 (0.688)\n",
      "Epoch: [62][6/9]\tTime 0.079 (0.098)\tData 0.059 (0.074)\tLoss 0.3032 (0.6258)\tAcc 1.000 (0.740)\n",
      "Epoch: [62][7/9]\tTime 0.078 (0.095)\tData 0.058 (0.072)\tLoss 0.6138 (0.6241)\tAcc 0.812 (0.750)\n",
      "Epoch: [62][8/9]\tTime 0.079 (0.093)\tData 0.059 (0.070)\tLoss 0.9000 (0.6586)\tAcc 0.562 (0.727)\n",
      "Epoch: [62][9/9]\tTime 0.078 (0.092)\tData 0.059 (0.069)\tLoss 0.2330 (0.6520)\tAcc 1.000 (0.731)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.201 (0.201)\tData 0.171 (0.171)\tLoss 0.8071 (0.8071)\tAcc 0.688 (0.688)\n",
      "Epoch: [63][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.111)\tLoss 0.5729 (0.6900)\tAcc 0.625 (0.656)\n",
      "Epoch: [63][3/5]\tTime 0.092 (0.123)\tData 0.068 (0.097)\tLoss 0.5416 (0.6405)\tAcc 0.875 (0.729)\n",
      "Epoch: [63][4/5]\tTime 0.085 (0.113)\tData 0.062 (0.088)\tLoss 0.6825 (0.6510)\tAcc 0.750 (0.734)\n",
      "Epoch: [63][5/5]\tTime 0.079 (0.106)\tData 0.055 (0.081)\tLoss 0.6840 (0.6551)\tAcc 0.667 (0.726)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.220 (0.220)\tData 0.173 (0.173)\tLoss 0.3753 (0.3753)\tAcc 0.938 (0.938)\n",
      "Epoch: [63][2/9]\tTime 0.054 (0.137)\tData 0.031 (0.102)\tLoss 0.8179 (0.5966)\tAcc 0.438 (0.688)\n",
      "Epoch: [63][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.085)\tLoss 0.6271 (0.6068)\tAcc 0.812 (0.729)\n",
      "Epoch: [63][4/9]\tTime 0.074 (0.105)\tData 0.055 (0.077)\tLoss 0.6271 (0.6119)\tAcc 0.688 (0.719)\n",
      "Epoch: [63][5/9]\tTime 0.078 (0.099)\tData 0.057 (0.073)\tLoss 0.7214 (0.6338)\tAcc 0.688 (0.713)\n",
      "Epoch: [63][6/9]\tTime 0.076 (0.095)\tData 0.057 (0.071)\tLoss 0.2895 (0.5764)\tAcc 1.000 (0.760)\n",
      "Epoch: [63][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.068)\tLoss 0.6594 (0.5882)\tAcc 0.750 (0.759)\n",
      "Epoch: [63][8/9]\tTime 0.076 (0.090)\tData 0.056 (0.067)\tLoss 0.8951 (0.6266)\tAcc 0.750 (0.758)\n",
      "Epoch: [63][9/9]\tTime 0.077 (0.089)\tData 0.058 (0.066)\tLoss 0.2760 (0.6212)\tAcc 1.000 (0.762)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.202 (0.202)\tData 0.168 (0.168)\tLoss 0.3087 (0.3087)\tAcc 0.938 (0.938)\n",
      "Epoch: [64][2/5]\tTime 0.074 (0.138)\tData 0.050 (0.109)\tLoss 0.7767 (0.5427)\tAcc 0.750 (0.844)\n",
      "Epoch: [64][3/5]\tTime 0.082 (0.119)\tData 0.058 (0.092)\tLoss 0.9933 (0.6929)\tAcc 0.562 (0.750)\n",
      "Epoch: [64][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.082)\tLoss 0.4845 (0.6408)\tAcc 0.812 (0.766)\n",
      "Epoch: [64][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.077)\tLoss 0.8042 (0.6609)\tAcc 0.667 (0.753)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.3606 (0.3606)\tAcc 0.938 (0.938)\n",
      "Epoch: [64][2/9]\tTime 0.069 (0.133)\tData 0.047 (0.109)\tLoss 0.9704 (0.6655)\tAcc 0.438 (0.688)\n",
      "Epoch: [64][3/9]\tTime 0.072 (0.113)\tData 0.053 (0.090)\tLoss 0.7032 (0.6781)\tAcc 0.750 (0.708)\n",
      "Epoch: [64][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.5986 (0.6582)\tAcc 0.688 (0.703)\n",
      "Epoch: [64][5/9]\tTime 0.075 (0.097)\tData 0.055 (0.076)\tLoss 0.8512 (0.6968)\tAcc 0.750 (0.713)\n",
      "Epoch: [64][6/9]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.2740 (0.6264)\tAcc 1.000 (0.760)\n",
      "Epoch: [64][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 0.5419 (0.6143)\tAcc 0.750 (0.759)\n",
      "Epoch: [64][8/9]\tTime 0.075 (0.088)\tData 0.056 (0.068)\tLoss 0.7988 (0.6373)\tAcc 0.688 (0.750)\n",
      "Epoch: [64][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.3140 (0.6324)\tAcc 1.000 (0.754)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.202 (0.202)\tData 0.172 (0.172)\tLoss 0.5383 (0.5383)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][2/5]\tTime 0.077 (0.139)\tData 0.052 (0.112)\tLoss 0.5384 (0.5383)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.093)\tLoss 0.5577 (0.5448)\tAcc 0.750 (0.833)\n",
      "Epoch: [65][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.083)\tLoss 0.5287 (0.5408)\tAcc 0.875 (0.844)\n",
      "Epoch: [65][5/5]\tTime 0.079 (0.103)\tData 0.055 (0.077)\tLoss 0.8028 (0.5731)\tAcc 0.667 (0.822)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.204 (0.204)\tData 0.176 (0.176)\tLoss 0.2962 (0.2962)\tAcc 0.938 (0.938)\n",
      "Epoch: [65][2/9]\tTime 0.071 (0.137)\tData 0.048 (0.112)\tLoss 0.9550 (0.6256)\tAcc 0.500 (0.719)\n",
      "Epoch: [65][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.092)\tLoss 0.6797 (0.6436)\tAcc 0.750 (0.729)\n",
      "Epoch: [65][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.082)\tLoss 0.6633 (0.6485)\tAcc 0.625 (0.703)\n",
      "Epoch: [65][5/9]\tTime 0.075 (0.099)\tData 0.056 (0.077)\tLoss 0.7747 (0.6738)\tAcc 0.750 (0.713)\n",
      "Epoch: [65][6/9]\tTime 0.080 (0.096)\tData 0.060 (0.074)\tLoss 0.3276 (0.6161)\tAcc 1.000 (0.760)\n",
      "Epoch: [65][7/9]\tTime 0.078 (0.093)\tData 0.058 (0.072)\tLoss 0.6020 (0.6141)\tAcc 0.750 (0.759)\n",
      "Epoch: [65][8/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.9888 (0.6609)\tAcc 0.625 (0.742)\n",
      "Epoch: [65][9/9]\tTime 0.078 (0.089)\tData 0.058 (0.069)\tLoss 0.1196 (0.6526)\tAcc 1.000 (0.746)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.208 (0.208)\tData 0.181 (0.181)\tLoss 0.7863 (0.7863)\tAcc 0.750 (0.750)\n",
      "Epoch: [66][2/5]\tTime 0.077 (0.143)\tData 0.053 (0.117)\tLoss 0.3721 (0.5792)\tAcc 0.938 (0.844)\n",
      "Epoch: [66][3/5]\tTime 0.078 (0.121)\tData 0.054 (0.096)\tLoss 0.8117 (0.6567)\tAcc 0.625 (0.771)\n",
      "Epoch: [66][4/5]\tTime 0.079 (0.111)\tData 0.056 (0.086)\tLoss 0.8714 (0.7104)\tAcc 0.688 (0.750)\n",
      "Epoch: [66][5/5]\tTime 0.081 (0.105)\tData 0.058 (0.080)\tLoss 0.7670 (0.7174)\tAcc 0.556 (0.726)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.204 (0.204)\tData 0.180 (0.180)\tLoss 0.3034 (0.3034)\tAcc 0.938 (0.938)\n",
      "Epoch: [66][2/9]\tTime 0.078 (0.141)\tData 0.051 (0.115)\tLoss 1.0205 (0.6619)\tAcc 0.438 (0.688)\n",
      "Epoch: [66][3/9]\tTime 0.066 (0.116)\tData 0.046 (0.092)\tLoss 0.7753 (0.6997)\tAcc 0.688 (0.688)\n",
      "Epoch: [66][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.083)\tLoss 0.6939 (0.6983)\tAcc 0.625 (0.672)\n",
      "Epoch: [66][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7870 (0.7160)\tAcc 0.812 (0.700)\n",
      "Epoch: [66][6/9]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.2861 (0.6443)\tAcc 1.000 (0.750)\n",
      "Epoch: [66][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.5831 (0.6356)\tAcc 0.812 (0.759)\n",
      "Epoch: [66][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.8139 (0.6579)\tAcc 0.625 (0.742)\n",
      "Epoch: [66][9/9]\tTime 0.076 (0.088)\tData 0.056 (0.067)\tLoss 0.3234 (0.6527)\tAcc 1.000 (0.746)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.9175 (0.9175)\tAcc 0.562 (0.562)\n",
      "Epoch: [67][2/5]\tTime 0.076 (0.138)\tData 0.052 (0.113)\tLoss 0.5056 (0.7116)\tAcc 0.875 (0.719)\n",
      "Epoch: [67][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.093)\tLoss 0.6616 (0.6949)\tAcc 0.750 (0.729)\n",
      "Epoch: [67][4/5]\tTime 0.079 (0.108)\tData 0.056 (0.084)\tLoss 0.7982 (0.7207)\tAcc 0.750 (0.734)\n",
      "Epoch: [67][5/5]\tTime 0.079 (0.103)\tData 0.056 (0.078)\tLoss 0.7536 (0.7248)\tAcc 0.556 (0.712)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.198 (0.198)\tData 0.166 (0.166)\tLoss 0.4341 (0.4341)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/9]\tTime 0.063 (0.131)\tData 0.042 (0.104)\tLoss 0.9433 (0.6887)\tAcc 0.438 (0.688)\n",
      "Epoch: [67][3/9]\tTime 0.073 (0.111)\tData 0.053 (0.087)\tLoss 0.6158 (0.6644)\tAcc 0.750 (0.708)\n",
      "Epoch: [67][4/9]\tTime 0.074 (0.102)\tData 0.055 (0.079)\tLoss 0.7121 (0.6763)\tAcc 0.562 (0.672)\n",
      "Epoch: [67][5/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.6965 (0.6804)\tAcc 0.812 (0.700)\n",
      "Epoch: [67][6/9]\tTime 0.075 (0.093)\tData 0.055 (0.071)\tLoss 0.3067 (0.6181)\tAcc 1.000 (0.750)\n",
      "Epoch: [67][7/9]\tTime 0.077 (0.090)\tData 0.057 (0.069)\tLoss 0.5978 (0.6152)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 0.8998 (0.6508)\tAcc 0.562 (0.727)\n",
      "Epoch: [67][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.3088 (0.6455)\tAcc 1.000 (0.731)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.4578 (0.4578)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.7748 (0.6163)\tAcc 0.750 (0.844)\n",
      "Epoch: [68][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.093)\tLoss 0.4781 (0.5702)\tAcc 0.875 (0.854)\n",
      "Epoch: [68][4/5]\tTime 0.079 (0.109)\tData 0.055 (0.084)\tLoss 0.8689 (0.6449)\tAcc 0.562 (0.781)\n",
      "Epoch: [68][5/5]\tTime 0.079 (0.103)\tData 0.056 (0.078)\tLoss 1.0421 (0.6939)\tAcc 0.444 (0.740)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.202 (0.202)\tData 0.178 (0.178)\tLoss 0.3826 (0.3826)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.083 (0.143)\tData 0.052 (0.115)\tLoss 0.9516 (0.6671)\tAcc 0.438 (0.688)\n",
      "Epoch: [68][3/9]\tTime 0.068 (0.118)\tData 0.048 (0.093)\tLoss 0.7148 (0.6830)\tAcc 0.688 (0.688)\n",
      "Epoch: [68][4/9]\tTime 0.075 (0.107)\tData 0.056 (0.083)\tLoss 0.6384 (0.6718)\tAcc 0.625 (0.672)\n",
      "Epoch: [68][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.078)\tLoss 0.8179 (0.7011)\tAcc 0.688 (0.675)\n",
      "Epoch: [68][6/9]\tTime 0.073 (0.096)\tData 0.054 (0.074)\tLoss 0.2761 (0.6302)\tAcc 1.000 (0.729)\n",
      "Epoch: [68][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.6416 (0.6319)\tAcc 0.750 (0.732)\n",
      "Epoch: [68][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.7746 (0.6497)\tAcc 0.750 (0.734)\n",
      "Epoch: [68][9/9]\tTime 0.075 (0.089)\tData 0.056 (0.067)\tLoss 0.0972 (0.6412)\tAcc 1.000 (0.738)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.5438 (0.5438)\tAcc 0.750 (0.750)\n",
      "Epoch: [69][2/5]\tTime 0.077 (0.138)\tData 0.052 (0.111)\tLoss 0.4889 (0.5164)\tAcc 0.875 (0.812)\n",
      "Epoch: [69][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.092)\tLoss 0.7010 (0.5779)\tAcc 0.688 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.7209 (0.6136)\tAcc 0.750 (0.766)\n",
      "Epoch: [69][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 1.2406 (0.6909)\tAcc 0.444 (0.726)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.200 (0.200)\tData 0.175 (0.175)\tLoss 0.3633 (0.3633)\tAcc 0.875 (0.875)\n",
      "Epoch: [69][2/9]\tTime 0.073 (0.136)\tData 0.050 (0.112)\tLoss 0.9870 (0.6751)\tAcc 0.438 (0.656)\n",
      "Epoch: [69][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.092)\tLoss 0.7284 (0.6929)\tAcc 0.688 (0.667)\n",
      "Epoch: [69][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 0.6568 (0.6839)\tAcc 0.625 (0.656)\n",
      "Epoch: [69][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 0.7482 (0.6967)\tAcc 0.688 (0.663)\n",
      "Epoch: [69][6/9]\tTime 0.078 (0.095)\tData 0.059 (0.074)\tLoss 0.3117 (0.6326)\tAcc 1.000 (0.719)\n",
      "Epoch: [69][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.6399 (0.6336)\tAcc 0.750 (0.723)\n",
      "Epoch: [69][8/9]\tTime 0.076 (0.090)\tData 0.057 (0.070)\tLoss 0.7554 (0.6488)\tAcc 0.750 (0.727)\n",
      "Epoch: [69][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 0.2193 (0.6422)\tAcc 1.000 (0.731)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.207 (0.207)\tData 0.179 (0.179)\tLoss 0.6583 (0.6583)\tAcc 0.812 (0.812)\n",
      "Epoch: [70][2/5]\tTime 0.075 (0.141)\tData 0.051 (0.115)\tLoss 0.4844 (0.5713)\tAcc 0.875 (0.844)\n",
      "Epoch: [70][3/5]\tTime 0.078 (0.120)\tData 0.054 (0.095)\tLoss 0.9489 (0.6972)\tAcc 0.562 (0.750)\n",
      "Epoch: [70][4/5]\tTime 0.078 (0.110)\tData 0.054 (0.084)\tLoss 0.4981 (0.6474)\tAcc 0.750 (0.750)\n",
      "Epoch: [70][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.078)\tLoss 0.7360 (0.6583)\tAcc 0.667 (0.740)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.202 (0.202)\tData 0.171 (0.171)\tLoss 0.4906 (0.4906)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/9]\tTime 0.065 (0.133)\tData 0.044 (0.107)\tLoss 0.9226 (0.7066)\tAcc 0.500 (0.719)\n",
      "Epoch: [70][3/9]\tTime 0.072 (0.113)\tData 0.053 (0.089)\tLoss 0.6601 (0.6911)\tAcc 0.750 (0.729)\n",
      "Epoch: [70][4/9]\tTime 0.078 (0.104)\tData 0.058 (0.081)\tLoss 0.7297 (0.7008)\tAcc 0.688 (0.719)\n",
      "Epoch: [70][5/9]\tTime 0.075 (0.098)\tData 0.056 (0.076)\tLoss 0.8012 (0.7208)\tAcc 0.625 (0.700)\n",
      "Epoch: [70][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.2804 (0.6474)\tAcc 1.000 (0.750)\n",
      "Epoch: [70][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6586 (0.6490)\tAcc 0.750 (0.750)\n",
      "Epoch: [70][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8707 (0.6767)\tAcc 0.812 (0.758)\n",
      "Epoch: [70][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.066)\tLoss 0.7504 (0.6779)\tAcc 0.500 (0.754)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.201 (0.201)\tData 0.172 (0.172)\tLoss 0.6902 (0.6902)\tAcc 0.688 (0.688)\n",
      "Epoch: [71][2/5]\tTime 0.074 (0.138)\tData 0.050 (0.111)\tLoss 0.6254 (0.6578)\tAcc 0.812 (0.750)\n",
      "Epoch: [71][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.092)\tLoss 0.8227 (0.7128)\tAcc 0.750 (0.750)\n",
      "Epoch: [71][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.082)\tLoss 0.5553 (0.6734)\tAcc 0.812 (0.766)\n",
      "Epoch: [71][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.5133 (0.6537)\tAcc 0.778 (0.767)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.200 (0.200)\tData 0.177 (0.177)\tLoss 0.3928 (0.3928)\tAcc 0.938 (0.938)\n",
      "Epoch: [71][2/9]\tTime 0.078 (0.139)\tData 0.051 (0.114)\tLoss 0.9136 (0.6532)\tAcc 0.438 (0.688)\n",
      "Epoch: [71][3/9]\tTime 0.067 (0.115)\tData 0.047 (0.092)\tLoss 0.6678 (0.6581)\tAcc 0.750 (0.708)\n",
      "Epoch: [71][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.6555 (0.6574)\tAcc 0.688 (0.703)\n",
      "Epoch: [71][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.8845 (0.7028)\tAcc 0.750 (0.713)\n",
      "Epoch: [71][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3341 (0.6414)\tAcc 1.000 (0.760)\n",
      "Epoch: [71][7/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.6207 (0.6384)\tAcc 0.688 (0.750)\n",
      "Epoch: [71][8/9]\tTime 0.077 (0.090)\tData 0.058 (0.069)\tLoss 0.7788 (0.6560)\tAcc 0.688 (0.742)\n",
      "Epoch: [71][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.1874 (0.6488)\tAcc 1.000 (0.746)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.4306 (0.4306)\tAcc 0.875 (0.875)\n",
      "Epoch: [72][2/5]\tTime 0.077 (0.140)\tData 0.053 (0.113)\tLoss 0.7244 (0.5775)\tAcc 0.750 (0.812)\n",
      "Epoch: [72][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.093)\tLoss 0.7452 (0.6334)\tAcc 0.688 (0.771)\n",
      "Epoch: [72][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.6576 (0.6395)\tAcc 0.750 (0.766)\n",
      "Epoch: [72][5/5]\tTime 0.086 (0.104)\tData 0.062 (0.079)\tLoss 1.0754 (0.6932)\tAcc 0.667 (0.753)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.200 (0.200)\tData 0.175 (0.175)\tLoss 0.3131 (0.3131)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.074 (0.137)\tData 0.049 (0.112)\tLoss 0.9534 (0.6332)\tAcc 0.438 (0.688)\n",
      "Epoch: [72][3/9]\tTime 0.068 (0.114)\tData 0.048 (0.091)\tLoss 0.6399 (0.6355)\tAcc 0.812 (0.729)\n",
      "Epoch: [72][4/9]\tTime 0.073 (0.104)\tData 0.053 (0.081)\tLoss 0.5890 (0.6238)\tAcc 0.688 (0.719)\n",
      "Epoch: [72][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.8355 (0.6662)\tAcc 0.688 (0.713)\n",
      "Epoch: [72][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3701 (0.6168)\tAcc 1.000 (0.760)\n",
      "Epoch: [72][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.6281 (0.6184)\tAcc 0.812 (0.768)\n",
      "Epoch: [72][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.8236 (0.6441)\tAcc 0.688 (0.758)\n",
      "Epoch: [72][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.067)\tLoss 0.2097 (0.6374)\tAcc 1.000 (0.762)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.9269 (0.9269)\tAcc 0.625 (0.625)\n",
      "Epoch: [73][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.8600 (0.8934)\tAcc 0.688 (0.656)\n",
      "Epoch: [73][3/5]\tTime 0.077 (0.118)\tData 0.053 (0.093)\tLoss 0.5741 (0.7870)\tAcc 0.750 (0.688)\n",
      "Epoch: [73][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.5199 (0.7202)\tAcc 0.875 (0.734)\n",
      "Epoch: [73][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.4425 (0.6860)\tAcc 0.889 (0.753)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.201 (0.201)\tData 0.176 (0.176)\tLoss 0.2625 (0.2625)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.073 (0.137)\tData 0.049 (0.112)\tLoss 0.9984 (0.6305)\tAcc 0.438 (0.688)\n",
      "Epoch: [73][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.092)\tLoss 0.6366 (0.6325)\tAcc 0.812 (0.729)\n",
      "Epoch: [73][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.6679 (0.6414)\tAcc 0.625 (0.703)\n",
      "Epoch: [73][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.8041 (0.6739)\tAcc 0.812 (0.725)\n",
      "Epoch: [73][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3562 (0.6210)\tAcc 1.000 (0.771)\n",
      "Epoch: [73][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.071)\tLoss 0.6062 (0.6188)\tAcc 0.812 (0.777)\n",
      "Epoch: [73][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.069)\tLoss 0.7882 (0.6400)\tAcc 0.750 (0.773)\n",
      "Epoch: [73][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.5468 (0.6386)\tAcc 1.000 (0.777)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.6530 (0.6530)\tAcc 0.688 (0.688)\n",
      "Epoch: [74][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.113)\tLoss 0.4975 (0.5752)\tAcc 0.938 (0.812)\n",
      "Epoch: [74][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.093)\tLoss 0.6207 (0.5904)\tAcc 0.875 (0.833)\n",
      "Epoch: [74][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.6750 (0.6115)\tAcc 0.812 (0.828)\n",
      "Epoch: [74][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.4236 (0.5884)\tAcc 0.889 (0.836)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.201 (0.201)\tData 0.178 (0.178)\tLoss 0.3837 (0.3837)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/9]\tTime 0.076 (0.139)\tData 0.051 (0.114)\tLoss 0.8785 (0.6311)\tAcc 0.438 (0.688)\n",
      "Epoch: [74][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.092)\tLoss 0.7170 (0.6597)\tAcc 0.750 (0.708)\n",
      "Epoch: [74][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.5998 (0.6447)\tAcc 0.688 (0.703)\n",
      "Epoch: [74][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.7594 (0.6677)\tAcc 0.750 (0.713)\n",
      "Epoch: [74][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.3058 (0.6074)\tAcc 1.000 (0.760)\n",
      "Epoch: [74][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6797 (0.6177)\tAcc 0.625 (0.741)\n",
      "Epoch: [74][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 1.0613 (0.6731)\tAcc 0.688 (0.734)\n",
      "Epoch: [74][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.067)\tLoss 0.2430 (0.6665)\tAcc 1.000 (0.738)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.206 (0.206)\tData 0.178 (0.178)\tLoss 0.5992 (0.5992)\tAcc 0.750 (0.750)\n",
      "Epoch: [75][2/5]\tTime 0.075 (0.140)\tData 0.051 (0.114)\tLoss 0.5958 (0.5975)\tAcc 0.812 (0.781)\n",
      "Epoch: [75][3/5]\tTime 0.079 (0.120)\tData 0.055 (0.094)\tLoss 0.6393 (0.6115)\tAcc 0.750 (0.771)\n",
      "Epoch: [75][4/5]\tTime 0.078 (0.109)\tData 0.055 (0.085)\tLoss 0.6605 (0.6237)\tAcc 0.750 (0.766)\n",
      "Epoch: [75][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 0.3442 (0.5892)\tAcc 0.889 (0.781)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.201 (0.201)\tData 0.175 (0.175)\tLoss 0.3859 (0.3859)\tAcc 0.938 (0.938)\n",
      "Epoch: [75][2/9]\tTime 0.072 (0.137)\tData 0.049 (0.112)\tLoss 0.9347 (0.6603)\tAcc 0.500 (0.719)\n",
      "Epoch: [75][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.092)\tLoss 0.6700 (0.6635)\tAcc 0.812 (0.750)\n",
      "Epoch: [75][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6010 (0.6479)\tAcc 0.750 (0.750)\n",
      "Epoch: [75][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 0.8067 (0.6796)\tAcc 0.688 (0.738)\n",
      "Epoch: [75][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.2846 (0.6138)\tAcc 1.000 (0.781)\n",
      "Epoch: [75][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6379 (0.6172)\tAcc 0.688 (0.768)\n",
      "Epoch: [75][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9023 (0.6529)\tAcc 0.500 (0.734)\n",
      "Epoch: [75][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.067)\tLoss 0.2609 (0.6468)\tAcc 1.000 (0.738)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.198 (0.198)\tData 0.168 (0.168)\tLoss 0.8359 (0.8359)\tAcc 0.688 (0.688)\n",
      "Epoch: [76][2/5]\tTime 0.073 (0.135)\tData 0.049 (0.108)\tLoss 0.6154 (0.7257)\tAcc 0.750 (0.719)\n",
      "Epoch: [76][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.090)\tLoss 0.5988 (0.6834)\tAcc 0.812 (0.750)\n",
      "Epoch: [76][4/5]\tTime 0.080 (0.107)\tData 0.056 (0.082)\tLoss 0.7682 (0.7046)\tAcc 0.688 (0.734)\n",
      "Epoch: [76][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.4157 (0.6690)\tAcc 0.778 (0.740)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.202 (0.202)\tData 0.178 (0.178)\tLoss 0.4846 (0.4846)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/9]\tTime 0.077 (0.140)\tData 0.051 (0.115)\tLoss 0.8752 (0.6799)\tAcc 0.438 (0.688)\n",
      "Epoch: [76][3/9]\tTime 0.069 (0.116)\tData 0.049 (0.093)\tLoss 0.6824 (0.6807)\tAcc 0.812 (0.729)\n",
      "Epoch: [76][4/9]\tTime 0.075 (0.106)\tData 0.055 (0.084)\tLoss 0.6192 (0.6653)\tAcc 0.750 (0.734)\n",
      "Epoch: [76][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.8569 (0.7036)\tAcc 0.688 (0.725)\n",
      "Epoch: [76][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.2766 (0.6325)\tAcc 1.000 (0.771)\n",
      "Epoch: [76][7/9]\tTime 0.073 (0.092)\tData 0.055 (0.071)\tLoss 0.6200 (0.6307)\tAcc 0.812 (0.777)\n",
      "Epoch: [76][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.069)\tLoss 1.0105 (0.6782)\tAcc 0.750 (0.773)\n",
      "Epoch: [76][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.2231 (0.6712)\tAcc 1.000 (0.777)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.5213 (0.5213)\tAcc 0.812 (0.812)\n",
      "Epoch: [77][2/5]\tTime 0.075 (0.137)\tData 0.050 (0.111)\tLoss 0.6857 (0.6035)\tAcc 0.812 (0.812)\n",
      "Epoch: [77][3/5]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 0.8815 (0.6962)\tAcc 0.688 (0.771)\n",
      "Epoch: [77][4/5]\tTime 0.080 (0.108)\tData 0.056 (0.083)\tLoss 0.6988 (0.6968)\tAcc 0.750 (0.766)\n",
      "Epoch: [77][5/5]\tTime 0.077 (0.102)\tData 0.054 (0.077)\tLoss 0.5910 (0.6838)\tAcc 0.889 (0.781)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.201 (0.201)\tData 0.177 (0.177)\tLoss 0.3153 (0.3153)\tAcc 0.938 (0.938)\n",
      "Epoch: [77][2/9]\tTime 0.078 (0.140)\tData 0.051 (0.114)\tLoss 0.8327 (0.5740)\tAcc 0.500 (0.719)\n",
      "Epoch: [77][3/9]\tTime 0.067 (0.115)\tData 0.047 (0.092)\tLoss 0.5880 (0.5786)\tAcc 0.812 (0.750)\n",
      "Epoch: [77][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.7138 (0.6124)\tAcc 0.688 (0.734)\n",
      "Epoch: [77][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7253 (0.6350)\tAcc 0.812 (0.750)\n",
      "Epoch: [77][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3289 (0.5840)\tAcc 1.000 (0.792)\n",
      "Epoch: [77][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5453 (0.5785)\tAcc 0.812 (0.795)\n",
      "Epoch: [77][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8358 (0.6106)\tAcc 0.812 (0.797)\n",
      "Epoch: [77][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.1910 (0.6042)\tAcc 1.000 (0.800)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.4945 (0.4945)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/5]\tTime 0.072 (0.135)\tData 0.048 (0.107)\tLoss 0.5831 (0.5388)\tAcc 0.812 (0.875)\n",
      "Epoch: [78][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.090)\tLoss 0.6755 (0.5844)\tAcc 0.750 (0.833)\n",
      "Epoch: [78][4/5]\tTime 0.078 (0.106)\tData 0.054 (0.081)\tLoss 0.6481 (0.6003)\tAcc 0.688 (0.797)\n",
      "Epoch: [78][5/5]\tTime 0.078 (0.101)\tData 0.055 (0.075)\tLoss 0.8049 (0.6255)\tAcc 0.778 (0.795)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.217 (0.217)\tData 0.181 (0.181)\tLoss 0.2856 (0.2856)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/9]\tTime 0.065 (0.141)\tData 0.038 (0.109)\tLoss 0.8202 (0.5529)\tAcc 0.438 (0.688)\n",
      "Epoch: [78][3/9]\tTime 0.066 (0.116)\tData 0.047 (0.089)\tLoss 0.5393 (0.5484)\tAcc 0.875 (0.750)\n",
      "Epoch: [78][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.080)\tLoss 0.5831 (0.5571)\tAcc 0.625 (0.719)\n",
      "Epoch: [78][5/9]\tTime 0.074 (0.099)\tData 0.055 (0.075)\tLoss 0.6319 (0.5720)\tAcc 0.750 (0.725)\n",
      "Epoch: [78][6/9]\tTime 0.074 (0.095)\tData 0.055 (0.071)\tLoss 0.2941 (0.5257)\tAcc 1.000 (0.771)\n",
      "Epoch: [78][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.069)\tLoss 0.6586 (0.5447)\tAcc 0.750 (0.768)\n",
      "Epoch: [78][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.067)\tLoss 0.9067 (0.5899)\tAcc 0.625 (0.750)\n",
      "Epoch: [78][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.1141 (0.5826)\tAcc 1.000 (0.754)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.9812 (0.9812)\tAcc 0.562 (0.562)\n",
      "Epoch: [79][2/5]\tTime 0.074 (0.137)\tData 0.050 (0.111)\tLoss 0.6755 (0.8283)\tAcc 0.750 (0.656)\n",
      "Epoch: [79][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.092)\tLoss 0.4912 (0.7159)\tAcc 0.750 (0.688)\n",
      "Epoch: [79][4/5]\tTime 0.081 (0.109)\tData 0.057 (0.083)\tLoss 0.5067 (0.6636)\tAcc 0.750 (0.703)\n",
      "Epoch: [79][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 0.9903 (0.7039)\tAcc 0.667 (0.699)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.219 (0.219)\tData 0.181 (0.181)\tLoss 0.3031 (0.3031)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.066 (0.142)\tData 0.038 (0.110)\tLoss 0.8546 (0.5788)\tAcc 0.500 (0.719)\n",
      "Epoch: [79][3/9]\tTime 0.067 (0.117)\tData 0.048 (0.089)\tLoss 0.7057 (0.6211)\tAcc 0.750 (0.729)\n",
      "Epoch: [79][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.080)\tLoss 0.6382 (0.6254)\tAcc 0.688 (0.719)\n",
      "Epoch: [79][5/9]\tTime 0.074 (0.100)\tData 0.054 (0.075)\tLoss 0.7192 (0.6442)\tAcc 0.750 (0.725)\n",
      "Epoch: [79][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.071)\tLoss 0.2102 (0.5718)\tAcc 1.000 (0.771)\n",
      "Epoch: [79][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.069)\tLoss 0.5284 (0.5656)\tAcc 0.938 (0.795)\n",
      "Epoch: [79][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.067)\tLoss 0.8188 (0.5973)\tAcc 0.688 (0.781)\n",
      "Epoch: [79][9/9]\tTime 0.074 (0.088)\tData 0.054 (0.066)\tLoss 0.1706 (0.5907)\tAcc 1.000 (0.785)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.195 (0.195)\tData 0.165 (0.165)\tLoss 0.5834 (0.5834)\tAcc 0.812 (0.812)\n",
      "Epoch: [80][2/5]\tTime 0.073 (0.134)\tData 0.049 (0.107)\tLoss 0.9485 (0.7660)\tAcc 0.625 (0.719)\n",
      "Epoch: [80][3/5]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.6613 (0.7311)\tAcc 0.812 (0.750)\n",
      "Epoch: [80][4/5]\tTime 0.077 (0.106)\tData 0.054 (0.081)\tLoss 0.5697 (0.6907)\tAcc 0.750 (0.750)\n",
      "Epoch: [80][5/5]\tTime 0.078 (0.100)\tData 0.055 (0.076)\tLoss 0.7124 (0.6934)\tAcc 0.667 (0.740)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.199 (0.199)\tData 0.175 (0.175)\tLoss 0.3742 (0.3742)\tAcc 0.938 (0.938)\n",
      "Epoch: [80][2/9]\tTime 0.075 (0.137)\tData 0.051 (0.113)\tLoss 0.9364 (0.6553)\tAcc 0.500 (0.719)\n",
      "Epoch: [80][3/9]\tTime 0.069 (0.114)\tData 0.050 (0.092)\tLoss 0.6654 (0.6587)\tAcc 0.812 (0.750)\n",
      "Epoch: [80][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.7140 (0.6725)\tAcc 0.688 (0.734)\n",
      "Epoch: [80][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.077)\tLoss 0.8239 (0.7028)\tAcc 0.812 (0.750)\n",
      "Epoch: [80][6/9]\tTime 0.073 (0.094)\tData 0.055 (0.073)\tLoss 0.3656 (0.6466)\tAcc 1.000 (0.792)\n",
      "Epoch: [80][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.5644 (0.6348)\tAcc 0.812 (0.795)\n",
      "Epoch: [80][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 0.8118 (0.6570)\tAcc 0.812 (0.797)\n",
      "Epoch: [80][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.1974 (0.6499)\tAcc 1.000 (0.800)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.6177 (0.6177)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.6238 (0.6207)\tAcc 0.812 (0.781)\n",
      "Epoch: [81][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.093)\tLoss 0.9267 (0.7227)\tAcc 0.500 (0.688)\n",
      "Epoch: [81][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.084)\tLoss 0.5465 (0.6787)\tAcc 0.812 (0.719)\n",
      "Epoch: [81][5/5]\tTime 0.079 (0.102)\tData 0.055 (0.078)\tLoss 0.8674 (0.7019)\tAcc 0.667 (0.712)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.199 (0.199)\tData 0.174 (0.174)\tLoss 0.3685 (0.3685)\tAcc 0.938 (0.938)\n",
      "Epoch: [81][2/9]\tTime 0.074 (0.136)\tData 0.049 (0.112)\tLoss 0.8789 (0.6237)\tAcc 0.500 (0.719)\n",
      "Epoch: [81][3/9]\tTime 0.069 (0.114)\tData 0.050 (0.091)\tLoss 0.6466 (0.6313)\tAcc 0.812 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6592 (0.6383)\tAcc 0.750 (0.750)\n",
      "Epoch: [81][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.7180 (0.6542)\tAcc 0.688 (0.738)\n",
      "Epoch: [81][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3364 (0.6013)\tAcc 1.000 (0.781)\n",
      "Epoch: [81][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5411 (0.5927)\tAcc 0.750 (0.777)\n",
      "Epoch: [81][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.9596 (0.6385)\tAcc 0.688 (0.766)\n",
      "Epoch: [81][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.3160 (0.6336)\tAcc 1.000 (0.769)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.197 (0.197)\tData 0.166 (0.166)\tLoss 0.9254 (0.9254)\tAcc 0.625 (0.625)\n",
      "Epoch: [82][2/5]\tTime 0.074 (0.135)\tData 0.049 (0.108)\tLoss 0.3936 (0.6595)\tAcc 0.938 (0.781)\n",
      "Epoch: [82][3/5]\tTime 0.077 (0.116)\tData 0.054 (0.090)\tLoss 0.7406 (0.6865)\tAcc 0.625 (0.729)\n",
      "Epoch: [82][4/5]\tTime 0.078 (0.106)\tData 0.054 (0.081)\tLoss 0.9996 (0.7648)\tAcc 0.562 (0.688)\n",
      "Epoch: [82][5/5]\tTime 0.078 (0.101)\tData 0.055 (0.076)\tLoss 0.5449 (0.7377)\tAcc 0.778 (0.699)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.198 (0.198)\tData 0.168 (0.168)\tLoss 0.4944 (0.4944)\tAcc 0.875 (0.875)\n",
      "Epoch: [82][2/9]\tTime 0.065 (0.132)\tData 0.044 (0.106)\tLoss 0.9714 (0.7329)\tAcc 0.438 (0.656)\n",
      "Epoch: [82][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.088)\tLoss 0.6426 (0.7028)\tAcc 0.812 (0.708)\n",
      "Epoch: [82][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.6626 (0.6927)\tAcc 0.688 (0.703)\n",
      "Epoch: [82][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.8329 (0.7208)\tAcc 0.688 (0.700)\n",
      "Epoch: [82][6/9]\tTime 0.075 (0.093)\tData 0.056 (0.071)\tLoss 0.2618 (0.6443)\tAcc 1.000 (0.750)\n",
      "Epoch: [82][7/9]\tTime 0.075 (0.091)\tData 0.056 (0.069)\tLoss 0.5421 (0.6297)\tAcc 0.812 (0.759)\n",
      "Epoch: [82][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.067)\tLoss 1.0112 (0.6774)\tAcc 0.562 (0.734)\n",
      "Epoch: [82][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.1468 (0.6692)\tAcc 1.000 (0.738)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.200 (0.200)\tData 0.168 (0.168)\tLoss 0.5623 (0.5623)\tAcc 0.812 (0.812)\n",
      "Epoch: [83][2/5]\tTime 0.078 (0.139)\tData 0.052 (0.110)\tLoss 0.4614 (0.5118)\tAcc 0.875 (0.844)\n",
      "Epoch: [83][3/5]\tTime 0.081 (0.120)\tData 0.058 (0.093)\tLoss 1.0063 (0.6766)\tAcc 0.688 (0.792)\n",
      "Epoch: [83][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.083)\tLoss 0.6268 (0.6642)\tAcc 0.750 (0.781)\n",
      "Epoch: [83][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.077)\tLoss 0.8158 (0.6829)\tAcc 0.556 (0.753)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.205 (0.205)\tData 0.175 (0.175)\tLoss 0.3268 (0.3268)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.068 (0.137)\tData 0.045 (0.110)\tLoss 0.8659 (0.5964)\tAcc 0.500 (0.719)\n",
      "Epoch: [83][3/9]\tTime 0.074 (0.116)\tData 0.053 (0.091)\tLoss 0.6472 (0.6133)\tAcc 0.688 (0.708)\n",
      "Epoch: [83][4/9]\tTime 0.078 (0.106)\tData 0.058 (0.083)\tLoss 0.7955 (0.6589)\tAcc 0.625 (0.688)\n",
      "Epoch: [83][5/9]\tTime 0.073 (0.100)\tData 0.054 (0.077)\tLoss 0.7315 (0.6734)\tAcc 0.812 (0.713)\n",
      "Epoch: [83][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.2669 (0.6056)\tAcc 1.000 (0.760)\n",
      "Epoch: [83][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.6216 (0.6079)\tAcc 0.812 (0.768)\n",
      "Epoch: [83][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.9025 (0.6447)\tAcc 0.562 (0.742)\n",
      "Epoch: [83][9/9]\tTime 0.075 (0.088)\tData 0.055 (0.067)\tLoss 0.1409 (0.6370)\tAcc 1.000 (0.746)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.206 (0.206)\tData 0.179 (0.179)\tLoss 0.6352 (0.6352)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][2/5]\tTime 0.075 (0.141)\tData 0.051 (0.115)\tLoss 0.5420 (0.5886)\tAcc 0.750 (0.750)\n",
      "Epoch: [84][3/5]\tTime 0.078 (0.120)\tData 0.054 (0.095)\tLoss 0.6992 (0.6254)\tAcc 0.625 (0.708)\n",
      "Epoch: [84][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.085)\tLoss 0.8040 (0.6701)\tAcc 0.625 (0.688)\n",
      "Epoch: [84][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.079)\tLoss 0.9785 (0.7081)\tAcc 0.556 (0.671)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.200 (0.200)\tData 0.172 (0.172)\tLoss 0.2889 (0.2889)\tAcc 0.938 (0.938)\n",
      "Epoch: [84][2/9]\tTime 0.068 (0.134)\tData 0.046 (0.109)\tLoss 0.8455 (0.5672)\tAcc 0.562 (0.750)\n",
      "Epoch: [84][3/9]\tTime 0.073 (0.114)\tData 0.052 (0.090)\tLoss 0.6341 (0.5895)\tAcc 0.812 (0.771)\n",
      "Epoch: [84][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.081)\tLoss 0.6498 (0.6046)\tAcc 0.688 (0.750)\n",
      "Epoch: [84][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.6477 (0.6132)\tAcc 0.875 (0.775)\n",
      "Epoch: [84][6/9]\tTime 0.076 (0.094)\tData 0.055 (0.072)\tLoss 0.3350 (0.5668)\tAcc 1.000 (0.812)\n",
      "Epoch: [84][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6211 (0.5746)\tAcc 0.750 (0.804)\n",
      "Epoch: [84][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.7640 (0.5983)\tAcc 0.812 (0.805)\n",
      "Epoch: [84][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.1738 (0.5917)\tAcc 1.000 (0.808)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.6531 (0.6531)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.111)\tLoss 0.5392 (0.5962)\tAcc 0.812 (0.750)\n",
      "Epoch: [85][3/5]\tTime 0.079 (0.118)\tData 0.054 (0.092)\tLoss 0.8435 (0.6786)\tAcc 0.688 (0.729)\n",
      "Epoch: [85][4/5]\tTime 0.083 (0.109)\tData 0.059 (0.084)\tLoss 0.4443 (0.6200)\tAcc 0.938 (0.781)\n",
      "Epoch: [85][5/5]\tTime 0.081 (0.103)\tData 0.057 (0.079)\tLoss 0.8021 (0.6425)\tAcc 0.556 (0.753)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.194 (0.194)\tData 0.164 (0.164)\tLoss 0.3273 (0.3273)\tAcc 0.938 (0.938)\n",
      "Epoch: [85][2/9]\tTime 0.067 (0.130)\tData 0.046 (0.105)\tLoss 0.9416 (0.6344)\tAcc 0.438 (0.688)\n",
      "Epoch: [85][3/9]\tTime 0.073 (0.111)\tData 0.053 (0.088)\tLoss 0.6890 (0.6526)\tAcc 0.750 (0.708)\n",
      "Epoch: [85][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.079)\tLoss 0.6975 (0.6638)\tAcc 0.688 (0.703)\n",
      "Epoch: [85][5/9]\tTime 0.073 (0.096)\tData 0.054 (0.074)\tLoss 0.8427 (0.6996)\tAcc 0.750 (0.713)\n",
      "Epoch: [85][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.3102 (0.6347)\tAcc 1.000 (0.760)\n",
      "Epoch: [85][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5380 (0.6209)\tAcc 0.875 (0.777)\n",
      "Epoch: [85][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8214 (0.6460)\tAcc 0.750 (0.773)\n",
      "Epoch: [85][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.065)\tLoss 0.2234 (0.6395)\tAcc 1.000 (0.777)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.6080 (0.6080)\tAcc 0.812 (0.812)\n",
      "Epoch: [86][2/5]\tTime 0.074 (0.137)\tData 0.050 (0.111)\tLoss 1.0200 (0.8140)\tAcc 0.562 (0.688)\n",
      "Epoch: [86][3/5]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 0.4349 (0.6876)\tAcc 0.750 (0.708)\n",
      "Epoch: [86][4/5]\tTime 0.078 (0.107)\tData 0.055 (0.083)\tLoss 0.7986 (0.7154)\tAcc 0.625 (0.688)\n",
      "Epoch: [86][5/5]\tTime 0.078 (0.101)\tData 0.055 (0.077)\tLoss 0.7444 (0.7190)\tAcc 0.889 (0.712)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.201 (0.201)\tData 0.176 (0.176)\tLoss 0.4169 (0.4169)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.075 (0.138)\tData 0.050 (0.113)\tLoss 0.8152 (0.6161)\tAcc 0.500 (0.719)\n",
      "Epoch: [86][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.091)\tLoss 0.7337 (0.6553)\tAcc 0.688 (0.708)\n",
      "Epoch: [86][4/9]\tTime 0.073 (0.104)\tData 0.053 (0.082)\tLoss 0.6456 (0.6529)\tAcc 0.750 (0.719)\n",
      "Epoch: [86][5/9]\tTime 0.073 (0.098)\tData 0.053 (0.076)\tLoss 0.7377 (0.6698)\tAcc 0.812 (0.738)\n",
      "Epoch: [86][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.3099 (0.6098)\tAcc 1.000 (0.781)\n",
      "Epoch: [86][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5949 (0.6077)\tAcc 0.750 (0.777)\n",
      "Epoch: [86][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8255 (0.6349)\tAcc 0.625 (0.758)\n",
      "Epoch: [86][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.1888 (0.6281)\tAcc 1.000 (0.762)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.198 (0.198)\tData 0.170 (0.170)\tLoss 0.7325 (0.7325)\tAcc 0.688 (0.688)\n",
      "Epoch: [87][2/5]\tTime 0.074 (0.136)\tData 0.051 (0.110)\tLoss 0.4332 (0.5828)\tAcc 0.812 (0.750)\n",
      "Epoch: [87][3/5]\tTime 0.077 (0.116)\tData 0.054 (0.091)\tLoss 0.6491 (0.6049)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][4/5]\tTime 0.078 (0.107)\tData 0.055 (0.082)\tLoss 0.7009 (0.6289)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][5/5]\tTime 0.081 (0.102)\tData 0.058 (0.077)\tLoss 0.7999 (0.6500)\tAcc 0.667 (0.740)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.202 (0.202)\tData 0.171 (0.171)\tLoss 0.3425 (0.3425)\tAcc 0.938 (0.938)\n",
      "Epoch: [87][2/9]\tTime 0.088 (0.145)\tData 0.058 (0.115)\tLoss 1.0663 (0.7044)\tAcc 0.438 (0.688)\n",
      "Epoch: [87][3/9]\tTime 0.070 (0.120)\tData 0.051 (0.093)\tLoss 0.5266 (0.6451)\tAcc 0.812 (0.729)\n",
      "Epoch: [87][4/9]\tTime 0.091 (0.113)\tData 0.071 (0.088)\tLoss 0.6740 (0.6524)\tAcc 0.625 (0.703)\n",
      "Epoch: [87][5/9]\tTime 0.078 (0.106)\tData 0.059 (0.082)\tLoss 0.7415 (0.6702)\tAcc 0.750 (0.713)\n",
      "Epoch: [87][6/9]\tTime 0.079 (0.101)\tData 0.060 (0.078)\tLoss 0.2803 (0.6052)\tAcc 1.000 (0.760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.078 (0.098)\tData 0.059 (0.076)\tLoss 0.5785 (0.6014)\tAcc 0.875 (0.777)\n",
      "Epoch: [87][8/9]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 0.8677 (0.6347)\tAcc 0.688 (0.766)\n",
      "Epoch: [87][9/9]\tTime 0.079 (0.094)\tData 0.060 (0.072)\tLoss 0.3049 (0.6296)\tAcc 1.000 (0.769)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.200 (0.200)\tData 0.168 (0.168)\tLoss 0.6162 (0.6162)\tAcc 0.750 (0.750)\n",
      "Epoch: [88][2/5]\tTime 0.074 (0.137)\tData 0.049 (0.109)\tLoss 0.6393 (0.6278)\tAcc 0.812 (0.781)\n",
      "Epoch: [88][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.090)\tLoss 1.0598 (0.7718)\tAcc 0.625 (0.729)\n",
      "Epoch: [88][4/5]\tTime 0.078 (0.107)\tData 0.055 (0.081)\tLoss 0.6156 (0.7327)\tAcc 0.688 (0.719)\n",
      "Epoch: [88][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.5730 (0.7131)\tAcc 0.889 (0.740)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.200 (0.200)\tData 0.176 (0.176)\tLoss 0.3698 (0.3698)\tAcc 0.938 (0.938)\n",
      "Epoch: [88][2/9]\tTime 0.076 (0.138)\tData 0.051 (0.113)\tLoss 0.9303 (0.6501)\tAcc 0.625 (0.781)\n",
      "Epoch: [88][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.092)\tLoss 0.6972 (0.6658)\tAcc 0.625 (0.729)\n",
      "Epoch: [88][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6544 (0.6629)\tAcc 0.688 (0.719)\n",
      "Epoch: [88][5/9]\tTime 0.076 (0.099)\tData 0.056 (0.077)\tLoss 0.8171 (0.6938)\tAcc 0.688 (0.713)\n",
      "Epoch: [88][6/9]\tTime 0.078 (0.095)\tData 0.057 (0.074)\tLoss 0.3423 (0.6352)\tAcc 1.000 (0.760)\n",
      "Epoch: [88][7/9]\tTime 0.079 (0.093)\tData 0.059 (0.072)\tLoss 0.5973 (0.6298)\tAcc 0.875 (0.777)\n",
      "Epoch: [88][8/9]\tTime 0.078 (0.091)\tData 0.058 (0.070)\tLoss 0.8135 (0.6527)\tAcc 0.750 (0.773)\n",
      "Epoch: [88][9/9]\tTime 0.077 (0.089)\tData 0.058 (0.069)\tLoss 0.2491 (0.6465)\tAcc 1.000 (0.777)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.6546 (0.6546)\tAcc 0.812 (0.812)\n",
      "Epoch: [89][2/5]\tTime 0.080 (0.142)\tData 0.055 (0.115)\tLoss 0.5662 (0.6104)\tAcc 0.688 (0.750)\n",
      "Epoch: [89][3/5]\tTime 0.084 (0.122)\tData 0.059 (0.096)\tLoss 0.7411 (0.6540)\tAcc 0.812 (0.771)\n",
      "Epoch: [89][4/5]\tTime 0.083 (0.113)\tData 0.059 (0.087)\tLoss 0.5688 (0.6327)\tAcc 0.750 (0.766)\n",
      "Epoch: [89][5/5]\tTime 0.083 (0.107)\tData 0.059 (0.081)\tLoss 0.9258 (0.6688)\tAcc 0.667 (0.753)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.205 (0.205)\tData 0.182 (0.182)\tLoss 0.3905 (0.3905)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.084 (0.145)\tData 0.056 (0.119)\tLoss 0.9454 (0.6680)\tAcc 0.438 (0.688)\n",
      "Epoch: [89][3/9]\tTime 0.066 (0.118)\tData 0.047 (0.095)\tLoss 0.5646 (0.6335)\tAcc 0.875 (0.750)\n",
      "Epoch: [89][4/9]\tTime 0.074 (0.107)\tData 0.054 (0.085)\tLoss 0.6610 (0.6404)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.079)\tLoss 0.7343 (0.6592)\tAcc 0.750 (0.750)\n",
      "Epoch: [89][6/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.3340 (0.6050)\tAcc 1.000 (0.792)\n",
      "Epoch: [89][7/9]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.6257 (0.6079)\tAcc 0.812 (0.795)\n",
      "Epoch: [89][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.9802 (0.6545)\tAcc 0.625 (0.773)\n",
      "Epoch: [89][9/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.3305 (0.6495)\tAcc 1.000 (0.777)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.205 (0.205)\tData 0.177 (0.177)\tLoss 0.9222 (0.9222)\tAcc 0.625 (0.625)\n",
      "Epoch: [90][2/5]\tTime 0.075 (0.140)\tData 0.051 (0.114)\tLoss 0.3863 (0.6542)\tAcc 0.812 (0.719)\n",
      "Epoch: [90][3/5]\tTime 0.077 (0.119)\tData 0.054 (0.094)\tLoss 0.6336 (0.6474)\tAcc 0.750 (0.729)\n",
      "Epoch: [90][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.084)\tLoss 0.5980 (0.6350)\tAcc 0.750 (0.734)\n",
      "Epoch: [90][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 0.9742 (0.6769)\tAcc 0.778 (0.740)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.195 (0.195)\tData 0.166 (0.166)\tLoss 0.3220 (0.3220)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/9]\tTime 0.067 (0.131)\tData 0.046 (0.106)\tLoss 0.9208 (0.6214)\tAcc 0.500 (0.719)\n",
      "Epoch: [90][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.088)\tLoss 0.6401 (0.6276)\tAcc 0.750 (0.729)\n",
      "Epoch: [90][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.6575 (0.6351)\tAcc 0.625 (0.703)\n",
      "Epoch: [90][5/9]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.6925 (0.6466)\tAcc 0.750 (0.713)\n",
      "Epoch: [90][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.2494 (0.5804)\tAcc 1.000 (0.760)\n",
      "Epoch: [90][7/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.6017 (0.5834)\tAcc 0.875 (0.777)\n",
      "Epoch: [90][8/9]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 1.0121 (0.6370)\tAcc 0.562 (0.750)\n",
      "Epoch: [90][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.066)\tLoss 0.2820 (0.6316)\tAcc 1.000 (0.754)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.201 (0.201)\tData 0.170 (0.170)\tLoss 0.7761 (0.7761)\tAcc 0.688 (0.688)\n",
      "Epoch: [91][2/5]\tTime 0.073 (0.137)\tData 0.049 (0.110)\tLoss 0.8518 (0.8139)\tAcc 0.625 (0.656)\n",
      "Epoch: [91][3/5]\tTime 0.081 (0.118)\tData 0.056 (0.092)\tLoss 0.5499 (0.7259)\tAcc 0.812 (0.708)\n",
      "Epoch: [91][4/5]\tTime 0.077 (0.108)\tData 0.054 (0.082)\tLoss 0.4809 (0.6647)\tAcc 0.875 (0.750)\n",
      "Epoch: [91][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.9062 (0.6944)\tAcc 0.556 (0.726)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.201 (0.201)\tData 0.167 (0.167)\tLoss 0.4406 (0.4406)\tAcc 0.938 (0.938)\n",
      "Epoch: [91][2/9]\tTime 0.064 (0.132)\tData 0.042 (0.104)\tLoss 0.9866 (0.7136)\tAcc 0.562 (0.750)\n",
      "Epoch: [91][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.087)\tLoss 0.6017 (0.6763)\tAcc 0.625 (0.708)\n",
      "Epoch: [91][4/9]\tTime 0.074 (0.103)\tData 0.054 (0.079)\tLoss 0.7465 (0.6938)\tAcc 0.625 (0.688)\n",
      "Epoch: [91][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.074)\tLoss 0.6525 (0.6856)\tAcc 0.875 (0.725)\n",
      "Epoch: [91][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.070)\tLoss 0.2604 (0.6147)\tAcc 1.000 (0.771)\n",
      "Epoch: [91][7/9]\tTime 0.076 (0.090)\tData 0.057 (0.068)\tLoss 0.6576 (0.6208)\tAcc 0.688 (0.759)\n",
      "Epoch: [91][8/9]\tTime 0.079 (0.089)\tData 0.059 (0.067)\tLoss 0.8681 (0.6517)\tAcc 0.625 (0.742)\n",
      "Epoch: [91][9/9]\tTime 0.080 (0.088)\tData 0.061 (0.066)\tLoss 0.1274 (0.6437)\tAcc 1.000 (0.746)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.203 (0.203)\tData 0.172 (0.172)\tLoss 0.7014 (0.7014)\tAcc 0.688 (0.688)\n",
      "Epoch: [92][2/5]\tTime 0.072 (0.138)\tData 0.048 (0.110)\tLoss 0.5430 (0.6222)\tAcc 0.750 (0.719)\n",
      "Epoch: [92][3/5]\tTime 0.078 (0.118)\tData 0.053 (0.091)\tLoss 0.7729 (0.6724)\tAcc 0.750 (0.729)\n",
      "Epoch: [92][4/5]\tTime 0.079 (0.108)\tData 0.054 (0.082)\tLoss 0.7908 (0.7020)\tAcc 0.688 (0.719)\n",
      "Epoch: [92][5/5]\tTime 0.081 (0.102)\tData 0.056 (0.076)\tLoss 0.5199 (0.6796)\tAcc 0.889 (0.740)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.224 (0.224)\tData 0.180 (0.180)\tLoss 0.3822 (0.3822)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/9]\tTime 0.069 (0.146)\tData 0.039 (0.110)\tLoss 1.0340 (0.7081)\tAcc 0.438 (0.688)\n",
      "Epoch: [92][3/9]\tTime 0.073 (0.122)\tData 0.053 (0.091)\tLoss 0.6351 (0.6838)\tAcc 0.750 (0.708)\n",
      "Epoch: [92][4/9]\tTime 0.077 (0.111)\tData 0.058 (0.083)\tLoss 0.5736 (0.6562)\tAcc 0.750 (0.719)\n",
      "Epoch: [92][5/9]\tTime 0.077 (0.104)\tData 0.058 (0.078)\tLoss 0.7441 (0.6738)\tAcc 0.812 (0.738)\n",
      "Epoch: [92][6/9]\tTime 0.079 (0.100)\tData 0.060 (0.075)\tLoss 0.3253 (0.6157)\tAcc 1.000 (0.781)\n",
      "Epoch: [92][7/9]\tTime 0.082 (0.097)\tData 0.062 (0.073)\tLoss 0.6834 (0.6254)\tAcc 0.812 (0.786)\n",
      "Epoch: [92][8/9]\tTime 0.089 (0.096)\tData 0.070 (0.073)\tLoss 0.8630 (0.6551)\tAcc 0.625 (0.766)\n",
      "Epoch: [92][9/9]\tTime 0.078 (0.094)\tData 0.060 (0.071)\tLoss 0.4186 (0.6514)\tAcc 1.000 (0.769)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.6754 (0.6754)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.111)\tLoss 0.4328 (0.5541)\tAcc 0.812 (0.750)\n",
      "Epoch: [93][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.092)\tLoss 0.6397 (0.5827)\tAcc 0.688 (0.729)\n",
      "Epoch: [93][4/5]\tTime 0.079 (0.108)\tData 0.056 (0.083)\tLoss 1.0637 (0.7029)\tAcc 0.562 (0.688)\n",
      "Epoch: [93][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.4246 (0.6686)\tAcc 0.889 (0.712)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.203 (0.203)\tData 0.179 (0.179)\tLoss 0.3865 (0.3865)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/9]\tTime 0.077 (0.140)\tData 0.051 (0.115)\tLoss 0.9608 (0.6736)\tAcc 0.438 (0.688)\n",
      "Epoch: [93][3/9]\tTime 0.067 (0.116)\tData 0.047 (0.092)\tLoss 0.7748 (0.7074)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][4/9]\tTime 0.074 (0.105)\tData 0.055 (0.083)\tLoss 0.6563 (0.6946)\tAcc 0.688 (0.688)\n",
      "Epoch: [93][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.7412 (0.7039)\tAcc 0.812 (0.713)\n",
      "Epoch: [93][6/9]\tTime 0.076 (0.095)\tData 0.054 (0.074)\tLoss 0.3553 (0.6458)\tAcc 1.000 (0.760)\n",
      "Epoch: [93][7/9]\tTime 0.071 (0.092)\tData 0.052 (0.070)\tLoss 0.6485 (0.6462)\tAcc 0.812 (0.768)\n",
      "Epoch: [93][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.068)\tLoss 0.7745 (0.6622)\tAcc 0.688 (0.758)\n",
      "Epoch: [93][9/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.2326 (0.6556)\tAcc 1.000 (0.762)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.209 (0.209)\tData 0.181 (0.181)\tLoss 0.5339 (0.5339)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][2/5]\tTime 0.077 (0.143)\tData 0.052 (0.117)\tLoss 0.6177 (0.5758)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][3/5]\tTime 0.078 (0.121)\tData 0.053 (0.096)\tLoss 0.9729 (0.7082)\tAcc 0.500 (0.708)\n",
      "Epoch: [94][4/5]\tTime 0.079 (0.111)\tData 0.056 (0.086)\tLoss 0.5043 (0.6572)\tAcc 0.875 (0.750)\n",
      "Epoch: [94][5/5]\tTime 0.078 (0.104)\tData 0.054 (0.079)\tLoss 0.9040 (0.6876)\tAcc 0.556 (0.726)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.3491 (0.3491)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/9]\tTime 0.069 (0.133)\tData 0.047 (0.109)\tLoss 0.9499 (0.6495)\tAcc 0.500 (0.719)\n",
      "Epoch: [94][3/9]\tTime 0.072 (0.113)\tData 0.052 (0.090)\tLoss 0.7470 (0.6820)\tAcc 0.688 (0.708)\n",
      "Epoch: [94][4/9]\tTime 0.074 (0.103)\tData 0.055 (0.081)\tLoss 0.6055 (0.6629)\tAcc 0.625 (0.688)\n",
      "Epoch: [94][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.076)\tLoss 0.6846 (0.6672)\tAcc 0.812 (0.713)\n",
      "Epoch: [94][6/9]\tTime 0.075 (0.094)\tData 0.056 (0.073)\tLoss 0.3467 (0.6138)\tAcc 1.000 (0.760)\n",
      "Epoch: [94][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.5343 (0.6024)\tAcc 0.750 (0.759)\n",
      "Epoch: [94][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.8953 (0.6390)\tAcc 0.625 (0.742)\n",
      "Epoch: [94][9/9]\tTime 0.074 (0.087)\tData 0.055 (0.067)\tLoss 0.2322 (0.6328)\tAcc 1.000 (0.746)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.196 (0.196)\tData 0.164 (0.164)\tLoss 0.3608 (0.3608)\tAcc 1.000 (1.000)\n",
      "Epoch: [95][2/5]\tTime 0.071 (0.134)\tData 0.047 (0.106)\tLoss 0.5599 (0.4603)\tAcc 0.812 (0.906)\n",
      "Epoch: [95][3/5]\tTime 0.078 (0.115)\tData 0.054 (0.089)\tLoss 0.9330 (0.6179)\tAcc 0.562 (0.792)\n",
      "Epoch: [95][4/5]\tTime 0.078 (0.106)\tData 0.054 (0.080)\tLoss 0.7066 (0.6401)\tAcc 0.688 (0.766)\n",
      "Epoch: [95][5/5]\tTime 0.078 (0.100)\tData 0.056 (0.075)\tLoss 0.8767 (0.6692)\tAcc 0.556 (0.740)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.203 (0.203)\tData 0.177 (0.177)\tLoss 0.3611 (0.3611)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/9]\tTime 0.075 (0.139)\tData 0.049 (0.113)\tLoss 0.9820 (0.6716)\tAcc 0.438 (0.688)\n",
      "Epoch: [95][3/9]\tTime 0.069 (0.116)\tData 0.049 (0.092)\tLoss 0.6988 (0.6806)\tAcc 0.812 (0.729)\n",
      "Epoch: [95][4/9]\tTime 0.075 (0.105)\tData 0.055 (0.083)\tLoss 0.5734 (0.6538)\tAcc 0.812 (0.750)\n",
      "Epoch: [95][5/9]\tTime 0.074 (0.099)\tData 0.055 (0.077)\tLoss 0.6249 (0.6480)\tAcc 0.750 (0.750)\n",
      "Epoch: [95][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.2719 (0.5854)\tAcc 1.000 (0.792)\n",
      "Epoch: [95][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.6124 (0.5892)\tAcc 0.750 (0.786)\n",
      "Epoch: [95][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.7897 (0.6143)\tAcc 0.750 (0.781)\n",
      "Epoch: [95][9/9]\tTime 0.074 (0.088)\tData 0.054 (0.067)\tLoss 0.2834 (0.6092)\tAcc 1.000 (0.785)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.200 (0.200)\tData 0.172 (0.172)\tLoss 0.4491 (0.4491)\tAcc 0.812 (0.812)\n",
      "Epoch: [96][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.112)\tLoss 0.9336 (0.6913)\tAcc 0.625 (0.719)\n",
      "Epoch: [96][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.093)\tLoss 0.7998 (0.7275)\tAcc 0.688 (0.708)\n",
      "Epoch: [96][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.7247 (0.7268)\tAcc 0.688 (0.703)\n",
      "Epoch: [96][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.3826 (0.6844)\tAcc 0.889 (0.726)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.195 (0.195)\tData 0.165 (0.165)\tLoss 0.4345 (0.4345)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/9]\tTime 0.066 (0.130)\tData 0.045 (0.105)\tLoss 0.9529 (0.6937)\tAcc 0.438 (0.688)\n",
      "Epoch: [96][3/9]\tTime 0.075 (0.112)\tData 0.055 (0.088)\tLoss 0.5806 (0.6560)\tAcc 0.812 (0.729)\n",
      "Epoch: [96][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.6161 (0.6460)\tAcc 0.625 (0.703)\n",
      "Epoch: [96][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.6779 (0.6524)\tAcc 0.875 (0.738)\n",
      "Epoch: [96][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.2718 (0.5890)\tAcc 1.000 (0.781)\n",
      "Epoch: [96][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5508 (0.5835)\tAcc 0.875 (0.795)\n",
      "Epoch: [96][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.7687 (0.6067)\tAcc 0.688 (0.781)\n",
      "Epoch: [96][9/9]\tTime 0.073 (0.086)\tData 0.054 (0.066)\tLoss 0.3536 (0.6028)\tAcc 1.000 (0.785)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.6305 (0.6305)\tAcc 0.688 (0.688)\n",
      "Epoch: [97][2/5]\tTime 0.075 (0.137)\tData 0.050 (0.110)\tLoss 0.4953 (0.5629)\tAcc 0.812 (0.750)\n",
      "Epoch: [97][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 0.8730 (0.6663)\tAcc 0.688 (0.729)\n",
      "Epoch: [97][4/5]\tTime 0.078 (0.107)\tData 0.054 (0.082)\tLoss 0.7146 (0.6784)\tAcc 0.750 (0.734)\n",
      "Epoch: [97][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.077)\tLoss 0.5167 (0.6584)\tAcc 0.778 (0.740)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.203 (0.203)\tData 0.179 (0.179)\tLoss 0.4301 (0.4301)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/9]\tTime 0.078 (0.141)\tData 0.051 (0.115)\tLoss 0.8477 (0.6389)\tAcc 0.500 (0.719)\n",
      "Epoch: [97][3/9]\tTime 0.068 (0.116)\tData 0.048 (0.093)\tLoss 0.6175 (0.6318)\tAcc 0.812 (0.750)\n",
      "Epoch: [97][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.6180 (0.6283)\tAcc 0.688 (0.734)\n",
      "Epoch: [97][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7277 (0.6482)\tAcc 0.812 (0.750)\n",
      "Epoch: [97][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.2677 (0.5848)\tAcc 1.000 (0.792)\n",
      "Epoch: [97][7/9]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.7291 (0.6054)\tAcc 0.750 (0.786)\n",
      "Epoch: [97][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.068)\tLoss 0.7773 (0.6269)\tAcc 0.750 (0.781)\n",
      "Epoch: [97][9/9]\tTime 0.075 (0.088)\tData 0.056 (0.067)\tLoss 0.3494 (0.6226)\tAcc 1.000 (0.785)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.201 (0.201)\tData 0.172 (0.172)\tLoss 0.8338 (0.8338)\tAcc 0.625 (0.625)\n",
      "Epoch: [98][2/5]\tTime 0.075 (0.138)\tData 0.050 (0.111)\tLoss 0.5705 (0.7021)\tAcc 0.812 (0.719)\n",
      "Epoch: [98][3/5]\tTime 0.079 (0.118)\tData 0.056 (0.092)\tLoss 0.5668 (0.6570)\tAcc 0.812 (0.750)\n",
      "Epoch: [98][4/5]\tTime 0.079 (0.108)\tData 0.055 (0.083)\tLoss 0.6480 (0.6548)\tAcc 0.812 (0.766)\n",
      "Epoch: [98][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.5607 (0.6432)\tAcc 0.778 (0.767)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.199 (0.199)\tData 0.174 (0.174)\tLoss 0.3838 (0.3838)\tAcc 0.938 (0.938)\n",
      "Epoch: [98][2/9]\tTime 0.074 (0.136)\tData 0.049 (0.111)\tLoss 0.8417 (0.6128)\tAcc 0.562 (0.750)\n",
      "Epoch: [98][3/9]\tTime 0.070 (0.114)\tData 0.050 (0.091)\tLoss 0.7210 (0.6489)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 0.7148 (0.6654)\tAcc 0.625 (0.719)\n",
      "Epoch: [98][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.077)\tLoss 0.6901 (0.6703)\tAcc 0.875 (0.750)\n",
      "Epoch: [98][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.073)\tLoss 0.2978 (0.6082)\tAcc 1.000 (0.792)\n",
      "Epoch: [98][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6124 (0.6088)\tAcc 0.875 (0.804)\n",
      "Epoch: [98][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9344 (0.6495)\tAcc 0.750 (0.797)\n",
      "Epoch: [98][9/9]\tTime 0.075 (0.087)\tData 0.055 (0.067)\tLoss 0.2985 (0.6441)\tAcc 1.000 (0.800)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.202 (0.202)\tData 0.175 (0.175)\tLoss 0.6288 (0.6288)\tAcc 0.750 (0.750)\n",
      "Epoch: [99][2/5]\tTime 0.076 (0.139)\tData 0.052 (0.113)\tLoss 0.4810 (0.5549)\tAcc 0.938 (0.844)\n",
      "Epoch: [99][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.094)\tLoss 0.8765 (0.6621)\tAcc 0.625 (0.771)\n",
      "Epoch: [99][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.5752 (0.6404)\tAcc 0.875 (0.797)\n",
      "Epoch: [99][5/5]\tTime 0.079 (0.102)\tData 0.056 (0.078)\tLoss 0.5815 (0.6331)\tAcc 0.778 (0.795)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.3838 (0.3838)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.071 (0.135)\tData 0.047 (0.108)\tLoss 0.9459 (0.6649)\tAcc 0.438 (0.688)\n",
      "Epoch: [99][3/9]\tTime 0.072 (0.114)\tData 0.052 (0.089)\tLoss 0.6397 (0.6565)\tAcc 0.812 (0.729)\n",
      "Epoch: [99][4/9]\tTime 0.074 (0.104)\tData 0.054 (0.081)\tLoss 0.7216 (0.6728)\tAcc 0.625 (0.703)\n",
      "Epoch: [99][5/9]\tTime 0.075 (0.098)\tData 0.055 (0.075)\tLoss 0.7348 (0.6852)\tAcc 0.750 (0.713)\n",
      "Epoch: [99][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.3269 (0.6254)\tAcc 1.000 (0.760)\n",
      "Epoch: [99][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.069)\tLoss 0.7123 (0.6379)\tAcc 0.750 (0.759)\n",
      "Epoch: [99][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.9140 (0.6724)\tAcc 0.750 (0.758)\n",
      "Epoch: [99][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.3443 (0.6673)\tAcc 1.000 (0.762)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.198 (0.198)\tData 0.167 (0.167)\tLoss 0.5918 (0.5918)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][2/5]\tTime 0.072 (0.135)\tData 0.048 (0.107)\tLoss 0.6628 (0.6273)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][3/5]\tTime 0.077 (0.116)\tData 0.053 (0.089)\tLoss 0.5515 (0.6020)\tAcc 0.875 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.078 (0.106)\tData 0.054 (0.081)\tLoss 0.7612 (0.6418)\tAcc 0.812 (0.797)\n",
      "Epoch: [100][5/5]\tTime 0.079 (0.101)\tData 0.055 (0.076)\tLoss 0.9723 (0.6826)\tAcc 0.667 (0.781)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.201 (0.201)\tData 0.177 (0.177)\tLoss 0.3431 (0.3431)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.078 (0.140)\tData 0.052 (0.114)\tLoss 0.8980 (0.6205)\tAcc 0.625 (0.781)\n",
      "Epoch: [100][3/9]\tTime 0.067 (0.115)\tData 0.048 (0.092)\tLoss 0.6725 (0.6378)\tAcc 0.750 (0.771)\n",
      "Epoch: [100][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.7060 (0.6549)\tAcc 0.688 (0.750)\n",
      "Epoch: [100][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7182 (0.6675)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3476 (0.6142)\tAcc 1.000 (0.792)\n",
      "Epoch: [100][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5645 (0.6071)\tAcc 0.812 (0.795)\n",
      "Epoch: [100][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.7930 (0.6303)\tAcc 0.688 (0.781)\n",
      "Epoch: [100][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.067)\tLoss 0.4989 (0.6283)\tAcc 1.000 (0.785)\n",
      "train at epoch 101\n",
      "Epoch: [101][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.5184 (0.5184)\tAcc 0.812 (0.812)\n",
      "Epoch: [101][2/5]\tTime 0.075 (0.138)\tData 0.052 (0.113)\tLoss 0.5342 (0.5263)\tAcc 0.812 (0.812)\n",
      "Epoch: [101][3/5]\tTime 0.078 (0.118)\tData 0.055 (0.094)\tLoss 0.8926 (0.6484)\tAcc 0.688 (0.771)\n",
      "Epoch: [101][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.7952 (0.6851)\tAcc 0.625 (0.734)\n",
      "Epoch: [101][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.9924 (0.7230)\tAcc 0.556 (0.712)\n",
      "validation at epoch 101\n",
      "Epoch: [101][1/9]\tTime 0.193 (0.193)\tData 0.165 (0.165)\tLoss 0.5118 (0.5118)\tAcc 0.938 (0.938)\n",
      "Epoch: [101][2/9]\tTime 0.067 (0.130)\tData 0.046 (0.106)\tLoss 0.8851 (0.6985)\tAcc 0.438 (0.688)\n",
      "Epoch: [101][3/9]\tTime 0.072 (0.111)\tData 0.053 (0.088)\tLoss 0.6786 (0.6918)\tAcc 0.750 (0.708)\n",
      "Epoch: [101][4/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.7291 (0.7012)\tAcc 0.625 (0.688)\n",
      "Epoch: [101][5/9]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.8001 (0.7209)\tAcc 0.750 (0.700)\n",
      "Epoch: [101][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.3592 (0.6607)\tAcc 1.000 (0.750)\n",
      "Epoch: [101][7/9]\tTime 0.074 (0.089)\tData 0.055 (0.069)\tLoss 0.7422 (0.6723)\tAcc 0.688 (0.741)\n",
      "Epoch: [101][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.8130 (0.6899)\tAcc 0.625 (0.727)\n",
      "Epoch: [101][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.066)\tLoss 0.3642 (0.6849)\tAcc 1.000 (0.731)\n",
      "train at epoch 102\n",
      "Epoch: [102][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.6088 (0.6088)\tAcc 0.688 (0.688)\n",
      "Epoch: [102][2/5]\tTime 0.076 (0.139)\tData 0.052 (0.113)\tLoss 0.7036 (0.6562)\tAcc 0.688 (0.688)\n",
      "Epoch: [102][3/5]\tTime 0.078 (0.119)\tData 0.055 (0.093)\tLoss 0.7800 (0.6975)\tAcc 0.750 (0.708)\n",
      "Epoch: [102][4/5]\tTime 0.079 (0.109)\tData 0.056 (0.084)\tLoss 0.5689 (0.6653)\tAcc 0.812 (0.734)\n",
      "Epoch: [102][5/5]\tTime 0.078 (0.103)\tData 0.054 (0.078)\tLoss 0.9793 (0.7040)\tAcc 0.667 (0.726)\n",
      "validation at epoch 102\n",
      "Epoch: [102][1/9]\tTime 0.201 (0.201)\tData 0.178 (0.178)\tLoss 0.3752 (0.3752)\tAcc 0.938 (0.938)\n",
      "Epoch: [102][2/9]\tTime 0.077 (0.139)\tData 0.051 (0.114)\tLoss 0.9780 (0.6766)\tAcc 0.438 (0.688)\n",
      "Epoch: [102][3/9]\tTime 0.067 (0.115)\tData 0.047 (0.092)\tLoss 0.6835 (0.6789)\tAcc 0.812 (0.729)\n",
      "Epoch: [102][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.7454 (0.6955)\tAcc 0.812 (0.750)\n",
      "Epoch: [102][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.077)\tLoss 0.7491 (0.7062)\tAcc 0.750 (0.750)\n",
      "Epoch: [102][6/9]\tTime 0.075 (0.094)\tData 0.055 (0.073)\tLoss 0.2814 (0.6354)\tAcc 1.000 (0.792)\n",
      "Epoch: [102][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5788 (0.6273)\tAcc 0.812 (0.795)\n",
      "Epoch: [102][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8899 (0.6601)\tAcc 0.562 (0.766)\n",
      "Epoch: [102][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.3104 (0.6548)\tAcc 1.000 (0.769)\n",
      "train at epoch 103\n",
      "Epoch: [103][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.5257 (0.5257)\tAcc 0.750 (0.750)\n",
      "Epoch: [103][2/5]\tTime 0.077 (0.139)\tData 0.053 (0.114)\tLoss 0.4820 (0.5038)\tAcc 0.812 (0.781)\n",
      "Epoch: [103][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.094)\tLoss 0.6314 (0.5464)\tAcc 0.750 (0.771)\n",
      "Epoch: [103][4/5]\tTime 0.079 (0.109)\tData 0.056 (0.085)\tLoss 0.7147 (0.5885)\tAcc 0.688 (0.750)\n",
      "Epoch: [103][5/5]\tTime 0.078 (0.103)\tData 0.056 (0.079)\tLoss 0.9230 (0.6297)\tAcc 0.778 (0.753)\n",
      "validation at epoch 103\n",
      "Epoch: [103][1/9]\tTime 0.201 (0.201)\tData 0.178 (0.178)\tLoss 0.3618 (0.3618)\tAcc 0.938 (0.938)\n",
      "Epoch: [103][2/9]\tTime 0.076 (0.139)\tData 0.051 (0.114)\tLoss 0.9300 (0.6459)\tAcc 0.438 (0.688)\n",
      "Epoch: [103][3/9]\tTime 0.069 (0.116)\tData 0.050 (0.093)\tLoss 0.7125 (0.6681)\tAcc 0.750 (0.708)\n",
      "Epoch: [103][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.6317 (0.6590)\tAcc 0.688 (0.703)\n",
      "Epoch: [103][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7657 (0.6804)\tAcc 0.750 (0.713)\n",
      "Epoch: [103][6/9]\tTime 0.074 (0.095)\tData 0.055 (0.074)\tLoss 0.3691 (0.6285)\tAcc 1.000 (0.760)\n",
      "Epoch: [103][7/9]\tTime 0.075 (0.092)\tData 0.056 (0.071)\tLoss 0.6146 (0.6265)\tAcc 0.812 (0.768)\n",
      "Epoch: [103][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.9062 (0.6615)\tAcc 0.688 (0.758)\n",
      "Epoch: [103][9/9]\tTime 0.072 (0.088)\tData 0.054 (0.067)\tLoss 0.2914 (0.6558)\tAcc 1.000 (0.762)\n",
      "train at epoch 104\n",
      "Epoch: [104][1/5]\tTime 0.196 (0.196)\tData 0.166 (0.166)\tLoss 0.6030 (0.6030)\tAcc 0.812 (0.812)\n",
      "Epoch: [104][2/5]\tTime 0.078 (0.137)\tData 0.053 (0.109)\tLoss 0.9297 (0.7663)\tAcc 0.562 (0.688)\n",
      "Epoch: [104][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 0.5204 (0.6844)\tAcc 0.875 (0.750)\n",
      "Epoch: [104][4/5]\tTime 0.080 (0.108)\tData 0.056 (0.082)\tLoss 0.8849 (0.7345)\tAcc 0.688 (0.734)\n",
      "Epoch: [104][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.6487 (0.7239)\tAcc 0.778 (0.740)\n",
      "validation at epoch 104\n",
      "Epoch: [104][1/9]\tTime 0.198 (0.198)\tData 0.171 (0.171)\tLoss 0.3411 (0.3411)\tAcc 0.938 (0.938)\n",
      "Epoch: [104][2/9]\tTime 0.079 (0.139)\tData 0.053 (0.112)\tLoss 0.9357 (0.6384)\tAcc 0.562 (0.750)\n",
      "Epoch: [104][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.091)\tLoss 0.6977 (0.6582)\tAcc 0.750 (0.750)\n",
      "Epoch: [104][4/9]\tTime 0.072 (0.104)\tData 0.053 (0.081)\tLoss 0.6667 (0.6603)\tAcc 0.625 (0.719)\n",
      "Epoch: [104][5/9]\tTime 0.073 (0.098)\tData 0.055 (0.076)\tLoss 0.8372 (0.6957)\tAcc 0.625 (0.700)\n",
      "Epoch: [104][6/9]\tTime 0.073 (0.094)\tData 0.055 (0.072)\tLoss 0.3270 (0.6342)\tAcc 1.000 (0.750)\n",
      "Epoch: [104][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.7108 (0.6452)\tAcc 0.750 (0.750)\n",
      "Epoch: [104][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.8451 (0.6702)\tAcc 0.625 (0.734)\n",
      "Epoch: [104][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.067)\tLoss 0.3453 (0.6652)\tAcc 1.000 (0.738)\n",
      "train at epoch 105\n",
      "Epoch: [105][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.7589 (0.7589)\tAcc 0.688 (0.688)\n",
      "Epoch: [105][2/5]\tTime 0.076 (0.138)\tData 0.051 (0.112)\tLoss 0.4191 (0.5890)\tAcc 0.875 (0.781)\n",
      "Epoch: [105][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.093)\tLoss 0.5898 (0.5893)\tAcc 0.875 (0.812)\n",
      "Epoch: [105][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.084)\tLoss 0.8465 (0.6536)\tAcc 0.625 (0.766)\n",
      "Epoch: [105][5/5]\tTime 0.084 (0.104)\tData 0.061 (0.079)\tLoss 1.3820 (0.7434)\tAcc 0.556 (0.740)\n",
      "validation at epoch 105\n",
      "Epoch: [105][1/9]\tTime 0.202 (0.202)\tData 0.178 (0.178)\tLoss 0.3375 (0.3375)\tAcc 0.938 (0.938)\n",
      "Epoch: [105][2/9]\tTime 0.076 (0.139)\tData 0.051 (0.114)\tLoss 0.8882 (0.6128)\tAcc 0.438 (0.688)\n",
      "Epoch: [105][3/9]\tTime 0.068 (0.115)\tData 0.048 (0.092)\tLoss 0.7018 (0.6425)\tAcc 0.812 (0.729)\n",
      "Epoch: [105][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.6500 (0.6444)\tAcc 0.688 (0.719)\n",
      "Epoch: [105][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.7039 (0.6563)\tAcc 0.812 (0.738)\n",
      "Epoch: [105][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3525 (0.6056)\tAcc 1.000 (0.781)\n",
      "Epoch: [105][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.071)\tLoss 0.6577 (0.6131)\tAcc 0.688 (0.768)\n",
      "Epoch: [105][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.069)\tLoss 0.9148 (0.6508)\tAcc 0.688 (0.758)\n",
      "Epoch: [105][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.7231 (0.6519)\tAcc 1.000 (0.762)\n",
      "train at epoch 106\n",
      "Epoch: [106][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.5810 (0.5810)\tAcc 0.812 (0.812)\n",
      "Epoch: [106][2/5]\tTime 0.077 (0.139)\tData 0.053 (0.113)\tLoss 0.5959 (0.5884)\tAcc 0.750 (0.781)\n",
      "Epoch: [106][3/5]\tTime 0.078 (0.119)\tData 0.054 (0.093)\tLoss 0.7419 (0.6396)\tAcc 0.750 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [106][4/5]\tTime 0.078 (0.109)\tData 0.054 (0.083)\tLoss 0.7175 (0.6591)\tAcc 0.812 (0.781)\n",
      "Epoch: [106][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.4941 (0.6387)\tAcc 0.889 (0.795)\n",
      "validation at epoch 106\n",
      "Epoch: [106][1/9]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.3179 (0.3179)\tAcc 1.000 (1.000)\n",
      "Epoch: [106][2/9]\tTime 0.069 (0.134)\tData 0.046 (0.108)\tLoss 1.0139 (0.6659)\tAcc 0.438 (0.719)\n",
      "Epoch: [106][3/9]\tTime 0.071 (0.113)\tData 0.052 (0.089)\tLoss 0.5845 (0.6388)\tAcc 0.812 (0.750)\n",
      "Epoch: [106][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.080)\tLoss 0.6141 (0.6326)\tAcc 0.688 (0.734)\n",
      "Epoch: [106][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.7058 (0.6472)\tAcc 0.812 (0.750)\n",
      "Epoch: [106][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.2630 (0.5832)\tAcc 1.000 (0.792)\n",
      "Epoch: [106][7/9]\tTime 0.073 (0.090)\tData 0.055 (0.069)\tLoss 0.6413 (0.5915)\tAcc 0.750 (0.786)\n",
      "Epoch: [106][8/9]\tTime 0.075 (0.088)\tData 0.056 (0.068)\tLoss 0.8584 (0.6249)\tAcc 0.562 (0.758)\n",
      "Epoch: [106][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2542 (0.6192)\tAcc 1.000 (0.762)\n",
      "train at epoch 107\n",
      "Epoch: [107][1/5]\tTime 0.198 (0.198)\tData 0.168 (0.168)\tLoss 0.5392 (0.5392)\tAcc 0.875 (0.875)\n",
      "Epoch: [107][2/5]\tTime 0.073 (0.136)\tData 0.048 (0.108)\tLoss 0.5728 (0.5560)\tAcc 0.812 (0.844)\n",
      "Epoch: [107][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.090)\tLoss 0.9950 (0.7024)\tAcc 0.562 (0.750)\n",
      "Epoch: [107][4/5]\tTime 0.077 (0.107)\tData 0.054 (0.081)\tLoss 0.8314 (0.7346)\tAcc 0.562 (0.703)\n",
      "Epoch: [107][5/5]\tTime 0.079 (0.101)\tData 0.056 (0.076)\tLoss 0.6681 (0.7264)\tAcc 0.778 (0.712)\n",
      "validation at epoch 107\n",
      "Epoch: [107][1/9]\tTime 0.206 (0.206)\tData 0.182 (0.182)\tLoss 0.3522 (0.3522)\tAcc 0.938 (0.938)\n",
      "Epoch: [107][2/9]\tTime 0.079 (0.142)\tData 0.052 (0.117)\tLoss 0.9226 (0.6374)\tAcc 0.438 (0.688)\n",
      "Epoch: [107][3/9]\tTime 0.068 (0.117)\tData 0.048 (0.094)\tLoss 0.6637 (0.6462)\tAcc 0.812 (0.729)\n",
      "Epoch: [107][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 0.7309 (0.6673)\tAcc 0.750 (0.734)\n",
      "Epoch: [107][5/9]\tTime 0.073 (0.100)\tData 0.054 (0.078)\tLoss 0.6290 (0.6597)\tAcc 0.812 (0.750)\n",
      "Epoch: [107][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.3138 (0.6020)\tAcc 1.000 (0.792)\n",
      "Epoch: [107][7/9]\tTime 0.073 (0.092)\tData 0.055 (0.071)\tLoss 0.5631 (0.5965)\tAcc 0.812 (0.795)\n",
      "Epoch: [107][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.9056 (0.6351)\tAcc 0.562 (0.766)\n",
      "Epoch: [107][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.068)\tLoss 0.1783 (0.6281)\tAcc 1.000 (0.769)\n",
      "train at epoch 108\n",
      "Epoch: [108][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.9371 (0.9371)\tAcc 0.688 (0.688)\n",
      "Epoch: [108][2/5]\tTime 0.075 (0.139)\tData 0.051 (0.113)\tLoss 0.5897 (0.7634)\tAcc 0.875 (0.781)\n",
      "Epoch: [108][3/5]\tTime 0.078 (0.118)\tData 0.055 (0.093)\tLoss 0.5027 (0.6765)\tAcc 0.875 (0.812)\n",
      "Epoch: [108][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.5463 (0.6440)\tAcc 0.875 (0.828)\n",
      "Epoch: [108][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.6969 (0.6505)\tAcc 0.778 (0.822)\n",
      "validation at epoch 108\n",
      "Epoch: [108][1/9]\tTime 0.200 (0.200)\tData 0.174 (0.174)\tLoss 0.4020 (0.4020)\tAcc 0.938 (0.938)\n",
      "Epoch: [108][2/9]\tTime 0.075 (0.137)\tData 0.050 (0.112)\tLoss 0.9202 (0.6611)\tAcc 0.438 (0.688)\n",
      "Epoch: [108][3/9]\tTime 0.070 (0.115)\tData 0.050 (0.091)\tLoss 0.8490 (0.7237)\tAcc 0.625 (0.667)\n",
      "Epoch: [108][4/9]\tTime 0.075 (0.105)\tData 0.055 (0.082)\tLoss 0.7128 (0.7210)\tAcc 0.625 (0.656)\n",
      "Epoch: [108][5/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.7623 (0.7293)\tAcc 0.750 (0.675)\n",
      "Epoch: [108][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3503 (0.6661)\tAcc 1.000 (0.729)\n",
      "Epoch: [108][7/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.6846 (0.6687)\tAcc 0.688 (0.723)\n",
      "Epoch: [108][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.068)\tLoss 0.9140 (0.6994)\tAcc 0.625 (0.711)\n",
      "Epoch: [108][9/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.3655 (0.6943)\tAcc 1.000 (0.715)\n",
      "train at epoch 109\n",
      "Epoch: [109][1/5]\tTime 0.198 (0.198)\tData 0.170 (0.170)\tLoss 0.8522 (0.8522)\tAcc 0.688 (0.688)\n",
      "Epoch: [109][2/5]\tTime 0.075 (0.136)\tData 0.050 (0.110)\tLoss 0.4493 (0.6508)\tAcc 0.875 (0.781)\n",
      "Epoch: [109][3/5]\tTime 0.077 (0.117)\tData 0.054 (0.091)\tLoss 0.4488 (0.5834)\tAcc 0.875 (0.812)\n",
      "Epoch: [109][4/5]\tTime 0.078 (0.107)\tData 0.054 (0.082)\tLoss 1.2683 (0.7547)\tAcc 0.500 (0.734)\n",
      "Epoch: [109][5/5]\tTime 0.078 (0.101)\tData 0.055 (0.077)\tLoss 0.9237 (0.7755)\tAcc 0.778 (0.740)\n",
      "validation at epoch 109\n",
      "Epoch: [109][1/9]\tTime 0.202 (0.202)\tData 0.172 (0.172)\tLoss 0.3460 (0.3460)\tAcc 0.938 (0.938)\n",
      "Epoch: [109][2/9]\tTime 0.072 (0.137)\tData 0.046 (0.109)\tLoss 0.9564 (0.6512)\tAcc 0.438 (0.688)\n",
      "Epoch: [109][3/9]\tTime 0.068 (0.114)\tData 0.048 (0.089)\tLoss 0.6335 (0.6453)\tAcc 0.750 (0.708)\n",
      "Epoch: [109][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.080)\tLoss 0.7489 (0.6712)\tAcc 0.625 (0.688)\n",
      "Epoch: [109][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.075)\tLoss 0.8135 (0.6997)\tAcc 0.750 (0.700)\n",
      "Epoch: [109][6/9]\tTime 0.074 (0.094)\tData 0.054 (0.071)\tLoss 0.3125 (0.6351)\tAcc 1.000 (0.750)\n",
      "Epoch: [109][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.5608 (0.6245)\tAcc 0.875 (0.768)\n",
      "Epoch: [109][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.067)\tLoss 0.8642 (0.6545)\tAcc 0.688 (0.758)\n",
      "Epoch: [109][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2026 (0.6475)\tAcc 1.000 (0.762)\n",
      "train at epoch 110\n",
      "Epoch: [110][1/5]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.6525 (0.6525)\tAcc 0.812 (0.812)\n",
      "Epoch: [110][2/5]\tTime 0.078 (0.141)\tData 0.053 (0.113)\tLoss 0.4232 (0.5379)\tAcc 0.812 (0.812)\n",
      "Epoch: [110][3/5]\tTime 0.082 (0.121)\tData 0.058 (0.095)\tLoss 0.8857 (0.6538)\tAcc 0.625 (0.750)\n",
      "Epoch: [110][4/5]\tTime 0.078 (0.110)\tData 0.054 (0.085)\tLoss 0.6010 (0.6406)\tAcc 0.812 (0.766)\n",
      "Epoch: [110][5/5]\tTime 0.083 (0.105)\tData 0.059 (0.079)\tLoss 0.7268 (0.6512)\tAcc 0.667 (0.753)\n",
      "validation at epoch 110\n",
      "Epoch: [110][1/9]\tTime 0.195 (0.195)\tData 0.166 (0.166)\tLoss 0.4275 (0.4275)\tAcc 0.938 (0.938)\n",
      "Epoch: [110][2/9]\tTime 0.066 (0.131)\tData 0.045 (0.106)\tLoss 0.9217 (0.6746)\tAcc 0.500 (0.719)\n",
      "Epoch: [110][3/9]\tTime 0.074 (0.112)\tData 0.055 (0.089)\tLoss 0.6629 (0.6707)\tAcc 0.750 (0.729)\n",
      "Epoch: [110][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.080)\tLoss 0.5941 (0.6516)\tAcc 0.688 (0.719)\n",
      "Epoch: [110][5/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.6985 (0.6609)\tAcc 0.750 (0.725)\n",
      "Epoch: [110][6/9]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.2618 (0.5944)\tAcc 1.000 (0.771)\n",
      "Epoch: [110][7/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.6769 (0.6062)\tAcc 0.750 (0.768)\n",
      "Epoch: [110][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8706 (0.6392)\tAcc 0.688 (0.758)\n",
      "Epoch: [110][9/9]\tTime 0.073 (0.086)\tData 0.055 (0.066)\tLoss 0.2671 (0.6335)\tAcc 1.000 (0.762)\n",
      "train at epoch 111\n",
      "Epoch: [111][1/5]\tTime 0.200 (0.200)\tData 0.171 (0.171)\tLoss 0.6163 (0.6163)\tAcc 0.625 (0.625)\n",
      "Epoch: [111][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.111)\tLoss 0.8316 (0.7239)\tAcc 0.625 (0.625)\n",
      "Epoch: [111][3/5]\tTime 0.077 (0.117)\tData 0.054 (0.092)\tLoss 1.0048 (0.8176)\tAcc 0.688 (0.646)\n",
      "Epoch: [111][4/5]\tTime 0.078 (0.107)\tData 0.055 (0.083)\tLoss 0.3437 (0.6991)\tAcc 1.000 (0.734)\n",
      "Epoch: [111][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.6287 (0.6904)\tAcc 0.889 (0.753)\n",
      "validation at epoch 111\n",
      "Epoch: [111][1/9]\tTime 0.200 (0.200)\tData 0.172 (0.172)\tLoss 0.3877 (0.3877)\tAcc 0.938 (0.938)\n",
      "Epoch: [111][2/9]\tTime 0.074 (0.137)\tData 0.049 (0.111)\tLoss 1.0083 (0.6980)\tAcc 0.438 (0.688)\n",
      "Epoch: [111][3/9]\tTime 0.069 (0.114)\tData 0.050 (0.090)\tLoss 0.6258 (0.6739)\tAcc 0.750 (0.708)\n",
      "Epoch: [111][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.7252 (0.6867)\tAcc 0.688 (0.703)\n",
      "Epoch: [111][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.8146 (0.7123)\tAcc 0.750 (0.713)\n",
      "Epoch: [111][6/9]\tTime 0.075 (0.094)\tData 0.056 (0.073)\tLoss 0.2960 (0.6429)\tAcc 1.000 (0.760)\n",
      "Epoch: [111][7/9]\tTime 0.074 (0.091)\tData 0.055 (0.070)\tLoss 0.5594 (0.6310)\tAcc 0.938 (0.786)\n",
      "Epoch: [111][8/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.9187 (0.6670)\tAcc 0.625 (0.766)\n",
      "Epoch: [111][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.2674 (0.6608)\tAcc 1.000 (0.769)\n",
      "train at epoch 112\n",
      "Epoch: [112][1/5]\tTime 0.206 (0.206)\tData 0.179 (0.179)\tLoss 0.5202 (0.5202)\tAcc 0.812 (0.812)\n",
      "Epoch: [112][2/5]\tTime 0.077 (0.141)\tData 0.052 (0.115)\tLoss 0.7597 (0.6400)\tAcc 0.562 (0.688)\n",
      "Epoch: [112][3/5]\tTime 0.079 (0.120)\tData 0.055 (0.095)\tLoss 0.4761 (0.5853)\tAcc 0.875 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [112][4/5]\tTime 0.079 (0.110)\tData 0.054 (0.085)\tLoss 0.8663 (0.6556)\tAcc 0.562 (0.703)\n",
      "Epoch: [112][5/5]\tTime 0.078 (0.104)\tData 0.055 (0.079)\tLoss 0.7388 (0.6658)\tAcc 0.667 (0.699)\n",
      "validation at epoch 112\n",
      "Epoch: [112][1/9]\tTime 0.197 (0.197)\tData 0.169 (0.169)\tLoss 0.2804 (0.2804)\tAcc 0.938 (0.938)\n",
      "Epoch: [112][2/9]\tTime 0.068 (0.132)\tData 0.047 (0.108)\tLoss 0.9213 (0.6009)\tAcc 0.438 (0.688)\n",
      "Epoch: [112][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.089)\tLoss 0.5887 (0.5968)\tAcc 0.938 (0.771)\n",
      "Epoch: [112][4/9]\tTime 0.075 (0.103)\tData 0.054 (0.080)\tLoss 0.6013 (0.5979)\tAcc 0.750 (0.766)\n",
      "Epoch: [112][5/9]\tTime 0.071 (0.097)\tData 0.052 (0.075)\tLoss 0.7340 (0.6251)\tAcc 0.812 (0.775)\n",
      "Epoch: [112][6/9]\tTime 0.075 (0.093)\tData 0.056 (0.071)\tLoss 0.2709 (0.5661)\tAcc 1.000 (0.812)\n",
      "Epoch: [112][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5277 (0.5606)\tAcc 0.812 (0.813)\n",
      "Epoch: [112][8/9]\tTime 0.075 (0.088)\tData 0.055 (0.067)\tLoss 0.9447 (0.6086)\tAcc 0.625 (0.789)\n",
      "Epoch: [112][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.4645 (0.6064)\tAcc 1.000 (0.792)\n",
      "train at epoch 113\n",
      "Epoch: [113][1/5]\tTime 0.200 (0.200)\tData 0.170 (0.170)\tLoss 0.5782 (0.5782)\tAcc 0.875 (0.875)\n",
      "Epoch: [113][2/5]\tTime 0.074 (0.137)\tData 0.050 (0.110)\tLoss 0.7812 (0.6797)\tAcc 0.812 (0.844)\n",
      "Epoch: [113][3/5]\tTime 0.079 (0.118)\tData 0.056 (0.092)\tLoss 0.6339 (0.6644)\tAcc 0.812 (0.833)\n",
      "Epoch: [113][4/5]\tTime 0.079 (0.108)\tData 0.054 (0.082)\tLoss 0.7859 (0.6948)\tAcc 0.688 (0.797)\n",
      "Epoch: [113][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.7913 (0.7067)\tAcc 0.667 (0.781)\n",
      "validation at epoch 113\n",
      "Epoch: [113][1/9]\tTime 0.207 (0.207)\tData 0.183 (0.183)\tLoss 0.3676 (0.3676)\tAcc 0.938 (0.938)\n",
      "Epoch: [113][2/9]\tTime 0.077 (0.142)\tData 0.051 (0.117)\tLoss 0.8005 (0.5840)\tAcc 0.500 (0.719)\n",
      "Epoch: [113][3/9]\tTime 0.067 (0.117)\tData 0.048 (0.094)\tLoss 0.5400 (0.5694)\tAcc 0.875 (0.771)\n",
      "Epoch: [113][4/9]\tTime 0.074 (0.106)\tData 0.055 (0.084)\tLoss 0.6796 (0.5969)\tAcc 0.625 (0.734)\n",
      "Epoch: [113][5/9]\tTime 0.074 (0.100)\tData 0.055 (0.078)\tLoss 0.6520 (0.6079)\tAcc 0.812 (0.750)\n",
      "Epoch: [113][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.3279 (0.5613)\tAcc 1.000 (0.792)\n",
      "Epoch: [113][7/9]\tTime 0.073 (0.092)\tData 0.055 (0.072)\tLoss 0.5474 (0.5593)\tAcc 0.875 (0.804)\n",
      "Epoch: [113][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.9044 (0.6024)\tAcc 0.625 (0.781)\n",
      "Epoch: [113][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.068)\tLoss 0.2674 (0.5973)\tAcc 1.000 (0.785)\n",
      "train at epoch 114\n",
      "Epoch: [114][1/5]\tTime 0.201 (0.201)\tData 0.173 (0.173)\tLoss 0.9388 (0.9388)\tAcc 0.562 (0.562)\n",
      "Epoch: [114][2/5]\tTime 0.076 (0.139)\tData 0.052 (0.112)\tLoss 0.5746 (0.7567)\tAcc 0.875 (0.719)\n",
      "Epoch: [114][3/5]\tTime 0.077 (0.118)\tData 0.053 (0.093)\tLoss 0.8476 (0.7870)\tAcc 0.562 (0.667)\n",
      "Epoch: [114][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.5539 (0.7287)\tAcc 0.812 (0.703)\n",
      "Epoch: [114][5/5]\tTime 0.079 (0.102)\tData 0.055 (0.077)\tLoss 0.4227 (0.6910)\tAcc 0.889 (0.726)\n",
      "validation at epoch 114\n",
      "Epoch: [114][1/9]\tTime 0.196 (0.196)\tData 0.169 (0.169)\tLoss 0.3940 (0.3940)\tAcc 0.938 (0.938)\n",
      "Epoch: [114][2/9]\tTime 0.072 (0.134)\tData 0.049 (0.109)\tLoss 0.8923 (0.6431)\tAcc 0.438 (0.688)\n",
      "Epoch: [114][3/9]\tTime 0.071 (0.113)\tData 0.051 (0.090)\tLoss 0.6302 (0.6388)\tAcc 0.812 (0.729)\n",
      "Epoch: [114][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6888 (0.6513)\tAcc 0.688 (0.719)\n",
      "Epoch: [114][5/9]\tTime 0.074 (0.097)\tData 0.054 (0.075)\tLoss 0.6358 (0.6482)\tAcc 0.750 (0.725)\n",
      "Epoch: [114][6/9]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.2642 (0.5842)\tAcc 1.000 (0.771)\n",
      "Epoch: [114][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.070)\tLoss 0.5404 (0.5779)\tAcc 0.812 (0.777)\n",
      "Epoch: [114][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.068)\tLoss 0.8159 (0.6077)\tAcc 0.688 (0.766)\n",
      "Epoch: [114][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.2765 (0.6026)\tAcc 1.000 (0.769)\n",
      "train at epoch 115\n",
      "Epoch: [115][1/5]\tTime 0.203 (0.203)\tData 0.174 (0.174)\tLoss 0.6278 (0.6278)\tAcc 0.750 (0.750)\n",
      "Epoch: [115][2/5]\tTime 0.075 (0.139)\tData 0.050 (0.112)\tLoss 0.7046 (0.6662)\tAcc 0.688 (0.719)\n",
      "Epoch: [115][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.093)\tLoss 0.5807 (0.6377)\tAcc 0.750 (0.729)\n",
      "Epoch: [115][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.6172 (0.6326)\tAcc 0.812 (0.750)\n",
      "Epoch: [115][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.7707 (0.6496)\tAcc 0.667 (0.740)\n",
      "validation at epoch 115\n",
      "Epoch: [115][1/9]\tTime 0.198 (0.198)\tData 0.173 (0.173)\tLoss 0.2946 (0.2946)\tAcc 0.938 (0.938)\n",
      "Epoch: [115][2/9]\tTime 0.074 (0.136)\tData 0.050 (0.111)\tLoss 0.9694 (0.6320)\tAcc 0.500 (0.719)\n",
      "Epoch: [115][3/9]\tTime 0.069 (0.114)\tData 0.049 (0.091)\tLoss 0.7366 (0.6669)\tAcc 0.750 (0.729)\n",
      "Epoch: [115][4/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6621 (0.6657)\tAcc 0.625 (0.703)\n",
      "Epoch: [115][5/9]\tTime 0.075 (0.098)\tData 0.054 (0.076)\tLoss 0.8037 (0.6933)\tAcc 0.688 (0.700)\n",
      "Epoch: [115][6/9]\tTime 0.080 (0.095)\tData 0.059 (0.073)\tLoss 0.2735 (0.6233)\tAcc 1.000 (0.750)\n",
      "Epoch: [115][7/9]\tTime 0.078 (0.092)\tData 0.058 (0.071)\tLoss 0.6243 (0.6235)\tAcc 0.688 (0.741)\n",
      "Epoch: [115][8/9]\tTime 0.078 (0.091)\tData 0.058 (0.069)\tLoss 1.0837 (0.6810)\tAcc 0.562 (0.719)\n",
      "Epoch: [115][9/9]\tTime 0.078 (0.089)\tData 0.058 (0.068)\tLoss 0.1161 (0.6723)\tAcc 1.000 (0.723)\n",
      "train at epoch 116\n",
      "Epoch: [116][1/5]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.4922 (0.4922)\tAcc 0.875 (0.875)\n",
      "Epoch: [116][2/5]\tTime 0.080 (0.142)\tData 0.055 (0.115)\tLoss 0.9848 (0.7385)\tAcc 0.688 (0.781)\n",
      "Epoch: [116][3/5]\tTime 0.084 (0.123)\tData 0.059 (0.096)\tLoss 0.4777 (0.6516)\tAcc 0.812 (0.792)\n",
      "Epoch: [116][4/5]\tTime 0.084 (0.113)\tData 0.059 (0.087)\tLoss 0.4326 (0.5968)\tAcc 0.812 (0.797)\n",
      "Epoch: [116][5/5]\tTime 0.084 (0.107)\tData 0.059 (0.081)\tLoss 1.0873 (0.6573)\tAcc 0.556 (0.767)\n",
      "validation at epoch 116\n",
      "Epoch: [116][1/9]\tTime 0.213 (0.213)\tData 0.179 (0.179)\tLoss 0.4285 (0.4285)\tAcc 0.938 (0.938)\n",
      "Epoch: [116][2/9]\tTime 0.076 (0.144)\tData 0.047 (0.113)\tLoss 0.8987 (0.6636)\tAcc 0.625 (0.781)\n",
      "Epoch: [116][3/9]\tTime 0.065 (0.118)\tData 0.045 (0.090)\tLoss 0.6730 (0.6667)\tAcc 0.750 (0.771)\n",
      "Epoch: [116][4/9]\tTime 0.077 (0.108)\tData 0.057 (0.082)\tLoss 0.4964 (0.6242)\tAcc 0.750 (0.766)\n",
      "Epoch: [116][5/9]\tTime 0.076 (0.101)\tData 0.056 (0.077)\tLoss 0.7153 (0.6424)\tAcc 0.812 (0.775)\n",
      "Epoch: [116][6/9]\tTime 0.073 (0.097)\tData 0.054 (0.073)\tLoss 0.2928 (0.5841)\tAcc 1.000 (0.812)\n",
      "Epoch: [116][7/9]\tTime 0.075 (0.094)\tData 0.056 (0.071)\tLoss 0.5496 (0.5792)\tAcc 0.812 (0.813)\n",
      "Epoch: [116][8/9]\tTime 0.074 (0.091)\tData 0.054 (0.069)\tLoss 0.9458 (0.6250)\tAcc 0.625 (0.789)\n",
      "Epoch: [116][9/9]\tTime 0.073 (0.089)\tData 0.055 (0.067)\tLoss 0.5255 (0.6235)\tAcc 1.000 (0.792)\n",
      "train at epoch 117\n",
      "Epoch: [117][1/5]\tTime 0.200 (0.200)\tData 0.172 (0.172)\tLoss 0.6860 (0.6860)\tAcc 0.750 (0.750)\n",
      "Epoch: [117][2/5]\tTime 0.078 (0.139)\tData 0.055 (0.113)\tLoss 0.4272 (0.5566)\tAcc 0.812 (0.781)\n",
      "Epoch: [117][3/5]\tTime 0.086 (0.121)\tData 0.062 (0.096)\tLoss 0.4495 (0.5209)\tAcc 0.812 (0.792)\n",
      "Epoch: [117][4/5]\tTime 0.085 (0.112)\tData 0.061 (0.087)\tLoss 0.8737 (0.6091)\tAcc 0.625 (0.750)\n",
      "Epoch: [117][5/5]\tTime 0.087 (0.107)\tData 0.062 (0.082)\tLoss 1.0064 (0.6581)\tAcc 0.556 (0.726)\n",
      "validation at epoch 117\n",
      "Epoch: [117][1/9]\tTime 0.215 (0.215)\tData 0.190 (0.190)\tLoss 0.4276 (0.4276)\tAcc 0.938 (0.938)\n",
      "Epoch: [117][2/9]\tTime 0.080 (0.148)\tData 0.055 (0.123)\tLoss 0.9354 (0.6815)\tAcc 0.500 (0.719)\n",
      "Epoch: [117][3/9]\tTime 0.074 (0.123)\tData 0.054 (0.100)\tLoss 0.5082 (0.6237)\tAcc 0.812 (0.750)\n",
      "Epoch: [117][4/9]\tTime 0.078 (0.112)\tData 0.058 (0.089)\tLoss 0.6551 (0.6316)\tAcc 0.688 (0.734)\n",
      "Epoch: [117][5/9]\tTime 0.091 (0.108)\tData 0.072 (0.086)\tLoss 0.7400 (0.6532)\tAcc 0.812 (0.750)\n",
      "Epoch: [117][6/9]\tTime 0.080 (0.103)\tData 0.060 (0.082)\tLoss 0.3104 (0.5961)\tAcc 1.000 (0.792)\n",
      "Epoch: [117][7/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 0.7719 (0.6212)\tAcc 0.688 (0.777)\n",
      "Epoch: [117][8/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.9648 (0.6642)\tAcc 0.625 (0.758)\n",
      "Epoch: [117][9/9]\tTime 0.074 (0.093)\tData 0.055 (0.073)\tLoss 0.1610 (0.6564)\tAcc 1.000 (0.762)\n",
      "train at epoch 118\n",
      "Epoch: [118][1/5]\tTime 0.203 (0.203)\tData 0.176 (0.176)\tLoss 0.4746 (0.4746)\tAcc 0.750 (0.750)\n",
      "Epoch: [118][2/5]\tTime 0.089 (0.146)\tData 0.065 (0.120)\tLoss 1.0963 (0.7855)\tAcc 0.562 (0.656)\n",
      "Epoch: [118][3/5]\tTime 0.082 (0.125)\tData 0.057 (0.099)\tLoss 0.7507 (0.7739)\tAcc 0.750 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [118][4/5]\tTime 0.082 (0.114)\tData 0.057 (0.089)\tLoss 0.7673 (0.7723)\tAcc 0.688 (0.688)\n",
      "Epoch: [118][5/5]\tTime 0.081 (0.107)\tData 0.057 (0.082)\tLoss 0.3939 (0.7256)\tAcc 1.000 (0.726)\n",
      "validation at epoch 118\n",
      "Epoch: [118][1/9]\tTime 0.214 (0.214)\tData 0.180 (0.180)\tLoss 0.3096 (0.3096)\tAcc 0.938 (0.938)\n",
      "Epoch: [118][2/9]\tTime 0.078 (0.146)\tData 0.050 (0.115)\tLoss 0.9969 (0.6533)\tAcc 0.438 (0.688)\n",
      "Epoch: [118][3/9]\tTime 0.067 (0.120)\tData 0.047 (0.092)\tLoss 0.7065 (0.6710)\tAcc 0.750 (0.708)\n",
      "Epoch: [118][4/9]\tTime 0.073 (0.108)\tData 0.054 (0.083)\tLoss 0.6235 (0.6591)\tAcc 0.750 (0.719)\n",
      "Epoch: [118][5/9]\tTime 0.075 (0.101)\tData 0.055 (0.077)\tLoss 0.7767 (0.6827)\tAcc 0.750 (0.725)\n",
      "Epoch: [118][6/9]\tTime 0.079 (0.098)\tData 0.059 (0.074)\tLoss 0.2942 (0.6179)\tAcc 1.000 (0.771)\n",
      "Epoch: [118][7/9]\tTime 0.084 (0.096)\tData 0.064 (0.073)\tLoss 0.5975 (0.6150)\tAcc 0.750 (0.768)\n",
      "Epoch: [118][8/9]\tTime 0.079 (0.093)\tData 0.059 (0.071)\tLoss 0.9849 (0.6612)\tAcc 0.688 (0.758)\n",
      "Epoch: [118][9/9]\tTime 0.078 (0.092)\tData 0.059 (0.070)\tLoss 0.4107 (0.6574)\tAcc 1.000 (0.762)\n",
      "train at epoch 119\n",
      "Epoch: [119][1/5]\tTime 0.205 (0.205)\tData 0.177 (0.177)\tLoss 0.9503 (0.9503)\tAcc 0.625 (0.625)\n",
      "Epoch: [119][2/5]\tTime 0.080 (0.143)\tData 0.056 (0.117)\tLoss 0.9913 (0.9708)\tAcc 0.688 (0.656)\n",
      "Epoch: [119][3/5]\tTime 0.082 (0.122)\tData 0.058 (0.097)\tLoss 0.4066 (0.7827)\tAcc 0.938 (0.750)\n",
      "Epoch: [119][4/5]\tTime 0.084 (0.113)\tData 0.060 (0.088)\tLoss 0.7275 (0.7689)\tAcc 0.750 (0.750)\n",
      "Epoch: [119][5/5]\tTime 0.082 (0.107)\tData 0.059 (0.082)\tLoss 0.7478 (0.7663)\tAcc 0.667 (0.740)\n",
      "validation at epoch 119\n",
      "Epoch: [119][1/9]\tTime 0.199 (0.199)\tData 0.173 (0.173)\tLoss 0.3371 (0.3371)\tAcc 0.938 (0.938)\n",
      "Epoch: [119][2/9]\tTime 0.074 (0.136)\tData 0.050 (0.112)\tLoss 0.9134 (0.6253)\tAcc 0.438 (0.688)\n",
      "Epoch: [119][3/9]\tTime 0.070 (0.114)\tData 0.050 (0.091)\tLoss 0.6902 (0.6469)\tAcc 0.750 (0.708)\n",
      "Epoch: [119][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6743 (0.6537)\tAcc 0.688 (0.703)\n",
      "Epoch: [119][5/9]\tTime 0.074 (0.098)\tData 0.054 (0.076)\tLoss 0.7358 (0.6701)\tAcc 0.812 (0.725)\n",
      "Epoch: [119][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.073)\tLoss 0.3121 (0.6105)\tAcc 1.000 (0.771)\n",
      "Epoch: [119][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.5069 (0.5957)\tAcc 0.875 (0.786)\n",
      "Epoch: [119][8/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.8038 (0.6217)\tAcc 0.688 (0.773)\n",
      "Epoch: [119][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.067)\tLoss 0.3543 (0.6176)\tAcc 1.000 (0.777)\n",
      "train at epoch 120\n",
      "Epoch: [120][1/5]\tTime 0.200 (0.200)\tData 0.170 (0.170)\tLoss 0.9159 (0.9159)\tAcc 0.688 (0.688)\n",
      "Epoch: [120][2/5]\tTime 0.074 (0.137)\tData 0.050 (0.110)\tLoss 0.6591 (0.7875)\tAcc 0.750 (0.719)\n",
      "Epoch: [120][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 0.7466 (0.7739)\tAcc 0.750 (0.729)\n",
      "Epoch: [120][4/5]\tTime 0.078 (0.107)\tData 0.054 (0.082)\tLoss 0.6918 (0.7534)\tAcc 0.750 (0.734)\n",
      "Epoch: [120][5/5]\tTime 0.080 (0.102)\tData 0.056 (0.077)\tLoss 0.6330 (0.7385)\tAcc 0.889 (0.753)\n",
      "validation at epoch 120\n",
      "Epoch: [120][1/9]\tTime 0.206 (0.206)\tData 0.183 (0.183)\tLoss 0.4184 (0.4184)\tAcc 0.938 (0.938)\n",
      "Epoch: [120][2/9]\tTime 0.078 (0.142)\tData 0.051 (0.117)\tLoss 0.8690 (0.6437)\tAcc 0.438 (0.688)\n",
      "Epoch: [120][3/9]\tTime 0.067 (0.117)\tData 0.048 (0.094)\tLoss 0.6508 (0.6461)\tAcc 0.875 (0.750)\n",
      "Epoch: [120][4/9]\tTime 0.074 (0.106)\tData 0.055 (0.084)\tLoss 0.6628 (0.6502)\tAcc 0.750 (0.750)\n",
      "Epoch: [120][5/9]\tTime 0.074 (0.100)\tData 0.056 (0.079)\tLoss 0.7322 (0.6666)\tAcc 0.750 (0.750)\n",
      "Epoch: [120][6/9]\tTime 0.074 (0.096)\tData 0.055 (0.075)\tLoss 0.3740 (0.6179)\tAcc 1.000 (0.792)\n",
      "Epoch: [120][7/9]\tTime 0.074 (0.093)\tData 0.055 (0.072)\tLoss 0.6807 (0.6268)\tAcc 0.688 (0.777)\n",
      "Epoch: [120][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.070)\tLoss 0.8902 (0.6598)\tAcc 0.500 (0.742)\n",
      "Epoch: [120][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 0.5377 (0.6579)\tAcc 1.000 (0.746)\n",
      "train at epoch 121\n",
      "Epoch: [121][1/5]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.3705 (0.3705)\tAcc 1.000 (1.000)\n",
      "Epoch: [121][2/5]\tTime 0.074 (0.137)\tData 0.050 (0.110)\tLoss 0.6629 (0.5167)\tAcc 0.750 (0.875)\n",
      "Epoch: [121][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.091)\tLoss 1.0439 (0.6925)\tAcc 0.625 (0.792)\n",
      "Epoch: [121][4/5]\tTime 0.079 (0.108)\tData 0.056 (0.082)\tLoss 0.8202 (0.7244)\tAcc 0.688 (0.766)\n",
      "Epoch: [121][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.6038 (0.7095)\tAcc 0.778 (0.767)\n",
      "validation at epoch 121\n",
      "Epoch: [121][1/9]\tTime 0.208 (0.208)\tData 0.185 (0.185)\tLoss 0.2838 (0.2838)\tAcc 0.938 (0.938)\n",
      "Epoch: [121][2/9]\tTime 0.078 (0.143)\tData 0.051 (0.118)\tLoss 0.9414 (0.6126)\tAcc 0.438 (0.688)\n",
      "Epoch: [121][3/9]\tTime 0.068 (0.118)\tData 0.049 (0.095)\tLoss 0.6522 (0.6258)\tAcc 0.812 (0.729)\n",
      "Epoch: [121][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.6941 (0.6429)\tAcc 0.625 (0.703)\n",
      "Epoch: [121][5/9]\tTime 0.074 (0.100)\tData 0.055 (0.079)\tLoss 0.7268 (0.6597)\tAcc 0.875 (0.738)\n",
      "Epoch: [121][6/9]\tTime 0.073 (0.096)\tData 0.055 (0.075)\tLoss 0.3494 (0.6079)\tAcc 0.938 (0.771)\n",
      "Epoch: [121][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.072)\tLoss 0.5957 (0.6062)\tAcc 0.812 (0.777)\n",
      "Epoch: [121][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.070)\tLoss 0.8387 (0.6353)\tAcc 0.688 (0.766)\n",
      "Epoch: [121][9/9]\tTime 0.074 (0.088)\tData 0.056 (0.068)\tLoss 0.2936 (0.6300)\tAcc 1.000 (0.769)\n",
      "train at epoch 122\n",
      "Epoch: [122][1/5]\tTime 0.205 (0.205)\tData 0.178 (0.178)\tLoss 0.6038 (0.6038)\tAcc 0.875 (0.875)\n",
      "Epoch: [122][2/5]\tTime 0.075 (0.140)\tData 0.052 (0.115)\tLoss 0.8188 (0.7113)\tAcc 0.688 (0.781)\n",
      "Epoch: [122][3/5]\tTime 0.078 (0.119)\tData 0.055 (0.095)\tLoss 0.8256 (0.7494)\tAcc 0.625 (0.729)\n",
      "Epoch: [122][4/5]\tTime 0.078 (0.109)\tData 0.055 (0.085)\tLoss 0.6137 (0.7155)\tAcc 0.812 (0.750)\n",
      "Epoch: [122][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 1.2517 (0.7816)\tAcc 0.333 (0.699)\n",
      "validation at epoch 122\n",
      "Epoch: [122][1/9]\tTime 0.200 (0.200)\tData 0.174 (0.174)\tLoss 0.3047 (0.3047)\tAcc 0.938 (0.938)\n",
      "Epoch: [122][2/9]\tTime 0.073 (0.137)\tData 0.049 (0.112)\tLoss 0.9816 (0.6432)\tAcc 0.438 (0.688)\n",
      "Epoch: [122][3/9]\tTime 0.071 (0.115)\tData 0.051 (0.091)\tLoss 0.7057 (0.6640)\tAcc 0.750 (0.708)\n",
      "Epoch: [122][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6503 (0.6606)\tAcc 0.688 (0.703)\n",
      "Epoch: [122][5/9]\tTime 0.073 (0.098)\tData 0.055 (0.077)\tLoss 0.6608 (0.6606)\tAcc 0.750 (0.713)\n",
      "Epoch: [122][6/9]\tTime 0.073 (0.094)\tData 0.055 (0.073)\tLoss 0.3110 (0.6023)\tAcc 1.000 (0.760)\n",
      "Epoch: [122][7/9]\tTime 0.073 (0.091)\tData 0.055 (0.070)\tLoss 0.5985 (0.6018)\tAcc 0.875 (0.777)\n",
      "Epoch: [122][8/9]\tTime 0.073 (0.089)\tData 0.055 (0.068)\tLoss 0.9278 (0.6426)\tAcc 0.625 (0.758)\n",
      "Epoch: [122][9/9]\tTime 0.073 (0.087)\tData 0.055 (0.067)\tLoss 0.2308 (0.6362)\tAcc 1.000 (0.762)\n",
      "train at epoch 123\n",
      "Epoch: [123][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.7844 (0.7844)\tAcc 0.625 (0.625)\n",
      "Epoch: [123][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.112)\tLoss 0.4034 (0.5939)\tAcc 0.875 (0.750)\n",
      "Epoch: [123][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.093)\tLoss 0.8712 (0.6863)\tAcc 0.625 (0.708)\n",
      "Epoch: [123][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.083)\tLoss 0.4656 (0.6311)\tAcc 0.750 (0.719)\n",
      "Epoch: [123][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.6658 (0.6354)\tAcc 0.889 (0.740)\n",
      "validation at epoch 123\n",
      "Epoch: [123][1/9]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.3305 (0.3305)\tAcc 0.938 (0.938)\n",
      "Epoch: [123][2/9]\tTime 0.067 (0.132)\tData 0.046 (0.106)\tLoss 0.8566 (0.5936)\tAcc 0.438 (0.688)\n",
      "Epoch: [123][3/9]\tTime 0.072 (0.112)\tData 0.053 (0.089)\tLoss 0.6832 (0.6235)\tAcc 0.812 (0.729)\n",
      "Epoch: [123][4/9]\tTime 0.075 (0.103)\tData 0.055 (0.080)\tLoss 0.6180 (0.6221)\tAcc 0.688 (0.719)\n",
      "Epoch: [123][5/9]\tTime 0.074 (0.097)\tData 0.055 (0.075)\tLoss 0.7727 (0.6522)\tAcc 0.750 (0.725)\n",
      "Epoch: [123][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.3228 (0.5973)\tAcc 1.000 (0.771)\n",
      "Epoch: [123][7/9]\tTime 0.075 (0.090)\tData 0.055 (0.069)\tLoss 0.6290 (0.6018)\tAcc 0.812 (0.777)\n",
      "Epoch: [123][8/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.8781 (0.6364)\tAcc 0.688 (0.766)\n",
      "Epoch: [123][9/9]\tTime 0.073 (0.087)\tData 0.054 (0.066)\tLoss 0.4405 (0.6334)\tAcc 1.000 (0.769)\n",
      "train at epoch 124\n",
      "Epoch: [124][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.7156 (0.7156)\tAcc 0.562 (0.562)\n",
      "Epoch: [124][2/5]\tTime 0.076 (0.139)\tData 0.052 (0.114)\tLoss 0.4612 (0.5884)\tAcc 0.875 (0.719)\n",
      "Epoch: [124][3/5]\tTime 0.077 (0.119)\tData 0.054 (0.094)\tLoss 0.6828 (0.6199)\tAcc 0.750 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [124][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.6019 (0.6154)\tAcc 0.875 (0.766)\n",
      "Epoch: [124][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.9029 (0.6508)\tAcc 0.778 (0.767)\n",
      "validation at epoch 124\n",
      "Epoch: [124][1/9]\tTime 0.196 (0.196)\tData 0.166 (0.166)\tLoss 0.3177 (0.3177)\tAcc 0.938 (0.938)\n",
      "Epoch: [124][2/9]\tTime 0.066 (0.131)\tData 0.045 (0.106)\tLoss 0.9143 (0.6160)\tAcc 0.438 (0.688)\n",
      "Epoch: [124][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.088)\tLoss 0.7181 (0.6500)\tAcc 0.562 (0.646)\n",
      "Epoch: [124][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.079)\tLoss 0.6886 (0.6597)\tAcc 0.625 (0.641)\n",
      "Epoch: [124][5/9]\tTime 0.074 (0.096)\tData 0.054 (0.074)\tLoss 0.7392 (0.6756)\tAcc 0.750 (0.663)\n",
      "Epoch: [124][6/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.3256 (0.6172)\tAcc 1.000 (0.719)\n",
      "Epoch: [124][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.6201 (0.6176)\tAcc 0.750 (0.723)\n",
      "Epoch: [124][8/9]\tTime 0.074 (0.088)\tData 0.055 (0.067)\tLoss 0.8497 (0.6467)\tAcc 0.625 (0.711)\n",
      "Epoch: [124][9/9]\tTime 0.074 (0.086)\tData 0.055 (0.066)\tLoss 0.3252 (0.6417)\tAcc 1.000 (0.715)\n",
      "train at epoch 125\n",
      "Epoch: [125][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.7049 (0.7049)\tAcc 0.688 (0.688)\n",
      "Epoch: [125][2/5]\tTime 0.075 (0.138)\tData 0.052 (0.113)\tLoss 0.6577 (0.6813)\tAcc 0.750 (0.719)\n",
      "Epoch: [125][3/5]\tTime 0.077 (0.118)\tData 0.054 (0.093)\tLoss 0.7261 (0.6962)\tAcc 0.750 (0.729)\n",
      "Epoch: [125][4/5]\tTime 0.078 (0.108)\tData 0.055 (0.084)\tLoss 0.7676 (0.7141)\tAcc 0.688 (0.719)\n",
      "Epoch: [125][5/5]\tTime 0.077 (0.102)\tData 0.055 (0.078)\tLoss 0.3866 (0.6737)\tAcc 0.778 (0.726)\n",
      "validation at epoch 125\n",
      "Epoch: [125][1/9]\tTime 0.202 (0.202)\tData 0.177 (0.177)\tLoss 0.3597 (0.3597)\tAcc 0.938 (0.938)\n",
      "Epoch: [125][2/9]\tTime 0.076 (0.139)\tData 0.050 (0.113)\tLoss 0.8762 (0.6179)\tAcc 0.500 (0.719)\n",
      "Epoch: [125][3/9]\tTime 0.067 (0.115)\tData 0.048 (0.091)\tLoss 0.6503 (0.6287)\tAcc 0.750 (0.729)\n",
      "Epoch: [125][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.6465 (0.6332)\tAcc 0.688 (0.719)\n",
      "Epoch: [125][5/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.8436 (0.6752)\tAcc 0.625 (0.700)\n",
      "Epoch: [125][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.2197 (0.5993)\tAcc 1.000 (0.750)\n",
      "Epoch: [125][7/9]\tTime 0.075 (0.091)\tData 0.056 (0.071)\tLoss 0.6306 (0.6038)\tAcc 0.750 (0.750)\n",
      "Epoch: [125][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.069)\tLoss 0.7835 (0.6263)\tAcc 0.750 (0.750)\n",
      "Epoch: [125][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2509 (0.6205)\tAcc 1.000 (0.754)\n",
      "train at epoch 126\n",
      "Epoch: [126][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.6825 (0.6825)\tAcc 0.812 (0.812)\n",
      "Epoch: [126][2/5]\tTime 0.076 (0.139)\tData 0.051 (0.113)\tLoss 0.4667 (0.5746)\tAcc 0.875 (0.844)\n",
      "Epoch: [126][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.093)\tLoss 0.8227 (0.6573)\tAcc 0.562 (0.750)\n",
      "Epoch: [126][4/5]\tTime 0.079 (0.109)\tData 0.056 (0.084)\tLoss 0.5121 (0.6210)\tAcc 0.875 (0.781)\n",
      "Epoch: [126][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.078)\tLoss 1.0798 (0.6776)\tAcc 0.444 (0.740)\n",
      "validation at epoch 126\n",
      "Epoch: [126][1/9]\tTime 0.205 (0.205)\tData 0.179 (0.179)\tLoss 0.3392 (0.3392)\tAcc 0.938 (0.938)\n",
      "Epoch: [126][2/9]\tTime 0.076 (0.140)\tData 0.050 (0.114)\tLoss 0.9868 (0.6630)\tAcc 0.500 (0.719)\n",
      "Epoch: [126][3/9]\tTime 0.069 (0.117)\tData 0.049 (0.093)\tLoss 0.7500 (0.6920)\tAcc 0.812 (0.750)\n",
      "Epoch: [126][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.7057 (0.6954)\tAcc 0.750 (0.750)\n",
      "Epoch: [126][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.6783 (0.6920)\tAcc 0.875 (0.775)\n",
      "Epoch: [126][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.3764 (0.6394)\tAcc 0.938 (0.802)\n",
      "Epoch: [126][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.5745 (0.6301)\tAcc 0.750 (0.795)\n",
      "Epoch: [126][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.8303 (0.6551)\tAcc 0.688 (0.781)\n",
      "Epoch: [126][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2381 (0.6487)\tAcc 1.000 (0.785)\n",
      "train at epoch 127\n",
      "Epoch: [127][1/5]\tTime 0.202 (0.202)\tData 0.174 (0.174)\tLoss 0.8070 (0.8070)\tAcc 0.688 (0.688)\n",
      "Epoch: [127][2/5]\tTime 0.078 (0.140)\tData 0.054 (0.114)\tLoss 0.6824 (0.7447)\tAcc 0.750 (0.719)\n",
      "Epoch: [127][3/5]\tTime 0.078 (0.119)\tData 0.055 (0.094)\tLoss 0.6567 (0.7153)\tAcc 0.750 (0.729)\n",
      "Epoch: [127][4/5]\tTime 0.078 (0.109)\tData 0.055 (0.085)\tLoss 0.5420 (0.6720)\tAcc 0.812 (0.750)\n",
      "Epoch: [127][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 0.7437 (0.6808)\tAcc 0.556 (0.726)\n",
      "validation at epoch 127\n",
      "Epoch: [127][1/9]\tTime 0.201 (0.201)\tData 0.176 (0.176)\tLoss 0.3708 (0.3708)\tAcc 0.938 (0.938)\n",
      "Epoch: [127][2/9]\tTime 0.077 (0.139)\tData 0.051 (0.114)\tLoss 0.9010 (0.6359)\tAcc 0.438 (0.688)\n",
      "Epoch: [127][3/9]\tTime 0.069 (0.116)\tData 0.049 (0.092)\tLoss 0.5831 (0.6183)\tAcc 0.875 (0.750)\n",
      "Epoch: [127][4/9]\tTime 0.074 (0.105)\tData 0.055 (0.083)\tLoss 0.7591 (0.6535)\tAcc 0.625 (0.719)\n",
      "Epoch: [127][5/9]\tTime 0.074 (0.099)\tData 0.055 (0.077)\tLoss 0.8022 (0.6832)\tAcc 0.688 (0.713)\n",
      "Epoch: [127][6/9]\tTime 0.076 (0.095)\tData 0.056 (0.074)\tLoss 0.2623 (0.6131)\tAcc 1.000 (0.760)\n",
      "Epoch: [127][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.6350 (0.6162)\tAcc 0.750 (0.759)\n",
      "Epoch: [127][8/9]\tTime 0.074 (0.090)\tData 0.054 (0.069)\tLoss 0.9244 (0.6547)\tAcc 0.750 (0.758)\n",
      "Epoch: [127][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.1583 (0.6471)\tAcc 1.000 (0.762)\n",
      "train at epoch 128\n",
      "Epoch: [128][1/5]\tTime 0.198 (0.198)\tData 0.167 (0.167)\tLoss 0.9051 (0.9051)\tAcc 0.688 (0.688)\n",
      "Epoch: [128][2/5]\tTime 0.075 (0.137)\tData 0.050 (0.109)\tLoss 0.6084 (0.7567)\tAcc 0.750 (0.719)\n",
      "Epoch: [128][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.090)\tLoss 0.5288 (0.6808)\tAcc 0.750 (0.729)\n",
      "Epoch: [128][4/5]\tTime 0.079 (0.107)\tData 0.055 (0.081)\tLoss 0.6361 (0.6696)\tAcc 0.688 (0.719)\n",
      "Epoch: [128][5/5]\tTime 0.077 (0.101)\tData 0.054 (0.076)\tLoss 0.7091 (0.6745)\tAcc 0.667 (0.712)\n",
      "validation at epoch 128\n",
      "Epoch: [128][1/9]\tTime 0.196 (0.196)\tData 0.166 (0.166)\tLoss 0.3290 (0.3290)\tAcc 0.938 (0.938)\n",
      "Epoch: [128][2/9]\tTime 0.068 (0.132)\tData 0.045 (0.106)\tLoss 0.9592 (0.6441)\tAcc 0.438 (0.688)\n",
      "Epoch: [128][3/9]\tTime 0.071 (0.112)\tData 0.052 (0.088)\tLoss 0.6042 (0.6308)\tAcc 0.812 (0.729)\n",
      "Epoch: [128][4/9]\tTime 0.073 (0.102)\tData 0.054 (0.079)\tLoss 0.6295 (0.6305)\tAcc 0.750 (0.734)\n",
      "Epoch: [128][5/9]\tTime 0.074 (0.096)\tData 0.055 (0.074)\tLoss 0.6839 (0.6412)\tAcc 0.688 (0.725)\n",
      "Epoch: [128][6/9]\tTime 0.073 (0.093)\tData 0.054 (0.071)\tLoss 0.3054 (0.5852)\tAcc 1.000 (0.771)\n",
      "Epoch: [128][7/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.7018 (0.6019)\tAcc 0.750 (0.768)\n",
      "Epoch: [128][8/9]\tTime 0.076 (0.088)\tData 0.056 (0.067)\tLoss 0.8783 (0.6364)\tAcc 0.562 (0.742)\n",
      "Epoch: [128][9/9]\tTime 0.075 (0.087)\tData 0.056 (0.066)\tLoss 0.3484 (0.6320)\tAcc 1.000 (0.746)\n",
      "train at epoch 129\n",
      "Epoch: [129][1/5]\tTime 0.199 (0.199)\tData 0.170 (0.170)\tLoss 0.6627 (0.6627)\tAcc 0.688 (0.688)\n",
      "Epoch: [129][2/5]\tTime 0.075 (0.137)\tData 0.051 (0.110)\tLoss 0.5819 (0.6223)\tAcc 0.750 (0.719)\n",
      "Epoch: [129][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.092)\tLoss 0.8511 (0.6986)\tAcc 0.562 (0.667)\n",
      "Epoch: [129][4/5]\tTime 0.080 (0.108)\tData 0.056 (0.083)\tLoss 0.6444 (0.6850)\tAcc 0.750 (0.688)\n",
      "Epoch: [129][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.077)\tLoss 0.4785 (0.6596)\tAcc 0.889 (0.712)\n",
      "validation at epoch 129\n",
      "Epoch: [129][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.3235 (0.3235)\tAcc 0.938 (0.938)\n",
      "Epoch: [129][2/9]\tTime 0.068 (0.133)\tData 0.047 (0.108)\tLoss 0.8333 (0.5784)\tAcc 0.562 (0.750)\n",
      "Epoch: [129][3/9]\tTime 0.072 (0.112)\tData 0.052 (0.090)\tLoss 0.7958 (0.6509)\tAcc 0.688 (0.729)\n",
      "Epoch: [129][4/9]\tTime 0.078 (0.104)\tData 0.058 (0.082)\tLoss 0.6233 (0.6440)\tAcc 0.625 (0.703)\n",
      "Epoch: [129][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.6835 (0.6519)\tAcc 0.750 (0.713)\n",
      "Epoch: [129][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3069 (0.5944)\tAcc 1.000 (0.760)\n",
      "Epoch: [129][7/9]\tTime 0.073 (0.091)\tData 0.054 (0.070)\tLoss 0.6046 (0.5959)\tAcc 0.750 (0.759)\n",
      "Epoch: [129][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8357 (0.6258)\tAcc 0.625 (0.742)\n",
      "Epoch: [129][9/9]\tTime 0.072 (0.087)\tData 0.054 (0.067)\tLoss 0.4736 (0.6235)\tAcc 1.000 (0.746)\n",
      "train at epoch 130\n",
      "Epoch: [130][1/5]\tTime 0.202 (0.202)\tData 0.172 (0.172)\tLoss 0.7530 (0.7530)\tAcc 0.812 (0.812)\n",
      "Epoch: [130][2/5]\tTime 0.074 (0.138)\tData 0.049 (0.111)\tLoss 0.8691 (0.8111)\tAcc 0.625 (0.719)\n",
      "Epoch: [130][3/5]\tTime 0.078 (0.118)\tData 0.053 (0.092)\tLoss 0.8068 (0.8096)\tAcc 0.688 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [130][4/5]\tTime 0.077 (0.108)\tData 0.054 (0.082)\tLoss 0.4458 (0.7187)\tAcc 0.875 (0.750)\n",
      "Epoch: [130][5/5]\tTime 0.079 (0.102)\tData 0.055 (0.077)\tLoss 0.3691 (0.6756)\tAcc 0.889 (0.767)\n",
      "validation at epoch 130\n",
      "Epoch: [130][1/9]\tTime 0.222 (0.222)\tData 0.187 (0.187)\tLoss 0.3774 (0.3774)\tAcc 0.938 (0.938)\n",
      "Epoch: [130][2/9]\tTime 0.072 (0.147)\tData 0.045 (0.116)\tLoss 0.9854 (0.6814)\tAcc 0.438 (0.688)\n",
      "Epoch: [130][3/9]\tTime 0.067 (0.121)\tData 0.048 (0.093)\tLoss 0.6974 (0.6867)\tAcc 0.812 (0.729)\n",
      "Epoch: [130][4/9]\tTime 0.073 (0.109)\tData 0.054 (0.083)\tLoss 0.7029 (0.6907)\tAcc 0.625 (0.703)\n",
      "Epoch: [130][5/9]\tTime 0.074 (0.102)\tData 0.054 (0.078)\tLoss 0.7243 (0.6975)\tAcc 0.750 (0.713)\n",
      "Epoch: [130][6/9]\tTime 0.077 (0.098)\tData 0.058 (0.074)\tLoss 0.2864 (0.6289)\tAcc 1.000 (0.760)\n",
      "Epoch: [130][7/9]\tTime 0.074 (0.094)\tData 0.054 (0.071)\tLoss 0.7659 (0.6485)\tAcc 0.750 (0.759)\n",
      "Epoch: [130][8/9]\tTime 0.073 (0.092)\tData 0.054 (0.069)\tLoss 0.8282 (0.6710)\tAcc 0.750 (0.758)\n",
      "Epoch: [130][9/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.3641 (0.6662)\tAcc 1.000 (0.762)\n",
      "train at epoch 131\n",
      "Epoch: [131][1/5]\tTime 0.200 (0.200)\tData 0.173 (0.173)\tLoss 1.2259 (1.2259)\tAcc 0.562 (0.562)\n",
      "Epoch: [131][2/5]\tTime 0.076 (0.138)\tData 0.052 (0.112)\tLoss 0.6622 (0.9440)\tAcc 0.750 (0.656)\n",
      "Epoch: [131][3/5]\tTime 0.079 (0.118)\tData 0.055 (0.093)\tLoss 0.4715 (0.7865)\tAcc 0.875 (0.729)\n",
      "Epoch: [131][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.5540 (0.7284)\tAcc 0.750 (0.734)\n",
      "Epoch: [131][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 0.5162 (0.7022)\tAcc 0.889 (0.753)\n",
      "validation at epoch 131\n",
      "Epoch: [131][1/9]\tTime 0.201 (0.201)\tData 0.178 (0.178)\tLoss 0.3689 (0.3689)\tAcc 0.938 (0.938)\n",
      "Epoch: [131][2/9]\tTime 0.077 (0.139)\tData 0.051 (0.114)\tLoss 0.9233 (0.6461)\tAcc 0.438 (0.688)\n",
      "Epoch: [131][3/9]\tTime 0.071 (0.116)\tData 0.051 (0.093)\tLoss 0.7062 (0.6662)\tAcc 0.812 (0.729)\n",
      "Epoch: [131][4/9]\tTime 0.074 (0.106)\tData 0.054 (0.083)\tLoss 0.7212 (0.6799)\tAcc 0.688 (0.719)\n",
      "Epoch: [131][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.7942 (0.7028)\tAcc 0.750 (0.725)\n",
      "Epoch: [131][6/9]\tTime 0.074 (0.095)\tData 0.054 (0.073)\tLoss 0.3517 (0.6443)\tAcc 1.000 (0.771)\n",
      "Epoch: [131][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.6430 (0.6441)\tAcc 0.750 (0.768)\n",
      "Epoch: [131][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.9861 (0.6868)\tAcc 0.562 (0.742)\n",
      "Epoch: [131][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.0934 (0.6777)\tAcc 1.000 (0.746)\n",
      "train at epoch 132\n",
      "Epoch: [132][1/5]\tTime 0.196 (0.196)\tData 0.164 (0.164)\tLoss 0.8713 (0.8713)\tAcc 0.688 (0.688)\n",
      "Epoch: [132][2/5]\tTime 0.072 (0.134)\tData 0.047 (0.106)\tLoss 0.5020 (0.6866)\tAcc 0.875 (0.781)\n",
      "Epoch: [132][3/5]\tTime 0.079 (0.116)\tData 0.055 (0.089)\tLoss 0.3490 (0.5741)\tAcc 1.000 (0.854)\n",
      "Epoch: [132][4/5]\tTime 0.079 (0.107)\tData 0.056 (0.081)\tLoss 0.8454 (0.6419)\tAcc 0.688 (0.812)\n",
      "Epoch: [132][5/5]\tTime 0.079 (0.101)\tData 0.055 (0.076)\tLoss 0.8424 (0.6666)\tAcc 0.778 (0.808)\n",
      "validation at epoch 132\n",
      "Epoch: [132][1/9]\tTime 0.202 (0.202)\tData 0.178 (0.178)\tLoss 0.5182 (0.5182)\tAcc 0.875 (0.875)\n",
      "Epoch: [132][2/9]\tTime 0.077 (0.140)\tData 0.050 (0.114)\tLoss 1.0745 (0.7964)\tAcc 0.500 (0.688)\n",
      "Epoch: [132][3/9]\tTime 0.066 (0.115)\tData 0.047 (0.092)\tLoss 0.7103 (0.7677)\tAcc 0.750 (0.708)\n",
      "Epoch: [132][4/9]\tTime 0.074 (0.105)\tData 0.054 (0.082)\tLoss 0.7202 (0.7558)\tAcc 0.625 (0.688)\n",
      "Epoch: [132][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.8102 (0.7667)\tAcc 0.688 (0.688)\n",
      "Epoch: [132][6/9]\tTime 0.075 (0.095)\tData 0.056 (0.073)\tLoss 0.3528 (0.6977)\tAcc 1.000 (0.740)\n",
      "Epoch: [132][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.6679 (0.6935)\tAcc 0.750 (0.741)\n",
      "Epoch: [132][8/9]\tTime 0.075 (0.089)\tData 0.055 (0.069)\tLoss 0.8078 (0.7077)\tAcc 0.750 (0.742)\n",
      "Epoch: [132][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.2620 (0.7009)\tAcc 1.000 (0.746)\n",
      "train at epoch 133\n",
      "Epoch: [133][1/5]\tTime 0.199 (0.199)\tData 0.168 (0.168)\tLoss 0.5753 (0.5753)\tAcc 0.688 (0.688)\n",
      "Epoch: [133][2/5]\tTime 0.074 (0.136)\tData 0.050 (0.109)\tLoss 0.8000 (0.6877)\tAcc 0.688 (0.688)\n",
      "Epoch: [133][3/5]\tTime 0.078 (0.117)\tData 0.054 (0.090)\tLoss 0.6598 (0.6784)\tAcc 0.812 (0.729)\n",
      "Epoch: [133][4/5]\tTime 0.079 (0.107)\tData 0.055 (0.082)\tLoss 0.4905 (0.6314)\tAcc 0.875 (0.766)\n",
      "Epoch: [133][5/5]\tTime 0.078 (0.101)\tData 0.054 (0.076)\tLoss 0.6789 (0.6373)\tAcc 0.778 (0.767)\n",
      "validation at epoch 133\n",
      "Epoch: [133][1/9]\tTime 0.202 (0.202)\tData 0.179 (0.179)\tLoss 0.3418 (0.3418)\tAcc 0.938 (0.938)\n",
      "Epoch: [133][2/9]\tTime 0.076 (0.139)\tData 0.051 (0.115)\tLoss 0.9294 (0.6356)\tAcc 0.500 (0.719)\n",
      "Epoch: [133][3/9]\tTime 0.070 (0.116)\tData 0.050 (0.093)\tLoss 0.6747 (0.6486)\tAcc 0.688 (0.708)\n",
      "Epoch: [133][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.6777 (0.6559)\tAcc 0.750 (0.719)\n",
      "Epoch: [133][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.078)\tLoss 0.7354 (0.6718)\tAcc 0.750 (0.725)\n",
      "Epoch: [133][6/9]\tTime 0.076 (0.095)\tData 0.057 (0.074)\tLoss 0.3706 (0.6216)\tAcc 0.938 (0.760)\n",
      "Epoch: [133][7/9]\tTime 0.075 (0.092)\tData 0.055 (0.072)\tLoss 0.7039 (0.6333)\tAcc 0.688 (0.750)\n",
      "Epoch: [133][8/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.8519 (0.6607)\tAcc 0.688 (0.742)\n",
      "Epoch: [133][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 0.2741 (0.6547)\tAcc 1.000 (0.746)\n",
      "train at epoch 134\n",
      "Epoch: [134][1/5]\tTime 0.207 (0.207)\tData 0.180 (0.180)\tLoss 0.6165 (0.6165)\tAcc 0.750 (0.750)\n",
      "Epoch: [134][2/5]\tTime 0.075 (0.141)\tData 0.051 (0.115)\tLoss 0.9926 (0.8046)\tAcc 0.562 (0.656)\n",
      "Epoch: [134][3/5]\tTime 0.079 (0.120)\tData 0.055 (0.095)\tLoss 1.0182 (0.8758)\tAcc 0.500 (0.604)\n",
      "Epoch: [134][4/5]\tTime 0.078 (0.110)\tData 0.055 (0.085)\tLoss 0.4893 (0.7792)\tAcc 0.938 (0.688)\n",
      "Epoch: [134][5/5]\tTime 0.078 (0.103)\tData 0.055 (0.079)\tLoss 0.6075 (0.7580)\tAcc 0.889 (0.712)\n",
      "validation at epoch 134\n",
      "Epoch: [134][1/9]\tTime 0.203 (0.203)\tData 0.178 (0.178)\tLoss 0.3754 (0.3754)\tAcc 0.938 (0.938)\n",
      "Epoch: [134][2/9]\tTime 0.075 (0.139)\tData 0.049 (0.114)\tLoss 1.0186 (0.6970)\tAcc 0.438 (0.688)\n",
      "Epoch: [134][3/9]\tTime 0.069 (0.116)\tData 0.050 (0.092)\tLoss 0.7944 (0.7294)\tAcc 0.625 (0.667)\n",
      "Epoch: [134][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.7212 (0.7274)\tAcc 0.625 (0.656)\n",
      "Epoch: [134][5/9]\tTime 0.074 (0.099)\tData 0.055 (0.077)\tLoss 0.8655 (0.7550)\tAcc 0.750 (0.675)\n",
      "Epoch: [134][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.074)\tLoss 0.3206 (0.6826)\tAcc 1.000 (0.729)\n",
      "Epoch: [134][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.7637 (0.6942)\tAcc 0.625 (0.714)\n",
      "Epoch: [134][8/9]\tTime 0.073 (0.089)\tData 0.054 (0.069)\tLoss 0.8907 (0.7188)\tAcc 0.688 (0.711)\n",
      "Epoch: [134][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.7208 (0.7188)\tAcc 1.000 (0.715)\n",
      "train at epoch 135\n",
      "Epoch: [135][1/5]\tTime 0.202 (0.202)\tData 0.173 (0.173)\tLoss 0.5455 (0.5455)\tAcc 0.875 (0.875)\n",
      "Epoch: [135][2/5]\tTime 0.074 (0.138)\tData 0.050 (0.111)\tLoss 0.6148 (0.5802)\tAcc 0.750 (0.812)\n",
      "Epoch: [135][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.092)\tLoss 0.7372 (0.6325)\tAcc 0.625 (0.750)\n",
      "Epoch: [135][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.6857 (0.6458)\tAcc 0.625 (0.719)\n",
      "Epoch: [135][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.5807 (0.6378)\tAcc 0.778 (0.726)\n",
      "validation at epoch 135\n",
      "Epoch: [135][1/9]\tTime 0.208 (0.208)\tData 0.183 (0.183)\tLoss 0.4749 (0.4749)\tAcc 0.938 (0.938)\n",
      "Epoch: [135][2/9]\tTime 0.077 (0.142)\tData 0.051 (0.117)\tLoss 0.8308 (0.6528)\tAcc 0.438 (0.688)\n",
      "Epoch: [135][3/9]\tTime 0.067 (0.117)\tData 0.047 (0.094)\tLoss 0.6631 (0.6562)\tAcc 0.750 (0.708)\n",
      "Epoch: [135][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 0.6951 (0.6660)\tAcc 0.688 (0.703)\n",
      "Epoch: [135][5/9]\tTime 0.076 (0.100)\tData 0.056 (0.078)\tLoss 0.7535 (0.6835)\tAcc 0.812 (0.725)\n",
      "Epoch: [135][6/9]\tTime 0.074 (0.096)\tData 0.055 (0.074)\tLoss 0.3467 (0.6273)\tAcc 1.000 (0.771)\n",
      "Epoch: [135][7/9]\tTime 0.073 (0.093)\tData 0.054 (0.072)\tLoss 0.7059 (0.6385)\tAcc 0.750 (0.768)\n",
      "Epoch: [135][8/9]\tTime 0.077 (0.091)\tData 0.057 (0.070)\tLoss 0.8323 (0.6628)\tAcc 0.688 (0.758)\n",
      "Epoch: [135][9/9]\tTime 0.079 (0.089)\tData 0.059 (0.069)\tLoss 0.6074 (0.6619)\tAcc 1.000 (0.762)\n",
      "train at epoch 136\n",
      "Epoch: [136][1/5]\tTime 0.204 (0.204)\tData 0.174 (0.174)\tLoss 0.7438 (0.7438)\tAcc 0.688 (0.688)\n",
      "Epoch: [136][2/5]\tTime 0.078 (0.141)\tData 0.053 (0.114)\tLoss 0.4838 (0.6138)\tAcc 0.750 (0.719)\n",
      "Epoch: [136][3/5]\tTime 0.091 (0.125)\tData 0.067 (0.098)\tLoss 0.8289 (0.6855)\tAcc 0.812 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [136][4/5]\tTime 0.086 (0.115)\tData 0.062 (0.089)\tLoss 0.7537 (0.7025)\tAcc 0.625 (0.719)\n",
      "Epoch: [136][5/5]\tTime 0.083 (0.109)\tData 0.059 (0.083)\tLoss 0.8372 (0.7191)\tAcc 0.667 (0.712)\n",
      "validation at epoch 136\n",
      "Epoch: [136][1/9]\tTime 0.208 (0.208)\tData 0.183 (0.183)\tLoss 0.4396 (0.4396)\tAcc 0.938 (0.938)\n",
      "Epoch: [136][2/9]\tTime 0.082 (0.145)\tData 0.055 (0.119)\tLoss 0.8931 (0.6664)\tAcc 0.500 (0.719)\n",
      "Epoch: [136][3/9]\tTime 0.069 (0.120)\tData 0.050 (0.096)\tLoss 0.6700 (0.6676)\tAcc 0.812 (0.750)\n",
      "Epoch: [136][4/9]\tTime 0.073 (0.108)\tData 0.054 (0.085)\tLoss 0.7057 (0.6771)\tAcc 0.625 (0.719)\n",
      "Epoch: [136][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.079)\tLoss 0.7674 (0.6952)\tAcc 0.750 (0.725)\n",
      "Epoch: [136][6/9]\tTime 0.073 (0.097)\tData 0.054 (0.075)\tLoss 0.2705 (0.6244)\tAcc 1.000 (0.771)\n",
      "Epoch: [136][7/9]\tTime 0.074 (0.093)\tData 0.054 (0.072)\tLoss 0.5073 (0.6077)\tAcc 0.938 (0.795)\n",
      "Epoch: [136][8/9]\tTime 0.075 (0.091)\tData 0.056 (0.070)\tLoss 0.8991 (0.6441)\tAcc 0.562 (0.766)\n",
      "Epoch: [136][9/9]\tTime 0.074 (0.089)\tData 0.055 (0.068)\tLoss 0.3522 (0.6396)\tAcc 1.000 (0.769)\n",
      "train at epoch 137\n",
      "Epoch: [137][1/5]\tTime 0.199 (0.199)\tData 0.171 (0.171)\tLoss 0.6655 (0.6655)\tAcc 0.688 (0.688)\n",
      "Epoch: [137][2/5]\tTime 0.079 (0.139)\tData 0.054 (0.112)\tLoss 0.6926 (0.6791)\tAcc 0.750 (0.719)\n",
      "Epoch: [137][3/5]\tTime 0.082 (0.120)\tData 0.058 (0.094)\tLoss 0.5877 (0.6486)\tAcc 0.875 (0.771)\n",
      "Epoch: [137][4/5]\tTime 0.080 (0.110)\tData 0.057 (0.085)\tLoss 0.6719 (0.6544)\tAcc 0.750 (0.766)\n",
      "Epoch: [137][5/5]\tTime 0.082 (0.104)\tData 0.058 (0.079)\tLoss 0.9903 (0.6958)\tAcc 0.444 (0.726)\n",
      "validation at epoch 137\n",
      "Epoch: [137][1/9]\tTime 0.207 (0.207)\tData 0.175 (0.175)\tLoss 0.3552 (0.3552)\tAcc 1.000 (1.000)\n",
      "Epoch: [137][2/9]\tTime 0.084 (0.145)\tData 0.048 (0.111)\tLoss 0.9167 (0.6360)\tAcc 0.500 (0.750)\n",
      "Epoch: [137][3/9]\tTime 0.064 (0.118)\tData 0.044 (0.089)\tLoss 0.7010 (0.6577)\tAcc 0.875 (0.792)\n",
      "Epoch: [137][4/9]\tTime 0.079 (0.108)\tData 0.059 (0.082)\tLoss 0.6117 (0.6462)\tAcc 0.688 (0.766)\n",
      "Epoch: [137][5/9]\tTime 0.079 (0.102)\tData 0.059 (0.077)\tLoss 0.6928 (0.6555)\tAcc 0.875 (0.788)\n",
      "Epoch: [137][6/9]\tTime 0.078 (0.098)\tData 0.058 (0.074)\tLoss 0.2707 (0.5914)\tAcc 1.000 (0.823)\n",
      "Epoch: [137][7/9]\tTime 0.078 (0.095)\tData 0.059 (0.072)\tLoss 0.5958 (0.5920)\tAcc 0.750 (0.813)\n",
      "Epoch: [137][8/9]\tTime 0.080 (0.093)\tData 0.059 (0.070)\tLoss 0.8663 (0.6263)\tAcc 0.688 (0.797)\n",
      "Epoch: [137][9/9]\tTime 0.077 (0.092)\tData 0.058 (0.069)\tLoss 0.5384 (0.6249)\tAcc 1.000 (0.800)\n",
      "train at epoch 138\n",
      "Epoch: [138][1/5]\tTime 0.204 (0.204)\tData 0.173 (0.173)\tLoss 0.6464 (0.6464)\tAcc 0.812 (0.812)\n",
      "Epoch: [138][2/5]\tTime 0.084 (0.144)\tData 0.060 (0.116)\tLoss 0.7531 (0.6997)\tAcc 0.688 (0.750)\n",
      "Epoch: [138][3/5]\tTime 0.079 (0.122)\tData 0.054 (0.096)\tLoss 1.0260 (0.8085)\tAcc 0.562 (0.688)\n",
      "Epoch: [138][4/5]\tTime 0.079 (0.112)\tData 0.056 (0.086)\tLoss 0.5267 (0.7380)\tAcc 0.812 (0.719)\n",
      "Epoch: [138][5/5]\tTime 0.081 (0.105)\tData 0.055 (0.079)\tLoss 0.4458 (0.7020)\tAcc 0.778 (0.726)\n",
      "validation at epoch 138\n",
      "Epoch: [138][1/9]\tTime 0.204 (0.204)\tData 0.181 (0.181)\tLoss 0.3299 (0.3299)\tAcc 0.938 (0.938)\n",
      "Epoch: [138][2/9]\tTime 0.081 (0.143)\tData 0.053 (0.117)\tLoss 0.8846 (0.6072)\tAcc 0.500 (0.719)\n",
      "Epoch: [138][3/9]\tTime 0.066 (0.117)\tData 0.046 (0.093)\tLoss 0.6727 (0.6291)\tAcc 0.812 (0.750)\n",
      "Epoch: [138][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 0.6131 (0.6251)\tAcc 0.688 (0.734)\n",
      "Epoch: [138][5/9]\tTime 0.075 (0.100)\tData 0.056 (0.078)\tLoss 0.7556 (0.6512)\tAcc 0.750 (0.738)\n",
      "Epoch: [138][6/9]\tTime 0.073 (0.095)\tData 0.055 (0.074)\tLoss 0.3042 (0.5934)\tAcc 1.000 (0.781)\n",
      "Epoch: [138][7/9]\tTime 0.076 (0.093)\tData 0.056 (0.072)\tLoss 0.6007 (0.5944)\tAcc 0.688 (0.768)\n",
      "Epoch: [138][8/9]\tTime 0.076 (0.091)\tData 0.057 (0.070)\tLoss 0.8714 (0.6290)\tAcc 0.625 (0.750)\n",
      "Epoch: [138][9/9]\tTime 0.075 (0.089)\tData 0.056 (0.068)\tLoss 0.1394 (0.6215)\tAcc 1.000 (0.754)\n",
      "train at epoch 139\n",
      "Epoch: [139][1/5]\tTime 0.202 (0.202)\tData 0.175 (0.175)\tLoss 0.8112 (0.8112)\tAcc 0.688 (0.688)\n",
      "Epoch: [139][2/5]\tTime 0.075 (0.139)\tData 0.052 (0.113)\tLoss 0.7425 (0.7768)\tAcc 0.750 (0.719)\n",
      "Epoch: [139][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.094)\tLoss 0.7593 (0.7710)\tAcc 0.562 (0.667)\n",
      "Epoch: [139][4/5]\tTime 0.077 (0.108)\tData 0.054 (0.084)\tLoss 0.6185 (0.7329)\tAcc 0.750 (0.688)\n",
      "Epoch: [139][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.078)\tLoss 0.5829 (0.7144)\tAcc 0.889 (0.712)\n",
      "validation at epoch 139\n",
      "Epoch: [139][1/9]\tTime 0.197 (0.197)\tData 0.170 (0.170)\tLoss 0.4460 (0.4460)\tAcc 0.938 (0.938)\n",
      "Epoch: [139][2/9]\tTime 0.071 (0.134)\tData 0.048 (0.109)\tLoss 1.0393 (0.7427)\tAcc 0.438 (0.688)\n",
      "Epoch: [139][3/9]\tTime 0.073 (0.114)\tData 0.054 (0.091)\tLoss 0.7958 (0.7604)\tAcc 0.688 (0.688)\n",
      "Epoch: [139][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.6482 (0.7323)\tAcc 0.750 (0.703)\n",
      "Epoch: [139][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.7858 (0.7430)\tAcc 0.812 (0.725)\n",
      "Epoch: [139][6/9]\tTime 0.073 (0.094)\tData 0.054 (0.072)\tLoss 0.2889 (0.6673)\tAcc 1.000 (0.771)\n",
      "Epoch: [139][7/9]\tTime 0.075 (0.091)\tData 0.055 (0.070)\tLoss 0.6262 (0.6615)\tAcc 0.875 (0.786)\n",
      "Epoch: [139][8/9]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.8621 (0.6865)\tAcc 0.625 (0.766)\n",
      "Epoch: [139][9/9]\tTime 0.077 (0.088)\tData 0.057 (0.067)\tLoss 0.2492 (0.6798)\tAcc 1.000 (0.769)\n",
      "train at epoch 140\n",
      "Epoch: [140][1/5]\tTime 0.203 (0.203)\tData 0.175 (0.175)\tLoss 0.8001 (0.8001)\tAcc 0.688 (0.688)\n",
      "Epoch: [140][2/5]\tTime 0.085 (0.144)\tData 0.061 (0.118)\tLoss 0.5701 (0.6851)\tAcc 0.812 (0.750)\n",
      "Epoch: [140][3/5]\tTime 0.080 (0.123)\tData 0.056 (0.097)\tLoss 0.5395 (0.6366)\tAcc 0.750 (0.750)\n",
      "Epoch: [140][4/5]\tTime 0.079 (0.112)\tData 0.055 (0.087)\tLoss 0.6890 (0.6497)\tAcc 0.688 (0.734)\n",
      "Epoch: [140][5/5]\tTime 0.081 (0.106)\tData 0.058 (0.081)\tLoss 0.4464 (0.6246)\tAcc 0.889 (0.753)\n",
      "validation at epoch 140\n",
      "Epoch: [140][1/9]\tTime 0.200 (0.200)\tData 0.174 (0.174)\tLoss 0.4308 (0.4308)\tAcc 0.938 (0.938)\n",
      "Epoch: [140][2/9]\tTime 0.081 (0.140)\tData 0.054 (0.114)\tLoss 0.9489 (0.6899)\tAcc 0.438 (0.688)\n",
      "Epoch: [140][3/9]\tTime 0.067 (0.116)\tData 0.047 (0.092)\tLoss 0.6529 (0.6775)\tAcc 0.750 (0.708)\n",
      "Epoch: [140][4/9]\tTime 0.076 (0.106)\tData 0.057 (0.083)\tLoss 0.7867 (0.7048)\tAcc 0.625 (0.688)\n",
      "Epoch: [140][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.7964 (0.7231)\tAcc 0.750 (0.700)\n",
      "Epoch: [140][6/9]\tTime 0.075 (0.095)\tData 0.055 (0.074)\tLoss 0.2614 (0.6462)\tAcc 1.000 (0.750)\n",
      "Epoch: [140][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.071)\tLoss 0.6232 (0.6429)\tAcc 0.812 (0.759)\n",
      "Epoch: [140][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 1.0045 (0.6881)\tAcc 0.562 (0.734)\n",
      "Epoch: [140][9/9]\tTime 0.072 (0.088)\tData 0.054 (0.067)\tLoss 0.6488 (0.6875)\tAcc 1.000 (0.738)\n",
      "train at epoch 141\n",
      "Epoch: [141][1/5]\tTime 0.196 (0.196)\tData 0.163 (0.163)\tLoss 0.5685 (0.5685)\tAcc 0.750 (0.750)\n",
      "Epoch: [141][2/5]\tTime 0.070 (0.133)\tData 0.046 (0.105)\tLoss 0.7065 (0.6375)\tAcc 0.688 (0.719)\n",
      "Epoch: [141][3/5]\tTime 0.077 (0.115)\tData 0.054 (0.088)\tLoss 0.7636 (0.6795)\tAcc 0.750 (0.729)\n",
      "Epoch: [141][4/5]\tTime 0.078 (0.105)\tData 0.054 (0.080)\tLoss 0.8442 (0.7207)\tAcc 0.625 (0.703)\n",
      "Epoch: [141][5/5]\tTime 0.081 (0.101)\tData 0.058 (0.075)\tLoss 1.1068 (0.7683)\tAcc 0.667 (0.699)\n",
      "validation at epoch 141\n",
      "Epoch: [141][1/9]\tTime 0.204 (0.204)\tData 0.179 (0.179)\tLoss 0.3865 (0.3865)\tAcc 0.938 (0.938)\n",
      "Epoch: [141][2/9]\tTime 0.075 (0.140)\tData 0.050 (0.115)\tLoss 0.9122 (0.6494)\tAcc 0.438 (0.688)\n",
      "Epoch: [141][3/9]\tTime 0.070 (0.116)\tData 0.051 (0.093)\tLoss 0.6900 (0.6629)\tAcc 0.750 (0.708)\n",
      "Epoch: [141][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.084)\tLoss 0.6751 (0.6660)\tAcc 0.625 (0.688)\n",
      "Epoch: [141][5/9]\tTime 0.074 (0.099)\tData 0.055 (0.078)\tLoss 0.6464 (0.6621)\tAcc 0.875 (0.725)\n",
      "Epoch: [141][6/9]\tTime 0.075 (0.095)\tData 0.056 (0.074)\tLoss 0.3157 (0.6043)\tAcc 1.000 (0.771)\n",
      "Epoch: [141][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.071)\tLoss 0.6501 (0.6109)\tAcc 0.812 (0.777)\n",
      "Epoch: [141][8/9]\tTime 0.074 (0.090)\tData 0.055 (0.069)\tLoss 0.9763 (0.6566)\tAcc 0.562 (0.750)\n",
      "Epoch: [141][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.068)\tLoss 0.4962 (0.6541)\tAcc 1.000 (0.754)\n",
      "train at epoch 142\n",
      "Epoch: [142][1/5]\tTime 0.200 (0.200)\tData 0.172 (0.172)\tLoss 0.8223 (0.8223)\tAcc 0.625 (0.625)\n",
      "Epoch: [142][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.112)\tLoss 0.4747 (0.6485)\tAcc 0.875 (0.750)\n",
      "Epoch: [142][3/5]\tTime 0.078 (0.118)\tData 0.054 (0.093)\tLoss 0.7353 (0.6774)\tAcc 0.688 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [142][4/5]\tTime 0.078 (0.108)\tData 0.054 (0.083)\tLoss 0.6177 (0.6625)\tAcc 0.750 (0.734)\n",
      "Epoch: [142][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 1.0260 (0.7073)\tAcc 0.667 (0.726)\n",
      "validation at epoch 142\n",
      "Epoch: [142][1/9]\tTime 0.207 (0.207)\tData 0.175 (0.175)\tLoss 0.3643 (0.3643)\tAcc 0.938 (0.938)\n",
      "Epoch: [142][2/9]\tTime 0.070 (0.139)\tData 0.046 (0.111)\tLoss 0.9430 (0.6536)\tAcc 0.500 (0.719)\n",
      "Epoch: [142][3/9]\tTime 0.070 (0.116)\tData 0.050 (0.090)\tLoss 0.7777 (0.6950)\tAcc 0.812 (0.750)\n",
      "Epoch: [142][4/9]\tTime 0.077 (0.106)\tData 0.055 (0.082)\tLoss 0.6981 (0.6958)\tAcc 0.688 (0.734)\n",
      "Epoch: [142][5/9]\tTime 0.071 (0.099)\tData 0.051 (0.076)\tLoss 0.7969 (0.7160)\tAcc 0.812 (0.750)\n",
      "Epoch: [142][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.072)\tLoss 0.3152 (0.6492)\tAcc 1.000 (0.792)\n",
      "Epoch: [142][7/9]\tTime 0.074 (0.092)\tData 0.055 (0.070)\tLoss 0.5632 (0.6369)\tAcc 0.812 (0.795)\n",
      "Epoch: [142][8/9]\tTime 0.076 (0.090)\tData 0.054 (0.068)\tLoss 0.8690 (0.6659)\tAcc 0.625 (0.773)\n",
      "Epoch: [142][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.066)\tLoss 0.3540 (0.6611)\tAcc 1.000 (0.777)\n",
      "train at epoch 143\n",
      "Epoch: [143][1/5]\tTime 0.201 (0.201)\tData 0.170 (0.170)\tLoss 0.5402 (0.5402)\tAcc 0.750 (0.750)\n",
      "Epoch: [143][2/5]\tTime 0.074 (0.138)\tData 0.050 (0.110)\tLoss 0.5469 (0.5436)\tAcc 0.875 (0.812)\n",
      "Epoch: [143][3/5]\tTime 0.080 (0.118)\tData 0.055 (0.092)\tLoss 0.6525 (0.5799)\tAcc 0.812 (0.812)\n",
      "Epoch: [143][4/5]\tTime 0.077 (0.108)\tData 0.054 (0.082)\tLoss 0.8785 (0.6545)\tAcc 0.500 (0.734)\n",
      "Epoch: [143][5/5]\tTime 0.078 (0.102)\tData 0.055 (0.077)\tLoss 0.3875 (0.6216)\tAcc 0.889 (0.753)\n",
      "validation at epoch 143\n",
      "Epoch: [143][1/9]\tTime 0.209 (0.209)\tData 0.183 (0.183)\tLoss 0.3474 (0.3474)\tAcc 0.938 (0.938)\n",
      "Epoch: [143][2/9]\tTime 0.079 (0.144)\tData 0.050 (0.117)\tLoss 1.0530 (0.7002)\tAcc 0.500 (0.719)\n",
      "Epoch: [143][3/9]\tTime 0.067 (0.118)\tData 0.048 (0.094)\tLoss 0.6909 (0.6971)\tAcc 0.750 (0.729)\n",
      "Epoch: [143][4/9]\tTime 0.073 (0.107)\tData 0.054 (0.084)\tLoss 0.6402 (0.6829)\tAcc 0.688 (0.719)\n",
      "Epoch: [143][5/9]\tTime 0.074 (0.101)\tData 0.054 (0.078)\tLoss 0.8083 (0.7080)\tAcc 0.750 (0.725)\n",
      "Epoch: [143][6/9]\tTime 0.075 (0.096)\tData 0.055 (0.074)\tLoss 0.3597 (0.6499)\tAcc 1.000 (0.771)\n",
      "Epoch: [143][7/9]\tTime 0.077 (0.094)\tData 0.058 (0.072)\tLoss 0.5315 (0.6330)\tAcc 0.812 (0.777)\n",
      "Epoch: [143][8/9]\tTime 0.078 (0.092)\tData 0.059 (0.070)\tLoss 0.8882 (0.6649)\tAcc 0.562 (0.750)\n",
      "Epoch: [143][9/9]\tTime 0.073 (0.090)\tData 0.054 (0.068)\tLoss 0.2158 (0.6580)\tAcc 1.000 (0.754)\n",
      "train at epoch 144\n",
      "Epoch: [144][1/5]\tTime 0.204 (0.204)\tData 0.172 (0.172)\tLoss 0.5850 (0.5850)\tAcc 0.750 (0.750)\n",
      "Epoch: [144][2/5]\tTime 0.073 (0.138)\tData 0.049 (0.110)\tLoss 0.7005 (0.6428)\tAcc 0.875 (0.812)\n",
      "Epoch: [144][3/5]\tTime 0.079 (0.119)\tData 0.055 (0.092)\tLoss 1.0363 (0.7739)\tAcc 0.562 (0.729)\n",
      "Epoch: [144][4/5]\tTime 0.079 (0.109)\tData 0.056 (0.083)\tLoss 0.9616 (0.8209)\tAcc 0.625 (0.703)\n",
      "Epoch: [144][5/5]\tTime 0.083 (0.104)\tData 0.060 (0.078)\tLoss 0.3929 (0.7681)\tAcc 1.000 (0.740)\n",
      "validation at epoch 144\n",
      "Epoch: [144][1/9]\tTime 0.198 (0.198)\tData 0.170 (0.170)\tLoss 0.3854 (0.3854)\tAcc 0.938 (0.938)\n",
      "Epoch: [144][2/9]\tTime 0.071 (0.134)\tData 0.048 (0.109)\tLoss 0.9758 (0.6806)\tAcc 0.438 (0.688)\n",
      "Epoch: [144][3/9]\tTime 0.072 (0.114)\tData 0.053 (0.090)\tLoss 0.6636 (0.6749)\tAcc 0.812 (0.729)\n",
      "Epoch: [144][4/9]\tTime 0.073 (0.104)\tData 0.054 (0.081)\tLoss 0.6234 (0.6620)\tAcc 0.688 (0.719)\n",
      "Epoch: [144][5/9]\tTime 0.074 (0.098)\tData 0.055 (0.076)\tLoss 0.6423 (0.6581)\tAcc 0.812 (0.738)\n",
      "Epoch: [144][6/9]\tTime 0.074 (0.094)\tData 0.055 (0.073)\tLoss 0.3036 (0.5990)\tAcc 1.000 (0.781)\n",
      "Epoch: [144][7/9]\tTime 0.074 (0.091)\tData 0.054 (0.070)\tLoss 0.6645 (0.6084)\tAcc 0.625 (0.759)\n",
      "Epoch: [144][8/9]\tTime 0.076 (0.089)\tData 0.056 (0.068)\tLoss 0.9212 (0.6475)\tAcc 0.750 (0.758)\n",
      "Epoch: [144][9/9]\tTime 0.077 (0.088)\tData 0.056 (0.067)\tLoss 0.2346 (0.6411)\tAcc 1.000 (0.762)\n",
      "train at epoch 145\n",
      "Epoch: [145][1/5]\tTime 0.228 (0.228)\tData 0.192 (0.192)\tLoss 0.7382 (0.7382)\tAcc 0.562 (0.562)\n",
      "Epoch: [145][2/5]\tTime 0.076 (0.152)\tData 0.051 (0.121)\tLoss 0.7180 (0.7281)\tAcc 0.688 (0.625)\n",
      "Epoch: [145][3/5]\tTime 0.085 (0.130)\tData 0.061 (0.101)\tLoss 0.7639 (0.7400)\tAcc 0.750 (0.667)\n",
      "Epoch: [145][4/5]\tTime 0.087 (0.119)\tData 0.061 (0.091)\tLoss 0.4229 (0.6608)\tAcc 0.875 (0.719)\n",
      "Epoch: [145][5/5]\tTime 0.085 (0.113)\tData 0.060 (0.085)\tLoss 0.6528 (0.6598)\tAcc 0.778 (0.726)\n",
      "validation at epoch 145\n",
      "Epoch: [145][1/9]\tTime 0.239 (0.239)\tData 0.207 (0.207)\tLoss 0.3922 (0.3922)\tAcc 0.938 (0.938)\n",
      "Epoch: [145][2/9]\tTime 0.081 (0.160)\tData 0.059 (0.133)\tLoss 1.0322 (0.7122)\tAcc 0.438 (0.688)\n",
      "Epoch: [145][3/9]\tTime 0.073 (0.131)\tData 0.054 (0.107)\tLoss 0.6531 (0.6925)\tAcc 0.875 (0.750)\n",
      "Epoch: [145][4/9]\tTime 0.074 (0.117)\tData 0.054 (0.094)\tLoss 0.6228 (0.6751)\tAcc 0.750 (0.750)\n",
      "Epoch: [145][5/9]\tTime 0.080 (0.110)\tData 0.060 (0.087)\tLoss 0.7484 (0.6897)\tAcc 0.812 (0.762)\n",
      "Epoch: [145][6/9]\tTime 0.080 (0.105)\tData 0.060 (0.082)\tLoss 0.2687 (0.6196)\tAcc 1.000 (0.802)\n",
      "Epoch: [145][7/9]\tTime 0.080 (0.101)\tData 0.060 (0.079)\tLoss 0.6289 (0.6209)\tAcc 0.812 (0.804)\n",
      "Epoch: [145][8/9]\tTime 0.080 (0.099)\tData 0.060 (0.077)\tLoss 0.9285 (0.6594)\tAcc 0.625 (0.781)\n",
      "Epoch: [145][9/9]\tTime 0.080 (0.096)\tData 0.060 (0.075)\tLoss 0.1615 (0.6517)\tAcc 1.000 (0.785)\n",
      "train at epoch 146\n",
      "Epoch: [146][1/5]\tTime 0.223 (0.223)\tData 0.183 (0.183)\tLoss 0.5316 (0.5316)\tAcc 0.750 (0.750)\n",
      "Epoch: [146][2/5]\tTime 0.072 (0.147)\tData 0.047 (0.115)\tLoss 0.7514 (0.6415)\tAcc 0.625 (0.688)\n",
      "Epoch: [146][3/5]\tTime 0.086 (0.127)\tData 0.061 (0.097)\tLoss 0.5981 (0.6271)\tAcc 0.688 (0.688)\n",
      "Epoch: [146][4/5]\tTime 0.086 (0.117)\tData 0.061 (0.088)\tLoss 0.6490 (0.6326)\tAcc 0.812 (0.719)\n",
      "Epoch: [146][5/5]\tTime 0.087 (0.111)\tData 0.062 (0.083)\tLoss 0.6842 (0.6389)\tAcc 0.889 (0.740)\n",
      "validation at epoch 146\n",
      "Epoch: [146][1/9]\tTime 0.217 (0.217)\tData 0.191 (0.191)\tLoss 0.3894 (0.3894)\tAcc 0.938 (0.938)\n",
      "Epoch: [146][2/9]\tTime 0.084 (0.151)\tData 0.057 (0.124)\tLoss 0.9092 (0.6493)\tAcc 0.438 (0.688)\n",
      "Epoch: [146][3/9]\tTime 0.073 (0.125)\tData 0.053 (0.100)\tLoss 0.6068 (0.6351)\tAcc 0.875 (0.750)\n",
      "Epoch: [146][4/9]\tTime 0.080 (0.114)\tData 0.060 (0.090)\tLoss 0.6603 (0.6414)\tAcc 0.625 (0.719)\n",
      "Epoch: [146][5/9]\tTime 0.080 (0.107)\tData 0.060 (0.084)\tLoss 0.6384 (0.6408)\tAcc 0.750 (0.725)\n",
      "Epoch: [146][6/9]\tTime 0.080 (0.102)\tData 0.060 (0.080)\tLoss 0.2778 (0.5803)\tAcc 1.000 (0.771)\n",
      "Epoch: [146][7/9]\tTime 0.080 (0.099)\tData 0.060 (0.077)\tLoss 0.6527 (0.5907)\tAcc 0.812 (0.777)\n",
      "Epoch: [146][8/9]\tTime 0.080 (0.097)\tData 0.061 (0.075)\tLoss 0.9509 (0.6357)\tAcc 0.625 (0.758)\n",
      "Epoch: [146][9/9]\tTime 0.081 (0.095)\tData 0.060 (0.073)\tLoss 0.3677 (0.6316)\tAcc 1.000 (0.762)\n",
      "train at epoch 147\n",
      "Epoch: [147][1/5]\tTime 0.201 (0.201)\tData 0.171 (0.171)\tLoss 0.7151 (0.7151)\tAcc 0.625 (0.625)\n",
      "Epoch: [147][2/5]\tTime 0.075 (0.138)\tData 0.050 (0.111)\tLoss 0.7577 (0.7364)\tAcc 0.812 (0.719)\n",
      "Epoch: [147][3/5]\tTime 0.080 (0.118)\tData 0.055 (0.092)\tLoss 0.7255 (0.7328)\tAcc 0.812 (0.750)\n",
      "Epoch: [147][4/5]\tTime 0.086 (0.110)\tData 0.061 (0.084)\tLoss 0.6763 (0.7186)\tAcc 0.688 (0.734)\n",
      "Epoch: [147][5/5]\tTime 0.089 (0.106)\tData 0.064 (0.080)\tLoss 1.1014 (0.7658)\tAcc 0.444 (0.699)\n",
      "validation at epoch 147\n",
      "Epoch: [147][1/9]\tTime 0.206 (0.206)\tData 0.180 (0.180)\tLoss 0.3774 (0.3774)\tAcc 0.938 (0.938)\n",
      "Epoch: [147][2/9]\tTime 0.077 (0.142)\tData 0.049 (0.115)\tLoss 1.0848 (0.7311)\tAcc 0.500 (0.719)\n",
      "Epoch: [147][3/9]\tTime 0.066 (0.116)\tData 0.046 (0.092)\tLoss 0.6812 (0.7144)\tAcc 0.875 (0.771)\n",
      "Epoch: [147][4/9]\tTime 0.073 (0.106)\tData 0.053 (0.082)\tLoss 0.6015 (0.6862)\tAcc 0.688 (0.750)\n",
      "Epoch: [147][5/9]\tTime 0.074 (0.099)\tData 0.054 (0.077)\tLoss 0.7123 (0.6914)\tAcc 0.812 (0.762)\n",
      "Epoch: [147][6/9]\tTime 0.075 (0.095)\tData 0.055 (0.073)\tLoss 0.3657 (0.6371)\tAcc 1.000 (0.802)\n",
      "Epoch: [147][7/9]\tTime 0.076 (0.092)\tData 0.056 (0.070)\tLoss 0.6530 (0.6394)\tAcc 0.750 (0.795)\n",
      "Epoch: [147][8/9]\tTime 0.075 (0.090)\tData 0.055 (0.069)\tLoss 0.9967 (0.6841)\tAcc 0.688 (0.781)\n",
      "Epoch: [147][9/9]\tTime 0.073 (0.088)\tData 0.054 (0.067)\tLoss 0.3252 (0.6786)\tAcc 1.000 (0.785)\n",
      "train at epoch 148\n",
      "Epoch: [148][1/5]\tTime 0.201 (0.201)\tData 0.174 (0.174)\tLoss 0.5124 (0.5124)\tAcc 0.812 (0.812)\n",
      "Epoch: [148][2/5]\tTime 0.075 (0.138)\tData 0.051 (0.112)\tLoss 0.6280 (0.5702)\tAcc 0.750 (0.781)\n",
      "Epoch: [148][3/5]\tTime 0.078 (0.118)\tData 0.055 (0.093)\tLoss 0.6091 (0.5831)\tAcc 0.562 (0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [148][4/5]\tTime 0.079 (0.109)\tData 0.055 (0.084)\tLoss 0.3935 (0.5357)\tAcc 0.938 (0.766)\n",
      "Epoch: [148][5/5]\tTime 0.078 (0.102)\tData 0.054 (0.078)\tLoss 1.0250 (0.5960)\tAcc 0.556 (0.740)\n",
      "validation at epoch 148\n",
      "Epoch: [148][1/9]\tTime 0.207 (0.207)\tData 0.182 (0.182)\tLoss 0.3829 (0.3829)\tAcc 0.938 (0.938)\n",
      "Epoch: [148][2/9]\tTime 0.075 (0.141)\tData 0.049 (0.115)\tLoss 0.9319 (0.6574)\tAcc 0.500 (0.719)\n",
      "Epoch: [148][3/9]\tTime 0.068 (0.116)\tData 0.048 (0.093)\tLoss 0.7133 (0.6761)\tAcc 0.812 (0.750)\n",
      "Epoch: [148][4/9]\tTime 0.073 (0.106)\tData 0.054 (0.083)\tLoss 0.6769 (0.6763)\tAcc 0.688 (0.734)\n",
      "Epoch: [148][5/9]\tTime 0.078 (0.100)\tData 0.058 (0.078)\tLoss 0.8498 (0.7110)\tAcc 0.812 (0.750)\n",
      "Epoch: [148][6/9]\tTime 0.081 (0.097)\tData 0.062 (0.075)\tLoss 0.2520 (0.6345)\tAcc 1.000 (0.792)\n",
      "Epoch: [148][7/9]\tTime 0.079 (0.094)\tData 0.059 (0.073)\tLoss 0.6258 (0.6332)\tAcc 0.875 (0.804)\n",
      "Epoch: [148][8/9]\tTime 0.079 (0.093)\tData 0.060 (0.071)\tLoss 0.8410 (0.6592)\tAcc 0.750 (0.797)\n",
      "Epoch: [148][9/9]\tTime 0.079 (0.091)\tData 0.060 (0.070)\tLoss 0.2945 (0.6536)\tAcc 1.000 (0.800)\n",
      "train at epoch 149\n",
      "Epoch: [149][1/5]\tTime 0.217 (0.217)\tData 0.184 (0.184)\tLoss 0.8745 (0.8745)\tAcc 0.625 (0.625)\n",
      "Epoch: [149][2/5]\tTime 0.092 (0.155)\tData 0.067 (0.126)\tLoss 1.1019 (0.9882)\tAcc 0.562 (0.594)\n",
      "Epoch: [149][3/5]\tTime 0.086 (0.132)\tData 0.061 (0.104)\tLoss 0.4703 (0.8156)\tAcc 0.812 (0.667)\n",
      "Epoch: [149][4/5]\tTime 0.086 (0.120)\tData 0.062 (0.094)\tLoss 0.5567 (0.7509)\tAcc 0.875 (0.719)\n",
      "Epoch: [149][5/5]\tTime 0.086 (0.113)\tData 0.062 (0.087)\tLoss 0.5439 (0.7253)\tAcc 0.778 (0.726)\n",
      "validation at epoch 149\n",
      "Epoch: [149][1/9]\tTime 0.206 (0.206)\tData 0.180 (0.180)\tLoss 0.4403 (0.4403)\tAcc 0.875 (0.875)\n",
      "Epoch: [149][2/9]\tTime 0.075 (0.140)\tData 0.048 (0.114)\tLoss 0.8534 (0.6469)\tAcc 0.438 (0.656)\n",
      "Epoch: [149][3/9]\tTime 0.066 (0.116)\tData 0.047 (0.092)\tLoss 0.7691 (0.6876)\tAcc 0.750 (0.688)\n",
      "Epoch: [149][4/9]\tTime 0.073 (0.105)\tData 0.054 (0.082)\tLoss 0.6121 (0.6687)\tAcc 0.625 (0.672)\n",
      "Epoch: [149][5/9]\tTime 0.075 (0.099)\tData 0.054 (0.077)\tLoss 0.8174 (0.6985)\tAcc 0.812 (0.700)\n",
      "Epoch: [149][6/9]\tTime 0.079 (0.096)\tData 0.059 (0.074)\tLoss 0.2305 (0.6205)\tAcc 1.000 (0.750)\n",
      "Epoch: [149][7/9]\tTime 0.089 (0.095)\tData 0.070 (0.073)\tLoss 0.5581 (0.6116)\tAcc 0.875 (0.768)\n",
      "Epoch: [149][8/9]\tTime 0.074 (0.092)\tData 0.054 (0.071)\tLoss 0.8098 (0.6363)\tAcc 0.688 (0.758)\n",
      "Epoch: [149][9/9]\tTime 0.073 (0.090)\tData 0.054 (0.069)\tLoss 0.5074 (0.6344)\tAcc 1.000 (0.762)\n",
      "train at epoch 150\n",
      "Epoch: [150][1/5]\tTime 0.197 (0.197)\tData 0.167 (0.167)\tLoss 0.5409 (0.5409)\tAcc 0.875 (0.875)\n",
      "Epoch: [150][2/5]\tTime 0.073 (0.135)\tData 0.049 (0.108)\tLoss 0.8496 (0.6953)\tAcc 0.750 (0.812)\n",
      "Epoch: [150][3/5]\tTime 0.078 (0.116)\tData 0.054 (0.090)\tLoss 0.8409 (0.7438)\tAcc 0.625 (0.750)\n",
      "Epoch: [150][4/5]\tTime 0.082 (0.107)\tData 0.058 (0.082)\tLoss 0.4582 (0.6724)\tAcc 0.875 (0.781)\n",
      "Epoch: [150][5/5]\tTime 0.083 (0.103)\tData 0.059 (0.078)\tLoss 0.4533 (0.6454)\tAcc 0.778 (0.781)\n",
      "validation at epoch 150\n",
      "Epoch: [150][1/9]\tTime 0.204 (0.204)\tData 0.180 (0.180)\tLoss 0.4384 (0.4384)\tAcc 0.938 (0.938)\n",
      "Epoch: [150][2/9]\tTime 0.078 (0.141)\tData 0.050 (0.115)\tLoss 0.9500 (0.6942)\tAcc 0.500 (0.719)\n",
      "Epoch: [150][3/9]\tTime 0.067 (0.116)\tData 0.047 (0.092)\tLoss 0.6289 (0.6725)\tAcc 0.688 (0.708)\n",
      "Epoch: [150][4/9]\tTime 0.073 (0.105)\tData 0.053 (0.083)\tLoss 0.6021 (0.6549)\tAcc 0.688 (0.703)\n",
      "Epoch: [150][5/9]\tTime 0.073 (0.099)\tData 0.054 (0.077)\tLoss 0.8156 (0.6870)\tAcc 0.750 (0.713)\n",
      "Epoch: [150][6/9]\tTime 0.073 (0.095)\tData 0.054 (0.073)\tLoss 0.2913 (0.6211)\tAcc 1.000 (0.760)\n",
      "Epoch: [150][7/9]\tTime 0.073 (0.092)\tData 0.054 (0.070)\tLoss 0.6509 (0.6253)\tAcc 0.688 (0.750)\n",
      "Epoch: [150][8/9]\tTime 0.074 (0.089)\tData 0.054 (0.068)\tLoss 0.8953 (0.6591)\tAcc 0.625 (0.734)\n",
      "Epoch: [150][9/9]\tTime 0.073 (0.088)\tData 0.055 (0.067)\tLoss 0.5313 (0.6571)\tAcc 1.000 (0.738)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=150\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:48.381087Z",
     "start_time": "2020-05-01T02:22:48.362871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:48.390704Z",
     "start_time": "2020-05-01T02:22:48.382110Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.147534Z",
     "start_time": "2020-05-01T02:22:48.391798Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 76 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.175597Z",
     "start_time": "2020-05-01T02:22:54.148610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 1.760331392288208},\n",
       " {'label': 'none', 'score': 1.760331392288208},\n",
       " {'label': 'none', 'score': 1.760331392288208},\n",
       " {'label': 'none', 'score': 1.9353742599487305},\n",
       " {'label': 'none', 'score': 1.9353742599487305},\n",
       " {'label': 'none', 'score': 1.9353742599487305},\n",
       " {'label': 'none', 'score': 1.5752846002578735},\n",
       " {'label': 'none', 'score': 1.5752846002578735},\n",
       " {'label': 'none', 'score': 1.5752846002578735},\n",
       " {'label': 'none', 'score': 1.5388823747634888},\n",
       " {'label': 'none', 'score': 1.5388823747634888},\n",
       " {'label': 'none', 'score': 1.5388823747634888},\n",
       " {'label': 'none', 'score': 2.095703601837158},\n",
       " {'label': 'none', 'score': 2.095703601837158},\n",
       " {'label': 'none', 'score': 2.095703601837158},\n",
       " {'label': 'none', 'score': 1.656265377998352},\n",
       " {'label': 'none', 'score': 1.656265377998352},\n",
       " {'label': 'none', 'score': 1.656265377998352},\n",
       " {'label': 'none', 'score': 2.1404428482055664},\n",
       " {'label': 'none', 'score': 2.1404428482055664},\n",
       " {'label': 'none', 'score': 2.1404428482055664},\n",
       " {'label': 'none', 'score': 1.9602677822113037},\n",
       " {'label': 'none', 'score': 1.9602677822113037},\n",
       " {'label': 'none', 'score': 1.9602677822113037},\n",
       " {'label': 'none', 'score': 2.141141891479492},\n",
       " {'label': 'none', 'score': 2.141141891479492},\n",
       " {'label': 'none', 'score': 2.141141891479492},\n",
       " {'label': 'none', 'score': 1.437898874282837},\n",
       " {'label': 'none', 'score': 1.437898874282837},\n",
       " {'label': 'none', 'score': 1.437898874282837},\n",
       " {'label': 'none', 'score': 1.3405961990356445},\n",
       " {'label': 'none', 'score': 1.3405961990356445},\n",
       " {'label': 'none', 'score': 1.3405961990356445},\n",
       " {'label': 'none', 'score': 1.8657317161560059},\n",
       " {'label': 'none', 'score': 1.8657317161560059},\n",
       " {'label': 'none', 'score': 1.8657317161560059},\n",
       " {'label': 'none', 'score': 2.0178399085998535},\n",
       " {'label': 'none', 'score': 2.0178399085998535},\n",
       " {'label': 'none', 'score': 2.0178399085998535},\n",
       " {'label': 'none', 'score': 1.6972051858901978},\n",
       " {'label': 'none', 'score': 1.6972051858901978},\n",
       " {'label': 'none', 'score': 1.6972051858901978},\n",
       " {'label': 'none', 'score': 2.020050525665283},\n",
       " {'label': 'none', 'score': 2.020050525665283},\n",
       " {'label': 'none', 'score': 2.020050525665283},\n",
       " {'label': 'none', 'score': 1.3521544933319092},\n",
       " {'label': 'none', 'score': 1.3521544933319092},\n",
       " {'label': 'none', 'score': 1.3521544933319092},\n",
       " {'label': 'none', 'score': 1.820921778678894},\n",
       " {'label': 'none', 'score': 1.820921778678894},\n",
       " {'label': 'none', 'score': 1.820921778678894},\n",
       " {'label': 'none', 'score': 1.963651180267334},\n",
       " {'label': 'none', 'score': 1.963651180267334},\n",
       " {'label': 'none', 'score': 1.963651180267334},\n",
       " {'label': 'none', 'score': 1.697060465812683},\n",
       " {'label': 'none', 'score': 1.697060465812683},\n",
       " {'label': 'none', 'score': 1.697060465812683},\n",
       " {'label': 'none', 'score': 2.0179941654205322},\n",
       " {'label': 'none', 'score': 2.0179941654205322},\n",
       " {'label': 'none', 'score': 2.0179941654205322},\n",
       " {'label': 'none', 'score': 1.611783742904663},\n",
       " {'label': 'none', 'score': 1.611783742904663},\n",
       " {'label': 'none', 'score': 1.611783742904663},\n",
       " {'label': 'none', 'score': 1.6840240955352783},\n",
       " {'label': 'none', 'score': 1.6840240955352783},\n",
       " {'label': 'none', 'score': 1.6840240955352783},\n",
       " {'label': 'none', 'score': 1.8814424276351929},\n",
       " {'label': 'none', 'score': 1.8814424276351929},\n",
       " {'label': 'none', 'score': 1.8814424276351929},\n",
       " {'label': 'returning', 'score': 0.7203042507171631},\n",
       " {'label': 'returning', 'score': 0.7203042507171631},\n",
       " {'label': 'returning', 'score': 0.7203042507171631},\n",
       " {'label': 'none', 'score': 0.45964741706848145},\n",
       " {'label': 'none', 'score': 0.45964741706848145},\n",
       " {'label': 'none', 'score': 0.45964741706848145},\n",
       " {'label': 'leaving', 'score': 0.4141997694969177},\n",
       " {'label': 'leaving', 'score': 0.4141997694969177},\n",
       " {'label': 'leaving', 'score': 0.4141997694969177},\n",
       " {'label': 'leaving', 'score': 0.740119218826294},\n",
       " {'label': 'leaving', 'score': 0.740119218826294},\n",
       " {'label': 'leaving', 'score': 0.740119218826294},\n",
       " {'label': 'returning', 'score': 1.0820882320404053},\n",
       " {'label': 'returning', 'score': 1.0820882320404053},\n",
       " {'label': 'returning', 'score': 1.0820882320404053},\n",
       " {'label': 'returning', 'score': 0.2185150682926178},\n",
       " {'label': 'returning', 'score': 0.2185150682926178},\n",
       " {'label': 'returning', 'score': 0.2185150682926178},\n",
       " {'label': 'returning', 'score': 0.5795515775680542},\n",
       " {'label': 'returning', 'score': 0.5795515775680542},\n",
       " {'label': 'returning', 'score': 0.5795515775680542},\n",
       " {'label': 'returning', 'score': 1.0006474256515503},\n",
       " {'label': 'returning', 'score': 1.0006474256515503},\n",
       " {'label': 'returning', 'score': 1.0006474256515503},\n",
       " {'label': 'none', 'score': 0.47482413053512573},\n",
       " {'label': 'none', 'score': 0.47482413053512573},\n",
       " {'label': 'none', 'score': 0.47482413053512573},\n",
       " {'label': 'returning', 'score': 0.4598276913166046},\n",
       " {'label': 'returning', 'score': 0.4598276913166046},\n",
       " {'label': 'returning', 'score': 0.4598276913166046},\n",
       " {'label': 'none', 'score': 0.9817432165145874},\n",
       " {'label': 'none', 'score': 0.9817432165145874},\n",
       " {'label': 'none', 'score': 0.9817432165145874},\n",
       " {'label': 'none', 'score': 1.4020359516143799},\n",
       " {'label': 'none', 'score': 1.4020359516143799},\n",
       " {'label': 'none', 'score': 1.4020359516143799},\n",
       " {'label': 'none', 'score': 1.9807087182998657},\n",
       " {'label': 'none', 'score': 1.9807087182998657},\n",
       " {'label': 'none', 'score': 1.9807087182998657},\n",
       " {'label': 'none', 'score': 1.7175071239471436},\n",
       " {'label': 'none', 'score': 1.7175071239471436},\n",
       " {'label': 'none', 'score': 1.7175071239471436},\n",
       " {'label': 'none', 'score': 1.9226881265640259},\n",
       " {'label': 'none', 'score': 1.9226881265640259},\n",
       " {'label': 'none', 'score': 1.9226881265640259},\n",
       " {'label': 'none', 'score': 1.7258100509643555},\n",
       " {'label': 'none', 'score': 1.7258100509643555},\n",
       " {'label': 'none', 'score': 1.7258100509643555},\n",
       " {'label': 'none', 'score': 1.1785261631011963},\n",
       " {'label': 'none', 'score': 1.1785261631011963},\n",
       " {'label': 'none', 'score': 1.1785261631011963},\n",
       " {'label': 'none', 'score': 1.6633299589157104},\n",
       " {'label': 'none', 'score': 1.6633299589157104},\n",
       " {'label': 'none', 'score': 1.6633299589157104},\n",
       " {'label': 'none', 'score': 1.6166388988494873},\n",
       " {'label': 'none', 'score': 1.6166388988494873},\n",
       " {'label': 'none', 'score': 1.6166388988494873},\n",
       " {'label': 'none', 'score': 1.6609658002853394},\n",
       " {'label': 'none', 'score': 1.6609658002853394},\n",
       " {'label': 'none', 'score': 1.6609658002853394},\n",
       " {'label': 'none', 'score': 1.4309003353118896},\n",
       " {'label': 'none', 'score': 1.4309003353118896},\n",
       " {'label': 'none', 'score': 1.4309003353118896},\n",
       " {'label': 'none', 'score': 1.180577278137207},\n",
       " {'label': 'none', 'score': 1.180577278137207},\n",
       " {'label': 'none', 'score': 1.180577278137207},\n",
       " {'label': 'none', 'score': 1.9082844257354736},\n",
       " {'label': 'none', 'score': 1.9082844257354736},\n",
       " {'label': 'none', 'score': 1.9082844257354736},\n",
       " {'label': 'none', 'score': 1.7944937944412231},\n",
       " {'label': 'none', 'score': 1.7944937944412231},\n",
       " {'label': 'none', 'score': 1.7944937944412231},\n",
       " {'label': 'none', 'score': 1.3379634618759155},\n",
       " {'label': 'none', 'score': 1.3379634618759155},\n",
       " {'label': 'none', 'score': 1.3379634618759155},\n",
       " {'label': 'none', 'score': 1.9776313304901123},\n",
       " {'label': 'none', 'score': 1.9776313304901123},\n",
       " {'label': 'none', 'score': 1.9776313304901123},\n",
       " {'label': 'none', 'score': 1.537513256072998},\n",
       " {'label': 'none', 'score': 1.537513256072998},\n",
       " {'label': 'none', 'score': 1.537513256072998},\n",
       " {'label': 'returning', 'score': 1.511371374130249},\n",
       " {'label': 'returning', 'score': 1.511371374130249},\n",
       " {'label': 'returning', 'score': 1.511371374130249},\n",
       " {'label': 'returning', 'score': 0.5774815082550049},\n",
       " {'label': 'returning', 'score': 0.5774815082550049},\n",
       " {'label': 'returning', 'score': 0.5774815082550049},\n",
       " {'label': 'returning', 'score': 0.5352646708488464},\n",
       " {'label': 'returning', 'score': 0.5352646708488464},\n",
       " {'label': 'returning', 'score': 0.5352646708488464},\n",
       " {'label': 'returning', 'score': 0.4193555414676666},\n",
       " {'label': 'returning', 'score': 0.4193555414676666},\n",
       " {'label': 'returning', 'score': 0.4193555414676666},\n",
       " {'label': 'returning', 'score': 0.5615861415863037},\n",
       " {'label': 'returning', 'score': 0.5615861415863037},\n",
       " {'label': 'returning', 'score': 0.5615861415863037},\n",
       " {'label': 'returning', 'score': 0.6310316324234009},\n",
       " {'label': 'returning', 'score': 0.6310316324234009},\n",
       " {'label': 'returning', 'score': 0.6310316324234009},\n",
       " {'label': 'returning', 'score': 0.4118812382221222},\n",
       " {'label': 'returning', 'score': 0.4118812382221222},\n",
       " {'label': 'returning', 'score': 0.4118812382221222},\n",
       " {'label': 'returning', 'score': 0.2993433475494385},\n",
       " {'label': 'returning', 'score': 0.2993433475494385},\n",
       " {'label': 'returning', 'score': 0.2993433475494385},\n",
       " {'label': 'returning', 'score': 0.5692727565765381},\n",
       " {'label': 'returning', 'score': 0.5692727565765381},\n",
       " {'label': 'returning', 'score': 0.5692727565765381},\n",
       " {'label': 'returning', 'score': 0.9449959993362427},\n",
       " {'label': 'returning', 'score': 0.9449959993362427},\n",
       " {'label': 'returning', 'score': 0.9449959993362427},\n",
       " {'label': 'none', 'score': 1.5036801099777222},\n",
       " {'label': 'none', 'score': 1.5036801099777222},\n",
       " {'label': 'none', 'score': 1.5036801099777222},\n",
       " {'label': 'none', 'score': 1.5670735836029053},\n",
       " {'label': 'none', 'score': 1.5670735836029053},\n",
       " {'label': 'none', 'score': 1.5670735836029053},\n",
       " {'label': 'none', 'score': 2.415526866912842},\n",
       " {'label': 'none', 'score': 2.415526866912842},\n",
       " {'label': 'none', 'score': 2.415526866912842},\n",
       " {'label': 'none', 'score': 1.467975378036499},\n",
       " {'label': 'none', 'score': 1.467975378036499},\n",
       " {'label': 'none', 'score': 1.467975378036499},\n",
       " {'label': 'none', 'score': 1.3375184535980225},\n",
       " {'label': 'none', 'score': 1.3375184535980225},\n",
       " {'label': 'none', 'score': 1.3375184535980225},\n",
       " {'label': 'none', 'score': 2.109360694885254},\n",
       " {'label': 'none', 'score': 2.109360694885254},\n",
       " {'label': 'none', 'score': 2.109360694885254},\n",
       " {'label': 'none', 'score': 1.7433820962905884},\n",
       " {'label': 'none', 'score': 1.7433820962905884},\n",
       " {'label': 'none', 'score': 1.7433820962905884},\n",
       " {'label': 'none', 'score': 1.3524168729782104},\n",
       " {'label': 'none', 'score': 1.3524168729782104},\n",
       " {'label': 'none', 'score': 1.3524168729782104},\n",
       " {'label': 'none', 'score': 2.2375288009643555},\n",
       " {'label': 'none', 'score': 2.2375288009643555},\n",
       " {'label': 'none', 'score': 2.2375288009643555},\n",
       " {'label': 'none', 'score': 1.8148176670074463},\n",
       " {'label': 'none', 'score': 1.8148176670074463},\n",
       " {'label': 'none', 'score': 1.8148176670074463},\n",
       " {'label': 'none', 'score': 1.852025032043457},\n",
       " {'label': 'none', 'score': 1.852025032043457},\n",
       " {'label': 'none', 'score': 1.852025032043457},\n",
       " {'label': 'none', 'score': 1.4582197666168213},\n",
       " {'label': 'none', 'score': 1.4582197666168213},\n",
       " {'label': 'none', 'score': 1.4582197666168213},\n",
       " {'label': 'none', 'score': 1.82668936252594},\n",
       " {'label': 'none', 'score': 1.82668936252594},\n",
       " {'label': 'none', 'score': 1.82668936252594},\n",
       " {'label': 'none', 'score': 2.0040242671966553},\n",
       " {'label': 'none', 'score': 2.0040242671966553},\n",
       " {'label': 'none', 'score': 2.0040242671966553},\n",
       " {'label': 'none', 'score': 1.8367490768432617},\n",
       " {'label': 'none', 'score': 1.8367490768432617},\n",
       " {'label': 'none', 'score': 1.8367490768432617},\n",
       " {'label': 'none', 'score': 2.0881595611572266},\n",
       " {'label': 'none', 'score': 2.0881595611572266},\n",
       " {'label': 'none', 'score': 2.0881595611572266},\n",
       " {'label': 'none', 'score': 1.6745554208755493},\n",
       " {'label': 'none', 'score': 1.6745554208755493},\n",
       " {'label': 'none', 'score': 1.6745554208755493},\n",
       " {'label': 'none', 'score': 1.5219695568084717},\n",
       " {'label': 'none', 'score': 1.5219695568084717},\n",
       " {'label': 'none', 'score': 1.5219695568084717},\n",
       " {'label': 'none', 'score': 1.6281267404556274},\n",
       " {'label': 'none', 'score': 1.6281267404556274},\n",
       " {'label': 'none', 'score': 1.6281267404556274},\n",
       " {'label': 'none', 'score': 1.6263424158096313},\n",
       " {'label': 'none', 'score': 1.6263424158096313},\n",
       " {'label': 'none', 'score': 1.6263424158096313},\n",
       " {'label': 'none', 'score': 1.7270528078079224},\n",
       " {'label': 'none', 'score': 1.7270528078079224},\n",
       " {'label': 'none', 'score': 1.7270528078079224},\n",
       " {'label': 'returning', 'score': 1.030167579650879},\n",
       " {'label': 'returning', 'score': 1.030167579650879},\n",
       " {'label': 'returning', 'score': 1.030167579650879},\n",
       " {'label': 'returning', 'score': 0.3416459262371063},\n",
       " {'label': 'returning', 'score': 0.3416459262371063},\n",
       " {'label': 'returning', 'score': 0.3416459262371063},\n",
       " {'label': 'returning', 'score': 0.4785431921482086},\n",
       " {'label': 'returning', 'score': 0.4785431921482086},\n",
       " {'label': 'returning', 'score': 0.4785431921482086},\n",
       " {'label': 'leaving', 'score': 0.6481753587722778},\n",
       " {'label': 'leaving', 'score': 0.6481753587722778},\n",
       " {'label': 'leaving', 'score': 0.6481753587722778},\n",
       " {'label': 'returning', 'score': 0.457662969827652},\n",
       " {'label': 'returning', 'score': 0.457662969827652},\n",
       " {'label': 'returning', 'score': 0.457662969827652},\n",
       " {'label': 'returning', 'score': 0.4797774851322174},\n",
       " {'label': 'returning', 'score': 0.4797774851322174},\n",
       " {'label': 'returning', 'score': 0.4797774851322174},\n",
       " {'label': 'returning', 'score': 0.8752714991569519},\n",
       " {'label': 'returning', 'score': 0.8752714991569519},\n",
       " {'label': 'returning', 'score': 0.8752714991569519},\n",
       " {'label': 'returning', 'score': 0.30497831106185913},\n",
       " {'label': 'returning', 'score': 0.30497831106185913},\n",
       " {'label': 'returning', 'score': 0.30497831106185913},\n",
       " {'label': 'returning', 'score': 0.3350811004638672},\n",
       " {'label': 'returning', 'score': 0.3350811004638672},\n",
       " {'label': 'returning', 'score': 0.3350811004638672},\n",
       " {'label': 'none', 'score': 1.5701369047164917},\n",
       " {'label': 'none', 'score': 1.5701369047164917},\n",
       " {'label': 'none', 'score': 1.5701369047164917},\n",
       " {'label': 'none', 'score': 2.1832895278930664},\n",
       " {'label': 'none', 'score': 2.1832895278930664},\n",
       " {'label': 'none', 'score': 2.1832895278930664},\n",
       " {'label': 'none', 'score': 1.2484829425811768},\n",
       " {'label': 'none', 'score': 1.2484829425811768},\n",
       " {'label': 'none', 'score': 1.2484829425811768},\n",
       " {'label': 'none', 'score': 1.6483489274978638},\n",
       " {'label': 'none', 'score': 1.6483489274978638},\n",
       " {'label': 'none', 'score': 1.6483489274978638},\n",
       " {'label': 'none', 'score': 1.5810925960540771},\n",
       " {'label': 'none', 'score': 1.5810925960540771},\n",
       " {'label': 'none', 'score': 1.5810925960540771},\n",
       " {'label': 'none', 'score': 1.492997407913208},\n",
       " {'label': 'none', 'score': 1.492997407913208},\n",
       " {'label': 'none', 'score': 1.492997407913208},\n",
       " {'label': 'none', 'score': 1.4636740684509277},\n",
       " {'label': 'none', 'score': 1.4636740684509277},\n",
       " {'label': 'none', 'score': 1.4636740684509277},\n",
       " {'label': 'none', 'score': 1.6389925479888916},\n",
       " {'label': 'none', 'score': 1.6389925479888916},\n",
       " {'label': 'none', 'score': 1.6389925479888916},\n",
       " {'label': 'none', 'score': 1.6450297832489014},\n",
       " {'label': 'none', 'score': 1.6450297832489014},\n",
       " {'label': 'none', 'score': 1.6450297832489014},\n",
       " {'label': 'none', 'score': 1.2732423543930054},\n",
       " {'label': 'none', 'score': 1.2732423543930054},\n",
       " {'label': 'none', 'score': 1.2732423543930054},\n",
       " {'label': 'none', 'score': 1.8980683088302612},\n",
       " {'label': 'none', 'score': 1.8980683088302612},\n",
       " {'label': 'none', 'score': 1.8980683088302612},\n",
       " {'label': 'none', 'score': 1.5935301780700684},\n",
       " {'label': 'none', 'score': 1.5935301780700684},\n",
       " {'label': 'none', 'score': 1.5935301780700684},\n",
       " {'label': 'none', 'score': 2.3360447883605957},\n",
       " {'label': 'none', 'score': 2.3360447883605957},\n",
       " {'label': 'none', 'score': 2.3360447883605957},\n",
       " {'label': 'none', 'score': 1.9610158205032349},\n",
       " {'label': 'none', 'score': 1.9610158205032349},\n",
       " {'label': 'none', 'score': 1.9610158205032349},\n",
       " {'label': 'none', 'score': 1.5951151847839355},\n",
       " {'label': 'none', 'score': 1.5951151847839355},\n",
       " {'label': 'none', 'score': 1.5951151847839355},\n",
       " {'label': 'none', 'score': 1.6013448238372803},\n",
       " {'label': 'none', 'score': 1.6013448238372803},\n",
       " {'label': 'none', 'score': 1.6013448238372803},\n",
       " {'label': 'none', 'score': 1.5783733129501343},\n",
       " {'label': 'none', 'score': 1.5783733129501343},\n",
       " {'label': 'none', 'score': 1.5783733129501343},\n",
       " {'label': 'none', 'score': 2.0936784744262695},\n",
       " {'label': 'none', 'score': 2.0936784744262695},\n",
       " {'label': 'none', 'score': 2.0936784744262695},\n",
       " {'label': 'returning', 'score': 0.29662320017814636},\n",
       " {'label': 'returning', 'score': 0.29662320017814636},\n",
       " {'label': 'returning', 'score': 0.29662320017814636},\n",
       " {'label': 'returning', 'score': 0.7293719053268433},\n",
       " {'label': 'returning', 'score': 0.7293719053268433},\n",
       " {'label': 'returning', 'score': 0.7293719053268433},\n",
       " {'label': 'returning', 'score': 0.6938649415969849},\n",
       " {'label': 'returning', 'score': 0.6938649415969849},\n",
       " {'label': 'returning', 'score': 0.6938649415969849},\n",
       " {'label': 'returning', 'score': 0.6807557344436646},\n",
       " {'label': 'returning', 'score': 0.6807557344436646},\n",
       " {'label': 'returning', 'score': 0.6807557344436646},\n",
       " {'label': 'returning', 'score': 0.6722597479820251},\n",
       " {'label': 'returning', 'score': 0.6722597479820251},\n",
       " {'label': 'returning', 'score': 0.6722597479820251},\n",
       " {'label': 'returning', 'score': 0.45131853222846985},\n",
       " {'label': 'returning', 'score': 0.45131853222846985},\n",
       " {'label': 'returning', 'score': 0.45131853222846985},\n",
       " {'label': 'returning', 'score': 0.35574471950531006},\n",
       " {'label': 'returning', 'score': 0.35574471950531006},\n",
       " {'label': 'returning', 'score': 0.35574471950531006},\n",
       " {'label': 'returning', 'score': 0.837631344795227},\n",
       " {'label': 'returning', 'score': 0.837631344795227},\n",
       " {'label': 'returning', 'score': 0.837631344795227},\n",
       " {'label': 'none', 'score': 1.5960725545883179},\n",
       " {'label': 'none', 'score': 1.5960725545883179},\n",
       " {'label': 'none', 'score': 1.5960725545883179},\n",
       " {'label': 'none', 'score': 2.1266133785247803},\n",
       " {'label': 'none', 'score': 2.1266133785247803},\n",
       " {'label': 'none', 'score': 2.1266133785247803},\n",
       " {'label': 'none', 'score': 1.9376322031021118},\n",
       " {'label': 'none', 'score': 1.9376322031021118},\n",
       " {'label': 'none', 'score': 1.9376322031021118},\n",
       " {'label': 'none', 'score': 2.3907251358032227},\n",
       " {'label': 'none', 'score': 2.3907251358032227},\n",
       " {'label': 'none', 'score': 2.3907251358032227},\n",
       " {'label': 'none', 'score': 1.1870930194854736},\n",
       " {'label': 'none', 'score': 1.1870930194854736},\n",
       " {'label': 'none', 'score': 1.1870930194854736},\n",
       " {'label': 'none', 'score': 2.409580707550049},\n",
       " {'label': 'none', 'score': 2.409580707550049},\n",
       " {'label': 'none', 'score': 2.409580707550049},\n",
       " {'label': 'none', 'score': 1.7995516061782837},\n",
       " {'label': 'none', 'score': 1.7995516061782837},\n",
       " {'label': 'none', 'score': 1.7995516061782837},\n",
       " {'label': 'none', 'score': 1.651576042175293},\n",
       " {'label': 'none', 'score': 1.651576042175293},\n",
       " {'label': 'none', 'score': 1.651576042175293},\n",
       " {'label': 'none', 'score': 1.6012375354766846},\n",
       " {'label': 'none', 'score': 1.6012375354766846},\n",
       " {'label': 'none', 'score': 1.6012375354766846},\n",
       " {'label': 'none', 'score': 1.629172682762146},\n",
       " {'label': 'none', 'score': 1.629172682762146},\n",
       " {'label': 'none', 'score': 1.629172682762146},\n",
       " {'label': 'none', 'score': 1.9158424139022827},\n",
       " {'label': 'none', 'score': 1.9158424139022827},\n",
       " {'label': 'none', 'score': 1.9158424139022827},\n",
       " {'label': 'none', 'score': 1.818000078201294},\n",
       " {'label': 'none', 'score': 1.818000078201294},\n",
       " {'label': 'none', 'score': 1.818000078201294},\n",
       " {'label': 'none', 'score': 2.0046114921569824},\n",
       " {'label': 'none', 'score': 2.0046114921569824},\n",
       " {'label': 'none', 'score': 2.0046114921569824},\n",
       " {'label': 'none', 'score': 1.7802529335021973},\n",
       " {'label': 'none', 'score': 1.7802529335021973},\n",
       " {'label': 'none', 'score': 1.7802529335021973},\n",
       " {'label': 'none', 'score': 1.8960884809494019},\n",
       " {'label': 'none', 'score': 1.8960884809494019},\n",
       " {'label': 'none', 'score': 1.8960884809494019},\n",
       " {'label': 'none', 'score': 1.5059058666229248},\n",
       " {'label': 'none', 'score': 1.5059058666229248},\n",
       " {'label': 'none', 'score': 1.5059058666229248},\n",
       " {'label': 'none', 'score': 1.4842808246612549},\n",
       " {'label': 'none', 'score': 1.4842808246612549},\n",
       " {'label': 'none', 'score': 1.4842808246612549},\n",
       " {'label': 'none', 'score': 2.190859794616699},\n",
       " {'label': 'none', 'score': 2.190859794616699},\n",
       " {'label': 'none', 'score': 2.190859794616699},\n",
       " {'label': 'none', 'score': 0.9384045600891113},\n",
       " {'label': 'none', 'score': 0.9384045600891113},\n",
       " {'label': 'none', 'score': 0.9384045600891113},\n",
       " {'label': 'none', 'score': 1.4331494569778442},\n",
       " {'label': 'none', 'score': 1.4331494569778442},\n",
       " {'label': 'none', 'score': 1.4331494569778442},\n",
       " {'label': 'none', 'score': 1.193021297454834},\n",
       " {'label': 'none', 'score': 1.193021297454834},\n",
       " {'label': 'none', 'score': 1.193021297454834},\n",
       " {'label': 'none', 'score': 1.2743607759475708},\n",
       " {'label': 'none', 'score': 1.2743607759475708},\n",
       " {'label': 'none', 'score': 1.2743607759475708},\n",
       " {'label': 'none', 'score': 1.2312260866165161},\n",
       " {'label': 'none', 'score': 1.2312260866165161},\n",
       " {'label': 'none', 'score': 1.2312260866165161},\n",
       " {'label': 'none', 'score': 1.6502574682235718},\n",
       " {'label': 'none', 'score': 1.6502574682235718},\n",
       " {'label': 'none', 'score': 1.6502574682235718},\n",
       " {'label': 'none', 'score': 1.5449858903884888},\n",
       " {'label': 'none', 'score': 1.5449858903884888},\n",
       " {'label': 'none', 'score': 1.5449858903884888},\n",
       " {'label': 'none', 'score': 1.8331691026687622},\n",
       " {'label': 'none', 'score': 1.8331691026687622},\n",
       " {'label': 'none', 'score': 1.8331691026687622},\n",
       " {'label': 'none', 'score': 1.6529474258422852},\n",
       " {'label': 'none', 'score': 1.6529474258422852},\n",
       " {'label': 'none', 'score': 1.6529474258422852},\n",
       " {'label': 'none', 'score': 1.3055051565170288},\n",
       " {'label': 'none', 'score': 1.3055051565170288},\n",
       " {'label': 'none', 'score': 1.3055051565170288},\n",
       " {'label': 'none', 'score': 1.9978833198547363},\n",
       " {'label': 'none', 'score': 1.9978833198547363},\n",
       " {'label': 'none', 'score': 1.9978833198547363},\n",
       " {'label': 'returning', 'score': 1.6049188375473022},\n",
       " {'label': 'returning', 'score': 1.6049188375473022},\n",
       " {'label': 'returning', 'score': 1.6049188375473022},\n",
       " {'label': 'returning', 'score': 0.5779063701629639},\n",
       " {'label': 'returning', 'score': 0.5779063701629639},\n",
       " {'label': 'returning', 'score': 0.5779063701629639},\n",
       " {'label': 'none', 'score': 0.6177223324775696},\n",
       " {'label': 'none', 'score': 0.6177223324775696},\n",
       " {'label': 'none', 'score': 0.6177223324775696},\n",
       " {'label': 'returning', 'score': 0.31869569420814514},\n",
       " {'label': 'returning', 'score': 0.31869569420814514},\n",
       " {'label': 'returning', 'score': 0.31869569420814514},\n",
       " {'label': 'returning', 'score': 1.1951751708984375},\n",
       " {'label': 'returning', 'score': 1.1951751708984375},\n",
       " {'label': 'returning', 'score': 1.1951751708984375},\n",
       " {'label': 'none', 'score': 1.5921522378921509},\n",
       " {'label': 'none', 'score': 1.5921522378921509},\n",
       " {'label': 'none', 'score': 1.5921522378921509},\n",
       " {'label': 'none', 'score': 1.1083555221557617},\n",
       " {'label': 'none', 'score': 1.1083555221557617},\n",
       " {'label': 'none', 'score': 1.1083555221557617},\n",
       " {'label': 'none', 'score': 1.6672009229660034},\n",
       " {'label': 'none', 'score': 1.6672009229660034},\n",
       " {'label': 'none', 'score': 1.6672009229660034},\n",
       " {'label': 'none', 'score': 1.6200987100601196},\n",
       " {'label': 'none', 'score': 1.6200987100601196},\n",
       " {'label': 'none', 'score': 1.6200987100601196},\n",
       " {'label': 'none', 'score': 1.5939610004425049},\n",
       " {'label': 'none', 'score': 1.5939610004425049},\n",
       " {'label': 'none', 'score': 1.5939610004425049},\n",
       " {'label': 'none', 'score': 1.6365243196487427},\n",
       " {'label': 'none', 'score': 1.6365243196487427},\n",
       " {'label': 'none', 'score': 1.6365243196487427},\n",
       " {'label': 'none', 'score': 1.9486669301986694},\n",
       " {'label': 'none', 'score': 1.9486669301986694},\n",
       " {'label': 'none', 'score': 1.9486669301986694},\n",
       " {'label': 'none', 'score': 1.3163108825683594},\n",
       " {'label': 'none', 'score': 1.3163108825683594},\n",
       " {'label': 'none', 'score': 1.3163108825683594},\n",
       " {'label': 'none', 'score': 2.0834579467773438},\n",
       " {'label': 'none', 'score': 2.0834579467773438},\n",
       " {'label': 'none', 'score': 2.0834579467773438},\n",
       " {'label': 'none', 'score': 1.8353474140167236},\n",
       " {'label': 'none', 'score': 1.8353474140167236},\n",
       " {'label': 'none', 'score': 1.8353474140167236},\n",
       " {'label': 'none', 'score': 2.381096363067627},\n",
       " {'label': 'none', 'score': 2.381096363067627},\n",
       " {'label': 'none', 'score': 2.381096363067627},\n",
       " {'label': 'none', 'score': 1.0997166633605957},\n",
       " {'label': 'none', 'score': 1.0997166633605957},\n",
       " {'label': 'none', 'score': 1.0997166633605957},\n",
       " {'label': 'returning', 'score': 0.7194594740867615},\n",
       " {'label': 'returning', 'score': 0.7194594740867615},\n",
       " {'label': 'returning', 'score': 0.7194594740867615},\n",
       " {'label': 'returning', 'score': 0.8550159931182861},\n",
       " {'label': 'returning', 'score': 0.8550159931182861},\n",
       " {'label': 'returning', 'score': 0.8550159931182861},\n",
       " {'label': 'returning', 'score': 0.3261886239051819},\n",
       " {'label': 'returning', 'score': 0.3261886239051819},\n",
       " {'label': 'returning', 'score': 0.3261886239051819},\n",
       " {'label': 'returning', 'score': 0.2930924892425537},\n",
       " {'label': 'returning', 'score': 0.2930924892425537},\n",
       " {'label': 'returning', 'score': 0.2930924892425537},\n",
       " {'label': 'returning', 'score': 0.6658145785331726},\n",
       " {'label': 'returning', 'score': 0.6658145785331726},\n",
       " {'label': 'returning', 'score': 0.6658145785331726},\n",
       " {'label': 'returning', 'score': 1.1097196340560913},\n",
       " {'label': 'returning', 'score': 1.1097196340560913},\n",
       " {'label': 'returning', 'score': 1.1097196340560913},\n",
       " {'label': 'returning', 'score': 0.5441551208496094},\n",
       " {'label': 'returning', 'score': 0.5441551208496094},\n",
       " {'label': 'returning', 'score': 0.5441551208496094},\n",
       " {'label': 'returning', 'score': 0.36025410890579224},\n",
       " {'label': 'returning', 'score': 0.36025410890579224},\n",
       " {'label': 'returning', 'score': 0.36025410890579224},\n",
       " {'label': 'none', 'score': 1.367663860321045},\n",
       " {'label': 'none', 'score': 1.367663860321045},\n",
       " {'label': 'none', 'score': 1.367663860321045},\n",
       " {'label': 'none', 'score': 1.6598832607269287},\n",
       " {'label': 'none', 'score': 1.6598832607269287},\n",
       " {'label': 'none', 'score': 1.6598832607269287},\n",
       " {'label': 'none', 'score': 1.2819803953170776},\n",
       " {'label': 'none', 'score': 1.2819803953170776},\n",
       " {'label': 'none', 'score': 1.2819803953170776},\n",
       " {'label': 'none', 'score': 1.4067046642303467},\n",
       " {'label': 'none', 'score': 1.4067046642303467},\n",
       " {'label': 'none', 'score': 1.4067046642303467},\n",
       " {'label': 'none', 'score': 1.7103533744812012},\n",
       " {'label': 'none', 'score': 1.7103533744812012},\n",
       " {'label': 'none', 'score': 1.7103533744812012},\n",
       " {'label': 'none', 'score': 1.4474616050720215},\n",
       " {'label': 'none', 'score': 1.4474616050720215},\n",
       " {'label': 'none', 'score': 1.4474616050720215},\n",
       " {'label': 'none', 'score': 1.5205597877502441},\n",
       " {'label': 'none', 'score': 1.5205597877502441},\n",
       " {'label': 'none', 'score': 1.5205597877502441},\n",
       " {'label': 'none', 'score': 1.922952651977539},\n",
       " {'label': 'none', 'score': 1.922952651977539},\n",
       " {'label': 'none', 'score': 1.922952651977539},\n",
       " {'label': 'none', 'score': 1.5224436521530151},\n",
       " {'label': 'none', 'score': 1.5224436521530151},\n",
       " {'label': 'none', 'score': 1.5224436521530151},\n",
       " {'label': 'none', 'score': 1.2639682292938232},\n",
       " {'label': 'none', 'score': 1.2639682292938232},\n",
       " {'label': 'none', 'score': 1.2639682292938232},\n",
       " {'label': 'none', 'score': 1.4764708280563354},\n",
       " {'label': 'none', 'score': 1.4764708280563354},\n",
       " {'label': 'none', 'score': 1.4764708280563354},\n",
       " {'label': 'returning', 'score': 0.7424981594085693},\n",
       " {'label': 'returning', 'score': 0.7424981594085693},\n",
       " {'label': 'returning', 'score': 0.7424981594085693},\n",
       " {'label': 'returning', 'score': 0.5594830513000488},\n",
       " {'label': 'returning', 'score': 0.5594830513000488},\n",
       " {'label': 'returning', 'score': 0.5594830513000488},\n",
       " {'label': 'returning', 'score': 0.6836078763008118},\n",
       " {'label': 'returning', 'score': 0.6836078763008118},\n",
       " {'label': 'returning', 'score': 0.6836078763008118},\n",
       " {'label': 'returning', 'score': 0.7460224032402039},\n",
       " {'label': 'returning', 'score': 0.7460224032402039},\n",
       " {'label': 'returning', 'score': 0.7460224032402039},\n",
       " {'label': 'returning', 'score': 0.7407013773918152},\n",
       " {'label': 'returning', 'score': 0.7407013773918152},\n",
       " {'label': 'returning', 'score': 0.7407013773918152},\n",
       " {'label': 'returning', 'score': 0.5868018865585327},\n",
       " {'label': 'returning', 'score': 0.5868018865585327},\n",
       " {'label': 'returning', 'score': 0.5868018865585327},\n",
       " {'label': 'returning', 'score': 0.5971434116363525},\n",
       " {'label': 'returning', 'score': 0.5971434116363525},\n",
       " {'label': 'returning', 'score': 0.5971434116363525},\n",
       " {'label': 'returning', 'score': 0.3556470274925232},\n",
       " {'label': 'returning', 'score': 0.3556470274925232},\n",
       " {'label': 'returning', 'score': 0.3556470274925232},\n",
       " {'label': 'leaving', 'score': 1.964470624923706},\n",
       " {'label': 'leaving', 'score': 1.964470624923706},\n",
       " {'label': 'leaving', 'score': 1.964470624923706},\n",
       " {'label': 'none', 'score': 1.5123950242996216},\n",
       " {'label': 'none', 'score': 1.5123950242996216},\n",
       " {'label': 'none', 'score': 1.5123950242996216},\n",
       " {'label': 'none', 'score': 1.287636399269104},\n",
       " {'label': 'none', 'score': 1.287636399269104},\n",
       " {'label': 'none', 'score': 1.287636399269104},\n",
       " {'label': 'none', 'score': 1.6699327230453491},\n",
       " {'label': 'none', 'score': 1.6699327230453491},\n",
       " {'label': 'none', 'score': 1.6699327230453491},\n",
       " {'label': 'none', 'score': 1.2401058673858643},\n",
       " {'label': 'none', 'score': 1.2401058673858643},\n",
       " {'label': 'none', 'score': 1.2401058673858643},\n",
       " {'label': 'none', 'score': 1.6685808897018433},\n",
       " {'label': 'none', 'score': 1.6685808897018433},\n",
       " {'label': 'none', 'score': 1.6685808897018433}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.187641Z",
     "start_time": "2020-05-01T02:22:54.176557Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(results_path,'validation_results.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.197203Z",
     "start_time": "2020-05-01T02:22:54.188684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.373491Z",
     "start_time": "2020-05-01T02:22:54.198190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - ~~More diverse dataset~~ (2020-04-01)\n",
    "    - Hyperparameter tuning (some improvement 2020-04-04)\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T02:22:54.546184Z",
     "start_time": "2020-05-01T02:22:54.374564Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/CSCE636-project-porta/porta.pth')\n",
    "torch.save(my_model, weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
