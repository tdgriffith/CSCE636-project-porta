{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Comment out javascript if jupyter widgets not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.566618Z",
     "start_time": "2020-04-03T01:55:19.558420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.743057Z",
     "start_time": "2020-04-03T01:55:19.567990Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.944293Z",
     "start_time": "2020-04-03T01:55:19.744155Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "Creating data for input to the model is a little tricky. Details in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.953154Z",
     "start_time": "2020-04-03T01:55:19.945337Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/train') #in jpg format, from included script\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json') # in json format, from included script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.964520Z",
     "start_time": "2020-04-03T01:55:19.954195Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dataset_import import get_training_set, get_validation_set, get_test_set\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    \n",
    "input_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.974774Z",
     "start_time": "2020-04-03T01:55:19.966106Z"
    }
   },
   "outputs": [],
   "source": [
    "from spatial_transforms2 import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms2 import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.985475Z",
     "start_time": "2020-04-03T01:55:19.975954Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_value=255 #for rgb data\n",
    "\n",
    "scale_step=0.84089 #for the kinetics dataset\n",
    "scales = [1]\n",
    "n_scales=5\n",
    "for i in range(1, n_scales):\n",
    "    scales.append(scales[-1] * scale_step)\n",
    "    \n",
    "sample_size=112 # default for kinetics\n",
    "sample_duration=4 # my choosen window size\n",
    "norm_method = Normalize([110.636/norm_value, 103.1606/norm_value, 96.29/norm_value], \n",
    "                        [38.756/norm_value, 37.8824/norm_value, 40.03/norm_value]) #per the averages of the dataset\n",
    "crop_method = MultiScaleRandomCrop(scales, sample_size)\n",
    "spatial_transform = Compose([\n",
    "            crop_method,\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(norm_value), norm_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:19.993786Z",
     "start_time": "2020-04-03T01:55:19.986396Z"
    }
   },
   "outputs": [],
   "source": [
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.082759Z",
     "start_time": "2020-04-03T01:55:19.994852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/73]\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_set(input_args, spatial_transform,\n",
    "                                 temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.092706Z",
     "start_time": "2020-04-03T01:55:20.083931Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=16 #32 was too large!\n",
    "n_threads=4\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            training_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=n_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "I have one video for training, another for test, and another for validation. Using the ActivityNet data crawler, these videos are easily transformed into the appropriate format as described in the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.102639Z",
     "start_time": "2020-04-03T01:55:20.093704Z"
    }
   },
   "outputs": [],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val')\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    n_val_samples=5\n",
    "    sample_duration=4\n",
    "    \n",
    "val_args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.114566Z",
     "start_time": "2020-04-03T01:55:20.103715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "validation_data = get_validation_set(\n",
    "    val_args, spatial_transform, temporal_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.124572Z",
     "start_time": "2020-04-03T01:55:20.115830Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model\n",
    "### First, import kinetics pretrained model exactly as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:20.614560Z",
     "start_time": "2020-04-03T01:55:20.125514Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import resnet, pre_act_resnet, wide_resnet, resnext, densenet\n",
    "import torch.nn as nn\n",
    "\n",
    "model = resnext.resnet101(\n",
    "    sample_size=112, #height and width of inputs\n",
    "    sample_duration=4, #temporal, 16!!!\n",
    "    num_classes=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.203705Z",
     "start_time": "2020-04-03T01:55:20.615584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNeXt(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResNeXtBottleneck(\n",
       "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from opts import parse_opts\n",
    "from model import generate_model\n",
    "class Args:\n",
    "    sample_size = 112\n",
    "    sample_duration = 4 #16!!!\n",
    "    n_classes = 400\n",
    "    mode='feature'\n",
    "    model_name='resnext'\n",
    "    model_depth=101\n",
    "    resnet_shortcut='B'\n",
    "    resnext_cardinality=32\n",
    "    no_cuda=False\n",
    "    batch_size=16\n",
    "    n_threads=4\n",
    "\n",
    "opt=Args()\n",
    "model=generate_model(opt)\n",
    "\n",
    "pretrain_path=Path('/media/tris/tris_files/github/csce_courses/video-classification-3d-cnn-pytorch/resnext-101-kinetics.pth')\n",
    "model_data = torch.load(pretrain_path)\n",
    "model.load_state_dict(model_data['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the model correcly imported, add a final layer to reduce the output size to my three desired outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.214348Z",
     "start_time": "2020-04-03T01:55:23.204807Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#     # Replace the last fully-connected layer\n",
    "#     # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(400, 256), #256 is arbitrary\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(256,3),\n",
    "#     nn.LogSoftmax(dim=1))\n",
    "# model.fc.requires_grad=True\n",
    "# model.cuda()\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.239222Z",
     "start_time": "2020-04-03T01:55:23.215558Z"
    }
   },
   "outputs": [],
   "source": [
    "my_module = nn.Sequential(\n",
    "    nn.Linear(2048, 1200), #256 is arbitrary\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1200,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,3))\n",
    "    #nn.Softmax(dim=1))#dim consider putting the softmax back in, unsure of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.256566Z",
     "start_time": "2020-04-03T01:55:23.241078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataParallel(\n",
       "    (module): ResNeXt(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ResNeXtBottleneck(\n",
       "          (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1200, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = nn.Sequential(model, my_module) #combining the pre-trained and new model\n",
    "my_model.cuda() #put it on the gpu\n",
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have the original model, plus a few extra layers to resize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.267651Z",
     "start_time": "2020-04-03T01:55:23.257715Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim# Loss and optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion=criterion.cuda()\n",
    "\n",
    "dampening=0 #0.9\n",
    "optimizer = optim.SGD(\n",
    "            my_model.parameters(),\n",
    "            lr=3e-3,\n",
    "            momentum=0.9,\n",
    "            dampening=dampening,\n",
    "            weight_decay=1e-3, #1e-3 #how important is this if I'm only training the last few layers? Set to 0?\n",
    "            nesterov=False)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', patience=10)\n",
    "# Definatley need some tuning here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:55:23.278102Z",
     "start_time": "2020-04-03T01:55:23.268569Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "import os\n",
    "results_path=Path('/media/tris/tris_files/github/csce_courses/')\n",
    "\n",
    "train_logger = Logger(os.path.join(results_path, 'train.log'),\n",
    "                      ['epoch', 'loss', 'acc', 'lr'])\n",
    "train_batch_logger = Logger(os.path.join(results_path, 'train_batch.log'),\n",
    "                            ['epoch', 'batch', 'iter', 'loss', 'acc', 'lr'])\n",
    "val_logger = Logger(\n",
    "            os.path.join(results_path, 'val.log'), ['epoch', 'loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:33.941366Z",
     "start_time": "2020-04-03T01:55:23.279135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1\n",
      "Epoch: [1][1/5]\tTime 0.633 (0.633)\tData 0.341 (0.341)\tLoss 1.0964 (1.0964)\tAcc 0.250 (0.250)\n",
      "Epoch: [1][2/5]\tTime 0.026 (0.330)\tData 0.002 (0.172)\tLoss 1.1118 (1.1041)\tAcc 0.125 (0.188)\n",
      "Epoch: [1][3/5]\tTime 0.083 (0.248)\tData 0.060 (0.134)\tLoss 1.0908 (1.0997)\tAcc 0.438 (0.271)\n",
      "Epoch: [1][4/5]\tTime 0.083 (0.206)\tData 0.059 (0.116)\tLoss 1.0809 (1.0950)\tAcc 0.312 (0.281)\n",
      "Epoch: [1][5/5]\tTime 0.087 (0.183)\tData 0.064 (0.105)\tLoss 1.0503 (1.0895)\tAcc 0.778 (0.342)\n",
      "validation at epoch 1\n",
      "Epoch: [1][1/9]\tTime 0.383 (0.383)\tData 0.359 (0.359)\tLoss 1.0460 (1.0460)\tAcc 0.938 (0.938)\n",
      "Epoch: [1][2/9]\tTime 0.070 (0.227)\tData 0.049 (0.204)\tLoss 1.0745 (1.0602)\tAcc 0.438 (0.688)\n",
      "Epoch: [1][3/9]\tTime 0.076 (0.177)\tData 0.052 (0.153)\tLoss 1.0782 (1.0662)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][4/9]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 1.0536 (1.0631)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][5/9]\tTime 0.072 (0.135)\tData 0.052 (0.113)\tLoss 1.0732 (1.0651)\tAcc 0.688 (0.688)\n",
      "Epoch: [1][6/9]\tTime 0.073 (0.125)\tData 0.054 (0.103)\tLoss 1.0413 (1.0611)\tAcc 1.000 (0.740)\n",
      "Epoch: [1][7/9]\tTime 0.072 (0.117)\tData 0.054 (0.096)\tLoss 1.0478 (1.0592)\tAcc 0.875 (0.759)\n",
      "Epoch: [1][8/9]\tTime 0.074 (0.112)\tData 0.054 (0.091)\tLoss 1.0910 (1.0632)\tAcc 0.500 (0.727)\n",
      "Epoch: [1][9/9]\tTime 0.072 (0.107)\tData 0.054 (0.087)\tLoss 1.0322 (1.0627)\tAcc 1.000 (0.731)\n",
      "train at epoch 2\n",
      "Epoch: [2][1/5]\tTime 0.477 (0.477)\tData 0.449 (0.449)\tLoss 1.0504 (1.0504)\tAcc 0.750 (0.750)\n",
      "Epoch: [2][2/5]\tTime 0.075 (0.276)\tData 0.050 (0.250)\tLoss 1.0699 (1.0601)\tAcc 0.500 (0.625)\n",
      "Epoch: [2][3/5]\tTime 0.078 (0.210)\tData 0.053 (0.184)\tLoss 0.9811 (1.0338)\tAcc 0.812 (0.688)\n",
      "Epoch: [2][4/5]\tTime 0.077 (0.177)\tData 0.052 (0.151)\tLoss 0.9895 (1.0227)\tAcc 0.750 (0.703)\n",
      "Epoch: [2][5/5]\tTime 0.083 (0.158)\tData 0.059 (0.133)\tLoss 1.0687 (1.0284)\tAcc 0.444 (0.671)\n",
      "validation at epoch 2\n",
      "Epoch: [2][1/9]\tTime 0.354 (0.354)\tData 0.329 (0.329)\tLoss 0.9103 (0.9103)\tAcc 0.938 (0.938)\n",
      "Epoch: [2][2/9]\tTime 0.078 (0.216)\tData 0.054 (0.191)\tLoss 1.0512 (0.9807)\tAcc 0.438 (0.688)\n",
      "Epoch: [2][3/9]\tTime 0.076 (0.170)\tData 0.055 (0.146)\tLoss 1.0094 (0.9903)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][4/9]\tTime 0.081 (0.147)\tData 0.060 (0.125)\tLoss 0.9900 (0.9902)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][5/9]\tTime 0.083 (0.134)\tData 0.058 (0.111)\tLoss 1.0025 (0.9927)\tAcc 0.688 (0.688)\n",
      "Epoch: [2][6/9]\tTime 0.070 (0.124)\tData 0.051 (0.101)\tLoss 0.8688 (0.9720)\tAcc 1.000 (0.740)\n",
      "Epoch: [2][7/9]\tTime 0.072 (0.116)\tData 0.053 (0.094)\tLoss 0.9286 (0.9658)\tAcc 0.875 (0.759)\n",
      "Epoch: [2][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.089)\tLoss 1.0524 (0.9767)\tAcc 0.500 (0.727)\n",
      "Epoch: [2][9/9]\tTime 0.076 (0.107)\tData 0.058 (0.086)\tLoss 0.8835 (0.9752)\tAcc 1.000 (0.731)\n",
      "train at epoch 3\n",
      "Epoch: [3][1/5]\tTime 0.352 (0.352)\tData 0.322 (0.322)\tLoss 0.9340 (0.9340)\tAcc 0.750 (0.750)\n",
      "Epoch: [3][2/5]\tTime 0.075 (0.213)\tData 0.049 (0.185)\tLoss 1.0642 (0.9991)\tAcc 0.500 (0.625)\n",
      "Epoch: [3][3/5]\tTime 0.075 (0.167)\tData 0.051 (0.141)\tLoss 0.8915 (0.9632)\tAcc 0.750 (0.667)\n",
      "Epoch: [3][4/5]\tTime 0.077 (0.145)\tData 0.053 (0.119)\tLoss 0.9046 (0.9486)\tAcc 0.750 (0.688)\n",
      "Epoch: [3][5/5]\tTime 0.079 (0.132)\tData 0.055 (0.106)\tLoss 1.0445 (0.9604)\tAcc 0.556 (0.671)\n",
      "validation at epoch 3\n",
      "Epoch: [3][1/9]\tTime 0.314 (0.314)\tData 0.288 (0.288)\tLoss 0.7717 (0.7717)\tAcc 0.938 (0.938)\n",
      "Epoch: [3][2/9]\tTime 0.069 (0.192)\tData 0.048 (0.168)\tLoss 1.0638 (0.9178)\tAcc 0.438 (0.688)\n",
      "Epoch: [3][3/9]\tTime 0.075 (0.153)\tData 0.052 (0.129)\tLoss 0.9255 (0.9204)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][4/9]\tTime 0.072 (0.133)\tData 0.051 (0.110)\tLoss 0.9127 (0.9184)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][5/9]\tTime 0.072 (0.120)\tData 0.052 (0.098)\tLoss 0.9300 (0.9208)\tAcc 0.688 (0.688)\n",
      "Epoch: [3][6/9]\tTime 0.076 (0.113)\tData 0.056 (0.091)\tLoss 0.7326 (0.8894)\tAcc 1.000 (0.740)\n",
      "Epoch: [3][7/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.7857 (0.8746)\tAcc 0.875 (0.759)\n",
      "Epoch: [3][8/9]\tTime 0.073 (0.103)\tData 0.054 (0.082)\tLoss 1.0653 (0.8984)\tAcc 0.500 (0.727)\n",
      "Epoch: [3][9/9]\tTime 0.072 (0.100)\tData 0.054 (0.079)\tLoss 0.7465 (0.8961)\tAcc 1.000 (0.731)\n",
      "train at epoch 4\n",
      "Epoch: [4][1/5]\tTime 0.309 (0.309)\tData 0.279 (0.279)\tLoss 0.9295 (0.9295)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][2/5]\tTime 0.074 (0.191)\tData 0.048 (0.163)\tLoss 0.9237 (0.9266)\tAcc 0.625 (0.656)\n",
      "Epoch: [4][3/5]\tTime 0.077 (0.153)\tData 0.053 (0.127)\tLoss 0.9478 (0.9336)\tAcc 0.625 (0.646)\n",
      "Epoch: [4][4/5]\tTime 0.077 (0.134)\tData 0.053 (0.108)\tLoss 0.9310 (0.9330)\tAcc 0.625 (0.641)\n",
      "Epoch: [4][5/5]\tTime 0.078 (0.123)\tData 0.055 (0.098)\tLoss 0.6358 (0.8963)\tAcc 0.889 (0.671)\n",
      "validation at epoch 4\n",
      "Epoch: [4][1/9]\tTime 0.305 (0.305)\tData 0.278 (0.278)\tLoss 0.6285 (0.6285)\tAcc 0.938 (0.938)\n",
      "Epoch: [4][2/9]\tTime 0.071 (0.188)\tData 0.049 (0.164)\tLoss 1.1309 (0.8797)\tAcc 0.438 (0.688)\n",
      "Epoch: [4][3/9]\tTime 0.073 (0.150)\tData 0.051 (0.126)\tLoss 0.8627 (0.8740)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][4/9]\tTime 0.072 (0.130)\tData 0.052 (0.108)\tLoss 0.8952 (0.8793)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][5/9]\tTime 0.072 (0.119)\tData 0.053 (0.097)\tLoss 0.8804 (0.8795)\tAcc 0.688 (0.688)\n",
      "Epoch: [4][6/9]\tTime 0.075 (0.111)\tData 0.055 (0.090)\tLoss 0.5567 (0.8257)\tAcc 1.000 (0.740)\n",
      "Epoch: [4][7/9]\tTime 0.072 (0.106)\tData 0.053 (0.085)\tLoss 0.6838 (0.8055)\tAcc 0.875 (0.759)\n",
      "Epoch: [4][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.081)\tLoss 1.0438 (0.8353)\tAcc 0.500 (0.727)\n",
      "Epoch: [4][9/9]\tTime 0.076 (0.099)\tData 0.057 (0.078)\tLoss 0.5345 (0.8306)\tAcc 1.000 (0.731)\n",
      "train at epoch 5\n",
      "Epoch: [5][1/5]\tTime 0.376 (0.376)\tData 0.346 (0.346)\tLoss 0.7504 (0.7504)\tAcc 0.750 (0.750)\n",
      "Epoch: [5][2/5]\tTime 0.074 (0.225)\tData 0.050 (0.198)\tLoss 1.0210 (0.8857)\tAcc 0.562 (0.656)\n",
      "Epoch: [5][3/5]\tTime 0.079 (0.177)\tData 0.055 (0.150)\tLoss 0.9763 (0.9159)\tAcc 0.562 (0.625)\n",
      "Epoch: [5][4/5]\tTime 0.079 (0.152)\tData 0.056 (0.127)\tLoss 0.6649 (0.8531)\tAcc 0.812 (0.672)\n",
      "Epoch: [5][5/5]\tTime 0.080 (0.138)\tData 0.057 (0.113)\tLoss 0.8644 (0.8545)\tAcc 0.667 (0.671)\n",
      "validation at epoch 5\n",
      "Epoch: [5][1/9]\tTime 0.344 (0.344)\tData 0.319 (0.319)\tLoss 0.5195 (0.5195)\tAcc 0.938 (0.938)\n",
      "Epoch: [5][2/9]\tTime 0.072 (0.208)\tData 0.049 (0.184)\tLoss 1.1891 (0.8543)\tAcc 0.438 (0.688)\n",
      "Epoch: [5][3/9]\tTime 0.072 (0.163)\tData 0.051 (0.139)\tLoss 0.8644 (0.8577)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][4/9]\tTime 0.072 (0.140)\tData 0.052 (0.118)\tLoss 0.8863 (0.8648)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.105)\tLoss 0.8544 (0.8627)\tAcc 0.688 (0.688)\n",
      "Epoch: [5][6/9]\tTime 0.077 (0.119)\tData 0.057 (0.097)\tLoss 0.4387 (0.7921)\tAcc 1.000 (0.740)\n",
      "Epoch: [5][7/9]\tTime 0.078 (0.113)\tData 0.059 (0.092)\tLoss 0.6082 (0.7658)\tAcc 0.875 (0.759)\n",
      "Epoch: [5][8/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 1.0580 (0.8023)\tAcc 0.500 (0.727)\n",
      "Epoch: [5][9/9]\tTime 0.074 (0.104)\tData 0.056 (0.084)\tLoss 0.5110 (0.7979)\tAcc 1.000 (0.731)\n",
      "train at epoch 6\n",
      "Epoch: [6][1/5]\tTime 0.414 (0.414)\tData 0.387 (0.387)\tLoss 0.8277 (0.8277)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][2/5]\tTime 0.075 (0.245)\tData 0.051 (0.219)\tLoss 0.8699 (0.8488)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][3/5]\tTime 0.077 (0.189)\tData 0.054 (0.164)\tLoss 1.0961 (0.9313)\tAcc 0.562 (0.646)\n",
      "Epoch: [6][4/5]\tTime 0.077 (0.161)\tData 0.054 (0.137)\tLoss 0.6044 (0.8495)\tAcc 0.812 (0.688)\n",
      "Epoch: [6][5/5]\tTime 0.079 (0.144)\tData 0.056 (0.120)\tLoss 1.0013 (0.8682)\tAcc 0.556 (0.671)\n",
      "validation at epoch 6\n",
      "Epoch: [6][1/9]\tTime 0.364 (0.364)\tData 0.341 (0.341)\tLoss 0.4941 (0.4941)\tAcc 0.938 (0.938)\n",
      "Epoch: [6][2/9]\tTime 0.076 (0.220)\tData 0.050 (0.196)\tLoss 1.2525 (0.8733)\tAcc 0.438 (0.688)\n",
      "Epoch: [6][3/9]\tTime 0.074 (0.171)\tData 0.051 (0.147)\tLoss 0.8664 (0.8710)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][4/9]\tTime 0.083 (0.149)\tData 0.055 (0.124)\tLoss 0.8112 (0.8561)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][5/9]\tTime 0.073 (0.134)\tData 0.053 (0.110)\tLoss 0.8533 (0.8555)\tAcc 0.688 (0.688)\n",
      "Epoch: [6][6/9]\tTime 0.073 (0.124)\tData 0.055 (0.101)\tLoss 0.3899 (0.7779)\tAcc 1.000 (0.740)\n",
      "Epoch: [6][7/9]\tTime 0.074 (0.117)\tData 0.055 (0.094)\tLoss 0.5617 (0.7470)\tAcc 0.875 (0.759)\n",
      "Epoch: [6][8/9]\tTime 0.075 (0.112)\tData 0.055 (0.089)\tLoss 1.1566 (0.7982)\tAcc 0.500 (0.727)\n",
      "Epoch: [6][9/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.3855 (0.7919)\tAcc 1.000 (0.731)\n",
      "train at epoch 7\n",
      "Epoch: [7][1/5]\tTime 0.382 (0.382)\tData 0.355 (0.355)\tLoss 0.8855 (0.8855)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][2/5]\tTime 0.078 (0.230)\tData 0.055 (0.205)\tLoss 0.7912 (0.8383)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][3/5]\tTime 0.077 (0.179)\tData 0.054 (0.154)\tLoss 0.5721 (0.7496)\tAcc 0.812 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][4/5]\tTime 0.078 (0.154)\tData 0.054 (0.129)\tLoss 1.0868 (0.8339)\tAcc 0.562 (0.688)\n",
      "Epoch: [7][5/5]\tTime 0.079 (0.139)\tData 0.056 (0.115)\tLoss 1.0368 (0.8589)\tAcc 0.556 (0.671)\n",
      "validation at epoch 7\n",
      "Epoch: [7][1/9]\tTime 0.293 (0.293)\tData 0.267 (0.267)\tLoss 0.4847 (0.4847)\tAcc 0.938 (0.938)\n",
      "Epoch: [7][2/9]\tTime 0.074 (0.183)\tData 0.048 (0.158)\tLoss 1.2295 (0.8571)\tAcc 0.438 (0.688)\n",
      "Epoch: [7][3/9]\tTime 0.073 (0.147)\tData 0.048 (0.121)\tLoss 0.8257 (0.8466)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][4/9]\tTime 0.069 (0.127)\tData 0.049 (0.103)\tLoss 0.9034 (0.8608)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][5/9]\tTime 0.074 (0.117)\tData 0.053 (0.093)\tLoss 0.8459 (0.8578)\tAcc 0.688 (0.688)\n",
      "Epoch: [7][6/9]\tTime 0.071 (0.109)\tData 0.052 (0.086)\tLoss 0.3845 (0.7790)\tAcc 1.000 (0.740)\n",
      "Epoch: [7][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.5579 (0.7474)\tAcc 0.875 (0.759)\n",
      "Epoch: [7][8/9]\tTime 0.074 (0.100)\tData 0.055 (0.078)\tLoss 1.1463 (0.7973)\tAcc 0.500 (0.727)\n",
      "Epoch: [7][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.076)\tLoss 0.4145 (0.7914)\tAcc 1.000 (0.731)\n",
      "train at epoch 8\n",
      "Epoch: [8][1/5]\tTime 0.312 (0.312)\tData 0.282 (0.282)\tLoss 0.7952 (0.7952)\tAcc 0.750 (0.750)\n",
      "Epoch: [8][2/5]\tTime 0.074 (0.193)\tData 0.049 (0.166)\tLoss 0.8146 (0.8049)\tAcc 0.688 (0.719)\n",
      "Epoch: [8][3/5]\tTime 0.078 (0.154)\tData 0.054 (0.128)\tLoss 1.1402 (0.9167)\tAcc 0.500 (0.646)\n",
      "Epoch: [8][4/5]\tTime 0.076 (0.135)\tData 0.053 (0.110)\tLoss 0.8656 (0.9039)\tAcc 0.625 (0.641)\n",
      "Epoch: [8][5/5]\tTime 0.078 (0.124)\tData 0.055 (0.099)\tLoss 0.5322 (0.8581)\tAcc 0.889 (0.671)\n",
      "validation at epoch 8\n",
      "Epoch: [8][1/9]\tTime 0.356 (0.356)\tData 0.327 (0.327)\tLoss 0.4807 (0.4807)\tAcc 0.938 (0.938)\n",
      "Epoch: [8][2/9]\tTime 0.069 (0.212)\tData 0.046 (0.186)\tLoss 1.2018 (0.8412)\tAcc 0.438 (0.688)\n",
      "Epoch: [8][3/9]\tTime 0.070 (0.165)\tData 0.050 (0.141)\tLoss 0.8726 (0.8517)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][4/9]\tTime 0.074 (0.142)\tData 0.052 (0.119)\tLoss 0.8668 (0.8554)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][5/9]\tTime 0.072 (0.128)\tData 0.053 (0.105)\tLoss 0.8381 (0.8520)\tAcc 0.688 (0.688)\n",
      "Epoch: [8][6/9]\tTime 0.072 (0.119)\tData 0.053 (0.097)\tLoss 0.3962 (0.7760)\tAcc 1.000 (0.740)\n",
      "Epoch: [8][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.5663 (0.7460)\tAcc 0.875 (0.759)\n",
      "Epoch: [8][8/9]\tTime 0.075 (0.108)\tData 0.055 (0.086)\tLoss 1.1167 (0.7924)\tAcc 0.500 (0.727)\n",
      "Epoch: [8][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.3924 (0.7862)\tAcc 1.000 (0.731)\n",
      "train at epoch 9\n",
      "Epoch: [9][1/5]\tTime 0.382 (0.382)\tData 0.353 (0.353)\tLoss 0.8213 (0.8213)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][2/5]\tTime 0.073 (0.228)\tData 0.049 (0.201)\tLoss 0.6422 (0.7317)\tAcc 0.812 (0.750)\n",
      "Epoch: [9][3/5]\tTime 0.076 (0.177)\tData 0.053 (0.151)\tLoss 0.8803 (0.7813)\tAcc 0.625 (0.708)\n",
      "Epoch: [9][4/5]\tTime 0.076 (0.152)\tData 0.054 (0.127)\tLoss 0.7378 (0.7704)\tAcc 0.688 (0.703)\n",
      "Epoch: [9][5/5]\tTime 0.081 (0.138)\tData 0.056 (0.113)\tLoss 1.1192 (0.8134)\tAcc 0.444 (0.671)\n",
      "validation at epoch 9\n",
      "Epoch: [9][1/9]\tTime 0.338 (0.338)\tData 0.313 (0.313)\tLoss 0.5227 (0.5227)\tAcc 0.938 (0.938)\n",
      "Epoch: [9][2/9]\tTime 0.077 (0.207)\tData 0.055 (0.184)\tLoss 1.1697 (0.8462)\tAcc 0.438 (0.688)\n",
      "Epoch: [9][3/9]\tTime 0.078 (0.164)\tData 0.055 (0.141)\tLoss 0.8334 (0.8419)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][4/9]\tTime 0.070 (0.141)\tData 0.050 (0.118)\tLoss 0.8686 (0.8486)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.105)\tLoss 0.8613 (0.8511)\tAcc 0.688 (0.688)\n",
      "Epoch: [9][6/9]\tTime 0.073 (0.118)\tData 0.053 (0.097)\tLoss 0.4182 (0.7790)\tAcc 1.000 (0.740)\n",
      "Epoch: [9][7/9]\tTime 0.072 (0.112)\tData 0.053 (0.091)\tLoss 0.5928 (0.7524)\tAcc 0.875 (0.759)\n",
      "Epoch: [9][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.086)\tLoss 1.0910 (0.7947)\tAcc 0.500 (0.727)\n",
      "Epoch: [9][9/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 0.4214 (0.7890)\tAcc 1.000 (0.731)\n",
      "train at epoch 10\n",
      "Epoch: [10][1/5]\tTime 0.364 (0.364)\tData 0.336 (0.336)\tLoss 0.8301 (0.8301)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][2/5]\tTime 0.076 (0.220)\tData 0.051 (0.194)\tLoss 0.9083 (0.8692)\tAcc 0.625 (0.656)\n",
      "Epoch: [10][3/5]\tTime 0.077 (0.172)\tData 0.053 (0.147)\tLoss 0.8417 (0.8600)\tAcc 0.688 (0.667)\n",
      "Epoch: [10][4/5]\tTime 0.077 (0.148)\tData 0.054 (0.124)\tLoss 0.8041 (0.8460)\tAcc 0.688 (0.672)\n",
      "Epoch: [10][5/5]\tTime 0.085 (0.136)\tData 0.060 (0.111)\tLoss 0.7841 (0.8384)\tAcc 0.667 (0.671)\n",
      "validation at epoch 10\n",
      "Epoch: [10][1/9]\tTime 0.331 (0.331)\tData 0.307 (0.307)\tLoss 0.5216 (0.5216)\tAcc 0.938 (0.938)\n",
      "Epoch: [10][2/9]\tTime 0.074 (0.203)\tData 0.053 (0.180)\tLoss 1.2298 (0.8757)\tAcc 0.438 (0.688)\n",
      "Epoch: [10][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.138)\tLoss 0.8477 (0.8663)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][4/9]\tTime 0.074 (0.138)\tData 0.054 (0.117)\tLoss 0.8391 (0.8595)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][5/9]\tTime 0.075 (0.126)\tData 0.056 (0.105)\tLoss 0.8478 (0.8572)\tAcc 0.688 (0.688)\n",
      "Epoch: [10][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.4517 (0.7896)\tAcc 1.000 (0.740)\n",
      "Epoch: [10][7/9]\tTime 0.074 (0.111)\tData 0.054 (0.090)\tLoss 0.6161 (0.7648)\tAcc 0.875 (0.759)\n",
      "Epoch: [10][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.086)\tLoss 1.0599 (0.8017)\tAcc 0.500 (0.727)\n",
      "Epoch: [10][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.082)\tLoss 0.3768 (0.7952)\tAcc 1.000 (0.731)\n",
      "train at epoch 11\n",
      "Epoch: [11][1/5]\tTime 0.346 (0.346)\tData 0.318 (0.318)\tLoss 0.8342 (0.8342)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][2/5]\tTime 0.091 (0.218)\tData 0.067 (0.192)\tLoss 0.7598 (0.7970)\tAcc 0.750 (0.719)\n",
      "Epoch: [11][3/5]\tTime 0.078 (0.172)\tData 0.054 (0.146)\tLoss 0.7590 (0.7843)\tAcc 0.750 (0.729)\n",
      "Epoch: [11][4/5]\tTime 0.080 (0.149)\tData 0.056 (0.124)\tLoss 1.0160 (0.8423)\tAcc 0.500 (0.672)\n",
      "Epoch: [11][5/5]\tTime 0.078 (0.134)\tData 0.055 (0.110)\tLoss 0.9020 (0.8496)\tAcc 0.667 (0.671)\n",
      "validation at epoch 11\n",
      "Epoch: [11][1/9]\tTime 0.306 (0.306)\tData 0.282 (0.282)\tLoss 0.5441 (0.5441)\tAcc 0.938 (0.938)\n",
      "Epoch: [11][2/9]\tTime 0.073 (0.189)\tData 0.050 (0.166)\tLoss 1.1730 (0.8586)\tAcc 0.438 (0.688)\n",
      "Epoch: [11][3/9]\tTime 0.072 (0.150)\tData 0.051 (0.128)\tLoss 0.8387 (0.8520)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][4/9]\tTime 0.073 (0.131)\tData 0.052 (0.109)\tLoss 0.8499 (0.8514)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][5/9]\tTime 0.077 (0.120)\tData 0.054 (0.098)\tLoss 0.8614 (0.8534)\tAcc 0.688 (0.688)\n",
      "Epoch: [11][6/9]\tTime 0.071 (0.112)\tData 0.051 (0.090)\tLoss 0.4486 (0.7860)\tAcc 1.000 (0.740)\n",
      "Epoch: [11][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.085)\tLoss 0.6289 (0.7635)\tAcc 0.875 (0.759)\n",
      "Epoch: [11][8/9]\tTime 0.077 (0.103)\tData 0.058 (0.081)\tLoss 1.1256 (0.8088)\tAcc 0.500 (0.727)\n",
      "Epoch: [11][9/9]\tTime 0.074 (0.100)\tData 0.055 (0.079)\tLoss 0.4101 (0.8026)\tAcc 1.000 (0.731)\n",
      "train at epoch 12\n",
      "Epoch: [12][1/5]\tTime 0.318 (0.318)\tData 0.288 (0.288)\tLoss 0.8415 (0.8415)\tAcc 0.625 (0.625)\n",
      "Epoch: [12][2/5]\tTime 0.084 (0.201)\tData 0.060 (0.174)\tLoss 1.0121 (0.9268)\tAcc 0.500 (0.562)\n",
      "Epoch: [12][3/5]\tTime 0.078 (0.160)\tData 0.055 (0.134)\tLoss 0.9776 (0.9437)\tAcc 0.562 (0.562)\n",
      "Epoch: [12][4/5]\tTime 0.076 (0.139)\tData 0.053 (0.114)\tLoss 0.5737 (0.8512)\tAcc 0.938 (0.656)\n",
      "Epoch: [12][5/5]\tTime 0.078 (0.127)\tData 0.055 (0.102)\tLoss 0.7821 (0.8427)\tAcc 0.778 (0.671)\n",
      "validation at epoch 12\n",
      "Epoch: [12][1/9]\tTime 0.311 (0.311)\tData 0.283 (0.283)\tLoss 0.5365 (0.5365)\tAcc 0.938 (0.938)\n",
      "Epoch: [12][2/9]\tTime 0.073 (0.192)\tData 0.052 (0.168)\tLoss 1.1888 (0.8626)\tAcc 0.438 (0.688)\n",
      "Epoch: [12][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.129)\tLoss 0.8400 (0.8551)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][4/9]\tTime 0.076 (0.133)\tData 0.056 (0.111)\tLoss 0.8346 (0.8500)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][5/9]\tTime 0.074 (0.121)\tData 0.054 (0.099)\tLoss 0.8243 (0.8448)\tAcc 0.688 (0.688)\n",
      "Epoch: [12][6/9]\tTime 0.074 (0.114)\tData 0.055 (0.092)\tLoss 0.4211 (0.7742)\tAcc 1.000 (0.740)\n",
      "Epoch: [12][7/9]\tTime 0.072 (0.108)\tData 0.054 (0.086)\tLoss 0.5803 (0.7465)\tAcc 0.875 (0.759)\n",
      "Epoch: [12][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 1.1160 (0.7927)\tAcc 0.500 (0.727)\n",
      "Epoch: [12][9/9]\tTime 0.074 (0.100)\tData 0.055 (0.080)\tLoss 0.4973 (0.7882)\tAcc 1.000 (0.731)\n",
      "train at epoch 13\n",
      "Epoch: [13][1/5]\tTime 0.354 (0.354)\tData 0.325 (0.325)\tLoss 0.7801 (0.7801)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][2/5]\tTime 0.072 (0.213)\tData 0.049 (0.187)\tLoss 1.0656 (0.9228)\tAcc 0.500 (0.594)\n",
      "Epoch: [13][3/5]\tTime 0.077 (0.168)\tData 0.054 (0.142)\tLoss 0.7675 (0.8711)\tAcc 0.688 (0.625)\n",
      "Epoch: [13][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.120)\tLoss 0.8298 (0.8608)\tAcc 0.625 (0.625)\n",
      "Epoch: [13][5/5]\tTime 0.080 (0.132)\tData 0.056 (0.107)\tLoss 0.4748 (0.8132)\tAcc 1.000 (0.671)\n",
      "validation at epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][1/9]\tTime 0.301 (0.301)\tData 0.277 (0.277)\tLoss 0.5025 (0.5025)\tAcc 0.938 (0.938)\n",
      "Epoch: [13][2/9]\tTime 0.072 (0.187)\tData 0.049 (0.163)\tLoss 1.1818 (0.8421)\tAcc 0.438 (0.688)\n",
      "Epoch: [13][3/9]\tTime 0.073 (0.149)\tData 0.051 (0.126)\tLoss 0.8083 (0.8309)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][4/9]\tTime 0.073 (0.130)\tData 0.052 (0.107)\tLoss 0.8437 (0.8341)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][5/9]\tTime 0.073 (0.118)\tData 0.053 (0.096)\tLoss 0.8433 (0.8359)\tAcc 0.688 (0.688)\n",
      "Epoch: [13][6/9]\tTime 0.079 (0.112)\tData 0.059 (0.090)\tLoss 0.3827 (0.7604)\tAcc 1.000 (0.740)\n",
      "Epoch: [13][7/9]\tTime 0.077 (0.107)\tData 0.058 (0.086)\tLoss 0.5374 (0.7285)\tAcc 0.875 (0.759)\n",
      "Epoch: [13][8/9]\tTime 0.076 (0.103)\tData 0.056 (0.082)\tLoss 1.0896 (0.7737)\tAcc 0.500 (0.727)\n",
      "Epoch: [13][9/9]\tTime 0.075 (0.100)\tData 0.057 (0.079)\tLoss 0.3798 (0.7676)\tAcc 1.000 (0.731)\n",
      "train at epoch 14\n",
      "Epoch: [14][1/5]\tTime 0.407 (0.407)\tData 0.379 (0.379)\tLoss 0.8832 (0.8832)\tAcc 0.562 (0.562)\n",
      "Epoch: [14][2/5]\tTime 0.075 (0.241)\tData 0.050 (0.215)\tLoss 0.7755 (0.8294)\tAcc 0.688 (0.625)\n",
      "Epoch: [14][3/5]\tTime 0.077 (0.186)\tData 0.053 (0.161)\tLoss 0.5867 (0.7485)\tAcc 0.812 (0.688)\n",
      "Epoch: [14][4/5]\tTime 0.076 (0.159)\tData 0.053 (0.134)\tLoss 0.8599 (0.7763)\tAcc 0.625 (0.672)\n",
      "Epoch: [14][5/5]\tTime 0.078 (0.143)\tData 0.055 (0.118)\tLoss 0.7946 (0.7786)\tAcc 0.667 (0.671)\n",
      "validation at epoch 14\n",
      "Epoch: [14][1/9]\tTime 0.325 (0.325)\tData 0.301 (0.301)\tLoss 0.5003 (0.5003)\tAcc 0.938 (0.938)\n",
      "Epoch: [14][2/9]\tTime 0.072 (0.198)\tData 0.050 (0.176)\tLoss 1.1902 (0.8452)\tAcc 0.438 (0.688)\n",
      "Epoch: [14][3/9]\tTime 0.074 (0.157)\tData 0.052 (0.134)\tLoss 0.9195 (0.8700)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][4/9]\tTime 0.072 (0.136)\tData 0.051 (0.113)\tLoss 0.8594 (0.8673)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][5/9]\tTime 0.072 (0.123)\tData 0.052 (0.101)\tLoss 0.8072 (0.8553)\tAcc 0.688 (0.688)\n",
      "Epoch: [14][6/9]\tTime 0.072 (0.115)\tData 0.053 (0.093)\tLoss 0.3726 (0.7749)\tAcc 1.000 (0.740)\n",
      "Epoch: [14][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.4958 (0.7350)\tAcc 0.875 (0.759)\n",
      "Epoch: [14][8/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 1.0914 (0.7796)\tAcc 0.500 (0.727)\n",
      "Epoch: [14][9/9]\tTime 0.072 (0.101)\tData 0.054 (0.080)\tLoss 0.4090 (0.7739)\tAcc 1.000 (0.731)\n",
      "train at epoch 15\n",
      "Epoch: [15][1/5]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 0.8953 (0.8953)\tAcc 0.625 (0.625)\n",
      "Epoch: [15][2/5]\tTime 0.073 (0.204)\tData 0.049 (0.177)\tLoss 0.8919 (0.8936)\tAcc 0.688 (0.656)\n",
      "Epoch: [15][3/5]\tTime 0.078 (0.162)\tData 0.055 (0.136)\tLoss 0.8984 (0.8952)\tAcc 0.562 (0.625)\n",
      "Epoch: [15][4/5]\tTime 0.081 (0.141)\tData 0.058 (0.117)\tLoss 0.6865 (0.8430)\tAcc 0.750 (0.656)\n",
      "Epoch: [15][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.105)\tLoss 0.6226 (0.8158)\tAcc 0.778 (0.671)\n",
      "validation at epoch 15\n",
      "Epoch: [15][1/9]\tTime 0.347 (0.347)\tData 0.321 (0.321)\tLoss 0.3873 (0.3873)\tAcc 0.938 (0.938)\n",
      "Epoch: [15][2/9]\tTime 0.069 (0.208)\tData 0.048 (0.184)\tLoss 1.1282 (0.7578)\tAcc 0.438 (0.688)\n",
      "Epoch: [15][3/9]\tTime 0.075 (0.164)\tData 0.052 (0.140)\tLoss 0.8387 (0.7847)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][4/9]\tTime 0.071 (0.140)\tData 0.051 (0.118)\tLoss 0.7655 (0.7799)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.105)\tLoss 0.8460 (0.7931)\tAcc 0.688 (0.688)\n",
      "Epoch: [15][6/9]\tTime 0.073 (0.118)\tData 0.055 (0.097)\tLoss 0.2980 (0.7106)\tAcc 1.000 (0.740)\n",
      "Epoch: [15][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.4681 (0.6760)\tAcc 0.875 (0.759)\n",
      "Epoch: [15][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 1.1066 (0.7298)\tAcc 0.500 (0.727)\n",
      "Epoch: [15][9/9]\tTime 0.072 (0.103)\tData 0.054 (0.083)\tLoss 0.3690 (0.7242)\tAcc 1.000 (0.731)\n",
      "train at epoch 16\n",
      "Epoch: [16][1/5]\tTime 0.332 (0.332)\tData 0.302 (0.302)\tLoss 0.7476 (0.7476)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][2/5]\tTime 0.073 (0.203)\tData 0.049 (0.176)\tLoss 0.4717 (0.6096)\tAcc 0.875 (0.781)\n",
      "Epoch: [16][3/5]\tTime 0.077 (0.161)\tData 0.053 (0.135)\tLoss 0.9629 (0.7274)\tAcc 0.500 (0.688)\n",
      "Epoch: [16][4/5]\tTime 0.077 (0.140)\tData 0.053 (0.114)\tLoss 0.9692 (0.7878)\tAcc 0.625 (0.672)\n",
      "Epoch: [16][5/5]\tTime 0.078 (0.127)\tData 0.055 (0.103)\tLoss 0.8605 (0.7968)\tAcc 0.667 (0.671)\n",
      "validation at epoch 16\n",
      "Epoch: [16][1/9]\tTime 0.388 (0.388)\tData 0.364 (0.364)\tLoss 0.4435 (0.4435)\tAcc 0.938 (0.938)\n",
      "Epoch: [16][2/9]\tTime 0.073 (0.230)\tData 0.052 (0.208)\tLoss 1.2051 (0.8243)\tAcc 0.438 (0.688)\n",
      "Epoch: [16][3/9]\tTime 0.079 (0.180)\tData 0.059 (0.158)\tLoss 0.7920 (0.8135)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][4/9]\tTime 0.076 (0.154)\tData 0.056 (0.133)\tLoss 0.8352 (0.8190)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][5/9]\tTime 0.074 (0.138)\tData 0.055 (0.117)\tLoss 0.8983 (0.8348)\tAcc 0.688 (0.688)\n",
      "Epoch: [16][6/9]\tTime 0.075 (0.128)\tData 0.056 (0.107)\tLoss 0.2903 (0.7441)\tAcc 1.000 (0.740)\n",
      "Epoch: [16][7/9]\tTime 0.073 (0.120)\tData 0.055 (0.100)\tLoss 0.5426 (0.7153)\tAcc 0.875 (0.759)\n",
      "Epoch: [16][8/9]\tTime 0.074 (0.114)\tData 0.055 (0.094)\tLoss 1.0750 (0.7603)\tAcc 0.500 (0.727)\n",
      "Epoch: [16][9/9]\tTime 0.074 (0.110)\tData 0.055 (0.090)\tLoss 0.3261 (0.7536)\tAcc 1.000 (0.731)\n",
      "train at epoch 17\n",
      "Epoch: [17][1/5]\tTime 0.368 (0.368)\tData 0.341 (0.341)\tLoss 0.5299 (0.5299)\tAcc 0.812 (0.812)\n",
      "Epoch: [17][2/5]\tTime 0.088 (0.228)\tData 0.063 (0.202)\tLoss 0.8307 (0.6803)\tAcc 0.625 (0.719)\n",
      "Epoch: [17][3/5]\tTime 0.077 (0.178)\tData 0.053 (0.153)\tLoss 0.4897 (0.6168)\tAcc 0.812 (0.750)\n",
      "Epoch: [17][4/5]\tTime 0.081 (0.154)\tData 0.057 (0.129)\tLoss 1.1385 (0.7472)\tAcc 0.438 (0.672)\n",
      "Epoch: [17][5/5]\tTime 0.079 (0.139)\tData 0.056 (0.114)\tLoss 0.6487 (0.7351)\tAcc 0.667 (0.671)\n",
      "validation at epoch 17\n",
      "Epoch: [17][1/9]\tTime 0.378 (0.378)\tData 0.354 (0.354)\tLoss 0.4250 (0.4250)\tAcc 0.938 (0.938)\n",
      "Epoch: [17][2/9]\tTime 0.071 (0.224)\tData 0.050 (0.202)\tLoss 1.1591 (0.7921)\tAcc 0.438 (0.688)\n",
      "Epoch: [17][3/9]\tTime 0.076 (0.175)\tData 0.054 (0.153)\tLoss 0.7947 (0.7929)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][4/9]\tTime 0.072 (0.149)\tData 0.051 (0.127)\tLoss 0.8972 (0.8190)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][5/9]\tTime 0.083 (0.136)\tData 0.063 (0.114)\tLoss 0.8816 (0.8315)\tAcc 0.688 (0.688)\n",
      "Epoch: [17][6/9]\tTime 0.074 (0.126)\tData 0.056 (0.105)\tLoss 0.2174 (0.7292)\tAcc 1.000 (0.740)\n",
      "Epoch: [17][7/9]\tTime 0.075 (0.118)\tData 0.056 (0.098)\tLoss 0.4827 (0.6940)\tAcc 0.875 (0.759)\n",
      "Epoch: [17][8/9]\tTime 0.076 (0.113)\tData 0.057 (0.093)\tLoss 1.0747 (0.7416)\tAcc 0.500 (0.727)\n",
      "Epoch: [17][9/9]\tTime 0.072 (0.109)\tData 0.054 (0.088)\tLoss 0.3607 (0.7357)\tAcc 1.000 (0.731)\n",
      "train at epoch 18\n",
      "Epoch: [18][1/5]\tTime 0.325 (0.325)\tData 0.295 (0.295)\tLoss 0.9798 (0.9798)\tAcc 0.562 (0.562)\n",
      "Epoch: [18][2/5]\tTime 0.074 (0.199)\tData 0.048 (0.171)\tLoss 0.5300 (0.7549)\tAcc 0.812 (0.688)\n",
      "Epoch: [18][3/5]\tTime 0.076 (0.158)\tData 0.052 (0.132)\tLoss 0.6433 (0.7177)\tAcc 0.750 (0.708)\n",
      "Epoch: [18][4/5]\tTime 0.077 (0.138)\tData 0.054 (0.112)\tLoss 0.6995 (0.7131)\tAcc 0.688 (0.703)\n",
      "Epoch: [18][5/5]\tTime 0.079 (0.126)\tData 0.055 (0.101)\tLoss 1.1419 (0.7660)\tAcc 0.444 (0.671)\n",
      "validation at epoch 18\n",
      "Epoch: [18][1/9]\tTime 0.331 (0.331)\tData 0.307 (0.307)\tLoss 0.3783 (0.3783)\tAcc 0.938 (0.938)\n",
      "Epoch: [18][2/9]\tTime 0.071 (0.201)\tData 0.050 (0.179)\tLoss 1.2434 (0.8108)\tAcc 0.438 (0.688)\n",
      "Epoch: [18][3/9]\tTime 0.073 (0.158)\tData 0.052 (0.137)\tLoss 0.7649 (0.7955)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][4/9]\tTime 0.073 (0.137)\tData 0.053 (0.116)\tLoss 0.8110 (0.7994)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][5/9]\tTime 0.075 (0.125)\tData 0.055 (0.104)\tLoss 0.8791 (0.8153)\tAcc 0.688 (0.688)\n",
      "Epoch: [18][6/9]\tTime 0.078 (0.117)\tData 0.058 (0.096)\tLoss 0.3037 (0.7301)\tAcc 1.000 (0.740)\n",
      "Epoch: [18][7/9]\tTime 0.081 (0.112)\tData 0.061 (0.091)\tLoss 0.6080 (0.7126)\tAcc 0.875 (0.759)\n",
      "Epoch: [18][8/9]\tTime 0.080 (0.108)\tData 0.060 (0.087)\tLoss 1.1005 (0.7611)\tAcc 0.500 (0.727)\n",
      "Epoch: [18][9/9]\tTime 0.078 (0.104)\tData 0.059 (0.084)\tLoss 0.3675 (0.7551)\tAcc 1.000 (0.731)\n",
      "train at epoch 19\n",
      "Epoch: [19][1/5]\tTime 0.416 (0.416)\tData 0.389 (0.389)\tLoss 0.9668 (0.9668)\tAcc 0.562 (0.562)\n",
      "Epoch: [19][2/5]\tTime 0.076 (0.246)\tData 0.051 (0.220)\tLoss 0.6034 (0.7851)\tAcc 0.812 (0.688)\n",
      "Epoch: [19][3/5]\tTime 0.078 (0.190)\tData 0.053 (0.164)\tLoss 0.9978 (0.8560)\tAcc 0.500 (0.625)\n",
      "Epoch: [19][4/5]\tTime 0.078 (0.162)\tData 0.054 (0.137)\tLoss 0.6447 (0.8032)\tAcc 0.750 (0.656)\n",
      "Epoch: [19][5/5]\tTime 0.078 (0.145)\tData 0.054 (0.120)\tLoss 0.6764 (0.7875)\tAcc 0.778 (0.671)\n",
      "validation at epoch 19\n",
      "Epoch: [19][1/9]\tTime 0.358 (0.358)\tData 0.331 (0.331)\tLoss 0.4313 (0.4313)\tAcc 0.938 (0.938)\n",
      "Epoch: [19][2/9]\tTime 0.078 (0.218)\tData 0.052 (0.192)\tLoss 1.0117 (0.7215)\tAcc 0.438 (0.688)\n",
      "Epoch: [19][3/9]\tTime 0.076 (0.171)\tData 0.054 (0.146)\tLoss 0.7373 (0.7267)\tAcc 0.688 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][4/9]\tTime 0.080 (0.148)\tData 0.059 (0.124)\tLoss 0.7358 (0.7290)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][5/9]\tTime 0.087 (0.136)\tData 0.067 (0.113)\tLoss 0.7975 (0.7427)\tAcc 0.688 (0.688)\n",
      "Epoch: [19][6/9]\tTime 0.079 (0.126)\tData 0.059 (0.104)\tLoss 0.3365 (0.6750)\tAcc 1.000 (0.740)\n",
      "Epoch: [19][7/9]\tTime 0.080 (0.120)\tData 0.060 (0.098)\tLoss 0.5653 (0.6593)\tAcc 0.875 (0.759)\n",
      "Epoch: [19][8/9]\tTime 0.075 (0.114)\tData 0.055 (0.092)\tLoss 1.0819 (0.7121)\tAcc 0.500 (0.727)\n",
      "Epoch: [19][9/9]\tTime 0.073 (0.110)\tData 0.053 (0.088)\tLoss 0.2379 (0.7048)\tAcc 1.000 (0.731)\n",
      "train at epoch 20\n",
      "Epoch: [20][1/5]\tTime 0.326 (0.326)\tData 0.298 (0.298)\tLoss 0.7962 (0.7962)\tAcc 0.562 (0.562)\n",
      "Epoch: [20][2/5]\tTime 0.076 (0.201)\tData 0.051 (0.174)\tLoss 0.8501 (0.8232)\tAcc 0.625 (0.594)\n",
      "Epoch: [20][3/5]\tTime 0.081 (0.161)\tData 0.056 (0.135)\tLoss 0.4806 (0.7090)\tAcc 0.875 (0.688)\n",
      "Epoch: [20][4/5]\tTime 0.083 (0.142)\tData 0.059 (0.116)\tLoss 0.7978 (0.7312)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][5/5]\tTime 0.088 (0.131)\tData 0.065 (0.106)\tLoss 0.7529 (0.7339)\tAcc 0.667 (0.685)\n",
      "validation at epoch 20\n",
      "Epoch: [20][1/9]\tTime 0.315 (0.315)\tData 0.289 (0.289)\tLoss 0.4300 (0.4300)\tAcc 0.938 (0.938)\n",
      "Epoch: [20][2/9]\tTime 0.076 (0.196)\tData 0.055 (0.172)\tLoss 1.1331 (0.7815)\tAcc 0.438 (0.688)\n",
      "Epoch: [20][3/9]\tTime 0.079 (0.157)\tData 0.058 (0.134)\tLoss 0.7649 (0.7760)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][4/9]\tTime 0.076 (0.137)\tData 0.057 (0.115)\tLoss 0.7465 (0.7686)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][5/9]\tTime 0.074 (0.124)\tData 0.054 (0.103)\tLoss 0.7696 (0.7688)\tAcc 0.688 (0.688)\n",
      "Epoch: [20][6/9]\tTime 0.073 (0.116)\tData 0.053 (0.094)\tLoss 0.3510 (0.6992)\tAcc 1.000 (0.740)\n",
      "Epoch: [20][7/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 0.6468 (0.6917)\tAcc 0.812 (0.750)\n",
      "Epoch: [20][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.085)\tLoss 0.9410 (0.7229)\tAcc 0.500 (0.719)\n",
      "Epoch: [20][9/9]\tTime 0.075 (0.102)\tData 0.056 (0.081)\tLoss 0.3506 (0.7171)\tAcc 1.000 (0.723)\n",
      "train at epoch 21\n",
      "Epoch: [21][1/5]\tTime 0.326 (0.326)\tData 0.299 (0.299)\tLoss 0.6672 (0.6672)\tAcc 0.750 (0.750)\n",
      "Epoch: [21][2/5]\tTime 0.081 (0.203)\tData 0.056 (0.178)\tLoss 0.6749 (0.6711)\tAcc 0.812 (0.781)\n",
      "Epoch: [21][3/5]\tTime 0.084 (0.164)\tData 0.060 (0.138)\tLoss 0.8097 (0.7173)\tAcc 0.625 (0.729)\n",
      "Epoch: [21][4/5]\tTime 0.084 (0.144)\tData 0.061 (0.119)\tLoss 0.7042 (0.7140)\tAcc 0.688 (0.719)\n",
      "Epoch: [21][5/5]\tTime 0.084 (0.132)\tData 0.061 (0.107)\tLoss 1.0132 (0.7509)\tAcc 0.667 (0.712)\n",
      "validation at epoch 21\n",
      "Epoch: [21][1/9]\tTime 0.312 (0.312)\tData 0.284 (0.284)\tLoss 0.3629 (0.3629)\tAcc 0.938 (0.938)\n",
      "Epoch: [21][2/9]\tTime 0.071 (0.191)\tData 0.049 (0.167)\tLoss 0.9751 (0.6690)\tAcc 0.438 (0.688)\n",
      "Epoch: [21][3/9]\tTime 0.074 (0.152)\tData 0.052 (0.128)\tLoss 0.6296 (0.6559)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][4/9]\tTime 0.072 (0.132)\tData 0.052 (0.109)\tLoss 0.6050 (0.6432)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][5/9]\tTime 0.075 (0.121)\tData 0.054 (0.098)\tLoss 0.7686 (0.6682)\tAcc 0.688 (0.688)\n",
      "Epoch: [21][6/9]\tTime 0.072 (0.113)\tData 0.052 (0.091)\tLoss 0.3098 (0.6085)\tAcc 1.000 (0.740)\n",
      "Epoch: [21][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.6345 (0.6122)\tAcc 0.875 (0.759)\n",
      "Epoch: [21][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 1.0873 (0.6716)\tAcc 0.500 (0.727)\n",
      "Epoch: [21][9/9]\tTime 0.073 (0.100)\tData 0.055 (0.079)\tLoss 0.1297 (0.6633)\tAcc 1.000 (0.731)\n",
      "train at epoch 22\n",
      "Epoch: [22][1/5]\tTime 0.368 (0.368)\tData 0.341 (0.341)\tLoss 0.9107 (0.9107)\tAcc 0.625 (0.625)\n",
      "Epoch: [22][2/5]\tTime 0.075 (0.222)\tData 0.051 (0.196)\tLoss 0.8239 (0.8673)\tAcc 0.625 (0.625)\n",
      "Epoch: [22][3/5]\tTime 0.078 (0.174)\tData 0.055 (0.149)\tLoss 0.7822 (0.8389)\tAcc 0.562 (0.604)\n",
      "Epoch: [22][4/5]\tTime 0.077 (0.150)\tData 0.053 (0.125)\tLoss 0.5431 (0.7650)\tAcc 0.812 (0.656)\n",
      "Epoch: [22][5/5]\tTime 0.079 (0.136)\tData 0.056 (0.111)\tLoss 0.6505 (0.7509)\tAcc 0.778 (0.671)\n",
      "validation at epoch 22\n",
      "Epoch: [22][1/9]\tTime 0.325 (0.325)\tData 0.302 (0.302)\tLoss 0.3180 (0.3180)\tAcc 0.938 (0.938)\n",
      "Epoch: [22][2/9]\tTime 0.075 (0.200)\tData 0.054 (0.178)\tLoss 1.0813 (0.6997)\tAcc 0.438 (0.688)\n",
      "Epoch: [22][3/9]\tTime 0.074 (0.158)\tData 0.053 (0.136)\tLoss 0.6132 (0.6708)\tAcc 0.688 (0.688)\n",
      "Epoch: [22][4/9]\tTime 0.074 (0.137)\tData 0.054 (0.116)\tLoss 0.7709 (0.6959)\tAcc 0.750 (0.703)\n",
      "Epoch: [22][5/9]\tTime 0.078 (0.125)\tData 0.058 (0.104)\tLoss 0.7953 (0.7157)\tAcc 0.688 (0.700)\n",
      "Epoch: [22][6/9]\tTime 0.075 (0.117)\tData 0.055 (0.096)\tLoss 0.2857 (0.6441)\tAcc 1.000 (0.750)\n",
      "Epoch: [22][7/9]\tTime 0.072 (0.110)\tData 0.054 (0.090)\tLoss 0.6286 (0.6419)\tAcc 0.812 (0.759)\n",
      "Epoch: [22][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.086)\tLoss 1.0855 (0.6973)\tAcc 0.438 (0.719)\n",
      "Epoch: [22][9/9]\tTime 0.075 (0.103)\tData 0.057 (0.083)\tLoss 0.2663 (0.6907)\tAcc 1.000 (0.723)\n",
      "train at epoch 23\n",
      "Epoch: [23][1/5]\tTime 0.348 (0.348)\tData 0.318 (0.318)\tLoss 0.6787 (0.6787)\tAcc 0.750 (0.750)\n",
      "Epoch: [23][2/5]\tTime 0.073 (0.211)\tData 0.049 (0.183)\tLoss 0.7663 (0.7225)\tAcc 0.688 (0.719)\n",
      "Epoch: [23][3/5]\tTime 0.078 (0.166)\tData 0.053 (0.140)\tLoss 0.7101 (0.7184)\tAcc 0.750 (0.729)\n",
      "Epoch: [23][4/5]\tTime 0.076 (0.144)\tData 0.052 (0.118)\tLoss 0.9872 (0.7856)\tAcc 0.625 (0.703)\n",
      "Epoch: [23][5/5]\tTime 0.085 (0.132)\tData 0.061 (0.107)\tLoss 0.5874 (0.7611)\tAcc 0.667 (0.699)\n",
      "validation at epoch 23\n",
      "Epoch: [23][1/9]\tTime 0.306 (0.306)\tData 0.282 (0.282)\tLoss 0.3059 (0.3059)\tAcc 0.938 (0.938)\n",
      "Epoch: [23][2/9]\tTime 0.075 (0.191)\tData 0.054 (0.168)\tLoss 1.0229 (0.6644)\tAcc 0.562 (0.750)\n",
      "Epoch: [23][3/9]\tTime 0.078 (0.153)\tData 0.057 (0.131)\tLoss 0.6386 (0.6558)\tAcc 0.688 (0.729)\n",
      "Epoch: [23][4/9]\tTime 0.076 (0.134)\tData 0.055 (0.112)\tLoss 0.7017 (0.6673)\tAcc 0.750 (0.734)\n",
      "Epoch: [23][5/9]\tTime 0.080 (0.123)\tData 0.059 (0.101)\tLoss 0.8969 (0.7132)\tAcc 0.688 (0.725)\n",
      "Epoch: [23][6/9]\tTime 0.072 (0.114)\tData 0.052 (0.093)\tLoss 0.2808 (0.6411)\tAcc 1.000 (0.771)\n",
      "Epoch: [23][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.087)\tLoss 0.6106 (0.6368)\tAcc 0.812 (0.777)\n",
      "Epoch: [23][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.1229 (0.6975)\tAcc 0.500 (0.742)\n",
      "Epoch: [23][9/9]\tTime 0.075 (0.101)\tData 0.057 (0.080)\tLoss 0.3040 (0.6915)\tAcc 1.000 (0.746)\n",
      "train at epoch 24\n",
      "Epoch: [24][1/5]\tTime 0.362 (0.362)\tData 0.333 (0.333)\tLoss 0.6082 (0.6082)\tAcc 0.750 (0.750)\n",
      "Epoch: [24][2/5]\tTime 0.074 (0.218)\tData 0.049 (0.191)\tLoss 0.8067 (0.7074)\tAcc 0.562 (0.656)\n",
      "Epoch: [24][3/5]\tTime 0.080 (0.172)\tData 0.055 (0.146)\tLoss 0.6856 (0.7002)\tAcc 0.750 (0.688)\n",
      "Epoch: [24][4/5]\tTime 0.082 (0.150)\tData 0.059 (0.124)\tLoss 0.8296 (0.7325)\tAcc 0.625 (0.672)\n",
      "Epoch: [24][5/5]\tTime 0.080 (0.136)\tData 0.056 (0.110)\tLoss 0.6280 (0.7196)\tAcc 0.667 (0.671)\n",
      "validation at epoch 24\n",
      "Epoch: [24][1/9]\tTime 0.369 (0.369)\tData 0.345 (0.345)\tLoss 0.3202 (0.3202)\tAcc 0.938 (0.938)\n",
      "Epoch: [24][2/9]\tTime 0.071 (0.220)\tData 0.050 (0.197)\tLoss 1.1596 (0.7399)\tAcc 0.500 (0.719)\n",
      "Epoch: [24][3/9]\tTime 0.075 (0.172)\tData 0.052 (0.149)\tLoss 0.6726 (0.7175)\tAcc 0.688 (0.708)\n",
      "Epoch: [24][4/9]\tTime 0.071 (0.147)\tData 0.050 (0.124)\tLoss 0.7923 (0.7362)\tAcc 0.625 (0.688)\n",
      "Epoch: [24][5/9]\tTime 0.073 (0.132)\tData 0.053 (0.110)\tLoss 0.7853 (0.7460)\tAcc 0.688 (0.688)\n",
      "Epoch: [24][6/9]\tTime 0.075 (0.122)\tData 0.054 (0.101)\tLoss 0.2540 (0.6640)\tAcc 1.000 (0.740)\n",
      "Epoch: [24][7/9]\tTime 0.072 (0.115)\tData 0.053 (0.094)\tLoss 0.4997 (0.6405)\tAcc 0.875 (0.759)\n",
      "Epoch: [24][8/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 1.1605 (0.7055)\tAcc 0.500 (0.727)\n",
      "Epoch: [24][9/9]\tTime 0.073 (0.106)\tData 0.054 (0.085)\tLoss 0.3097 (0.6994)\tAcc 1.000 (0.731)\n",
      "train at epoch 25\n",
      "Epoch: [25][1/5]\tTime 0.305 (0.305)\tData 0.276 (0.276)\tLoss 1.0433 (1.0433)\tAcc 0.688 (0.688)\n",
      "Epoch: [25][2/5]\tTime 0.075 (0.190)\tData 0.050 (0.163)\tLoss 0.7914 (0.9174)\tAcc 0.750 (0.719)\n",
      "Epoch: [25][3/5]\tTime 0.076 (0.152)\tData 0.052 (0.126)\tLoss 0.7638 (0.8662)\tAcc 0.750 (0.729)\n",
      "Epoch: [25][4/5]\tTime 0.078 (0.134)\tData 0.054 (0.108)\tLoss 0.5193 (0.7795)\tAcc 0.812 (0.750)\n",
      "Epoch: [25][5/5]\tTime 0.078 (0.123)\tData 0.054 (0.097)\tLoss 0.7401 (0.7746)\tAcc 0.667 (0.740)\n",
      "validation at epoch 25\n",
      "Epoch: [25][1/9]\tTime 0.338 (0.338)\tData 0.311 (0.311)\tLoss 0.3370 (0.3370)\tAcc 0.938 (0.938)\n",
      "Epoch: [25][2/9]\tTime 0.070 (0.204)\tData 0.049 (0.180)\tLoss 0.9563 (0.6467)\tAcc 0.625 (0.781)\n",
      "Epoch: [25][3/9]\tTime 0.080 (0.163)\tData 0.059 (0.139)\tLoss 0.5356 (0.6097)\tAcc 0.688 (0.750)\n",
      "Epoch: [25][4/9]\tTime 0.085 (0.143)\tData 0.058 (0.119)\tLoss 0.8358 (0.6662)\tAcc 0.625 (0.719)\n",
      "Epoch: [25][5/9]\tTime 0.076 (0.130)\tData 0.056 (0.106)\tLoss 0.8851 (0.7100)\tAcc 0.625 (0.700)\n",
      "Epoch: [25][6/9]\tTime 0.079 (0.121)\tData 0.059 (0.099)\tLoss 0.2783 (0.6380)\tAcc 1.000 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][7/9]\tTime 0.081 (0.116)\tData 0.060 (0.093)\tLoss 0.6002 (0.6326)\tAcc 0.750 (0.750)\n",
      "Epoch: [25][8/9]\tTime 0.077 (0.111)\tData 0.057 (0.088)\tLoss 0.8838 (0.6640)\tAcc 0.500 (0.719)\n",
      "Epoch: [25][9/9]\tTime 0.079 (0.107)\tData 0.059 (0.085)\tLoss 0.1483 (0.6561)\tAcc 1.000 (0.723)\n",
      "train at epoch 26\n",
      "Epoch: [26][1/5]\tTime 0.291 (0.291)\tData 0.262 (0.262)\tLoss 1.2296 (1.2296)\tAcc 0.438 (0.438)\n",
      "Epoch: [26][2/5]\tTime 0.075 (0.183)\tData 0.050 (0.156)\tLoss 0.7114 (0.9705)\tAcc 0.750 (0.594)\n",
      "Epoch: [26][3/5]\tTime 0.077 (0.148)\tData 0.053 (0.122)\tLoss 0.6091 (0.8500)\tAcc 0.812 (0.667)\n",
      "Epoch: [26][4/5]\tTime 0.078 (0.130)\tData 0.053 (0.105)\tLoss 0.7583 (0.8271)\tAcc 0.625 (0.656)\n",
      "Epoch: [26][5/5]\tTime 0.078 (0.120)\tData 0.054 (0.095)\tLoss 0.7615 (0.8190)\tAcc 0.778 (0.671)\n",
      "validation at epoch 26\n",
      "Epoch: [26][1/9]\tTime 0.308 (0.308)\tData 0.282 (0.282)\tLoss 0.3964 (0.3964)\tAcc 0.938 (0.938)\n",
      "Epoch: [26][2/9]\tTime 0.077 (0.192)\tData 0.050 (0.166)\tLoss 0.9606 (0.6785)\tAcc 0.438 (0.688)\n",
      "Epoch: [26][3/9]\tTime 0.090 (0.158)\tData 0.055 (0.129)\tLoss 0.6271 (0.6613)\tAcc 0.750 (0.708)\n",
      "Epoch: [26][4/9]\tTime 0.073 (0.137)\tData 0.048 (0.109)\tLoss 0.7328 (0.6792)\tAcc 0.688 (0.703)\n",
      "Epoch: [26][5/9]\tTime 0.072 (0.124)\tData 0.052 (0.097)\tLoss 0.7891 (0.7012)\tAcc 0.750 (0.713)\n",
      "Epoch: [26][6/9]\tTime 0.073 (0.115)\tData 0.054 (0.090)\tLoss 0.2749 (0.6301)\tAcc 1.000 (0.760)\n",
      "Epoch: [26][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.085)\tLoss 0.6837 (0.6378)\tAcc 0.688 (0.750)\n",
      "Epoch: [26][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.081)\tLoss 1.1034 (0.6960)\tAcc 0.438 (0.711)\n",
      "Epoch: [26][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.078)\tLoss 0.3390 (0.6905)\tAcc 1.000 (0.715)\n",
      "train at epoch 27\n",
      "Epoch: [27][1/5]\tTime 0.276 (0.276)\tData 0.247 (0.247)\tLoss 0.7645 (0.7645)\tAcc 0.750 (0.750)\n",
      "Epoch: [27][2/5]\tTime 0.088 (0.182)\tData 0.061 (0.154)\tLoss 0.9397 (0.8521)\tAcc 0.625 (0.688)\n",
      "Epoch: [27][3/5]\tTime 0.076 (0.146)\tData 0.052 (0.120)\tLoss 0.6581 (0.7874)\tAcc 0.750 (0.708)\n",
      "Epoch: [27][4/5]\tTime 0.080 (0.130)\tData 0.056 (0.104)\tLoss 0.8131 (0.7938)\tAcc 0.688 (0.703)\n",
      "Epoch: [27][5/5]\tTime 0.080 (0.120)\tData 0.057 (0.095)\tLoss 0.7448 (0.7878)\tAcc 0.667 (0.699)\n",
      "validation at epoch 27\n",
      "Epoch: [27][1/9]\tTime 0.369 (0.369)\tData 0.343 (0.343)\tLoss 0.2932 (0.2932)\tAcc 1.000 (1.000)\n",
      "Epoch: [27][2/9]\tTime 0.069 (0.219)\tData 0.048 (0.195)\tLoss 1.0198 (0.6565)\tAcc 0.562 (0.781)\n",
      "Epoch: [27][3/9]\tTime 0.075 (0.171)\tData 0.052 (0.148)\tLoss 0.6139 (0.6423)\tAcc 0.688 (0.750)\n",
      "Epoch: [27][4/9]\tTime 0.072 (0.146)\tData 0.051 (0.123)\tLoss 0.6571 (0.6460)\tAcc 0.688 (0.734)\n",
      "Epoch: [27][5/9]\tTime 0.077 (0.132)\tData 0.057 (0.110)\tLoss 0.8770 (0.6922)\tAcc 0.625 (0.713)\n",
      "Epoch: [27][6/9]\tTime 0.076 (0.123)\tData 0.057 (0.101)\tLoss 0.3430 (0.6340)\tAcc 1.000 (0.760)\n",
      "Epoch: [27][7/9]\tTime 0.074 (0.116)\tData 0.053 (0.094)\tLoss 0.7630 (0.6524)\tAcc 0.688 (0.750)\n",
      "Epoch: [27][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.089)\tLoss 1.0747 (0.7052)\tAcc 0.562 (0.727)\n",
      "Epoch: [27][9/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 0.1367 (0.6965)\tAcc 1.000 (0.731)\n",
      "train at epoch 28\n",
      "Epoch: [28][1/5]\tTime 0.374 (0.374)\tData 0.347 (0.347)\tLoss 0.5103 (0.5103)\tAcc 0.875 (0.875)\n",
      "Epoch: [28][2/5]\tTime 0.077 (0.226)\tData 0.052 (0.200)\tLoss 1.0768 (0.7935)\tAcc 0.500 (0.688)\n",
      "Epoch: [28][3/5]\tTime 0.077 (0.176)\tData 0.053 (0.151)\tLoss 0.6009 (0.7293)\tAcc 0.750 (0.708)\n",
      "Epoch: [28][4/5]\tTime 0.077 (0.151)\tData 0.054 (0.127)\tLoss 0.8158 (0.7510)\tAcc 0.688 (0.703)\n",
      "Epoch: [28][5/5]\tTime 0.081 (0.137)\tData 0.057 (0.113)\tLoss 0.6280 (0.7358)\tAcc 0.778 (0.712)\n",
      "validation at epoch 28\n",
      "Epoch: [28][1/9]\tTime 0.315 (0.315)\tData 0.289 (0.289)\tLoss 0.3605 (0.3605)\tAcc 0.938 (0.938)\n",
      "Epoch: [28][2/9]\tTime 0.071 (0.193)\tData 0.050 (0.169)\tLoss 0.9809 (0.6707)\tAcc 0.625 (0.781)\n",
      "Epoch: [28][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.131)\tLoss 0.7186 (0.6867)\tAcc 0.625 (0.729)\n",
      "Epoch: [28][4/9]\tTime 0.074 (0.134)\tData 0.052 (0.111)\tLoss 0.7144 (0.6936)\tAcc 0.625 (0.703)\n",
      "Epoch: [28][5/9]\tTime 0.073 (0.121)\tData 0.053 (0.099)\tLoss 0.9366 (0.7422)\tAcc 0.625 (0.688)\n",
      "Epoch: [28][6/9]\tTime 0.072 (0.113)\tData 0.052 (0.091)\tLoss 0.1926 (0.6506)\tAcc 1.000 (0.740)\n",
      "Epoch: [28][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.086)\tLoss 0.6797 (0.6547)\tAcc 0.688 (0.732)\n",
      "Epoch: [28][8/9]\tTime 0.078 (0.104)\tData 0.058 (0.083)\tLoss 1.1177 (0.7126)\tAcc 0.500 (0.703)\n",
      "Epoch: [28][9/9]\tTime 0.075 (0.101)\tData 0.056 (0.080)\tLoss 0.0894 (0.7030)\tAcc 1.000 (0.708)\n",
      "train at epoch 29\n",
      "Epoch: [29][1/5]\tTime 0.368 (0.368)\tData 0.340 (0.340)\tLoss 0.6507 (0.6507)\tAcc 0.750 (0.750)\n",
      "Epoch: [29][2/5]\tTime 0.077 (0.223)\tData 0.053 (0.196)\tLoss 0.7506 (0.7007)\tAcc 0.688 (0.719)\n",
      "Epoch: [29][3/5]\tTime 0.080 (0.175)\tData 0.054 (0.149)\tLoss 1.0487 (0.8167)\tAcc 0.625 (0.688)\n",
      "Epoch: [29][4/5]\tTime 0.076 (0.150)\tData 0.052 (0.125)\tLoss 0.8172 (0.8168)\tAcc 0.562 (0.656)\n",
      "Epoch: [29][5/5]\tTime 0.079 (0.136)\tData 0.055 (0.111)\tLoss 0.4965 (0.7773)\tAcc 0.889 (0.685)\n",
      "validation at epoch 29\n",
      "Epoch: [29][1/9]\tTime 0.371 (0.371)\tData 0.343 (0.343)\tLoss 0.3044 (0.3044)\tAcc 0.938 (0.938)\n",
      "Epoch: [29][2/9]\tTime 0.068 (0.220)\tData 0.047 (0.195)\tLoss 1.0513 (0.6779)\tAcc 0.500 (0.719)\n",
      "Epoch: [29][3/9]\tTime 0.074 (0.171)\tData 0.053 (0.148)\tLoss 0.7396 (0.6985)\tAcc 0.562 (0.667)\n",
      "Epoch: [29][4/9]\tTime 0.073 (0.147)\tData 0.053 (0.124)\tLoss 0.6081 (0.6759)\tAcc 0.812 (0.703)\n",
      "Epoch: [29][5/9]\tTime 0.074 (0.132)\tData 0.054 (0.110)\tLoss 0.8401 (0.7087)\tAcc 0.625 (0.688)\n",
      "Epoch: [29][6/9]\tTime 0.074 (0.122)\tData 0.055 (0.101)\tLoss 0.2785 (0.6370)\tAcc 1.000 (0.740)\n",
      "Epoch: [29][7/9]\tTime 0.074 (0.116)\tData 0.055 (0.094)\tLoss 0.5985 (0.6315)\tAcc 0.875 (0.759)\n",
      "Epoch: [29][8/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 1.0794 (0.6875)\tAcc 0.500 (0.727)\n",
      "Epoch: [29][9/9]\tTime 0.074 (0.106)\tData 0.056 (0.086)\tLoss 0.3082 (0.6817)\tAcc 1.000 (0.731)\n",
      "train at epoch 30\n",
      "Epoch: [30][1/5]\tTime 0.338 (0.338)\tData 0.308 (0.308)\tLoss 0.9939 (0.9939)\tAcc 0.500 (0.500)\n",
      "Epoch: [30][2/5]\tTime 0.074 (0.206)\tData 0.050 (0.179)\tLoss 0.5824 (0.7881)\tAcc 0.750 (0.625)\n",
      "Epoch: [30][3/5]\tTime 0.077 (0.163)\tData 0.053 (0.137)\tLoss 0.6057 (0.7273)\tAcc 0.688 (0.646)\n",
      "Epoch: [30][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.116)\tLoss 0.6073 (0.6973)\tAcc 0.688 (0.656)\n",
      "Epoch: [30][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.104)\tLoss 0.9018 (0.7225)\tAcc 0.444 (0.630)\n",
      "validation at epoch 30\n",
      "Epoch: [30][1/9]\tTime 0.319 (0.319)\tData 0.291 (0.291)\tLoss 0.3439 (0.3439)\tAcc 0.938 (0.938)\n",
      "Epoch: [30][2/9]\tTime 0.071 (0.195)\tData 0.050 (0.170)\tLoss 0.9706 (0.6572)\tAcc 0.562 (0.750)\n",
      "Epoch: [30][3/9]\tTime 0.076 (0.155)\tData 0.053 (0.131)\tLoss 0.7887 (0.7010)\tAcc 0.625 (0.708)\n",
      "Epoch: [30][4/9]\tTime 0.074 (0.135)\tData 0.051 (0.111)\tLoss 0.6684 (0.6929)\tAcc 0.812 (0.734)\n",
      "Epoch: [30][5/9]\tTime 0.071 (0.122)\tData 0.051 (0.099)\tLoss 0.7861 (0.7115)\tAcc 0.688 (0.725)\n",
      "Epoch: [30][6/9]\tTime 0.074 (0.114)\tData 0.055 (0.092)\tLoss 0.2886 (0.6410)\tAcc 1.000 (0.771)\n",
      "Epoch: [30][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.086)\tLoss 0.7038 (0.6500)\tAcc 0.812 (0.777)\n",
      "Epoch: [30][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.082)\tLoss 1.2409 (0.7239)\tAcc 0.500 (0.742)\n",
      "Epoch: [30][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.1442 (0.7149)\tAcc 1.000 (0.746)\n",
      "train at epoch 31\n",
      "Epoch: [31][1/5]\tTime 0.334 (0.334)\tData 0.304 (0.304)\tLoss 0.4875 (0.4875)\tAcc 0.875 (0.875)\n",
      "Epoch: [31][2/5]\tTime 0.075 (0.205)\tData 0.051 (0.178)\tLoss 0.7854 (0.6365)\tAcc 0.625 (0.750)\n",
      "Epoch: [31][3/5]\tTime 0.077 (0.162)\tData 0.053 (0.136)\tLoss 0.7723 (0.6818)\tAcc 0.750 (0.750)\n",
      "Epoch: [31][4/5]\tTime 0.082 (0.142)\tData 0.058 (0.116)\tLoss 0.7765 (0.7055)\tAcc 0.688 (0.734)\n",
      "Epoch: [31][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.104)\tLoss 0.6812 (0.7025)\tAcc 0.778 (0.740)\n",
      "validation at epoch 31\n",
      "Epoch: [31][1/9]\tTime 0.359 (0.359)\tData 0.330 (0.330)\tLoss 0.2906 (0.2906)\tAcc 0.938 (0.938)\n",
      "Epoch: [31][2/9]\tTime 0.075 (0.217)\tData 0.052 (0.191)\tLoss 1.0222 (0.6564)\tAcc 0.625 (0.781)\n",
      "Epoch: [31][3/9]\tTime 0.071 (0.168)\tData 0.051 (0.144)\tLoss 0.5798 (0.6308)\tAcc 0.688 (0.750)\n",
      "Epoch: [31][4/9]\tTime 0.074 (0.145)\tData 0.053 (0.122)\tLoss 0.6753 (0.6420)\tAcc 0.688 (0.734)\n",
      "Epoch: [31][5/9]\tTime 0.077 (0.131)\tData 0.057 (0.109)\tLoss 0.8060 (0.6748)\tAcc 0.625 (0.713)\n",
      "Epoch: [31][6/9]\tTime 0.074 (0.122)\tData 0.054 (0.100)\tLoss 0.2838 (0.6096)\tAcc 1.000 (0.760)\n",
      "Epoch: [31][7/9]\tTime 0.074 (0.115)\tData 0.055 (0.093)\tLoss 0.5062 (0.5948)\tAcc 0.875 (0.777)\n",
      "Epoch: [31][8/9]\tTime 0.074 (0.110)\tData 0.054 (0.088)\tLoss 1.0323 (0.6495)\tAcc 0.500 (0.742)\n",
      "Epoch: [31][9/9]\tTime 0.073 (0.106)\tData 0.055 (0.085)\tLoss 0.2428 (0.6433)\tAcc 1.000 (0.746)\n",
      "train at epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32][1/5]\tTime 0.302 (0.302)\tData 0.273 (0.273)\tLoss 0.7457 (0.7457)\tAcc 0.688 (0.688)\n",
      "Epoch: [32][2/5]\tTime 0.074 (0.188)\tData 0.050 (0.161)\tLoss 0.9811 (0.8634)\tAcc 0.625 (0.656)\n",
      "Epoch: [32][3/5]\tTime 0.078 (0.151)\tData 0.054 (0.126)\tLoss 0.6189 (0.7819)\tAcc 0.750 (0.688)\n",
      "Epoch: [32][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.108)\tLoss 0.8296 (0.7938)\tAcc 0.562 (0.656)\n",
      "Epoch: [32][5/5]\tTime 0.079 (0.122)\tData 0.056 (0.097)\tLoss 0.6677 (0.7783)\tAcc 0.667 (0.658)\n",
      "validation at epoch 32\n",
      "Epoch: [32][1/9]\tTime 0.361 (0.361)\tData 0.334 (0.334)\tLoss 0.3603 (0.3603)\tAcc 0.875 (0.875)\n",
      "Epoch: [32][2/9]\tTime 0.071 (0.216)\tData 0.049 (0.192)\tLoss 1.0524 (0.7063)\tAcc 0.562 (0.719)\n",
      "Epoch: [32][3/9]\tTime 0.074 (0.168)\tData 0.052 (0.145)\tLoss 0.6360 (0.6829)\tAcc 0.688 (0.708)\n",
      "Epoch: [32][4/9]\tTime 0.072 (0.144)\tData 0.052 (0.122)\tLoss 0.7631 (0.7029)\tAcc 0.625 (0.688)\n",
      "Epoch: [32][5/9]\tTime 0.073 (0.130)\tData 0.054 (0.108)\tLoss 0.8463 (0.7316)\tAcc 0.562 (0.663)\n",
      "Epoch: [32][6/9]\tTime 0.073 (0.121)\tData 0.053 (0.099)\tLoss 0.2339 (0.6487)\tAcc 1.000 (0.719)\n",
      "Epoch: [32][7/9]\tTime 0.072 (0.114)\tData 0.054 (0.093)\tLoss 0.6683 (0.6515)\tAcc 0.750 (0.723)\n",
      "Epoch: [32][8/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 1.1730 (0.7167)\tAcc 0.500 (0.695)\n",
      "Epoch: [32][9/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.2396 (0.7093)\tAcc 1.000 (0.700)\n",
      "train at epoch 33\n",
      "Epoch: [33][1/5]\tTime 0.329 (0.329)\tData 0.302 (0.302)\tLoss 0.6548 (0.6548)\tAcc 0.750 (0.750)\n",
      "Epoch: [33][2/5]\tTime 0.075 (0.202)\tData 0.051 (0.176)\tLoss 1.0143 (0.8345)\tAcc 0.562 (0.656)\n",
      "Epoch: [33][3/5]\tTime 0.080 (0.162)\tData 0.054 (0.136)\tLoss 0.6167 (0.7619)\tAcc 0.875 (0.729)\n",
      "Epoch: [33][4/5]\tTime 0.078 (0.141)\tData 0.052 (0.115)\tLoss 0.8383 (0.7810)\tAcc 0.625 (0.703)\n",
      "Epoch: [33][5/5]\tTime 0.081 (0.129)\tData 0.057 (0.103)\tLoss 0.8459 (0.7890)\tAcc 0.667 (0.699)\n",
      "validation at epoch 33\n",
      "Epoch: [33][1/9]\tTime 0.333 (0.333)\tData 0.305 (0.305)\tLoss 0.3451 (0.3451)\tAcc 0.938 (0.938)\n",
      "Epoch: [33][2/9]\tTime 0.074 (0.204)\tData 0.052 (0.179)\tLoss 1.0825 (0.7138)\tAcc 0.625 (0.781)\n",
      "Epoch: [33][3/9]\tTime 0.079 (0.162)\tData 0.058 (0.138)\tLoss 0.5764 (0.6680)\tAcc 0.688 (0.750)\n",
      "Epoch: [33][4/9]\tTime 0.081 (0.142)\tData 0.059 (0.118)\tLoss 0.6386 (0.6606)\tAcc 0.812 (0.766)\n",
      "Epoch: [33][5/9]\tTime 0.078 (0.129)\tData 0.057 (0.106)\tLoss 0.7829 (0.6851)\tAcc 0.625 (0.738)\n",
      "Epoch: [33][6/9]\tTime 0.080 (0.121)\tData 0.059 (0.098)\tLoss 0.2738 (0.6165)\tAcc 1.000 (0.781)\n",
      "Epoch: [33][7/9]\tTime 0.080 (0.115)\tData 0.060 (0.093)\tLoss 0.6745 (0.6248)\tAcc 0.812 (0.786)\n",
      "Epoch: [33][8/9]\tTime 0.080 (0.111)\tData 0.059 (0.089)\tLoss 1.0092 (0.6729)\tAcc 0.438 (0.742)\n",
      "Epoch: [33][9/9]\tTime 0.078 (0.107)\tData 0.059 (0.085)\tLoss 0.1701 (0.6651)\tAcc 1.000 (0.746)\n",
      "train at epoch 34\n",
      "Epoch: [34][1/5]\tTime 0.305 (0.305)\tData 0.272 (0.272)\tLoss 0.6753 (0.6753)\tAcc 0.750 (0.750)\n",
      "Epoch: [34][2/5]\tTime 0.081 (0.193)\tData 0.054 (0.163)\tLoss 0.8856 (0.7805)\tAcc 0.688 (0.719)\n",
      "Epoch: [34][3/5]\tTime 0.084 (0.157)\tData 0.059 (0.128)\tLoss 0.7190 (0.7600)\tAcc 0.688 (0.708)\n",
      "Epoch: [34][4/5]\tTime 0.086 (0.139)\tData 0.061 (0.112)\tLoss 0.7618 (0.7604)\tAcc 0.625 (0.688)\n",
      "Epoch: [34][5/5]\tTime 0.086 (0.128)\tData 0.061 (0.102)\tLoss 0.8143 (0.7671)\tAcc 0.667 (0.685)\n",
      "validation at epoch 34\n",
      "Epoch: [34][1/9]\tTime 0.313 (0.313)\tData 0.289 (0.289)\tLoss 0.3943 (0.3943)\tAcc 0.938 (0.938)\n",
      "Epoch: [34][2/9]\tTime 0.073 (0.193)\tData 0.052 (0.171)\tLoss 1.0170 (0.7057)\tAcc 0.500 (0.719)\n",
      "Epoch: [34][3/9]\tTime 0.078 (0.155)\tData 0.058 (0.133)\tLoss 0.7021 (0.7045)\tAcc 0.562 (0.667)\n",
      "Epoch: [34][4/9]\tTime 0.083 (0.137)\tData 0.063 (0.115)\tLoss 0.6710 (0.6961)\tAcc 0.688 (0.672)\n",
      "Epoch: [34][5/9]\tTime 0.079 (0.125)\tData 0.059 (0.104)\tLoss 0.8753 (0.7319)\tAcc 0.625 (0.663)\n",
      "Epoch: [34][6/9]\tTime 0.079 (0.118)\tData 0.059 (0.097)\tLoss 0.2254 (0.6475)\tAcc 1.000 (0.719)\n",
      "Epoch: [34][7/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 0.6651 (0.6500)\tAcc 0.688 (0.714)\n",
      "Epoch: [34][8/9]\tTime 0.080 (0.108)\tData 0.060 (0.087)\tLoss 1.0716 (0.7027)\tAcc 0.375 (0.672)\n",
      "Epoch: [34][9/9]\tTime 0.080 (0.105)\tData 0.059 (0.084)\tLoss 0.2690 (0.6961)\tAcc 1.000 (0.677)\n",
      "train at epoch 35\n",
      "Epoch: [35][1/5]\tTime 0.330 (0.330)\tData 0.302 (0.302)\tLoss 0.9286 (0.9286)\tAcc 0.688 (0.688)\n",
      "Epoch: [35][2/5]\tTime 0.084 (0.207)\tData 0.058 (0.180)\tLoss 0.6914 (0.8100)\tAcc 0.562 (0.625)\n",
      "Epoch: [35][3/5]\tTime 0.084 (0.166)\tData 0.059 (0.140)\tLoss 0.6734 (0.7645)\tAcc 0.750 (0.667)\n",
      "Epoch: [35][4/5]\tTime 0.086 (0.146)\tData 0.061 (0.120)\tLoss 0.6913 (0.7462)\tAcc 0.688 (0.672)\n",
      "Epoch: [35][5/5]\tTime 0.086 (0.134)\tData 0.061 (0.108)\tLoss 0.5615 (0.7234)\tAcc 0.778 (0.685)\n",
      "validation at epoch 35\n",
      "Epoch: [35][1/9]\tTime 0.359 (0.359)\tData 0.328 (0.328)\tLoss 0.2903 (0.2903)\tAcc 0.938 (0.938)\n",
      "Epoch: [35][2/9]\tTime 0.078 (0.218)\tData 0.049 (0.189)\tLoss 0.9515 (0.6209)\tAcc 0.562 (0.750)\n",
      "Epoch: [35][3/9]\tTime 0.089 (0.175)\tData 0.053 (0.143)\tLoss 0.7008 (0.6476)\tAcc 0.625 (0.708)\n",
      "Epoch: [35][4/9]\tTime 0.068 (0.149)\tData 0.046 (0.119)\tLoss 0.5682 (0.6277)\tAcc 0.812 (0.734)\n",
      "Epoch: [35][5/9]\tTime 0.079 (0.135)\tData 0.058 (0.107)\tLoss 0.8232 (0.6668)\tAcc 0.625 (0.713)\n",
      "Epoch: [35][6/9]\tTime 0.079 (0.125)\tData 0.059 (0.099)\tLoss 0.2261 (0.5933)\tAcc 1.000 (0.760)\n",
      "Epoch: [35][7/9]\tTime 0.079 (0.119)\tData 0.059 (0.093)\tLoss 0.6340 (0.5992)\tAcc 0.750 (0.759)\n",
      "Epoch: [35][8/9]\tTime 0.079 (0.114)\tData 0.059 (0.089)\tLoss 1.0994 (0.6617)\tAcc 0.438 (0.719)\n",
      "Epoch: [35][9/9]\tTime 0.080 (0.110)\tData 0.061 (0.086)\tLoss 0.1158 (0.6533)\tAcc 1.000 (0.723)\n",
      "train at epoch 36\n",
      "Epoch: [36][1/5]\tTime 0.341 (0.341)\tData 0.311 (0.311)\tLoss 0.6355 (0.6355)\tAcc 0.812 (0.812)\n",
      "Epoch: [36][2/5]\tTime 0.081 (0.211)\tData 0.056 (0.184)\tLoss 0.7185 (0.6770)\tAcc 0.812 (0.812)\n",
      "Epoch: [36][3/5]\tTime 0.084 (0.169)\tData 0.059 (0.142)\tLoss 0.8523 (0.7354)\tAcc 0.625 (0.750)\n",
      "Epoch: [36][4/5]\tTime 0.086 (0.148)\tData 0.062 (0.122)\tLoss 0.8256 (0.7580)\tAcc 0.562 (0.703)\n",
      "Epoch: [36][5/5]\tTime 0.086 (0.136)\tData 0.062 (0.110)\tLoss 0.5333 (0.7303)\tAcc 0.778 (0.712)\n",
      "validation at epoch 36\n",
      "Epoch: [36][1/9]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 0.2587 (0.2587)\tAcc 0.938 (0.938)\n",
      "Epoch: [36][2/9]\tTime 0.079 (0.206)\tData 0.052 (0.179)\tLoss 1.1627 (0.7107)\tAcc 0.438 (0.688)\n",
      "Epoch: [36][3/9]\tTime 0.081 (0.165)\tData 0.053 (0.137)\tLoss 0.5667 (0.6627)\tAcc 0.750 (0.708)\n",
      "Epoch: [36][4/9]\tTime 0.078 (0.143)\tData 0.056 (0.117)\tLoss 0.7858 (0.6935)\tAcc 0.688 (0.703)\n",
      "Epoch: [36][5/9]\tTime 0.076 (0.130)\tData 0.057 (0.105)\tLoss 0.7554 (0.7059)\tAcc 0.688 (0.700)\n",
      "Epoch: [36][6/9]\tTime 0.080 (0.121)\tData 0.060 (0.097)\tLoss 0.2448 (0.6290)\tAcc 1.000 (0.750)\n",
      "Epoch: [36][7/9]\tTime 0.080 (0.115)\tData 0.060 (0.092)\tLoss 0.5987 (0.6247)\tAcc 0.688 (0.741)\n",
      "Epoch: [36][8/9]\tTime 0.081 (0.111)\tData 0.061 (0.088)\tLoss 1.1836 (0.6946)\tAcc 0.500 (0.711)\n",
      "Epoch: [36][9/9]\tTime 0.079 (0.108)\tData 0.060 (0.085)\tLoss 0.2523 (0.6877)\tAcc 1.000 (0.715)\n",
      "train at epoch 37\n",
      "Epoch: [37][1/5]\tTime 0.376 (0.376)\tData 0.346 (0.346)\tLoss 0.4489 (0.4489)\tAcc 0.812 (0.812)\n",
      "Epoch: [37][2/5]\tTime 0.073 (0.225)\tData 0.049 (0.197)\tLoss 0.7786 (0.6138)\tAcc 0.688 (0.750)\n",
      "Epoch: [37][3/5]\tTime 0.077 (0.175)\tData 0.053 (0.149)\tLoss 0.8016 (0.6764)\tAcc 0.750 (0.750)\n",
      "Epoch: [37][4/5]\tTime 0.084 (0.152)\tData 0.059 (0.127)\tLoss 0.8464 (0.7189)\tAcc 0.625 (0.719)\n",
      "Epoch: [37][5/5]\tTime 0.085 (0.139)\tData 0.061 (0.113)\tLoss 0.9537 (0.7478)\tAcc 0.556 (0.699)\n",
      "validation at epoch 37\n",
      "Epoch: [37][1/9]\tTime 0.332 (0.332)\tData 0.293 (0.293)\tLoss 0.3120 (0.3120)\tAcc 0.938 (0.938)\n",
      "Epoch: [37][2/9]\tTime 0.066 (0.199)\tData 0.044 (0.168)\tLoss 0.9625 (0.6372)\tAcc 0.688 (0.812)\n",
      "Epoch: [37][3/9]\tTime 0.079 (0.159)\tData 0.057 (0.131)\tLoss 0.6405 (0.6383)\tAcc 0.750 (0.792)\n",
      "Epoch: [37][4/9]\tTime 0.073 (0.138)\tData 0.053 (0.112)\tLoss 0.6540 (0.6423)\tAcc 0.750 (0.781)\n",
      "Epoch: [37][5/9]\tTime 0.073 (0.125)\tData 0.053 (0.100)\tLoss 0.7863 (0.6711)\tAcc 0.625 (0.750)\n",
      "Epoch: [37][6/9]\tTime 0.079 (0.117)\tData 0.059 (0.093)\tLoss 0.2062 (0.5936)\tAcc 1.000 (0.792)\n",
      "Epoch: [37][7/9]\tTime 0.080 (0.112)\tData 0.060 (0.088)\tLoss 0.4616 (0.5747)\tAcc 0.750 (0.786)\n",
      "Epoch: [37][8/9]\tTime 0.080 (0.108)\tData 0.059 (0.085)\tLoss 1.1637 (0.6484)\tAcc 0.500 (0.750)\n",
      "Epoch: [37][9/9]\tTime 0.079 (0.105)\tData 0.059 (0.082)\tLoss 0.2082 (0.6416)\tAcc 1.000 (0.754)\n",
      "train at epoch 38\n",
      "Epoch: [38][1/5]\tTime 0.316 (0.316)\tData 0.284 (0.284)\tLoss 1.1624 (1.1624)\tAcc 0.438 (0.438)\n",
      "Epoch: [38][2/5]\tTime 0.081 (0.198)\tData 0.056 (0.170)\tLoss 0.8432 (1.0028)\tAcc 0.625 (0.531)\n",
      "Epoch: [38][3/5]\tTime 0.086 (0.161)\tData 0.061 (0.134)\tLoss 0.5703 (0.8586)\tAcc 0.812 (0.625)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][4/5]\tTime 0.084 (0.141)\tData 0.060 (0.115)\tLoss 0.7252 (0.8253)\tAcc 0.688 (0.641)\n",
      "Epoch: [38][5/5]\tTime 0.081 (0.129)\tData 0.057 (0.104)\tLoss 0.6381 (0.8022)\tAcc 0.778 (0.658)\n",
      "validation at epoch 38\n",
      "Epoch: [38][1/9]\tTime 0.326 (0.326)\tData 0.300 (0.300)\tLoss 0.3726 (0.3726)\tAcc 0.938 (0.938)\n",
      "Epoch: [38][2/9]\tTime 0.080 (0.203)\tData 0.055 (0.178)\tLoss 0.9425 (0.6576)\tAcc 0.562 (0.750)\n",
      "Epoch: [38][3/9]\tTime 0.077 (0.161)\tData 0.054 (0.136)\tLoss 0.6546 (0.6566)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][4/9]\tTime 0.079 (0.140)\tData 0.058 (0.117)\tLoss 0.7506 (0.6801)\tAcc 0.750 (0.750)\n",
      "Epoch: [38][5/9]\tTime 0.080 (0.128)\tData 0.060 (0.105)\tLoss 0.8913 (0.7223)\tAcc 0.688 (0.738)\n",
      "Epoch: [38][6/9]\tTime 0.075 (0.119)\tData 0.055 (0.097)\tLoss 0.2849 (0.6494)\tAcc 1.000 (0.781)\n",
      "Epoch: [38][7/9]\tTime 0.073 (0.113)\tData 0.053 (0.091)\tLoss 0.6617 (0.6512)\tAcc 0.688 (0.768)\n",
      "Epoch: [38][8/9]\tTime 0.074 (0.108)\tData 0.054 (0.086)\tLoss 1.1053 (0.7079)\tAcc 0.500 (0.734)\n",
      "Epoch: [38][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.1775 (0.6998)\tAcc 1.000 (0.738)\n",
      "train at epoch 39\n",
      "Epoch: [39][1/5]\tTime 0.292 (0.292)\tData 0.261 (0.261)\tLoss 0.9612 (0.9612)\tAcc 0.562 (0.562)\n",
      "Epoch: [39][2/5]\tTime 0.322 (0.307)\tData 0.297 (0.279)\tLoss 0.6436 (0.8024)\tAcc 0.750 (0.656)\n",
      "Epoch: [39][3/5]\tTime 0.078 (0.231)\tData 0.054 (0.204)\tLoss 0.7053 (0.7701)\tAcc 0.812 (0.708)\n",
      "Epoch: [39][4/5]\tTime 0.078 (0.192)\tData 0.054 (0.167)\tLoss 0.6815 (0.7479)\tAcc 0.812 (0.734)\n",
      "Epoch: [39][5/5]\tTime 0.077 (0.169)\tData 0.054 (0.144)\tLoss 0.7216 (0.7447)\tAcc 0.778 (0.740)\n",
      "validation at epoch 39\n",
      "Epoch: [39][1/9]\tTime 0.355 (0.355)\tData 0.331 (0.331)\tLoss 0.3992 (0.3992)\tAcc 0.938 (0.938)\n",
      "Epoch: [39][2/9]\tTime 0.072 (0.213)\tData 0.050 (0.190)\tLoss 0.9513 (0.6753)\tAcc 0.438 (0.688)\n",
      "Epoch: [39][3/9]\tTime 0.077 (0.168)\tData 0.052 (0.144)\tLoss 0.7608 (0.7038)\tAcc 0.688 (0.688)\n",
      "Epoch: [39][4/9]\tTime 0.068 (0.143)\tData 0.049 (0.120)\tLoss 0.6472 (0.6896)\tAcc 0.625 (0.672)\n",
      "Epoch: [39][5/9]\tTime 0.074 (0.129)\tData 0.055 (0.107)\tLoss 0.8855 (0.7288)\tAcc 0.562 (0.650)\n",
      "Epoch: [39][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.3592 (0.6672)\tAcc 0.938 (0.698)\n",
      "Epoch: [39][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.7285 (0.6760)\tAcc 0.625 (0.688)\n",
      "Epoch: [39][8/9]\tTime 0.076 (0.108)\tData 0.056 (0.088)\tLoss 0.8819 (0.7017)\tAcc 0.750 (0.695)\n",
      "Epoch: [39][9/9]\tTime 0.074 (0.105)\tData 0.055 (0.084)\tLoss 0.3892 (0.6969)\tAcc 1.000 (0.700)\n",
      "train at epoch 40\n",
      "Epoch: [40][1/5]\tTime 0.314 (0.314)\tData 0.284 (0.284)\tLoss 0.9013 (0.9013)\tAcc 0.625 (0.625)\n",
      "Epoch: [40][2/5]\tTime 0.075 (0.194)\tData 0.050 (0.167)\tLoss 0.5311 (0.7162)\tAcc 0.750 (0.688)\n",
      "Epoch: [40][3/5]\tTime 0.076 (0.155)\tData 0.052 (0.129)\tLoss 0.9174 (0.7833)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.110)\tLoss 0.6174 (0.7418)\tAcc 0.812 (0.719)\n",
      "Epoch: [40][5/5]\tTime 0.081 (0.124)\tData 0.057 (0.099)\tLoss 0.5416 (0.7171)\tAcc 0.778 (0.726)\n",
      "validation at epoch 40\n",
      "Epoch: [40][1/9]\tTime 0.236 (0.236)\tData 0.212 (0.212)\tLoss 0.4180 (0.4180)\tAcc 0.938 (0.938)\n",
      "Epoch: [40][2/9]\tTime 0.074 (0.155)\tData 0.050 (0.131)\tLoss 1.0417 (0.7298)\tAcc 0.438 (0.688)\n",
      "Epoch: [40][3/9]\tTime 0.074 (0.128)\tData 0.051 (0.104)\tLoss 0.7827 (0.7474)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][4/9]\tTime 0.073 (0.114)\tData 0.051 (0.091)\tLoss 0.6649 (0.7268)\tAcc 0.688 (0.688)\n",
      "Epoch: [40][5/9]\tTime 0.073 (0.106)\tData 0.053 (0.083)\tLoss 0.7866 (0.7388)\tAcc 0.625 (0.675)\n",
      "Epoch: [40][6/9]\tTime 0.073 (0.100)\tData 0.053 (0.078)\tLoss 0.3101 (0.6673)\tAcc 1.000 (0.729)\n",
      "Epoch: [40][7/9]\tTime 0.073 (0.096)\tData 0.053 (0.075)\tLoss 0.7279 (0.6760)\tAcc 0.688 (0.723)\n",
      "Epoch: [40][8/9]\tTime 0.074 (0.094)\tData 0.054 (0.072)\tLoss 0.9685 (0.7126)\tAcc 0.500 (0.695)\n",
      "Epoch: [40][9/9]\tTime 0.078 (0.092)\tData 0.059 (0.071)\tLoss 0.2533 (0.7055)\tAcc 1.000 (0.700)\n",
      "train at epoch 41\n",
      "Epoch: [41][1/5]\tTime 0.379 (0.379)\tData 0.351 (0.351)\tLoss 0.9630 (0.9630)\tAcc 0.500 (0.500)\n",
      "Epoch: [41][2/5]\tTime 0.076 (0.227)\tData 0.051 (0.201)\tLoss 0.6306 (0.7968)\tAcc 0.812 (0.656)\n",
      "Epoch: [41][3/5]\tTime 0.077 (0.177)\tData 0.053 (0.152)\tLoss 0.6907 (0.7614)\tAcc 0.625 (0.646)\n",
      "Epoch: [41][4/5]\tTime 0.077 (0.152)\tData 0.054 (0.127)\tLoss 0.7400 (0.7561)\tAcc 0.750 (0.672)\n",
      "Epoch: [41][5/5]\tTime 0.080 (0.138)\tData 0.057 (0.113)\tLoss 0.7842 (0.7595)\tAcc 0.778 (0.685)\n",
      "validation at epoch 41\n",
      "Epoch: [41][1/9]\tTime 0.325 (0.325)\tData 0.298 (0.298)\tLoss 0.3472 (0.3472)\tAcc 0.875 (0.875)\n",
      "Epoch: [41][2/9]\tTime 0.068 (0.197)\tData 0.046 (0.172)\tLoss 0.9421 (0.6447)\tAcc 0.438 (0.656)\n",
      "Epoch: [41][3/9]\tTime 0.075 (0.156)\tData 0.052 (0.132)\tLoss 0.6140 (0.6344)\tAcc 0.812 (0.708)\n",
      "Epoch: [41][4/9]\tTime 0.073 (0.135)\tData 0.050 (0.112)\tLoss 0.6578 (0.6403)\tAcc 0.688 (0.703)\n",
      "Epoch: [41][5/9]\tTime 0.071 (0.122)\tData 0.052 (0.100)\tLoss 0.8149 (0.6752)\tAcc 0.688 (0.700)\n",
      "Epoch: [41][6/9]\tTime 0.073 (0.114)\tData 0.054 (0.092)\tLoss 0.2675 (0.6073)\tAcc 1.000 (0.750)\n",
      "Epoch: [41][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.7262 (0.6243)\tAcc 0.562 (0.723)\n",
      "Epoch: [41][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.9740 (0.6680)\tAcc 0.562 (0.703)\n",
      "Epoch: [41][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.079)\tLoss 0.1129 (0.6594)\tAcc 1.000 (0.708)\n",
      "train at epoch 42\n",
      "Epoch: [42][1/5]\tTime 0.330 (0.330)\tData 0.302 (0.302)\tLoss 0.5832 (0.5832)\tAcc 0.812 (0.812)\n",
      "Epoch: [42][2/5]\tTime 0.075 (0.202)\tData 0.051 (0.177)\tLoss 0.7836 (0.6834)\tAcc 0.688 (0.750)\n",
      "Epoch: [42][3/5]\tTime 0.077 (0.161)\tData 0.054 (0.136)\tLoss 1.0730 (0.8132)\tAcc 0.500 (0.667)\n",
      "Epoch: [42][4/5]\tTime 0.077 (0.140)\tData 0.054 (0.115)\tLoss 0.4175 (0.7143)\tAcc 0.812 (0.703)\n",
      "Epoch: [42][5/5]\tTime 0.081 (0.128)\tData 0.058 (0.104)\tLoss 0.7423 (0.7178)\tAcc 0.667 (0.699)\n",
      "validation at epoch 42\n",
      "Epoch: [42][1/9]\tTime 0.274 (0.274)\tData 0.251 (0.251)\tLoss 0.2739 (0.2739)\tAcc 0.938 (0.938)\n",
      "Epoch: [42][2/9]\tTime 0.086 (0.180)\tData 0.065 (0.158)\tLoss 0.8507 (0.5623)\tAcc 0.438 (0.688)\n",
      "Epoch: [42][3/9]\tTime 0.074 (0.145)\tData 0.053 (0.123)\tLoss 0.6525 (0.5924)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][4/9]\tTime 0.073 (0.127)\tData 0.053 (0.105)\tLoss 0.6482 (0.6063)\tAcc 0.688 (0.688)\n",
      "Epoch: [42][5/9]\tTime 0.077 (0.117)\tData 0.055 (0.095)\tLoss 0.8329 (0.6516)\tAcc 0.750 (0.700)\n",
      "Epoch: [42][6/9]\tTime 0.071 (0.109)\tData 0.053 (0.088)\tLoss 0.2363 (0.5824)\tAcc 1.000 (0.750)\n",
      "Epoch: [42][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.7006 (0.5993)\tAcc 0.688 (0.741)\n",
      "Epoch: [42][8/9]\tTime 0.075 (0.100)\tData 0.055 (0.080)\tLoss 1.1019 (0.6621)\tAcc 0.500 (0.711)\n",
      "Epoch: [42][9/9]\tTime 0.072 (0.097)\tData 0.054 (0.077)\tLoss 0.1281 (0.6539)\tAcc 1.000 (0.715)\n",
      "train at epoch 43\n",
      "Epoch: [43][1/5]\tTime 0.350 (0.350)\tData 0.320 (0.320)\tLoss 0.8954 (0.8954)\tAcc 0.688 (0.688)\n",
      "Epoch: [43][2/5]\tTime 0.073 (0.211)\tData 0.048 (0.184)\tLoss 0.7339 (0.8146)\tAcc 0.750 (0.719)\n",
      "Epoch: [43][3/5]\tTime 0.077 (0.167)\tData 0.053 (0.140)\tLoss 0.7976 (0.8090)\tAcc 0.625 (0.688)\n",
      "Epoch: [43][4/5]\tTime 0.077 (0.144)\tData 0.054 (0.119)\tLoss 0.6783 (0.7763)\tAcc 0.812 (0.719)\n",
      "Epoch: [43][5/5]\tTime 0.081 (0.131)\tData 0.057 (0.106)\tLoss 0.4935 (0.7414)\tAcc 0.778 (0.726)\n",
      "validation at epoch 43\n",
      "Epoch: [43][1/9]\tTime 0.335 (0.335)\tData 0.311 (0.311)\tLoss 0.3043 (0.3043)\tAcc 0.938 (0.938)\n",
      "Epoch: [43][2/9]\tTime 0.072 (0.203)\tData 0.050 (0.181)\tLoss 0.9470 (0.6257)\tAcc 0.500 (0.719)\n",
      "Epoch: [43][3/9]\tTime 0.074 (0.160)\tData 0.053 (0.138)\tLoss 0.5224 (0.5912)\tAcc 0.812 (0.750)\n",
      "Epoch: [43][4/9]\tTime 0.072 (0.138)\tData 0.053 (0.117)\tLoss 0.6680 (0.6104)\tAcc 0.750 (0.750)\n",
      "Epoch: [43][5/9]\tTime 0.074 (0.125)\tData 0.055 (0.104)\tLoss 0.8052 (0.6494)\tAcc 0.688 (0.738)\n",
      "Epoch: [43][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.2489 (0.5826)\tAcc 1.000 (0.781)\n",
      "Epoch: [43][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.090)\tLoss 0.6452 (0.5916)\tAcc 0.750 (0.777)\n",
      "Epoch: [43][8/9]\tTime 0.074 (0.106)\tData 0.055 (0.086)\tLoss 0.9907 (0.6415)\tAcc 0.688 (0.766)\n",
      "Epoch: [43][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.082)\tLoss 0.1821 (0.6344)\tAcc 1.000 (0.769)\n",
      "train at epoch 44\n",
      "Epoch: [44][1/5]\tTime 0.355 (0.355)\tData 0.326 (0.326)\tLoss 0.5859 (0.5859)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][2/5]\tTime 0.074 (0.214)\tData 0.050 (0.188)\tLoss 0.6622 (0.6240)\tAcc 0.688 (0.688)\n",
      "Epoch: [44][3/5]\tTime 0.078 (0.169)\tData 0.054 (0.143)\tLoss 0.7279 (0.6587)\tAcc 0.625 (0.667)\n",
      "Epoch: [44][4/5]\tTime 0.076 (0.146)\tData 0.053 (0.121)\tLoss 0.6742 (0.6625)\tAcc 0.750 (0.688)\n",
      "Epoch: [44][5/5]\tTime 0.081 (0.133)\tData 0.058 (0.108)\tLoss 0.6215 (0.6575)\tAcc 0.556 (0.671)\n",
      "validation at epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [44][1/9]\tTime 0.335 (0.335)\tData 0.311 (0.311)\tLoss 0.2578 (0.2578)\tAcc 0.938 (0.938)\n",
      "Epoch: [44][2/9]\tTime 0.072 (0.203)\tData 0.050 (0.180)\tLoss 1.1301 (0.6940)\tAcc 0.500 (0.719)\n",
      "Epoch: [44][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.138)\tLoss 0.7129 (0.7003)\tAcc 0.688 (0.708)\n",
      "Epoch: [44][4/9]\tTime 0.074 (0.139)\tData 0.052 (0.116)\tLoss 0.7285 (0.7073)\tAcc 0.625 (0.688)\n",
      "Epoch: [44][5/9]\tTime 0.072 (0.125)\tData 0.052 (0.103)\tLoss 0.9128 (0.7484)\tAcc 0.625 (0.675)\n",
      "Epoch: [44][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.095)\tLoss 0.1481 (0.6484)\tAcc 1.000 (0.729)\n",
      "Epoch: [44][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.4928 (0.6262)\tAcc 0.750 (0.732)\n",
      "Epoch: [44][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.085)\tLoss 1.1354 (0.6898)\tAcc 0.438 (0.695)\n",
      "Epoch: [44][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.082)\tLoss 0.1623 (0.6817)\tAcc 1.000 (0.700)\n",
      "train at epoch 45\n",
      "Epoch: [45][1/5]\tTime 0.318 (0.318)\tData 0.288 (0.288)\tLoss 0.7853 (0.7853)\tAcc 0.750 (0.750)\n",
      "Epoch: [45][2/5]\tTime 0.073 (0.196)\tData 0.049 (0.168)\tLoss 0.9138 (0.8496)\tAcc 0.562 (0.656)\n",
      "Epoch: [45][3/5]\tTime 0.077 (0.156)\tData 0.054 (0.130)\tLoss 0.6799 (0.7930)\tAcc 0.688 (0.667)\n",
      "Epoch: [45][4/5]\tTime 0.077 (0.136)\tData 0.054 (0.111)\tLoss 0.7215 (0.7751)\tAcc 0.750 (0.688)\n",
      "Epoch: [45][5/5]\tTime 0.079 (0.125)\tData 0.055 (0.100)\tLoss 0.4699 (0.7375)\tAcc 0.889 (0.712)\n",
      "validation at epoch 45\n",
      "Epoch: [45][1/9]\tTime 0.358 (0.358)\tData 0.334 (0.334)\tLoss 0.3398 (0.3398)\tAcc 0.875 (0.875)\n",
      "Epoch: [45][2/9]\tTime 0.071 (0.214)\tData 0.050 (0.192)\tLoss 1.0288 (0.6843)\tAcc 0.500 (0.688)\n",
      "Epoch: [45][3/9]\tTime 0.074 (0.168)\tData 0.053 (0.145)\tLoss 0.6392 (0.6693)\tAcc 0.750 (0.708)\n",
      "Epoch: [45][4/9]\tTime 0.073 (0.144)\tData 0.052 (0.122)\tLoss 0.6498 (0.6644)\tAcc 0.688 (0.703)\n",
      "Epoch: [45][5/9]\tTime 0.072 (0.130)\tData 0.053 (0.108)\tLoss 0.9111 (0.7137)\tAcc 0.688 (0.700)\n",
      "Epoch: [45][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.2423 (0.6352)\tAcc 1.000 (0.750)\n",
      "Epoch: [45][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.093)\tLoss 0.4898 (0.6144)\tAcc 0.875 (0.768)\n",
      "Epoch: [45][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.088)\tLoss 1.0864 (0.6734)\tAcc 0.562 (0.742)\n",
      "Epoch: [45][9/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.2238 (0.6665)\tAcc 1.000 (0.746)\n",
      "train at epoch 46\n",
      "Epoch: [46][1/5]\tTime 0.317 (0.317)\tData 0.288 (0.288)\tLoss 0.7633 (0.7633)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][2/5]\tTime 0.074 (0.196)\tData 0.050 (0.169)\tLoss 0.7000 (0.7317)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][3/5]\tTime 0.077 (0.156)\tData 0.053 (0.130)\tLoss 0.8793 (0.7809)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][4/5]\tTime 0.078 (0.136)\tData 0.054 (0.111)\tLoss 0.6235 (0.7415)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][5/5]\tTime 0.080 (0.125)\tData 0.055 (0.100)\tLoss 0.8361 (0.7532)\tAcc 0.667 (0.740)\n",
      "validation at epoch 46\n",
      "Epoch: [46][1/9]\tTime 0.356 (0.356)\tData 0.332 (0.332)\tLoss 0.2881 (0.2881)\tAcc 0.938 (0.938)\n",
      "Epoch: [46][2/9]\tTime 0.072 (0.214)\tData 0.050 (0.191)\tLoss 0.9561 (0.6221)\tAcc 0.562 (0.750)\n",
      "Epoch: [46][3/9]\tTime 0.073 (0.167)\tData 0.052 (0.145)\tLoss 0.6555 (0.6332)\tAcc 0.750 (0.750)\n",
      "Epoch: [46][4/9]\tTime 0.074 (0.144)\tData 0.053 (0.122)\tLoss 0.5817 (0.6203)\tAcc 0.625 (0.719)\n",
      "Epoch: [46][5/9]\tTime 0.073 (0.130)\tData 0.053 (0.108)\tLoss 0.8544 (0.6672)\tAcc 0.625 (0.700)\n",
      "Epoch: [46][6/9]\tTime 0.072 (0.120)\tData 0.053 (0.099)\tLoss 0.2639 (0.6000)\tAcc 1.000 (0.750)\n",
      "Epoch: [46][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.093)\tLoss 0.7904 (0.6272)\tAcc 0.562 (0.723)\n",
      "Epoch: [46][8/9]\tTime 0.075 (0.109)\tData 0.055 (0.088)\tLoss 1.0450 (0.6794)\tAcc 0.625 (0.711)\n",
      "Epoch: [46][9/9]\tTime 0.072 (0.105)\tData 0.054 (0.084)\tLoss 0.2604 (0.6729)\tAcc 1.000 (0.715)\n",
      "train at epoch 47\n",
      "Epoch: [47][1/5]\tTime 0.276 (0.276)\tData 0.246 (0.246)\tLoss 0.9603 (0.9603)\tAcc 0.625 (0.625)\n",
      "Epoch: [47][2/5]\tTime 0.074 (0.175)\tData 0.050 (0.148)\tLoss 0.8844 (0.9224)\tAcc 0.688 (0.656)\n",
      "Epoch: [47][3/5]\tTime 0.077 (0.142)\tData 0.053 (0.116)\tLoss 0.6262 (0.8236)\tAcc 0.750 (0.688)\n",
      "Epoch: [47][4/5]\tTime 0.077 (0.126)\tData 0.054 (0.101)\tLoss 0.7468 (0.8044)\tAcc 0.750 (0.703)\n",
      "Epoch: [47][5/5]\tTime 0.079 (0.117)\tData 0.056 (0.092)\tLoss 0.7904 (0.8027)\tAcc 0.778 (0.712)\n",
      "validation at epoch 47\n",
      "Epoch: [47][1/9]\tTime 0.316 (0.316)\tData 0.292 (0.292)\tLoss 0.4192 (0.4192)\tAcc 0.875 (0.875)\n",
      "Epoch: [47][2/9]\tTime 0.090 (0.203)\tData 0.069 (0.181)\tLoss 0.9743 (0.6968)\tAcc 0.688 (0.781)\n",
      "Epoch: [47][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.138)\tLoss 0.7320 (0.7085)\tAcc 0.625 (0.729)\n",
      "Epoch: [47][4/9]\tTime 0.074 (0.138)\tData 0.053 (0.117)\tLoss 0.6375 (0.6908)\tAcc 0.688 (0.719)\n",
      "Epoch: [47][5/9]\tTime 0.074 (0.125)\tData 0.054 (0.104)\tLoss 0.8325 (0.7191)\tAcc 0.688 (0.713)\n",
      "Epoch: [47][6/9]\tTime 0.073 (0.117)\tData 0.053 (0.095)\tLoss 0.3468 (0.6571)\tAcc 1.000 (0.760)\n",
      "Epoch: [47][7/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 0.7880 (0.6758)\tAcc 0.562 (0.732)\n",
      "Epoch: [47][8/9]\tTime 0.074 (0.106)\tData 0.054 (0.085)\tLoss 1.2438 (0.7468)\tAcc 0.438 (0.695)\n",
      "Epoch: [47][9/9]\tTime 0.074 (0.102)\tData 0.056 (0.082)\tLoss 0.1870 (0.7382)\tAcc 1.000 (0.700)\n",
      "train at epoch 48\n",
      "Epoch: [48][1/5]\tTime 0.336 (0.336)\tData 0.308 (0.308)\tLoss 0.8703 (0.8703)\tAcc 0.750 (0.750)\n",
      "Epoch: [48][2/5]\tTime 0.075 (0.206)\tData 0.050 (0.179)\tLoss 0.7004 (0.7854)\tAcc 0.688 (0.719)\n",
      "Epoch: [48][3/5]\tTime 0.076 (0.162)\tData 0.053 (0.137)\tLoss 0.5226 (0.6978)\tAcc 0.812 (0.750)\n",
      "Epoch: [48][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.116)\tLoss 0.8591 (0.7381)\tAcc 0.625 (0.719)\n",
      "Epoch: [48][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.104)\tLoss 0.7994 (0.7457)\tAcc 0.778 (0.726)\n",
      "validation at epoch 48\n",
      "Epoch: [48][1/9]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.3736 (0.3736)\tAcc 0.875 (0.875)\n",
      "Epoch: [48][2/9]\tTime 0.070 (0.218)\tData 0.048 (0.194)\tLoss 1.1121 (0.7429)\tAcc 0.562 (0.719)\n",
      "Epoch: [48][3/9]\tTime 0.073 (0.169)\tData 0.052 (0.147)\tLoss 0.6799 (0.7219)\tAcc 0.688 (0.708)\n",
      "Epoch: [48][4/9]\tTime 0.074 (0.146)\tData 0.053 (0.123)\tLoss 0.7606 (0.7315)\tAcc 0.562 (0.672)\n",
      "Epoch: [48][5/9]\tTime 0.072 (0.131)\tData 0.053 (0.109)\tLoss 0.8850 (0.7622)\tAcc 0.688 (0.675)\n",
      "Epoch: [48][6/9]\tTime 0.073 (0.121)\tData 0.055 (0.100)\tLoss 0.2857 (0.6828)\tAcc 0.938 (0.719)\n",
      "Epoch: [48][7/9]\tTime 0.073 (0.114)\tData 0.054 (0.094)\tLoss 0.6549 (0.6788)\tAcc 0.688 (0.714)\n",
      "Epoch: [48][8/9]\tTime 0.075 (0.109)\tData 0.056 (0.089)\tLoss 1.0348 (0.7233)\tAcc 0.500 (0.688)\n",
      "Epoch: [48][9/9]\tTime 0.073 (0.105)\tData 0.054 (0.085)\tLoss 0.1518 (0.7145)\tAcc 1.000 (0.692)\n",
      "train at epoch 49\n",
      "Epoch: [49][1/5]\tTime 0.334 (0.334)\tData 0.307 (0.307)\tLoss 0.5110 (0.5110)\tAcc 0.750 (0.750)\n",
      "Epoch: [49][2/5]\tTime 0.075 (0.205)\tData 0.051 (0.179)\tLoss 0.5502 (0.5306)\tAcc 0.812 (0.781)\n",
      "Epoch: [49][3/5]\tTime 0.077 (0.162)\tData 0.054 (0.137)\tLoss 0.9927 (0.6846)\tAcc 0.625 (0.729)\n",
      "Epoch: [49][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.116)\tLoss 0.6527 (0.6766)\tAcc 0.750 (0.734)\n",
      "Epoch: [49][5/5]\tTime 0.079 (0.129)\tData 0.055 (0.104)\tLoss 0.7887 (0.6905)\tAcc 0.778 (0.740)\n",
      "validation at epoch 49\n",
      "Epoch: [49][1/9]\tTime 0.309 (0.309)\tData 0.283 (0.283)\tLoss 0.3390 (0.3390)\tAcc 0.938 (0.938)\n",
      "Epoch: [49][2/9]\tTime 0.070 (0.190)\tData 0.049 (0.166)\tLoss 0.9996 (0.6693)\tAcc 0.562 (0.750)\n",
      "Epoch: [49][3/9]\tTime 0.074 (0.151)\tData 0.052 (0.128)\tLoss 0.6100 (0.6495)\tAcc 0.688 (0.729)\n",
      "Epoch: [49][4/9]\tTime 0.071 (0.131)\tData 0.052 (0.109)\tLoss 0.5566 (0.6263)\tAcc 0.750 (0.734)\n",
      "Epoch: [49][5/9]\tTime 0.074 (0.120)\tData 0.055 (0.098)\tLoss 0.8066 (0.6624)\tAcc 0.750 (0.738)\n",
      "Epoch: [49][6/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.2804 (0.5987)\tAcc 1.000 (0.781)\n",
      "Epoch: [49][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.6608 (0.6076)\tAcc 0.688 (0.768)\n",
      "Epoch: [49][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 1.0587 (0.6640)\tAcc 0.438 (0.727)\n",
      "Epoch: [49][9/9]\tTime 0.073 (0.099)\tData 0.054 (0.079)\tLoss 0.1081 (0.6554)\tAcc 1.000 (0.731)\n",
      "train at epoch 50\n",
      "Epoch: [50][1/5]\tTime 0.378 (0.378)\tData 0.351 (0.351)\tLoss 0.6650 (0.6650)\tAcc 0.812 (0.812)\n",
      "Epoch: [50][2/5]\tTime 0.076 (0.227)\tData 0.052 (0.202)\tLoss 0.8472 (0.7561)\tAcc 0.750 (0.781)\n",
      "Epoch: [50][3/5]\tTime 0.077 (0.177)\tData 0.054 (0.152)\tLoss 0.5424 (0.6849)\tAcc 0.750 (0.771)\n",
      "Epoch: [50][4/5]\tTime 0.077 (0.152)\tData 0.055 (0.128)\tLoss 1.0452 (0.7749)\tAcc 0.500 (0.703)\n",
      "Epoch: [50][5/5]\tTime 0.079 (0.137)\tData 0.056 (0.114)\tLoss 0.7933 (0.7772)\tAcc 0.889 (0.726)\n",
      "validation at epoch 50\n",
      "Epoch: [50][1/9]\tTime 0.407 (0.407)\tData 0.383 (0.383)\tLoss 0.3225 (0.3225)\tAcc 0.938 (0.938)\n",
      "Epoch: [50][2/9]\tTime 0.071 (0.239)\tData 0.050 (0.216)\tLoss 0.9883 (0.6554)\tAcc 0.500 (0.719)\n",
      "Epoch: [50][3/9]\tTime 0.073 (0.184)\tData 0.053 (0.162)\tLoss 0.6981 (0.6696)\tAcc 0.625 (0.688)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][4/9]\tTime 0.073 (0.156)\tData 0.053 (0.135)\tLoss 0.5988 (0.6519)\tAcc 0.875 (0.734)\n",
      "Epoch: [50][5/9]\tTime 0.074 (0.140)\tData 0.054 (0.119)\tLoss 0.8108 (0.6837)\tAcc 0.688 (0.725)\n",
      "Epoch: [50][6/9]\tTime 0.073 (0.128)\tData 0.054 (0.108)\tLoss 0.2688 (0.6145)\tAcc 1.000 (0.771)\n",
      "Epoch: [50][7/9]\tTime 0.073 (0.121)\tData 0.054 (0.100)\tLoss 0.7200 (0.6296)\tAcc 0.688 (0.759)\n",
      "Epoch: [50][8/9]\tTime 0.077 (0.115)\tData 0.055 (0.095)\tLoss 0.9340 (0.6677)\tAcc 0.438 (0.719)\n",
      "Epoch: [50][9/9]\tTime 0.070 (0.110)\tData 0.052 (0.090)\tLoss 0.1408 (0.6596)\tAcc 1.000 (0.723)\n",
      "train at epoch 51\n",
      "Epoch: [51][1/5]\tTime 0.399 (0.399)\tData 0.371 (0.371)\tLoss 0.4580 (0.4580)\tAcc 0.875 (0.875)\n",
      "Epoch: [51][2/5]\tTime 0.075 (0.237)\tData 0.051 (0.211)\tLoss 0.6890 (0.5735)\tAcc 0.750 (0.812)\n",
      "Epoch: [51][3/5]\tTime 0.077 (0.184)\tData 0.053 (0.158)\tLoss 0.7672 (0.6381)\tAcc 0.688 (0.771)\n",
      "Epoch: [51][4/5]\tTime 0.079 (0.158)\tData 0.056 (0.133)\tLoss 0.7417 (0.6640)\tAcc 0.625 (0.734)\n",
      "Epoch: [51][5/5]\tTime 0.079 (0.142)\tData 0.055 (0.117)\tLoss 1.0101 (0.7067)\tAcc 0.444 (0.699)\n",
      "validation at epoch 51\n",
      "Epoch: [51][1/9]\tTime 0.331 (0.331)\tData 0.307 (0.307)\tLoss 0.2403 (0.2403)\tAcc 0.938 (0.938)\n",
      "Epoch: [51][2/9]\tTime 0.072 (0.201)\tData 0.050 (0.179)\tLoss 0.9682 (0.6042)\tAcc 0.688 (0.812)\n",
      "Epoch: [51][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.137)\tLoss 0.6421 (0.6168)\tAcc 0.625 (0.750)\n",
      "Epoch: [51][4/9]\tTime 0.072 (0.137)\tData 0.053 (0.116)\tLoss 0.5602 (0.6027)\tAcc 0.812 (0.766)\n",
      "Epoch: [51][5/9]\tTime 0.074 (0.124)\tData 0.055 (0.104)\tLoss 0.8045 (0.6430)\tAcc 0.688 (0.750)\n",
      "Epoch: [51][6/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.2892 (0.5841)\tAcc 1.000 (0.792)\n",
      "Epoch: [51][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6064 (0.5873)\tAcc 0.875 (0.804)\n",
      "Epoch: [51][8/9]\tTime 0.075 (0.105)\tData 0.055 (0.085)\tLoss 0.9983 (0.6386)\tAcc 0.562 (0.773)\n",
      "Epoch: [51][9/9]\tTime 0.072 (0.102)\tData 0.054 (0.082)\tLoss 0.2864 (0.6332)\tAcc 1.000 (0.777)\n",
      "train at epoch 52\n",
      "Epoch: [52][1/5]\tTime 0.267 (0.267)\tData 0.238 (0.238)\tLoss 0.6989 (0.6989)\tAcc 0.750 (0.750)\n",
      "Epoch: [52][2/5]\tTime 0.075 (0.171)\tData 0.049 (0.143)\tLoss 1.1486 (0.9238)\tAcc 0.562 (0.656)\n",
      "Epoch: [52][3/5]\tTime 0.075 (0.139)\tData 0.052 (0.113)\tLoss 0.6062 (0.8179)\tAcc 0.625 (0.646)\n",
      "Epoch: [52][4/5]\tTime 0.077 (0.124)\tData 0.054 (0.098)\tLoss 0.7602 (0.8035)\tAcc 0.688 (0.656)\n",
      "Epoch: [52][5/5]\tTime 0.079 (0.115)\tData 0.056 (0.090)\tLoss 0.7310 (0.7945)\tAcc 0.778 (0.671)\n",
      "validation at epoch 52\n",
      "Epoch: [52][1/9]\tTime 0.313 (0.313)\tData 0.287 (0.287)\tLoss 0.2555 (0.2555)\tAcc 1.000 (1.000)\n",
      "Epoch: [52][2/9]\tTime 0.071 (0.192)\tData 0.049 (0.168)\tLoss 1.0413 (0.6484)\tAcc 0.562 (0.781)\n",
      "Epoch: [52][3/9]\tTime 0.073 (0.152)\tData 0.052 (0.129)\tLoss 0.5699 (0.6223)\tAcc 0.688 (0.750)\n",
      "Epoch: [52][4/9]\tTime 0.073 (0.132)\tData 0.053 (0.110)\tLoss 0.5977 (0.6161)\tAcc 0.875 (0.781)\n",
      "Epoch: [52][5/9]\tTime 0.075 (0.121)\tData 0.055 (0.099)\tLoss 0.8936 (0.6716)\tAcc 0.625 (0.750)\n",
      "Epoch: [52][6/9]\tTime 0.073 (0.113)\tData 0.053 (0.092)\tLoss 0.2407 (0.5998)\tAcc 1.000 (0.792)\n",
      "Epoch: [52][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.6097 (0.6012)\tAcc 0.750 (0.786)\n",
      "Epoch: [52][8/9]\tTime 0.074 (0.103)\tData 0.055 (0.082)\tLoss 0.9710 (0.6474)\tAcc 0.500 (0.750)\n",
      "Epoch: [52][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.1439 (0.6397)\tAcc 1.000 (0.754)\n",
      "train at epoch 53\n",
      "Epoch: [53][1/5]\tTime 0.366 (0.366)\tData 0.340 (0.340)\tLoss 0.5613 (0.5613)\tAcc 0.938 (0.938)\n",
      "Epoch: [53][2/5]\tTime 0.076 (0.221)\tData 0.052 (0.196)\tLoss 0.7819 (0.6716)\tAcc 0.562 (0.750)\n",
      "Epoch: [53][3/5]\tTime 0.077 (0.173)\tData 0.054 (0.148)\tLoss 0.9269 (0.7567)\tAcc 0.500 (0.667)\n",
      "Epoch: [53][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.125)\tLoss 0.5814 (0.7129)\tAcc 0.812 (0.703)\n",
      "Epoch: [53][5/5]\tTime 0.079 (0.135)\tData 0.056 (0.111)\tLoss 0.5072 (0.6875)\tAcc 0.889 (0.726)\n",
      "validation at epoch 53\n",
      "Epoch: [53][1/9]\tTime 0.351 (0.351)\tData 0.327 (0.327)\tLoss 0.3578 (0.3578)\tAcc 0.875 (0.875)\n",
      "Epoch: [53][2/9]\tTime 0.072 (0.211)\tData 0.050 (0.188)\tLoss 1.0045 (0.6812)\tAcc 0.625 (0.750)\n",
      "Epoch: [53][3/9]\tTime 0.074 (0.166)\tData 0.052 (0.143)\tLoss 0.7270 (0.6965)\tAcc 0.688 (0.729)\n",
      "Epoch: [53][4/9]\tTime 0.074 (0.143)\tData 0.051 (0.120)\tLoss 0.5856 (0.6687)\tAcc 0.812 (0.750)\n",
      "Epoch: [53][5/9]\tTime 0.071 (0.128)\tData 0.052 (0.106)\tLoss 0.8999 (0.7150)\tAcc 0.750 (0.750)\n",
      "Epoch: [53][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.2131 (0.6313)\tAcc 1.000 (0.792)\n",
      "Epoch: [53][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6514 (0.6342)\tAcc 0.688 (0.777)\n",
      "Epoch: [53][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.087)\tLoss 1.1659 (0.7007)\tAcc 0.438 (0.734)\n",
      "Epoch: [53][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.1152 (0.6916)\tAcc 1.000 (0.738)\n",
      "train at epoch 54\n",
      "Epoch: [54][1/5]\tTime 0.312 (0.312)\tData 0.284 (0.284)\tLoss 0.9022 (0.9022)\tAcc 0.562 (0.562)\n",
      "Epoch: [54][2/5]\tTime 0.074 (0.193)\tData 0.050 (0.167)\tLoss 0.6003 (0.7513)\tAcc 0.812 (0.688)\n",
      "Epoch: [54][3/5]\tTime 0.076 (0.154)\tData 0.053 (0.129)\tLoss 1.3823 (0.9616)\tAcc 0.375 (0.583)\n",
      "Epoch: [54][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.110)\tLoss 0.5516 (0.8591)\tAcc 0.812 (0.641)\n",
      "Epoch: [54][5/5]\tTime 0.079 (0.124)\tData 0.056 (0.099)\tLoss 0.5395 (0.8197)\tAcc 0.667 (0.644)\n",
      "validation at epoch 54\n",
      "Epoch: [54][1/9]\tTime 0.335 (0.335)\tData 0.310 (0.310)\tLoss 0.3575 (0.3575)\tAcc 0.938 (0.938)\n",
      "Epoch: [54][2/9]\tTime 0.071 (0.203)\tData 0.050 (0.180)\tLoss 0.9801 (0.6688)\tAcc 0.688 (0.812)\n",
      "Epoch: [54][3/9]\tTime 0.075 (0.160)\tData 0.052 (0.137)\tLoss 0.7270 (0.6882)\tAcc 0.625 (0.750)\n",
      "Epoch: [54][4/9]\tTime 0.073 (0.139)\tData 0.051 (0.116)\tLoss 0.7097 (0.6936)\tAcc 0.750 (0.750)\n",
      "Epoch: [54][5/9]\tTime 0.072 (0.125)\tData 0.052 (0.103)\tLoss 0.8798 (0.7308)\tAcc 0.625 (0.725)\n",
      "Epoch: [54][6/9]\tTime 0.072 (0.116)\tData 0.054 (0.095)\tLoss 0.2261 (0.6467)\tAcc 1.000 (0.771)\n",
      "Epoch: [54][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6036 (0.6406)\tAcc 0.688 (0.759)\n",
      "Epoch: [54][8/9]\tTime 0.074 (0.106)\tData 0.055 (0.085)\tLoss 0.9921 (0.6845)\tAcc 0.500 (0.727)\n",
      "Epoch: [54][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.0750 (0.6751)\tAcc 1.000 (0.731)\n",
      "train at epoch 55\n",
      "Epoch: [55][1/5]\tTime 0.296 (0.296)\tData 0.267 (0.267)\tLoss 0.9152 (0.9152)\tAcc 0.625 (0.625)\n",
      "Epoch: [55][2/5]\tTime 0.074 (0.185)\tData 0.050 (0.158)\tLoss 0.8814 (0.8983)\tAcc 0.688 (0.656)\n",
      "Epoch: [55][3/5]\tTime 0.076 (0.149)\tData 0.053 (0.123)\tLoss 0.5433 (0.7800)\tAcc 0.688 (0.667)\n",
      "Epoch: [55][4/5]\tTime 0.077 (0.131)\tData 0.054 (0.106)\tLoss 0.5201 (0.7150)\tAcc 0.875 (0.719)\n",
      "Epoch: [55][5/5]\tTime 0.079 (0.120)\tData 0.056 (0.096)\tLoss 0.8158 (0.7274)\tAcc 0.667 (0.712)\n",
      "validation at epoch 55\n",
      "Epoch: [55][1/9]\tTime 0.352 (0.352)\tData 0.326 (0.326)\tLoss 0.3229 (0.3229)\tAcc 0.938 (0.938)\n",
      "Epoch: [55][2/9]\tTime 0.070 (0.211)\tData 0.049 (0.187)\tLoss 0.8594 (0.5911)\tAcc 0.625 (0.781)\n",
      "Epoch: [55][3/9]\tTime 0.073 (0.165)\tData 0.052 (0.142)\tLoss 0.6262 (0.6028)\tAcc 0.688 (0.750)\n",
      "Epoch: [55][4/9]\tTime 0.073 (0.142)\tData 0.052 (0.120)\tLoss 0.6508 (0.6148)\tAcc 0.688 (0.734)\n",
      "Epoch: [55][5/9]\tTime 0.073 (0.128)\tData 0.053 (0.106)\tLoss 0.8378 (0.6594)\tAcc 0.625 (0.713)\n",
      "Epoch: [55][6/9]\tTime 0.072 (0.119)\tData 0.053 (0.098)\tLoss 0.2967 (0.5989)\tAcc 1.000 (0.760)\n",
      "Epoch: [55][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6755 (0.6099)\tAcc 0.688 (0.750)\n",
      "Epoch: [55][8/9]\tTime 0.075 (0.108)\tData 0.055 (0.087)\tLoss 1.0360 (0.6631)\tAcc 0.562 (0.727)\n",
      "Epoch: [55][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.2697 (0.6571)\tAcc 1.000 (0.731)\n",
      "train at epoch 56\n",
      "Epoch: [56][1/5]\tTime 0.339 (0.339)\tData 0.311 (0.311)\tLoss 0.8552 (0.8552)\tAcc 0.750 (0.750)\n",
      "Epoch: [56][2/5]\tTime 0.075 (0.207)\tData 0.051 (0.181)\tLoss 0.7090 (0.7821)\tAcc 0.688 (0.719)\n",
      "Epoch: [56][3/5]\tTime 0.077 (0.163)\tData 0.054 (0.139)\tLoss 1.0387 (0.8676)\tAcc 0.562 (0.667)\n",
      "Epoch: [56][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.118)\tLoss 0.7121 (0.8288)\tAcc 0.812 (0.703)\n",
      "Epoch: [56][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.105)\tLoss 0.7002 (0.8129)\tAcc 0.889 (0.726)\n",
      "validation at epoch 56\n",
      "Epoch: [56][1/9]\tTime 0.327 (0.327)\tData 0.302 (0.302)\tLoss 0.3315 (0.3315)\tAcc 0.938 (0.938)\n",
      "Epoch: [56][2/9]\tTime 0.072 (0.199)\tData 0.050 (0.176)\tLoss 1.1189 (0.7252)\tAcc 0.438 (0.688)\n",
      "Epoch: [56][3/9]\tTime 0.074 (0.157)\tData 0.052 (0.135)\tLoss 0.7875 (0.7460)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][4/9]\tTime 0.072 (0.136)\tData 0.052 (0.114)\tLoss 0.7061 (0.7360)\tAcc 0.688 (0.688)\n",
      "Epoch: [56][5/9]\tTime 0.074 (0.124)\tData 0.054 (0.102)\tLoss 0.9273 (0.7743)\tAcc 0.625 (0.675)\n",
      "Epoch: [56][6/9]\tTime 0.073 (0.115)\tData 0.053 (0.094)\tLoss 0.2904 (0.6936)\tAcc 1.000 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [56][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.6971 (0.6941)\tAcc 0.688 (0.723)\n",
      "Epoch: [56][8/9]\tTime 0.074 (0.105)\tData 0.054 (0.084)\tLoss 1.0217 (0.7351)\tAcc 0.562 (0.703)\n",
      "Epoch: [56][9/9]\tTime 0.074 (0.101)\tData 0.055 (0.081)\tLoss 0.2522 (0.7276)\tAcc 1.000 (0.708)\n",
      "train at epoch 57\n",
      "Epoch: [57][1/5]\tTime 0.381 (0.381)\tData 0.353 (0.353)\tLoss 0.7769 (0.7769)\tAcc 0.750 (0.750)\n",
      "Epoch: [57][2/5]\tTime 0.076 (0.229)\tData 0.051 (0.202)\tLoss 0.5608 (0.6688)\tAcc 0.938 (0.844)\n",
      "Epoch: [57][3/5]\tTime 0.076 (0.178)\tData 0.052 (0.152)\tLoss 0.7312 (0.6896)\tAcc 0.750 (0.812)\n",
      "Epoch: [57][4/5]\tTime 0.077 (0.152)\tData 0.054 (0.128)\tLoss 0.7938 (0.7157)\tAcc 0.750 (0.797)\n",
      "Epoch: [57][5/5]\tTime 0.079 (0.138)\tData 0.056 (0.113)\tLoss 0.8035 (0.7265)\tAcc 0.556 (0.767)\n",
      "validation at epoch 57\n",
      "Epoch: [57][1/9]\tTime 0.330 (0.330)\tData 0.306 (0.306)\tLoss 0.3050 (0.3050)\tAcc 0.938 (0.938)\n",
      "Epoch: [57][2/9]\tTime 0.072 (0.201)\tData 0.050 (0.178)\tLoss 1.0758 (0.6904)\tAcc 0.438 (0.688)\n",
      "Epoch: [57][3/9]\tTime 0.073 (0.158)\tData 0.053 (0.136)\tLoss 0.4894 (0.6234)\tAcc 0.750 (0.708)\n",
      "Epoch: [57][4/9]\tTime 0.073 (0.137)\tData 0.053 (0.116)\tLoss 0.6537 (0.6310)\tAcc 0.750 (0.719)\n",
      "Epoch: [57][5/9]\tTime 0.077 (0.125)\tData 0.055 (0.103)\tLoss 0.7581 (0.6564)\tAcc 0.812 (0.738)\n",
      "Epoch: [57][6/9]\tTime 0.070 (0.116)\tData 0.051 (0.095)\tLoss 0.2471 (0.5882)\tAcc 1.000 (0.781)\n",
      "Epoch: [57][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.5241 (0.5790)\tAcc 0.812 (0.786)\n",
      "Epoch: [57][8/9]\tTime 0.074 (0.105)\tData 0.055 (0.085)\tLoss 1.0709 (0.6405)\tAcc 0.625 (0.766)\n",
      "Epoch: [57][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.081)\tLoss 0.1491 (0.6329)\tAcc 1.000 (0.769)\n",
      "train at epoch 58\n",
      "Epoch: [58][1/5]\tTime 0.363 (0.363)\tData 0.335 (0.335)\tLoss 0.5097 (0.5097)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/5]\tTime 0.076 (0.219)\tData 0.051 (0.193)\tLoss 0.5184 (0.5141)\tAcc 0.875 (0.906)\n",
      "Epoch: [58][3/5]\tTime 0.076 (0.172)\tData 0.053 (0.147)\tLoss 0.8777 (0.6353)\tAcc 0.500 (0.771)\n",
      "Epoch: [58][4/5]\tTime 0.079 (0.148)\tData 0.056 (0.124)\tLoss 1.0338 (0.7349)\tAcc 0.625 (0.734)\n",
      "Epoch: [58][5/5]\tTime 0.079 (0.134)\tData 0.056 (0.110)\tLoss 0.8120 (0.7444)\tAcc 0.778 (0.740)\n",
      "validation at epoch 58\n",
      "Epoch: [58][1/9]\tTime 0.288 (0.288)\tData 0.263 (0.263)\tLoss 0.3515 (0.3515)\tAcc 0.938 (0.938)\n",
      "Epoch: [58][2/9]\tTime 0.072 (0.180)\tData 0.050 (0.157)\tLoss 1.0174 (0.6845)\tAcc 0.438 (0.688)\n",
      "Epoch: [58][3/9]\tTime 0.073 (0.144)\tData 0.052 (0.122)\tLoss 0.7526 (0.7072)\tAcc 0.625 (0.667)\n",
      "Epoch: [58][4/9]\tTime 0.073 (0.126)\tData 0.052 (0.105)\tLoss 0.6259 (0.6869)\tAcc 0.625 (0.656)\n",
      "Epoch: [58][5/9]\tTime 0.073 (0.116)\tData 0.054 (0.094)\tLoss 0.9011 (0.7297)\tAcc 0.625 (0.650)\n",
      "Epoch: [58][6/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.3089 (0.6596)\tAcc 1.000 (0.708)\n",
      "Epoch: [58][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.7065 (0.6663)\tAcc 0.625 (0.696)\n",
      "Epoch: [58][8/9]\tTime 0.074 (0.100)\tData 0.054 (0.079)\tLoss 1.1077 (0.7215)\tAcc 0.562 (0.680)\n",
      "Epoch: [58][9/9]\tTime 0.072 (0.097)\tData 0.054 (0.076)\tLoss 0.3010 (0.7150)\tAcc 1.000 (0.685)\n",
      "train at epoch 59\n",
      "Epoch: [59][1/5]\tTime 0.328 (0.328)\tData 0.298 (0.298)\tLoss 0.8507 (0.8507)\tAcc 0.562 (0.562)\n",
      "Epoch: [59][2/5]\tTime 0.074 (0.201)\tData 0.049 (0.173)\tLoss 0.4171 (0.6339)\tAcc 0.938 (0.750)\n",
      "Epoch: [59][3/5]\tTime 0.075 (0.159)\tData 0.052 (0.133)\tLoss 0.8574 (0.7084)\tAcc 0.562 (0.688)\n",
      "Epoch: [59][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.113)\tLoss 0.6835 (0.7022)\tAcc 0.812 (0.719)\n",
      "Epoch: [59][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.102)\tLoss 0.9752 (0.7358)\tAcc 0.556 (0.699)\n",
      "validation at epoch 59\n",
      "Epoch: [59][1/9]\tTime 0.319 (0.319)\tData 0.293 (0.293)\tLoss 0.3163 (0.3163)\tAcc 0.938 (0.938)\n",
      "Epoch: [59][2/9]\tTime 0.070 (0.194)\tData 0.049 (0.171)\tLoss 0.9269 (0.6216)\tAcc 0.500 (0.719)\n",
      "Epoch: [59][3/9]\tTime 0.073 (0.154)\tData 0.053 (0.131)\tLoss 0.5904 (0.6112)\tAcc 0.812 (0.750)\n",
      "Epoch: [59][4/9]\tTime 0.075 (0.134)\tData 0.053 (0.112)\tLoss 0.6840 (0.6294)\tAcc 0.625 (0.719)\n",
      "Epoch: [59][5/9]\tTime 0.072 (0.122)\tData 0.052 (0.100)\tLoss 0.8236 (0.6682)\tAcc 0.750 (0.725)\n",
      "Epoch: [59][6/9]\tTime 0.073 (0.114)\tData 0.054 (0.092)\tLoss 0.2608 (0.6003)\tAcc 1.000 (0.771)\n",
      "Epoch: [59][7/9]\tTime 0.072 (0.108)\tData 0.054 (0.087)\tLoss 0.6713 (0.6105)\tAcc 0.750 (0.768)\n",
      "Epoch: [59][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 1.0599 (0.6667)\tAcc 0.625 (0.750)\n",
      "Epoch: [59][9/9]\tTime 0.073 (0.100)\tData 0.055 (0.080)\tLoss 0.4019 (0.6626)\tAcc 1.000 (0.754)\n",
      "train at epoch 60\n",
      "Epoch: [60][1/5]\tTime 0.341 (0.341)\tData 0.312 (0.312)\tLoss 0.6048 (0.6048)\tAcc 0.750 (0.750)\n",
      "Epoch: [60][2/5]\tTime 0.074 (0.207)\tData 0.050 (0.181)\tLoss 0.7186 (0.6617)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][3/5]\tTime 0.077 (0.164)\tData 0.054 (0.139)\tLoss 0.6710 (0.6648)\tAcc 0.750 (0.708)\n",
      "Epoch: [60][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.118)\tLoss 0.7492 (0.6859)\tAcc 0.812 (0.734)\n",
      "Epoch: [60][5/5]\tTime 0.082 (0.130)\tData 0.056 (0.105)\tLoss 1.3994 (0.7739)\tAcc 0.333 (0.685)\n",
      "validation at epoch 60\n",
      "Epoch: [60][1/9]\tTime 0.279 (0.279)\tData 0.253 (0.253)\tLoss 0.3368 (0.3368)\tAcc 0.938 (0.938)\n",
      "Epoch: [60][2/9]\tTime 0.070 (0.175)\tData 0.048 (0.151)\tLoss 1.0938 (0.7153)\tAcc 0.500 (0.719)\n",
      "Epoch: [60][3/9]\tTime 0.073 (0.141)\tData 0.052 (0.118)\tLoss 0.7049 (0.7119)\tAcc 0.625 (0.688)\n",
      "Epoch: [60][4/9]\tTime 0.074 (0.124)\tData 0.052 (0.101)\tLoss 0.6407 (0.6941)\tAcc 0.688 (0.688)\n",
      "Epoch: [60][5/9]\tTime 0.077 (0.115)\tData 0.056 (0.092)\tLoss 0.8213 (0.7195)\tAcc 0.688 (0.688)\n",
      "Epoch: [60][6/9]\tTime 0.072 (0.108)\tData 0.053 (0.086)\tLoss 0.2565 (0.6424)\tAcc 1.000 (0.740)\n",
      "Epoch: [60][7/9]\tTime 0.072 (0.103)\tData 0.053 (0.081)\tLoss 0.5591 (0.6305)\tAcc 0.812 (0.750)\n",
      "Epoch: [60][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 0.9889 (0.6753)\tAcc 0.688 (0.742)\n",
      "Epoch: [60][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.075)\tLoss 0.1612 (0.6674)\tAcc 1.000 (0.746)\n",
      "train at epoch 61\n",
      "Epoch: [61][1/5]\tTime 0.298 (0.298)\tData 0.270 (0.270)\tLoss 0.9244 (0.9244)\tAcc 0.688 (0.688)\n",
      "Epoch: [61][2/5]\tTime 0.077 (0.188)\tData 0.051 (0.160)\tLoss 1.1585 (1.0415)\tAcc 0.375 (0.531)\n",
      "Epoch: [61][3/5]\tTime 0.075 (0.150)\tData 0.051 (0.124)\tLoss 0.6192 (0.9007)\tAcc 0.750 (0.604)\n",
      "Epoch: [61][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.107)\tLoss 0.5529 (0.8138)\tAcc 0.875 (0.672)\n",
      "Epoch: [61][5/5]\tTime 0.079 (0.121)\tData 0.056 (0.096)\tLoss 0.4796 (0.7726)\tAcc 0.889 (0.699)\n",
      "validation at epoch 61\n",
      "Epoch: [61][1/9]\tTime 0.354 (0.354)\tData 0.328 (0.328)\tLoss 0.3614 (0.3614)\tAcc 0.938 (0.938)\n",
      "Epoch: [61][2/9]\tTime 0.070 (0.212)\tData 0.049 (0.189)\tLoss 0.9464 (0.6539)\tAcc 0.500 (0.719)\n",
      "Epoch: [61][3/9]\tTime 0.075 (0.166)\tData 0.053 (0.143)\tLoss 0.6716 (0.6598)\tAcc 0.750 (0.729)\n",
      "Epoch: [61][4/9]\tTime 0.076 (0.144)\tData 0.051 (0.120)\tLoss 0.5873 (0.6417)\tAcc 0.688 (0.719)\n",
      "Epoch: [61][5/9]\tTime 0.070 (0.129)\tData 0.050 (0.106)\tLoss 0.8818 (0.6897)\tAcc 0.625 (0.700)\n",
      "Epoch: [61][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.097)\tLoss 0.3871 (0.6393)\tAcc 1.000 (0.750)\n",
      "Epoch: [61][7/9]\tTime 0.072 (0.113)\tData 0.054 (0.091)\tLoss 0.5876 (0.6319)\tAcc 0.750 (0.750)\n",
      "Epoch: [61][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.087)\tLoss 1.1046 (0.6910)\tAcc 0.438 (0.711)\n",
      "Epoch: [61][9/9]\tTime 0.072 (0.104)\tData 0.054 (0.083)\tLoss 0.1736 (0.6830)\tAcc 1.000 (0.715)\n",
      "train at epoch 62\n",
      "Epoch: [62][1/5]\tTime 0.366 (0.366)\tData 0.339 (0.339)\tLoss 0.9176 (0.9176)\tAcc 0.562 (0.562)\n",
      "Epoch: [62][2/5]\tTime 0.076 (0.221)\tData 0.051 (0.195)\tLoss 0.7867 (0.8522)\tAcc 0.688 (0.625)\n",
      "Epoch: [62][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.6617 (0.7887)\tAcc 0.750 (0.667)\n",
      "Epoch: [62][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.125)\tLoss 0.7456 (0.7779)\tAcc 0.688 (0.672)\n",
      "Epoch: [62][5/5]\tTime 0.080 (0.135)\tData 0.056 (0.111)\tLoss 0.7348 (0.7726)\tAcc 0.667 (0.671)\n",
      "validation at epoch 62\n",
      "Epoch: [62][1/9]\tTime 0.354 (0.354)\tData 0.330 (0.330)\tLoss 0.3494 (0.3494)\tAcc 0.938 (0.938)\n",
      "Epoch: [62][2/9]\tTime 0.071 (0.213)\tData 0.050 (0.190)\tLoss 0.9090 (0.6292)\tAcc 0.500 (0.719)\n",
      "Epoch: [62][3/9]\tTime 0.074 (0.166)\tData 0.053 (0.144)\tLoss 0.5665 (0.6083)\tAcc 0.750 (0.729)\n",
      "Epoch: [62][4/9]\tTime 0.075 (0.144)\tData 0.052 (0.121)\tLoss 0.7046 (0.6324)\tAcc 0.688 (0.719)\n",
      "Epoch: [62][5/9]\tTime 0.073 (0.130)\tData 0.054 (0.108)\tLoss 0.9711 (0.7001)\tAcc 0.625 (0.700)\n",
      "Epoch: [62][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.3395 (0.6400)\tAcc 1.000 (0.750)\n",
      "Epoch: [62][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.4896 (0.6185)\tAcc 0.812 (0.759)\n",
      "Epoch: [62][8/9]\tTime 0.074 (0.108)\tData 0.055 (0.088)\tLoss 0.9737 (0.6629)\tAcc 0.562 (0.734)\n",
      "Epoch: [62][9/9]\tTime 0.073 (0.105)\tData 0.055 (0.084)\tLoss 0.1354 (0.6548)\tAcc 1.000 (0.738)\n",
      "train at epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][1/5]\tTime 0.404 (0.404)\tData 0.377 (0.377)\tLoss 1.0854 (1.0854)\tAcc 0.500 (0.500)\n",
      "Epoch: [63][2/5]\tTime 0.075 (0.239)\tData 0.051 (0.214)\tLoss 0.5057 (0.7956)\tAcc 0.812 (0.656)\n",
      "Epoch: [63][3/5]\tTime 0.077 (0.185)\tData 0.054 (0.161)\tLoss 0.7403 (0.7771)\tAcc 0.812 (0.708)\n",
      "Epoch: [63][4/5]\tTime 0.077 (0.158)\tData 0.054 (0.134)\tLoss 0.7809 (0.7781)\tAcc 0.625 (0.688)\n",
      "Epoch: [63][5/5]\tTime 0.079 (0.142)\tData 0.056 (0.119)\tLoss 0.3989 (0.7313)\tAcc 1.000 (0.726)\n",
      "validation at epoch 63\n",
      "Epoch: [63][1/9]\tTime 0.280 (0.280)\tData 0.256 (0.256)\tLoss 0.3571 (0.3571)\tAcc 0.938 (0.938)\n",
      "Epoch: [63][2/9]\tTime 0.073 (0.177)\tData 0.050 (0.153)\tLoss 0.9325 (0.6448)\tAcc 0.438 (0.688)\n",
      "Epoch: [63][3/9]\tTime 0.071 (0.142)\tData 0.051 (0.119)\tLoss 0.7082 (0.6659)\tAcc 0.750 (0.708)\n",
      "Epoch: [63][4/9]\tTime 0.074 (0.125)\tData 0.053 (0.103)\tLoss 0.6147 (0.6531)\tAcc 0.688 (0.703)\n",
      "Epoch: [63][5/9]\tTime 0.074 (0.115)\tData 0.053 (0.093)\tLoss 0.9569 (0.7139)\tAcc 0.625 (0.688)\n",
      "Epoch: [63][6/9]\tTime 0.072 (0.107)\tData 0.053 (0.086)\tLoss 0.3407 (0.6517)\tAcc 0.938 (0.729)\n",
      "Epoch: [63][7/9]\tTime 0.073 (0.102)\tData 0.054 (0.081)\tLoss 0.4728 (0.6261)\tAcc 0.875 (0.750)\n",
      "Epoch: [63][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 1.0968 (0.6850)\tAcc 0.562 (0.727)\n",
      "Epoch: [63][9/9]\tTime 0.072 (0.096)\tData 0.054 (0.076)\tLoss 0.1630 (0.6769)\tAcc 1.000 (0.731)\n",
      "train at epoch 64\n",
      "Epoch: [64][1/5]\tTime 0.281 (0.281)\tData 0.250 (0.250)\tLoss 0.7344 (0.7344)\tAcc 0.562 (0.562)\n",
      "Epoch: [64][2/5]\tTime 0.075 (0.178)\tData 0.048 (0.149)\tLoss 0.5326 (0.6335)\tAcc 0.812 (0.688)\n",
      "Epoch: [64][3/5]\tTime 0.075 (0.144)\tData 0.051 (0.117)\tLoss 0.7682 (0.6784)\tAcc 0.750 (0.708)\n",
      "Epoch: [64][4/5]\tTime 0.077 (0.127)\tData 0.054 (0.101)\tLoss 0.6927 (0.6820)\tAcc 0.750 (0.719)\n",
      "Epoch: [64][5/5]\tTime 0.079 (0.117)\tData 0.055 (0.092)\tLoss 0.7399 (0.6891)\tAcc 0.667 (0.712)\n",
      "validation at epoch 64\n",
      "Epoch: [64][1/9]\tTime 0.336 (0.336)\tData 0.309 (0.309)\tLoss 0.3252 (0.3252)\tAcc 1.000 (1.000)\n",
      "Epoch: [64][2/9]\tTime 0.069 (0.202)\tData 0.047 (0.178)\tLoss 0.9104 (0.6178)\tAcc 0.500 (0.750)\n",
      "Epoch: [64][3/9]\tTime 0.073 (0.159)\tData 0.052 (0.136)\tLoss 0.5946 (0.6101)\tAcc 0.688 (0.729)\n",
      "Epoch: [64][4/9]\tTime 0.075 (0.138)\tData 0.053 (0.115)\tLoss 0.5220 (0.5880)\tAcc 0.812 (0.750)\n",
      "Epoch: [64][5/9]\tTime 0.072 (0.125)\tData 0.053 (0.103)\tLoss 0.7242 (0.6153)\tAcc 0.750 (0.750)\n",
      "Epoch: [64][6/9]\tTime 0.072 (0.116)\tData 0.054 (0.095)\tLoss 0.3169 (0.5655)\tAcc 1.000 (0.792)\n",
      "Epoch: [64][7/9]\tTime 0.074 (0.110)\tData 0.055 (0.089)\tLoss 0.7023 (0.5851)\tAcc 0.688 (0.777)\n",
      "Epoch: [64][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 1.1642 (0.6575)\tAcc 0.500 (0.742)\n",
      "Epoch: [64][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.081)\tLoss 0.1773 (0.6501)\tAcc 1.000 (0.746)\n",
      "train at epoch 65\n",
      "Epoch: [65][1/5]\tTime 0.315 (0.315)\tData 0.285 (0.285)\tLoss 0.5546 (0.5546)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][2/5]\tTime 0.073 (0.194)\tData 0.049 (0.167)\tLoss 1.0416 (0.7981)\tAcc 0.625 (0.750)\n",
      "Epoch: [65][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.129)\tLoss 0.8884 (0.8282)\tAcc 0.562 (0.688)\n",
      "Epoch: [65][4/5]\tTime 0.077 (0.136)\tData 0.054 (0.110)\tLoss 0.6920 (0.7942)\tAcc 0.688 (0.688)\n",
      "Epoch: [65][5/5]\tTime 0.079 (0.124)\tData 0.056 (0.099)\tLoss 0.4102 (0.7468)\tAcc 0.889 (0.712)\n",
      "validation at epoch 65\n",
      "Epoch: [65][1/9]\tTime 0.324 (0.324)\tData 0.297 (0.297)\tLoss 0.4124 (0.4124)\tAcc 0.875 (0.875)\n",
      "Epoch: [65][2/9]\tTime 0.068 (0.196)\tData 0.047 (0.172)\tLoss 1.0397 (0.7261)\tAcc 0.688 (0.781)\n",
      "Epoch: [65][3/9]\tTime 0.074 (0.155)\tData 0.052 (0.132)\tLoss 0.5882 (0.6801)\tAcc 0.688 (0.750)\n",
      "Epoch: [65][4/9]\tTime 0.076 (0.135)\tData 0.052 (0.112)\tLoss 0.6353 (0.6689)\tAcc 0.750 (0.750)\n",
      "Epoch: [65][5/9]\tTime 0.071 (0.123)\tData 0.051 (0.100)\tLoss 0.9148 (0.7181)\tAcc 0.625 (0.725)\n",
      "Epoch: [65][6/9]\tTime 0.073 (0.114)\tData 0.054 (0.092)\tLoss 0.2945 (0.6475)\tAcc 1.000 (0.771)\n",
      "Epoch: [65][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.7725 (0.6654)\tAcc 0.812 (0.777)\n",
      "Epoch: [65][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 0.9286 (0.6983)\tAcc 0.375 (0.727)\n",
      "Epoch: [65][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.1291 (0.6895)\tAcc 1.000 (0.731)\n",
      "train at epoch 66\n",
      "Epoch: [66][1/5]\tTime 0.322 (0.322)\tData 0.293 (0.293)\tLoss 0.8037 (0.8037)\tAcc 0.688 (0.688)\n",
      "Epoch: [66][2/5]\tTime 0.075 (0.198)\tData 0.050 (0.171)\tLoss 0.8594 (0.8316)\tAcc 0.625 (0.656)\n",
      "Epoch: [66][3/5]\tTime 0.077 (0.158)\tData 0.053 (0.132)\tLoss 0.5537 (0.7389)\tAcc 0.750 (0.688)\n",
      "Epoch: [66][4/5]\tTime 0.077 (0.138)\tData 0.053 (0.112)\tLoss 0.5875 (0.7011)\tAcc 0.750 (0.703)\n",
      "Epoch: [66][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.101)\tLoss 0.7172 (0.7031)\tAcc 0.667 (0.699)\n",
      "validation at epoch 66\n",
      "Epoch: [66][1/9]\tTime 0.241 (0.241)\tData 0.218 (0.218)\tLoss 0.3572 (0.3572)\tAcc 0.938 (0.938)\n",
      "Epoch: [66][2/9]\tTime 0.073 (0.157)\tData 0.051 (0.135)\tLoss 1.0908 (0.7240)\tAcc 0.625 (0.781)\n",
      "Epoch: [66][3/9]\tTime 0.074 (0.129)\tData 0.053 (0.107)\tLoss 0.5307 (0.6596)\tAcc 0.688 (0.750)\n",
      "Epoch: [66][4/9]\tTime 0.074 (0.115)\tData 0.053 (0.094)\tLoss 0.5640 (0.6357)\tAcc 0.938 (0.797)\n",
      "Epoch: [66][5/9]\tTime 0.073 (0.107)\tData 0.053 (0.086)\tLoss 0.8617 (0.6809)\tAcc 0.562 (0.750)\n",
      "Epoch: [66][6/9]\tTime 0.075 (0.102)\tData 0.055 (0.080)\tLoss 0.2734 (0.6130)\tAcc 1.000 (0.792)\n",
      "Epoch: [66][7/9]\tTime 0.090 (0.100)\tData 0.069 (0.079)\tLoss 0.8053 (0.6404)\tAcc 0.688 (0.777)\n",
      "Epoch: [66][8/9]\tTime 0.081 (0.097)\tData 0.060 (0.076)\tLoss 1.0268 (0.6887)\tAcc 0.500 (0.742)\n",
      "Epoch: [66][9/9]\tTime 0.080 (0.096)\tData 0.060 (0.075)\tLoss 0.2800 (0.6824)\tAcc 1.000 (0.746)\n",
      "train at epoch 67\n",
      "Epoch: [67][1/5]\tTime 0.326 (0.326)\tData 0.295 (0.295)\tLoss 0.5638 (0.5638)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][2/5]\tTime 0.079 (0.203)\tData 0.055 (0.175)\tLoss 0.7866 (0.6752)\tAcc 0.750 (0.750)\n",
      "Epoch: [67][3/5]\tTime 0.083 (0.163)\tData 0.059 (0.136)\tLoss 1.0295 (0.7933)\tAcc 0.625 (0.708)\n",
      "Epoch: [67][4/5]\tTime 0.087 (0.144)\tData 0.062 (0.118)\tLoss 0.6003 (0.7451)\tAcc 0.750 (0.719)\n",
      "Epoch: [67][5/5]\tTime 0.086 (0.132)\tData 0.061 (0.106)\tLoss 0.6708 (0.7359)\tAcc 0.667 (0.712)\n",
      "validation at epoch 67\n",
      "Epoch: [67][1/9]\tTime 0.377 (0.377)\tData 0.348 (0.348)\tLoss 0.2493 (0.2493)\tAcc 0.938 (0.938)\n",
      "Epoch: [67][2/9]\tTime 0.076 (0.227)\tData 0.054 (0.201)\tLoss 0.9525 (0.6009)\tAcc 0.625 (0.781)\n",
      "Epoch: [67][3/9]\tTime 0.079 (0.178)\tData 0.058 (0.153)\tLoss 0.7950 (0.6656)\tAcc 0.562 (0.708)\n",
      "Epoch: [67][4/9]\tTime 0.080 (0.153)\tData 0.059 (0.130)\tLoss 0.6802 (0.6692)\tAcc 0.875 (0.750)\n",
      "Epoch: [67][5/9]\tTime 0.080 (0.138)\tData 0.059 (0.116)\tLoss 0.9652 (0.7284)\tAcc 0.562 (0.713)\n",
      "Epoch: [67][6/9]\tTime 0.080 (0.129)\tData 0.060 (0.106)\tLoss 0.2338 (0.6460)\tAcc 1.000 (0.760)\n",
      "Epoch: [67][7/9]\tTime 0.080 (0.122)\tData 0.059 (0.100)\tLoss 0.6430 (0.6456)\tAcc 0.625 (0.741)\n",
      "Epoch: [67][8/9]\tTime 0.080 (0.117)\tData 0.060 (0.095)\tLoss 1.3235 (0.7303)\tAcc 0.438 (0.703)\n",
      "Epoch: [67][9/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 0.1696 (0.7217)\tAcc 1.000 (0.708)\n",
      "train at epoch 68\n",
      "Epoch: [68][1/5]\tTime 0.364 (0.364)\tData 0.334 (0.334)\tLoss 0.8360 (0.8360)\tAcc 0.625 (0.625)\n",
      "Epoch: [68][2/5]\tTime 0.078 (0.221)\tData 0.053 (0.193)\tLoss 1.2643 (1.0501)\tAcc 0.438 (0.531)\n",
      "Epoch: [68][3/5]\tTime 0.086 (0.176)\tData 0.061 (0.149)\tLoss 0.7544 (0.9515)\tAcc 0.750 (0.604)\n",
      "Epoch: [68][4/5]\tTime 0.086 (0.153)\tData 0.062 (0.127)\tLoss 0.4215 (0.8190)\tAcc 0.875 (0.672)\n",
      "Epoch: [68][5/5]\tTime 0.086 (0.140)\tData 0.062 (0.114)\tLoss 0.6346 (0.7963)\tAcc 0.667 (0.671)\n",
      "validation at epoch 68\n",
      "Epoch: [68][1/9]\tTime 0.338 (0.338)\tData 0.311 (0.311)\tLoss 0.3238 (0.3238)\tAcc 0.938 (0.938)\n",
      "Epoch: [68][2/9]\tTime 0.072 (0.205)\tData 0.051 (0.181)\tLoss 0.8962 (0.6100)\tAcc 0.625 (0.781)\n",
      "Epoch: [68][3/9]\tTime 0.081 (0.164)\tData 0.059 (0.141)\tLoss 0.7175 (0.6458)\tAcc 0.625 (0.729)\n",
      "Epoch: [68][4/9]\tTime 0.080 (0.143)\tData 0.058 (0.120)\tLoss 0.5547 (0.6230)\tAcc 0.812 (0.750)\n",
      "Epoch: [68][5/9]\tTime 0.080 (0.130)\tData 0.059 (0.108)\tLoss 0.9666 (0.6918)\tAcc 0.625 (0.725)\n",
      "Epoch: [68][6/9]\tTime 0.079 (0.122)\tData 0.058 (0.100)\tLoss 0.2455 (0.6174)\tAcc 1.000 (0.771)\n",
      "Epoch: [68][7/9]\tTime 0.079 (0.116)\tData 0.059 (0.094)\tLoss 0.5980 (0.6146)\tAcc 0.750 (0.768)\n",
      "Epoch: [68][8/9]\tTime 0.081 (0.111)\tData 0.060 (0.090)\tLoss 0.9545 (0.6571)\tAcc 0.500 (0.734)\n",
      "Epoch: [68][9/9]\tTime 0.080 (0.108)\tData 0.060 (0.086)\tLoss 0.0582 (0.6479)\tAcc 1.000 (0.738)\n",
      "train at epoch 69\n",
      "Epoch: [69][1/5]\tTime 0.360 (0.360)\tData 0.329 (0.329)\tLoss 0.6373 (0.6373)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][2/5]\tTime 0.081 (0.220)\tData 0.056 (0.193)\tLoss 0.6886 (0.6630)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][3/5]\tTime 0.085 (0.175)\tData 0.061 (0.149)\tLoss 0.9965 (0.7741)\tAcc 0.625 (0.667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69][4/5]\tTime 0.087 (0.153)\tData 0.062 (0.127)\tLoss 0.9458 (0.8171)\tAcc 0.688 (0.672)\n",
      "Epoch: [69][5/5]\tTime 0.086 (0.140)\tData 0.061 (0.114)\tLoss 0.4309 (0.7694)\tAcc 0.778 (0.685)\n",
      "validation at epoch 69\n",
      "Epoch: [69][1/9]\tTime 0.392 (0.392)\tData 0.367 (0.367)\tLoss 0.2880 (0.2880)\tAcc 0.938 (0.938)\n",
      "Epoch: [69][2/9]\tTime 0.081 (0.236)\tData 0.055 (0.211)\tLoss 0.9719 (0.6299)\tAcc 0.438 (0.688)\n",
      "Epoch: [69][3/9]\tTime 0.072 (0.182)\tData 0.051 (0.158)\tLoss 0.6329 (0.6309)\tAcc 0.688 (0.688)\n",
      "Epoch: [69][4/9]\tTime 0.073 (0.155)\tData 0.053 (0.132)\tLoss 0.6418 (0.6336)\tAcc 0.750 (0.703)\n",
      "Epoch: [69][5/9]\tTime 0.074 (0.138)\tData 0.054 (0.116)\tLoss 0.9650 (0.6999)\tAcc 0.625 (0.688)\n",
      "Epoch: [69][6/9]\tTime 0.074 (0.128)\tData 0.054 (0.106)\tLoss 0.2140 (0.6189)\tAcc 1.000 (0.740)\n",
      "Epoch: [69][7/9]\tTime 0.076 (0.120)\tData 0.056 (0.099)\tLoss 0.6123 (0.6180)\tAcc 0.688 (0.732)\n",
      "Epoch: [69][8/9]\tTime 0.080 (0.115)\tData 0.059 (0.094)\tLoss 1.2528 (0.6973)\tAcc 0.500 (0.703)\n",
      "Epoch: [69][9/9]\tTime 0.079 (0.111)\tData 0.059 (0.090)\tLoss 0.0520 (0.6874)\tAcc 1.000 (0.708)\n",
      "train at epoch 70\n",
      "Epoch: [70][1/5]\tTime 0.320 (0.320)\tData 0.290 (0.290)\tLoss 1.1066 (1.1066)\tAcc 0.500 (0.500)\n",
      "Epoch: [70][2/5]\tTime 0.073 (0.197)\tData 0.049 (0.170)\tLoss 0.6133 (0.8600)\tAcc 0.875 (0.688)\n",
      "Epoch: [70][3/5]\tTime 0.080 (0.158)\tData 0.056 (0.132)\tLoss 0.7484 (0.8228)\tAcc 0.688 (0.688)\n",
      "Epoch: [70][4/5]\tTime 0.085 (0.140)\tData 0.060 (0.114)\tLoss 0.4700 (0.7346)\tAcc 0.812 (0.719)\n",
      "Epoch: [70][5/5]\tTime 0.086 (0.129)\tData 0.061 (0.103)\tLoss 1.0742 (0.7765)\tAcc 0.667 (0.712)\n",
      "validation at epoch 70\n",
      "Epoch: [70][1/9]\tTime 0.293 (0.293)\tData 0.267 (0.267)\tLoss 0.3659 (0.3659)\tAcc 0.938 (0.938)\n",
      "Epoch: [70][2/9]\tTime 0.083 (0.188)\tData 0.056 (0.162)\tLoss 1.0767 (0.7213)\tAcc 0.562 (0.750)\n",
      "Epoch: [70][3/9]\tTime 0.070 (0.149)\tData 0.049 (0.124)\tLoss 0.5253 (0.6559)\tAcc 0.750 (0.750)\n",
      "Epoch: [70][4/9]\tTime 0.076 (0.131)\tData 0.053 (0.106)\tLoss 0.5277 (0.6239)\tAcc 0.875 (0.781)\n",
      "Epoch: [70][5/9]\tTime 0.073 (0.119)\tData 0.052 (0.095)\tLoss 0.8340 (0.6659)\tAcc 0.562 (0.738)\n",
      "Epoch: [70][6/9]\tTime 0.073 (0.111)\tData 0.054 (0.088)\tLoss 0.3106 (0.6067)\tAcc 1.000 (0.781)\n",
      "Epoch: [70][7/9]\tTime 0.074 (0.106)\tData 0.054 (0.084)\tLoss 0.6679 (0.6154)\tAcc 0.750 (0.777)\n",
      "Epoch: [70][8/9]\tTime 0.080 (0.103)\tData 0.060 (0.081)\tLoss 0.8872 (0.6494)\tAcc 0.625 (0.758)\n",
      "Epoch: [70][9/9]\tTime 0.080 (0.100)\tData 0.060 (0.078)\tLoss 0.2037 (0.6426)\tAcc 1.000 (0.762)\n",
      "train at epoch 71\n",
      "Epoch: [71][1/5]\tTime 0.311 (0.311)\tData 0.284 (0.284)\tLoss 0.6809 (0.6809)\tAcc 0.688 (0.688)\n",
      "Epoch: [71][2/5]\tTime 0.076 (0.194)\tData 0.051 (0.167)\tLoss 1.0393 (0.8601)\tAcc 0.625 (0.656)\n",
      "Epoch: [71][3/5]\tTime 0.077 (0.155)\tData 0.054 (0.130)\tLoss 0.8871 (0.8691)\tAcc 0.562 (0.625)\n",
      "Epoch: [71][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.111)\tLoss 0.4783 (0.7714)\tAcc 0.812 (0.672)\n",
      "Epoch: [71][5/5]\tTime 0.081 (0.125)\tData 0.058 (0.100)\tLoss 0.6102 (0.7515)\tAcc 0.889 (0.699)\n",
      "validation at epoch 71\n",
      "Epoch: [71][1/9]\tTime 0.304 (0.304)\tData 0.278 (0.278)\tLoss 0.3027 (0.3027)\tAcc 0.938 (0.938)\n",
      "Epoch: [71][2/9]\tTime 0.070 (0.187)\tData 0.049 (0.163)\tLoss 0.8528 (0.5777)\tAcc 0.750 (0.844)\n",
      "Epoch: [71][3/9]\tTime 0.074 (0.149)\tData 0.053 (0.127)\tLoss 0.4566 (0.5374)\tAcc 0.812 (0.833)\n",
      "Epoch: [71][4/9]\tTime 0.075 (0.130)\tData 0.053 (0.108)\tLoss 0.5973 (0.5524)\tAcc 0.875 (0.844)\n",
      "Epoch: [71][5/9]\tTime 0.076 (0.119)\tData 0.054 (0.097)\tLoss 0.7275 (0.5874)\tAcc 0.625 (0.800)\n",
      "Epoch: [71][6/9]\tTime 0.071 (0.111)\tData 0.053 (0.090)\tLoss 0.2550 (0.5320)\tAcc 1.000 (0.833)\n",
      "Epoch: [71][7/9]\tTime 0.073 (0.106)\tData 0.055 (0.085)\tLoss 0.7793 (0.5673)\tAcc 0.625 (0.804)\n",
      "Epoch: [71][8/9]\tTime 0.076 (0.102)\tData 0.056 (0.081)\tLoss 1.0144 (0.6232)\tAcc 0.500 (0.766)\n",
      "Epoch: [71][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.078)\tLoss 0.1306 (0.6156)\tAcc 1.000 (0.769)\n",
      "train at epoch 72\n",
      "Epoch: [72][1/5]\tTime 0.289 (0.289)\tData 0.258 (0.258)\tLoss 0.6688 (0.6688)\tAcc 0.812 (0.812)\n",
      "Epoch: [72][2/5]\tTime 0.072 (0.181)\tData 0.048 (0.153)\tLoss 0.7857 (0.7273)\tAcc 0.688 (0.750)\n",
      "Epoch: [72][3/5]\tTime 0.077 (0.146)\tData 0.054 (0.120)\tLoss 0.7064 (0.7203)\tAcc 0.750 (0.750)\n",
      "Epoch: [72][4/5]\tTime 0.077 (0.129)\tData 0.054 (0.103)\tLoss 1.1233 (0.8211)\tAcc 0.562 (0.703)\n",
      "Epoch: [72][5/5]\tTime 0.084 (0.120)\tData 0.058 (0.094)\tLoss 1.2118 (0.8692)\tAcc 0.667 (0.699)\n",
      "validation at epoch 72\n",
      "Epoch: [72][1/9]\tTime 0.307 (0.307)\tData 0.283 (0.283)\tLoss 0.3461 (0.3461)\tAcc 0.938 (0.938)\n",
      "Epoch: [72][2/9]\tTime 0.072 (0.189)\tData 0.051 (0.167)\tLoss 0.9858 (0.6659)\tAcc 0.500 (0.719)\n",
      "Epoch: [72][3/9]\tTime 0.073 (0.151)\tData 0.053 (0.129)\tLoss 0.6252 (0.6524)\tAcc 0.688 (0.708)\n",
      "Epoch: [72][4/9]\tTime 0.073 (0.131)\tData 0.053 (0.110)\tLoss 0.5968 (0.6385)\tAcc 0.812 (0.734)\n",
      "Epoch: [72][5/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.7431 (0.6594)\tAcc 0.688 (0.725)\n",
      "Epoch: [72][6/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.1914 (0.5814)\tAcc 1.000 (0.771)\n",
      "Epoch: [72][7/9]\tTime 0.072 (0.106)\tData 0.054 (0.086)\tLoss 0.6732 (0.5945)\tAcc 0.750 (0.768)\n",
      "Epoch: [72][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.082)\tLoss 0.9890 (0.6438)\tAcc 0.562 (0.742)\n",
      "Epoch: [72][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.079)\tLoss 0.1133 (0.6357)\tAcc 1.000 (0.746)\n",
      "train at epoch 73\n",
      "Epoch: [73][1/5]\tTime 0.298 (0.298)\tData 0.269 (0.269)\tLoss 1.0192 (1.0192)\tAcc 0.625 (0.625)\n",
      "Epoch: [73][2/5]\tTime 0.077 (0.188)\tData 0.050 (0.159)\tLoss 0.9131 (0.9662)\tAcc 0.625 (0.625)\n",
      "Epoch: [73][3/5]\tTime 0.075 (0.150)\tData 0.051 (0.123)\tLoss 0.4624 (0.7982)\tAcc 0.938 (0.729)\n",
      "Epoch: [73][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.106)\tLoss 0.5697 (0.7411)\tAcc 0.750 (0.734)\n",
      "Epoch: [73][5/5]\tTime 0.079 (0.121)\tData 0.055 (0.096)\tLoss 1.1410 (0.7904)\tAcc 0.556 (0.712)\n",
      "validation at epoch 73\n",
      "Epoch: [73][1/9]\tTime 0.288 (0.288)\tData 0.264 (0.264)\tLoss 0.3896 (0.3896)\tAcc 0.938 (0.938)\n",
      "Epoch: [73][2/9]\tTime 0.104 (0.196)\tData 0.084 (0.174)\tLoss 0.9909 (0.6903)\tAcc 0.625 (0.781)\n",
      "Epoch: [73][3/9]\tTime 0.076 (0.156)\tData 0.053 (0.134)\tLoss 0.6167 (0.6657)\tAcc 0.750 (0.771)\n",
      "Epoch: [73][4/9]\tTime 0.072 (0.135)\tData 0.051 (0.113)\tLoss 0.6506 (0.6620)\tAcc 0.750 (0.766)\n",
      "Epoch: [73][5/9]\tTime 0.076 (0.123)\tData 0.056 (0.101)\tLoss 0.8066 (0.6909)\tAcc 0.750 (0.762)\n",
      "Epoch: [73][6/9]\tTime 0.072 (0.115)\tData 0.054 (0.094)\tLoss 0.2678 (0.6204)\tAcc 1.000 (0.802)\n",
      "Epoch: [73][7/9]\tTime 0.075 (0.109)\tData 0.054 (0.088)\tLoss 0.7310 (0.6362)\tAcc 0.688 (0.786)\n",
      "Epoch: [73][8/9]\tTime 0.073 (0.105)\tData 0.053 (0.084)\tLoss 1.1059 (0.6949)\tAcc 0.562 (0.758)\n",
      "Epoch: [73][9/9]\tTime 0.073 (0.101)\tData 0.054 (0.080)\tLoss 0.2610 (0.6882)\tAcc 1.000 (0.762)\n",
      "train at epoch 74\n",
      "Epoch: [74][1/5]\tTime 0.302 (0.302)\tData 0.270 (0.270)\tLoss 0.4760 (0.4760)\tAcc 0.875 (0.875)\n",
      "Epoch: [74][2/5]\tTime 0.071 (0.186)\tData 0.047 (0.158)\tLoss 0.7719 (0.6240)\tAcc 0.625 (0.750)\n",
      "Epoch: [74][3/5]\tTime 0.077 (0.150)\tData 0.054 (0.124)\tLoss 0.9264 (0.7248)\tAcc 0.625 (0.708)\n",
      "Epoch: [74][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.106)\tLoss 0.6229 (0.6993)\tAcc 0.812 (0.734)\n",
      "Epoch: [74][5/5]\tTime 0.080 (0.121)\tData 0.057 (0.096)\tLoss 0.7618 (0.7070)\tAcc 0.667 (0.726)\n",
      "validation at epoch 74\n",
      "Epoch: [74][1/9]\tTime 0.324 (0.324)\tData 0.300 (0.300)\tLoss 0.2965 (0.2965)\tAcc 0.938 (0.938)\n",
      "Epoch: [74][2/9]\tTime 0.071 (0.198)\tData 0.050 (0.175)\tLoss 0.9795 (0.6380)\tAcc 0.562 (0.750)\n",
      "Epoch: [74][3/9]\tTime 0.074 (0.156)\tData 0.052 (0.134)\tLoss 0.6823 (0.6528)\tAcc 0.688 (0.729)\n",
      "Epoch: [74][4/9]\tTime 0.073 (0.136)\tData 0.052 (0.114)\tLoss 0.6826 (0.6602)\tAcc 0.688 (0.719)\n",
      "Epoch: [74][5/9]\tTime 0.072 (0.123)\tData 0.053 (0.101)\tLoss 0.8843 (0.7050)\tAcc 0.625 (0.700)\n",
      "Epoch: [74][6/9]\tTime 0.073 (0.115)\tData 0.054 (0.094)\tLoss 0.3460 (0.6452)\tAcc 1.000 (0.750)\n",
      "Epoch: [74][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.088)\tLoss 0.7950 (0.6666)\tAcc 0.688 (0.741)\n",
      "Epoch: [74][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.084)\tLoss 1.1475 (0.7267)\tAcc 0.438 (0.703)\n",
      "Epoch: [74][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.081)\tLoss 0.2705 (0.7197)\tAcc 1.000 (0.708)\n",
      "train at epoch 75\n",
      "Epoch: [75][1/5]\tTime 0.305 (0.305)\tData 0.274 (0.274)\tLoss 0.8193 (0.8193)\tAcc 0.688 (0.688)\n",
      "Epoch: [75][2/5]\tTime 0.072 (0.188)\tData 0.048 (0.161)\tLoss 0.9686 (0.8939)\tAcc 0.625 (0.656)\n",
      "Epoch: [75][3/5]\tTime 0.077 (0.151)\tData 0.054 (0.125)\tLoss 0.8710 (0.8863)\tAcc 0.562 (0.625)\n",
      "Epoch: [75][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.107)\tLoss 0.4427 (0.7754)\tAcc 0.812 (0.672)\n",
      "Epoch: [75][5/5]\tTime 0.081 (0.122)\tData 0.057 (0.097)\tLoss 0.6625 (0.7614)\tAcc 0.778 (0.685)\n",
      "validation at epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][1/9]\tTime 0.305 (0.305)\tData 0.278 (0.278)\tLoss 0.3458 (0.3458)\tAcc 0.875 (0.875)\n",
      "Epoch: [75][2/9]\tTime 0.070 (0.187)\tData 0.048 (0.163)\tLoss 1.0394 (0.6926)\tAcc 0.562 (0.719)\n",
      "Epoch: [75][3/9]\tTime 0.073 (0.149)\tData 0.052 (0.126)\tLoss 0.6963 (0.6938)\tAcc 0.625 (0.688)\n",
      "Epoch: [75][4/9]\tTime 0.075 (0.131)\tData 0.052 (0.108)\tLoss 0.6157 (0.6743)\tAcc 0.812 (0.719)\n",
      "Epoch: [75][5/9]\tTime 0.071 (0.119)\tData 0.052 (0.097)\tLoss 0.8328 (0.7060)\tAcc 0.688 (0.713)\n",
      "Epoch: [75][6/9]\tTime 0.079 (0.112)\tData 0.060 (0.090)\tLoss 0.2438 (0.6290)\tAcc 1.000 (0.760)\n",
      "Epoch: [75][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.5571 (0.6187)\tAcc 0.875 (0.777)\n",
      "Epoch: [75][8/9]\tTime 0.075 (0.103)\tData 0.056 (0.082)\tLoss 1.1433 (0.6843)\tAcc 0.500 (0.742)\n",
      "Epoch: [75][9/9]\tTime 0.073 (0.099)\tData 0.054 (0.079)\tLoss 0.4088 (0.6800)\tAcc 1.000 (0.746)\n",
      "train at epoch 76\n",
      "Epoch: [76][1/5]\tTime 0.326 (0.326)\tData 0.296 (0.296)\tLoss 0.7863 (0.7863)\tAcc 0.750 (0.750)\n",
      "Epoch: [76][2/5]\tTime 0.074 (0.200)\tData 0.049 (0.172)\tLoss 0.8396 (0.8130)\tAcc 0.625 (0.688)\n",
      "Epoch: [76][3/5]\tTime 0.075 (0.159)\tData 0.052 (0.132)\tLoss 0.6679 (0.7646)\tAcc 0.625 (0.667)\n",
      "Epoch: [76][4/5]\tTime 0.077 (0.138)\tData 0.054 (0.113)\tLoss 0.6276 (0.7304)\tAcc 0.750 (0.688)\n",
      "Epoch: [76][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.101)\tLoss 0.9609 (0.7588)\tAcc 0.667 (0.685)\n",
      "validation at epoch 76\n",
      "Epoch: [76][1/9]\tTime 0.331 (0.331)\tData 0.307 (0.307)\tLoss 0.3583 (0.3583)\tAcc 0.938 (0.938)\n",
      "Epoch: [76][2/9]\tTime 0.072 (0.201)\tData 0.050 (0.178)\tLoss 1.0234 (0.6908)\tAcc 0.562 (0.750)\n",
      "Epoch: [76][3/9]\tTime 0.074 (0.159)\tData 0.052 (0.136)\tLoss 0.6183 (0.6667)\tAcc 0.688 (0.729)\n",
      "Epoch: [76][4/9]\tTime 0.073 (0.137)\tData 0.052 (0.115)\tLoss 0.6163 (0.6541)\tAcc 0.750 (0.734)\n",
      "Epoch: [76][5/9]\tTime 0.074 (0.125)\tData 0.055 (0.103)\tLoss 0.9678 (0.7168)\tAcc 0.625 (0.713)\n",
      "Epoch: [76][6/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.2511 (0.6392)\tAcc 1.000 (0.760)\n",
      "Epoch: [76][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6168 (0.6360)\tAcc 0.812 (0.768)\n",
      "Epoch: [76][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.085)\tLoss 1.1383 (0.6988)\tAcc 0.562 (0.742)\n",
      "Epoch: [76][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.082)\tLoss 0.2708 (0.6922)\tAcc 1.000 (0.746)\n",
      "train at epoch 77\n",
      "Epoch: [77][1/5]\tTime 0.314 (0.314)\tData 0.283 (0.283)\tLoss 0.6201 (0.6201)\tAcc 0.750 (0.750)\n",
      "Epoch: [77][2/5]\tTime 0.073 (0.194)\tData 0.048 (0.166)\tLoss 0.6443 (0.6322)\tAcc 0.875 (0.812)\n",
      "Epoch: [77][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.128)\tLoss 0.8143 (0.6929)\tAcc 0.688 (0.771)\n",
      "Epoch: [77][4/5]\tTime 0.076 (0.135)\tData 0.053 (0.109)\tLoss 1.2154 (0.8235)\tAcc 0.500 (0.703)\n",
      "Epoch: [77][5/5]\tTime 0.079 (0.124)\tData 0.056 (0.099)\tLoss 0.5203 (0.7861)\tAcc 0.889 (0.726)\n",
      "validation at epoch 77\n",
      "Epoch: [77][1/9]\tTime 0.282 (0.282)\tData 0.255 (0.255)\tLoss 0.3363 (0.3363)\tAcc 0.875 (0.875)\n",
      "Epoch: [77][2/9]\tTime 0.069 (0.176)\tData 0.048 (0.151)\tLoss 0.9634 (0.6499)\tAcc 0.688 (0.781)\n",
      "Epoch: [77][3/9]\tTime 0.074 (0.142)\tData 0.053 (0.119)\tLoss 0.6062 (0.6353)\tAcc 0.750 (0.771)\n",
      "Epoch: [77][4/9]\tTime 0.074 (0.125)\tData 0.052 (0.102)\tLoss 0.6137 (0.6299)\tAcc 0.750 (0.766)\n",
      "Epoch: [77][5/9]\tTime 0.072 (0.114)\tData 0.052 (0.092)\tLoss 0.9416 (0.6922)\tAcc 0.562 (0.725)\n",
      "Epoch: [77][6/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.2457 (0.6178)\tAcc 1.000 (0.771)\n",
      "Epoch: [77][7/9]\tTime 0.073 (0.103)\tData 0.054 (0.081)\tLoss 0.6942 (0.6287)\tAcc 0.750 (0.768)\n",
      "Epoch: [77][8/9]\tTime 0.075 (0.099)\tData 0.056 (0.078)\tLoss 1.1283 (0.6912)\tAcc 0.438 (0.727)\n",
      "Epoch: [77][9/9]\tTime 0.073 (0.096)\tData 0.054 (0.075)\tLoss 0.3159 (0.6854)\tAcc 1.000 (0.731)\n",
      "train at epoch 78\n",
      "Epoch: [78][1/5]\tTime 0.327 (0.327)\tData 0.300 (0.300)\tLoss 0.9389 (0.9389)\tAcc 0.625 (0.625)\n",
      "Epoch: [78][2/5]\tTime 0.076 (0.202)\tData 0.052 (0.176)\tLoss 0.6511 (0.7950)\tAcc 0.688 (0.656)\n",
      "Epoch: [78][3/5]\tTime 0.077 (0.160)\tData 0.053 (0.135)\tLoss 0.5223 (0.7041)\tAcc 0.875 (0.729)\n",
      "Epoch: [78][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.115)\tLoss 1.0719 (0.7960)\tAcc 0.562 (0.688)\n",
      "Epoch: [78][5/5]\tTime 0.079 (0.127)\tData 0.056 (0.103)\tLoss 0.7996 (0.7965)\tAcc 0.667 (0.685)\n",
      "validation at epoch 78\n",
      "Epoch: [78][1/9]\tTime 0.332 (0.332)\tData 0.308 (0.308)\tLoss 0.3177 (0.3177)\tAcc 0.938 (0.938)\n",
      "Epoch: [78][2/9]\tTime 0.072 (0.202)\tData 0.051 (0.179)\tLoss 1.0212 (0.6695)\tAcc 0.500 (0.719)\n",
      "Epoch: [78][3/9]\tTime 0.074 (0.159)\tData 0.053 (0.137)\tLoss 0.6050 (0.6480)\tAcc 0.688 (0.708)\n",
      "Epoch: [78][4/9]\tTime 0.074 (0.138)\tData 0.053 (0.116)\tLoss 0.5727 (0.6292)\tAcc 0.750 (0.719)\n",
      "Epoch: [78][5/9]\tTime 0.078 (0.126)\tData 0.059 (0.105)\tLoss 0.7869 (0.6607)\tAcc 0.625 (0.700)\n",
      "Epoch: [78][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.2688 (0.5954)\tAcc 1.000 (0.750)\n",
      "Epoch: [78][7/9]\tTime 0.073 (0.111)\tData 0.055 (0.090)\tLoss 0.8529 (0.6322)\tAcc 0.562 (0.723)\n",
      "Epoch: [78][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.086)\tLoss 0.9118 (0.6671)\tAcc 0.625 (0.711)\n",
      "Epoch: [78][9/9]\tTime 0.073 (0.103)\tData 0.055 (0.083)\tLoss 0.3369 (0.6621)\tAcc 1.000 (0.715)\n",
      "train at epoch 79\n",
      "Epoch: [79][1/5]\tTime 0.343 (0.343)\tData 0.315 (0.315)\tLoss 0.6749 (0.6749)\tAcc 0.750 (0.750)\n",
      "Epoch: [79][2/5]\tTime 0.075 (0.209)\tData 0.051 (0.183)\tLoss 0.5057 (0.5903)\tAcc 0.875 (0.812)\n",
      "Epoch: [79][3/5]\tTime 0.077 (0.165)\tData 0.054 (0.140)\tLoss 0.9180 (0.6995)\tAcc 0.688 (0.771)\n",
      "Epoch: [79][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.118)\tLoss 0.8154 (0.7285)\tAcc 0.625 (0.734)\n",
      "Epoch: [79][5/5]\tTime 0.079 (0.130)\tData 0.056 (0.106)\tLoss 0.9818 (0.7597)\tAcc 0.667 (0.726)\n",
      "validation at epoch 79\n",
      "Epoch: [79][1/9]\tTime 0.366 (0.366)\tData 0.342 (0.342)\tLoss 0.3507 (0.3507)\tAcc 0.938 (0.938)\n",
      "Epoch: [79][2/9]\tTime 0.072 (0.219)\tData 0.050 (0.196)\tLoss 0.8966 (0.6237)\tAcc 0.562 (0.750)\n",
      "Epoch: [79][3/9]\tTime 0.077 (0.172)\tData 0.053 (0.149)\tLoss 0.5783 (0.6085)\tAcc 0.875 (0.792)\n",
      "Epoch: [79][4/9]\tTime 0.070 (0.146)\tData 0.050 (0.124)\tLoss 0.7203 (0.6365)\tAcc 0.750 (0.781)\n",
      "Epoch: [79][5/9]\tTime 0.074 (0.132)\tData 0.055 (0.110)\tLoss 0.7937 (0.6679)\tAcc 0.688 (0.762)\n",
      "Epoch: [79][6/9]\tTime 0.072 (0.122)\tData 0.054 (0.101)\tLoss 0.2663 (0.6010)\tAcc 1.000 (0.802)\n",
      "Epoch: [79][7/9]\tTime 0.073 (0.115)\tData 0.055 (0.094)\tLoss 0.5794 (0.5979)\tAcc 0.812 (0.804)\n",
      "Epoch: [79][8/9]\tTime 0.075 (0.110)\tData 0.056 (0.089)\tLoss 0.9465 (0.6415)\tAcc 0.688 (0.789)\n",
      "Epoch: [79][9/9]\tTime 0.073 (0.106)\tData 0.055 (0.086)\tLoss 0.1067 (0.6332)\tAcc 1.000 (0.792)\n",
      "train at epoch 80\n",
      "Epoch: [80][1/5]\tTime 0.270 (0.270)\tData 0.241 (0.241)\tLoss 0.9751 (0.9751)\tAcc 0.562 (0.562)\n",
      "Epoch: [80][2/5]\tTime 0.094 (0.182)\tData 0.069 (0.155)\tLoss 0.6247 (0.7999)\tAcc 0.625 (0.594)\n",
      "Epoch: [80][3/5]\tTime 0.076 (0.147)\tData 0.052 (0.121)\tLoss 0.6948 (0.7649)\tAcc 0.812 (0.667)\n",
      "Epoch: [80][4/5]\tTime 0.081 (0.130)\tData 0.057 (0.105)\tLoss 0.5803 (0.7187)\tAcc 0.750 (0.688)\n",
      "Epoch: [80][5/5]\tTime 0.079 (0.120)\tData 0.056 (0.095)\tLoss 0.7874 (0.7272)\tAcc 0.556 (0.671)\n",
      "validation at epoch 80\n",
      "Epoch: [80][1/9]\tTime 0.447 (0.447)\tData 0.423 (0.423)\tLoss 0.2912 (0.2912)\tAcc 0.938 (0.938)\n",
      "Epoch: [80][2/9]\tTime 0.072 (0.259)\tData 0.050 (0.237)\tLoss 0.9278 (0.6095)\tAcc 0.438 (0.688)\n",
      "Epoch: [80][3/9]\tTime 0.072 (0.197)\tData 0.052 (0.175)\tLoss 0.6299 (0.6163)\tAcc 0.750 (0.708)\n",
      "Epoch: [80][4/9]\tTime 0.073 (0.166)\tData 0.054 (0.145)\tLoss 0.5844 (0.6083)\tAcc 0.875 (0.750)\n",
      "Epoch: [80][5/9]\tTime 0.073 (0.147)\tData 0.054 (0.127)\tLoss 0.9011 (0.6669)\tAcc 0.562 (0.713)\n",
      "Epoch: [80][6/9]\tTime 0.073 (0.135)\tData 0.054 (0.115)\tLoss 0.2502 (0.5974)\tAcc 1.000 (0.760)\n",
      "Epoch: [80][7/9]\tTime 0.073 (0.126)\tData 0.054 (0.106)\tLoss 0.5546 (0.5913)\tAcc 0.750 (0.759)\n",
      "Epoch: [80][8/9]\tTime 0.075 (0.120)\tData 0.055 (0.100)\tLoss 1.0501 (0.6487)\tAcc 0.500 (0.727)\n",
      "Epoch: [80][9/9]\tTime 0.073 (0.115)\tData 0.055 (0.095)\tLoss 0.2214 (0.6421)\tAcc 1.000 (0.731)\n",
      "train at epoch 81\n",
      "Epoch: [81][1/5]\tTime 0.335 (0.335)\tData 0.302 (0.302)\tLoss 1.1010 (1.1010)\tAcc 0.500 (0.500)\n",
      "Epoch: [81][2/5]\tTime 0.071 (0.203)\tData 0.047 (0.175)\tLoss 0.7881 (0.9446)\tAcc 0.812 (0.656)\n",
      "Epoch: [81][3/5]\tTime 0.077 (0.161)\tData 0.054 (0.134)\tLoss 1.2684 (1.0525)\tAcc 0.500 (0.604)\n",
      "Epoch: [81][4/5]\tTime 0.077 (0.140)\tData 0.054 (0.114)\tLoss 0.3981 (0.8889)\tAcc 0.938 (0.688)\n",
      "Epoch: [81][5/5]\tTime 0.082 (0.128)\tData 0.056 (0.103)\tLoss 0.3260 (0.8195)\tAcc 1.000 (0.726)\n",
      "validation at epoch 81\n",
      "Epoch: [81][1/9]\tTime 0.386 (0.386)\tData 0.361 (0.361)\tLoss 0.2312 (0.2312)\tAcc 1.000 (1.000)\n",
      "Epoch: [81][2/9]\tTime 0.070 (0.228)\tData 0.049 (0.205)\tLoss 0.9749 (0.6031)\tAcc 0.562 (0.781)\n",
      "Epoch: [81][3/9]\tTime 0.075 (0.177)\tData 0.052 (0.154)\tLoss 0.6144 (0.6068)\tAcc 0.812 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][4/9]\tTime 0.073 (0.151)\tData 0.051 (0.128)\tLoss 0.5102 (0.5827)\tAcc 0.812 (0.797)\n",
      "Epoch: [81][5/9]\tTime 0.093 (0.139)\tData 0.073 (0.117)\tLoss 0.7408 (0.6143)\tAcc 0.688 (0.775)\n",
      "Epoch: [81][6/9]\tTime 0.073 (0.128)\tData 0.053 (0.107)\tLoss 0.2979 (0.5616)\tAcc 1.000 (0.812)\n",
      "Epoch: [81][7/9]\tTime 0.073 (0.120)\tData 0.053 (0.099)\tLoss 0.7016 (0.5816)\tAcc 0.750 (0.804)\n",
      "Epoch: [81][8/9]\tTime 0.074 (0.115)\tData 0.054 (0.093)\tLoss 1.0256 (0.6371)\tAcc 0.500 (0.766)\n",
      "Epoch: [81][9/9]\tTime 0.072 (0.110)\tData 0.054 (0.089)\tLoss 0.1552 (0.6297)\tAcc 1.000 (0.769)\n",
      "train at epoch 82\n",
      "Epoch: [82][1/5]\tTime 0.323 (0.323)\tData 0.295 (0.295)\tLoss 0.5541 (0.5541)\tAcc 0.875 (0.875)\n",
      "Epoch: [82][2/5]\tTime 0.075 (0.199)\tData 0.050 (0.173)\tLoss 0.7601 (0.6571)\tAcc 0.688 (0.781)\n",
      "Epoch: [82][3/5]\tTime 0.077 (0.158)\tData 0.053 (0.133)\tLoss 0.8430 (0.7191)\tAcc 0.750 (0.771)\n",
      "Epoch: [82][4/5]\tTime 0.077 (0.138)\tData 0.054 (0.113)\tLoss 0.8366 (0.7484)\tAcc 0.750 (0.766)\n",
      "Epoch: [82][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.102)\tLoss 0.6398 (0.7350)\tAcc 0.778 (0.767)\n",
      "validation at epoch 82\n",
      "Epoch: [82][1/9]\tTime 0.302 (0.302)\tData 0.275 (0.275)\tLoss 0.3073 (0.3073)\tAcc 0.938 (0.938)\n",
      "Epoch: [82][2/9]\tTime 0.068 (0.185)\tData 0.047 (0.161)\tLoss 1.0092 (0.6582)\tAcc 0.500 (0.719)\n",
      "Epoch: [82][3/9]\tTime 0.074 (0.148)\tData 0.053 (0.125)\tLoss 0.6666 (0.6610)\tAcc 0.688 (0.708)\n",
      "Epoch: [82][4/9]\tTime 0.073 (0.129)\tData 0.052 (0.107)\tLoss 0.7435 (0.6817)\tAcc 0.688 (0.703)\n",
      "Epoch: [82][5/9]\tTime 0.073 (0.118)\tData 0.054 (0.096)\tLoss 0.7398 (0.6933)\tAcc 0.750 (0.713)\n",
      "Epoch: [82][6/9]\tTime 0.072 (0.110)\tData 0.054 (0.089)\tLoss 0.2286 (0.6158)\tAcc 1.000 (0.760)\n",
      "Epoch: [82][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.6580 (0.6219)\tAcc 0.812 (0.768)\n",
      "Epoch: [82][8/9]\tTime 0.074 (0.101)\tData 0.055 (0.080)\tLoss 1.0613 (0.6768)\tAcc 0.625 (0.750)\n",
      "Epoch: [82][9/9]\tTime 0.073 (0.098)\tData 0.055 (0.078)\tLoss 0.2652 (0.6705)\tAcc 1.000 (0.754)\n",
      "train at epoch 83\n",
      "Epoch: [83][1/5]\tTime 0.317 (0.317)\tData 0.287 (0.287)\tLoss 0.6793 (0.6793)\tAcc 0.750 (0.750)\n",
      "Epoch: [83][2/5]\tTime 0.073 (0.195)\tData 0.049 (0.168)\tLoss 0.8600 (0.7696)\tAcc 0.688 (0.719)\n",
      "Epoch: [83][3/5]\tTime 0.077 (0.155)\tData 0.053 (0.130)\tLoss 0.8003 (0.7799)\tAcc 0.688 (0.708)\n",
      "Epoch: [83][4/5]\tTime 0.077 (0.136)\tData 0.054 (0.111)\tLoss 0.4944 (0.7085)\tAcc 0.875 (0.750)\n",
      "Epoch: [83][5/5]\tTime 0.079 (0.124)\tData 0.056 (0.100)\tLoss 0.8482 (0.7257)\tAcc 0.667 (0.740)\n",
      "validation at epoch 83\n",
      "Epoch: [83][1/9]\tTime 0.299 (0.299)\tData 0.275 (0.275)\tLoss 0.3359 (0.3359)\tAcc 0.938 (0.938)\n",
      "Epoch: [83][2/9]\tTime 0.071 (0.185)\tData 0.050 (0.163)\tLoss 0.9350 (0.6355)\tAcc 0.500 (0.719)\n",
      "Epoch: [83][3/9]\tTime 0.073 (0.148)\tData 0.052 (0.126)\tLoss 0.6317 (0.6342)\tAcc 0.688 (0.708)\n",
      "Epoch: [83][4/9]\tTime 0.074 (0.130)\tData 0.053 (0.108)\tLoss 0.7080 (0.6527)\tAcc 0.625 (0.688)\n",
      "Epoch: [83][5/9]\tTime 0.072 (0.118)\tData 0.053 (0.097)\tLoss 0.8609 (0.6943)\tAcc 0.625 (0.675)\n",
      "Epoch: [83][6/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.2847 (0.6261)\tAcc 1.000 (0.729)\n",
      "Epoch: [83][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.7500 (0.6438)\tAcc 0.688 (0.723)\n",
      "Epoch: [83][8/9]\tTime 0.075 (0.101)\tData 0.056 (0.081)\tLoss 1.1269 (0.7041)\tAcc 0.562 (0.703)\n",
      "Epoch: [83][9/9]\tTime 0.073 (0.098)\tData 0.055 (0.078)\tLoss 0.1911 (0.6963)\tAcc 1.000 (0.708)\n",
      "train at epoch 84\n",
      "Epoch: [84][1/5]\tTime 0.287 (0.287)\tData 0.256 (0.256)\tLoss 0.4938 (0.4938)\tAcc 0.812 (0.812)\n",
      "Epoch: [84][2/5]\tTime 0.073 (0.180)\tData 0.049 (0.152)\tLoss 0.5262 (0.5100)\tAcc 0.875 (0.844)\n",
      "Epoch: [84][3/5]\tTime 0.077 (0.146)\tData 0.053 (0.119)\tLoss 1.0222 (0.6808)\tAcc 0.500 (0.729)\n",
      "Epoch: [84][4/5]\tTime 0.077 (0.128)\tData 0.054 (0.103)\tLoss 0.7582 (0.7001)\tAcc 0.688 (0.719)\n",
      "Epoch: [84][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.094)\tLoss 0.5550 (0.6822)\tAcc 0.667 (0.712)\n",
      "validation at epoch 84\n",
      "Epoch: [84][1/9]\tTime 0.310 (0.310)\tData 0.284 (0.284)\tLoss 0.3879 (0.3879)\tAcc 0.875 (0.875)\n",
      "Epoch: [84][2/9]\tTime 0.070 (0.190)\tData 0.048 (0.166)\tLoss 1.0958 (0.7419)\tAcc 0.500 (0.688)\n",
      "Epoch: [84][3/9]\tTime 0.074 (0.151)\tData 0.053 (0.128)\tLoss 0.7115 (0.7318)\tAcc 0.688 (0.688)\n",
      "Epoch: [84][4/9]\tTime 0.077 (0.133)\tData 0.052 (0.109)\tLoss 0.6842 (0.7199)\tAcc 0.688 (0.688)\n",
      "Epoch: [84][5/9]\tTime 0.070 (0.120)\tData 0.050 (0.097)\tLoss 0.6978 (0.7154)\tAcc 0.688 (0.688)\n",
      "Epoch: [84][6/9]\tTime 0.072 (0.112)\tData 0.053 (0.090)\tLoss 0.2490 (0.6377)\tAcc 1.000 (0.740)\n",
      "Epoch: [84][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.5384 (0.6235)\tAcc 0.812 (0.750)\n",
      "Epoch: [84][8/9]\tTime 0.075 (0.103)\tData 0.055 (0.081)\tLoss 1.1044 (0.6836)\tAcc 0.562 (0.727)\n",
      "Epoch: [84][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.078)\tLoss 0.2225 (0.6765)\tAcc 1.000 (0.731)\n",
      "train at epoch 85\n",
      "Epoch: [85][1/5]\tTime 0.301 (0.301)\tData 0.272 (0.272)\tLoss 0.6539 (0.6539)\tAcc 0.688 (0.688)\n",
      "Epoch: [85][2/5]\tTime 0.074 (0.188)\tData 0.050 (0.161)\tLoss 1.0126 (0.8333)\tAcc 0.625 (0.656)\n",
      "Epoch: [85][3/5]\tTime 0.077 (0.151)\tData 0.054 (0.125)\tLoss 0.6423 (0.7696)\tAcc 0.750 (0.688)\n",
      "Epoch: [85][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.107)\tLoss 0.4642 (0.6932)\tAcc 0.750 (0.703)\n",
      "Epoch: [85][5/5]\tTime 0.079 (0.122)\tData 0.056 (0.097)\tLoss 1.2840 (0.7661)\tAcc 0.333 (0.658)\n",
      "validation at epoch 85\n",
      "Epoch: [85][1/9]\tTime 0.311 (0.311)\tData 0.283 (0.283)\tLoss 0.2757 (0.2757)\tAcc 0.938 (0.938)\n",
      "Epoch: [85][2/9]\tTime 0.070 (0.190)\tData 0.047 (0.165)\tLoss 0.9691 (0.6224)\tAcc 0.688 (0.812)\n",
      "Epoch: [85][3/9]\tTime 0.075 (0.152)\tData 0.053 (0.128)\tLoss 0.6003 (0.6150)\tAcc 0.750 (0.792)\n",
      "Epoch: [85][4/9]\tTime 0.073 (0.132)\tData 0.052 (0.109)\tLoss 0.6720 (0.6293)\tAcc 0.625 (0.750)\n",
      "Epoch: [85][5/9]\tTime 0.076 (0.121)\tData 0.055 (0.098)\tLoss 0.9740 (0.6982)\tAcc 0.688 (0.738)\n",
      "Epoch: [85][6/9]\tTime 0.072 (0.113)\tData 0.053 (0.091)\tLoss 0.2291 (0.6200)\tAcc 1.000 (0.781)\n",
      "Epoch: [85][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.085)\tLoss 0.5261 (0.6066)\tAcc 0.812 (0.786)\n",
      "Epoch: [85][8/9]\tTime 0.076 (0.103)\tData 0.056 (0.082)\tLoss 1.0775 (0.6655)\tAcc 0.562 (0.758)\n",
      "Epoch: [85][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.079)\tLoss 0.1206 (0.6571)\tAcc 1.000 (0.762)\n",
      "train at epoch 86\n",
      "Epoch: [86][1/5]\tTime 0.354 (0.354)\tData 0.321 (0.321)\tLoss 0.4618 (0.4618)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][2/5]\tTime 0.070 (0.212)\tData 0.046 (0.183)\tLoss 0.7639 (0.6129)\tAcc 0.688 (0.719)\n",
      "Epoch: [86][3/5]\tTime 0.077 (0.167)\tData 0.053 (0.140)\tLoss 0.6487 (0.6248)\tAcc 0.812 (0.750)\n",
      "Epoch: [86][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.119)\tLoss 0.8621 (0.6841)\tAcc 0.688 (0.734)\n",
      "Epoch: [86][5/5]\tTime 0.079 (0.132)\tData 0.056 (0.106)\tLoss 1.1782 (0.7451)\tAcc 0.556 (0.712)\n",
      "validation at epoch 86\n",
      "Epoch: [86][1/9]\tTime 0.352 (0.352)\tData 0.328 (0.328)\tLoss 0.2941 (0.2941)\tAcc 0.938 (0.938)\n",
      "Epoch: [86][2/9]\tTime 0.072 (0.212)\tData 0.051 (0.189)\tLoss 0.8943 (0.5942)\tAcc 0.562 (0.750)\n",
      "Epoch: [86][3/9]\tTime 0.074 (0.166)\tData 0.053 (0.144)\tLoss 0.6071 (0.5985)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][4/9]\tTime 0.073 (0.143)\tData 0.053 (0.121)\tLoss 0.7374 (0.6332)\tAcc 0.750 (0.750)\n",
      "Epoch: [86][5/9]\tTime 0.073 (0.129)\tData 0.054 (0.108)\tLoss 0.9357 (0.6937)\tAcc 0.625 (0.725)\n",
      "Epoch: [86][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.099)\tLoss 0.2386 (0.6179)\tAcc 1.000 (0.771)\n",
      "Epoch: [86][7/9]\tTime 0.073 (0.113)\tData 0.055 (0.093)\tLoss 0.6592 (0.6238)\tAcc 0.812 (0.777)\n",
      "Epoch: [86][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.088)\tLoss 1.1293 (0.6870)\tAcc 0.562 (0.750)\n",
      "Epoch: [86][9/9]\tTime 0.073 (0.104)\tData 0.055 (0.084)\tLoss 0.2744 (0.6806)\tAcc 1.000 (0.754)\n",
      "train at epoch 87\n",
      "Epoch: [87][1/5]\tTime 0.320 (0.320)\tData 0.292 (0.292)\tLoss 0.5999 (0.5999)\tAcc 0.812 (0.812)\n",
      "Epoch: [87][2/5]\tTime 0.076 (0.198)\tData 0.050 (0.171)\tLoss 0.6959 (0.6479)\tAcc 0.750 (0.781)\n",
      "Epoch: [87][3/5]\tTime 0.076 (0.158)\tData 0.053 (0.132)\tLoss 0.5837 (0.6265)\tAcc 0.812 (0.792)\n",
      "Epoch: [87][4/5]\tTime 0.078 (0.138)\tData 0.054 (0.112)\tLoss 1.1778 (0.7643)\tAcc 0.500 (0.719)\n",
      "Epoch: [87][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.101)\tLoss 0.9879 (0.7919)\tAcc 0.444 (0.685)\n",
      "validation at epoch 87\n",
      "Epoch: [87][1/9]\tTime 0.316 (0.316)\tData 0.291 (0.291)\tLoss 0.4201 (0.4201)\tAcc 0.875 (0.875)\n",
      "Epoch: [87][2/9]\tTime 0.071 (0.193)\tData 0.050 (0.170)\tLoss 1.0494 (0.7348)\tAcc 0.625 (0.750)\n",
      "Epoch: [87][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.131)\tLoss 0.6829 (0.7175)\tAcc 0.688 (0.729)\n",
      "Epoch: [87][4/9]\tTime 0.073 (0.133)\tData 0.053 (0.112)\tLoss 0.6875 (0.7100)\tAcc 0.812 (0.750)\n",
      "Epoch: [87][5/9]\tTime 0.074 (0.121)\tData 0.055 (0.100)\tLoss 0.7863 (0.7253)\tAcc 0.750 (0.750)\n",
      "Epoch: [87][6/9]\tTime 0.073 (0.113)\tData 0.054 (0.093)\tLoss 0.3241 (0.6584)\tAcc 1.000 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.6938 (0.6634)\tAcc 0.625 (0.768)\n",
      "Epoch: [87][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 1.1762 (0.7275)\tAcc 0.438 (0.727)\n",
      "Epoch: [87][9/9]\tTime 0.073 (0.100)\tData 0.054 (0.080)\tLoss 0.2801 (0.7207)\tAcc 1.000 (0.731)\n",
      "train at epoch 88\n",
      "Epoch: [88][1/5]\tTime 0.383 (0.383)\tData 0.356 (0.356)\tLoss 0.5901 (0.5901)\tAcc 0.812 (0.812)\n",
      "Epoch: [88][2/5]\tTime 0.075 (0.229)\tData 0.051 (0.204)\tLoss 0.6495 (0.6198)\tAcc 0.812 (0.812)\n",
      "Epoch: [88][3/5]\tTime 0.077 (0.179)\tData 0.054 (0.154)\tLoss 0.5959 (0.6118)\tAcc 0.750 (0.792)\n",
      "Epoch: [88][4/5]\tTime 0.078 (0.153)\tData 0.054 (0.129)\tLoss 1.2883 (0.7809)\tAcc 0.375 (0.688)\n",
      "Epoch: [88][5/5]\tTime 0.079 (0.138)\tData 0.056 (0.114)\tLoss 0.8981 (0.7954)\tAcc 0.556 (0.671)\n",
      "validation at epoch 88\n",
      "Epoch: [88][1/9]\tTime 0.281 (0.281)\tData 0.257 (0.257)\tLoss 0.3835 (0.3835)\tAcc 0.875 (0.875)\n",
      "Epoch: [88][2/9]\tTime 0.077 (0.179)\tData 0.056 (0.156)\tLoss 0.8982 (0.6409)\tAcc 0.562 (0.719)\n",
      "Epoch: [88][3/9]\tTime 0.073 (0.144)\tData 0.053 (0.122)\tLoss 0.6879 (0.6565)\tAcc 0.625 (0.688)\n",
      "Epoch: [88][4/9]\tTime 0.073 (0.126)\tData 0.052 (0.104)\tLoss 0.7285 (0.6745)\tAcc 0.750 (0.703)\n",
      "Epoch: [88][5/9]\tTime 0.082 (0.117)\tData 0.053 (0.094)\tLoss 0.8878 (0.7172)\tAcc 0.562 (0.675)\n",
      "Epoch: [88][6/9]\tTime 0.073 (0.110)\tData 0.054 (0.088)\tLoss 0.2559 (0.6403)\tAcc 1.000 (0.729)\n",
      "Epoch: [88][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.083)\tLoss 0.6825 (0.6463)\tAcc 0.688 (0.723)\n",
      "Epoch: [88][8/9]\tTime 0.075 (0.101)\tData 0.056 (0.079)\tLoss 1.0952 (0.7024)\tAcc 0.500 (0.695)\n",
      "Epoch: [88][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.077)\tLoss 0.2563 (0.6956)\tAcc 1.000 (0.700)\n",
      "train at epoch 89\n",
      "Epoch: [89][1/5]\tTime 0.380 (0.380)\tData 0.353 (0.353)\tLoss 0.8105 (0.8105)\tAcc 0.625 (0.625)\n",
      "Epoch: [89][2/5]\tTime 0.075 (0.228)\tData 0.052 (0.202)\tLoss 0.7969 (0.8037)\tAcc 0.562 (0.594)\n",
      "Epoch: [89][3/5]\tTime 0.077 (0.178)\tData 0.054 (0.153)\tLoss 0.3421 (0.6498)\tAcc 0.938 (0.708)\n",
      "Epoch: [89][4/5]\tTime 0.077 (0.153)\tData 0.054 (0.128)\tLoss 0.9754 (0.7312)\tAcc 0.625 (0.688)\n",
      "Epoch: [89][5/5]\tTime 0.079 (0.138)\tData 0.056 (0.114)\tLoss 0.9497 (0.7581)\tAcc 0.556 (0.671)\n",
      "validation at epoch 89\n",
      "Epoch: [89][1/9]\tTime 0.352 (0.352)\tData 0.328 (0.328)\tLoss 0.4246 (0.4246)\tAcc 0.938 (0.938)\n",
      "Epoch: [89][2/9]\tTime 0.071 (0.212)\tData 0.050 (0.189)\tLoss 0.9292 (0.6769)\tAcc 0.562 (0.750)\n",
      "Epoch: [89][3/9]\tTime 0.073 (0.165)\tData 0.053 (0.144)\tLoss 0.6073 (0.6537)\tAcc 0.688 (0.729)\n",
      "Epoch: [89][4/9]\tTime 0.075 (0.143)\tData 0.053 (0.121)\tLoss 0.6930 (0.6635)\tAcc 0.688 (0.719)\n",
      "Epoch: [89][5/9]\tTime 0.072 (0.129)\tData 0.053 (0.107)\tLoss 0.7955 (0.6899)\tAcc 0.625 (0.700)\n",
      "Epoch: [89][6/9]\tTime 0.073 (0.119)\tData 0.055 (0.099)\tLoss 0.3614 (0.6352)\tAcc 1.000 (0.750)\n",
      "Epoch: [89][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.092)\tLoss 0.5417 (0.6218)\tAcc 0.812 (0.759)\n",
      "Epoch: [89][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.088)\tLoss 0.8880 (0.6551)\tAcc 0.500 (0.727)\n",
      "Epoch: [89][9/9]\tTime 0.073 (0.104)\tData 0.055 (0.084)\tLoss 0.1022 (0.6466)\tAcc 1.000 (0.731)\n",
      "train at epoch 90\n",
      "Epoch: [90][1/5]\tTime 0.353 (0.353)\tData 0.324 (0.324)\tLoss 0.5810 (0.5810)\tAcc 0.875 (0.875)\n",
      "Epoch: [90][2/5]\tTime 0.074 (0.213)\tData 0.050 (0.187)\tLoss 0.8600 (0.7205)\tAcc 0.562 (0.719)\n",
      "Epoch: [90][3/5]\tTime 0.077 (0.168)\tData 0.054 (0.143)\tLoss 0.8960 (0.7790)\tAcc 0.688 (0.708)\n",
      "Epoch: [90][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.121)\tLoss 0.6455 (0.7456)\tAcc 0.875 (0.750)\n",
      "Epoch: [90][5/5]\tTime 0.079 (0.132)\tData 0.056 (0.108)\tLoss 0.5298 (0.7190)\tAcc 0.889 (0.767)\n",
      "validation at epoch 90\n",
      "Epoch: [90][1/9]\tTime 0.261 (0.261)\tData 0.237 (0.237)\tLoss 0.3162 (0.3162)\tAcc 0.938 (0.938)\n",
      "Epoch: [90][2/9]\tTime 0.119 (0.190)\tData 0.097 (0.167)\tLoss 1.0396 (0.6779)\tAcc 0.625 (0.781)\n",
      "Epoch: [90][3/9]\tTime 0.073 (0.151)\tData 0.052 (0.129)\tLoss 0.5697 (0.6418)\tAcc 0.750 (0.771)\n",
      "Epoch: [90][4/9]\tTime 0.074 (0.132)\tData 0.052 (0.110)\tLoss 0.6997 (0.6563)\tAcc 0.812 (0.781)\n",
      "Epoch: [90][5/9]\tTime 0.073 (0.120)\tData 0.053 (0.098)\tLoss 0.8947 (0.7040)\tAcc 0.562 (0.738)\n",
      "Epoch: [90][6/9]\tTime 0.072 (0.112)\tData 0.053 (0.091)\tLoss 0.2608 (0.6301)\tAcc 1.000 (0.781)\n",
      "Epoch: [90][7/9]\tTime 0.073 (0.106)\tData 0.054 (0.086)\tLoss 0.5335 (0.6163)\tAcc 0.750 (0.777)\n",
      "Epoch: [90][8/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 1.1538 (0.6835)\tAcc 0.375 (0.727)\n",
      "Epoch: [90][9/9]\tTime 0.073 (0.099)\tData 0.054 (0.079)\tLoss 0.1703 (0.6756)\tAcc 1.000 (0.731)\n",
      "train at epoch 91\n",
      "Epoch: [91][1/5]\tTime 0.320 (0.320)\tData 0.290 (0.290)\tLoss 0.6064 (0.6064)\tAcc 0.875 (0.875)\n",
      "Epoch: [91][2/5]\tTime 0.073 (0.196)\tData 0.048 (0.169)\tLoss 0.8678 (0.7371)\tAcc 0.750 (0.812)\n",
      "Epoch: [91][3/5]\tTime 0.077 (0.157)\tData 0.053 (0.131)\tLoss 0.8111 (0.7618)\tAcc 0.688 (0.771)\n",
      "Epoch: [91][4/5]\tTime 0.077 (0.137)\tData 0.054 (0.111)\tLoss 0.6751 (0.7401)\tAcc 0.875 (0.797)\n",
      "Epoch: [91][5/5]\tTime 0.079 (0.125)\tData 0.056 (0.100)\tLoss 0.7732 (0.7442)\tAcc 0.889 (0.808)\n",
      "validation at epoch 91\n",
      "Epoch: [91][1/9]\tTime 0.373 (0.373)\tData 0.348 (0.348)\tLoss 0.2600 (0.2600)\tAcc 1.000 (1.000)\n",
      "Epoch: [91][2/9]\tTime 0.072 (0.223)\tData 0.050 (0.199)\tLoss 1.1157 (0.6878)\tAcc 0.562 (0.781)\n",
      "Epoch: [91][3/9]\tTime 0.071 (0.172)\tData 0.051 (0.150)\tLoss 0.7446 (0.7068)\tAcc 0.625 (0.729)\n",
      "Epoch: [91][4/9]\tTime 0.074 (0.148)\tData 0.053 (0.126)\tLoss 0.7502 (0.7176)\tAcc 0.688 (0.719)\n",
      "Epoch: [91][5/9]\tTime 0.072 (0.133)\tData 0.053 (0.111)\tLoss 0.9227 (0.7586)\tAcc 0.688 (0.713)\n",
      "Epoch: [91][6/9]\tTime 0.073 (0.123)\tData 0.054 (0.101)\tLoss 0.2753 (0.6781)\tAcc 1.000 (0.760)\n",
      "Epoch: [91][7/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.6184 (0.6695)\tAcc 0.688 (0.750)\n",
      "Epoch: [91][8/9]\tTime 0.077 (0.111)\tData 0.058 (0.090)\tLoss 1.0842 (0.7214)\tAcc 0.688 (0.742)\n",
      "Epoch: [91][9/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.2454 (0.7141)\tAcc 1.000 (0.746)\n",
      "train at epoch 92\n",
      "Epoch: [92][1/5]\tTime 0.325 (0.325)\tData 0.297 (0.297)\tLoss 0.4938 (0.4938)\tAcc 0.875 (0.875)\n",
      "Epoch: [92][2/5]\tTime 0.075 (0.200)\tData 0.051 (0.174)\tLoss 0.8389 (0.6663)\tAcc 0.688 (0.781)\n",
      "Epoch: [92][3/5]\tTime 0.077 (0.159)\tData 0.054 (0.134)\tLoss 0.7496 (0.6941)\tAcc 0.625 (0.729)\n",
      "Epoch: [92][4/5]\tTime 0.077 (0.139)\tData 0.054 (0.114)\tLoss 0.6855 (0.6920)\tAcc 0.750 (0.734)\n",
      "Epoch: [92][5/5]\tTime 0.079 (0.127)\tData 0.056 (0.102)\tLoss 0.8696 (0.7139)\tAcc 0.444 (0.699)\n",
      "validation at epoch 92\n",
      "Epoch: [92][1/9]\tTime 0.305 (0.305)\tData 0.279 (0.279)\tLoss 0.3264 (0.3264)\tAcc 0.938 (0.938)\n",
      "Epoch: [92][2/9]\tTime 0.070 (0.187)\tData 0.048 (0.164)\tLoss 0.9648 (0.6456)\tAcc 0.625 (0.781)\n",
      "Epoch: [92][3/9]\tTime 0.074 (0.149)\tData 0.052 (0.127)\tLoss 0.6640 (0.6517)\tAcc 0.750 (0.771)\n",
      "Epoch: [92][4/9]\tTime 0.076 (0.131)\tData 0.052 (0.108)\tLoss 0.7535 (0.6772)\tAcc 0.688 (0.750)\n",
      "Epoch: [92][5/9]\tTime 0.070 (0.119)\tData 0.050 (0.096)\tLoss 0.8142 (0.7046)\tAcc 0.750 (0.750)\n",
      "Epoch: [92][6/9]\tTime 0.073 (0.111)\tData 0.054 (0.089)\tLoss 0.2016 (0.6207)\tAcc 1.000 (0.792)\n",
      "Epoch: [92][7/9]\tTime 0.073 (0.106)\tData 0.055 (0.084)\tLoss 0.7419 (0.6380)\tAcc 0.625 (0.768)\n",
      "Epoch: [92][8/9]\tTime 0.075 (0.102)\tData 0.056 (0.081)\tLoss 1.0392 (0.6882)\tAcc 0.562 (0.742)\n",
      "Epoch: [92][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.078)\tLoss 0.2048 (0.6807)\tAcc 1.000 (0.746)\n",
      "train at epoch 93\n",
      "Epoch: [93][1/5]\tTime 0.347 (0.347)\tData 0.316 (0.316)\tLoss 0.4714 (0.4714)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/5]\tTime 0.073 (0.210)\tData 0.047 (0.181)\tLoss 0.6946 (0.5830)\tAcc 0.750 (0.844)\n",
      "Epoch: [93][3/5]\tTime 0.076 (0.165)\tData 0.052 (0.138)\tLoss 0.8649 (0.6770)\tAcc 0.625 (0.771)\n",
      "Epoch: [93][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.117)\tLoss 0.5598 (0.6477)\tAcc 0.812 (0.781)\n",
      "Epoch: [93][5/5]\tTime 0.079 (0.130)\tData 0.056 (0.105)\tLoss 1.2350 (0.7201)\tAcc 0.667 (0.767)\n",
      "validation at epoch 93\n",
      "Epoch: [93][1/9]\tTime 0.281 (0.281)\tData 0.257 (0.257)\tLoss 0.2652 (0.2652)\tAcc 0.938 (0.938)\n",
      "Epoch: [93][2/9]\tTime 0.075 (0.178)\tData 0.054 (0.156)\tLoss 1.0496 (0.6574)\tAcc 0.625 (0.781)\n",
      "Epoch: [93][3/9]\tTime 0.073 (0.143)\tData 0.052 (0.121)\tLoss 0.5723 (0.6290)\tAcc 0.625 (0.729)\n",
      "Epoch: [93][4/9]\tTime 0.074 (0.126)\tData 0.053 (0.104)\tLoss 0.5912 (0.6196)\tAcc 0.750 (0.734)\n",
      "Epoch: [93][5/9]\tTime 0.086 (0.118)\tData 0.064 (0.096)\tLoss 0.8270 (0.6610)\tAcc 0.688 (0.725)\n",
      "Epoch: [93][6/9]\tTime 0.072 (0.110)\tData 0.053 (0.089)\tLoss 0.2593 (0.5941)\tAcc 1.000 (0.771)\n",
      "Epoch: [93][7/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.5522 (0.5881)\tAcc 0.812 (0.777)\n",
      "Epoch: [93][8/9]\tTime 0.075 (0.101)\tData 0.056 (0.081)\tLoss 1.2160 (0.6666)\tAcc 0.438 (0.734)\n",
      "Epoch: [93][9/9]\tTime 0.073 (0.098)\tData 0.054 (0.078)\tLoss 0.1053 (0.6580)\tAcc 1.000 (0.738)\n",
      "train at epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [94][1/5]\tTime 0.268 (0.268)\tData 0.239 (0.239)\tLoss 0.5783 (0.5783)\tAcc 0.812 (0.812)\n",
      "Epoch: [94][2/5]\tTime 0.083 (0.176)\tData 0.057 (0.148)\tLoss 0.7116 (0.6449)\tAcc 0.750 (0.781)\n",
      "Epoch: [94][3/5]\tTime 0.076 (0.142)\tData 0.052 (0.116)\tLoss 0.9076 (0.7325)\tAcc 0.500 (0.688)\n",
      "Epoch: [94][4/5]\tTime 0.077 (0.126)\tData 0.054 (0.100)\tLoss 0.8497 (0.7618)\tAcc 0.625 (0.672)\n",
      "Epoch: [94][5/5]\tTime 0.079 (0.117)\tData 0.055 (0.091)\tLoss 0.5745 (0.7387)\tAcc 0.778 (0.685)\n",
      "validation at epoch 94\n",
      "Epoch: [94][1/9]\tTime 0.308 (0.308)\tData 0.282 (0.282)\tLoss 0.1968 (0.1968)\tAcc 0.938 (0.938)\n",
      "Epoch: [94][2/9]\tTime 0.070 (0.189)\tData 0.049 (0.166)\tLoss 1.0176 (0.6072)\tAcc 0.438 (0.688)\n",
      "Epoch: [94][3/9]\tTime 0.074 (0.151)\tData 0.053 (0.128)\tLoss 0.7244 (0.6463)\tAcc 0.688 (0.688)\n",
      "Epoch: [94][4/9]\tTime 0.074 (0.132)\tData 0.052 (0.109)\tLoss 0.5936 (0.6331)\tAcc 0.750 (0.703)\n",
      "Epoch: [94][5/9]\tTime 0.073 (0.120)\tData 0.054 (0.098)\tLoss 0.8234 (0.6712)\tAcc 0.688 (0.700)\n",
      "Epoch: [94][6/9]\tTime 0.074 (0.112)\tData 0.055 (0.091)\tLoss 0.2326 (0.5981)\tAcc 1.000 (0.750)\n",
      "Epoch: [94][7/9]\tTime 0.073 (0.107)\tData 0.054 (0.086)\tLoss 0.5774 (0.5951)\tAcc 0.812 (0.759)\n",
      "Epoch: [94][8/9]\tTime 0.075 (0.103)\tData 0.056 (0.082)\tLoss 1.0595 (0.6532)\tAcc 0.625 (0.742)\n",
      "Epoch: [94][9/9]\tTime 0.073 (0.099)\tData 0.055 (0.079)\tLoss 0.1873 (0.6460)\tAcc 1.000 (0.746)\n",
      "train at epoch 95\n",
      "Epoch: [95][1/5]\tTime 0.289 (0.289)\tData 0.262 (0.262)\tLoss 0.6073 (0.6073)\tAcc 0.812 (0.812)\n",
      "Epoch: [95][2/5]\tTime 0.075 (0.182)\tData 0.051 (0.156)\tLoss 0.7852 (0.6962)\tAcc 0.688 (0.750)\n",
      "Epoch: [95][3/5]\tTime 0.077 (0.147)\tData 0.054 (0.122)\tLoss 0.7937 (0.7287)\tAcc 0.688 (0.729)\n",
      "Epoch: [95][4/5]\tTime 0.078 (0.130)\tData 0.054 (0.105)\tLoss 0.8736 (0.7650)\tAcc 0.625 (0.703)\n",
      "Epoch: [95][5/5]\tTime 0.079 (0.120)\tData 0.056 (0.095)\tLoss 0.9267 (0.7849)\tAcc 0.778 (0.712)\n",
      "validation at epoch 95\n",
      "Epoch: [95][1/9]\tTime 0.356 (0.356)\tData 0.328 (0.328)\tLoss 0.2536 (0.2536)\tAcc 0.938 (0.938)\n",
      "Epoch: [95][2/9]\tTime 0.067 (0.212)\tData 0.046 (0.187)\tLoss 0.8914 (0.5725)\tAcc 0.438 (0.688)\n",
      "Epoch: [95][3/9]\tTime 0.074 (0.166)\tData 0.053 (0.142)\tLoss 0.6168 (0.5873)\tAcc 0.688 (0.688)\n",
      "Epoch: [95][4/9]\tTime 0.074 (0.143)\tData 0.052 (0.120)\tLoss 0.5684 (0.5826)\tAcc 0.750 (0.703)\n",
      "Epoch: [95][5/9]\tTime 0.073 (0.129)\tData 0.053 (0.106)\tLoss 0.9156 (0.6492)\tAcc 0.625 (0.688)\n",
      "Epoch: [95][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.098)\tLoss 0.1878 (0.5723)\tAcc 1.000 (0.740)\n",
      "Epoch: [95][7/9]\tTime 0.073 (0.113)\tData 0.054 (0.091)\tLoss 0.4869 (0.5601)\tAcc 0.812 (0.750)\n",
      "Epoch: [95][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.087)\tLoss 0.8955 (0.6020)\tAcc 0.625 (0.734)\n",
      "Epoch: [95][9/9]\tTime 0.073 (0.104)\tData 0.055 (0.083)\tLoss 0.1336 (0.5948)\tAcc 1.000 (0.738)\n",
      "train at epoch 96\n",
      "Epoch: [96][1/5]\tTime 0.360 (0.360)\tData 0.332 (0.332)\tLoss 0.8925 (0.8925)\tAcc 0.562 (0.562)\n",
      "Epoch: [96][2/5]\tTime 0.075 (0.217)\tData 0.051 (0.192)\tLoss 0.7088 (0.8007)\tAcc 0.750 (0.656)\n",
      "Epoch: [96][3/5]\tTime 0.077 (0.171)\tData 0.054 (0.146)\tLoss 0.8344 (0.8119)\tAcc 0.625 (0.646)\n",
      "Epoch: [96][4/5]\tTime 0.077 (0.147)\tData 0.054 (0.123)\tLoss 0.6980 (0.7834)\tAcc 0.750 (0.672)\n",
      "Epoch: [96][5/5]\tTime 0.079 (0.134)\tData 0.056 (0.109)\tLoss 0.4386 (0.7409)\tAcc 0.889 (0.699)\n",
      "validation at epoch 96\n",
      "Epoch: [96][1/9]\tTime 0.320 (0.320)\tData 0.296 (0.296)\tLoss 0.3766 (0.3766)\tAcc 0.938 (0.938)\n",
      "Epoch: [96][2/9]\tTime 0.072 (0.196)\tData 0.050 (0.173)\tLoss 1.1146 (0.7456)\tAcc 0.500 (0.719)\n",
      "Epoch: [96][3/9]\tTime 0.074 (0.155)\tData 0.053 (0.133)\tLoss 0.6967 (0.7293)\tAcc 0.750 (0.729)\n",
      "Epoch: [96][4/9]\tTime 0.074 (0.135)\tData 0.052 (0.113)\tLoss 0.6757 (0.7159)\tAcc 0.812 (0.750)\n",
      "Epoch: [96][5/9]\tTime 0.072 (0.122)\tData 0.052 (0.101)\tLoss 0.7788 (0.7285)\tAcc 0.625 (0.725)\n",
      "Epoch: [96][6/9]\tTime 0.073 (0.114)\tData 0.054 (0.093)\tLoss 0.1801 (0.6371)\tAcc 1.000 (0.771)\n",
      "Epoch: [96][7/9]\tTime 0.072 (0.108)\tData 0.054 (0.087)\tLoss 0.5807 (0.6290)\tAcc 0.750 (0.768)\n",
      "Epoch: [96][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.083)\tLoss 0.9859 (0.6736)\tAcc 0.562 (0.742)\n",
      "Epoch: [96][9/9]\tTime 0.073 (0.100)\tData 0.055 (0.080)\tLoss 0.1052 (0.6649)\tAcc 1.000 (0.746)\n",
      "train at epoch 97\n",
      "Epoch: [97][1/5]\tTime 0.285 (0.285)\tData 0.255 (0.255)\tLoss 0.5760 (0.5760)\tAcc 0.750 (0.750)\n",
      "Epoch: [97][2/5]\tTime 0.073 (0.179)\tData 0.049 (0.152)\tLoss 0.5372 (0.5566)\tAcc 0.875 (0.812)\n",
      "Epoch: [97][3/5]\tTime 0.077 (0.145)\tData 0.053 (0.119)\tLoss 0.7889 (0.6340)\tAcc 0.625 (0.750)\n",
      "Epoch: [97][4/5]\tTime 0.077 (0.128)\tData 0.054 (0.103)\tLoss 0.7478 (0.6625)\tAcc 0.812 (0.766)\n",
      "Epoch: [97][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.093)\tLoss 1.1549 (0.7232)\tAcc 0.556 (0.740)\n",
      "validation at epoch 97\n",
      "Epoch: [97][1/9]\tTime 0.313 (0.313)\tData 0.289 (0.289)\tLoss 0.3353 (0.3353)\tAcc 0.938 (0.938)\n",
      "Epoch: [97][2/9]\tTime 0.072 (0.192)\tData 0.050 (0.170)\tLoss 1.0521 (0.6937)\tAcc 0.500 (0.719)\n",
      "Epoch: [97][3/9]\tTime 0.073 (0.153)\tData 0.052 (0.131)\tLoss 0.5730 (0.6535)\tAcc 0.688 (0.708)\n",
      "Epoch: [97][4/9]\tTime 0.075 (0.133)\tData 0.053 (0.111)\tLoss 0.5565 (0.6292)\tAcc 0.938 (0.766)\n",
      "Epoch: [97][5/9]\tTime 0.083 (0.123)\tData 0.064 (0.102)\tLoss 0.8590 (0.6752)\tAcc 0.625 (0.738)\n",
      "Epoch: [97][6/9]\tTime 0.074 (0.115)\tData 0.055 (0.094)\tLoss 0.2570 (0.6055)\tAcc 1.000 (0.781)\n",
      "Epoch: [97][7/9]\tTime 0.073 (0.109)\tData 0.055 (0.088)\tLoss 0.4070 (0.5771)\tAcc 0.938 (0.804)\n",
      "Epoch: [97][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.084)\tLoss 1.0337 (0.6342)\tAcc 0.562 (0.773)\n",
      "Epoch: [97][9/9]\tTime 0.074 (0.101)\tData 0.056 (0.081)\tLoss 0.1013 (0.6260)\tAcc 1.000 (0.777)\n",
      "train at epoch 98\n",
      "Epoch: [98][1/5]\tTime 0.338 (0.338)\tData 0.309 (0.309)\tLoss 0.7131 (0.7131)\tAcc 0.750 (0.750)\n",
      "Epoch: [98][2/5]\tTime 0.075 (0.207)\tData 0.050 (0.179)\tLoss 0.7458 (0.7294)\tAcc 0.812 (0.781)\n",
      "Epoch: [98][3/5]\tTime 0.076 (0.163)\tData 0.052 (0.137)\tLoss 0.9083 (0.7891)\tAcc 0.688 (0.750)\n",
      "Epoch: [98][4/5]\tTime 0.077 (0.142)\tData 0.054 (0.116)\tLoss 0.5537 (0.7302)\tAcc 0.812 (0.766)\n",
      "Epoch: [98][5/5]\tTime 0.079 (0.129)\tData 0.056 (0.104)\tLoss 0.6242 (0.7171)\tAcc 0.778 (0.767)\n",
      "validation at epoch 98\n",
      "Epoch: [98][1/9]\tTime 0.335 (0.335)\tData 0.309 (0.309)\tLoss 0.2962 (0.2962)\tAcc 0.875 (0.875)\n",
      "Epoch: [98][2/9]\tTime 0.071 (0.203)\tData 0.049 (0.179)\tLoss 0.9827 (0.6394)\tAcc 0.500 (0.688)\n",
      "Epoch: [98][3/9]\tTime 0.073 (0.160)\tData 0.052 (0.137)\tLoss 0.5534 (0.6107)\tAcc 0.812 (0.729)\n",
      "Epoch: [98][4/9]\tTime 0.072 (0.138)\tData 0.052 (0.116)\tLoss 0.6375 (0.6174)\tAcc 0.812 (0.750)\n",
      "Epoch: [98][5/9]\tTime 0.074 (0.125)\tData 0.055 (0.104)\tLoss 0.8519 (0.6643)\tAcc 0.688 (0.738)\n",
      "Epoch: [98][6/9]\tTime 0.072 (0.116)\tData 0.053 (0.095)\tLoss 0.2452 (0.5945)\tAcc 1.000 (0.781)\n",
      "Epoch: [98][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.6122 (0.5970)\tAcc 0.750 (0.777)\n",
      "Epoch: [98][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 0.9892 (0.6460)\tAcc 0.625 (0.758)\n",
      "Epoch: [98][9/9]\tTime 0.074 (0.102)\tData 0.055 (0.082)\tLoss 0.1253 (0.6380)\tAcc 1.000 (0.762)\n",
      "train at epoch 99\n",
      "Epoch: [99][1/5]\tTime 0.334 (0.334)\tData 0.307 (0.307)\tLoss 0.4936 (0.4936)\tAcc 0.812 (0.812)\n",
      "Epoch: [99][2/5]\tTime 0.076 (0.205)\tData 0.051 (0.179)\tLoss 0.9401 (0.7169)\tAcc 0.625 (0.719)\n",
      "Epoch: [99][3/5]\tTime 0.077 (0.162)\tData 0.053 (0.137)\tLoss 0.6579 (0.6972)\tAcc 0.688 (0.708)\n",
      "Epoch: [99][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.116)\tLoss 0.8519 (0.7359)\tAcc 0.625 (0.688)\n",
      "Epoch: [99][5/5]\tTime 0.078 (0.128)\tData 0.055 (0.104)\tLoss 0.6919 (0.7305)\tAcc 0.778 (0.699)\n",
      "validation at epoch 99\n",
      "Epoch: [99][1/9]\tTime 0.383 (0.383)\tData 0.358 (0.358)\tLoss 0.2938 (0.2938)\tAcc 0.938 (0.938)\n",
      "Epoch: [99][2/9]\tTime 0.072 (0.227)\tData 0.050 (0.204)\tLoss 0.9650 (0.6294)\tAcc 0.625 (0.781)\n",
      "Epoch: [99][3/9]\tTime 0.074 (0.176)\tData 0.052 (0.153)\tLoss 0.5982 (0.6190)\tAcc 0.750 (0.771)\n",
      "Epoch: [99][4/9]\tTime 0.073 (0.150)\tData 0.052 (0.128)\tLoss 0.6112 (0.6170)\tAcc 0.750 (0.766)\n",
      "Epoch: [99][5/9]\tTime 0.072 (0.135)\tData 0.053 (0.113)\tLoss 0.9758 (0.6888)\tAcc 0.688 (0.750)\n",
      "Epoch: [99][6/9]\tTime 0.073 (0.125)\tData 0.054 (0.103)\tLoss 0.1975 (0.6069)\tAcc 1.000 (0.792)\n",
      "Epoch: [99][7/9]\tTime 0.073 (0.117)\tData 0.054 (0.096)\tLoss 0.4662 (0.5868)\tAcc 0.938 (0.813)\n",
      "Epoch: [99][8/9]\tTime 0.075 (0.112)\tData 0.056 (0.091)\tLoss 1.0644 (0.6465)\tAcc 0.562 (0.781)\n",
      "Epoch: [99][9/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.2066 (0.6397)\tAcc 1.000 (0.785)\n",
      "train at epoch 100\n",
      "Epoch: [100][1/5]\tTime 0.305 (0.305)\tData 0.274 (0.274)\tLoss 0.7274 (0.7274)\tAcc 0.812 (0.812)\n",
      "Epoch: [100][2/5]\tTime 0.075 (0.190)\tData 0.049 (0.162)\tLoss 0.7224 (0.7249)\tAcc 0.625 (0.719)\n",
      "Epoch: [100][3/5]\tTime 0.076 (0.152)\tData 0.052 (0.125)\tLoss 0.5176 (0.6558)\tAcc 0.812 (0.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.107)\tLoss 0.7351 (0.6756)\tAcc 0.750 (0.750)\n",
      "Epoch: [100][5/5]\tTime 0.079 (0.122)\tData 0.056 (0.097)\tLoss 0.6095 (0.6674)\tAcc 0.778 (0.753)\n",
      "validation at epoch 100\n",
      "Epoch: [100][1/9]\tTime 0.353 (0.353)\tData 0.329 (0.329)\tLoss 0.3081 (0.3081)\tAcc 0.938 (0.938)\n",
      "Epoch: [100][2/9]\tTime 0.073 (0.213)\tData 0.050 (0.190)\tLoss 0.9598 (0.6339)\tAcc 0.625 (0.781)\n",
      "Epoch: [100][3/9]\tTime 0.072 (0.166)\tData 0.051 (0.143)\tLoss 0.6614 (0.6431)\tAcc 0.625 (0.729)\n",
      "Epoch: [100][4/9]\tTime 0.073 (0.143)\tData 0.053 (0.121)\tLoss 0.6454 (0.6437)\tAcc 0.750 (0.734)\n",
      "Epoch: [100][5/9]\tTime 0.074 (0.129)\tData 0.054 (0.107)\tLoss 0.7935 (0.6736)\tAcc 0.688 (0.725)\n",
      "Epoch: [100][6/9]\tTime 0.073 (0.120)\tData 0.054 (0.099)\tLoss 0.2511 (0.6032)\tAcc 1.000 (0.771)\n",
      "Epoch: [100][7/9]\tTime 0.073 (0.113)\tData 0.055 (0.092)\tLoss 0.6239 (0.6062)\tAcc 0.688 (0.759)\n",
      "Epoch: [100][8/9]\tTime 0.075 (0.108)\tData 0.056 (0.088)\tLoss 1.0286 (0.6590)\tAcc 0.500 (0.727)\n",
      "Epoch: [100][9/9]\tTime 0.073 (0.104)\tData 0.055 (0.084)\tLoss 0.1289 (0.6508)\tAcc 1.000 (0.731)\n",
      "train at epoch 101\n",
      "Epoch: [101][1/5]\tTime 0.384 (0.384)\tData 0.357 (0.357)\tLoss 0.8139 (0.8139)\tAcc 0.562 (0.562)\n",
      "Epoch: [101][2/5]\tTime 0.076 (0.230)\tData 0.052 (0.204)\tLoss 0.6474 (0.7307)\tAcc 0.688 (0.625)\n",
      "Epoch: [101][3/5]\tTime 0.078 (0.179)\tData 0.054 (0.154)\tLoss 0.7360 (0.7325)\tAcc 0.750 (0.667)\n",
      "Epoch: [101][4/5]\tTime 0.077 (0.154)\tData 0.054 (0.129)\tLoss 0.6999 (0.7243)\tAcc 0.750 (0.688)\n",
      "Epoch: [101][5/5]\tTime 0.079 (0.139)\tData 0.056 (0.114)\tLoss 0.7950 (0.7330)\tAcc 0.667 (0.685)\n",
      "validation at epoch 101\n",
      "Epoch: [101][1/9]\tTime 0.336 (0.336)\tData 0.311 (0.311)\tLoss 0.3434 (0.3434)\tAcc 0.875 (0.875)\n",
      "Epoch: [101][2/9]\tTime 0.072 (0.204)\tData 0.050 (0.181)\tLoss 1.1651 (0.7542)\tAcc 0.562 (0.719)\n",
      "Epoch: [101][3/9]\tTime 0.074 (0.161)\tData 0.052 (0.138)\tLoss 0.6401 (0.7162)\tAcc 0.750 (0.729)\n",
      "Epoch: [101][4/9]\tTime 0.072 (0.138)\tData 0.051 (0.116)\tLoss 0.7226 (0.7178)\tAcc 0.625 (0.703)\n",
      "Epoch: [101][5/9]\tTime 0.073 (0.125)\tData 0.054 (0.104)\tLoss 0.8305 (0.7403)\tAcc 0.688 (0.700)\n",
      "Epoch: [101][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.095)\tLoss 0.2721 (0.6623)\tAcc 1.000 (0.750)\n",
      "Epoch: [101][7/9]\tTime 0.072 (0.110)\tData 0.054 (0.089)\tLoss 0.5050 (0.6398)\tAcc 0.875 (0.768)\n",
      "Epoch: [101][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 1.0932 (0.6965)\tAcc 0.688 (0.758)\n",
      "Epoch: [101][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.082)\tLoss 0.0976 (0.6873)\tAcc 1.000 (0.762)\n",
      "train at epoch 102\n",
      "Epoch: [102][1/5]\tTime 0.321 (0.321)\tData 0.292 (0.292)\tLoss 0.6585 (0.6585)\tAcc 0.750 (0.750)\n",
      "Epoch: [102][2/5]\tTime 0.075 (0.198)\tData 0.051 (0.171)\tLoss 0.9976 (0.8280)\tAcc 0.562 (0.656)\n",
      "Epoch: [102][3/5]\tTime 0.076 (0.157)\tData 0.052 (0.132)\tLoss 0.6485 (0.7682)\tAcc 0.812 (0.708)\n",
      "Epoch: [102][4/5]\tTime 0.077 (0.137)\tData 0.054 (0.112)\tLoss 0.7008 (0.7514)\tAcc 0.688 (0.703)\n",
      "Epoch: [102][5/5]\tTime 0.079 (0.126)\tData 0.056 (0.101)\tLoss 0.7538 (0.7516)\tAcc 0.556 (0.685)\n",
      "validation at epoch 102\n",
      "Epoch: [102][1/9]\tTime 0.290 (0.290)\tData 0.264 (0.264)\tLoss 0.3557 (0.3557)\tAcc 0.938 (0.938)\n",
      "Epoch: [102][2/9]\tTime 0.070 (0.180)\tData 0.049 (0.157)\tLoss 0.9728 (0.6642)\tAcc 0.500 (0.719)\n",
      "Epoch: [102][3/9]\tTime 0.074 (0.145)\tData 0.053 (0.122)\tLoss 0.6886 (0.6724)\tAcc 0.750 (0.729)\n",
      "Epoch: [102][4/9]\tTime 0.073 (0.127)\tData 0.053 (0.105)\tLoss 0.6772 (0.6736)\tAcc 0.625 (0.703)\n",
      "Epoch: [102][5/9]\tTime 0.073 (0.116)\tData 0.054 (0.095)\tLoss 0.6977 (0.6784)\tAcc 0.750 (0.713)\n",
      "Epoch: [102][6/9]\tTime 0.074 (0.109)\tData 0.055 (0.088)\tLoss 0.2319 (0.6040)\tAcc 1.000 (0.760)\n",
      "Epoch: [102][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.083)\tLoss 0.6188 (0.6061)\tAcc 0.688 (0.750)\n",
      "Epoch: [102][8/9]\tTime 0.075 (0.100)\tData 0.056 (0.080)\tLoss 1.0246 (0.6584)\tAcc 0.562 (0.727)\n",
      "Epoch: [102][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.077)\tLoss 0.1841 (0.6511)\tAcc 1.000 (0.731)\n",
      "train at epoch 103\n",
      "Epoch: [103][1/5]\tTime 0.365 (0.365)\tData 0.337 (0.337)\tLoss 0.6910 (0.6910)\tAcc 0.750 (0.750)\n",
      "Epoch: [103][2/5]\tTime 0.076 (0.220)\tData 0.051 (0.194)\tLoss 0.6592 (0.6751)\tAcc 0.688 (0.719)\n",
      "Epoch: [103][3/5]\tTime 0.076 (0.172)\tData 0.053 (0.147)\tLoss 0.4506 (0.6003)\tAcc 0.875 (0.771)\n",
      "Epoch: [103][4/5]\tTime 0.077 (0.149)\tData 0.054 (0.124)\tLoss 0.8604 (0.6653)\tAcc 0.625 (0.734)\n",
      "Epoch: [103][5/5]\tTime 0.079 (0.135)\tData 0.056 (0.110)\tLoss 1.0350 (0.7109)\tAcc 0.556 (0.712)\n",
      "validation at epoch 103\n",
      "Epoch: [103][1/9]\tTime 0.344 (0.344)\tData 0.317 (0.317)\tLoss 0.2777 (0.2777)\tAcc 1.000 (1.000)\n",
      "Epoch: [103][2/9]\tTime 0.070 (0.207)\tData 0.048 (0.183)\tLoss 0.9851 (0.6314)\tAcc 0.625 (0.812)\n",
      "Epoch: [103][3/9]\tTime 0.073 (0.162)\tData 0.052 (0.139)\tLoss 0.7352 (0.6660)\tAcc 0.625 (0.750)\n",
      "Epoch: [103][4/9]\tTime 0.074 (0.140)\tData 0.053 (0.118)\tLoss 0.6433 (0.6603)\tAcc 0.688 (0.734)\n",
      "Epoch: [103][5/9]\tTime 0.073 (0.127)\tData 0.054 (0.105)\tLoss 0.9251 (0.7133)\tAcc 0.625 (0.713)\n",
      "Epoch: [103][6/9]\tTime 0.073 (0.118)\tData 0.054 (0.096)\tLoss 0.1979 (0.6274)\tAcc 1.000 (0.760)\n",
      "Epoch: [103][7/9]\tTime 0.073 (0.111)\tData 0.055 (0.090)\tLoss 0.6631 (0.6325)\tAcc 0.812 (0.768)\n",
      "Epoch: [103][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.086)\tLoss 1.0787 (0.6883)\tAcc 0.562 (0.742)\n",
      "Epoch: [103][9/9]\tTime 0.073 (0.103)\tData 0.054 (0.083)\tLoss 0.0851 (0.6790)\tAcc 1.000 (0.746)\n",
      "train at epoch 104\n",
      "Epoch: [104][1/5]\tTime 0.297 (0.297)\tData 0.266 (0.266)\tLoss 0.8262 (0.8262)\tAcc 0.625 (0.625)\n",
      "Epoch: [104][2/5]\tTime 0.075 (0.186)\tData 0.048 (0.157)\tLoss 0.6445 (0.7354)\tAcc 0.812 (0.719)\n",
      "Epoch: [104][3/5]\tTime 0.075 (0.149)\tData 0.051 (0.122)\tLoss 0.6247 (0.6985)\tAcc 0.750 (0.729)\n",
      "Epoch: [104][4/5]\tTime 0.077 (0.131)\tData 0.054 (0.105)\tLoss 0.7165 (0.7030)\tAcc 0.625 (0.703)\n",
      "Epoch: [104][5/5]\tTime 0.079 (0.121)\tData 0.056 (0.095)\tLoss 0.6759 (0.6997)\tAcc 0.667 (0.699)\n",
      "validation at epoch 104\n",
      "Epoch: [104][1/9]\tTime 0.377 (0.377)\tData 0.353 (0.353)\tLoss 0.2271 (0.2271)\tAcc 0.938 (0.938)\n",
      "Epoch: [104][2/9]\tTime 0.072 (0.224)\tData 0.050 (0.202)\tLoss 1.0736 (0.6503)\tAcc 0.625 (0.781)\n",
      "Epoch: [104][3/9]\tTime 0.073 (0.174)\tData 0.052 (0.152)\tLoss 0.4878 (0.5962)\tAcc 0.812 (0.792)\n",
      "Epoch: [104][4/9]\tTime 0.075 (0.149)\tData 0.053 (0.127)\tLoss 0.6330 (0.6054)\tAcc 0.875 (0.812)\n",
      "Epoch: [104][5/9]\tTime 0.072 (0.134)\tData 0.053 (0.112)\tLoss 0.7415 (0.6326)\tAcc 0.812 (0.812)\n",
      "Epoch: [104][6/9]\tTime 0.073 (0.123)\tData 0.054 (0.103)\tLoss 0.2125 (0.5626)\tAcc 1.000 (0.844)\n",
      "Epoch: [104][7/9]\tTime 0.074 (0.116)\tData 0.055 (0.096)\tLoss 0.6069 (0.5689)\tAcc 0.750 (0.830)\n",
      "Epoch: [104][8/9]\tTime 0.075 (0.111)\tData 0.056 (0.091)\tLoss 0.9659 (0.6185)\tAcc 0.500 (0.789)\n",
      "Epoch: [104][9/9]\tTime 0.073 (0.107)\tData 0.054 (0.087)\tLoss 0.1923 (0.6120)\tAcc 1.000 (0.792)\n",
      "train at epoch 105\n",
      "Epoch: [105][1/5]\tTime 0.302 (0.302)\tData 0.274 (0.274)\tLoss 0.7017 (0.7017)\tAcc 0.625 (0.625)\n",
      "Epoch: [105][2/5]\tTime 0.076 (0.189)\tData 0.051 (0.162)\tLoss 0.7108 (0.7063)\tAcc 0.750 (0.688)\n",
      "Epoch: [105][3/5]\tTime 0.076 (0.151)\tData 0.053 (0.126)\tLoss 0.6063 (0.6729)\tAcc 0.812 (0.729)\n",
      "Epoch: [105][4/5]\tTime 0.077 (0.133)\tData 0.054 (0.108)\tLoss 0.7793 (0.6995)\tAcc 0.688 (0.719)\n",
      "Epoch: [105][5/5]\tTime 0.079 (0.122)\tData 0.056 (0.097)\tLoss 1.1813 (0.7589)\tAcc 0.556 (0.699)\n",
      "validation at epoch 105\n",
      "Epoch: [105][1/9]\tTime 0.324 (0.324)\tData 0.297 (0.297)\tLoss 0.2471 (0.2471)\tAcc 0.938 (0.938)\n",
      "Epoch: [105][2/9]\tTime 0.068 (0.196)\tData 0.047 (0.172)\tLoss 0.9696 (0.6083)\tAcc 0.562 (0.750)\n",
      "Epoch: [105][3/9]\tTime 0.074 (0.155)\tData 0.052 (0.132)\tLoss 0.6518 (0.6228)\tAcc 0.750 (0.750)\n",
      "Epoch: [105][4/9]\tTime 0.075 (0.135)\tData 0.052 (0.112)\tLoss 0.7388 (0.6518)\tAcc 0.688 (0.734)\n",
      "Epoch: [105][5/9]\tTime 0.072 (0.123)\tData 0.052 (0.100)\tLoss 0.9134 (0.7041)\tAcc 0.688 (0.725)\n",
      "Epoch: [105][6/9]\tTime 0.072 (0.114)\tData 0.054 (0.092)\tLoss 0.2681 (0.6315)\tAcc 1.000 (0.771)\n",
      "Epoch: [105][7/9]\tTime 0.073 (0.108)\tData 0.055 (0.087)\tLoss 0.6360 (0.6321)\tAcc 0.812 (0.777)\n",
      "Epoch: [105][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 1.0447 (0.6837)\tAcc 0.625 (0.758)\n",
      "Epoch: [105][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.080)\tLoss 0.3754 (0.6790)\tAcc 1.000 (0.762)\n",
      "train at epoch 106\n",
      "Epoch: [106][1/5]\tTime 0.351 (0.351)\tData 0.323 (0.323)\tLoss 0.7661 (0.7661)\tAcc 0.750 (0.750)\n",
      "Epoch: [106][2/5]\tTime 0.075 (0.213)\tData 0.051 (0.187)\tLoss 0.6297 (0.6979)\tAcc 0.750 (0.750)\n",
      "Epoch: [106][3/5]\tTime 0.077 (0.168)\tData 0.054 (0.143)\tLoss 0.6334 (0.6764)\tAcc 0.812 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [106][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.121)\tLoss 0.9525 (0.7454)\tAcc 0.562 (0.719)\n",
      "Epoch: [106][5/5]\tTime 0.079 (0.132)\tData 0.056 (0.108)\tLoss 0.3849 (0.7010)\tAcc 0.889 (0.740)\n",
      "validation at epoch 106\n",
      "Epoch: [106][1/9]\tTime 0.335 (0.335)\tData 0.310 (0.310)\tLoss 0.3933 (0.3933)\tAcc 0.875 (0.875)\n",
      "Epoch: [106][2/9]\tTime 0.072 (0.203)\tData 0.050 (0.180)\tLoss 1.0318 (0.7126)\tAcc 0.438 (0.656)\n",
      "Epoch: [106][3/9]\tTime 0.076 (0.161)\tData 0.052 (0.138)\tLoss 0.7196 (0.7149)\tAcc 0.750 (0.688)\n",
      "Epoch: [106][4/9]\tTime 0.071 (0.138)\tData 0.050 (0.116)\tLoss 0.5929 (0.6844)\tAcc 0.812 (0.719)\n",
      "Epoch: [106][5/9]\tTime 0.073 (0.125)\tData 0.053 (0.103)\tLoss 0.8596 (0.7195)\tAcc 0.688 (0.713)\n",
      "Epoch: [106][6/9]\tTime 0.073 (0.117)\tData 0.054 (0.095)\tLoss 0.2319 (0.6382)\tAcc 1.000 (0.760)\n",
      "Epoch: [106][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.089)\tLoss 0.7686 (0.6568)\tAcc 0.625 (0.741)\n",
      "Epoch: [106][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.085)\tLoss 1.1400 (0.7172)\tAcc 0.500 (0.711)\n",
      "Epoch: [106][9/9]\tTime 0.073 (0.102)\tData 0.054 (0.082)\tLoss 0.1450 (0.7084)\tAcc 1.000 (0.715)\n",
      "train at epoch 107\n",
      "Epoch: [107][1/5]\tTime 0.303 (0.303)\tData 0.272 (0.272)\tLoss 0.7954 (0.7954)\tAcc 0.688 (0.688)\n",
      "Epoch: [107][2/5]\tTime 0.075 (0.189)\tData 0.049 (0.160)\tLoss 0.5950 (0.6952)\tAcc 0.750 (0.719)\n",
      "Epoch: [107][3/5]\tTime 0.077 (0.151)\tData 0.053 (0.124)\tLoss 0.9109 (0.7671)\tAcc 0.562 (0.667)\n",
      "Epoch: [107][4/5]\tTime 0.077 (0.133)\tData 0.053 (0.107)\tLoss 0.6514 (0.7382)\tAcc 0.688 (0.672)\n",
      "Epoch: [107][5/5]\tTime 0.079 (0.122)\tData 0.055 (0.096)\tLoss 0.8511 (0.7521)\tAcc 0.556 (0.658)\n",
      "validation at epoch 107\n",
      "Epoch: [107][1/9]\tTime 0.348 (0.348)\tData 0.324 (0.324)\tLoss 0.4063 (0.4063)\tAcc 0.875 (0.875)\n",
      "Epoch: [107][2/9]\tTime 0.072 (0.210)\tData 0.051 (0.187)\tLoss 0.9911 (0.6987)\tAcc 0.750 (0.812)\n",
      "Epoch: [107][3/9]\tTime 0.074 (0.164)\tData 0.053 (0.142)\tLoss 0.6717 (0.6897)\tAcc 0.625 (0.750)\n",
      "Epoch: [107][4/9]\tTime 0.073 (0.142)\tData 0.052 (0.120)\tLoss 0.5457 (0.6537)\tAcc 0.750 (0.750)\n",
      "Epoch: [107][5/9]\tTime 0.072 (0.128)\tData 0.052 (0.106)\tLoss 1.0179 (0.7265)\tAcc 0.625 (0.725)\n",
      "Epoch: [107][6/9]\tTime 0.073 (0.119)\tData 0.054 (0.098)\tLoss 0.2903 (0.6538)\tAcc 1.000 (0.771)\n",
      "Epoch: [107][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.091)\tLoss 0.6368 (0.6514)\tAcc 0.688 (0.759)\n",
      "Epoch: [107][8/9]\tTime 0.075 (0.107)\tData 0.056 (0.087)\tLoss 1.0882 (0.7060)\tAcc 0.500 (0.727)\n",
      "Epoch: [107][9/9]\tTime 0.076 (0.104)\tData 0.057 (0.084)\tLoss 0.2069 (0.6983)\tAcc 1.000 (0.731)\n",
      "train at epoch 108\n",
      "Epoch: [108][1/5]\tTime 0.324 (0.324)\tData 0.293 (0.293)\tLoss 0.6379 (0.6379)\tAcc 0.688 (0.688)\n",
      "Epoch: [108][2/5]\tTime 0.080 (0.202)\tData 0.055 (0.174)\tLoss 0.7419 (0.6899)\tAcc 0.688 (0.688)\n",
      "Epoch: [108][3/5]\tTime 0.085 (0.163)\tData 0.061 (0.136)\tLoss 0.6307 (0.6701)\tAcc 0.812 (0.729)\n",
      "Epoch: [108][4/5]\tTime 0.086 (0.144)\tData 0.061 (0.117)\tLoss 0.8927 (0.7258)\tAcc 0.562 (0.688)\n",
      "Epoch: [108][5/5]\tTime 0.090 (0.133)\tData 0.066 (0.107)\tLoss 0.7707 (0.7313)\tAcc 0.667 (0.685)\n",
      "validation at epoch 108\n",
      "Epoch: [108][1/9]\tTime 0.399 (0.399)\tData 0.367 (0.367)\tLoss 0.3151 (0.3151)\tAcc 0.938 (0.938)\n",
      "Epoch: [108][2/9]\tTime 0.073 (0.236)\tData 0.049 (0.208)\tLoss 1.1032 (0.7091)\tAcc 0.500 (0.719)\n",
      "Epoch: [108][3/9]\tTime 0.079 (0.184)\tData 0.056 (0.158)\tLoss 0.6910 (0.7031)\tAcc 0.625 (0.688)\n",
      "Epoch: [108][4/9]\tTime 0.079 (0.157)\tData 0.058 (0.133)\tLoss 0.6338 (0.6858)\tAcc 0.750 (0.703)\n",
      "Epoch: [108][5/9]\tTime 0.080 (0.142)\tData 0.060 (0.118)\tLoss 0.8378 (0.7162)\tAcc 0.688 (0.700)\n",
      "Epoch: [108][6/9]\tTime 0.080 (0.132)\tData 0.060 (0.108)\tLoss 0.2205 (0.6336)\tAcc 1.000 (0.750)\n",
      "Epoch: [108][7/9]\tTime 0.078 (0.124)\tData 0.058 (0.101)\tLoss 0.5472 (0.6212)\tAcc 0.875 (0.768)\n",
      "Epoch: [108][8/9]\tTime 0.079 (0.118)\tData 0.059 (0.096)\tLoss 1.0679 (0.6771)\tAcc 0.562 (0.742)\n",
      "Epoch: [108][9/9]\tTime 0.080 (0.114)\tData 0.060 (0.092)\tLoss 0.2326 (0.6702)\tAcc 1.000 (0.746)\n",
      "train at epoch 109\n",
      "Epoch: [109][1/5]\tTime 0.318 (0.318)\tData 0.286 (0.286)\tLoss 0.7972 (0.7972)\tAcc 0.688 (0.688)\n",
      "Epoch: [109][2/5]\tTime 0.081 (0.199)\tData 0.055 (0.171)\tLoss 0.6863 (0.7418)\tAcc 0.750 (0.719)\n",
      "Epoch: [109][3/5]\tTime 0.085 (0.161)\tData 0.060 (0.134)\tLoss 0.7179 (0.7338)\tAcc 0.750 (0.729)\n",
      "Epoch: [109][4/5]\tTime 0.086 (0.142)\tData 0.062 (0.116)\tLoss 0.6350 (0.7091)\tAcc 0.625 (0.703)\n",
      "Epoch: [109][5/5]\tTime 0.085 (0.131)\tData 0.061 (0.105)\tLoss 0.5071 (0.6842)\tAcc 0.889 (0.726)\n",
      "validation at epoch 109\n",
      "Epoch: [109][1/9]\tTime 0.318 (0.318)\tData 0.275 (0.275)\tLoss 0.2884 (0.2884)\tAcc 0.938 (0.938)\n",
      "Epoch: [109][2/9]\tTime 0.065 (0.191)\tData 0.041 (0.158)\tLoss 1.0286 (0.6585)\tAcc 0.625 (0.781)\n",
      "Epoch: [109][3/9]\tTime 0.078 (0.154)\tData 0.056 (0.124)\tLoss 0.5661 (0.6277)\tAcc 0.688 (0.750)\n",
      "Epoch: [109][4/9]\tTime 0.079 (0.135)\tData 0.056 (0.107)\tLoss 0.6237 (0.6267)\tAcc 0.688 (0.734)\n",
      "Epoch: [109][5/9]\tTime 0.082 (0.124)\tData 0.058 (0.097)\tLoss 0.8464 (0.6706)\tAcc 0.562 (0.700)\n",
      "Epoch: [109][6/9]\tTime 0.078 (0.117)\tData 0.058 (0.091)\tLoss 0.1879 (0.5902)\tAcc 1.000 (0.750)\n",
      "Epoch: [109][7/9]\tTime 0.080 (0.112)\tData 0.060 (0.086)\tLoss 0.7446 (0.6123)\tAcc 0.688 (0.741)\n",
      "Epoch: [109][8/9]\tTime 0.081 (0.108)\tData 0.060 (0.083)\tLoss 1.0416 (0.6659)\tAcc 0.625 (0.727)\n",
      "Epoch: [109][9/9]\tTime 0.080 (0.105)\tData 0.060 (0.080)\tLoss 0.1253 (0.6576)\tAcc 1.000 (0.731)\n",
      "train at epoch 110\n",
      "Epoch: [110][1/5]\tTime 0.287 (0.287)\tData 0.256 (0.256)\tLoss 0.5586 (0.5586)\tAcc 0.812 (0.812)\n",
      "Epoch: [110][2/5]\tTime 0.081 (0.184)\tData 0.056 (0.156)\tLoss 0.6451 (0.6019)\tAcc 0.750 (0.781)\n",
      "Epoch: [110][3/5]\tTime 0.086 (0.151)\tData 0.061 (0.124)\tLoss 0.6970 (0.6336)\tAcc 0.625 (0.729)\n",
      "Epoch: [110][4/5]\tTime 0.085 (0.135)\tData 0.060 (0.108)\tLoss 0.5600 (0.6152)\tAcc 0.812 (0.750)\n",
      "Epoch: [110][5/5]\tTime 0.086 (0.125)\tData 0.062 (0.099)\tLoss 1.4585 (0.7192)\tAcc 0.222 (0.685)\n",
      "validation at epoch 110\n",
      "Epoch: [110][1/9]\tTime 0.358 (0.358)\tData 0.331 (0.331)\tLoss 0.2233 (0.2233)\tAcc 1.000 (1.000)\n",
      "Epoch: [110][2/9]\tTime 0.076 (0.217)\tData 0.053 (0.192)\tLoss 1.1101 (0.6667)\tAcc 0.625 (0.812)\n",
      "Epoch: [110][3/9]\tTime 0.082 (0.172)\tData 0.059 (0.148)\tLoss 0.6482 (0.6606)\tAcc 0.688 (0.771)\n",
      "Epoch: [110][4/9]\tTime 0.079 (0.149)\tData 0.057 (0.125)\tLoss 0.5916 (0.6433)\tAcc 0.688 (0.750)\n",
      "Epoch: [110][5/9]\tTime 0.079 (0.135)\tData 0.059 (0.112)\tLoss 0.7233 (0.6593)\tAcc 0.812 (0.762)\n",
      "Epoch: [110][6/9]\tTime 0.081 (0.126)\tData 0.060 (0.103)\tLoss 0.2021 (0.5831)\tAcc 1.000 (0.802)\n",
      "Epoch: [110][7/9]\tTime 0.080 (0.119)\tData 0.060 (0.097)\tLoss 0.5313 (0.5757)\tAcc 0.875 (0.813)\n",
      "Epoch: [110][8/9]\tTime 0.081 (0.114)\tData 0.060 (0.093)\tLoss 1.0025 (0.6290)\tAcc 0.562 (0.781)\n",
      "Epoch: [110][9/9]\tTime 0.079 (0.111)\tData 0.060 (0.089)\tLoss 0.1159 (0.6212)\tAcc 1.000 (0.785)\n",
      "train at epoch 111\n",
      "Epoch: [111][1/5]\tTime 0.298 (0.298)\tData 0.263 (0.263)\tLoss 0.6434 (0.6434)\tAcc 0.625 (0.625)\n",
      "Epoch: [111][2/5]\tTime 0.070 (0.184)\tData 0.045 (0.154)\tLoss 0.8647 (0.7541)\tAcc 0.688 (0.656)\n",
      "Epoch: [111][3/5]\tTime 0.078 (0.149)\tData 0.054 (0.121)\tLoss 0.6982 (0.7355)\tAcc 0.750 (0.688)\n",
      "Epoch: [111][4/5]\tTime 0.078 (0.131)\tData 0.054 (0.104)\tLoss 0.7179 (0.7311)\tAcc 0.625 (0.672)\n",
      "Epoch: [111][5/5]\tTime 0.083 (0.121)\tData 0.058 (0.095)\tLoss 0.7593 (0.7345)\tAcc 0.667 (0.671)\n",
      "validation at epoch 111\n",
      "Epoch: [111][1/9]\tTime 0.385 (0.385)\tData 0.355 (0.355)\tLoss 0.3359 (0.3359)\tAcc 0.938 (0.938)\n",
      "Epoch: [111][2/9]\tTime 0.078 (0.231)\tData 0.051 (0.203)\tLoss 0.9358 (0.6358)\tAcc 0.500 (0.719)\n",
      "Epoch: [111][3/9]\tTime 0.075 (0.179)\tData 0.054 (0.153)\tLoss 0.6674 (0.6464)\tAcc 0.750 (0.729)\n",
      "Epoch: [111][4/9]\tTime 0.082 (0.155)\tData 0.059 (0.130)\tLoss 0.7313 (0.6676)\tAcc 0.750 (0.734)\n",
      "Epoch: [111][5/9]\tTime 0.077 (0.139)\tData 0.057 (0.115)\tLoss 0.8986 (0.7138)\tAcc 0.688 (0.725)\n",
      "Epoch: [111][6/9]\tTime 0.080 (0.129)\tData 0.060 (0.106)\tLoss 0.2237 (0.6321)\tAcc 1.000 (0.771)\n",
      "Epoch: [111][7/9]\tTime 0.079 (0.122)\tData 0.059 (0.099)\tLoss 0.6414 (0.6334)\tAcc 0.750 (0.768)\n",
      "Epoch: [111][8/9]\tTime 0.080 (0.117)\tData 0.061 (0.094)\tLoss 1.0714 (0.6882)\tAcc 0.562 (0.742)\n",
      "Epoch: [111][9/9]\tTime 0.080 (0.113)\tData 0.060 (0.091)\tLoss 0.1647 (0.6801)\tAcc 1.000 (0.746)\n",
      "train at epoch 112\n",
      "Epoch: [112][1/5]\tTime 0.331 (0.331)\tData 0.301 (0.301)\tLoss 0.9766 (0.9766)\tAcc 0.562 (0.562)\n",
      "Epoch: [112][2/5]\tTime 0.082 (0.206)\tData 0.056 (0.179)\tLoss 0.7893 (0.8829)\tAcc 0.688 (0.625)\n",
      "Epoch: [112][3/5]\tTime 0.086 (0.166)\tData 0.061 (0.140)\tLoss 0.6784 (0.8148)\tAcc 0.688 (0.646)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [112][4/5]\tTime 0.085 (0.146)\tData 0.061 (0.120)\tLoss 0.5815 (0.7564)\tAcc 0.812 (0.688)\n",
      "Epoch: [112][5/5]\tTime 0.086 (0.134)\tData 0.062 (0.108)\tLoss 0.6462 (0.7429)\tAcc 0.778 (0.699)\n",
      "validation at epoch 112\n",
      "Epoch: [112][1/9]\tTime 0.332 (0.332)\tData 0.301 (0.301)\tLoss 0.3301 (0.3301)\tAcc 0.938 (0.938)\n",
      "Epoch: [112][2/9]\tTime 0.075 (0.203)\tData 0.049 (0.175)\tLoss 1.0335 (0.6818)\tAcc 0.562 (0.750)\n",
      "Epoch: [112][3/9]\tTime 0.078 (0.162)\tData 0.057 (0.135)\tLoss 0.4576 (0.6071)\tAcc 0.812 (0.771)\n",
      "Epoch: [112][4/9]\tTime 0.080 (0.141)\tData 0.059 (0.116)\tLoss 0.5968 (0.6045)\tAcc 0.750 (0.766)\n",
      "Epoch: [112][5/9]\tTime 0.079 (0.129)\tData 0.058 (0.105)\tLoss 0.9135 (0.6663)\tAcc 0.625 (0.738)\n",
      "Epoch: [112][6/9]\tTime 0.080 (0.121)\tData 0.060 (0.097)\tLoss 0.2366 (0.5947)\tAcc 1.000 (0.781)\n",
      "Epoch: [112][7/9]\tTime 0.080 (0.115)\tData 0.060 (0.092)\tLoss 0.4879 (0.5794)\tAcc 0.875 (0.795)\n",
      "Epoch: [112][8/9]\tTime 0.080 (0.111)\tData 0.060 (0.088)\tLoss 1.1783 (0.6543)\tAcc 0.438 (0.750)\n",
      "Epoch: [112][9/9]\tTime 0.081 (0.107)\tData 0.060 (0.085)\tLoss 0.2048 (0.6474)\tAcc 1.000 (0.754)\n",
      "train at epoch 113\n",
      "Epoch: [113][1/5]\tTime 0.357 (0.357)\tData 0.328 (0.328)\tLoss 0.8452 (0.8452)\tAcc 0.625 (0.625)\n",
      "Epoch: [113][2/5]\tTime 0.075 (0.216)\tData 0.050 (0.189)\tLoss 0.6514 (0.7483)\tAcc 0.625 (0.625)\n",
      "Epoch: [113][3/5]\tTime 0.075 (0.169)\tData 0.052 (0.143)\tLoss 0.8349 (0.7772)\tAcc 0.688 (0.646)\n",
      "Epoch: [113][4/5]\tTime 0.078 (0.146)\tData 0.054 (0.121)\tLoss 0.4819 (0.7034)\tAcc 0.875 (0.703)\n",
      "Epoch: [113][5/5]\tTime 0.080 (0.133)\tData 0.057 (0.108)\tLoss 1.3190 (0.7793)\tAcc 0.333 (0.658)\n",
      "validation at epoch 113\n",
      "Epoch: [113][1/9]\tTime 0.311 (0.311)\tData 0.287 (0.287)\tLoss 0.3030 (0.3030)\tAcc 0.938 (0.938)\n",
      "Epoch: [113][2/9]\tTime 0.078 (0.194)\tData 0.056 (0.171)\tLoss 1.0070 (0.6550)\tAcc 0.438 (0.688)\n",
      "Epoch: [113][3/9]\tTime 0.079 (0.156)\tData 0.058 (0.134)\tLoss 0.6835 (0.6645)\tAcc 0.625 (0.667)\n",
      "Epoch: [113][4/9]\tTime 0.080 (0.137)\tData 0.059 (0.115)\tLoss 0.8101 (0.7009)\tAcc 0.688 (0.672)\n",
      "Epoch: [113][5/9]\tTime 0.081 (0.126)\tData 0.060 (0.104)\tLoss 0.8620 (0.7331)\tAcc 0.688 (0.675)\n",
      "Epoch: [113][6/9]\tTime 0.080 (0.118)\tData 0.059 (0.097)\tLoss 0.2511 (0.6528)\tAcc 1.000 (0.729)\n",
      "Epoch: [113][7/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 0.6934 (0.6586)\tAcc 0.688 (0.723)\n",
      "Epoch: [113][8/9]\tTime 0.078 (0.108)\tData 0.059 (0.087)\tLoss 1.1165 (0.7158)\tAcc 0.500 (0.695)\n",
      "Epoch: [113][9/9]\tTime 0.073 (0.104)\tData 0.054 (0.084)\tLoss 0.1235 (0.7067)\tAcc 1.000 (0.700)\n",
      "train at epoch 114\n",
      "Epoch: [114][1/5]\tTime 0.336 (0.336)\tData 0.308 (0.308)\tLoss 0.3824 (0.3824)\tAcc 0.938 (0.938)\n",
      "Epoch: [114][2/5]\tTime 0.084 (0.210)\tData 0.058 (0.183)\tLoss 0.7472 (0.5648)\tAcc 0.688 (0.812)\n",
      "Epoch: [114][3/5]\tTime 0.085 (0.168)\tData 0.060 (0.142)\tLoss 0.8507 (0.6601)\tAcc 0.688 (0.771)\n",
      "Epoch: [114][4/5]\tTime 0.086 (0.148)\tData 0.061 (0.122)\tLoss 0.9880 (0.7421)\tAcc 0.500 (0.703)\n",
      "Epoch: [114][5/5]\tTime 0.086 (0.135)\tData 0.061 (0.110)\tLoss 0.8244 (0.7522)\tAcc 0.667 (0.699)\n",
      "validation at epoch 114\n",
      "Epoch: [114][1/9]\tTime 0.256 (0.256)\tData 0.230 (0.230)\tLoss 0.3099 (0.3099)\tAcc 0.938 (0.938)\n",
      "Epoch: [114][2/9]\tTime 0.088 (0.172)\tData 0.065 (0.148)\tLoss 0.9227 (0.6163)\tAcc 0.500 (0.719)\n",
      "Epoch: [114][3/9]\tTime 0.073 (0.139)\tData 0.052 (0.116)\tLoss 0.6121 (0.6149)\tAcc 0.688 (0.708)\n",
      "Epoch: [114][4/9]\tTime 0.083 (0.125)\tData 0.059 (0.101)\tLoss 0.5357 (0.5951)\tAcc 0.812 (0.734)\n",
      "Epoch: [114][5/9]\tTime 0.076 (0.115)\tData 0.055 (0.092)\tLoss 0.7404 (0.6241)\tAcc 0.625 (0.713)\n",
      "Epoch: [114][6/9]\tTime 0.079 (0.109)\tData 0.059 (0.087)\tLoss 0.2232 (0.5573)\tAcc 1.000 (0.760)\n",
      "Epoch: [114][7/9]\tTime 0.080 (0.105)\tData 0.060 (0.083)\tLoss 0.4965 (0.5486)\tAcc 0.875 (0.777)\n",
      "Epoch: [114][8/9]\tTime 0.080 (0.102)\tData 0.060 (0.080)\tLoss 1.1491 (0.6237)\tAcc 0.562 (0.750)\n",
      "Epoch: [114][9/9]\tTime 0.079 (0.099)\tData 0.060 (0.078)\tLoss 0.1886 (0.6170)\tAcc 1.000 (0.754)\n",
      "train at epoch 115\n",
      "Epoch: [115][1/5]\tTime 0.343 (0.343)\tData 0.312 (0.312)\tLoss 0.5666 (0.5666)\tAcc 0.875 (0.875)\n",
      "Epoch: [115][2/5]\tTime 0.073 (0.208)\tData 0.049 (0.180)\tLoss 0.7298 (0.6482)\tAcc 0.812 (0.844)\n",
      "Epoch: [115][3/5]\tTime 0.078 (0.165)\tData 0.054 (0.138)\tLoss 0.6177 (0.6380)\tAcc 0.812 (0.833)\n",
      "Epoch: [115][4/5]\tTime 0.085 (0.145)\tData 0.060 (0.119)\tLoss 0.9745 (0.7222)\tAcc 0.625 (0.781)\n",
      "Epoch: [115][5/5]\tTime 0.087 (0.133)\tData 0.062 (0.107)\tLoss 0.7019 (0.7197)\tAcc 0.667 (0.767)\n",
      "validation at epoch 115\n",
      "Epoch: [115][1/9]\tTime 0.364 (0.364)\tData 0.332 (0.332)\tLoss 0.3584 (0.3584)\tAcc 0.938 (0.938)\n",
      "Epoch: [115][2/9]\tTime 0.079 (0.221)\tData 0.055 (0.194)\tLoss 1.0372 (0.6978)\tAcc 0.500 (0.719)\n",
      "Epoch: [115][3/9]\tTime 0.072 (0.172)\tData 0.051 (0.146)\tLoss 0.6653 (0.6870)\tAcc 0.812 (0.750)\n",
      "Epoch: [115][4/9]\tTime 0.075 (0.147)\tData 0.053 (0.123)\tLoss 0.6742 (0.6838)\tAcc 0.750 (0.750)\n",
      "Epoch: [115][5/9]\tTime 0.072 (0.132)\tData 0.052 (0.109)\tLoss 0.9140 (0.7298)\tAcc 0.625 (0.725)\n",
      "Epoch: [115][6/9]\tTime 0.079 (0.124)\tData 0.060 (0.100)\tLoss 0.2983 (0.6579)\tAcc 0.938 (0.760)\n",
      "Epoch: [115][7/9]\tTime 0.086 (0.118)\tData 0.066 (0.095)\tLoss 0.7097 (0.6653)\tAcc 0.688 (0.750)\n",
      "Epoch: [115][8/9]\tTime 0.080 (0.113)\tData 0.060 (0.091)\tLoss 0.9500 (0.7009)\tAcc 0.562 (0.727)\n",
      "Epoch: [115][9/9]\tTime 0.079 (0.110)\tData 0.060 (0.088)\tLoss 0.3603 (0.6956)\tAcc 1.000 (0.731)\n",
      "train at epoch 116\n",
      "Epoch: [116][1/5]\tTime 0.355 (0.355)\tData 0.325 (0.325)\tLoss 0.6060 (0.6060)\tAcc 0.812 (0.812)\n",
      "Epoch: [116][2/5]\tTime 0.082 (0.218)\tData 0.057 (0.191)\tLoss 0.6682 (0.6371)\tAcc 0.812 (0.812)\n",
      "Epoch: [116][3/5]\tTime 0.086 (0.174)\tData 0.061 (0.148)\tLoss 0.9239 (0.7327)\tAcc 0.562 (0.729)\n",
      "Epoch: [116][4/5]\tTime 0.086 (0.152)\tData 0.061 (0.126)\tLoss 0.5736 (0.6930)\tAcc 0.750 (0.734)\n",
      "Epoch: [116][5/5]\tTime 0.082 (0.138)\tData 0.058 (0.112)\tLoss 1.0442 (0.7363)\tAcc 0.667 (0.726)\n",
      "validation at epoch 116\n",
      "Epoch: [116][1/9]\tTime 0.339 (0.339)\tData 0.309 (0.309)\tLoss 0.2789 (0.2789)\tAcc 0.938 (0.938)\n",
      "Epoch: [116][2/9]\tTime 0.076 (0.208)\tData 0.054 (0.182)\tLoss 0.9227 (0.6008)\tAcc 0.500 (0.719)\n",
      "Epoch: [116][3/9]\tTime 0.079 (0.165)\tData 0.057 (0.140)\tLoss 0.6661 (0.6226)\tAcc 0.688 (0.708)\n",
      "Epoch: [116][4/9]\tTime 0.080 (0.143)\tData 0.058 (0.120)\tLoss 0.6606 (0.6321)\tAcc 0.750 (0.719)\n",
      "Epoch: [116][5/9]\tTime 0.078 (0.130)\tData 0.058 (0.107)\tLoss 0.8841 (0.6825)\tAcc 0.688 (0.713)\n",
      "Epoch: [116][6/9]\tTime 0.080 (0.122)\tData 0.059 (0.099)\tLoss 0.2124 (0.6041)\tAcc 1.000 (0.760)\n",
      "Epoch: [116][7/9]\tTime 0.078 (0.116)\tData 0.058 (0.093)\tLoss 0.6079 (0.6047)\tAcc 0.812 (0.768)\n",
      "Epoch: [116][8/9]\tTime 0.075 (0.111)\tData 0.056 (0.089)\tLoss 0.9243 (0.6446)\tAcc 0.688 (0.758)\n",
      "Epoch: [116][9/9]\tTime 0.074 (0.107)\tData 0.055 (0.085)\tLoss 0.1909 (0.6376)\tAcc 1.000 (0.762)\n",
      "train at epoch 117\n",
      "Epoch: [117][1/5]\tTime 0.303 (0.303)\tData 0.271 (0.271)\tLoss 0.5085 (0.5085)\tAcc 0.812 (0.812)\n",
      "Epoch: [117][2/5]\tTime 0.076 (0.190)\tData 0.048 (0.160)\tLoss 0.9324 (0.7205)\tAcc 0.562 (0.688)\n",
      "Epoch: [117][3/5]\tTime 0.083 (0.154)\tData 0.059 (0.126)\tLoss 0.6057 (0.6822)\tAcc 0.750 (0.708)\n",
      "Epoch: [117][4/5]\tTime 0.085 (0.137)\tData 0.061 (0.110)\tLoss 0.6223 (0.6672)\tAcc 0.750 (0.719)\n",
      "Epoch: [117][5/5]\tTime 0.085 (0.127)\tData 0.060 (0.100)\tLoss 0.7692 (0.6798)\tAcc 0.667 (0.712)\n",
      "validation at epoch 117\n",
      "Epoch: [117][1/9]\tTime 0.318 (0.318)\tData 0.294 (0.294)\tLoss 0.2997 (0.2997)\tAcc 0.938 (0.938)\n",
      "Epoch: [117][2/9]\tTime 0.073 (0.195)\tData 0.052 (0.173)\tLoss 1.0352 (0.6674)\tAcc 0.438 (0.688)\n",
      "Epoch: [117][3/9]\tTime 0.075 (0.155)\tData 0.053 (0.133)\tLoss 0.5944 (0.6431)\tAcc 0.750 (0.708)\n",
      "Epoch: [117][4/9]\tTime 0.072 (0.135)\tData 0.052 (0.113)\tLoss 0.6880 (0.6543)\tAcc 0.688 (0.703)\n",
      "Epoch: [117][5/9]\tTime 0.075 (0.123)\tData 0.053 (0.101)\tLoss 0.8832 (0.7001)\tAcc 0.625 (0.688)\n",
      "Epoch: [117][6/9]\tTime 0.078 (0.115)\tData 0.058 (0.094)\tLoss 0.2568 (0.6262)\tAcc 1.000 (0.740)\n",
      "Epoch: [117][7/9]\tTime 0.080 (0.110)\tData 0.060 (0.089)\tLoss 0.5718 (0.6184)\tAcc 0.750 (0.741)\n",
      "Epoch: [117][8/9]\tTime 0.081 (0.106)\tData 0.061 (0.085)\tLoss 0.9599 (0.6611)\tAcc 0.500 (0.711)\n",
      "Epoch: [117][9/9]\tTime 0.080 (0.104)\tData 0.061 (0.083)\tLoss 0.2267 (0.6544)\tAcc 1.000 (0.715)\n",
      "train at epoch 118\n",
      "Epoch: [118][1/5]\tTime 0.311 (0.311)\tData 0.281 (0.281)\tLoss 0.4846 (0.4846)\tAcc 0.875 (0.875)\n",
      "Epoch: [118][2/5]\tTime 0.081 (0.196)\tData 0.056 (0.168)\tLoss 0.5775 (0.5311)\tAcc 0.875 (0.875)\n",
      "Epoch: [118][3/5]\tTime 0.085 (0.159)\tData 0.061 (0.132)\tLoss 0.9417 (0.6679)\tAcc 0.562 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [118][4/5]\tTime 0.098 (0.144)\tData 0.072 (0.117)\tLoss 0.7635 (0.6918)\tAcc 0.562 (0.719)\n",
      "Epoch: [118][5/5]\tTime 0.085 (0.132)\tData 0.061 (0.106)\tLoss 1.1163 (0.7442)\tAcc 0.556 (0.699)\n",
      "validation at epoch 118\n",
      "Epoch: [118][1/9]\tTime 0.326 (0.326)\tData 0.301 (0.301)\tLoss 0.2993 (0.2993)\tAcc 0.938 (0.938)\n",
      "Epoch: [118][2/9]\tTime 0.070 (0.198)\tData 0.049 (0.175)\tLoss 0.9977 (0.6485)\tAcc 0.500 (0.719)\n",
      "Epoch: [118][3/9]\tTime 0.074 (0.157)\tData 0.053 (0.134)\tLoss 0.5098 (0.6023)\tAcc 0.750 (0.729)\n",
      "Epoch: [118][4/9]\tTime 0.078 (0.137)\tData 0.053 (0.114)\tLoss 0.7251 (0.6330)\tAcc 0.688 (0.719)\n",
      "Epoch: [118][5/9]\tTime 0.069 (0.124)\tData 0.049 (0.101)\tLoss 0.9929 (0.7050)\tAcc 0.562 (0.688)\n",
      "Epoch: [118][6/9]\tTime 0.074 (0.115)\tData 0.054 (0.093)\tLoss 0.2715 (0.6327)\tAcc 1.000 (0.740)\n",
      "Epoch: [118][7/9]\tTime 0.079 (0.110)\tData 0.058 (0.088)\tLoss 0.6114 (0.6297)\tAcc 0.750 (0.741)\n",
      "Epoch: [118][8/9]\tTime 0.080 (0.106)\tData 0.060 (0.085)\tLoss 1.1729 (0.6976)\tAcc 0.625 (0.727)\n",
      "Epoch: [118][9/9]\tTime 0.080 (0.103)\tData 0.060 (0.082)\tLoss 0.2591 (0.6908)\tAcc 1.000 (0.731)\n",
      "train at epoch 119\n",
      "Epoch: [119][1/5]\tTime 0.401 (0.401)\tData 0.372 (0.372)\tLoss 0.6711 (0.6711)\tAcc 0.750 (0.750)\n",
      "Epoch: [119][2/5]\tTime 0.084 (0.242)\tData 0.058 (0.215)\tLoss 0.7528 (0.7119)\tAcc 0.750 (0.750)\n",
      "Epoch: [119][3/5]\tTime 0.084 (0.190)\tData 0.060 (0.163)\tLoss 0.6382 (0.6874)\tAcc 0.750 (0.750)\n",
      "Epoch: [119][4/5]\tTime 0.085 (0.164)\tData 0.061 (0.138)\tLoss 0.6531 (0.6788)\tAcc 0.812 (0.766)\n",
      "Epoch: [119][5/5]\tTime 0.081 (0.147)\tData 0.058 (0.122)\tLoss 0.8602 (0.7012)\tAcc 0.667 (0.753)\n",
      "validation at epoch 119\n",
      "Epoch: [119][1/9]\tTime 0.310 (0.310)\tData 0.286 (0.286)\tLoss 0.3628 (0.3628)\tAcc 0.938 (0.938)\n",
      "Epoch: [119][2/9]\tTime 0.084 (0.197)\tData 0.063 (0.174)\tLoss 0.9748 (0.6688)\tAcc 0.625 (0.781)\n",
      "Epoch: [119][3/9]\tTime 0.073 (0.156)\tData 0.053 (0.134)\tLoss 0.6507 (0.6628)\tAcc 0.812 (0.792)\n",
      "Epoch: [119][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.114)\tLoss 0.7000 (0.6721)\tAcc 0.750 (0.781)\n",
      "Epoch: [119][5/9]\tTime 0.074 (0.123)\tData 0.054 (0.102)\tLoss 0.8129 (0.7002)\tAcc 0.688 (0.762)\n",
      "Epoch: [119][6/9]\tTime 0.077 (0.115)\tData 0.054 (0.094)\tLoss 0.3025 (0.6340)\tAcc 1.000 (0.802)\n",
      "Epoch: [119][7/9]\tTime 0.069 (0.109)\tData 0.050 (0.087)\tLoss 0.6750 (0.6398)\tAcc 0.750 (0.795)\n",
      "Epoch: [119][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.084)\tLoss 0.8998 (0.6723)\tAcc 0.625 (0.773)\n",
      "Epoch: [119][9/9]\tTime 0.075 (0.101)\tData 0.055 (0.080)\tLoss 0.1195 (0.6638)\tAcc 1.000 (0.777)\n",
      "train at epoch 120\n",
      "Epoch: [120][1/5]\tTime 0.321 (0.321)\tData 0.293 (0.293)\tLoss 0.3686 (0.3686)\tAcc 1.000 (1.000)\n",
      "Epoch: [120][2/5]\tTime 0.075 (0.198)\tData 0.051 (0.172)\tLoss 0.7329 (0.5508)\tAcc 0.688 (0.844)\n",
      "Epoch: [120][3/5]\tTime 0.077 (0.158)\tData 0.053 (0.132)\tLoss 1.3618 (0.8211)\tAcc 0.500 (0.729)\n",
      "Epoch: [120][4/5]\tTime 0.080 (0.139)\tData 0.056 (0.113)\tLoss 0.6921 (0.7889)\tAcc 0.750 (0.734)\n",
      "Epoch: [120][5/5]\tTime 0.086 (0.128)\tData 0.062 (0.103)\tLoss 0.8206 (0.7928)\tAcc 0.667 (0.726)\n",
      "validation at epoch 120\n",
      "Epoch: [120][1/9]\tTime 0.360 (0.360)\tData 0.317 (0.317)\tLoss 0.2542 (0.2542)\tAcc 0.938 (0.938)\n",
      "Epoch: [120][2/9]\tTime 0.065 (0.213)\tData 0.034 (0.176)\tLoss 1.0834 (0.6688)\tAcc 0.500 (0.719)\n",
      "Epoch: [120][3/9]\tTime 0.067 (0.164)\tData 0.044 (0.132)\tLoss 0.7788 (0.7055)\tAcc 0.625 (0.688)\n",
      "Epoch: [120][4/9]\tTime 0.070 (0.141)\tData 0.050 (0.111)\tLoss 0.6588 (0.6938)\tAcc 0.625 (0.672)\n",
      "Epoch: [120][5/9]\tTime 0.074 (0.127)\tData 0.054 (0.100)\tLoss 0.8273 (0.7205)\tAcc 0.688 (0.675)\n",
      "Epoch: [120][6/9]\tTime 0.079 (0.119)\tData 0.059 (0.093)\tLoss 0.2448 (0.6412)\tAcc 1.000 (0.729)\n",
      "Epoch: [120][7/9]\tTime 0.080 (0.114)\tData 0.060 (0.088)\tLoss 0.6096 (0.6367)\tAcc 0.750 (0.732)\n",
      "Epoch: [120][8/9]\tTime 0.081 (0.110)\tData 0.061 (0.085)\tLoss 1.0333 (0.6863)\tAcc 0.500 (0.703)\n",
      "Epoch: [120][9/9]\tTime 0.080 (0.106)\tData 0.061 (0.082)\tLoss 0.1963 (0.6787)\tAcc 1.000 (0.708)\n",
      "train at epoch 121\n",
      "Epoch: [121][1/5]\tTime 0.389 (0.389)\tData 0.362 (0.362)\tLoss 0.5817 (0.5817)\tAcc 0.750 (0.750)\n",
      "Epoch: [121][2/5]\tTime 0.075 (0.232)\tData 0.052 (0.207)\tLoss 0.7319 (0.6568)\tAcc 0.812 (0.781)\n",
      "Epoch: [121][3/5]\tTime 0.079 (0.181)\tData 0.055 (0.156)\tLoss 0.5958 (0.6365)\tAcc 0.750 (0.771)\n",
      "Epoch: [121][4/5]\tTime 0.085 (0.157)\tData 0.062 (0.133)\tLoss 0.7519 (0.6653)\tAcc 0.750 (0.766)\n",
      "Epoch: [121][5/5]\tTime 0.088 (0.143)\tData 0.063 (0.119)\tLoss 0.8788 (0.6917)\tAcc 0.667 (0.753)\n",
      "validation at epoch 121\n",
      "Epoch: [121][1/9]\tTime 0.316 (0.316)\tData 0.291 (0.291)\tLoss 0.3336 (0.3336)\tAcc 0.938 (0.938)\n",
      "Epoch: [121][2/9]\tTime 0.075 (0.195)\tData 0.053 (0.172)\tLoss 0.8986 (0.6161)\tAcc 0.500 (0.719)\n",
      "Epoch: [121][3/9]\tTime 0.082 (0.157)\tData 0.059 (0.134)\tLoss 0.6528 (0.6283)\tAcc 0.625 (0.688)\n",
      "Epoch: [121][4/9]\tTime 0.080 (0.138)\tData 0.057 (0.115)\tLoss 0.7078 (0.6482)\tAcc 0.688 (0.688)\n",
      "Epoch: [121][5/9]\tTime 0.079 (0.126)\tData 0.059 (0.104)\tLoss 0.9351 (0.7056)\tAcc 0.625 (0.675)\n",
      "Epoch: [121][6/9]\tTime 0.075 (0.118)\tData 0.056 (0.096)\tLoss 0.2177 (0.6243)\tAcc 1.000 (0.729)\n",
      "Epoch: [121][7/9]\tTime 0.073 (0.112)\tData 0.054 (0.090)\tLoss 0.7028 (0.6355)\tAcc 0.688 (0.723)\n",
      "Epoch: [121][8/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 0.9186 (0.6709)\tAcc 0.625 (0.711)\n",
      "Epoch: [121][9/9]\tTime 0.073 (0.103)\tData 0.055 (0.082)\tLoss 0.1464 (0.6628)\tAcc 1.000 (0.715)\n",
      "train at epoch 122\n",
      "Epoch: [122][1/5]\tTime 0.311 (0.311)\tData 0.281 (0.281)\tLoss 0.5721 (0.5721)\tAcc 0.812 (0.812)\n",
      "Epoch: [122][2/5]\tTime 0.076 (0.193)\tData 0.051 (0.166)\tLoss 0.7228 (0.6474)\tAcc 0.688 (0.750)\n",
      "Epoch: [122][3/5]\tTime 0.076 (0.154)\tData 0.053 (0.128)\tLoss 0.8667 (0.7205)\tAcc 0.750 (0.750)\n",
      "Epoch: [122][4/5]\tTime 0.077 (0.135)\tData 0.054 (0.110)\tLoss 0.8159 (0.7444)\tAcc 0.625 (0.719)\n",
      "Epoch: [122][5/5]\tTime 0.081 (0.124)\tData 0.058 (0.099)\tLoss 1.1916 (0.7995)\tAcc 0.556 (0.699)\n",
      "validation at epoch 122\n",
      "Epoch: [122][1/9]\tTime 0.329 (0.329)\tData 0.300 (0.300)\tLoss 0.3121 (0.3121)\tAcc 0.938 (0.938)\n",
      "Epoch: [122][2/9]\tTime 0.068 (0.198)\tData 0.046 (0.173)\tLoss 1.0793 (0.6957)\tAcc 0.500 (0.719)\n",
      "Epoch: [122][3/9]\tTime 0.074 (0.157)\tData 0.052 (0.133)\tLoss 0.6255 (0.6723)\tAcc 0.625 (0.688)\n",
      "Epoch: [122][4/9]\tTime 0.082 (0.138)\tData 0.059 (0.114)\tLoss 0.5888 (0.6514)\tAcc 0.750 (0.703)\n",
      "Epoch: [122][5/9]\tTime 0.078 (0.126)\tData 0.057 (0.103)\tLoss 0.8946 (0.7001)\tAcc 0.625 (0.688)\n",
      "Epoch: [122][6/9]\tTime 0.081 (0.118)\tData 0.060 (0.096)\tLoss 0.2163 (0.6194)\tAcc 1.000 (0.740)\n",
      "Epoch: [122][7/9]\tTime 0.080 (0.113)\tData 0.060 (0.090)\tLoss 0.7348 (0.6359)\tAcc 0.750 (0.741)\n",
      "Epoch: [122][8/9]\tTime 0.076 (0.108)\tData 0.056 (0.086)\tLoss 1.0775 (0.6911)\tAcc 0.500 (0.711)\n",
      "Epoch: [122][9/9]\tTime 0.074 (0.104)\tData 0.055 (0.083)\tLoss 0.1684 (0.6831)\tAcc 1.000 (0.715)\n",
      "train at epoch 123\n",
      "Epoch: [123][1/5]\tTime 0.337 (0.337)\tData 0.308 (0.308)\tLoss 0.5203 (0.5203)\tAcc 0.875 (0.875)\n",
      "Epoch: [123][2/5]\tTime 0.083 (0.210)\tData 0.057 (0.183)\tLoss 1.1149 (0.8176)\tAcc 0.562 (0.719)\n",
      "Epoch: [123][3/5]\tTime 0.085 (0.168)\tData 0.060 (0.142)\tLoss 0.6116 (0.7489)\tAcc 0.750 (0.729)\n",
      "Epoch: [123][4/5]\tTime 0.085 (0.147)\tData 0.061 (0.122)\tLoss 0.5568 (0.7009)\tAcc 0.875 (0.766)\n",
      "Epoch: [123][5/5]\tTime 0.081 (0.134)\tData 0.058 (0.109)\tLoss 0.9764 (0.7349)\tAcc 0.444 (0.726)\n",
      "validation at epoch 123\n",
      "Epoch: [123][1/9]\tTime 0.332 (0.332)\tData 0.286 (0.286)\tLoss 0.3513 (0.3513)\tAcc 0.938 (0.938)\n",
      "Epoch: [123][2/9]\tTime 0.054 (0.193)\tData 0.032 (0.159)\tLoss 0.9315 (0.6414)\tAcc 0.562 (0.750)\n",
      "Epoch: [123][3/9]\tTime 0.081 (0.156)\tData 0.059 (0.126)\tLoss 0.4939 (0.5922)\tAcc 0.812 (0.771)\n",
      "Epoch: [123][4/9]\tTime 0.081 (0.137)\tData 0.058 (0.109)\tLoss 0.6671 (0.6109)\tAcc 0.750 (0.766)\n",
      "Epoch: [123][5/9]\tTime 0.077 (0.125)\tData 0.057 (0.098)\tLoss 0.7423 (0.6372)\tAcc 0.688 (0.750)\n",
      "Epoch: [123][6/9]\tTime 0.074 (0.116)\tData 0.055 (0.091)\tLoss 0.2228 (0.5681)\tAcc 1.000 (0.792)\n",
      "Epoch: [123][7/9]\tTime 0.073 (0.110)\tData 0.054 (0.086)\tLoss 0.5552 (0.5663)\tAcc 0.812 (0.795)\n",
      "Epoch: [123][8/9]\tTime 0.075 (0.106)\tData 0.055 (0.082)\tLoss 1.1300 (0.6367)\tAcc 0.500 (0.758)\n",
      "Epoch: [123][9/9]\tTime 0.073 (0.102)\tData 0.055 (0.079)\tLoss 0.1451 (0.6292)\tAcc 1.000 (0.762)\n",
      "train at epoch 124\n",
      "Epoch: [124][1/5]\tTime 0.351 (0.351)\tData 0.323 (0.323)\tLoss 0.8767 (0.8767)\tAcc 0.562 (0.562)\n",
      "Epoch: [124][2/5]\tTime 0.075 (0.213)\tData 0.051 (0.187)\tLoss 0.6068 (0.7418)\tAcc 0.812 (0.688)\n",
      "Epoch: [124][3/5]\tTime 0.078 (0.168)\tData 0.054 (0.143)\tLoss 0.5613 (0.6816)\tAcc 0.812 (0.729)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [124][4/5]\tTime 0.077 (0.145)\tData 0.054 (0.120)\tLoss 0.5874 (0.6581)\tAcc 0.750 (0.734)\n",
      "Epoch: [124][5/5]\tTime 0.081 (0.132)\tData 0.057 (0.108)\tLoss 0.9249 (0.6910)\tAcc 0.667 (0.726)\n",
      "validation at epoch 124\n",
      "Epoch: [124][1/9]\tTime 0.287 (0.287)\tData 0.258 (0.258)\tLoss 0.3839 (0.3839)\tAcc 0.938 (0.938)\n",
      "Epoch: [124][2/9]\tTime 0.068 (0.177)\tData 0.046 (0.152)\tLoss 1.0249 (0.7044)\tAcc 0.562 (0.750)\n",
      "Epoch: [124][3/9]\tTime 0.075 (0.143)\tData 0.053 (0.119)\tLoss 0.7520 (0.7203)\tAcc 0.562 (0.688)\n",
      "Epoch: [124][4/9]\tTime 0.076 (0.126)\tData 0.056 (0.103)\tLoss 0.5905 (0.6878)\tAcc 0.750 (0.703)\n",
      "Epoch: [124][5/9]\tTime 0.090 (0.119)\tData 0.070 (0.097)\tLoss 0.7539 (0.7011)\tAcc 0.625 (0.688)\n",
      "Epoch: [124][6/9]\tTime 0.081 (0.113)\tData 0.061 (0.091)\tLoss 0.2270 (0.6220)\tAcc 1.000 (0.740)\n",
      "Epoch: [124][7/9]\tTime 0.080 (0.108)\tData 0.061 (0.086)\tLoss 0.5720 (0.6149)\tAcc 0.875 (0.759)\n",
      "Epoch: [124][8/9]\tTime 0.076 (0.104)\tData 0.057 (0.083)\tLoss 0.9113 (0.6519)\tAcc 0.625 (0.742)\n",
      "Epoch: [124][9/9]\tTime 0.074 (0.101)\tData 0.055 (0.080)\tLoss 0.2140 (0.6452)\tAcc 1.000 (0.746)\n",
      "train at epoch 125\n",
      "Epoch: [125][1/5]\tTime 0.288 (0.288)\tData 0.254 (0.254)\tLoss 0.5262 (0.5262)\tAcc 0.750 (0.750)\n",
      "Epoch: [125][2/5]\tTime 0.082 (0.185)\tData 0.054 (0.154)\tLoss 0.7018 (0.6140)\tAcc 0.750 (0.750)\n",
      "Epoch: [125][3/5]\tTime 0.082 (0.151)\tData 0.058 (0.122)\tLoss 0.8280 (0.6853)\tAcc 0.688 (0.729)\n",
      "Epoch: [125][4/5]\tTime 0.078 (0.133)\tData 0.054 (0.105)\tLoss 0.5553 (0.6528)\tAcc 0.875 (0.766)\n",
      "Epoch: [125][5/5]\tTime 0.081 (0.122)\tData 0.057 (0.095)\tLoss 0.7940 (0.6702)\tAcc 0.667 (0.753)\n",
      "validation at epoch 125\n",
      "Epoch: [125][1/9]\tTime 0.356 (0.356)\tData 0.329 (0.329)\tLoss 0.3301 (0.3301)\tAcc 0.938 (0.938)\n",
      "Epoch: [125][2/9]\tTime 0.069 (0.212)\tData 0.048 (0.189)\tLoss 0.9901 (0.6601)\tAcc 0.750 (0.844)\n",
      "Epoch: [125][3/9]\tTime 0.076 (0.167)\tData 0.055 (0.144)\tLoss 0.6244 (0.6482)\tAcc 0.625 (0.771)\n",
      "Epoch: [125][4/9]\tTime 0.078 (0.145)\tData 0.058 (0.122)\tLoss 0.7938 (0.6846)\tAcc 0.625 (0.734)\n",
      "Epoch: [125][5/9]\tTime 0.080 (0.132)\tData 0.059 (0.110)\tLoss 1.0632 (0.7603)\tAcc 0.625 (0.713)\n",
      "Epoch: [125][6/9]\tTime 0.080 (0.123)\tData 0.059 (0.101)\tLoss 0.2806 (0.6804)\tAcc 1.000 (0.760)\n",
      "Epoch: [125][7/9]\tTime 0.075 (0.116)\tData 0.056 (0.095)\tLoss 0.7735 (0.6937)\tAcc 0.500 (0.723)\n",
      "Epoch: [125][8/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 1.0908 (0.7433)\tAcc 0.562 (0.703)\n",
      "Epoch: [125][9/9]\tTime 0.075 (0.107)\tData 0.056 (0.086)\tLoss 0.1000 (0.7334)\tAcc 1.000 (0.708)\n",
      "train at epoch 126\n",
      "Epoch: [126][1/5]\tTime 0.343 (0.343)\tData 0.313 (0.313)\tLoss 0.7734 (0.7734)\tAcc 0.688 (0.688)\n",
      "Epoch: [126][2/5]\tTime 0.074 (0.208)\tData 0.050 (0.182)\tLoss 0.6779 (0.7256)\tAcc 0.750 (0.719)\n",
      "Epoch: [126][3/5]\tTime 0.077 (0.165)\tData 0.053 (0.139)\tLoss 0.7751 (0.7421)\tAcc 0.750 (0.729)\n",
      "Epoch: [126][4/5]\tTime 0.079 (0.143)\tData 0.055 (0.118)\tLoss 0.6983 (0.7312)\tAcc 0.750 (0.734)\n",
      "Epoch: [126][5/5]\tTime 0.080 (0.130)\tData 0.056 (0.106)\tLoss 0.8723 (0.7486)\tAcc 0.556 (0.712)\n",
      "validation at epoch 126\n",
      "Epoch: [126][1/9]\tTime 0.294 (0.294)\tData 0.269 (0.269)\tLoss 0.3930 (0.3930)\tAcc 0.938 (0.938)\n",
      "Epoch: [126][2/9]\tTime 0.086 (0.190)\tData 0.058 (0.164)\tLoss 0.9351 (0.6641)\tAcc 0.625 (0.781)\n",
      "Epoch: [126][3/9]\tTime 0.081 (0.154)\tData 0.052 (0.126)\tLoss 0.7009 (0.6763)\tAcc 0.750 (0.771)\n",
      "Epoch: [126][4/9]\tTime 0.079 (0.135)\tData 0.054 (0.108)\tLoss 0.5963 (0.6563)\tAcc 0.812 (0.781)\n",
      "Epoch: [126][5/9]\tTime 0.077 (0.123)\tData 0.057 (0.098)\tLoss 0.8806 (0.7012)\tAcc 0.688 (0.762)\n",
      "Epoch: [126][6/9]\tTime 0.075 (0.115)\tData 0.056 (0.091)\tLoss 0.3163 (0.6370)\tAcc 1.000 (0.802)\n",
      "Epoch: [126][7/9]\tTime 0.073 (0.109)\tData 0.054 (0.086)\tLoss 0.6892 (0.6445)\tAcc 0.750 (0.795)\n",
      "Epoch: [126][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.082)\tLoss 1.0728 (0.6980)\tAcc 0.500 (0.758)\n",
      "Epoch: [126][9/9]\tTime 0.074 (0.102)\tData 0.055 (0.079)\tLoss 0.4255 (0.6938)\tAcc 1.000 (0.762)\n",
      "train at epoch 127\n",
      "Epoch: [127][1/5]\tTime 0.356 (0.356)\tData 0.328 (0.328)\tLoss 0.7481 (0.7481)\tAcc 0.750 (0.750)\n",
      "Epoch: [127][2/5]\tTime 0.075 (0.215)\tData 0.051 (0.190)\tLoss 0.6000 (0.6741)\tAcc 0.812 (0.781)\n",
      "Epoch: [127][3/5]\tTime 0.077 (0.169)\tData 0.054 (0.144)\tLoss 0.9440 (0.7641)\tAcc 0.688 (0.750)\n",
      "Epoch: [127][4/5]\tTime 0.077 (0.146)\tData 0.054 (0.122)\tLoss 0.7168 (0.7522)\tAcc 0.750 (0.750)\n",
      "Epoch: [127][5/5]\tTime 0.082 (0.133)\tData 0.058 (0.109)\tLoss 0.8574 (0.7652)\tAcc 0.667 (0.740)\n",
      "validation at epoch 127\n",
      "Epoch: [127][1/9]\tTime 0.359 (0.359)\tData 0.335 (0.335)\tLoss 0.2585 (0.2585)\tAcc 1.000 (1.000)\n",
      "Epoch: [127][2/9]\tTime 0.072 (0.215)\tData 0.050 (0.193)\tLoss 1.0296 (0.6441)\tAcc 0.562 (0.781)\n",
      "Epoch: [127][3/9]\tTime 0.075 (0.169)\tData 0.053 (0.146)\tLoss 0.6288 (0.6390)\tAcc 0.688 (0.750)\n",
      "Epoch: [127][4/9]\tTime 0.073 (0.145)\tData 0.052 (0.122)\tLoss 0.6806 (0.6494)\tAcc 0.625 (0.719)\n",
      "Epoch: [127][5/9]\tTime 0.076 (0.131)\tData 0.056 (0.109)\tLoss 0.8435 (0.6882)\tAcc 0.688 (0.713)\n",
      "Epoch: [127][6/9]\tTime 0.080 (0.123)\tData 0.060 (0.101)\tLoss 0.2590 (0.6167)\tAcc 1.000 (0.760)\n",
      "Epoch: [127][7/9]\tTime 0.080 (0.116)\tData 0.060 (0.095)\tLoss 0.7049 (0.6293)\tAcc 0.688 (0.750)\n",
      "Epoch: [127][8/9]\tTime 0.080 (0.112)\tData 0.060 (0.091)\tLoss 1.0896 (0.6868)\tAcc 0.562 (0.727)\n",
      "Epoch: [127][9/9]\tTime 0.079 (0.108)\tData 0.060 (0.087)\tLoss 0.2652 (0.6803)\tAcc 1.000 (0.731)\n",
      "train at epoch 128\n",
      "Epoch: [128][1/5]\tTime 0.292 (0.292)\tData 0.257 (0.257)\tLoss 0.7737 (0.7737)\tAcc 0.688 (0.688)\n",
      "Epoch: [128][2/5]\tTime 0.082 (0.187)\tData 0.057 (0.157)\tLoss 1.0596 (0.9166)\tAcc 0.500 (0.594)\n",
      "Epoch: [128][3/5]\tTime 0.077 (0.151)\tData 0.054 (0.123)\tLoss 0.6695 (0.8342)\tAcc 0.812 (0.667)\n",
      "Epoch: [128][4/5]\tTime 0.077 (0.132)\tData 0.054 (0.106)\tLoss 0.4553 (0.7395)\tAcc 0.938 (0.734)\n",
      "Epoch: [128][5/5]\tTime 0.081 (0.122)\tData 0.058 (0.096)\tLoss 0.6314 (0.7262)\tAcc 0.667 (0.726)\n",
      "validation at epoch 128\n",
      "Epoch: [128][1/9]\tTime 0.340 (0.340)\tData 0.309 (0.309)\tLoss 0.3646 (0.3646)\tAcc 0.938 (0.938)\n",
      "Epoch: [128][2/9]\tTime 0.076 (0.208)\tData 0.050 (0.180)\tLoss 1.0117 (0.6882)\tAcc 0.500 (0.719)\n",
      "Epoch: [128][3/9]\tTime 0.078 (0.165)\tData 0.055 (0.138)\tLoss 0.6281 (0.6681)\tAcc 0.688 (0.708)\n",
      "Epoch: [128][4/9]\tTime 0.082 (0.144)\tData 0.057 (0.118)\tLoss 0.5775 (0.6455)\tAcc 0.875 (0.750)\n",
      "Epoch: [128][5/9]\tTime 0.076 (0.130)\tData 0.056 (0.106)\tLoss 0.8877 (0.6939)\tAcc 0.625 (0.725)\n",
      "Epoch: [128][6/9]\tTime 0.080 (0.122)\tData 0.060 (0.098)\tLoss 0.2189 (0.6148)\tAcc 1.000 (0.771)\n",
      "Epoch: [128][7/9]\tTime 0.079 (0.116)\tData 0.059 (0.093)\tLoss 0.6994 (0.6268)\tAcc 0.625 (0.750)\n",
      "Epoch: [128][8/9]\tTime 0.076 (0.111)\tData 0.056 (0.088)\tLoss 1.0668 (0.6818)\tAcc 0.562 (0.727)\n",
      "Epoch: [128][9/9]\tTime 0.076 (0.107)\tData 0.057 (0.085)\tLoss 0.2348 (0.6750)\tAcc 1.000 (0.731)\n",
      "train at epoch 129\n",
      "Epoch: [129][1/5]\tTime 0.323 (0.323)\tData 0.294 (0.294)\tLoss 0.8723 (0.8723)\tAcc 0.625 (0.625)\n",
      "Epoch: [129][2/5]\tTime 0.075 (0.199)\tData 0.050 (0.172)\tLoss 0.7021 (0.7872)\tAcc 0.812 (0.719)\n",
      "Epoch: [129][3/5]\tTime 0.076 (0.158)\tData 0.052 (0.132)\tLoss 0.4561 (0.6769)\tAcc 0.875 (0.771)\n",
      "Epoch: [129][4/5]\tTime 0.078 (0.138)\tData 0.054 (0.112)\tLoss 0.8606 (0.7228)\tAcc 0.625 (0.734)\n",
      "Epoch: [129][5/5]\tTime 0.080 (0.127)\tData 0.056 (0.101)\tLoss 1.1544 (0.7760)\tAcc 0.667 (0.726)\n",
      "validation at epoch 129\n",
      "Epoch: [129][1/9]\tTime 0.313 (0.313)\tData 0.289 (0.289)\tLoss 0.3156 (0.3156)\tAcc 0.938 (0.938)\n",
      "Epoch: [129][2/9]\tTime 0.071 (0.192)\tData 0.050 (0.170)\tLoss 1.0361 (0.6758)\tAcc 0.625 (0.781)\n",
      "Epoch: [129][3/9]\tTime 0.075 (0.153)\tData 0.053 (0.131)\tLoss 0.5888 (0.6468)\tAcc 0.812 (0.792)\n",
      "Epoch: [129][4/9]\tTime 0.074 (0.133)\tData 0.051 (0.111)\tLoss 0.6151 (0.6389)\tAcc 0.750 (0.781)\n",
      "Epoch: [129][5/9]\tTime 0.071 (0.121)\tData 0.051 (0.099)\tLoss 0.8660 (0.6843)\tAcc 0.750 (0.775)\n",
      "Epoch: [129][6/9]\tTime 0.079 (0.114)\tData 0.059 (0.092)\tLoss 0.2596 (0.6135)\tAcc 1.000 (0.812)\n",
      "Epoch: [129][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.087)\tLoss 0.6432 (0.6178)\tAcc 0.688 (0.795)\n",
      "Epoch: [129][8/9]\tTime 0.074 (0.104)\tData 0.054 (0.083)\tLoss 1.1436 (0.6835)\tAcc 0.438 (0.750)\n",
      "Epoch: [129][9/9]\tTime 0.078 (0.101)\tData 0.060 (0.080)\tLoss 0.3333 (0.6781)\tAcc 1.000 (0.754)\n",
      "train at epoch 130\n",
      "Epoch: [130][1/5]\tTime 0.343 (0.343)\tData 0.315 (0.315)\tLoss 0.8042 (0.8042)\tAcc 0.688 (0.688)\n",
      "Epoch: [130][2/5]\tTime 0.076 (0.210)\tData 0.051 (0.183)\tLoss 0.4921 (0.6481)\tAcc 0.875 (0.781)\n",
      "Epoch: [130][3/5]\tTime 0.080 (0.166)\tData 0.055 (0.140)\tLoss 0.5398 (0.6120)\tAcc 0.938 (0.833)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [130][4/5]\tTime 0.078 (0.144)\tData 0.054 (0.119)\tLoss 1.1222 (0.7396)\tAcc 0.500 (0.750)\n",
      "Epoch: [130][5/5]\tTime 0.080 (0.131)\tData 0.055 (0.106)\tLoss 0.5839 (0.7204)\tAcc 0.778 (0.753)\n",
      "validation at epoch 130\n",
      "Epoch: [130][1/9]\tTime 0.408 (0.408)\tData 0.383 (0.383)\tLoss 0.3315 (0.3315)\tAcc 0.938 (0.938)\n",
      "Epoch: [130][2/9]\tTime 0.077 (0.243)\tData 0.055 (0.219)\tLoss 0.8991 (0.6153)\tAcc 0.438 (0.688)\n",
      "Epoch: [130][3/9]\tTime 0.083 (0.189)\tData 0.062 (0.167)\tLoss 0.6413 (0.6240)\tAcc 0.750 (0.708)\n",
      "Epoch: [130][4/9]\tTime 0.080 (0.162)\tData 0.060 (0.140)\tLoss 0.6938 (0.6414)\tAcc 0.688 (0.703)\n",
      "Epoch: [130][5/9]\tTime 0.080 (0.146)\tData 0.060 (0.124)\tLoss 0.8787 (0.6889)\tAcc 0.625 (0.688)\n",
      "Epoch: [130][6/9]\tTime 0.074 (0.134)\tData 0.055 (0.112)\tLoss 0.2423 (0.6145)\tAcc 1.000 (0.740)\n",
      "Epoch: [130][7/9]\tTime 0.080 (0.126)\tData 0.060 (0.105)\tLoss 0.6770 (0.6234)\tAcc 0.688 (0.732)\n",
      "Epoch: [130][8/9]\tTime 0.081 (0.120)\tData 0.061 (0.099)\tLoss 0.8127 (0.6470)\tAcc 0.688 (0.727)\n",
      "Epoch: [130][9/9]\tTime 0.080 (0.116)\tData 0.060 (0.095)\tLoss 0.1366 (0.6392)\tAcc 1.000 (0.731)\n",
      "train at epoch 131\n",
      "Epoch: [131][1/5]\tTime 0.354 (0.354)\tData 0.324 (0.324)\tLoss 0.7581 (0.7581)\tAcc 0.625 (0.625)\n",
      "Epoch: [131][2/5]\tTime 0.083 (0.218)\tData 0.058 (0.191)\tLoss 0.9051 (0.8316)\tAcc 0.625 (0.625)\n",
      "Epoch: [131][3/5]\tTime 0.077 (0.171)\tData 0.054 (0.146)\tLoss 0.7034 (0.7889)\tAcc 0.625 (0.625)\n",
      "Epoch: [131][4/5]\tTime 0.080 (0.149)\tData 0.054 (0.123)\tLoss 0.6142 (0.7452)\tAcc 0.812 (0.672)\n",
      "Epoch: [131][5/5]\tTime 0.083 (0.135)\tData 0.057 (0.110)\tLoss 0.4815 (0.7127)\tAcc 0.889 (0.699)\n",
      "validation at epoch 131\n",
      "Epoch: [131][1/9]\tTime 0.279 (0.279)\tData 0.253 (0.253)\tLoss 0.3442 (0.3442)\tAcc 0.938 (0.938)\n",
      "Epoch: [131][2/9]\tTime 0.115 (0.197)\tData 0.093 (0.173)\tLoss 0.9769 (0.6605)\tAcc 0.812 (0.875)\n",
      "Epoch: [131][3/9]\tTime 0.074 (0.156)\tData 0.052 (0.133)\tLoss 0.6092 (0.6434)\tAcc 0.688 (0.812)\n",
      "Epoch: [131][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.113)\tLoss 0.7772 (0.6769)\tAcc 0.688 (0.781)\n",
      "Epoch: [131][5/9]\tTime 0.077 (0.124)\tData 0.056 (0.102)\tLoss 0.9497 (0.7314)\tAcc 0.625 (0.750)\n",
      "Epoch: [131][6/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.2451 (0.6504)\tAcc 1.000 (0.792)\n",
      "Epoch: [131][7/9]\tTime 0.075 (0.110)\tData 0.055 (0.088)\tLoss 0.6047 (0.6438)\tAcc 0.750 (0.786)\n",
      "Epoch: [131][8/9]\tTime 0.080 (0.106)\tData 0.060 (0.085)\tLoss 0.9582 (0.6831)\tAcc 0.562 (0.758)\n",
      "Epoch: [131][9/9]\tTime 0.080 (0.103)\tData 0.060 (0.082)\tLoss 0.1611 (0.6751)\tAcc 1.000 (0.762)\n",
      "train at epoch 132\n",
      "Epoch: [132][1/5]\tTime 0.255 (0.255)\tData 0.226 (0.226)\tLoss 0.5963 (0.5963)\tAcc 0.750 (0.750)\n",
      "Epoch: [132][2/5]\tTime 0.076 (0.165)\tData 0.050 (0.138)\tLoss 0.6491 (0.6227)\tAcc 0.812 (0.781)\n",
      "Epoch: [132][3/5]\tTime 0.076 (0.136)\tData 0.053 (0.110)\tLoss 0.9509 (0.7321)\tAcc 0.562 (0.708)\n",
      "Epoch: [132][4/5]\tTime 0.077 (0.121)\tData 0.054 (0.096)\tLoss 0.6070 (0.7008)\tAcc 0.812 (0.734)\n",
      "Epoch: [132][5/5]\tTime 0.082 (0.113)\tData 0.058 (0.088)\tLoss 1.1641 (0.7579)\tAcc 0.444 (0.699)\n",
      "validation at epoch 132\n",
      "Epoch: [132][1/9]\tTime 0.287 (0.287)\tData 0.261 (0.261)\tLoss 0.2883 (0.2883)\tAcc 0.938 (0.938)\n",
      "Epoch: [132][2/9]\tTime 0.070 (0.178)\tData 0.049 (0.155)\tLoss 0.9694 (0.6289)\tAcc 0.625 (0.781)\n",
      "Epoch: [132][3/9]\tTime 0.074 (0.144)\tData 0.053 (0.121)\tLoss 0.6425 (0.6334)\tAcc 0.750 (0.771)\n",
      "Epoch: [132][4/9]\tTime 0.074 (0.126)\tData 0.053 (0.104)\tLoss 0.6987 (0.6497)\tAcc 0.750 (0.766)\n",
      "Epoch: [132][5/9]\tTime 0.073 (0.116)\tData 0.053 (0.094)\tLoss 0.8215 (0.6841)\tAcc 0.688 (0.750)\n",
      "Epoch: [132][6/9]\tTime 0.074 (0.109)\tData 0.054 (0.087)\tLoss 0.2741 (0.6158)\tAcc 1.000 (0.792)\n",
      "Epoch: [132][7/9]\tTime 0.073 (0.104)\tData 0.054 (0.082)\tLoss 0.6314 (0.6180)\tAcc 0.875 (0.804)\n",
      "Epoch: [132][8/9]\tTime 0.075 (0.100)\tData 0.055 (0.079)\tLoss 0.9827 (0.6636)\tAcc 0.625 (0.781)\n",
      "Epoch: [132][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.076)\tLoss 0.2928 (0.6579)\tAcc 1.000 (0.785)\n",
      "train at epoch 133\n",
      "Epoch: [133][1/5]\tTime 0.258 (0.258)\tData 0.228 (0.228)\tLoss 0.8219 (0.8219)\tAcc 0.688 (0.688)\n",
      "Epoch: [133][2/5]\tTime 0.093 (0.175)\tData 0.065 (0.146)\tLoss 0.5159 (0.6689)\tAcc 0.875 (0.781)\n",
      "Epoch: [133][3/5]\tTime 0.075 (0.142)\tData 0.051 (0.114)\tLoss 0.6356 (0.6578)\tAcc 0.688 (0.750)\n",
      "Epoch: [133][4/5]\tTime 0.078 (0.126)\tData 0.054 (0.099)\tLoss 0.6449 (0.6546)\tAcc 0.688 (0.734)\n",
      "Epoch: [133][5/5]\tTime 0.080 (0.116)\tData 0.056 (0.091)\tLoss 0.9658 (0.6929)\tAcc 0.556 (0.712)\n",
      "validation at epoch 133\n",
      "Epoch: [133][1/9]\tTime 0.330 (0.330)\tData 0.306 (0.306)\tLoss 0.3193 (0.3193)\tAcc 0.938 (0.938)\n",
      "Epoch: [133][2/9]\tTime 0.071 (0.201)\tData 0.050 (0.178)\tLoss 0.9752 (0.6473)\tAcc 0.562 (0.750)\n",
      "Epoch: [133][3/9]\tTime 0.074 (0.159)\tData 0.053 (0.136)\tLoss 0.5628 (0.6191)\tAcc 0.812 (0.771)\n",
      "Epoch: [133][4/9]\tTime 0.072 (0.137)\tData 0.053 (0.115)\tLoss 0.6934 (0.6377)\tAcc 0.750 (0.766)\n",
      "Epoch: [133][5/9]\tTime 0.074 (0.124)\tData 0.055 (0.103)\tLoss 0.8170 (0.6736)\tAcc 0.750 (0.762)\n",
      "Epoch: [133][6/9]\tTime 0.079 (0.117)\tData 0.060 (0.096)\tLoss 0.2023 (0.5950)\tAcc 1.000 (0.802)\n",
      "Epoch: [133][7/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 0.5396 (0.5871)\tAcc 0.812 (0.804)\n",
      "Epoch: [133][8/9]\tTime 0.076 (0.106)\tData 0.056 (0.086)\tLoss 0.9707 (0.6350)\tAcc 0.688 (0.789)\n",
      "Epoch: [133][9/9]\tTime 0.074 (0.103)\tData 0.056 (0.083)\tLoss 0.2910 (0.6297)\tAcc 1.000 (0.792)\n",
      "train at epoch 134\n",
      "Epoch: [134][1/5]\tTime 0.293 (0.293)\tData 0.263 (0.263)\tLoss 0.7338 (0.7338)\tAcc 0.625 (0.625)\n",
      "Epoch: [134][2/5]\tTime 0.075 (0.184)\tData 0.050 (0.156)\tLoss 0.6933 (0.7135)\tAcc 0.812 (0.719)\n",
      "Epoch: [134][3/5]\tTime 0.076 (0.148)\tData 0.053 (0.122)\tLoss 0.9356 (0.7875)\tAcc 0.688 (0.708)\n",
      "Epoch: [134][4/5]\tTime 0.078 (0.130)\tData 0.054 (0.105)\tLoss 0.7242 (0.7717)\tAcc 0.688 (0.703)\n",
      "Epoch: [134][5/5]\tTime 0.081 (0.121)\tData 0.057 (0.096)\tLoss 0.9424 (0.7928)\tAcc 0.556 (0.685)\n",
      "validation at epoch 134\n",
      "Epoch: [134][1/9]\tTime 0.240 (0.240)\tData 0.216 (0.216)\tLoss 0.3440 (0.3440)\tAcc 0.938 (0.938)\n",
      "Epoch: [134][2/9]\tTime 0.073 (0.156)\tData 0.051 (0.134)\tLoss 0.8338 (0.5889)\tAcc 0.562 (0.750)\n",
      "Epoch: [134][3/9]\tTime 0.074 (0.129)\tData 0.053 (0.107)\tLoss 0.5481 (0.5753)\tAcc 0.812 (0.771)\n",
      "Epoch: [134][4/9]\tTime 0.073 (0.115)\tData 0.053 (0.093)\tLoss 0.6085 (0.5836)\tAcc 0.812 (0.781)\n",
      "Epoch: [134][5/9]\tTime 0.074 (0.107)\tData 0.055 (0.086)\tLoss 0.7954 (0.6260)\tAcc 0.688 (0.762)\n",
      "Epoch: [134][6/9]\tTime 0.074 (0.101)\tData 0.055 (0.081)\tLoss 0.2621 (0.5653)\tAcc 1.000 (0.802)\n",
      "Epoch: [134][7/9]\tTime 0.073 (0.097)\tData 0.055 (0.077)\tLoss 0.7488 (0.5915)\tAcc 0.688 (0.786)\n",
      "Epoch: [134][8/9]\tTime 0.075 (0.095)\tData 0.056 (0.074)\tLoss 1.0572 (0.6497)\tAcc 0.562 (0.758)\n",
      "Epoch: [134][9/9]\tTime 0.074 (0.092)\tData 0.056 (0.072)\tLoss 0.1526 (0.6421)\tAcc 1.000 (0.762)\n",
      "train at epoch 135\n",
      "Epoch: [135][1/5]\tTime 0.368 (0.368)\tData 0.340 (0.340)\tLoss 0.6723 (0.6723)\tAcc 0.812 (0.812)\n",
      "Epoch: [135][2/5]\tTime 0.075 (0.222)\tData 0.050 (0.195)\tLoss 0.7881 (0.7302)\tAcc 0.625 (0.719)\n",
      "Epoch: [135][3/5]\tTime 0.076 (0.173)\tData 0.053 (0.148)\tLoss 0.5518 (0.6708)\tAcc 0.812 (0.750)\n",
      "Epoch: [135][4/5]\tTime 0.078 (0.149)\tData 0.055 (0.125)\tLoss 0.7196 (0.6830)\tAcc 0.625 (0.719)\n",
      "Epoch: [135][5/5]\tTime 0.082 (0.136)\tData 0.059 (0.111)\tLoss 0.7599 (0.6924)\tAcc 0.667 (0.712)\n",
      "validation at epoch 135\n",
      "Epoch: [135][1/9]\tTime 0.328 (0.328)\tData 0.302 (0.302)\tLoss 0.3229 (0.3229)\tAcc 0.938 (0.938)\n",
      "Epoch: [135][2/9]\tTime 0.071 (0.200)\tData 0.049 (0.176)\tLoss 1.0153 (0.6691)\tAcc 0.562 (0.750)\n",
      "Epoch: [135][3/9]\tTime 0.072 (0.157)\tData 0.051 (0.134)\tLoss 0.4982 (0.6122)\tAcc 0.812 (0.771)\n",
      "Epoch: [135][4/9]\tTime 0.074 (0.136)\tData 0.054 (0.114)\tLoss 0.7907 (0.6568)\tAcc 0.688 (0.750)\n",
      "Epoch: [135][5/9]\tTime 0.074 (0.124)\tData 0.054 (0.102)\tLoss 0.7332 (0.6721)\tAcc 0.688 (0.738)\n",
      "Epoch: [135][6/9]\tTime 0.073 (0.115)\tData 0.055 (0.094)\tLoss 0.1898 (0.5917)\tAcc 1.000 (0.781)\n",
      "Epoch: [135][7/9]\tTime 0.073 (0.109)\tData 0.055 (0.089)\tLoss 0.6171 (0.5953)\tAcc 0.812 (0.786)\n",
      "Epoch: [135][8/9]\tTime 0.075 (0.105)\tData 0.056 (0.084)\tLoss 1.1947 (0.6702)\tAcc 0.438 (0.742)\n",
      "Epoch: [135][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.081)\tLoss 0.1250 (0.6619)\tAcc 1.000 (0.746)\n",
      "train at epoch 136\n",
      "Epoch: [136][1/5]\tTime 0.334 (0.334)\tData 0.303 (0.303)\tLoss 0.6114 (0.6114)\tAcc 0.688 (0.688)\n",
      "Epoch: [136][2/5]\tTime 0.073 (0.203)\tData 0.049 (0.176)\tLoss 0.6044 (0.6079)\tAcc 0.875 (0.781)\n",
      "Epoch: [136][3/5]\tTime 0.077 (0.161)\tData 0.054 (0.135)\tLoss 0.5575 (0.5911)\tAcc 0.812 (0.792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [136][4/5]\tTime 0.077 (0.140)\tData 0.055 (0.115)\tLoss 1.0246 (0.6995)\tAcc 0.562 (0.734)\n",
      "Epoch: [136][5/5]\tTime 0.082 (0.128)\tData 0.058 (0.104)\tLoss 0.9338 (0.7284)\tAcc 0.556 (0.712)\n",
      "validation at epoch 136\n",
      "Epoch: [136][1/9]\tTime 0.273 (0.273)\tData 0.247 (0.247)\tLoss 0.2713 (0.2713)\tAcc 0.938 (0.938)\n",
      "Epoch: [136][2/9]\tTime 0.088 (0.181)\tData 0.068 (0.158)\tLoss 0.8931 (0.5822)\tAcc 0.688 (0.812)\n",
      "Epoch: [136][3/9]\tTime 0.074 (0.145)\tData 0.053 (0.123)\tLoss 0.6105 (0.5916)\tAcc 0.625 (0.750)\n",
      "Epoch: [136][4/9]\tTime 0.074 (0.127)\tData 0.053 (0.105)\tLoss 0.7368 (0.6279)\tAcc 0.688 (0.734)\n",
      "Epoch: [136][5/9]\tTime 0.075 (0.117)\tData 0.054 (0.095)\tLoss 0.8701 (0.6763)\tAcc 0.688 (0.725)\n",
      "Epoch: [136][6/9]\tTime 0.071 (0.109)\tData 0.053 (0.088)\tLoss 0.2350 (0.6028)\tAcc 1.000 (0.771)\n",
      "Epoch: [136][7/9]\tTime 0.073 (0.104)\tData 0.055 (0.083)\tLoss 0.6745 (0.6130)\tAcc 0.625 (0.750)\n",
      "Epoch: [136][8/9]\tTime 0.075 (0.100)\tData 0.056 (0.080)\tLoss 1.0585 (0.6687)\tAcc 0.562 (0.727)\n",
      "Epoch: [136][9/9]\tTime 0.073 (0.097)\tData 0.055 (0.077)\tLoss 0.1303 (0.6604)\tAcc 1.000 (0.731)\n",
      "train at epoch 137\n",
      "Epoch: [137][1/5]\tTime 0.287 (0.287)\tData 0.250 (0.250)\tLoss 0.5740 (0.5740)\tAcc 0.875 (0.875)\n",
      "Epoch: [137][2/5]\tTime 0.066 (0.177)\tData 0.042 (0.146)\tLoss 0.8514 (0.7127)\tAcc 0.688 (0.781)\n",
      "Epoch: [137][3/5]\tTime 0.077 (0.144)\tData 0.054 (0.115)\tLoss 0.8133 (0.7462)\tAcc 0.750 (0.771)\n",
      "Epoch: [137][4/5]\tTime 0.078 (0.127)\tData 0.055 (0.100)\tLoss 0.5212 (0.6900)\tAcc 0.812 (0.781)\n",
      "Epoch: [137][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.091)\tLoss 0.7634 (0.6990)\tAcc 0.667 (0.767)\n",
      "validation at epoch 137\n",
      "Epoch: [137][1/9]\tTime 0.314 (0.314)\tData 0.290 (0.290)\tLoss 0.3365 (0.3365)\tAcc 0.938 (0.938)\n",
      "Epoch: [137][2/9]\tTime 0.072 (0.193)\tData 0.051 (0.170)\tLoss 0.9521 (0.6443)\tAcc 0.438 (0.688)\n",
      "Epoch: [137][3/9]\tTime 0.074 (0.153)\tData 0.053 (0.131)\tLoss 0.6826 (0.6570)\tAcc 0.750 (0.708)\n",
      "Epoch: [137][4/9]\tTime 0.074 (0.133)\tData 0.053 (0.112)\tLoss 0.7241 (0.6738)\tAcc 0.625 (0.688)\n",
      "Epoch: [137][5/9]\tTime 0.073 (0.121)\tData 0.054 (0.100)\tLoss 0.9044 (0.7199)\tAcc 0.625 (0.675)\n",
      "Epoch: [137][6/9]\tTime 0.073 (0.113)\tData 0.054 (0.093)\tLoss 0.2512 (0.6418)\tAcc 1.000 (0.729)\n",
      "Epoch: [137][7/9]\tTime 0.073 (0.108)\tData 0.055 (0.087)\tLoss 0.6084 (0.6370)\tAcc 0.875 (0.750)\n",
      "Epoch: [137][8/9]\tTime 0.074 (0.103)\tData 0.056 (0.083)\tLoss 0.9997 (0.6824)\tAcc 0.500 (0.719)\n",
      "Epoch: [137][9/9]\tTime 0.073 (0.100)\tData 0.055 (0.080)\tLoss 0.2601 (0.6759)\tAcc 1.000 (0.723)\n",
      "train at epoch 138\n",
      "Epoch: [138][1/5]\tTime 0.282 (0.282)\tData 0.253 (0.253)\tLoss 0.7536 (0.7536)\tAcc 0.688 (0.688)\n",
      "Epoch: [138][2/5]\tTime 0.076 (0.179)\tData 0.050 (0.152)\tLoss 0.8187 (0.7861)\tAcc 0.688 (0.688)\n",
      "Epoch: [138][3/5]\tTime 0.076 (0.145)\tData 0.053 (0.119)\tLoss 0.9264 (0.8329)\tAcc 0.562 (0.646)\n",
      "Epoch: [138][4/5]\tTime 0.078 (0.128)\tData 0.055 (0.103)\tLoss 0.7286 (0.8068)\tAcc 0.750 (0.672)\n",
      "Epoch: [138][5/5]\tTime 0.079 (0.118)\tData 0.056 (0.094)\tLoss 0.6225 (0.7841)\tAcc 0.778 (0.685)\n",
      "validation at epoch 138\n",
      "Epoch: [138][1/9]\tTime 0.338 (0.338)\tData 0.314 (0.314)\tLoss 0.3376 (0.3376)\tAcc 0.875 (0.875)\n",
      "Epoch: [138][2/9]\tTime 0.072 (0.205)\tData 0.051 (0.182)\tLoss 1.0436 (0.6906)\tAcc 0.500 (0.688)\n",
      "Epoch: [138][3/9]\tTime 0.075 (0.162)\tData 0.053 (0.139)\tLoss 0.6211 (0.6674)\tAcc 0.750 (0.708)\n",
      "Epoch: [138][4/9]\tTime 0.071 (0.139)\tData 0.052 (0.117)\tLoss 0.6517 (0.6635)\tAcc 0.750 (0.719)\n",
      "Epoch: [138][5/9]\tTime 0.074 (0.126)\tData 0.055 (0.105)\tLoss 0.8616 (0.7031)\tAcc 0.688 (0.713)\n",
      "Epoch: [138][6/9]\tTime 0.074 (0.117)\tData 0.055 (0.097)\tLoss 0.2538 (0.6282)\tAcc 1.000 (0.760)\n",
      "Epoch: [138][7/9]\tTime 0.073 (0.111)\tData 0.055 (0.091)\tLoss 0.5949 (0.6235)\tAcc 0.750 (0.759)\n",
      "Epoch: [138][8/9]\tTime 0.075 (0.106)\tData 0.056 (0.086)\tLoss 1.0895 (0.6817)\tAcc 0.562 (0.734)\n",
      "Epoch: [138][9/9]\tTime 0.073 (0.103)\tData 0.055 (0.083)\tLoss 0.1417 (0.6734)\tAcc 1.000 (0.738)\n",
      "train at epoch 139\n",
      "Epoch: [139][1/5]\tTime 0.333 (0.333)\tData 0.301 (0.301)\tLoss 0.7829 (0.7829)\tAcc 0.688 (0.688)\n",
      "Epoch: [139][2/5]\tTime 0.072 (0.203)\tData 0.048 (0.174)\tLoss 0.6978 (0.7404)\tAcc 0.625 (0.656)\n",
      "Epoch: [139][3/5]\tTime 0.077 (0.161)\tData 0.053 (0.134)\tLoss 0.6440 (0.7082)\tAcc 0.750 (0.688)\n",
      "Epoch: [139][4/5]\tTime 0.079 (0.140)\tData 0.054 (0.114)\tLoss 0.5179 (0.6606)\tAcc 0.938 (0.750)\n",
      "Epoch: [139][5/5]\tTime 0.079 (0.128)\tData 0.056 (0.102)\tLoss 0.8193 (0.6802)\tAcc 0.444 (0.712)\n",
      "validation at epoch 139\n",
      "Epoch: [139][1/9]\tTime 0.376 (0.376)\tData 0.352 (0.352)\tLoss 0.3644 (0.3644)\tAcc 0.875 (0.875)\n",
      "Epoch: [139][2/9]\tTime 0.073 (0.224)\tData 0.051 (0.202)\tLoss 1.0022 (0.6833)\tAcc 0.500 (0.688)\n",
      "Epoch: [139][3/9]\tTime 0.073 (0.174)\tData 0.053 (0.152)\tLoss 0.7181 (0.6949)\tAcc 0.625 (0.667)\n",
      "Epoch: [139][4/9]\tTime 0.073 (0.149)\tData 0.053 (0.127)\tLoss 0.6740 (0.6897)\tAcc 0.625 (0.656)\n",
      "Epoch: [139][5/9]\tTime 0.074 (0.134)\tData 0.054 (0.113)\tLoss 0.7183 (0.6954)\tAcc 0.688 (0.663)\n",
      "Epoch: [139][6/9]\tTime 0.073 (0.124)\tData 0.055 (0.103)\tLoss 0.2546 (0.6219)\tAcc 1.000 (0.719)\n",
      "Epoch: [139][7/9]\tTime 0.073 (0.116)\tData 0.055 (0.096)\tLoss 0.5680 (0.6142)\tAcc 0.812 (0.732)\n",
      "Epoch: [139][8/9]\tTime 0.075 (0.111)\tData 0.056 (0.091)\tLoss 1.1869 (0.6858)\tAcc 0.438 (0.695)\n",
      "Epoch: [139][9/9]\tTime 0.073 (0.107)\tData 0.055 (0.087)\tLoss 0.0780 (0.6765)\tAcc 1.000 (0.700)\n",
      "train at epoch 140\n",
      "Epoch: [140][1/5]\tTime 0.324 (0.324)\tData 0.295 (0.295)\tLoss 0.4934 (0.4934)\tAcc 0.938 (0.938)\n",
      "Epoch: [140][2/5]\tTime 0.074 (0.199)\tData 0.050 (0.172)\tLoss 0.7384 (0.6159)\tAcc 0.688 (0.812)\n",
      "Epoch: [140][3/5]\tTime 0.078 (0.159)\tData 0.054 (0.133)\tLoss 0.7843 (0.6720)\tAcc 0.688 (0.771)\n",
      "Epoch: [140][4/5]\tTime 0.077 (0.138)\tData 0.054 (0.113)\tLoss 0.7589 (0.6937)\tAcc 0.750 (0.766)\n",
      "Epoch: [140][5/5]\tTime 0.080 (0.126)\tData 0.056 (0.102)\tLoss 1.1538 (0.7505)\tAcc 0.556 (0.740)\n",
      "validation at epoch 140\n",
      "Epoch: [140][1/9]\tTime 0.266 (0.266)\tData 0.239 (0.239)\tLoss 0.3833 (0.3833)\tAcc 0.875 (0.875)\n",
      "Epoch: [140][2/9]\tTime 0.069 (0.168)\tData 0.049 (0.144)\tLoss 0.9434 (0.6633)\tAcc 0.625 (0.750)\n",
      "Epoch: [140][3/9]\tTime 0.074 (0.136)\tData 0.053 (0.114)\tLoss 0.7547 (0.6938)\tAcc 0.688 (0.729)\n",
      "Epoch: [140][4/9]\tTime 0.074 (0.121)\tData 0.053 (0.099)\tLoss 0.5800 (0.6653)\tAcc 0.812 (0.750)\n",
      "Epoch: [140][5/9]\tTime 0.074 (0.111)\tData 0.055 (0.090)\tLoss 0.9367 (0.7196)\tAcc 0.625 (0.725)\n",
      "Epoch: [140][6/9]\tTime 0.073 (0.105)\tData 0.054 (0.084)\tLoss 0.3288 (0.6545)\tAcc 1.000 (0.771)\n",
      "Epoch: [140][7/9]\tTime 0.073 (0.100)\tData 0.054 (0.080)\tLoss 0.6730 (0.6571)\tAcc 0.688 (0.759)\n",
      "Epoch: [140][8/9]\tTime 0.075 (0.097)\tData 0.056 (0.077)\tLoss 1.0857 (0.7107)\tAcc 0.500 (0.727)\n",
      "Epoch: [140][9/9]\tTime 0.073 (0.094)\tData 0.055 (0.074)\tLoss 0.1717 (0.7024)\tAcc 1.000 (0.731)\n",
      "train at epoch 141\n",
      "Epoch: [141][1/5]\tTime 0.345 (0.345)\tData 0.317 (0.317)\tLoss 0.4855 (0.4855)\tAcc 0.750 (0.750)\n",
      "Epoch: [141][2/5]\tTime 0.075 (0.210)\tData 0.051 (0.184)\tLoss 0.6175 (0.5515)\tAcc 0.750 (0.750)\n",
      "Epoch: [141][3/5]\tTime 0.077 (0.166)\tData 0.054 (0.141)\tLoss 0.9650 (0.6893)\tAcc 0.625 (0.708)\n",
      "Epoch: [141][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.119)\tLoss 0.6938 (0.6905)\tAcc 0.750 (0.719)\n",
      "Epoch: [141][5/5]\tTime 0.079 (0.131)\tData 0.056 (0.107)\tLoss 0.7218 (0.6943)\tAcc 0.778 (0.726)\n",
      "validation at epoch 141\n",
      "Epoch: [141][1/9]\tTime 0.359 (0.359)\tData 0.333 (0.333)\tLoss 0.3563 (0.3563)\tAcc 0.875 (0.875)\n",
      "Epoch: [141][2/9]\tTime 0.070 (0.214)\tData 0.049 (0.191)\tLoss 1.0248 (0.6906)\tAcc 0.625 (0.750)\n",
      "Epoch: [141][3/9]\tTime 0.073 (0.167)\tData 0.053 (0.145)\tLoss 0.6261 (0.6691)\tAcc 0.812 (0.771)\n",
      "Epoch: [141][4/9]\tTime 0.073 (0.144)\tData 0.053 (0.122)\tLoss 0.6210 (0.6571)\tAcc 0.812 (0.781)\n",
      "Epoch: [141][5/9]\tTime 0.074 (0.130)\tData 0.055 (0.108)\tLoss 0.8040 (0.6865)\tAcc 0.688 (0.762)\n",
      "Epoch: [141][6/9]\tTime 0.073 (0.120)\tData 0.055 (0.100)\tLoss 0.3035 (0.6226)\tAcc 1.000 (0.802)\n",
      "Epoch: [141][7/9]\tTime 0.073 (0.114)\tData 0.055 (0.093)\tLoss 0.6562 (0.6274)\tAcc 0.750 (0.795)\n",
      "Epoch: [141][8/9]\tTime 0.075 (0.109)\tData 0.056 (0.089)\tLoss 1.0548 (0.6809)\tAcc 0.562 (0.766)\n",
      "Epoch: [141][9/9]\tTime 0.073 (0.105)\tData 0.055 (0.085)\tLoss 0.2595 (0.6744)\tAcc 1.000 (0.769)\n",
      "train at epoch 142\n",
      "Epoch: [142][1/5]\tTime 0.270 (0.270)\tData 0.235 (0.235)\tLoss 0.7279 (0.7279)\tAcc 0.625 (0.625)\n",
      "Epoch: [142][2/5]\tTime 0.072 (0.171)\tData 0.048 (0.141)\tLoss 0.8328 (0.7804)\tAcc 0.688 (0.656)\n",
      "Epoch: [142][3/5]\tTime 0.079 (0.140)\tData 0.055 (0.112)\tLoss 0.7742 (0.7783)\tAcc 0.625 (0.646)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [142][4/5]\tTime 0.077 (0.125)\tData 0.054 (0.098)\tLoss 0.6329 (0.7419)\tAcc 0.812 (0.688)\n",
      "Epoch: [142][5/5]\tTime 0.079 (0.115)\tData 0.055 (0.089)\tLoss 0.6588 (0.7317)\tAcc 0.889 (0.712)\n",
      "validation at epoch 142\n",
      "Epoch: [142][1/9]\tTime 0.378 (0.378)\tData 0.350 (0.350)\tLoss 0.3162 (0.3162)\tAcc 0.938 (0.938)\n",
      "Epoch: [142][2/9]\tTime 0.079 (0.229)\tData 0.056 (0.203)\tLoss 1.0863 (0.7012)\tAcc 0.500 (0.719)\n",
      "Epoch: [142][3/9]\tTime 0.080 (0.179)\tData 0.056 (0.154)\tLoss 0.6187 (0.6737)\tAcc 0.750 (0.729)\n",
      "Epoch: [142][4/9]\tTime 0.073 (0.153)\tData 0.053 (0.129)\tLoss 0.5909 (0.6530)\tAcc 0.750 (0.734)\n",
      "Epoch: [142][5/9]\tTime 0.080 (0.138)\tData 0.059 (0.115)\tLoss 0.8715 (0.6967)\tAcc 0.625 (0.713)\n",
      "Epoch: [142][6/9]\tTime 0.080 (0.128)\tData 0.060 (0.106)\tLoss 0.2566 (0.6234)\tAcc 1.000 (0.760)\n",
      "Epoch: [142][7/9]\tTime 0.080 (0.122)\tData 0.060 (0.099)\tLoss 0.5162 (0.6081)\tAcc 0.875 (0.777)\n",
      "Epoch: [142][8/9]\tTime 0.078 (0.116)\tData 0.058 (0.094)\tLoss 1.0906 (0.6684)\tAcc 0.438 (0.734)\n",
      "Epoch: [142][9/9]\tTime 0.080 (0.112)\tData 0.060 (0.090)\tLoss 0.0859 (0.6594)\tAcc 1.000 (0.738)\n",
      "train at epoch 143\n",
      "Epoch: [143][1/5]\tTime 0.275 (0.275)\tData 0.244 (0.244)\tLoss 0.6894 (0.6894)\tAcc 0.812 (0.812)\n",
      "Epoch: [143][2/5]\tTime 0.081 (0.178)\tData 0.056 (0.150)\tLoss 0.5956 (0.6425)\tAcc 0.812 (0.812)\n",
      "Epoch: [143][3/5]\tTime 0.086 (0.147)\tData 0.061 (0.121)\tLoss 0.5778 (0.6209)\tAcc 0.812 (0.812)\n",
      "Epoch: [143][4/5]\tTime 0.085 (0.132)\tData 0.061 (0.106)\tLoss 0.8126 (0.6689)\tAcc 0.688 (0.781)\n",
      "Epoch: [143][5/5]\tTime 0.083 (0.122)\tData 0.059 (0.096)\tLoss 1.0637 (0.7175)\tAcc 0.667 (0.767)\n",
      "validation at epoch 143\n",
      "Epoch: [143][1/9]\tTime 0.353 (0.353)\tData 0.328 (0.328)\tLoss 0.2690 (0.2690)\tAcc 0.938 (0.938)\n",
      "Epoch: [143][2/9]\tTime 0.077 (0.215)\tData 0.056 (0.192)\tLoss 0.9724 (0.6207)\tAcc 0.625 (0.781)\n",
      "Epoch: [143][3/9]\tTime 0.081 (0.171)\tData 0.058 (0.147)\tLoss 0.6935 (0.6450)\tAcc 0.750 (0.771)\n",
      "Epoch: [143][4/9]\tTime 0.080 (0.148)\tData 0.058 (0.125)\tLoss 0.6119 (0.6367)\tAcc 0.688 (0.750)\n",
      "Epoch: [143][5/9]\tTime 0.077 (0.134)\tData 0.057 (0.111)\tLoss 0.7733 (0.6640)\tAcc 0.625 (0.725)\n",
      "Epoch: [143][6/9]\tTime 0.080 (0.125)\tData 0.060 (0.103)\tLoss 0.1830 (0.5839)\tAcc 1.000 (0.771)\n",
      "Epoch: [143][7/9]\tTime 0.081 (0.119)\tData 0.061 (0.097)\tLoss 0.7118 (0.6021)\tAcc 0.750 (0.768)\n",
      "Epoch: [143][8/9]\tTime 0.081 (0.114)\tData 0.061 (0.092)\tLoss 1.0718 (0.6608)\tAcc 0.562 (0.742)\n",
      "Epoch: [143][9/9]\tTime 0.080 (0.110)\tData 0.061 (0.089)\tLoss 0.2728 (0.6549)\tAcc 1.000 (0.746)\n",
      "train at epoch 144\n",
      "Epoch: [144][1/5]\tTime 0.391 (0.391)\tData 0.363 (0.363)\tLoss 0.9234 (0.9234)\tAcc 0.625 (0.625)\n",
      "Epoch: [144][2/5]\tTime 0.084 (0.237)\tData 0.059 (0.211)\tLoss 0.6415 (0.7824)\tAcc 0.750 (0.688)\n",
      "Epoch: [144][3/5]\tTime 0.084 (0.186)\tData 0.060 (0.161)\tLoss 0.5935 (0.7194)\tAcc 0.812 (0.729)\n",
      "Epoch: [144][4/5]\tTime 0.079 (0.159)\tData 0.055 (0.134)\tLoss 0.7934 (0.7379)\tAcc 0.688 (0.719)\n",
      "Epoch: [144][5/5]\tTime 0.080 (0.144)\tData 0.057 (0.119)\tLoss 0.6739 (0.7300)\tAcc 0.667 (0.712)\n",
      "validation at epoch 144\n",
      "Epoch: [144][1/9]\tTime 0.286 (0.286)\tData 0.260 (0.260)\tLoss 0.3874 (0.3874)\tAcc 0.938 (0.938)\n",
      "Epoch: [144][2/9]\tTime 0.081 (0.184)\tData 0.059 (0.160)\tLoss 0.8917 (0.6395)\tAcc 0.562 (0.750)\n",
      "Epoch: [144][3/9]\tTime 0.081 (0.150)\tData 0.058 (0.126)\tLoss 0.6254 (0.6348)\tAcc 0.750 (0.750)\n",
      "Epoch: [144][4/9]\tTime 0.078 (0.132)\tData 0.057 (0.108)\tLoss 0.5466 (0.6128)\tAcc 0.750 (0.750)\n",
      "Epoch: [144][5/9]\tTime 0.079 (0.121)\tData 0.059 (0.099)\tLoss 0.8250 (0.6552)\tAcc 0.688 (0.738)\n",
      "Epoch: [144][6/9]\tTime 0.076 (0.114)\tData 0.056 (0.092)\tLoss 0.2674 (0.5906)\tAcc 1.000 (0.781)\n",
      "Epoch: [144][7/9]\tTime 0.075 (0.108)\tData 0.055 (0.086)\tLoss 0.6690 (0.6018)\tAcc 0.812 (0.786)\n",
      "Epoch: [144][8/9]\tTime 0.081 (0.105)\tData 0.060 (0.083)\tLoss 0.9798 (0.6490)\tAcc 0.500 (0.750)\n",
      "Epoch: [144][9/9]\tTime 0.081 (0.102)\tData 0.060 (0.081)\tLoss 0.0762 (0.6402)\tAcc 1.000 (0.754)\n",
      "train at epoch 145\n",
      "Epoch: [145][1/5]\tTime 0.352 (0.352)\tData 0.323 (0.323)\tLoss 0.5735 (0.5735)\tAcc 0.812 (0.812)\n",
      "Epoch: [145][2/5]\tTime 0.089 (0.220)\tData 0.063 (0.193)\tLoss 0.8001 (0.6868)\tAcc 0.688 (0.750)\n",
      "Epoch: [145][3/5]\tTime 0.084 (0.175)\tData 0.060 (0.149)\tLoss 0.6177 (0.6638)\tAcc 0.688 (0.729)\n",
      "Epoch: [145][4/5]\tTime 0.078 (0.151)\tData 0.055 (0.125)\tLoss 0.8145 (0.7015)\tAcc 0.625 (0.703)\n",
      "Epoch: [145][5/5]\tTime 0.079 (0.136)\tData 0.056 (0.111)\tLoss 0.5374 (0.6812)\tAcc 0.778 (0.712)\n",
      "validation at epoch 145\n",
      "Epoch: [145][1/9]\tTime 0.349 (0.349)\tData 0.320 (0.320)\tLoss 0.3511 (0.3511)\tAcc 0.938 (0.938)\n",
      "Epoch: [145][2/9]\tTime 0.074 (0.212)\tData 0.053 (0.186)\tLoss 1.0464 (0.6988)\tAcc 0.625 (0.781)\n",
      "Epoch: [145][3/9]\tTime 0.080 (0.168)\tData 0.059 (0.144)\tLoss 0.6244 (0.6740)\tAcc 0.750 (0.771)\n",
      "Epoch: [145][4/9]\tTime 0.079 (0.146)\tData 0.059 (0.123)\tLoss 0.8027 (0.7062)\tAcc 0.625 (0.734)\n",
      "Epoch: [145][5/9]\tTime 0.076 (0.132)\tData 0.056 (0.109)\tLoss 0.7397 (0.7129)\tAcc 0.688 (0.725)\n",
      "Epoch: [145][6/9]\tTime 0.074 (0.122)\tData 0.055 (0.100)\tLoss 0.2228 (0.6312)\tAcc 1.000 (0.771)\n",
      "Epoch: [145][7/9]\tTime 0.076 (0.116)\tData 0.056 (0.094)\tLoss 0.5966 (0.6263)\tAcc 0.750 (0.768)\n",
      "Epoch: [145][8/9]\tTime 0.079 (0.111)\tData 0.059 (0.090)\tLoss 0.9298 (0.6642)\tAcc 0.688 (0.758)\n",
      "Epoch: [145][9/9]\tTime 0.080 (0.108)\tData 0.060 (0.086)\tLoss 0.2702 (0.6581)\tAcc 1.000 (0.762)\n",
      "train at epoch 146\n",
      "Epoch: [146][1/5]\tTime 0.380 (0.380)\tData 0.353 (0.353)\tLoss 0.7105 (0.7105)\tAcc 0.750 (0.750)\n",
      "Epoch: [146][2/5]\tTime 0.080 (0.230)\tData 0.055 (0.204)\tLoss 0.7944 (0.7525)\tAcc 0.688 (0.719)\n",
      "Epoch: [146][3/5]\tTime 0.084 (0.182)\tData 0.060 (0.156)\tLoss 0.6525 (0.7191)\tAcc 0.688 (0.708)\n",
      "Epoch: [146][4/5]\tTime 0.086 (0.158)\tData 0.061 (0.132)\tLoss 0.5343 (0.6729)\tAcc 0.812 (0.734)\n",
      "Epoch: [146][5/5]\tTime 0.086 (0.143)\tData 0.062 (0.118)\tLoss 1.1121 (0.7271)\tAcc 0.556 (0.712)\n",
      "validation at epoch 146\n",
      "Epoch: [146][1/9]\tTime 0.291 (0.291)\tData 0.265 (0.265)\tLoss 0.3874 (0.3874)\tAcc 0.938 (0.938)\n",
      "Epoch: [146][2/9]\tTime 0.070 (0.181)\tData 0.049 (0.157)\tLoss 0.8158 (0.6016)\tAcc 0.750 (0.844)\n",
      "Epoch: [146][3/9]\tTime 0.080 (0.147)\tData 0.059 (0.124)\tLoss 0.6629 (0.6220)\tAcc 0.812 (0.833)\n",
      "Epoch: [146][4/9]\tTime 0.083 (0.131)\tData 0.058 (0.108)\tLoss 0.6432 (0.6273)\tAcc 0.750 (0.812)\n",
      "Epoch: [146][5/9]\tTime 0.077 (0.120)\tData 0.056 (0.097)\tLoss 0.7545 (0.6528)\tAcc 0.625 (0.775)\n",
      "Epoch: [146][6/9]\tTime 0.080 (0.114)\tData 0.060 (0.091)\tLoss 0.3326 (0.5994)\tAcc 1.000 (0.812)\n",
      "Epoch: [146][7/9]\tTime 0.074 (0.108)\tData 0.055 (0.086)\tLoss 0.6279 (0.6035)\tAcc 0.750 (0.804)\n",
      "Epoch: [146][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.082)\tLoss 1.0546 (0.6599)\tAcc 0.438 (0.758)\n",
      "Epoch: [146][9/9]\tTime 0.080 (0.101)\tData 0.060 (0.080)\tLoss 0.1803 (0.6525)\tAcc 1.000 (0.762)\n",
      "train at epoch 147\n",
      "Epoch: [147][1/5]\tTime 0.336 (0.336)\tData 0.306 (0.306)\tLoss 1.0141 (1.0141)\tAcc 0.438 (0.438)\n",
      "Epoch: [147][2/5]\tTime 0.073 (0.205)\tData 0.049 (0.177)\tLoss 0.6303 (0.8222)\tAcc 0.812 (0.625)\n",
      "Epoch: [147][3/5]\tTime 0.077 (0.162)\tData 0.053 (0.136)\tLoss 0.7824 (0.8090)\tAcc 0.750 (0.667)\n",
      "Epoch: [147][4/5]\tTime 0.077 (0.141)\tData 0.054 (0.115)\tLoss 0.7404 (0.7918)\tAcc 0.750 (0.688)\n",
      "Epoch: [147][5/5]\tTime 0.080 (0.129)\tData 0.057 (0.104)\tLoss 0.7819 (0.7906)\tAcc 0.667 (0.685)\n",
      "validation at epoch 147\n",
      "Epoch: [147][1/9]\tTime 0.320 (0.320)\tData 0.296 (0.296)\tLoss 0.3456 (0.3456)\tAcc 0.875 (0.875)\n",
      "Epoch: [147][2/9]\tTime 0.072 (0.196)\tData 0.051 (0.173)\tLoss 0.9355 (0.6406)\tAcc 0.688 (0.781)\n",
      "Epoch: [147][3/9]\tTime 0.074 (0.155)\tData 0.053 (0.133)\tLoss 0.6404 (0.6405)\tAcc 0.688 (0.750)\n",
      "Epoch: [147][4/9]\tTime 0.074 (0.135)\tData 0.053 (0.113)\tLoss 0.5596 (0.6203)\tAcc 0.812 (0.766)\n",
      "Epoch: [147][5/9]\tTime 0.074 (0.123)\tData 0.054 (0.101)\tLoss 0.8005 (0.6563)\tAcc 0.688 (0.750)\n",
      "Epoch: [147][6/9]\tTime 0.073 (0.114)\tData 0.054 (0.093)\tLoss 0.2153 (0.5828)\tAcc 1.000 (0.792)\n",
      "Epoch: [147][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.088)\tLoss 0.6497 (0.5924)\tAcc 0.750 (0.786)\n",
      "Epoch: [147][8/9]\tTime 0.075 (0.104)\tData 0.055 (0.084)\tLoss 0.9247 (0.6339)\tAcc 0.625 (0.766)\n",
      "Epoch: [147][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.080)\tLoss 0.0982 (0.6257)\tAcc 1.000 (0.769)\n",
      "train at epoch 148\n",
      "Epoch: [148][1/5]\tTime 0.279 (0.279)\tData 0.250 (0.250)\tLoss 0.6326 (0.6326)\tAcc 0.750 (0.750)\n",
      "Epoch: [148][2/5]\tTime 0.078 (0.179)\tData 0.050 (0.150)\tLoss 0.6265 (0.6295)\tAcc 0.812 (0.781)\n",
      "Epoch: [148][3/5]\tTime 0.075 (0.144)\tData 0.050 (0.117)\tLoss 0.6357 (0.6316)\tAcc 0.750 (0.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [148][4/5]\tTime 0.077 (0.127)\tData 0.053 (0.101)\tLoss 1.0107 (0.7264)\tAcc 0.625 (0.734)\n",
      "Epoch: [148][5/5]\tTime 0.081 (0.118)\tData 0.057 (0.092)\tLoss 0.9956 (0.7596)\tAcc 0.667 (0.726)\n",
      "validation at epoch 148\n",
      "Epoch: [148][1/9]\tTime 0.321 (0.321)\tData 0.295 (0.295)\tLoss 0.4034 (0.4034)\tAcc 0.875 (0.875)\n",
      "Epoch: [148][2/9]\tTime 0.070 (0.195)\tData 0.048 (0.172)\tLoss 0.9980 (0.7007)\tAcc 0.562 (0.719)\n",
      "Epoch: [148][3/9]\tTime 0.075 (0.155)\tData 0.052 (0.132)\tLoss 0.6394 (0.6802)\tAcc 0.750 (0.729)\n",
      "Epoch: [148][4/9]\tTime 0.073 (0.135)\tData 0.051 (0.112)\tLoss 0.6417 (0.6706)\tAcc 0.875 (0.766)\n",
      "Epoch: [148][5/9]\tTime 0.075 (0.123)\tData 0.052 (0.100)\tLoss 0.7845 (0.6934)\tAcc 0.625 (0.738)\n",
      "Epoch: [148][6/9]\tTime 0.070 (0.114)\tData 0.051 (0.092)\tLoss 0.2481 (0.6192)\tAcc 1.000 (0.781)\n",
      "Epoch: [148][7/9]\tTime 0.073 (0.108)\tData 0.054 (0.086)\tLoss 0.5005 (0.6022)\tAcc 0.938 (0.804)\n",
      "Epoch: [148][8/9]\tTime 0.075 (0.104)\tData 0.056 (0.083)\tLoss 1.0430 (0.6573)\tAcc 0.625 (0.781)\n",
      "Epoch: [148][9/9]\tTime 0.073 (0.101)\tData 0.055 (0.079)\tLoss 0.0955 (0.6487)\tAcc 1.000 (0.785)\n",
      "train at epoch 149\n",
      "Epoch: [149][1/5]\tTime 0.309 (0.309)\tData 0.282 (0.282)\tLoss 0.5590 (0.5590)\tAcc 0.875 (0.875)\n",
      "Epoch: [149][2/5]\tTime 0.075 (0.192)\tData 0.051 (0.166)\tLoss 0.9417 (0.7503)\tAcc 0.625 (0.750)\n",
      "Epoch: [149][3/5]\tTime 0.077 (0.154)\tData 0.054 (0.129)\tLoss 0.7139 (0.7382)\tAcc 0.750 (0.750)\n",
      "Epoch: [149][4/5]\tTime 0.078 (0.135)\tData 0.054 (0.110)\tLoss 0.7424 (0.7392)\tAcc 0.625 (0.719)\n",
      "Epoch: [149][5/5]\tTime 0.078 (0.124)\tData 0.055 (0.099)\tLoss 0.8965 (0.7586)\tAcc 0.556 (0.699)\n",
      "validation at epoch 149\n",
      "Epoch: [149][1/9]\tTime 0.338 (0.338)\tData 0.315 (0.315)\tLoss 0.2714 (0.2714)\tAcc 0.938 (0.938)\n",
      "Epoch: [149][2/9]\tTime 0.072 (0.205)\tData 0.051 (0.183)\tLoss 1.1607 (0.7160)\tAcc 0.500 (0.719)\n",
      "Epoch: [149][3/9]\tTime 0.074 (0.161)\tData 0.053 (0.140)\tLoss 0.7498 (0.7273)\tAcc 0.688 (0.708)\n",
      "Epoch: [149][4/9]\tTime 0.072 (0.139)\tData 0.053 (0.118)\tLoss 0.7206 (0.7256)\tAcc 0.625 (0.688)\n",
      "Epoch: [149][5/9]\tTime 0.074 (0.126)\tData 0.055 (0.105)\tLoss 0.8737 (0.7552)\tAcc 0.688 (0.688)\n",
      "Epoch: [149][6/9]\tTime 0.080 (0.118)\tData 0.062 (0.098)\tLoss 0.2630 (0.6732)\tAcc 1.000 (0.740)\n",
      "Epoch: [149][7/9]\tTime 0.073 (0.112)\tData 0.055 (0.092)\tLoss 0.6852 (0.6749)\tAcc 0.625 (0.723)\n",
      "Epoch: [149][8/9]\tTime 0.075 (0.107)\tData 0.057 (0.087)\tLoss 1.0309 (0.7194)\tAcc 0.562 (0.703)\n",
      "Epoch: [149][9/9]\tTime 0.073 (0.103)\tData 0.055 (0.084)\tLoss 0.1570 (0.7107)\tAcc 1.000 (0.708)\n",
      "train at epoch 150\n",
      "Epoch: [150][1/5]\tTime 0.343 (0.343)\tData 0.316 (0.316)\tLoss 0.7094 (0.7094)\tAcc 0.750 (0.750)\n",
      "Epoch: [150][2/5]\tTime 0.075 (0.209)\tData 0.051 (0.184)\tLoss 0.7208 (0.7151)\tAcc 0.625 (0.688)\n",
      "Epoch: [150][3/5]\tTime 0.077 (0.165)\tData 0.053 (0.140)\tLoss 0.5894 (0.6732)\tAcc 0.875 (0.750)\n",
      "Epoch: [150][4/5]\tTime 0.077 (0.143)\tData 0.054 (0.119)\tLoss 0.8491 (0.7172)\tAcc 0.625 (0.719)\n",
      "Epoch: [150][5/5]\tTime 0.078 (0.130)\tData 0.055 (0.106)\tLoss 0.7675 (0.7234)\tAcc 0.667 (0.712)\n",
      "validation at epoch 150\n",
      "Epoch: [150][1/9]\tTime 0.372 (0.372)\tData 0.339 (0.339)\tLoss 0.3121 (0.3121)\tAcc 0.875 (0.875)\n",
      "Epoch: [150][2/9]\tTime 0.075 (0.224)\tData 0.048 (0.194)\tLoss 0.8659 (0.5890)\tAcc 0.812 (0.844)\n",
      "Epoch: [150][3/9]\tTime 0.074 (0.174)\tData 0.052 (0.147)\tLoss 0.7136 (0.6305)\tAcc 0.688 (0.792)\n",
      "Epoch: [150][4/9]\tTime 0.079 (0.150)\tData 0.058 (0.124)\tLoss 0.7804 (0.6680)\tAcc 0.688 (0.766)\n",
      "Epoch: [150][5/9]\tTime 0.080 (0.136)\tData 0.060 (0.112)\tLoss 0.8297 (0.7004)\tAcc 0.688 (0.750)\n",
      "Epoch: [150][6/9]\tTime 0.077 (0.126)\tData 0.057 (0.103)\tLoss 0.2964 (0.6330)\tAcc 1.000 (0.792)\n",
      "Epoch: [150][7/9]\tTime 0.079 (0.119)\tData 0.059 (0.096)\tLoss 0.7459 (0.6492)\tAcc 0.688 (0.777)\n",
      "Epoch: [150][8/9]\tTime 0.080 (0.114)\tData 0.060 (0.092)\tLoss 1.0280 (0.6965)\tAcc 0.562 (0.750)\n",
      "Epoch: [150][9/9]\tTime 0.080 (0.111)\tData 0.061 (0.088)\tLoss 0.1711 (0.6884)\tAcc 1.000 (0.754)\n"
     ]
    }
   ],
   "source": [
    "begin_epoch=1\n",
    "n_epoch=150\n",
    "from train2 import train_epoch\n",
    "from validation import val_epoch\n",
    "\n",
    "for i in range(begin_epoch, n_epoch + 1):\n",
    "    train_epoch(i, train_loader, my_model, criterion, optimizer, opt,\n",
    "                    train_logger, train_batch_logger)\n",
    "    validation_loss = val_epoch(i, val_loader, my_model, criterion, opt,\n",
    "                                    val_logger)\n",
    "    scheduler.step(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:33.962629Z",
     "start_time": "2020-04-03T01:59:33.942638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/26]\n"
     ]
    }
   ],
   "source": [
    "v_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/val') # can also put the test data here, have included validation b.c. it has labels for comp.\n",
    "a_path = Path('/media/tris/tris_files/github/csce_courses/project_clean/videos/jpg_door/labels.json')\n",
    "import test\n",
    "class Args:\n",
    "    dataset = 'kinetics'\n",
    "    test_subset='val'\n",
    "    video_path = v_path\n",
    "    annotation_path = a_path\n",
    "    sample_duration=4\n",
    "    \n",
    "test_set_args=Args()\n",
    "\n",
    "test_data = get_test_set(test_set_args, spatial_transform, temporal_transform,\n",
    "                                 target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:33.972212Z",
     "start_time": "2020-04-03T01:59:33.963663Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:39.870452Z",
     "start_time": "2020-04-03T01:59:33.973518Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Accuracy of the network on the test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_final=[]\n",
    "label_final=[]\n",
    "video_results=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        labels=labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "#         print(torch.max(outputs, 1))\n",
    "#         print(outputs)\n",
    "        conf, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        predicted=predicted.cuda()\n",
    "        print(max(labels), max(predicted)) #for validation\n",
    "#         print(pred_final) #for test (unlabeled)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "        predicted=predicted.cpu()\n",
    "        pred_final.append(max(predicted.data.numpy()))\n",
    "        labels=labels.cpu()\n",
    "        conf=conf.cpu()\n",
    "        label_final.append(max(labels.data.numpy()))\n",
    "        json_label=max(predicted.data.numpy())\n",
    "        json_label=json_label.tolist()\n",
    "        json_conf=max(conf.data.numpy())\n",
    "        json_conf=json_conf.tolist()\n",
    "        for i in range(3):\n",
    "            video_results.append({'label': test_data.class_names[json_label], 'score': json_conf})\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# I think there's a better way to print results, look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:39.900377Z",
     "start_time": "2020-04-03T01:59:39.871694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'none', 'score': 2.2729620933532715},\n",
       " {'label': 'none', 'score': 2.2729620933532715},\n",
       " {'label': 'none', 'score': 2.2729620933532715},\n",
       " {'label': 'none', 'score': 1.9002113342285156},\n",
       " {'label': 'none', 'score': 1.9002113342285156},\n",
       " {'label': 'none', 'score': 1.9002113342285156},\n",
       " {'label': 'none', 'score': 2.189619779586792},\n",
       " {'label': 'none', 'score': 2.189619779586792},\n",
       " {'label': 'none', 'score': 2.189619779586792},\n",
       " {'label': 'none', 'score': 2.514200448989868},\n",
       " {'label': 'none', 'score': 2.514200448989868},\n",
       " {'label': 'none', 'score': 2.514200448989868},\n",
       " {'label': 'none', 'score': 1.8418633937835693},\n",
       " {'label': 'none', 'score': 1.8418633937835693},\n",
       " {'label': 'none', 'score': 1.8418633937835693},\n",
       " {'label': 'none', 'score': 2.2441630363464355},\n",
       " {'label': 'none', 'score': 2.2441630363464355},\n",
       " {'label': 'none', 'score': 2.2441630363464355},\n",
       " {'label': 'none', 'score': 2.0357606410980225},\n",
       " {'label': 'none', 'score': 2.0357606410980225},\n",
       " {'label': 'none', 'score': 2.0357606410980225},\n",
       " {'label': 'none', 'score': 1.7405916452407837},\n",
       " {'label': 'none', 'score': 1.7405916452407837},\n",
       " {'label': 'none', 'score': 1.7405916452407837},\n",
       " {'label': 'none', 'score': 2.0362465381622314},\n",
       " {'label': 'none', 'score': 2.0362465381622314},\n",
       " {'label': 'none', 'score': 2.0362465381622314},\n",
       " {'label': 'none', 'score': 1.9330905675888062},\n",
       " {'label': 'none', 'score': 1.9330905675888062},\n",
       " {'label': 'none', 'score': 1.9330905675888062},\n",
       " {'label': 'none', 'score': 1.7367421388626099},\n",
       " {'label': 'none', 'score': 1.7367421388626099},\n",
       " {'label': 'none', 'score': 1.7367421388626099},\n",
       " {'label': 'none', 'score': 1.861293077468872},\n",
       " {'label': 'none', 'score': 1.861293077468872},\n",
       " {'label': 'none', 'score': 1.861293077468872},\n",
       " {'label': 'none', 'score': 1.9215041399002075},\n",
       " {'label': 'none', 'score': 1.9215041399002075},\n",
       " {'label': 'none', 'score': 1.9215041399002075},\n",
       " {'label': 'none', 'score': 2.2819745540618896},\n",
       " {'label': 'none', 'score': 2.2819745540618896},\n",
       " {'label': 'none', 'score': 2.2819745540618896},\n",
       " {'label': 'none', 'score': 1.9380042552947998},\n",
       " {'label': 'none', 'score': 1.9380042552947998},\n",
       " {'label': 'none', 'score': 1.9380042552947998},\n",
       " {'label': 'none', 'score': 2.2757108211517334},\n",
       " {'label': 'none', 'score': 2.2757108211517334},\n",
       " {'label': 'none', 'score': 2.2757108211517334},\n",
       " {'label': 'none', 'score': 2.3531365394592285},\n",
       " {'label': 'none', 'score': 2.3531365394592285},\n",
       " {'label': 'none', 'score': 2.3531365394592285},\n",
       " {'label': 'none', 'score': 1.8885403871536255},\n",
       " {'label': 'none', 'score': 1.8885403871536255},\n",
       " {'label': 'none', 'score': 1.8885403871536255},\n",
       " {'label': 'none', 'score': 2.186414957046509},\n",
       " {'label': 'none', 'score': 2.186414957046509},\n",
       " {'label': 'none', 'score': 2.186414957046509},\n",
       " {'label': 'none', 'score': 1.7624225616455078},\n",
       " {'label': 'none', 'score': 1.7624225616455078},\n",
       " {'label': 'none', 'score': 1.7624225616455078},\n",
       " {'label': 'none', 'score': 2.0147433280944824},\n",
       " {'label': 'none', 'score': 2.0147433280944824},\n",
       " {'label': 'none', 'score': 2.0147433280944824},\n",
       " {'label': 'none', 'score': 1.8206039667129517},\n",
       " {'label': 'none', 'score': 1.8206039667129517},\n",
       " {'label': 'none', 'score': 1.8206039667129517},\n",
       " {'label': 'returning', 'score': 1.1336400508880615},\n",
       " {'label': 'returning', 'score': 1.1336400508880615},\n",
       " {'label': 'returning', 'score': 1.1336400508880615},\n",
       " {'label': 'returning', 'score': 1.2190229892730713},\n",
       " {'label': 'returning', 'score': 1.2190229892730713},\n",
       " {'label': 'returning', 'score': 1.2190229892730713},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.3831334710121155},\n",
       " {'label': 'returning', 'score': 0.3831334710121155},\n",
       " {'label': 'returning', 'score': 0.3831334710121155},\n",
       " {'label': 'returning', 'score': 0.27353477478027344},\n",
       " {'label': 'returning', 'score': 0.27353477478027344},\n",
       " {'label': 'returning', 'score': 0.27353477478027344},\n",
       " {'label': 'returning', 'score': 0.25817805528640747},\n",
       " {'label': 'returning', 'score': 0.25817805528640747},\n",
       " {'label': 'returning', 'score': 0.25817805528640747},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.7141220569610596},\n",
       " {'label': 'returning', 'score': 0.7141220569610596},\n",
       " {'label': 'returning', 'score': 0.7141220569610596},\n",
       " {'label': 'none', 'score': 1.7416419982910156},\n",
       " {'label': 'none', 'score': 1.7416419982910156},\n",
       " {'label': 'none', 'score': 1.7416419982910156},\n",
       " {'label': 'none', 'score': 1.5123016834259033},\n",
       " {'label': 'none', 'score': 1.5123016834259033},\n",
       " {'label': 'none', 'score': 1.5123016834259033},\n",
       " {'label': 'none', 'score': 1.9958075284957886},\n",
       " {'label': 'none', 'score': 1.9958075284957886},\n",
       " {'label': 'none', 'score': 1.9958075284957886},\n",
       " {'label': 'none', 'score': 1.9693231582641602},\n",
       " {'label': 'none', 'score': 1.9693231582641602},\n",
       " {'label': 'none', 'score': 1.9693231582641602},\n",
       " {'label': 'none', 'score': 2.1160433292388916},\n",
       " {'label': 'none', 'score': 2.1160433292388916},\n",
       " {'label': 'none', 'score': 2.1160433292388916},\n",
       " {'label': 'none', 'score': 2.115626573562622},\n",
       " {'label': 'none', 'score': 2.115626573562622},\n",
       " {'label': 'none', 'score': 2.115626573562622},\n",
       " {'label': 'none', 'score': 1.7040737867355347},\n",
       " {'label': 'none', 'score': 1.7040737867355347},\n",
       " {'label': 'none', 'score': 1.7040737867355347},\n",
       " {'label': 'none', 'score': 1.9344048500061035},\n",
       " {'label': 'none', 'score': 1.9344048500061035},\n",
       " {'label': 'none', 'score': 1.9344048500061035},\n",
       " {'label': 'none', 'score': 2.2489373683929443},\n",
       " {'label': 'none', 'score': 2.2489373683929443},\n",
       " {'label': 'none', 'score': 2.2489373683929443},\n",
       " {'label': 'none', 'score': 2.55006742477417},\n",
       " {'label': 'none', 'score': 2.55006742477417},\n",
       " {'label': 'none', 'score': 2.55006742477417},\n",
       " {'label': 'none', 'score': 2.233410120010376},\n",
       " {'label': 'none', 'score': 2.233410120010376},\n",
       " {'label': 'none', 'score': 2.233410120010376},\n",
       " {'label': 'none', 'score': 2.3851253986358643},\n",
       " {'label': 'none', 'score': 2.3851253986358643},\n",
       " {'label': 'none', 'score': 2.3851253986358643},\n",
       " {'label': 'none', 'score': 2.2717807292938232},\n",
       " {'label': 'none', 'score': 2.2717807292938232},\n",
       " {'label': 'none', 'score': 2.2717807292938232},\n",
       " {'label': 'none', 'score': 1.9744727611541748},\n",
       " {'label': 'none', 'score': 1.9744727611541748},\n",
       " {'label': 'none', 'score': 1.9744727611541748},\n",
       " {'label': 'none', 'score': 1.446955919265747},\n",
       " {'label': 'none', 'score': 1.446955919265747},\n",
       " {'label': 'none', 'score': 1.446955919265747},\n",
       " {'label': 'none', 'score': 1.9419320821762085},\n",
       " {'label': 'none', 'score': 1.9419320821762085},\n",
       " {'label': 'none', 'score': 1.9419320821762085},\n",
       " {'label': 'none', 'score': 2.6217164993286133},\n",
       " {'label': 'none', 'score': 2.6217164993286133},\n",
       " {'label': 'none', 'score': 2.6217164993286133},\n",
       " {'label': 'none', 'score': 1.688017725944519},\n",
       " {'label': 'none', 'score': 1.688017725944519},\n",
       " {'label': 'none', 'score': 1.688017725944519},\n",
       " {'label': 'none', 'score': 0.7410182952880859},\n",
       " {'label': 'none', 'score': 0.7410182952880859},\n",
       " {'label': 'none', 'score': 0.7410182952880859},\n",
       " {'label': 'returning', 'score': 0.5163020491600037},\n",
       " {'label': 'returning', 'score': 0.5163020491600037},\n",
       " {'label': 'returning', 'score': 0.5163020491600037},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.39111632108688354},\n",
       " {'label': 'returning', 'score': 0.39111632108688354},\n",
       " {'label': 'returning', 'score': 0.39111632108688354},\n",
       " {'label': 'returning', 'score': 0.33371502161026},\n",
       " {'label': 'returning', 'score': 0.33371502161026},\n",
       " {'label': 'returning', 'score': 0.33371502161026},\n",
       " {'label': 'leaving', 'score': 0.3024899959564209},\n",
       " {'label': 'leaving', 'score': 0.3024899959564209},\n",
       " {'label': 'leaving', 'score': 0.3024899959564209},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 1.1466511487960815},\n",
       " {'label': 'none', 'score': 1.1466511487960815},\n",
       " {'label': 'none', 'score': 1.1466511487960815},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 1.3547813892364502},\n",
       " {'label': 'returning', 'score': 1.3547813892364502},\n",
       " {'label': 'returning', 'score': 1.3547813892364502},\n",
       " {'label': 'none', 'score': 1.2059820890426636},\n",
       " {'label': 'none', 'score': 1.2059820890426636},\n",
       " {'label': 'none', 'score': 1.2059820890426636},\n",
       " {'label': 'none', 'score': 2.1768829822540283},\n",
       " {'label': 'none', 'score': 2.1768829822540283},\n",
       " {'label': 'none', 'score': 2.1768829822540283},\n",
       " {'label': 'none', 'score': 1.9930977821350098},\n",
       " {'label': 'none', 'score': 1.9930977821350098},\n",
       " {'label': 'none', 'score': 1.9930977821350098},\n",
       " {'label': 'none', 'score': 2.1280040740966797},\n",
       " {'label': 'none', 'score': 2.1280040740966797},\n",
       " {'label': 'none', 'score': 2.1280040740966797},\n",
       " {'label': 'none', 'score': 1.635337233543396},\n",
       " {'label': 'none', 'score': 1.635337233543396},\n",
       " {'label': 'none', 'score': 1.635337233543396},\n",
       " {'label': 'none', 'score': 1.7680338621139526},\n",
       " {'label': 'none', 'score': 1.7680338621139526},\n",
       " {'label': 'none', 'score': 1.7680338621139526},\n",
       " {'label': 'none', 'score': 2.1218841075897217},\n",
       " {'label': 'none', 'score': 2.1218841075897217},\n",
       " {'label': 'none', 'score': 2.1218841075897217},\n",
       " {'label': 'none', 'score': 1.7936781644821167},\n",
       " {'label': 'none', 'score': 1.7936781644821167},\n",
       " {'label': 'none', 'score': 1.7936781644821167},\n",
       " {'label': 'none', 'score': 1.7061058282852173},\n",
       " {'label': 'none', 'score': 1.7061058282852173},\n",
       " {'label': 'none', 'score': 1.7061058282852173},\n",
       " {'label': 'none', 'score': 1.4774116277694702},\n",
       " {'label': 'none', 'score': 1.4774116277694702},\n",
       " {'label': 'none', 'score': 1.4774116277694702},\n",
       " {'label': 'none', 'score': 1.8150269985198975},\n",
       " {'label': 'none', 'score': 1.8150269985198975},\n",
       " {'label': 'none', 'score': 1.8150269985198975},\n",
       " {'label': 'none', 'score': 1.9367632865905762},\n",
       " {'label': 'none', 'score': 1.9367632865905762},\n",
       " {'label': 'none', 'score': 1.9367632865905762},\n",
       " {'label': 'none', 'score': 2.04516339302063},\n",
       " {'label': 'none', 'score': 2.04516339302063},\n",
       " {'label': 'none', 'score': 2.04516339302063},\n",
       " {'label': 'none', 'score': 1.832176923751831},\n",
       " {'label': 'none', 'score': 1.832176923751831},\n",
       " {'label': 'none', 'score': 1.832176923751831},\n",
       " {'label': 'none', 'score': 1.9737900495529175},\n",
       " {'label': 'none', 'score': 1.9737900495529175},\n",
       " {'label': 'none', 'score': 1.9737900495529175},\n",
       " {'label': 'none', 'score': 1.8853881359100342},\n",
       " {'label': 'none', 'score': 1.8853881359100342},\n",
       " {'label': 'none', 'score': 1.8853881359100342},\n",
       " {'label': 'none', 'score': 2.3481862545013428},\n",
       " {'label': 'none', 'score': 2.3481862545013428},\n",
       " {'label': 'none', 'score': 2.3481862545013428},\n",
       " {'label': 'none', 'score': 2.3040404319763184},\n",
       " {'label': 'none', 'score': 2.3040404319763184},\n",
       " {'label': 'none', 'score': 2.3040404319763184},\n",
       " {'label': 'none', 'score': 1.726838231086731},\n",
       " {'label': 'none', 'score': 1.726838231086731},\n",
       " {'label': 'none', 'score': 1.726838231086731},\n",
       " {'label': 'none', 'score': 1.5515869855880737},\n",
       " {'label': 'none', 'score': 1.5515869855880737},\n",
       " {'label': 'none', 'score': 1.5515869855880737},\n",
       " {'label': 'none', 'score': 1.0463612079620361},\n",
       " {'label': 'none', 'score': 1.0463612079620361},\n",
       " {'label': 'none', 'score': 1.0463612079620361},\n",
       " {'label': 'returning', 'score': 0.7390362620353699},\n",
       " {'label': 'returning', 'score': 0.7390362620353699},\n",
       " {'label': 'returning', 'score': 0.7390362620353699},\n",
       " {'label': 'leaving', 'score': 0.3461453914642334},\n",
       " {'label': 'leaving', 'score': 0.3461453914642334},\n",
       " {'label': 'leaving', 'score': 0.3461453914642334},\n",
       " {'label': 'leaving', 'score': 0.9316094517707825},\n",
       " {'label': 'leaving', 'score': 0.9316094517707825},\n",
       " {'label': 'leaving', 'score': 0.9316094517707825},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.36871302127838135},\n",
       " {'label': 'returning', 'score': 0.36871302127838135},\n",
       " {'label': 'returning', 'score': 0.36871302127838135},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 1.9306391477584839},\n",
       " {'label': 'none', 'score': 1.9306391477584839},\n",
       " {'label': 'none', 'score': 1.9306391477584839},\n",
       " {'label': 'none', 'score': 2.2087225914001465},\n",
       " {'label': 'none', 'score': 2.2087225914001465},\n",
       " {'label': 'none', 'score': 2.2087225914001465},\n",
       " {'label': 'none', 'score': 2.346956253051758},\n",
       " {'label': 'none', 'score': 2.346956253051758},\n",
       " {'label': 'none', 'score': 2.346956253051758},\n",
       " {'label': 'none', 'score': 1.6239818334579468},\n",
       " {'label': 'none', 'score': 1.6239818334579468},\n",
       " {'label': 'none', 'score': 1.6239818334579468},\n",
       " {'label': 'none', 'score': 1.8467141389846802},\n",
       " {'label': 'none', 'score': 1.8467141389846802},\n",
       " {'label': 'none', 'score': 1.8467141389846802},\n",
       " {'label': 'none', 'score': 1.8898464441299438},\n",
       " {'label': 'none', 'score': 1.8898464441299438},\n",
       " {'label': 'none', 'score': 1.8898464441299438},\n",
       " {'label': 'none', 'score': 2.0602078437805176},\n",
       " {'label': 'none', 'score': 2.0602078437805176},\n",
       " {'label': 'none', 'score': 2.0602078437805176},\n",
       " {'label': 'none', 'score': 2.2648720741271973},\n",
       " {'label': 'none', 'score': 2.2648720741271973},\n",
       " {'label': 'none', 'score': 2.2648720741271973},\n",
       " {'label': 'none', 'score': 1.6948386430740356},\n",
       " {'label': 'none', 'score': 1.6948386430740356},\n",
       " {'label': 'none', 'score': 1.6948386430740356},\n",
       " {'label': 'none', 'score': 2.0946362018585205},\n",
       " {'label': 'none', 'score': 2.0946362018585205},\n",
       " {'label': 'none', 'score': 2.0946362018585205},\n",
       " {'label': 'none', 'score': 2.0283124446868896},\n",
       " {'label': 'none', 'score': 2.0283124446868896},\n",
       " {'label': 'none', 'score': 2.0283124446868896},\n",
       " {'label': 'none', 'score': 2.168553590774536},\n",
       " {'label': 'none', 'score': 2.168553590774536},\n",
       " {'label': 'none', 'score': 2.168553590774536},\n",
       " {'label': 'none', 'score': 1.482796311378479},\n",
       " {'label': 'none', 'score': 1.482796311378479},\n",
       " {'label': 'none', 'score': 1.482796311378479},\n",
       " {'label': 'none', 'score': 1.6599904298782349},\n",
       " {'label': 'none', 'score': 1.6599904298782349},\n",
       " {'label': 'none', 'score': 1.6599904298782349},\n",
       " {'label': 'none', 'score': 1.9725266695022583},\n",
       " {'label': 'none', 'score': 1.9725266695022583},\n",
       " {'label': 'none', 'score': 1.9725266695022583},\n",
       " {'label': 'none', 'score': 1.7718329429626465},\n",
       " {'label': 'none', 'score': 1.7718329429626465},\n",
       " {'label': 'none', 'score': 1.7718329429626465},\n",
       " {'label': 'none', 'score': 2.2855801582336426},\n",
       " {'label': 'none', 'score': 2.2855801582336426},\n",
       " {'label': 'none', 'score': 2.2855801582336426},\n",
       " {'label': 'none', 'score': 2.888319253921509},\n",
       " {'label': 'none', 'score': 2.888319253921509},\n",
       " {'label': 'none', 'score': 2.888319253921509},\n",
       " {'label': 'none', 'score': 1.2193269729614258},\n",
       " {'label': 'none', 'score': 1.2193269729614258},\n",
       " {'label': 'none', 'score': 1.2193269729614258},\n",
       " {'label': 'returning', 'score': 0.5843040943145752},\n",
       " {'label': 'returning', 'score': 0.5843040943145752},\n",
       " {'label': 'returning', 'score': 0.5843040943145752},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.24283964931964874},\n",
       " {'label': 'returning', 'score': 0.24283964931964874},\n",
       " {'label': 'returning', 'score': 0.24283964931964874},\n",
       " {'label': 'returning', 'score': 1.7980353832244873},\n",
       " {'label': 'returning', 'score': 1.7980353832244873},\n",
       " {'label': 'returning', 'score': 1.7980353832244873},\n",
       " {'label': 'leaving', 'score': 2.0519258975982666},\n",
       " {'label': 'leaving', 'score': 2.0519258975982666},\n",
       " {'label': 'leaving', 'score': 2.0519258975982666},\n",
       " {'label': 'none', 'score': 1.7704170942306519},\n",
       " {'label': 'none', 'score': 1.7704170942306519},\n",
       " {'label': 'none', 'score': 1.7704170942306519},\n",
       " {'label': 'none', 'score': 2.293412208557129},\n",
       " {'label': 'none', 'score': 2.293412208557129},\n",
       " {'label': 'none', 'score': 2.293412208557129},\n",
       " {'label': 'none', 'score': 2.3437602519989014},\n",
       " {'label': 'none', 'score': 2.3437602519989014},\n",
       " {'label': 'none', 'score': 2.3437602519989014},\n",
       " {'label': 'none', 'score': 1.5026545524597168},\n",
       " {'label': 'none', 'score': 1.5026545524597168},\n",
       " {'label': 'none', 'score': 1.5026545524597168},\n",
       " {'label': 'none', 'score': 1.6859267950057983},\n",
       " {'label': 'none', 'score': 1.6859267950057983},\n",
       " {'label': 'none', 'score': 1.6859267950057983},\n",
       " {'label': 'none', 'score': 1.8992562294006348},\n",
       " {'label': 'none', 'score': 1.8992562294006348},\n",
       " {'label': 'none', 'score': 1.8992562294006348},\n",
       " {'label': 'none', 'score': 1.4559286832809448},\n",
       " {'label': 'none', 'score': 1.4559286832809448},\n",
       " {'label': 'none', 'score': 1.4559286832809448},\n",
       " {'label': 'none', 'score': 1.880169153213501},\n",
       " {'label': 'none', 'score': 1.880169153213501},\n",
       " {'label': 'none', 'score': 1.880169153213501},\n",
       " {'label': 'none', 'score': 2.0388076305389404},\n",
       " {'label': 'none', 'score': 2.0388076305389404},\n",
       " {'label': 'none', 'score': 2.0388076305389404},\n",
       " {'label': 'none', 'score': 2.0804245471954346},\n",
       " {'label': 'none', 'score': 2.0804245471954346},\n",
       " {'label': 'none', 'score': 2.0804245471954346},\n",
       " {'label': 'none', 'score': 1.841972827911377},\n",
       " {'label': 'none', 'score': 1.841972827911377},\n",
       " {'label': 'none', 'score': 1.841972827911377},\n",
       " {'label': 'none', 'score': 1.978188395500183},\n",
       " {'label': 'none', 'score': 1.978188395500183},\n",
       " {'label': 'none', 'score': 1.978188395500183},\n",
       " {'label': 'none', 'score': 2.372098207473755},\n",
       " {'label': 'none', 'score': 2.372098207473755},\n",
       " {'label': 'none', 'score': 2.372098207473755},\n",
       " {'label': 'none', 'score': 1.454261064529419},\n",
       " {'label': 'none', 'score': 1.454261064529419},\n",
       " {'label': 'none', 'score': 1.454261064529419},\n",
       " {'label': 'none', 'score': 2.03580641746521},\n",
       " {'label': 'none', 'score': 2.03580641746521},\n",
       " {'label': 'none', 'score': 2.03580641746521},\n",
       " {'label': 'none', 'score': 2.300832509994507},\n",
       " {'label': 'none', 'score': 2.300832509994507},\n",
       " {'label': 'none', 'score': 2.300832509994507},\n",
       " {'label': 'none', 'score': 1.9955947399139404},\n",
       " {'label': 'none', 'score': 1.9955947399139404},\n",
       " {'label': 'none', 'score': 1.9955947399139404},\n",
       " {'label': 'none', 'score': 2.221238613128662},\n",
       " {'label': 'none', 'score': 2.221238613128662},\n",
       " {'label': 'none', 'score': 2.221238613128662},\n",
       " {'label': 'none', 'score': 0.8966137170791626},\n",
       " {'label': 'none', 'score': 0.8966137170791626},\n",
       " {'label': 'none', 'score': 0.8966137170791626},\n",
       " {'label': 'none', 'score': 1.4953299760818481},\n",
       " {'label': 'none', 'score': 1.4953299760818481},\n",
       " {'label': 'none', 'score': 1.4953299760818481},\n",
       " {'label': 'none', 'score': 1.9048781394958496},\n",
       " {'label': 'none', 'score': 1.9048781394958496},\n",
       " {'label': 'none', 'score': 1.9048781394958496},\n",
       " {'label': 'none', 'score': 1.939422607421875},\n",
       " {'label': 'none', 'score': 1.939422607421875},\n",
       " {'label': 'none', 'score': 1.939422607421875},\n",
       " {'label': 'none', 'score': 1.774628758430481},\n",
       " {'label': 'none', 'score': 1.774628758430481},\n",
       " {'label': 'none', 'score': 1.774628758430481},\n",
       " {'label': 'none', 'score': 1.9838260412216187},\n",
       " {'label': 'none', 'score': 1.9838260412216187},\n",
       " {'label': 'none', 'score': 1.9838260412216187},\n",
       " {'label': 'none', 'score': 1.688411831855774},\n",
       " {'label': 'none', 'score': 1.688411831855774},\n",
       " {'label': 'none', 'score': 1.688411831855774},\n",
       " {'label': 'none', 'score': 1.7595744132995605},\n",
       " {'label': 'none', 'score': 1.7595744132995605},\n",
       " {'label': 'none', 'score': 1.7595744132995605},\n",
       " {'label': 'none', 'score': 1.9282164573669434},\n",
       " {'label': 'none', 'score': 1.9282164573669434},\n",
       " {'label': 'none', 'score': 1.9282164573669434},\n",
       " {'label': 'none', 'score': 1.7153570652008057},\n",
       " {'label': 'none', 'score': 1.7153570652008057},\n",
       " {'label': 'none', 'score': 1.7153570652008057},\n",
       " {'label': 'returning', 'score': 1.3797024488449097},\n",
       " {'label': 'returning', 'score': 1.3797024488449097},\n",
       " {'label': 'returning', 'score': 1.3797024488449097},\n",
       " {'label': 'none', 'score': 1.1464859247207642},\n",
       " {'label': 'none', 'score': 1.1464859247207642},\n",
       " {'label': 'none', 'score': 1.1464859247207642},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.4708597660064697},\n",
       " {'label': 'leaving', 'score': 0.4708597660064697},\n",
       " {'label': 'leaving', 'score': 0.4708597660064697},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 1.6919026374816895},\n",
       " {'label': 'none', 'score': 1.6919026374816895},\n",
       " {'label': 'none', 'score': 1.6919026374816895},\n",
       " {'label': 'none', 'score': 1.7742588520050049},\n",
       " {'label': 'none', 'score': 1.7742588520050049},\n",
       " {'label': 'none', 'score': 1.7742588520050049},\n",
       " {'label': 'none', 'score': 2.156432628631592},\n",
       " {'label': 'none', 'score': 2.156432628631592},\n",
       " {'label': 'none', 'score': 2.156432628631592},\n",
       " {'label': 'none', 'score': 1.7876731157302856},\n",
       " {'label': 'none', 'score': 1.7876731157302856},\n",
       " {'label': 'none', 'score': 1.7876731157302856},\n",
       " {'label': 'none', 'score': 2.1079328060150146},\n",
       " {'label': 'none', 'score': 2.1079328060150146},\n",
       " {'label': 'none', 'score': 2.1079328060150146},\n",
       " {'label': 'none', 'score': 1.8721873760223389},\n",
       " {'label': 'none', 'score': 1.8721873760223389},\n",
       " {'label': 'none', 'score': 1.8721873760223389},\n",
       " {'label': 'none', 'score': 2.226837158203125},\n",
       " {'label': 'none', 'score': 2.226837158203125},\n",
       " {'label': 'none', 'score': 2.226837158203125},\n",
       " {'label': 'none', 'score': 1.5641124248504639},\n",
       " {'label': 'none', 'score': 1.5641124248504639},\n",
       " {'label': 'none', 'score': 1.5641124248504639},\n",
       " {'label': 'none', 'score': 1.6656321287155151},\n",
       " {'label': 'none', 'score': 1.6656321287155151},\n",
       " {'label': 'none', 'score': 1.6656321287155151},\n",
       " {'label': 'none', 'score': 2.1243820190429688},\n",
       " {'label': 'none', 'score': 2.1243820190429688},\n",
       " {'label': 'none', 'score': 2.1243820190429688},\n",
       " {'label': 'none', 'score': 1.7250632047653198},\n",
       " {'label': 'none', 'score': 1.7250632047653198},\n",
       " {'label': 'none', 'score': 1.7250632047653198},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'none', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.3210528492927551},\n",
       " {'label': 'returning', 'score': 0.3210528492927551},\n",
       " {'label': 'returning', 'score': 0.3210528492927551},\n",
       " {'label': 'leaving', 'score': 0.3812737464904785},\n",
       " {'label': 'leaving', 'score': 0.3812737464904785},\n",
       " {'label': 'leaving', 'score': 0.3812737464904785},\n",
       " {'label': 'returning', 'score': 0.24205325543880463},\n",
       " {'label': 'returning', 'score': 0.24205325543880463},\n",
       " {'label': 'returning', 'score': 0.24205325543880463},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.45611459016799927},\n",
       " {'label': 'returning', 'score': 0.45611459016799927},\n",
       " {'label': 'returning', 'score': 0.45611459016799927},\n",
       " {'label': 'returning', 'score': 0.8651623129844666},\n",
       " {'label': 'returning', 'score': 0.8651623129844666},\n",
       " {'label': 'returning', 'score': 0.8651623129844666},\n",
       " {'label': 'returning', 'score': 1.3745802640914917},\n",
       " {'label': 'returning', 'score': 1.3745802640914917},\n",
       " {'label': 'returning', 'score': 1.3745802640914917},\n",
       " {'label': 'none', 'score': 1.6631351709365845},\n",
       " {'label': 'none', 'score': 1.6631351709365845},\n",
       " {'label': 'none', 'score': 1.6631351709365845},\n",
       " {'label': 'none', 'score': 1.9742790460586548},\n",
       " {'label': 'none', 'score': 1.9742790460586548},\n",
       " {'label': 'none', 'score': 1.9742790460586548},\n",
       " {'label': 'none', 'score': 1.6418077945709229},\n",
       " {'label': 'none', 'score': 1.6418077945709229},\n",
       " {'label': 'none', 'score': 1.6418077945709229},\n",
       " {'label': 'none', 'score': 1.952303409576416},\n",
       " {'label': 'none', 'score': 1.952303409576416},\n",
       " {'label': 'none', 'score': 1.952303409576416},\n",
       " {'label': 'none', 'score': 2.199455499649048},\n",
       " {'label': 'none', 'score': 2.199455499649048},\n",
       " {'label': 'none', 'score': 2.199455499649048},\n",
       " {'label': 'none', 'score': 2.1647632122039795},\n",
       " {'label': 'none', 'score': 2.1647632122039795},\n",
       " {'label': 'none', 'score': 2.1647632122039795},\n",
       " {'label': 'none', 'score': 1.9783573150634766},\n",
       " {'label': 'none', 'score': 1.9783573150634766},\n",
       " {'label': 'none', 'score': 1.9783573150634766},\n",
       " {'label': 'none', 'score': 1.978881597518921},\n",
       " {'label': 'none', 'score': 1.978881597518921},\n",
       " {'label': 'none', 'score': 1.978881597518921},\n",
       " {'label': 'none', 'score': 2.288677453994751},\n",
       " {'label': 'none', 'score': 2.288677453994751},\n",
       " {'label': 'none', 'score': 2.288677453994751},\n",
       " {'label': 'none', 'score': 1.52407968044281},\n",
       " {'label': 'none', 'score': 1.52407968044281},\n",
       " {'label': 'none', 'score': 1.52407968044281},\n",
       " {'label': 'none', 'score': 1.890899419784546},\n",
       " {'label': 'none', 'score': 1.890899419784546},\n",
       " {'label': 'none', 'score': 1.890899419784546},\n",
       " {'label': 'returning', 'score': 1.718227505683899},\n",
       " {'label': 'returning', 'score': 1.718227505683899},\n",
       " {'label': 'returning', 'score': 1.718227505683899},\n",
       " {'label': 'returning', 'score': 0.6749778985977173},\n",
       " {'label': 'returning', 'score': 0.6749778985977173},\n",
       " {'label': 'returning', 'score': 0.6749778985977173},\n",
       " {'label': 'returning', 'score': 0.4439464211463928},\n",
       " {'label': 'returning', 'score': 0.4439464211463928},\n",
       " {'label': 'returning', 'score': 0.4439464211463928},\n",
       " {'label': 'returning', 'score': 0.4672865867614746},\n",
       " {'label': 'returning', 'score': 0.4672865867614746},\n",
       " {'label': 'returning', 'score': 0.4672865867614746},\n",
       " {'label': 'returning', 'score': 0.4812321662902832},\n",
       " {'label': 'returning', 'score': 0.4812321662902832},\n",
       " {'label': 'returning', 'score': 0.4812321662902832},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.36973628401756287},\n",
       " {'label': 'returning', 'score': 0.36973628401756287},\n",
       " {'label': 'returning', 'score': 0.36973628401756287},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'leaving', 'score': 0.9506396055221558},\n",
       " {'label': 'returning', 'score': 0.9886391758918762},\n",
       " {'label': 'returning', 'score': 0.9886391758918762},\n",
       " {'label': 'returning', 'score': 0.9886391758918762},\n",
       " {'label': 'none', 'score': 1.9529732465744019},\n",
       " {'label': 'none', 'score': 1.9529732465744019},\n",
       " {'label': 'none', 'score': 1.9529732465744019},\n",
       " {'label': 'none', 'score': 1.634975552558899},\n",
       " {'label': 'none', 'score': 1.634975552558899},\n",
       " {'label': 'none', 'score': 1.634975552558899},\n",
       " {'label': 'none', 'score': 2.1784372329711914},\n",
       " {'label': 'none', 'score': 2.1784372329711914},\n",
       " {'label': 'none', 'score': 2.1784372329711914},\n",
       " {'label': 'none', 'score': 2.8515920639038086},\n",
       " {'label': 'none', 'score': 2.8515920639038086},\n",
       " {'label': 'none', 'score': 2.8515920639038086}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:39.913171Z",
     "start_time": "2020-04-03T01:59:39.901446Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " with open(os.path.join(results_path,'validation_results.json'),\n",
    "              'w') as f:\n",
    "        json.dump(video_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:39.924956Z",
     "start_time": "2020-04-03T01:59:39.914435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'leaving', 2: 'returning'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:40.108507Z",
     "start_time": "2020-04-03T01:59:39.926217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(pred_final, color='steelblue')\n",
    "ax.plot(label_final, color='red')\n",
    "plt.title('Comparison of model and truth for validation input')\n",
    "plt.legend(['Predicted Class','True Class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the model is struggling to predict leaving vs entering. Overall, a good start, need more data\n",
    "\n",
    "## Still a little bit of underfitting\n",
    "- Areas for improvment\n",
    "    - ~~More diverse dataset~~ (2020-04-01)\n",
    "    - Hyperparameter tuning (some improvement 2020-04-04)\n",
    "    - Make video window overlapping\n",
    "    - ~~How to freeze some layers?~~ (2020-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:59:41.290909Z",
     "start_time": "2020-04-03T01:59:40.109640Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_save_path=Path('/media/tris/tris_files/CSCE636-project-porta/porta.pth')\n",
    "torch.save(my_model.state_dict(), weight_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
